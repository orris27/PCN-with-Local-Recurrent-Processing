==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=128, out_features=32, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=128, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=32, out_features=100, bias=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=288, out_features=64, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64])
      (linear_bw): Linear(in_features=64, out_features=288, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=64, out_features=100, bias=True)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=576, out_features=64, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64])
      (linear_bw): Linear(in_features=64, out_features=576, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=64, out_features=100, bias=True)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 14.110 | Acc: 0.000,3.125,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.808 | Acc: 1.376,2.158,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.647 | Acc: 1.639,2.744,3.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.535 | Acc: 2.024,3.343,3.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.427 | Acc: 2.614,3.810,4.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.329 | Acc: 3.009,4.169,4.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.243 | Acc: 3.280,4.507,5.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.159 | Acc: 3.485,5.003,5.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.088 | Acc: 3.717,5.280,6.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.016 | Acc: 3.850,5.525,6.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.951 | Acc: 3.996,5.749,6.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.884 | Acc: 4.154,5.981,6.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.822 | Acc: 4.302,6.221,7.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.767 | Acc: 4.382,6.376,7.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.716 | Acc: 4.554,6.592,7.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.663 | Acc: 4.732,6.746,7.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.605 | Acc: 4.936,7.002,8.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.561 | Acc: 5.043,7.171,8.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.514 | Acc: 5.125,7.367,8.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.471 | Acc: 5.233,7.538,8.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.589 | Acc: 10.156,11.719,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.803 | Acc: 7.738,10.454,10.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.793 | Acc: 7.622,10.404,10.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.790 | Acc: 7.390,10.643,10.771,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 11.314 | Acc: 10.938,11.719,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.478 | Acc: 7.478,11.421,13.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.399 | Acc: 8.441,12.309,14.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.406 | Acc: 8.210,12.001,13.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.405 | Acc: 8.073,11.941,13.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.397 | Acc: 8.153,11.873,13.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.374 | Acc: 8.284,12.074,13.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.342 | Acc: 8.350,12.112,13.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.339 | Acc: 8.307,12.107,13.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.322 | Acc: 8.309,12.168,13.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.306 | Acc: 8.431,12.224,13.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.280 | Acc: 8.576,12.468,14.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.251 | Acc: 8.685,12.610,14.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.221 | Acc: 8.728,12.781,14.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.189 | Acc: 8.788,12.959,14.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.160 | Acc: 8.833,13.097,14.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.132 | Acc: 8.937,13.252,15.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.103 | Acc: 9.008,13.442,15.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.080 | Acc: 9.055,13.560,15.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.055 | Acc: 9.086,13.656,15.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.986 | Acc: 7.812,17.969,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.037 | Acc: 9.412,13.653,17.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.976 | Acc: 8.822,13.643,17.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.966 | Acc: 8.940,13.717,17.969,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 10.435 | Acc: 14.062,23.438,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.460 | Acc: 11.644,17.485,21.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.477 | Acc: 11.643,17.207,20.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.452 | Acc: 11.386,16.995,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.415 | Acc: 11.468,17.313,20.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.396 | Acc: 11.409,17.218,20.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.376 | Acc: 11.467,17.330,20.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.335 | Acc: 11.547,17.625,20.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.316 | Acc: 11.520,17.770,21.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.278 | Acc: 11.585,18.025,21.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.249 | Acc: 11.719,18.113,21.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.221 | Acc: 11.857,18.223,21.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.201 | Acc: 11.939,18.419,21.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.181 | Acc: 11.961,18.528,21.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.155 | Acc: 12.083,18.700,22.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.127 | Acc: 12.189,18.836,22.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.109 | Acc: 12.257,18.928,22.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.079 | Acc: 12.379,19.110,22.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.055 | Acc: 12.496,19.269,22.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.028 | Acc: 12.670,19.418,23.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.115 | Acc: 12.500,20.312,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.900 | Acc: 13.504,20.275,24.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.875 | Acc: 13.472,20.236,24.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.872 | Acc: 13.550,20.735,23.604,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 9.112 | Acc: 18.750,25.000,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.548 | Acc: 15.923,24.107,26.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.529 | Acc: 15.644,22.961,25.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.503 | Acc: 15.561,22.413,26.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.467 | Acc: 15.152,22.521,26.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.417 | Acc: 15.679,22.757,27.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.410 | Acc: 15.638,23.076,27.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.399 | Acc: 15.642,22.972,27.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.376 | Acc: 15.717,23.015,27.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.364 | Acc: 15.858,23.161,27.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.334 | Acc: 15.940,23.422,27.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.322 | Acc: 16.046,23.476,27.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.308 | Acc: 16.179,23.554,28.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.281 | Acc: 16.340,23.668,28.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.265 | Acc: 16.484,23.774,28.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.253 | Acc: 16.570,23.840,28.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.230 | Acc: 16.635,23.922,28.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.209 | Acc: 16.748,23.992,28.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.187 | Acc: 16.915,24.137,29.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.165 | Acc: 17.077,24.284,29.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.854 | Acc: 17.969,29.688,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.004 | Acc: 19.010,23.586,32.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.999 | Acc: 18.655,23.285,31.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.995 | Acc: 18.225,23.181,31.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 8.857 | Acc: 16.406,26.562,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.709 | Acc: 19.494,26.228,33.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.705 | Acc: 19.588,26.391,33.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.662 | Acc: 19.518,26.857,33.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.615 | Acc: 19.917,27.112,33.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.600 | Acc: 19.872,27.259,34.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.607 | Acc: 19.564,27.228,34.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.592 | Acc: 19.614,27.227,34.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.575 | Acc: 19.623,27.363,34.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.582 | Acc: 19.436,27.249,34.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.583 | Acc: 19.543,27.421,34.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.576 | Acc: 19.538,27.574,34.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.564 | Acc: 19.632,27.668,34.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.551 | Acc: 19.849,27.742,34.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.530 | Acc: 19.962,27.961,34.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.515 | Acc: 20.120,28.120,34.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.498 | Acc: 20.237,28.174,35.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.487 | Acc: 20.356,28.269,35.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.469 | Acc: 20.460,28.432,35.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.464 | Acc: 20.489,28.459,35.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.708 | Acc: 17.969,28.125,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.692 | Acc: 17.932,26.897,35.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.685 | Acc: 17.835,26.677,35.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.682 | Acc: 17.789,26.409,35.489,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 8.249 | Acc: 22.656,26.562,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.107 | Acc: 22.545,30.655,37.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.121 | Acc: 22.523,30.850,37.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.078 | Acc: 22.349,30.917,38.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.078 | Acc: 22.396,31.047,38.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.083 | Acc: 22.177,30.956,38.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.051 | Acc: 22.404,31.282,38.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.026 | Acc: 22.579,31.566,38.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.010 | Acc: 22.516,31.614,38.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.994 | Acc: 22.505,31.746,39.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.982 | Acc: 22.532,32.008,39.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.971 | Acc: 22.564,31.999,39.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.964 | Acc: 22.582,31.992,39.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.949 | Acc: 22.611,32.085,40.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.940 | Acc: 22.642,32.101,40.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.930 | Acc: 22.664,32.213,40.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.917 | Acc: 22.705,32.311,40.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.902 | Acc: 22.755,32.368,40.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.893 | Acc: 22.875,32.462,40.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.888 | Acc: 22.915,32.499,40.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.972 | Acc: 17.969,32.812,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.344 | Acc: 16.406,30.097,41.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.329 | Acc: 15.968,30.354,40.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.322 | Acc: 16.201,30.328,40.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 7.527 | Acc: 27.344,34.375,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.545 | Acc: 24.330,34.189,44.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.532 | Acc: 24.676,34.184,43.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.588 | Acc: 24.039,34.298,43.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.568 | Acc: 24.325,34.471,43.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.546 | Acc: 24.420,34.808,43.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.519 | Acc: 24.580,34.904,43.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.510 | Acc: 24.679,35.007,43.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.513 | Acc: 24.655,34.826,43.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.493 | Acc: 24.875,34.923,43.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.472 | Acc: 25.082,35.129,44.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.472 | Acc: 25.078,35.086,44.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.479 | Acc: 25.084,34.981,44.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.468 | Acc: 25.186,35.084,44.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.474 | Acc: 25.114,35.078,44.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.457 | Acc: 25.218,35.302,44.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.438 | Acc: 25.246,35.373,44.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.425 | Acc: 25.394,35.486,45.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.419 | Acc: 25.387,35.652,45.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.410 | Acc: 25.355,35.704,45.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.711 | Acc: 25.781,34.375,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.598 | Acc: 24.144,33.780,45.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.560 | Acc: 24.085,34.013,45.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.549 | Acc: 24.027,34.298,45.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 6.791 | Acc: 24.219,33.594,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.065 | Acc: 27.865,37.946,47.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.121 | Acc: 27.439,37.519,47.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.111 | Acc: 27.152,37.871,47.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.097 | Acc: 27.016,38.108,48.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.103 | Acc: 27.065,37.910,48.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.104 | Acc: 26.950,38.100,48.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.096 | Acc: 26.950,38.259,47.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.078 | Acc: 27.023,38.441,48.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.061 | Acc: 27.050,38.523,48.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.054 | Acc: 27.041,38.569,48.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.058 | Acc: 26.881,38.486,48.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.058 | Acc: 26.864,38.408,48.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.040 | Acc: 26.922,38.602,48.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.040 | Acc: 26.921,38.623,48.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.027 | Acc: 27.141,38.769,48.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.016 | Acc: 27.242,38.946,48.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.020 | Acc: 27.188,38.936,48.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.011 | Acc: 27.259,38.993,49.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.002 | Acc: 27.315,39.097,49.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.028 | Acc: 23.438,42.969,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.337 | Acc: 22.359,36.086,48.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.345 | Acc: 22.618,36.376,47.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.348 | Acc: 22.669,36.219,48.105,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 6.549 | Acc: 28.125,44.531,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.700 | Acc: 28.981,40.365,52.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.717 | Acc: 29.059,40.739,52.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.696 | Acc: 28.945,41.432,52.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.704 | Acc: 28.954,41.271,52.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.711 | Acc: 28.860,41.236,52.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.708 | Acc: 28.835,41.206,52.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.705 | Acc: 28.690,41.174,52.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.715 | Acc: 28.567,41.149,52.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.721 | Acc: 28.414,41.195,52.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.704 | Acc: 28.591,41.449,52.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.691 | Acc: 28.687,41.541,52.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.687 | Acc: 28.751,41.649,52.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.679 | Acc: 28.888,41.765,52.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.679 | Acc: 28.881,41.712,52.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.667 | Acc: 28.937,41.806,52.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.665 | Acc: 28.938,41.832,52.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.653 | Acc: 29.078,41.917,52.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.642 | Acc: 29.170,42.010,52.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.639 | Acc: 29.136,41.999,52.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.863 | Acc: 22.656,40.625,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.066 | Acc: 23.065,40.551,49.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.042 | Acc: 24.085,40.396,50.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.061 | Acc: 24.065,40.382,50.384,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 6.293 | Acc: 32.812,46.875,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.432 | Acc: 29.948,44.978,55.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.292 | Acc: 30.640,45.255,56.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.284 | Acc: 31.084,44.967,56.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.284 | Acc: 30.951,44.801,56.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.309 | Acc: 30.647,44.632,56.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.312 | Acc: 30.817,44.493,56.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.334 | Acc: 30.436,44.199,55.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.357 | Acc: 30.284,44.109,55.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.362 | Acc: 30.313,44.091,55.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.370 | Acc: 30.290,44.119,55.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.374 | Acc: 30.395,44.075,55.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.375 | Acc: 30.368,44.077,55.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.371 | Acc: 30.451,44.166,55.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.364 | Acc: 30.491,44.192,55.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.358 | Acc: 30.521,44.329,55.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.348 | Acc: 30.593,44.375,55.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.341 | Acc: 30.707,44.403,55.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.347 | Acc: 30.629,44.362,55.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.343 | Acc: 30.678,44.435,55.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.912 | Acc: 25.781,37.500,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.861 | Acc: 26.637,39.955,52.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.865 | Acc: 26.696,40.644,52.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.868 | Acc: 26.908,40.279,52.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 5.319 | Acc: 35.938,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.004 | Acc: 32.440,46.615,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.026 | Acc: 31.993,46.437,58.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.030 | Acc: 31.890,46.286,58.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.020 | Acc: 32.079,46.721,59.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.057 | Acc: 31.745,46.573,58.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.062 | Acc: 31.708,46.488,58.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.090 | Acc: 31.660,46.205,58.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.078 | Acc: 31.721,46.409,58.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.085 | Acc: 31.617,46.383,58.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.079 | Acc: 31.654,46.409,58.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.076 | Acc: 31.766,46.465,58.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.074 | Acc: 31.765,46.418,58.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.069 | Acc: 31.885,46.576,58.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.057 | Acc: 32.020,46.664,58.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.053 | Acc: 31.995,46.623,58.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.061 | Acc: 31.946,46.600,58.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.064 | Acc: 31.866,46.552,58.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.065 | Acc: 31.975,46.533,58.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.066 | Acc: 32.058,46.528,58.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.178 | Acc: 28.125,50.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.860 | Acc: 26.302,42.597,54.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.835 | Acc: 25.915,43.426,54.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.845 | Acc: 25.423,43.186,54.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 5.797 | Acc: 35.156,51.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.744 | Acc: 32.478,48.698,61.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.795 | Acc: 32.450,48.323,61.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.798 | Acc: 32.684,48.604,61.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.780 | Acc: 33.160,49.026,61.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.809 | Acc: 32.944,48.793,61.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.792 | Acc: 32.916,48.722,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.778 | Acc: 33.023,49.064,61.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.796 | Acc: 33.133,49.063,61.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.804 | Acc: 33.283,49.132,60.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.810 | Acc: 33.283,49.048,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.813 | Acc: 33.357,48.961,60.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.822 | Acc: 33.315,48.830,60.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.834 | Acc: 33.169,48.785,60.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.841 | Acc: 33.146,48.685,60.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.850 | Acc: 33.132,48.539,60.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.849 | Acc: 33.143,48.647,60.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.848 | Acc: 33.191,48.673,60.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.837 | Acc: 33.263,48.738,60.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.847 | Acc: 33.141,48.620,60.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.235 | Acc: 28.906,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.386 | Acc: 28.571,45.796,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.380 | Acc: 28.601,44.855,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.386 | Acc: 28.471,44.980,55.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 5.743 | Acc: 31.250,50.781,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.661 | Acc: 32.031,50.298,64.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.664 | Acc: 32.851,50.400,63.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.660 | Acc: 32.812,50.333,63.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.640 | Acc: 33.459,50.945,63.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.646 | Acc: 33.385,50.843,63.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.624 | Acc: 33.587,50.885,63.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.624 | Acc: 33.610,51.036,63.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.632 | Acc: 33.623,50.839,63.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.627 | Acc: 33.520,50.794,63.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.635 | Acc: 33.524,50.661,63.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.635 | Acc: 33.601,50.622,63.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.618 | Acc: 33.740,50.655,63.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.614 | Acc: 33.872,50.721,63.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.623 | Acc: 33.869,50.676,63.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.620 | Acc: 33.905,50.664,62.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.623 | Acc: 33.900,50.662,62.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.639 | Acc: 33.818,50.541,62.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.642 | Acc: 33.763,50.563,62.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.638 | Acc: 33.801,50.591,62.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.809 | Acc: 38.281,57.812,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.239 | Acc: 30.357,47.433,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.196 | Acc: 30.507,46.837,58.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.180 | Acc: 30.405,46.875,58.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 6.382 | Acc: 31.250,48.438,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.526 | Acc: 35.045,51.004,64.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.431 | Acc: 35.213,52.591,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.460 | Acc: 34.618,52.561,65.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.458 | Acc: 34.558,52.508,65.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.471 | Acc: 34.491,52.382,65.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.450 | Acc: 34.808,52.628,65.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.462 | Acc: 34.646,52.333,65.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.445 | Acc: 34.885,52.572,65.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.435 | Acc: 35.070,52.693,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.421 | Acc: 35.067,52.659,65.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.411 | Acc: 34.994,52.658,65.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.426 | Acc: 34.813,52.422,65.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.424 | Acc: 34.878,52.416,65.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.427 | Acc: 34.820,52.422,65.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.427 | Acc: 34.868,52.336,65.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.421 | Acc: 34.962,52.407,65.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.427 | Acc: 34.916,52.367,65.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.427 | Acc: 34.918,52.381,65.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.430 | Acc: 34.957,52.276,65.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.936 | Acc: 33.594,51.562,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.156 | Acc: 30.990,48.214,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.138 | Acc: 30.774,47.999,58.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.129 | Acc: 30.610,47.579,58.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 4.969 | Acc: 43.750,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.084 | Acc: 37.872,55.283,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.094 | Acc: 36.986,54.402,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.157 | Acc: 36.040,53.560,68.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.171 | Acc: 35.899,53.376,68.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.182 | Acc: 35.767,53.721,67.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.197 | Acc: 35.938,53.545,67.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.226 | Acc: 35.744,53.430,67.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.237 | Acc: 35.734,53.571,67.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.249 | Acc: 35.640,53.367,66.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.260 | Acc: 35.642,53.347,66.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.251 | Acc: 35.761,53.549,66.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.244 | Acc: 35.672,53.712,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.249 | Acc: 35.707,53.706,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.250 | Acc: 35.648,53.714,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.254 | Acc: 35.582,53.704,67.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.253 | Acc: 35.631,53.685,67.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.254 | Acc: 35.679,53.744,67.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.262 | Acc: 35.676,53.711,67.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.263 | Acc: 35.722,53.697,67.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.496 | Acc: 34.375,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.882 | Acc: 29.725,51.488,62.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.885 | Acc: 30.678,50.724,61.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.899 | Acc: 30.379,50.589,61.002,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 4.898 | Acc: 37.500,57.812,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.081 | Acc: 36.830,53.869,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.026 | Acc: 36.852,54.821,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.034 | Acc: 36.860,54.700,69.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.040 | Acc: 36.825,54.784,69.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.070 | Acc: 36.672,54.695,69.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.065 | Acc: 36.816,54.875,69.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.084 | Acc: 36.564,54.671,69.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.096 | Acc: 36.457,54.508,69.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.104 | Acc: 36.408,54.571,69.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.109 | Acc: 36.412,54.361,68.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.107 | Acc: 36.496,54.419,68.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.098 | Acc: 36.495,54.600,69.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.088 | Acc: 36.596,54.816,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.088 | Acc: 36.627,54.904,68.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.101 | Acc: 36.498,54.799,68.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.116 | Acc: 36.376,54.685,68.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.117 | Acc: 36.425,54.658,68.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.121 | Acc: 36.360,54.599,68.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.118 | Acc: 36.387,54.587,68.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.948 | Acc: 30.469,50.000,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.238 | Acc: 28.646,48.996,60.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.245 | Acc: 27.973,48.704,60.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.260 | Acc: 27.830,48.681,60.220,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 4.624 | Acc: 42.188,63.281,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.776 | Acc: 37.351,59.077,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.792 | Acc: 37.462,58.422,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.832 | Acc: 37.564,58.069,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.857 | Acc: 37.297,57.745,71.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.863 | Acc: 37.183,57.387,71.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.884 | Acc: 37.203,57.154,71.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.899 | Acc: 37.184,56.948,71.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.911 | Acc: 37.354,56.827,71.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.917 | Acc: 37.271,56.802,71.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.923 | Acc: 37.345,56.798,71.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.939 | Acc: 37.051,56.639,70.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.944 | Acc: 37.043,56.645,70.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.948 | Acc: 37.078,56.534,70.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.955 | Acc: 37.013,56.514,70.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.964 | Acc: 36.924,56.390,70.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.973 | Acc: 36.918,56.389,70.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.974 | Acc: 36.955,56.360,70.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.970 | Acc: 37.063,56.404,70.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.974 | Acc: 37.024,56.320,70.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.919 | Acc: 35.156,48.438,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.186 | Acc: 26.749,49.740,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.163 | Acc: 27.401,49.257,61.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.156 | Acc: 27.459,49.372,61.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 5.788 | Acc: 27.344,47.656,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.749 | Acc: 38.021,58.222,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.702 | Acc: 38.357,58.041,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.741 | Acc: 38.153,57.390,73.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.753 | Acc: 37.944,57.514,73.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.758 | Acc: 38.049,57.696,73.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.773 | Acc: 37.984,57.774,72.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.778 | Acc: 38.159,57.968,72.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.799 | Acc: 37.840,57.793,72.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.812 | Acc: 37.664,57.597,72.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.805 | Acc: 37.823,57.673,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.801 | Acc: 37.829,57.784,72.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.808 | Acc: 37.840,57.660,72.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.814 | Acc: 37.874,57.546,72.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.826 | Acc: 37.959,57.490,72.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.827 | Acc: 37.931,57.569,71.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.836 | Acc: 37.870,57.506,71.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.841 | Acc: 37.807,57.409,71.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.845 | Acc: 37.784,57.380,71.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.847 | Acc: 37.812,57.353,71.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.468 | Acc: 31.250,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.736 | Acc: 32.850,53.609,62.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.693 | Acc: 33.041,52.973,62.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.682 | Acc: 33.133,52.843,61.796,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 4.822 | Acc: 32.812,61.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.676 | Acc: 37.649,59.338,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.692 | Acc: 38.129,59.089,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.655 | Acc: 38.665,58.952,74.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.646 | Acc: 38.667,59.047,74.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.645 | Acc: 38.776,59.197,74.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.641 | Acc: 38.623,58.994,74.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.646 | Acc: 38.680,59.065,74.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.653 | Acc: 38.568,58.963,74.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.664 | Acc: 38.484,58.702,73.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.658 | Acc: 38.534,58.769,73.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.673 | Acc: 38.366,58.534,73.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.684 | Acc: 38.388,58.484,73.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.703 | Acc: 38.287,58.330,73.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.708 | Acc: 38.240,58.416,73.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.715 | Acc: 38.190,58.381,73.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.717 | Acc: 38.308,58.290,73.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.721 | Acc: 38.320,58.330,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.728 | Acc: 38.247,58.295,73.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.735 | Acc: 38.228,58.257,72.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.724 | Acc: 35.156,55.469,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.973 | Acc: 29.129,51.339,64.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.960 | Acc: 29.611,51.448,62.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.940 | Acc: 29.521,51.575,62.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 4.481 | Acc: 39.062,57.031,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.513 | Acc: 39.286,60.677,76.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.495 | Acc: 39.596,60.461,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.514 | Acc: 39.511,60.054,76.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.530 | Acc: 39.275,59.954,76.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.561 | Acc: 39.295,59.653,76.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.556 | Acc: 38.920,59.840,75.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.556 | Acc: 39.245,59.791,75.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.569 | Acc: 39.179,59.516,75.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.571 | Acc: 39.170,59.543,75.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.568 | Acc: 39.206,59.600,75.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.583 | Acc: 39.098,59.485,74.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.598 | Acc: 38.926,59.378,74.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.602 | Acc: 38.820,59.375,74.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.603 | Acc: 38.837,59.433,74.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.606 | Acc: 38.928,59.378,74.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.617 | Acc: 38.912,59.300,74.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.625 | Acc: 38.898,59.212,74.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.631 | Acc: 38.853,59.180,74.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.629 | Acc: 38.859,59.174,74.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.381 | Acc: 29.688,52.344,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.758 | Acc: 30.134,54.018,64.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.729 | Acc: 30.583,53.316,63.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.743 | Acc: 30.430,53.394,63.384,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 4.048 | Acc: 39.062,62.500,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.442 | Acc: 39.509,60.975,76.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.379 | Acc: 40.625,61.338,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.358 | Acc: 40.753,61.578,77.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.378 | Acc: 40.336,61.130,77.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.415 | Acc: 40.014,60.968,77.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.446 | Acc: 39.760,60.640,76.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.448 | Acc: 39.423,60.655,76.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.462 | Acc: 39.271,60.666,76.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.482 | Acc: 39.347,60.437,76.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.475 | Acc: 39.234,60.529,76.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.485 | Acc: 39.260,60.503,76.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.483 | Acc: 39.276,60.526,76.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.491 | Acc: 39.248,60.432,76.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.497 | Acc: 39.257,60.484,76.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.505 | Acc: 39.229,60.379,75.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.508 | Acc: 39.179,60.375,75.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.515 | Acc: 39.200,60.317,75.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.521 | Acc: 39.197,60.267,75.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.526 | Acc: 39.149,60.222,75.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.189 | Acc: 38.281,56.250,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.717 | Acc: 32.664,52.865,63.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.676 | Acc: 33.022,53.087,63.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.661 | Acc: 32.966,53.266,62.999,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 4.358 | Acc: 33.594,62.500,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.409 | Acc: 39.658,62.240,78.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.391 | Acc: 40.015,61.871,78.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.382 | Acc: 39.908,62.141,78.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.372 | Acc: 39.709,61.998,78.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.364 | Acc: 39.534,62.136,78.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.375 | Acc: 39.598,61.919,77.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.409 | Acc: 39.484,61.486,77.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.418 | Acc: 39.417,61.321,77.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.418 | Acc: 39.451,61.460,77.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.408 | Acc: 39.572,61.552,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.417 | Acc: 39.600,61.404,77.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.418 | Acc: 39.490,61.271,77.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.426 | Acc: 39.574,61.288,76.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.428 | Acc: 39.619,61.193,76.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.432 | Acc: 39.639,61.137,76.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.432 | Acc: 39.683,61.103,76.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.437 | Acc: 39.654,61.084,76.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.443 | Acc: 39.679,61.044,76.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.444 | Acc: 39.692,60.997,76.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.538 | Acc: 35.938,50.781,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.670 | Acc: 32.031,53.757,62.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.658 | Acc: 31.536,53.544,63.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.647 | Acc: 31.814,54.009,63.537,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 4.222 | Acc: 41.406,63.281,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.322 | Acc: 39.546,62.909,78.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.336 | Acc: 40.282,61.871,77.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.259 | Acc: 40.984,62.487,78.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.259 | Acc: 40.779,62.278,78.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.278 | Acc: 40.695,62.121,78.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.265 | Acc: 40.909,62.313,78.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.275 | Acc: 40.603,62.262,78.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.276 | Acc: 40.562,62.350,78.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.296 | Acc: 40.284,62.051,78.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.306 | Acc: 40.295,61.975,78.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.316 | Acc: 40.233,61.821,78.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.311 | Acc: 40.340,61.975,78.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.315 | Acc: 40.389,61.874,78.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.330 | Acc: 40.264,61.735,77.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.334 | Acc: 40.269,61.768,77.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.341 | Acc: 40.260,61.777,77.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.348 | Acc: 40.245,61.735,77.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.355 | Acc: 40.326,61.639,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.363 | Acc: 40.309,61.579,77.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.217 | Acc: 39.062,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.640 | Acc: 33.073,54.948,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.570 | Acc: 33.803,55.450,65.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.584 | Acc: 33.440,54.982,65.241,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 4.524 | Acc: 42.188,60.156,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.243 | Acc: 40.588,62.686,79.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.212 | Acc: 40.473,63.281,80.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.196 | Acc: 40.727,63.473,80.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.177 | Acc: 40.808,63.696,80.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.198 | Acc: 40.501,63.490,80.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.201 | Acc: 40.470,63.333,80.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.220 | Acc: 40.342,63.043,79.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.238 | Acc: 40.222,62.704,79.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.245 | Acc: 40.189,62.535,79.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.243 | Acc: 40.353,62.558,79.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.266 | Acc: 40.197,62.295,79.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.257 | Acc: 40.512,62.448,79.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.257 | Acc: 40.586,62.482,79.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.255 | Acc: 40.664,62.489,79.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.268 | Acc: 40.594,62.404,78.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.265 | Acc: 40.525,62.478,78.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.269 | Acc: 40.460,62.509,78.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.275 | Acc: 40.380,62.392,78.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.283 | Acc: 40.381,62.315,78.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.927 | Acc: 36.719,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.539 | Acc: 33.817,54.539,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.556 | Acc: 34.089,54.402,64.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.595 | Acc: 33.607,54.521,64.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 3.542 | Acc: 44.531,69.531,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.068 | Acc: 40.588,64.062,82.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.057 | Acc: 41.101,63.948,82.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.102 | Acc: 40.535,63.819,82.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.091 | Acc: 41.011,63.754,81.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.102 | Acc: 41.050,63.699,81.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.105 | Acc: 41.077,63.436,81.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.111 | Acc: 41.174,63.314,81.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.118 | Acc: 41.105,63.223,81.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.138 | Acc: 41.031,63.126,80.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.145 | Acc: 40.971,63.153,80.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.145 | Acc: 41.007,63.172,80.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.156 | Acc: 40.949,63.106,80.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.164 | Acc: 40.963,63.048,80.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.171 | Acc: 41.050,63.050,79.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.189 | Acc: 40.921,62.918,79.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.198 | Acc: 40.873,62.880,79.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.205 | Acc: 40.870,62.830,79.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.213 | Acc: 40.867,62.831,79.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.217 | Acc: 40.894,62.799,79.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.941 | Acc: 39.062,55.469,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.386 | Acc: 35.975,55.134,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.388 | Acc: 36.147,54.973,65.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.394 | Acc: 35.848,55.020,64.882,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 4.167 | Acc: 40.625,65.625,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.130 | Acc: 40.104,64.621,82.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.078 | Acc: 41.387,64.367,81.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.064 | Acc: 41.240,64.191,81.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.082 | Acc: 40.972,64.198,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.077 | Acc: 41.128,64.202,82.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.100 | Acc: 41.264,63.714,81.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.103 | Acc: 41.428,63.669,81.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.102 | Acc: 41.479,63.810,81.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.110 | Acc: 41.480,63.596,81.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.094 | Acc: 41.632,63.829,81.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.097 | Acc: 41.671,63.861,81.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.103 | Acc: 41.756,63.797,81.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.109 | Acc: 41.700,63.757,81.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.114 | Acc: 41.590,63.754,80.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.123 | Acc: 41.554,63.660,80.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.127 | Acc: 41.508,63.588,80.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.139 | Acc: 41.374,63.428,80.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.149 | Acc: 41.365,63.363,80.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.156 | Acc: 41.291,63.333,80.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.064 | Acc: 37.500,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.511 | Acc: 34.859,55.506,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.492 | Acc: 34.870,54.707,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.496 | Acc: 34.157,54.803,65.881,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 3.379 | Acc: 49.219,70.312,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.933 | Acc: 42.708,65.104,82.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.867 | Acc: 42.950,66.178,82.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.909 | Acc: 42.905,65.996,83.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.920 | Acc: 42.496,65.664,82.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.936 | Acc: 42.319,65.277,82.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.947 | Acc: 42.362,65.050,82.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.957 | Acc: 42.309,64.910,82.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.982 | Acc: 41.979,64.596,82.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.992 | Acc: 41.967,64.490,82.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.999 | Acc: 42.051,64.494,82.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.011 | Acc: 41.905,64.444,81.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.015 | Acc: 41.961,64.367,81.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.020 | Acc: 41.978,64.437,81.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.040 | Acc: 41.848,64.249,81.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.050 | Acc: 41.790,64.218,81.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.054 | Acc: 41.676,64.179,81.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.054 | Acc: 41.812,64.163,81.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.067 | Acc: 41.755,64.093,81.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.070 | Acc: 41.697,64.052,80.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.420 | Acc: 36.719,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.530 | Acc: 35.565,55.841,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.543 | Acc: 35.690,54.726,65.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.524 | Acc: 35.873,54.098,65.356,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 4.031 | Acc: 38.281,58.594,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.922 | Acc: 41.481,64.360,83.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.919 | Acc: 41.940,64.901,82.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.879 | Acc: 42.713,65.433,82.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.880 | Acc: 42.901,65.432,82.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.905 | Acc: 42.597,65.478,82.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.917 | Acc: 42.349,65.444,83.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.935 | Acc: 42.115,65.376,82.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.953 | Acc: 42.163,65.271,82.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.953 | Acc: 42.226,65.241,82.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.953 | Acc: 42.374,65.252,82.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.954 | Acc: 42.410,65.268,82.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.957 | Acc: 42.470,65.129,82.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.979 | Acc: 42.412,64.916,81.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.995 | Acc: 42.379,64.674,81.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.999 | Acc: 42.374,64.576,81.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.009 | Acc: 42.324,64.532,81.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.025 | Acc: 42.192,64.376,81.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.034 | Acc: 42.149,64.244,81.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.045 | Acc: 42.030,64.149,81.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.066 | Acc: 43.750,53.906,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.514 | Acc: 34.747,54.055,65.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.554 | Acc: 34.832,53.144,64.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.583 | Acc: 34.913,53.458,64.178,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 3.210 | Acc: 47.656,72.656,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.842 | Acc: 42.039,66.629,83.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.813 | Acc: 42.645,66.425,84.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.812 | Acc: 42.789,66.406,84.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.816 | Acc: 42.872,66.454,84.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.822 | Acc: 43.100,66.422,84.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.831 | Acc: 43.221,66.355,84.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.868 | Acc: 42.902,66.135,83.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.885 | Acc: 42.746,65.960,83.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.892 | Acc: 42.740,65.845,83.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.900 | Acc: 42.798,65.757,83.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.911 | Acc: 42.827,65.636,82.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.926 | Acc: 42.612,65.424,82.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.945 | Acc: 42.406,65.287,82.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.954 | Acc: 42.293,65.236,82.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.959 | Acc: 42.413,65.218,82.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.975 | Acc: 42.263,65.094,81.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.984 | Acc: 42.224,65.032,81.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.988 | Acc: 42.248,64.982,81.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.995 | Acc: 42.212,64.911,81.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.647 | Acc: 32.812,50.000,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.602 | Acc: 35.491,53.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.585 | Acc: 35.271,54.135,65.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.612 | Acc: 34.426,53.919,64.805,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 3.152 | Acc: 49.219,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.776 | Acc: 43.080,68.415,84.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.764 | Acc: 43.121,68.121,84.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.770 | Acc: 43.430,68.379,84.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.788 | Acc: 43.316,67.689,84.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.808 | Acc: 43.085,67.319,84.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.845 | Acc: 42.930,66.819,84.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.867 | Acc: 42.725,66.417,83.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.877 | Acc: 42.629,66.290,83.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.877 | Acc: 42.533,66.221,83.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.869 | Acc: 42.662,66.336,83.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.877 | Acc: 42.608,66.222,83.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.876 | Acc: 42.641,66.160,83.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.876 | Acc: 42.693,66.212,83.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.892 | Acc: 42.605,66.028,83.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.894 | Acc: 42.696,66.038,83.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.900 | Acc: 42.711,65.842,82.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.913 | Acc: 42.664,65.742,82.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.928 | Acc: 42.620,65.571,82.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.934 | Acc: 42.493,65.426,82.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.920 | Acc: 45.312,56.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.270 | Acc: 37.723,56.659,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.281 | Acc: 38.396,56.803,64.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.296 | Acc: 38.115,56.826,64.588,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 3.826 | Acc: 35.156,63.281,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.749 | Acc: 43.080,68.452,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.766 | Acc: 42.435,67.130,84.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.783 | Acc: 42.700,66.880,84.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.770 | Acc: 42.834,67.130,84.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.802 | Acc: 42.775,66.723,83.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.819 | Acc: 42.659,66.529,83.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.825 | Acc: 42.675,66.362,83.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.833 | Acc: 42.615,66.236,83.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.833 | Acc: 42.688,66.247,83.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.839 | Acc: 42.650,66.165,83.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.854 | Acc: 42.640,65.908,83.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.861 | Acc: 42.538,65.842,83.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.868 | Acc: 42.490,65.757,83.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.873 | Acc: 42.602,65.717,83.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.879 | Acc: 42.642,65.602,83.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.889 | Acc: 42.665,65.530,82.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.892 | Acc: 42.698,65.545,82.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.898 | Acc: 42.692,65.528,82.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.904 | Acc: 42.657,65.518,82.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.136 | Acc: 41.406,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.369 | Acc: 35.603,54.725,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.390 | Acc: 35.995,55.069,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.424 | Acc: 36.078,54.816,66.086,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 3.795 | Acc: 44.531,67.188,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.764 | Acc: 42.411,66.629,85.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.724 | Acc: 42.588,67.054,85.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.729 | Acc: 42.392,67.213,85.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.743 | Acc: 42.535,67.226,85.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.765 | Acc: 42.830,66.994,84.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.773 | Acc: 42.859,66.897,84.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.794 | Acc: 42.780,66.700,84.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.806 | Acc: 42.877,66.528,84.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.812 | Acc: 42.848,66.514,84.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.813 | Acc: 42.949,66.659,84.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.817 | Acc: 42.965,66.654,83.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.824 | Acc: 42.923,66.552,83.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.822 | Acc: 43.056,66.520,83.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.825 | Acc: 43.041,66.465,83.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.833 | Acc: 43.117,66.313,83.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.844 | Acc: 43.064,66.277,83.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.858 | Acc: 43.040,66.207,83.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.868 | Acc: 42.943,65.989,83.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.865 | Acc: 42.997,66.010,83.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.308 | Acc: 39.062,60.156,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.577 | Acc: 34.896,55.915,65.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.571 | Acc: 35.213,55.107,64.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.609 | Acc: 34.887,55.033,64.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 3.387 | Acc: 47.656,71.875,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.636 | Acc: 44.382,68.601,86.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.667 | Acc: 43.693,68.236,86.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.674 | Acc: 43.353,68.084,86.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.691 | Acc: 43.326,67.824,86.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.709 | Acc: 43.286,67.652,86.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.713 | Acc: 43.511,67.646,86.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.720 | Acc: 43.473,67.586,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.735 | Acc: 43.231,67.479,85.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.733 | Acc: 43.280,67.442,85.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.744 | Acc: 43.116,67.316,85.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.749 | Acc: 43.135,67.237,85.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.763 | Acc: 42.982,67.038,85.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.783 | Acc: 42.867,66.921,84.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.788 | Acc: 42.941,66.868,84.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.804 | Acc: 42.862,66.671,84.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.802 | Acc: 42.915,66.645,84.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.799 | Acc: 42.950,66.766,84.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.802 | Acc: 43.016,66.714,84.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.810 | Acc: 43.002,66.595,84.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.057 | Acc: 41.406,57.031,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.387 | Acc: 38.244,55.543,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.367 | Acc: 38.567,55.850,65.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.380 | Acc: 37.999,55.840,65.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 3.081 | Acc: 47.656,74.219,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.674 | Acc: 44.345,67.374,84.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.634 | Acc: 44.036,68.502,85.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.626 | Acc: 44.045,68.366,86.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.628 | Acc: 44.223,68.499,86.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.629 | Acc: 44.059,68.580,86.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.651 | Acc: 43.827,68.111,86.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.674 | Acc: 43.844,67.791,86.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.685 | Acc: 43.721,67.653,85.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.693 | Acc: 43.776,67.636,85.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.709 | Acc: 43.630,67.495,85.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.726 | Acc: 43.605,67.340,85.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.738 | Acc: 43.523,67.168,85.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.750 | Acc: 43.406,67.107,84.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.766 | Acc: 43.230,66.957,84.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.766 | Acc: 43.296,66.925,84.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.771 | Acc: 43.309,66.895,84.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.775 | Acc: 43.312,66.807,84.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.782 | Acc: 43.250,66.685,84.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.783 | Acc: 43.241,66.724,84.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.274 | Acc: 37.500,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.489 | Acc: 34.561,57.068,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.431 | Acc: 35.671,57.146,65.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.427 | Acc: 35.835,56.993,65.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 3.697 | Acc: 43.750,67.188,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.590 | Acc: 44.940,68.713,86.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.628 | Acc: 44.112,67.073,86.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.681 | Acc: 43.648,66.752,85.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.665 | Acc: 43.615,67.014,85.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.668 | Acc: 43.611,67.172,85.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.689 | Acc: 43.434,66.936,85.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.689 | Acc: 43.517,66.999,85.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.692 | Acc: 43.566,67.008,85.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.691 | Acc: 43.616,67.222,85.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.695 | Acc: 43.493,67.114,85.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.700 | Acc: 43.506,67.032,85.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.704 | Acc: 43.461,66.954,85.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.702 | Acc: 43.418,66.987,85.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.701 | Acc: 43.483,67.043,85.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.707 | Acc: 43.516,66.915,85.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.719 | Acc: 43.546,66.866,85.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.727 | Acc: 43.484,66.814,84.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.735 | Acc: 43.449,66.765,84.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.745 | Acc: 43.348,66.732,84.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.974 | Acc: 38.281,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.517 | Acc: 35.789,57.068,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.477 | Acc: 35.899,56.555,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.508 | Acc: 35.476,56.481,66.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 3.898 | Acc: 40.625,64.062,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.635 | Acc: 43.564,69.643,84.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.580 | Acc: 44.684,69.036,85.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.608 | Acc: 44.672,68.289,86.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.601 | Acc: 44.657,68.364,86.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.610 | Acc: 44.454,68.178,86.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.621 | Acc: 44.344,68.007,86.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.635 | Acc: 44.105,67.980,86.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.650 | Acc: 43.939,67.823,85.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.651 | Acc: 44.009,67.926,85.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.658 | Acc: 44.003,67.860,85.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.671 | Acc: 43.937,67.799,85.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.683 | Acc: 43.854,67.739,85.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.690 | Acc: 43.822,67.589,85.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.702 | Acc: 43.714,67.502,84.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.714 | Acc: 43.610,67.400,84.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.723 | Acc: 43.572,67.285,84.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.728 | Acc: 43.626,67.183,84.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.730 | Acc: 43.607,67.175,84.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.739 | Acc: 43.520,67.110,84.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.895 | Acc: 36.719,52.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.386 | Acc: 37.426,56.250,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.356 | Acc: 37.538,56.212,66.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.368 | Acc: 37.564,55.686,66.522,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 3.920 | Acc: 42.188,65.625,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.576 | Acc: 44.085,69.829,86.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.530 | Acc: 44.817,70.027,86.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.568 | Acc: 44.096,69.390,87.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.574 | Acc: 44.049,68.924,87.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.590 | Acc: 44.067,68.750,87.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.611 | Acc: 43.827,68.660,86.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.602 | Acc: 43.905,68.678,87.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.607 | Acc: 44.027,68.590,86.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.626 | Acc: 43.823,68.474,86.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.632 | Acc: 43.699,68.381,86.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.639 | Acc: 43.807,68.319,86.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.643 | Acc: 43.815,68.248,86.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.654 | Acc: 43.882,68.124,86.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.659 | Acc: 43.908,68.047,85.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.661 | Acc: 43.862,67.987,85.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.671 | Acc: 43.799,67.815,85.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.676 | Acc: 43.823,67.760,85.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.682 | Acc: 43.867,67.653,85.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.685 | Acc: 43.918,67.594,85.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.241 | Acc: 42.188,55.469,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.416 | Acc: 35.119,54.985,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.471 | Acc: 35.442,55.011,65.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.473 | Acc: 35.400,55.443,65.343,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 3.022 | Acc: 43.750,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.578 | Acc: 41.778,69.531,87.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.547 | Acc: 42.816,69.684,87.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.527 | Acc: 43.391,69.416,87.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.538 | Acc: 43.731,69.367,87.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.560 | Acc: 43.711,68.897,87.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.560 | Acc: 44.021,68.737,86.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.571 | Acc: 44.021,68.567,86.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.575 | Acc: 44.104,68.536,86.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.582 | Acc: 44.065,68.353,86.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.592 | Acc: 43.991,68.241,86.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.591 | Acc: 43.934,68.368,86.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.606 | Acc: 43.867,68.205,86.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.619 | Acc: 43.897,68.166,86.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.621 | Acc: 43.970,68.205,86.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.628 | Acc: 43.911,68.195,86.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.633 | Acc: 43.799,68.051,86.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.645 | Acc: 43.787,67.877,86.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.648 | Acc: 43.769,67.837,85.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.646 | Acc: 43.789,67.860,85.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.821 | Acc: 39.844,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.135 | Acc: 38.728,58.817,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.122 | Acc: 39.234,58.861,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.167 | Acc: 38.832,58.133,66.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.580 | Acc: 46.875,73.438,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.463 | Acc: 45.089,70.573,88.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.477 | Acc: 44.436,69.607,88.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.504 | Acc: 44.249,69.314,88.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.529 | Acc: 44.637,69.078,88.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.535 | Acc: 44.578,69.052,88.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.560 | Acc: 44.434,68.595,88.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.557 | Acc: 44.537,68.545,87.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.561 | Acc: 44.730,68.541,87.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.561 | Acc: 44.618,68.564,87.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.567 | Acc: 44.613,68.455,87.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.582 | Acc: 44.411,68.414,87.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.591 | Acc: 44.385,68.212,87.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.597 | Acc: 44.423,68.214,86.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.604 | Acc: 44.326,68.124,86.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.605 | Acc: 44.355,68.148,86.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.608 | Acc: 44.317,68.166,86.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.610 | Acc: 44.309,68.154,86.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.610 | Acc: 44.343,68.215,86.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.615 | Acc: 44.310,68.155,86.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.955 | Acc: 42.969,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.228 | Acc: 38.914,58.333,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.216 | Acc: 39.615,56.993,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.215 | Acc: 39.690,57.095,65.881,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 3.295 | Acc: 46.094,69.531,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.478 | Acc: 46.094,68.601,87.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.507 | Acc: 44.950,68.502,87.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.522 | Acc: 44.954,68.673,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.513 | Acc: 44.618,69.049,87.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.512 | Acc: 44.763,69.114,87.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.516 | Acc: 44.460,68.957,87.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.516 | Acc: 44.531,69.082,87.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.509 | Acc: 44.609,69.221,87.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.522 | Acc: 44.609,69.056,87.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.527 | Acc: 44.621,68.983,87.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.538 | Acc: 44.485,68.792,87.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.547 | Acc: 44.418,68.692,87.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.562 | Acc: 44.307,68.558,86.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.571 | Acc: 44.253,68.391,86.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.577 | Acc: 44.339,68.327,86.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.587 | Acc: 44.388,68.244,86.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.591 | Acc: 44.458,68.255,86.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.599 | Acc: 44.384,68.181,86.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.603 | Acc: 44.421,68.166,86.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.165 | Acc: 36.719,60.938,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.319 | Acc: 36.124,57.626,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.293 | Acc: 36.623,58.060,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.316 | Acc: 36.578,57.684,65.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.174 | Acc: 53.125,73.438,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.305 | Acc: 47.024,72.247,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.379 | Acc: 46.894,70.941,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.395 | Acc: 46.030,70.377,89.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.393 | Acc: 45.988,70.235,89.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.403 | Acc: 46.109,70.065,88.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.434 | Acc: 45.648,69.731,88.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.451 | Acc: 45.518,69.509,88.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.463 | Acc: 45.584,69.492,88.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.468 | Acc: 45.567,69.492,87.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.473 | Acc: 45.620,69.380,87.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.490 | Acc: 45.609,69.100,87.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.504 | Acc: 45.462,68.925,87.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.507 | Acc: 45.531,68.960,87.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.525 | Acc: 45.310,68.744,87.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.529 | Acc: 45.248,68.805,86.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.543 | Acc: 45.064,68.740,86.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.559 | Acc: 44.896,68.684,86.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.569 | Acc: 44.847,68.588,86.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.566 | Acc: 44.839,68.613,86.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.022 | Acc: 42.969,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.300 | Acc: 37.872,57.924,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.326 | Acc: 37.843,57.069,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.294 | Acc: 38.179,57.313,65.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 3.458 | Acc: 42.969,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.391 | Acc: 44.717,70.796,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.481 | Acc: 44.055,69.512,88.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.483 | Acc: 43.814,69.595,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.477 | Acc: 44.203,69.570,88.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.468 | Acc: 44.709,69.531,88.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.455 | Acc: 44.880,69.486,88.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.457 | Acc: 44.947,69.642,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.465 | Acc: 44.885,69.604,88.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.471 | Acc: 44.980,69.553,87.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.484 | Acc: 44.932,69.426,87.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.487 | Acc: 44.927,69.404,87.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.487 | Acc: 45.030,69.359,87.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.490 | Acc: 45.001,69.343,87.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.493 | Acc: 45.012,69.214,87.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.502 | Acc: 45.001,69.054,87.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.518 | Acc: 44.950,68.879,87.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.526 | Acc: 44.914,68.849,87.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.529 | Acc: 44.865,68.789,87.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.537 | Acc: 44.806,68.705,87.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.964 | Acc: 42.188,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.327 | Acc: 38.132,57.440,65.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.292 | Acc: 38.605,57.393,65.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.326 | Acc: 38.614,57.403,65.394,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.152 | Acc: 46.875,77.344,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.525 | Acc: 43.750,68.787,87.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.465 | Acc: 45.484,69.569,88.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.446 | Acc: 45.710,69.903,88.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.440 | Acc: 45.689,69.946,88.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.444 | Acc: 45.591,70.181,88.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.445 | Acc: 45.448,70.067,88.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.460 | Acc: 45.202,70.013,88.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.479 | Acc: 45.206,69.677,87.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.487 | Acc: 45.075,69.605,87.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.496 | Acc: 45.149,69.578,87.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.498 | Acc: 45.139,69.485,87.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.504 | Acc: 45.141,69.385,87.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.515 | Acc: 45.049,69.235,87.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.517 | Acc: 45.101,69.156,87.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.514 | Acc: 45.087,69.181,87.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.520 | Acc: 45.023,69.142,87.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.527 | Acc: 44.969,69.080,87.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.535 | Acc: 44.942,69.021,86.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.538 | Acc: 44.865,69.000,86.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.010 | Acc: 36.719,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.272 | Acc: 37.314,58.482,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.291 | Acc: 37.233,58.060,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.342 | Acc: 36.732,57.172,66.573,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 3.353 | Acc: 43.750,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.511 | Acc: 43.713,70.089,88.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.485 | Acc: 44.436,69.627,88.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.428 | Acc: 45.248,70.210,89.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.397 | Acc: 45.428,70.505,89.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.390 | Acc: 45.452,70.784,89.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.376 | Acc: 45.777,70.687,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.384 | Acc: 45.994,70.523,89.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.389 | Acc: 45.846,70.380,89.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.394 | Acc: 45.839,70.317,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.404 | Acc: 45.725,70.134,89.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.416 | Acc: 45.546,70.044,88.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.431 | Acc: 45.384,69.787,88.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.432 | Acc: 45.474,69.765,88.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.441 | Acc: 45.463,69.701,88.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.445 | Acc: 45.541,69.695,88.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.453 | Acc: 45.483,69.595,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.463 | Acc: 45.400,69.575,87.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.473 | Acc: 45.386,69.596,87.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.487 | Acc: 45.310,69.431,87.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.694 | Acc: 36.719,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.294 | Acc: 37.909,59.598,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.293 | Acc: 37.309,59.223,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.300 | Acc: 37.218,58.850,66.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 3.127 | Acc: 48.438,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.367 | Acc: 45.052,72.284,89.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.389 | Acc: 45.541,71.875,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.397 | Acc: 45.248,71.516,88.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.382 | Acc: 45.505,71.296,89.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.390 | Acc: 45.351,71.016,89.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.402 | Acc: 45.442,70.861,88.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.389 | Acc: 45.573,70.916,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.386 | Acc: 45.803,70.963,89.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.385 | Acc: 45.964,70.956,88.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.392 | Acc: 45.954,70.810,88.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.396 | Acc: 45.938,70.613,88.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.407 | Acc: 45.805,70.407,88.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.411 | Acc: 45.741,70.387,88.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.423 | Acc: 45.574,70.293,88.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.428 | Acc: 45.556,70.206,88.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.436 | Acc: 45.553,70.125,88.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.442 | Acc: 45.565,70.049,88.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.451 | Acc: 45.607,69.975,87.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.464 | Acc: 45.546,69.837,87.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.977 | Acc: 38.281,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.345 | Acc: 36.272,58.966,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.372 | Acc: 36.414,57.965,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.384 | Acc: 36.565,57.864,65.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 3.310 | Acc: 51.562,71.875,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.325 | Acc: 47.210,70.350,87.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.321 | Acc: 46.970,70.370,88.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.317 | Acc: 46.990,70.838,88.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.370 | Acc: 46.508,70.361,88.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.390 | Acc: 45.962,70.073,88.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.403 | Acc: 45.790,69.796,88.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.417 | Acc: 45.529,69.609,88.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.419 | Acc: 45.604,69.589,88.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.439 | Acc: 45.477,69.389,88.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.435 | Acc: 45.456,69.477,88.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.438 | Acc: 45.528,69.411,88.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.445 | Acc: 45.403,69.346,88.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.444 | Acc: 45.537,69.400,88.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.444 | Acc: 45.585,69.565,88.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.453 | Acc: 45.429,69.552,88.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.461 | Acc: 45.407,69.483,87.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.467 | Acc: 45.338,69.492,87.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.479 | Acc: 45.351,69.397,87.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.478 | Acc: 45.341,69.355,87.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.783 | Acc: 38.281,60.938,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.555 | Acc: 35.938,57.329,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.522 | Acc: 36.433,56.726,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.526 | Acc: 36.219,56.557,65.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 3.754 | Acc: 45.312,64.062,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.356 | Acc: 45.871,70.275,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.356 | Acc: 45.560,71.246,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.325 | Acc: 45.799,71.491,89.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.310 | Acc: 45.891,71.779,89.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.299 | Acc: 45.730,71.774,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.313 | Acc: 45.887,71.662,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.322 | Acc: 45.867,71.426,89.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.326 | Acc: 45.720,71.293,89.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.345 | Acc: 45.649,70.990,89.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.350 | Acc: 45.674,71.039,89.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.357 | Acc: 45.592,70.875,89.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.373 | Acc: 45.595,70.659,89.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.384 | Acc: 45.588,70.480,88.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.388 | Acc: 45.652,70.443,88.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.400 | Acc: 45.614,70.372,88.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.404 | Acc: 45.585,70.347,88.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.410 | Acc: 45.562,70.338,88.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.419 | Acc: 45.512,70.312,88.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.426 | Acc: 45.501,70.261,88.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.152 | Acc: 39.844,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.483 | Acc: 35.640,58.780,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.421 | Acc: 36.490,58.594,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.395 | Acc: 36.693,58.658,66.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 3.413 | Acc: 41.406,65.625,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.311 | Acc: 45.201,71.094,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.333 | Acc: 45.312,71.094,89.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.308 | Acc: 46.030,71.017,89.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.291 | Acc: 46.132,71.209,89.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.293 | Acc: 46.488,71.295,89.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.311 | Acc: 46.210,71.068,89.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.317 | Acc: 46.177,70.900,89.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.325 | Acc: 46.142,70.924,89.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.328 | Acc: 46.279,70.947,89.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.333 | Acc: 46.206,70.903,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.350 | Acc: 46.041,70.694,89.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.366 | Acc: 45.899,70.491,88.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.381 | Acc: 45.860,70.292,88.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.390 | Acc: 45.910,70.165,88.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.395 | Acc: 45.829,70.126,88.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.404 | Acc: 45.802,70.050,88.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.408 | Acc: 45.716,70.031,88.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.416 | Acc: 45.683,69.921,88.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.427 | Acc: 45.567,69.814,88.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.334 | Acc: 39.062,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.339 | Acc: 39.732,57.961,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.227 | Acc: 39.958,58.327,66.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.262 | Acc: 39.408,58.043,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.099 | Acc: 46.875,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.236 | Acc: 46.838,72.024,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.215 | Acc: 47.409,72.180,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.224 | Acc: 47.310,72.029,90.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.272 | Acc: 46.856,71.480,89.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.271 | Acc: 47.061,71.488,89.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.264 | Acc: 47.024,71.520,89.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.283 | Acc: 46.864,71.493,89.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.294 | Acc: 46.846,71.356,89.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.302 | Acc: 46.789,71.266,89.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.315 | Acc: 46.665,71.148,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.332 | Acc: 46.582,71.020,89.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.341 | Acc: 46.389,70.831,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.353 | Acc: 46.282,70.663,88.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.356 | Acc: 46.386,70.613,88.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.369 | Acc: 46.268,70.494,88.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.370 | Acc: 46.286,70.480,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.381 | Acc: 46.162,70.306,88.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.394 | Acc: 46.079,70.155,88.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.406 | Acc: 45.985,70.021,88.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.108 | Acc: 34.375,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.370 | Acc: 36.533,58.705,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.422 | Acc: 36.509,57.717,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.420 | Acc: 35.605,57.748,65.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 3.079 | Acc: 48.438,70.312,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.240 | Acc: 47.470,73.251,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.264 | Acc: 46.761,72.370,90.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 46.222,72.182,90.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.307 | Acc: 46.026,71.653,90.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.305 | Acc: 46.194,71.558,90.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.311 | Acc: 46.210,71.488,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.317 | Acc: 46.382,71.326,89.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.312 | Acc: 46.477,71.370,89.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.314 | Acc: 46.491,71.232,89.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.321 | Acc: 46.444,71.137,89.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.330 | Acc: 46.331,71.016,89.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.345 | Acc: 46.103,70.844,89.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.348 | Acc: 46.160,70.788,89.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.344 | Acc: 46.277,70.819,88.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.351 | Acc: 46.268,70.681,88.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.362 | Acc: 46.111,70.568,88.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.379 | Acc: 45.961,70.367,88.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.386 | Acc: 45.955,70.373,88.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.399 | Acc: 45.809,70.255,88.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.057 | Acc: 39.844,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.326 | Acc: 37.723,58.333,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.295 | Acc: 38.605,57.622,66.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.305 | Acc: 38.307,57.646,66.112,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 3.209 | Acc: 54.688,73.438,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.271 | Acc: 46.205,71.354,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.314 | Acc: 45.732,71.018,89.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.321 | Acc: 45.517,71.030,89.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.311 | Acc: 45.939,71.007,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.326 | Acc: 45.746,70.808,89.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.320 | Acc: 46.049,70.868,88.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.314 | Acc: 46.066,71.061,89.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.317 | Acc: 46.094,71.230,89.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.323 | Acc: 46.107,71.094,89.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.330 | Acc: 46.090,71.024,89.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.342 | Acc: 46.016,70.931,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.352 | Acc: 45.922,70.838,88.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.351 | Acc: 45.995,70.929,88.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.354 | Acc: 45.935,70.930,88.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.371 | Acc: 45.819,70.767,88.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.376 | Acc: 45.889,70.714,88.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.377 | Acc: 45.952,70.711,88.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.378 | Acc: 45.962,70.769,88.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.384 | Acc: 45.905,70.716,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.896 | Acc: 46.094,63.281,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.236 | Acc: 41.220,57.924,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.225 | Acc: 40.949,57.908,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.235 | Acc: 40.920,57.864,65.279,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 3.298 | Acc: 39.844,67.969,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.281 | Acc: 46.354,71.429,89.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.237 | Acc: 46.704,72.428,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.257 | Acc: 46.260,72.515,90.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.251 | Acc: 46.624,72.425,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.255 | Acc: 46.272,72.076,90.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.256 | Acc: 46.501,71.965,90.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.269 | Acc: 46.570,71.930,90.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.273 | Acc: 46.676,71.739,90.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.270 | Acc: 46.633,71.646,90.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.276 | Acc: 46.611,71.541,89.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.287 | Acc: 46.578,71.373,89.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.285 | Acc: 46.713,71.424,89.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.287 | Acc: 46.722,71.432,89.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.300 | Acc: 46.678,71.330,89.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.314 | Acc: 46.468,71.174,89.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.326 | Acc: 46.415,71.057,89.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.330 | Acc: 46.424,71.014,89.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.334 | Acc: 46.388,71.070,89.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.337 | Acc: 46.401,71.026,89.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.051 | Acc: 36.719,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.376 | Acc: 36.756,57.775,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.432 | Acc: 36.833,57.031,66.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.444 | Acc: 36.732,57.249,65.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.183 | Acc: 49.219,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.198 | Acc: 46.317,71.949,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.204 | Acc: 46.837,72.771,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.183 | Acc: 47.041,73.130,90.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.183 | Acc: 46.971,72.897,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.197 | Acc: 47.076,72.687,90.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.214 | Acc: 46.701,72.514,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.232 | Acc: 46.520,72.496,90.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.245 | Acc: 46.564,72.283,90.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.262 | Acc: 46.288,72.160,89.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.271 | Acc: 46.249,71.999,89.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.275 | Acc: 46.253,71.889,89.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.286 | Acc: 46.291,71.787,89.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.293 | Acc: 46.381,71.662,89.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.302 | Acc: 46.416,71.586,89.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.305 | Acc: 46.431,71.548,89.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.318 | Acc: 46.432,71.415,89.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.330 | Acc: 46.350,71.282,89.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.341 | Acc: 46.265,71.098,88.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.350 | Acc: 46.174,70.969,88.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.262 | Acc: 36.719,60.156,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.347 | Acc: 36.421,58.929,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.321 | Acc: 36.490,58.727,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.343 | Acc: 36.155,58.863,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 2.907 | Acc: 52.344,78.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.328 | Acc: 45.387,71.763,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.272 | Acc: 46.151,72.294,90.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.250 | Acc: 46.632,72.413,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.220 | Acc: 46.981,72.859,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.236 | Acc: 46.929,72.455,90.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.243 | Acc: 46.901,72.172,90.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.252 | Acc: 46.858,72.041,89.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.245 | Acc: 46.860,72.113,89.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.258 | Acc: 46.875,71.905,89.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.266 | Acc: 46.972,71.840,89.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.284 | Acc: 46.847,71.504,89.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.287 | Acc: 46.742,71.343,89.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.300 | Acc: 46.680,71.246,89.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.302 | Acc: 46.758,71.269,89.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.318 | Acc: 46.582,71.115,88.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.330 | Acc: 46.520,70.996,88.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.343 | Acc: 46.433,70.956,88.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.350 | Acc: 46.436,70.856,88.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.355 | Acc: 46.471,70.741,88.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.999 | Acc: 40.625,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.229 | Acc: 39.025,58.631,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.202 | Acc: 38.472,58.803,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.206 | Acc: 38.461,58.594,66.547,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 3.362 | Acc: 46.875,67.188,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.326 | Acc: 46.205,71.168,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.255 | Acc: 46.265,71.589,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.243 | Acc: 46.683,72.003,90.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.237 | Acc: 46.836,72.299,90.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.252 | Acc: 46.813,72.208,90.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.245 | Acc: 46.907,72.082,89.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.265 | Acc: 46.781,71.892,89.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.280 | Acc: 46.477,71.671,89.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.282 | Acc: 46.430,71.633,89.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.293 | Acc: 46.451,71.467,89.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.294 | Acc: 46.550,71.483,89.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.312 | Acc: 46.483,71.298,89.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.317 | Acc: 46.429,71.196,89.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.318 | Acc: 46.480,71.163,89.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.328 | Acc: 46.416,71.055,89.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.340 | Acc: 46.291,70.948,88.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.343 | Acc: 46.369,70.938,88.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.351 | Acc: 46.377,70.897,88.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.356 | Acc: 46.336,70.839,88.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.179 | Acc: 38.281,53.125,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.458 | Acc: 37.946,58.185,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.371 | Acc: 38.815,57.565,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.354 | Acc: 38.768,57.428,65.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 3.046 | Acc: 46.094,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.206 | Acc: 45.833,72.210,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.237 | Acc: 45.770,72.142,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.221 | Acc: 46.324,72.182,90.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.198 | Acc: 46.721,72.463,90.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.206 | Acc: 46.627,72.409,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.210 | Acc: 46.623,72.256,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.219 | Acc: 46.620,72.036,90.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.231 | Acc: 46.594,71.860,90.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.235 | Acc: 46.651,71.819,90.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.240 | Acc: 46.673,71.599,90.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.243 | Acc: 46.783,71.546,90.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.246 | Acc: 46.768,71.518,90.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.244 | Acc: 46.800,71.570,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.255 | Acc: 46.786,71.472,89.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.261 | Acc: 46.743,71.436,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.275 | Acc: 46.666,71.332,89.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.278 | Acc: 46.644,71.227,89.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.285 | Acc: 46.611,71.204,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.293 | Acc: 46.578,71.166,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.320 | Acc: 39.062,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.371 | Acc: 39.583,57.775,64.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.336 | Acc: 39.806,58.003,65.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.351 | Acc: 39.267,57.723,65.177,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 3.048 | Acc: 50.781,74.219,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.055 | Acc: 49.107,73.772,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.109 | Acc: 48.514,73.114,91.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.115 | Acc: 48.438,73.450,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.113 | Acc: 48.312,73.457,90.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.123 | Acc: 48.221,73.151,90.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.137 | Acc: 47.986,72.992,90.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.147 | Acc: 47.856,73.061,90.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.172 | Acc: 47.676,72.719,90.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.180 | Acc: 47.531,72.622,90.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.184 | Acc: 47.446,72.645,90.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.199 | Acc: 47.388,72.487,90.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.206 | Acc: 47.296,72.484,90.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.215 | Acc: 47.225,72.384,90.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.224 | Acc: 47.164,72.311,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.228 | Acc: 47.109,72.319,90.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.235 | Acc: 47.053,72.262,89.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.249 | Acc: 47.008,72.118,89.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.264 | Acc: 46.946,71.914,89.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.276 | Acc: 46.939,71.816,89.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.852 | Acc: 42.969,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.122 | Acc: 41.369,58.185,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.079 | Acc: 41.940,58.117,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.090 | Acc: 41.432,58.210,66.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 3.037 | Acc: 46.875,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.046 | Acc: 47.768,73.586,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.116 | Acc: 47.389,73.380,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.139 | Acc: 46.990,73.425,91.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.129 | Acc: 47.193,73.254,91.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.152 | Acc: 47.138,73.144,90.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.158 | Acc: 47.153,73.024,90.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.159 | Acc: 47.058,72.745,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.165 | Acc: 47.093,72.661,90.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.180 | Acc: 46.979,72.553,90.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.200 | Acc: 46.840,72.310,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.211 | Acc: 46.949,72.190,89.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.223 | Acc: 46.972,72.037,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.240 | Acc: 46.917,71.902,89.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.249 | Acc: 46.883,71.869,89.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.258 | Acc: 46.901,71.779,89.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.269 | Acc: 46.783,71.641,89.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.275 | Acc: 46.712,71.584,89.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.280 | Acc: 46.713,71.579,89.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.287 | Acc: 46.725,71.490,89.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.043 | Acc: 32.812,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.634 | Acc: 35.193,57.329,65.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.591 | Acc: 34.775,57.050,65.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.585 | Acc: 34.426,56.942,65.100,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.254 | Acc: 50.000,71.875,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.176 | Acc: 49.033,72.954,90.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.174 | Acc: 48.133,73.190,90.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.190 | Acc: 47.912,73.092,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.197 | Acc: 47.598,72.975,90.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.207 | Acc: 47.192,72.757,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.198 | Acc: 47.295,73.082,90.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.203 | Acc: 47.363,72.950,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.210 | Acc: 47.375,72.676,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.211 | Acc: 47.419,72.509,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.222 | Acc: 47.163,72.357,90.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.224 | Acc: 47.267,72.282,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.237 | Acc: 47.118,72.086,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.241 | Acc: 47.120,71.998,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.249 | Acc: 46.953,71.942,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.251 | Acc: 46.992,71.937,89.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.264 | Acc: 46.851,71.817,89.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.269 | Acc: 46.852,71.781,89.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.271 | Acc: 46.849,71.691,89.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.274 | Acc: 46.842,71.711,89.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.177 | Acc: 38.281,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.441 | Acc: 37.537,57.552,64.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.399 | Acc: 37.938,57.489,64.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.411 | Acc: 37.679,57.095,64.780,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 2.977 | Acc: 50.000,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.099 | Acc: 47.917,74.293,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.137 | Acc: 48.018,73.628,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.148 | Acc: 47.720,73.284,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.123 | Acc: 48.052,73.573,91.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.099 | Acc: 48.298,73.654,91.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.126 | Acc: 47.747,73.405,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.145 | Acc: 47.551,73.133,90.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.162 | Acc: 47.520,73.093,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.172 | Acc: 47.570,72.863,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.191 | Acc: 47.380,72.715,90.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.203 | Acc: 47.158,72.571,90.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.199 | Acc: 47.358,72.575,90.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.202 | Acc: 47.384,72.587,90.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.216 | Acc: 47.281,72.492,90.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.222 | Acc: 47.238,72.469,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.233 | Acc: 47.211,72.301,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.239 | Acc: 47.164,72.219,89.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.245 | Acc: 47.174,72.146,89.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.253 | Acc: 47.121,72.066,89.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.656 | Acc: 46.875,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.023 | Acc: 42.262,60.565,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.984 | Acc: 41.997,60.423,67.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.997 | Acc: 41.906,60.681,67.392,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 2.842 | Acc: 53.125,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.111 | Acc: 49.219,73.735,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.080 | Acc: 49.447,74.638,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.096 | Acc: 48.847,74.155,91.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.113 | Acc: 48.167,74.103,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.114 | Acc: 48.229,73.894,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.128 | Acc: 48.257,73.515,90.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.153 | Acc: 47.978,73.221,90.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.167 | Acc: 47.947,72.977,90.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.183 | Acc: 47.756,72.868,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.186 | Acc: 47.660,72.785,90.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.195 | Acc: 47.571,72.607,90.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.204 | Acc: 47.540,72.420,90.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.207 | Acc: 47.474,72.414,90.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.214 | Acc: 47.353,72.337,90.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.216 | Acc: 47.376,72.262,89.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.224 | Acc: 47.379,72.128,89.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.231 | Acc: 47.365,72.042,89.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.239 | Acc: 47.334,71.864,89.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.246 | Acc: 47.215,71.783,89.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.671 | Acc: 42.188,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.065 | Acc: 42.039,59.449,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.094 | Acc: 41.692,59.337,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.088 | Acc: 41.675,59.401,66.393,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 3.242 | Acc: 49.219,71.875,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.147 | Acc: 48.140,73.475,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.142 | Acc: 48.285,73.285,90.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.121 | Acc: 48.130,73.130,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.137 | Acc: 47.656,72.791,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.136 | Acc: 47.656,72.679,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.141 | Acc: 47.689,72.618,90.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.146 | Acc: 47.828,72.623,90.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.141 | Acc: 47.904,72.744,90.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.149 | Acc: 47.695,72.566,90.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.161 | Acc: 47.590,72.481,90.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.177 | Acc: 47.441,72.419,90.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.189 | Acc: 47.384,72.345,90.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.190 | Acc: 47.390,72.303,90.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.191 | Acc: 47.434,72.350,90.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.204 | Acc: 47.392,72.282,90.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.214 | Acc: 47.359,72.101,89.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.226 | Acc: 47.310,71.980,89.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.241 | Acc: 47.102,71.804,89.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.244 | Acc: 47.090,71.801,89.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.602 | Acc: 38.281,58.594,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.408 | Acc: 38.095,59.040,65.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.458 | Acc: 38.300,58.041,64.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.416 | Acc: 38.371,58.017,64.869,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 3.015 | Acc: 45.312,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.198 | Acc: 46.726,72.842,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.132 | Acc: 47.828,73.761,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.129 | Acc: 47.669,73.694,91.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.139 | Acc: 47.386,73.505,91.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.150 | Acc: 47.532,73.538,91.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.149 | Acc: 47.585,73.334,91.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.159 | Acc: 47.534,72.994,91.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.171 | Acc: 47.360,72.671,91.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.166 | Acc: 47.358,72.781,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.173 | Acc: 47.287,72.660,90.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.182 | Acc: 47.193,72.515,90.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.182 | Acc: 47.329,72.536,90.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.196 | Acc: 47.135,72.366,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.205 | Acc: 47.161,72.248,90.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.210 | Acc: 47.212,72.236,90.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.214 | Acc: 47.269,72.245,90.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.221 | Acc: 47.230,72.226,90.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.227 | Acc: 47.239,72.154,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.238 | Acc: 47.150,72.045,89.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.754 | Acc: 46.875,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.211 | Acc: 40.960,57.701,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.182 | Acc: 41.063,58.117,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.188 | Acc: 41.035,58.005,66.227,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 3.114 | Acc: 46.094,70.312,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.165 | Acc: 46.912,71.949,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.092 | Acc: 47.618,73.514,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.080 | Acc: 48.040,73.899,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.067 | Acc: 48.515,73.746,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.107 | Acc: 47.958,73.244,91.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.097 | Acc: 48.179,73.425,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.093 | Acc: 48.183,73.554,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.110 | Acc: 48.025,73.316,91.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.122 | Acc: 47.868,73.256,91.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.136 | Acc: 47.672,73.146,90.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.152 | Acc: 47.578,73.027,90.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.165 | Acc: 47.504,72.848,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.171 | Acc: 47.444,72.806,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.179 | Acc: 47.409,72.648,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.187 | Acc: 47.272,72.633,90.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.193 | Acc: 47.221,72.552,90.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.201 | Acc: 47.255,72.549,90.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.207 | Acc: 47.204,72.531,90.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.216 | Acc: 47.131,72.422,89.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.230 | Acc: 46.094,62.500,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.391 | Acc: 38.653,59.524,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.365 | Acc: 38.377,59.489,65.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.345 | Acc: 38.038,59.388,65.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 2.769 | Acc: 50.781,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.124 | Acc: 46.652,73.363,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.055 | Acc: 47.542,74.181,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.055 | Acc: 47.631,74.142,91.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.050 | Acc: 47.926,74.248,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.048 | Acc: 47.919,74.095,91.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.064 | Acc: 47.960,74.025,91.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.083 | Acc: 47.645,73.665,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.096 | Acc: 47.569,73.505,91.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.106 | Acc: 47.583,73.381,91.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.121 | Acc: 47.411,73.278,91.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.126 | Acc: 47.479,73.247,90.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.129 | Acc: 47.582,73.249,90.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.135 | Acc: 47.704,73.174,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.141 | Acc: 47.617,73.112,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.156 | Acc: 47.508,72.937,90.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.165 | Acc: 47.357,72.868,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.170 | Acc: 47.365,72.794,90.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.179 | Acc: 47.310,72.695,90.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.192 | Acc: 47.222,72.517,90.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.949 | Acc: 48.438,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.323 | Acc: 38.839,58.631,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.360 | Acc: 38.491,58.136,64.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.373 | Acc: 38.153,58.107,64.229,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 3.177 | Acc: 44.531,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.137 | Acc: 47.545,72.805,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.117 | Acc: 47.713,73.418,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.134 | Acc: 47.579,73.476,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.122 | Acc: 47.791,73.515,91.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.114 | Acc: 47.912,73.554,91.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.124 | Acc: 47.889,73.399,91.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.127 | Acc: 47.856,73.465,91.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.131 | Acc: 47.744,73.355,90.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.133 | Acc: 47.708,73.243,90.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.143 | Acc: 47.773,73.146,90.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.145 | Acc: 47.741,73.123,90.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.152 | Acc: 47.721,73.023,90.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.155 | Acc: 47.839,73.009,90.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.162 | Acc: 47.845,72.965,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.172 | Acc: 47.708,72.921,90.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.179 | Acc: 47.693,72.853,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.190 | Acc: 47.542,72.759,90.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.201 | Acc: 47.546,72.658,89.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.210 | Acc: 47.492,72.541,89.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.061 | Acc: 43.750,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.452 | Acc: 35.826,58.631,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.454 | Acc: 35.766,58.518,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.465 | Acc: 35.502,58.466,66.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 3.516 | Acc: 45.312,69.531,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.144 | Acc: 47.024,73.958,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.103 | Acc: 47.370,74.028,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.125 | Acc: 47.426,73.770,90.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.150 | Acc: 47.396,73.264,89.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.131 | Acc: 47.749,73.314,90.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.128 | Acc: 47.740,73.244,90.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.127 | Acc: 47.634,73.249,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.127 | Acc: 47.598,73.282,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.135 | Acc: 47.583,73.127,90.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.143 | Acc: 47.602,73.037,90.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.155 | Acc: 47.635,72.957,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.166 | Acc: 47.682,72.890,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.173 | Acc: 47.698,72.791,90.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.185 | Acc: 47.581,72.676,90.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.198 | Acc: 47.576,72.493,89.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.204 | Acc: 47.522,72.471,89.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.212 | Acc: 47.475,72.386,89.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.215 | Acc: 47.466,72.418,89.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.217 | Acc: 47.457,72.392,89.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.349 | Acc: 41.406,60.156,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.362 | Acc: 39.881,57.329,65.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.353 | Acc: 40.377,56.669,64.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.373 | Acc: 40.330,56.506,64.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 3.020 | Acc: 52.344,71.875,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.081 | Acc: 47.098,73.884,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.042 | Acc: 47.675,74.333,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.098 | Acc: 47.541,73.335,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.082 | Acc: 47.820,73.630,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.081 | Acc: 47.958,73.584,91.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.070 | Acc: 48.057,73.483,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.083 | Acc: 47.828,73.515,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.092 | Acc: 47.666,73.578,91.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.101 | Acc: 47.691,73.489,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.100 | Acc: 47.773,73.426,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.115 | Acc: 47.653,73.194,91.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.120 | Acc: 47.569,73.162,91.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.118 | Acc: 47.665,73.099,90.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.123 | Acc: 47.678,73.043,90.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.132 | Acc: 47.633,72.975,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.142 | Acc: 47.600,72.897,90.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.149 | Acc: 47.601,72.883,90.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.158 | Acc: 47.613,72.803,90.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.163 | Acc: 47.691,72.775,90.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.187 | Acc: 34.375,63.281,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.314 | Acc: 38.579,58.705,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.289 | Acc: 39.101,58.479,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.269 | Acc: 39.191,58.658,66.214,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 2.964 | Acc: 49.219,72.656,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.125 | Acc: 47.359,74.479,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.078 | Acc: 47.332,74.486,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.078 | Acc: 47.669,74.244,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.084 | Acc: 47.560,73.756,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.081 | Acc: 47.904,73.670,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.081 | Acc: 47.992,73.612,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.093 | Acc: 47.983,73.582,91.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.094 | Acc: 48.074,73.481,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.100 | Acc: 48.105,73.412,91.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.108 | Acc: 48.045,73.410,90.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.116 | Acc: 47.911,73.388,90.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.121 | Acc: 48.003,73.343,90.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.127 | Acc: 47.926,73.264,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.136 | Acc: 47.915,73.140,90.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.139 | Acc: 47.864,73.066,90.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.148 | Acc: 47.841,73.016,90.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.158 | Acc: 47.789,72.922,90.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.172 | Acc: 47.732,72.808,90.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.185 | Acc: 47.673,72.658,89.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.263 | Acc: 37.500,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.610 | Acc: 35.193,57.217,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.564 | Acc: 35.747,56.803,65.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.562 | Acc: 35.387,56.583,65.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 2.912 | Acc: 48.438,73.438,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.087 | Acc: 48.586,73.065,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.030 | Acc: 49.085,74.143,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.033 | Acc: 48.822,73.950,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.044 | Acc: 48.466,73.823,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.050 | Acc: 48.623,73.840,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.056 | Acc: 48.573,73.851,91.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.066 | Acc: 48.532,73.914,91.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.082 | Acc: 48.496,73.690,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.094 | Acc: 48.602,73.494,91.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.107 | Acc: 48.414,73.426,91.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.118 | Acc: 48.229,73.427,91.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.121 | Acc: 48.120,73.525,90.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.123 | Acc: 48.183,73.417,90.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.137 | Acc: 48.034,73.276,90.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.140 | Acc: 47.975,73.258,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.152 | Acc: 47.866,73.102,90.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.160 | Acc: 47.837,73.009,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.171 | Acc: 47.797,72.901,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.177 | Acc: 47.718,72.759,90.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.249 | Acc: 44.531,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.395 | Acc: 41.555,58.333,65.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.313 | Acc: 41.139,58.441,65.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.299 | Acc: 40.945,58.491,65.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 3.088 | Acc: 43.750,71.875,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.106 | Acc: 47.991,72.991,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.050 | Acc: 48.133,74.085,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.063 | Acc: 48.105,73.450,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.066 | Acc: 47.685,73.717,91.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.062 | Acc: 48.066,73.716,91.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.043 | Acc: 48.276,73.928,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.044 | Acc: 48.094,73.986,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.060 | Acc: 47.758,73.894,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.061 | Acc: 47.838,73.804,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.076 | Acc: 47.687,73.745,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.082 | Acc: 47.805,73.703,91.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.083 | Acc: 47.799,73.671,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.091 | Acc: 47.785,73.611,91.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.101 | Acc: 47.723,73.504,91.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.108 | Acc: 47.773,73.474,90.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.110 | Acc: 47.812,73.428,90.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.115 | Acc: 47.844,73.415,90.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.121 | Acc: 47.851,73.344,90.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.127 | Acc: 47.880,73.314,90.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.094 | Acc: 38.281,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.479 | Acc: 37.240,58.631,65.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.551 | Acc: 36.490,58.270,65.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.521 | Acc: 36.514,58.210,65.356,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 3.158 | Acc: 46.875,69.531,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.038 | Acc: 48.512,74.070,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.995 | Acc: 49.009,74.943,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.019 | Acc: 48.322,74.539,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.016 | Acc: 48.302,74.498,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.028 | Acc: 48.051,74.296,91.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.043 | Acc: 47.953,74.103,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.058 | Acc: 48.005,73.975,91.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.069 | Acc: 47.986,73.782,91.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.079 | Acc: 48.114,73.696,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.086 | Acc: 48.068,73.640,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.091 | Acc: 48.098,73.526,90.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.097 | Acc: 48.010,73.428,90.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.108 | Acc: 47.836,73.312,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.108 | Acc: 48.007,73.318,90.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.120 | Acc: 47.926,73.284,90.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.131 | Acc: 47.795,73.216,90.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.143 | Acc: 47.730,73.117,90.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.143 | Acc: 47.782,73.143,90.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.147 | Acc: 47.816,73.107,90.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.083 | Acc: 44.531,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.173 | Acc: 40.439,59.487,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.125 | Acc: 40.606,59.299,67.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.128 | Acc: 40.612,58.850,67.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 3.348 | Acc: 44.531,70.312,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.056 | Acc: 48.140,74.219,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.017 | Acc: 48.761,74.619,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.026 | Acc: 48.911,74.513,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.047 | Acc: 48.524,74.334,91.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.045 | Acc: 48.492,74.381,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.066 | Acc: 48.399,74.083,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.061 | Acc: 48.471,73.964,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.069 | Acc: 48.428,73.918,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.073 | Acc: 48.476,74.029,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.092 | Acc: 48.266,73.651,91.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.101 | Acc: 48.208,73.547,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.103 | Acc: 48.272,73.421,90.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.119 | Acc: 48.129,73.195,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.127 | Acc: 48.129,73.159,90.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.133 | Acc: 48.087,73.035,90.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.141 | Acc: 48.109,72.931,90.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.139 | Acc: 48.096,72.956,90.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.143 | Acc: 48.163,72.868,90.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.143 | Acc: 48.280,72.878,90.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.686 | Acc: 39.844,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.438 | Acc: 37.351,59.747,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.394 | Acc: 37.729,59.394,65.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.440 | Acc: 36.655,59.132,65.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 3.073 | Acc: 46.875,75.000,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.903 | Acc: 48.363,76.302,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.912 | Acc: 49.600,76.105,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.953 | Acc: 49.347,75.320,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.983 | Acc: 48.717,74.961,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.008 | Acc: 48.221,74.791,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.018 | Acc: 48.263,74.761,92.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.026 | Acc: 48.365,74.523,91.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.033 | Acc: 48.496,74.432,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.049 | Acc: 48.135,74.240,91.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.051 | Acc: 48.325,74.160,91.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.058 | Acc: 48.370,73.954,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.061 | Acc: 48.489,73.917,91.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.063 | Acc: 48.491,73.955,91.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.070 | Acc: 48.524,73.918,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.086 | Acc: 48.386,73.848,91.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.101 | Acc: 48.245,73.625,90.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.108 | Acc: 48.163,73.554,90.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.116 | Acc: 48.122,73.435,90.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.126 | Acc: 48.056,73.294,90.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.783 | Acc: 38.281,59.375,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.847 | Acc: 36.235,57.701,63.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.702 | Acc: 37.062,57.412,63.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.669 | Acc: 37.065,57.697,63.883,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 2.874 | Acc: 46.094,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.024 | Acc: 47.954,75.149,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.013 | Acc: 48.209,74.200,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.041 | Acc: 48.207,74.360,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.072 | Acc: 47.946,73.987,91.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.068 | Acc: 47.788,73.948,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.069 | Acc: 47.947,73.625,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.076 | Acc: 47.961,73.576,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.098 | Acc: 47.753,73.476,90.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.099 | Acc: 47.721,73.545,90.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.107 | Acc: 47.812,73.426,90.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.116 | Acc: 47.769,73.289,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.126 | Acc: 47.695,73.227,90.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.131 | Acc: 47.773,73.231,90.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.133 | Acc: 47.806,73.296,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.137 | Acc: 47.809,73.277,90.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.146 | Acc: 47.783,73.121,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.147 | Acc: 47.837,73.121,90.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.150 | Acc: 47.881,73.059,90.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.159 | Acc: 47.863,72.997,89.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.227 | Acc: 36.719,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.250 | Acc: 40.402,60.119,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.235 | Acc: 39.996,60.004,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.228 | Acc: 39.716,59.503,66.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 2.621 | Acc: 54.688,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.096 | Acc: 47.507,74.479,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.012 | Acc: 48.685,75.305,90.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.021 | Acc: 48.835,75.115,91.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.030 | Acc: 49.064,74.769,91.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.036 | Acc: 48.948,74.675,91.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.022 | Acc: 49.064,74.839,91.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.006 | Acc: 49.141,75.000,91.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.010 | Acc: 49.020,74.859,91.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.015 | Acc: 48.955,74.715,91.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.032 | Acc: 48.780,74.615,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.047 | Acc: 48.618,74.427,91.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.056 | Acc: 48.606,74.212,91.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.065 | Acc: 48.605,74.102,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.072 | Acc: 48.543,74.080,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.075 | Acc: 48.694,73.996,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.084 | Acc: 48.569,73.902,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.092 | Acc: 48.481,73.722,90.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.100 | Acc: 48.392,73.660,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.109 | Acc: 48.376,73.573,90.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.579 | Acc: 36.719,71.094,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.360 | Acc: 39.100,59.449,65.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.280 | Acc: 39.958,59.508,65.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.267 | Acc: 39.588,59.170,66.342,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 2.710 | Acc: 50.781,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.005 | Acc: 48.065,73.847,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.037 | Acc: 48.685,73.971,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.070 | Acc: 48.412,73.591,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.103 | Acc: 48.139,73.322,90.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.103 | Acc: 47.966,73.414,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.120 | Acc: 47.727,73.224,90.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.134 | Acc: 47.689,73.055,90.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.118 | Acc: 47.812,73.258,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.114 | Acc: 47.876,73.364,90.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.111 | Acc: 47.854,73.375,90.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.108 | Acc: 47.932,73.462,90.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.117 | Acc: 47.906,73.379,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.122 | Acc: 47.842,73.378,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.125 | Acc: 47.893,73.410,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.121 | Acc: 47.937,73.482,90.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.115 | Acc: 48.080,73.476,90.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.113 | Acc: 48.124,73.492,90.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.117 | Acc: 48.141,73.492,90.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.125 | Acc: 48.124,73.407,90.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.993 | Acc: 42.969,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.062 | Acc: 43.006,60.156,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.020 | Acc: 43.178,60.137,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.039 | Acc: 42.956,59.682,66.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 3.184 | Acc: 47.656,72.656,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 49.033,76.265,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.938 | Acc: 50.038,76.543,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.959 | Acc: 49.411,75.756,92.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.985 | Acc: 48.804,75.405,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.972 | Acc: 49.064,75.418,92.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.993 | Acc: 48.818,75.161,92.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.997 | Acc: 48.931,75.066,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.002 | Acc: 49.190,74.971,91.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.013 | Acc: 48.930,74.888,91.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.021 | Acc: 48.811,74.681,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.032 | Acc: 48.650,74.608,91.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.047 | Acc: 48.632,74.452,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.061 | Acc: 48.503,74.359,91.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.068 | Acc: 48.482,74.216,91.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.078 | Acc: 48.406,74.143,91.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.082 | Acc: 48.382,74.112,91.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.087 | Acc: 48.328,74.033,90.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.087 | Acc: 48.388,74.002,90.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.089 | Acc: 48.310,73.981,90.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.713 | Acc: 46.094,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.174 | Acc: 40.402,59.821,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.157 | Acc: 39.996,59.451,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.142 | Acc: 39.703,59.170,66.931,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 2.950 | Acc: 46.875,76.562,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.070 | Acc: 48.884,73.847,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.019 | Acc: 48.495,73.780,91.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.023 | Acc: 48.476,73.988,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.013 | Acc: 48.476,74.296,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.010 | Acc: 48.530,74.451,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.000 | Acc: 48.838,74.690,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.004 | Acc: 48.908,74.729,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.020 | Acc: 48.719,74.558,91.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.020 | Acc: 48.835,74.525,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.028 | Acc: 48.659,74.440,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.033 | Acc: 48.653,74.364,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.047 | Acc: 48.745,74.186,91.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.059 | Acc: 48.611,74.072,91.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.065 | Acc: 48.551,73.946,91.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.079 | Acc: 48.479,73.832,90.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.084 | Acc: 48.435,73.790,90.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.082 | Acc: 48.497,73.804,90.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.088 | Acc: 48.472,73.723,90.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.101 | Acc: 48.442,73.628,90.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.209 | Acc: 46.875,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.638 | Acc: 37.760,58.408,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.626 | Acc: 37.367,57.489,65.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.620 | Acc: 37.167,57.595,65.100,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 2.849 | Acc: 57.031,73.438,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.089 | Acc: 48.921,74.219,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.024 | Acc: 48.780,75.095,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.977 | Acc: 48.924,75.448,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.975 | Acc: 48.679,75.530,91.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.978 | Acc: 48.940,75.340,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.011 | Acc: 48.573,74.716,91.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.016 | Acc: 48.487,74.695,91.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.022 | Acc: 48.748,74.704,91.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.024 | Acc: 48.679,74.702,91.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.032 | Acc: 48.644,74.631,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.050 | Acc: 48.558,74.367,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.052 | Acc: 48.551,74.267,90.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.058 | Acc: 48.500,74.210,90.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.069 | Acc: 48.293,74.021,90.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.081 | Acc: 48.201,73.949,90.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.095 | Acc: 48.167,73.805,90.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.111 | Acc: 47.984,73.655,90.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.111 | Acc: 48.074,73.654,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.113 | Acc: 48.126,73.653,90.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.690 | Acc: 45.312,61.719,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.023 | Acc: 41.778,60.454,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.061 | Acc: 41.235,60.290,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.085 | Acc: 40.766,59.657,66.842,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 2.979 | Acc: 50.000,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.996 | Acc: 49.479,74.628,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.978 | Acc: 49.104,75.191,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.969 | Acc: 49.641,75.346,91.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.973 | Acc: 49.219,75.299,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.964 | Acc: 49.459,75.433,91.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.994 | Acc: 49.038,75.213,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.008 | Acc: 48.897,74.956,91.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.005 | Acc: 48.729,74.898,91.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.011 | Acc: 48.714,74.763,91.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.024 | Acc: 48.647,74.561,91.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.031 | Acc: 48.660,74.420,91.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.030 | Acc: 48.732,74.501,91.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.038 | Acc: 48.623,74.374,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.048 | Acc: 48.549,74.266,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.059 | Acc: 48.510,74.156,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.061 | Acc: 48.574,74.082,91.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.067 | Acc: 48.515,73.958,90.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.080 | Acc: 48.459,73.773,90.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.087 | Acc: 48.485,73.733,90.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.871 | Acc: 42.969,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.177 | Acc: 39.807,60.268,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.214 | Acc: 39.520,59.642,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.224 | Acc: 39.370,59.516,66.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 3.530 | Acc: 45.312,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.991 | Acc: 49.851,75.409,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.975 | Acc: 49.790,75.419,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.003 | Acc: 49.014,74.923,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.993 | Acc: 49.074,75.087,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.990 | Acc: 48.886,75.286,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.007 | Acc: 48.470,75.065,91.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.019 | Acc: 48.654,74.717,91.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.025 | Acc: 48.675,74.554,91.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.021 | Acc: 48.520,74.642,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.015 | Acc: 48.616,74.689,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.019 | Acc: 48.692,74.590,91.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.038 | Acc: 48.570,74.251,91.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.035 | Acc: 48.614,74.240,91.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.045 | Acc: 48.521,74.146,90.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.057 | Acc: 48.448,73.996,90.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.069 | Acc: 48.343,73.888,90.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.075 | Acc: 48.323,73.834,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.081 | Acc: 48.399,73.799,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.085 | Acc: 48.442,73.725,90.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.325 | Acc: 43.750,59.375,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.319 | Acc: 42.448,58.668,64.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.349 | Acc: 41.616,58.765,63.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.369 | Acc: 41.317,58.338,64.011,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 2.781 | Acc: 48.438,70.312,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.012 | Acc: 48.065,75.298,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.996 | Acc: 48.228,75.553,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.965 | Acc: 48.796,75.948,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.951 | Acc: 49.113,75.704,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.964 | Acc: 48.786,75.565,92.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.965 | Acc: 48.754,75.407,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.973 | Acc: 48.548,75.255,92.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.977 | Acc: 48.593,75.262,92.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.993 | Acc: 48.407,74.965,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.005 | Acc: 48.375,74.728,91.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.016 | Acc: 48.448,74.590,91.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.022 | Acc: 48.489,74.520,91.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.028 | Acc: 48.593,74.482,91.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.032 | Acc: 48.560,74.369,91.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.040 | Acc: 48.606,74.242,91.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.048 | Acc: 48.569,74.129,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.056 | Acc: 48.504,73.992,91.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.066 | Acc: 48.377,73.818,91.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.079 | Acc: 48.310,73.704,90.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.728 | Acc: 44.531,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.109 | Acc: 39.769,60.119,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.175 | Acc: 40.434,59.108,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.191 | Acc: 40.266,58.786,66.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 2.837 | Acc: 55.469,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.046 | Acc: 48.438,74.851,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.017 | Acc: 49.104,74.943,91.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.983 | Acc: 49.014,75.346,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.973 | Acc: 49.257,75.434,91.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.993 | Acc: 48.987,75.255,91.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.995 | Acc: 48.960,75.187,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.011 | Acc: 48.770,74.878,91.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.004 | Acc: 48.996,74.888,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.000 | Acc: 49.016,74.991,91.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.017 | Acc: 48.869,74.802,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.030 | Acc: 48.915,74.654,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.028 | Acc: 49.002,74.553,91.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.036 | Acc: 48.913,74.443,91.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.043 | Acc: 48.855,74.366,90.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.047 | Acc: 48.809,74.278,90.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.058 | Acc: 48.710,74.153,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.067 | Acc: 48.651,74.106,90.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.079 | Acc: 48.628,73.985,90.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.087 | Acc: 48.595,73.844,90.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.289 | Acc: 40.625,62.500,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.319 | Acc: 39.621,60.045,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.298 | Acc: 39.101,59.661,65.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.281 | Acc: 39.203,59.183,65.625,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 2.988 | Acc: 43.750,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.943 | Acc: 48.103,75.893,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.978 | Acc: 48.457,75.210,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.965 | Acc: 48.258,75.231,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.955 | Acc: 48.679,75.463,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.947 | Acc: 49.041,75.201,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.956 | Acc: 49.090,75.058,91.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.979 | Acc: 48.742,74.917,91.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.988 | Acc: 48.661,74.738,91.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.002 | Acc: 48.593,74.542,91.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.002 | Acc: 48.682,74.530,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.008 | Acc: 48.604,74.392,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.012 | Acc: 48.574,74.429,91.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.020 | Acc: 48.578,74.455,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.027 | Acc: 48.615,74.349,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.030 | Acc: 48.640,74.317,91.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.038 | Acc: 48.640,74.255,91.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.041 | Acc: 48.632,74.278,91.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.048 | Acc: 48.608,74.214,91.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.059 | Acc: 48.556,74.085,90.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.167 | Acc: 46.875,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.304 | Acc: 40.141,59.226,65.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.375 | Acc: 39.253,58.727,64.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.384 | Acc: 39.293,58.363,64.908,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 2.990 | Acc: 46.094,75.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 49.405,73.810,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.969 | Acc: 49.600,74.505,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.957 | Acc: 49.782,74.974,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.954 | Acc: 49.441,75.135,92.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.937 | Acc: 49.505,75.418,92.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.927 | Acc: 49.703,75.413,92.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.943 | Acc: 49.512,75.150,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.958 | Acc: 49.194,74.908,92.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.957 | Acc: 49.189,74.957,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.965 | Acc: 49.184,74.821,92.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.966 | Acc: 49.268,74.816,92.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.975 | Acc: 49.310,74.741,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.980 | Acc: 49.371,74.731,91.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.995 | Acc: 49.255,74.583,91.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.000 | Acc: 49.190,74.502,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.000 | Acc: 49.143,74.474,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.006 | Acc: 49.155,74.427,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.015 | Acc: 49.078,74.316,91.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.027 | Acc: 48.985,74.219,91.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.747 | Acc: 39.062,54.688,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.853 | Acc: 38.504,54.241,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.867 | Acc: 38.357,53.868,64.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.873 | Acc: 38.025,53.893,64.357,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 2.861 | Acc: 50.781,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.042 | Acc: 47.768,73.586,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 48.647,74.238,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.977 | Acc: 49.232,74.603,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.966 | Acc: 49.354,74.904,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.975 | Acc: 49.126,74.869,91.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.988 | Acc: 48.960,74.871,91.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.994 | Acc: 48.969,74.679,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.991 | Acc: 49.093,74.723,91.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.984 | Acc: 49.072,74.849,91.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.996 | Acc: 48.966,74.790,91.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.003 | Acc: 48.961,74.745,91.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.009 | Acc: 48.917,74.666,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.014 | Acc: 48.967,74.659,91.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.012 | Acc: 49.038,74.633,91.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.027 | Acc: 49.011,74.406,90.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.029 | Acc: 49.070,74.396,90.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.037 | Acc: 49.061,74.299,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.047 | Acc: 49.005,74.251,90.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.057 | Acc: 48.839,74.129,90.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.265 | Acc: 43.750,60.156,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.330 | Acc: 40.960,58.817,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.299 | Acc: 41.101,58.518,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.294 | Acc: 40.779,58.504,67.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.050 | Acc: 46.875,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.930 | Acc: 50.074,75.112,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 49.771,75.610,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.935 | Acc: 48.924,75.935,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.916 | Acc: 49.219,75.916,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.935 | Acc: 49.134,75.665,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.945 | Acc: 49.186,75.549,92.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.945 | Acc: 49.341,75.543,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.959 | Acc: 49.267,75.364,91.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.970 | Acc: 49.292,75.164,91.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.989 | Acc: 48.947,74.981,91.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.992 | Acc: 49.123,74.781,91.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.996 | Acc: 49.160,74.763,91.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.011 | Acc: 49.087,74.548,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.024 | Acc: 48.996,74.408,90.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.037 | Acc: 48.897,74.237,90.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.042 | Acc: 48.902,74.177,90.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.051 | Acc: 48.818,74.157,90.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.064 | Acc: 48.723,74.022,90.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.077 | Acc: 48.606,73.936,90.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.451 | Acc: 37.500,57.812,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.505 | Acc: 40.662,57.478,63.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.457 | Acc: 39.653,57.489,64.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.454 | Acc: 39.191,57.134,64.946,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 2.831 | Acc: 50.000,73.438,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.011 | Acc: 49.888,73.921,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 49.752,75.000,91.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 49.219,74.693,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.007 | Acc: 48.987,74.518,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.009 | Acc: 48.832,74.598,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.999 | Acc: 48.825,74.671,91.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.985 | Acc: 49.053,74.789,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.993 | Acc: 48.947,74.660,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.009 | Acc: 48.938,74.422,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.010 | Acc: 48.954,74.433,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.015 | Acc: 48.823,74.434,91.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.014 | Acc: 48.969,74.400,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.008 | Acc: 49.132,74.512,91.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.005 | Acc: 49.146,74.516,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.014 | Acc: 49.032,74.442,91.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.016 | Acc: 49.095,74.445,91.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.019 | Acc: 49.065,74.404,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.033 | Acc: 48.922,74.249,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.042 | Acc: 48.852,74.129,90.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.919 | Acc: 42.188,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.217 | Acc: 39.062,61.384,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.172 | Acc: 39.920,61.452,66.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.187 | Acc: 39.357,61.296,66.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 2.647 | Acc: 50.781,86.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.916 | Acc: 49.777,76.600,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.935 | Acc: 49.447,75.991,92.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.907 | Acc: 49.488,76.255,92.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.902 | Acc: 50.096,76.080,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.911 | Acc: 49.752,76.006,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.908 | Acc: 49.742,76.033,92.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.916 | Acc: 49.740,76.097,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.918 | Acc: 49.602,76.043,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.938 | Acc: 49.508,75.829,91.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.942 | Acc: 49.549,75.781,91.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.958 | Acc: 49.480,75.502,91.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.970 | Acc: 49.426,75.282,91.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.981 | Acc: 49.338,75.111,91.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.993 | Acc: 49.205,75.033,91.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.999 | Acc: 49.141,74.907,91.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.009 | Acc: 49.075,74.757,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.020 | Acc: 48.937,74.572,91.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.028 | Acc: 48.894,74.431,91.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.042 | Acc: 48.811,74.270,90.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.509 | Acc: 38.281,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.370 | Acc: 38.839,60.714,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.377 | Acc: 38.681,60.690,66.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.383 | Acc: 38.704,60.707,66.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 3.016 | Acc: 51.562,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.876 | Acc: 51.265,76.637,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.922 | Acc: 50.076,76.162,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.910 | Acc: 49.565,76.178,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.891 | Acc: 49.537,76.264,92.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.880 | Acc: 49.652,76.222,92.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.875 | Acc: 49.897,76.117,92.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.875 | Acc: 49.839,76.036,92.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.889 | Acc: 49.850,75.888,92.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.901 | Acc: 49.737,75.729,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.909 | Acc: 49.674,75.645,92.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.925 | Acc: 49.516,75.421,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.941 | Acc: 49.306,75.301,92.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.963 | Acc: 49.177,75.063,91.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.966 | Acc: 49.238,75.106,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.975 | Acc: 49.208,75.010,91.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.979 | Acc: 49.197,75.000,91.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.991 | Acc: 49.084,74.830,91.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.002 | Acc: 49.059,74.697,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.009 | Acc: 49.116,74.633,91.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.926 | Acc: 39.844,63.281,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.359 | Acc: 39.211,59.040,65.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.314 | Acc: 38.853,58.270,65.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.323 | Acc: 38.461,58.414,65.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 3.485 | Acc: 40.625,65.625,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.060 | Acc: 48.140,73.661,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.010 | Acc: 48.266,74.943,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.962 | Acc: 48.822,75.704,92.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.929 | Acc: 49.171,75.858,92.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.923 | Acc: 49.536,75.804,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.937 | Acc: 49.264,75.652,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.946 | Acc: 49.197,75.382,92.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.946 | Acc: 49.262,75.417,91.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.959 | Acc: 49.089,75.242,91.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.978 | Acc: 48.935,74.946,91.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.979 | Acc: 49.024,75.007,91.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.988 | Acc: 48.979,74.906,91.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.999 | Acc: 48.895,74.808,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.009 | Acc: 48.921,74.733,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.013 | Acc: 48.923,74.613,91.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.018 | Acc: 48.910,74.513,91.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.033 | Acc: 48.829,74.354,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.042 | Acc: 48.849,74.290,90.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.053 | Acc: 48.821,74.131,90.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.257 | Acc: 39.844,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.279 | Acc: 40.402,58.705,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.262 | Acc: 39.844,58.251,65.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.247 | Acc: 39.921,58.427,66.176,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 2.981 | Acc: 50.000,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.941 | Acc: 48.921,75.707,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.929 | Acc: 49.276,75.800,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.905 | Acc: 49.475,75.794,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.912 | Acc: 49.306,75.801,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.903 | Acc: 49.513,76.052,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.902 | Acc: 49.419,76.046,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.905 | Acc: 49.357,75.964,92.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.918 | Acc: 49.423,75.718,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.924 | Acc: 49.547,75.565,91.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.933 | Acc: 49.580,75.564,91.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.929 | Acc: 49.707,75.562,91.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.938 | Acc: 49.656,75.464,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.949 | Acc: 49.605,75.353,91.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.960 | Acc: 49.513,75.303,91.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.970 | Acc: 49.458,75.189,91.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.980 | Acc: 49.340,75.039,91.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.991 | Acc: 49.265,74.924,91.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.003 | Acc: 49.178,74.799,91.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.012 | Acc: 49.139,74.656,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.148 | Acc: 35.156,55.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.374 | Acc: 40.402,58.110,64.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.394 | Acc: 40.149,57.774,64.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.389 | Acc: 40.164,57.774,64.178,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 3.053 | Acc: 50.781,67.969,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.912 | Acc: 50.223,75.484,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.897 | Acc: 50.362,75.572,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.897 | Acc: 50.077,75.909,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.880 | Acc: 50.231,76.061,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.877 | Acc: 50.348,76.013,92.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.883 | Acc: 50.232,76.117,91.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.897 | Acc: 49.900,75.798,91.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.919 | Acc: 49.602,75.510,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.925 | Acc: 49.607,75.565,91.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.933 | Acc: 49.534,75.501,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.948 | Acc: 49.392,75.223,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.957 | Acc: 49.355,75.182,91.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.967 | Acc: 49.321,75.090,91.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.980 | Acc: 49.202,74.981,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.988 | Acc: 49.182,74.824,91.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.994 | Acc: 49.160,74.688,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.009 | Acc: 49.033,74.501,91.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.010 | Acc: 49.115,74.559,91.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.016 | Acc: 49.051,74.528,91.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.387 | Acc: 41.406,60.156,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.330 | Acc: 39.472,58.743,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.341 | Acc: 40.320,57.965,66.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.361 | Acc: 40.036,58.133,66.662,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 2.681 | Acc: 53.125,75.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.908 | Acc: 50.893,76.525,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.883 | Acc: 51.124,76.353,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.883 | Acc: 50.653,76.460,91.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.875 | Acc: 50.829,76.370,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.881 | Acc: 50.580,76.199,91.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.895 | Acc: 50.355,75.981,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.901 | Acc: 50.249,75.936,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.911 | Acc: 50.374,75.854,91.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.922 | Acc: 50.155,75.837,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.931 | Acc: 50.051,75.793,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.940 | Acc: 49.905,75.679,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.949 | Acc: 49.783,75.509,91.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.954 | Acc: 49.805,75.392,91.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.969 | Acc: 49.711,75.203,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.978 | Acc: 49.647,75.145,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.982 | Acc: 49.584,75.029,91.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.993 | Acc: 49.418,74.927,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.996 | Acc: 49.377,74.905,91.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.003 | Acc: 49.301,74.813,90.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.893 | Acc: 43.750,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.242 | Acc: 40.774,59.487,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.237 | Acc: 41.216,59.070,65.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.243 | Acc: 41.457,59.004,65.420,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 3.257 | Acc: 38.281,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.921 | Acc: 49.702,75.856,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.900 | Acc: 50.286,75.743,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.918 | Acc: 49.872,75.576,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.897 | Acc: 50.019,75.878,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.916 | Acc: 49.752,75.812,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.907 | Acc: 49.632,76.085,92.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.914 | Acc: 49.474,75.970,92.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.911 | Acc: 49.602,76.004,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.925 | Acc: 49.594,75.850,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.936 | Acc: 49.588,75.626,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.943 | Acc: 49.494,75.615,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.951 | Acc: 49.511,75.395,91.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.961 | Acc: 49.455,75.198,91.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.962 | Acc: 49.497,75.158,91.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.966 | Acc: 49.463,75.067,91.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.980 | Acc: 49.323,74.912,91.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.982 | Acc: 49.297,74.922,91.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.983 | Acc: 49.299,74.911,91.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.988 | Acc: 49.315,74.795,91.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.088 | Acc: 42.969,61.719,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.152 | Acc: 42.299,59.635,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.171 | Acc: 41.730,59.794,65.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.172 | Acc: 41.432,59.734,66.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 2.904 | Acc: 47.656,75.000,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.970 | Acc: 48.400,74.479,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.931 | Acc: 48.800,75.476,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.941 | Acc: 48.425,75.384,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.947 | Acc: 48.708,75.347,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.933 | Acc: 49.203,75.704,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.937 | Acc: 48.973,75.768,92.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.937 | Acc: 49.180,75.837,91.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.930 | Acc: 49.423,75.878,91.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.931 | Acc: 49.504,75.924,91.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.935 | Acc: 49.448,75.770,91.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.939 | Acc: 49.632,75.686,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.943 | Acc: 49.669,75.590,91.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.954 | Acc: 49.590,75.431,91.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.964 | Acc: 49.572,75.292,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.978 | Acc: 49.382,75.143,91.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.984 | Acc: 49.394,75.037,91.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.990 | Acc: 49.375,74.945,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.998 | Acc: 49.299,74.894,91.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.009 | Acc: 49.170,74.781,90.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.499 | Acc: 46.875,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.280 | Acc: 42.001,59.152,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.252 | Acc: 42.188,58.861,65.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.256 | Acc: 41.650,58.696,65.548,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 3.164 | Acc: 47.656,72.656,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.970 | Acc: 50.186,75.037,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.941 | Acc: 50.591,75.210,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.941 | Acc: 50.384,75.295,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.938 | Acc: 50.087,75.579,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.936 | Acc: 50.139,75.588,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.934 | Acc: 50.084,75.542,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.924 | Acc: 50.105,75.781,92.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.920 | Acc: 49.918,75.806,92.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.926 | Acc: 49.827,75.729,92.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.933 | Acc: 49.697,75.692,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.939 | Acc: 49.753,75.527,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.949 | Acc: 49.637,75.321,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.959 | Acc: 49.614,75.224,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.962 | Acc: 49.505,75.170,91.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.970 | Acc: 49.481,75.018,91.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.976 | Acc: 49.477,74.934,91.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.984 | Acc: 49.356,74.904,91.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.990 | Acc: 49.279,74.872,91.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.994 | Acc: 49.313,74.815,91.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.404 | Acc: 39.844,60.938,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.254 | Acc: 40.699,60.789,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.213 | Acc: 40.854,60.899,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.210 | Acc: 40.318,60.873,66.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 2.526 | Acc: 56.250,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.903 | Acc: 49.926,76.153,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.871 | Acc: 50.514,76.315,92.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.836 | Acc: 50.743,76.588,92.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.846 | Acc: 50.492,76.447,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.877 | Acc: 50.232,76.006,92.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.886 | Acc: 50.394,75.859,92.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.897 | Acc: 50.161,75.936,92.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.914 | Acc: 49.990,75.747,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.923 | Acc: 49.918,75.535,92.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.931 | Acc: 49.829,75.326,92.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.940 | Acc: 49.813,75.251,92.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.943 | Acc: 49.799,75.217,92.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.952 | Acc: 49.665,75.165,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.960 | Acc: 49.666,75.058,91.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.966 | Acc: 49.642,75.044,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.972 | Acc: 49.552,74.988,91.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.977 | Acc: 49.517,74.936,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.984 | Acc: 49.465,74.859,91.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.989 | Acc: 49.414,74.824,91.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.845 | Acc: 39.062,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.162 | Acc: 39.211,59.859,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.155 | Acc: 39.901,58.994,65.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.118 | Acc: 40.228,59.144,66.060,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 3.400 | Acc: 42.969,69.531,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 50.074,75.372,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.933 | Acc: 48.552,76.048,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.912 | Acc: 49.257,76.063,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.885 | Acc: 49.614,76.196,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.882 | Acc: 49.474,76.207,92.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.877 | Acc: 49.529,76.298,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.891 | Acc: 49.501,76.080,92.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.909 | Acc: 49.408,75.878,92.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.923 | Acc: 49.253,75.583,92.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.935 | Acc: 49.199,75.439,92.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.943 | Acc: 49.187,75.382,92.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.937 | Acc: 49.196,75.431,92.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.941 | Acc: 49.156,75.404,92.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.944 | Acc: 49.169,75.373,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.945 | Acc: 49.195,75.335,92.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.959 | Acc: 49.097,75.241,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.967 | Acc: 49.070,75.176,91.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.972 | Acc: 49.050,75.093,91.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.973 | Acc: 49.176,75.047,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.739 | Acc: 44.531,67.969,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.170 | Acc: 42.857,61.198,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.177 | Acc: 42.168,60.766,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.183 | Acc: 41.355,60.643,66.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.612 | Acc: 54.688,81.250,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.868 | Acc: 50.744,76.749,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.886 | Acc: 50.267,76.467,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.903 | Acc: 49.654,76.294,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.882 | Acc: 49.855,76.399,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.878 | Acc: 50.062,76.562,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.877 | Acc: 50.142,76.427,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.883 | Acc: 50.017,76.186,92.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.883 | Acc: 49.864,76.233,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.902 | Acc: 49.750,75.876,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.903 | Acc: 49.802,75.777,92.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.907 | Acc: 49.890,75.707,92.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.923 | Acc: 49.754,75.574,92.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.926 | Acc: 49.704,75.518,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.938 | Acc: 49.577,75.384,91.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.942 | Acc: 49.598,75.291,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.952 | Acc: 49.496,75.097,91.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.958 | Acc: 49.464,75.094,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.968 | Acc: 49.357,75.050,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.971 | Acc: 49.325,75.023,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.140 | Acc: 42.188,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.517 | Acc: 38.690,57.664,65.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.495 | Acc: 38.072,57.812,65.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.487 | Acc: 38.128,57.992,65.740,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 3.054 | Acc: 46.875,72.656,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.863 | Acc: 50.818,77.418,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.872 | Acc: 50.743,77.325,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.848 | Acc: 50.871,77.651,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.876 | Acc: 50.473,76.890,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.892 | Acc: 50.232,76.570,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.915 | Acc: 50.090,76.324,92.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.923 | Acc: 50.294,76.158,91.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.933 | Acc: 50.053,76.087,91.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.939 | Acc: 49.905,75.911,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.941 | Acc: 49.895,75.843,91.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.943 | Acc: 49.830,75.951,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.943 | Acc: 49.828,75.849,91.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.956 | Acc: 49.752,75.668,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.967 | Acc: 49.630,75.503,91.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.972 | Acc: 49.748,75.431,91.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.974 | Acc: 49.779,75.436,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.979 | Acc: 49.704,75.396,91.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.994 | Acc: 49.543,75.268,91.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.998 | Acc: 49.510,75.228,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.209 | Acc: 39.844,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.613 | Acc: 38.988,58.296,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.603 | Acc: 38.910,57.774,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.602 | Acc: 38.653,57.774,66.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 3.106 | Acc: 47.656,67.188,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.920 | Acc: 48.847,75.409,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.917 | Acc: 49.085,75.267,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.907 | Acc: 49.052,75.576,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.882 | Acc: 49.643,75.839,92.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.870 | Acc: 49.691,76.160,92.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.874 | Acc: 49.755,75.981,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.883 | Acc: 49.479,75.953,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.867 | Acc: 49.782,76.140,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.878 | Acc: 49.883,75.967,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.893 | Acc: 49.876,75.824,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.897 | Acc: 49.855,75.841,92.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.903 | Acc: 49.754,75.784,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.914 | Acc: 49.662,75.653,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.925 | Acc: 49.625,75.517,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.937 | Acc: 49.538,75.356,91.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.946 | Acc: 49.491,75.302,91.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.952 | Acc: 49.491,75.291,91.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.961 | Acc: 49.385,75.171,91.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.969 | Acc: 49.313,75.117,91.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.063 | Acc: 46.094,65.625,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.055 | Acc: 42.039,61.347,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.119 | Acc: 41.502,60.690,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.122 | Acc: 41.624,60.566,67.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 2.557 | Acc: 52.344,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.736 | Acc: 51.190,78.571,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.799 | Acc: 50.076,77.534,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.786 | Acc: 50.487,77.677,93.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.796 | Acc: 50.318,77.392,92.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.811 | Acc: 50.410,77.344,92.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.810 | Acc: 50.400,77.234,92.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.830 | Acc: 50.305,76.917,92.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.848 | Acc: 50.184,76.572,92.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.856 | Acc: 50.142,76.437,92.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.872 | Acc: 50.012,76.290,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.890 | Acc: 49.965,76.106,91.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.909 | Acc: 49.686,75.830,91.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.914 | Acc: 49.790,75.763,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.921 | Acc: 49.844,75.659,91.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.930 | Acc: 49.772,75.545,91.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.933 | Acc: 49.740,75.501,91.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.936 | Acc: 49.814,75.502,91.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.943 | Acc: 49.719,75.405,91.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.952 | Acc: 49.653,75.289,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.375 | Acc: 41.406,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.358 | Acc: 42.560,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.361 | Acc: 41.997,59.146,64.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.350 | Acc: 41.855,59.209,64.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 2.847 | Acc: 46.094,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.928 | Acc: 49.740,75.632,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.836 | Acc: 50.400,76.753,92.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.850 | Acc: 50.307,76.767,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.855 | Acc: 50.203,76.630,92.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.880 | Acc: 49.977,76.129,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.879 | Acc: 50.045,76.059,92.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.894 | Acc: 49.939,75.898,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.898 | Acc: 49.806,75.801,92.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.912 | Acc: 49.607,75.613,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.918 | Acc: 49.534,75.459,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.924 | Acc: 49.576,75.445,91.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.937 | Acc: 49.517,75.353,91.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.947 | Acc: 49.515,75.165,91.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.948 | Acc: 49.541,75.200,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.951 | Acc: 49.585,75.202,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.958 | Acc: 49.598,75.161,91.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.967 | Acc: 49.629,75.053,91.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.974 | Acc: 49.591,75.024,91.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.974 | Acc: 49.588,75.039,91.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.839 | Acc: 40.625,64.844,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.119 | Acc: 40.848,61.719,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.127 | Acc: 40.377,61.128,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.130 | Acc: 40.599,60.425,67.354,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 2.784 | Acc: 48.438,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.857 | Acc: 48.400,77.716,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.862 | Acc: 48.895,77.248,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.879 | Acc: 49.103,76.998,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.877 | Acc: 49.508,76.698,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.880 | Acc: 49.629,76.431,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.867 | Acc: 49.774,76.550,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.868 | Acc: 49.762,76.513,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.862 | Acc: 49.898,76.543,92.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.882 | Acc: 49.676,76.355,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.894 | Acc: 49.662,76.197,92.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.898 | Acc: 49.622,76.071,92.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.902 | Acc: 49.695,75.985,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.909 | Acc: 49.683,75.937,91.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.912 | Acc: 49.711,75.959,91.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.925 | Acc: 49.600,75.807,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.941 | Acc: 49.618,75.484,91.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.947 | Acc: 49.572,75.353,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.952 | Acc: 49.554,75.258,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.967 | Acc: 49.440,75.125,91.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.047 | Acc: 33.594,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.228 | Acc: 40.662,60.082,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.230 | Acc: 40.091,60.137,66.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.249 | Acc: 40.036,59.862,66.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 2.677 | Acc: 53.906,73.438,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.847 | Acc: 50.335,76.786,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.867 | Acc: 50.152,76.677,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.862 | Acc: 49.808,76.870,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.872 | Acc: 49.788,76.736,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.872 | Acc: 49.714,76.648,92.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.869 | Acc: 49.929,76.550,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.872 | Acc: 49.961,76.707,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.881 | Acc: 50.102,76.509,92.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.883 | Acc: 49.991,76.424,92.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.902 | Acc: 49.860,76.088,92.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.912 | Acc: 49.866,75.933,92.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.912 | Acc: 49.854,75.888,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.922 | Acc: 49.764,75.793,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.925 | Acc: 49.705,75.770,91.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.925 | Acc: 49.613,75.698,91.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.924 | Acc: 49.730,75.772,91.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.927 | Acc: 49.670,75.729,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.935 | Acc: 49.645,75.675,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.945 | Acc: 49.541,75.513,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.787 | Acc: 46.875,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.098 | Acc: 41.815,61.235,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.105 | Acc: 42.054,60.271,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.106 | Acc: 42.047,60.630,66.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.805 | Acc: 53.125,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.783 | Acc: 51.153,76.897,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.813 | Acc: 50.457,76.601,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.822 | Acc: 50.282,76.306,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.841 | Acc: 50.029,75.955,93.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.846 | Acc: 49.907,76.145,93.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.861 | Acc: 49.632,76.046,93.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.865 | Acc: 49.629,76.147,93.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.871 | Acc: 49.602,76.092,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.877 | Acc: 49.555,76.014,92.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.884 | Acc: 49.642,75.859,92.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.892 | Acc: 49.795,75.707,92.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.912 | Acc: 49.624,75.545,92.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.910 | Acc: 49.656,75.614,92.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.912 | Acc: 49.741,75.523,92.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.913 | Acc: 49.753,75.519,92.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.921 | Acc: 49.742,75.416,91.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.928 | Acc: 49.682,75.385,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.936 | Acc: 49.608,75.305,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.942 | Acc: 49.649,75.265,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.026 | Acc: 38.281,62.500,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.305 | Acc: 42.411,58.631,64.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.301 | Acc: 42.588,58.899,64.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.273 | Acc: 42.431,59.004,64.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 2.822 | Acc: 47.656,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.860 | Acc: 50.223,77.865,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.826 | Acc: 50.838,78.011,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.852 | Acc: 50.320,77.408,92.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.844 | Acc: 50.347,77.402,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.846 | Acc: 50.456,77.158,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.856 | Acc: 50.284,76.982,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.855 | Acc: 50.139,76.945,92.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.870 | Acc: 49.990,76.626,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.885 | Acc: 49.719,76.386,92.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.902 | Acc: 49.806,76.084,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.912 | Acc: 49.735,75.923,91.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.921 | Acc: 49.605,75.794,91.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.922 | Acc: 49.584,75.679,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.930 | Acc: 49.564,75.562,91.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.935 | Acc: 49.489,75.506,91.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.940 | Acc: 49.547,75.496,91.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.948 | Acc: 49.446,75.458,91.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.956 | Acc: 49.340,75.392,91.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.961 | Acc: 49.348,75.297,91.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.164 | Acc: 36.719,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.567 | Acc: 39.881,56.808,64.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.571 | Acc: 39.539,56.745,64.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.564 | Acc: 39.588,56.980,64.562,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 2.526 | Acc: 54.688,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.870 | Acc: 51.228,76.860,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.912 | Acc: 49.657,76.239,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.888 | Acc: 49.616,76.268,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.874 | Acc: 49.740,76.784,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.868 | Acc: 49.853,76.802,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.862 | Acc: 50.155,76.711,92.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.863 | Acc: 50.144,76.679,92.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.861 | Acc: 50.345,76.616,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.866 | Acc: 50.250,76.506,92.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.869 | Acc: 50.288,76.458,92.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.885 | Acc: 50.152,76.220,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.895 | Acc: 50.068,76.028,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.908 | Acc: 50.006,75.868,92.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.914 | Acc: 50.031,75.784,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.921 | Acc: 49.982,75.690,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.924 | Acc: 49.937,75.750,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.928 | Acc: 49.973,75.680,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.935 | Acc: 49.944,75.615,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.945 | Acc: 49.918,75.513,91.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.072 | Acc: 43.750,57.812,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.107 | Acc: 42.894,59.263,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.073 | Acc: 43.255,60.004,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.095 | Acc: 42.815,59.682,67.469,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 3.066 | Acc: 44.531,68.750,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.783 | Acc: 50.670,77.195,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.801 | Acc: 49.733,76.886,93.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.794 | Acc: 49.859,77.472,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.790 | Acc: 50.068,77.604,93.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.799 | Acc: 50.108,77.290,93.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.822 | Acc: 49.994,76.937,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.834 | Acc: 49.889,76.668,92.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.838 | Acc: 49.908,76.548,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.848 | Acc: 49.875,76.502,92.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.856 | Acc: 49.872,76.423,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.860 | Acc: 49.859,76.389,92.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.875 | Acc: 49.721,76.300,92.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.876 | Acc: 49.805,76.242,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.889 | Acc: 49.728,76.104,92.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.898 | Acc: 49.689,76.030,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.914 | Acc: 49.749,75.862,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.928 | Acc: 49.750,75.660,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.935 | Acc: 49.836,75.573,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.945 | Acc: 49.770,75.427,91.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.150 | Acc: 42.969,57.812,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.389 | Acc: 40.699,58.780,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.321 | Acc: 40.225,58.937,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.301 | Acc: 39.626,58.965,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 2.894 | Acc: 46.875,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 48.438,77.232,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.882 | Acc: 49.886,77.744,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.845 | Acc: 50.512,77.600,92.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.827 | Acc: 50.627,77.672,92.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.820 | Acc: 50.572,77.584,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.816 | Acc: 50.594,77.583,92.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.838 | Acc: 50.382,77.100,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.846 | Acc: 50.378,77.053,92.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.851 | Acc: 50.332,76.929,92.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.863 | Acc: 50.070,76.683,92.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.877 | Acc: 49.975,76.474,92.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.891 | Acc: 49.874,76.303,92.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.899 | Acc: 49.958,76.245,92.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.909 | Acc: 49.878,76.101,91.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.917 | Acc: 49.803,76.085,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.927 | Acc: 49.764,75.974,91.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.933 | Acc: 49.780,75.845,91.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.937 | Acc: 49.836,75.731,91.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.944 | Acc: 49.844,75.595,91.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.234 | Acc: 35.938,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.315 | Acc: 41.034,59.747,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.332 | Acc: 40.720,58.899,66.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.315 | Acc: 40.241,59.144,66.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 2.715 | Acc: 50.781,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.845 | Acc: 49.740,77.753,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.780 | Acc: 49.905,77.744,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.759 | Acc: 50.628,77.830,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.773 | Acc: 50.714,77.720,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.780 | Acc: 50.928,77.607,92.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.797 | Acc: 50.549,77.415,92.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.823 | Acc: 50.371,77.089,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.834 | Acc: 50.388,76.980,92.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 50.220,76.610,92.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.867 | Acc: 50.225,76.465,92.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.884 | Acc: 50.057,76.393,92.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.893 | Acc: 49.890,76.248,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.902 | Acc: 49.847,76.039,92.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.905 | Acc: 49.864,75.943,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.911 | Acc: 49.769,75.888,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.913 | Acc: 49.786,75.905,91.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.924 | Acc: 49.702,75.820,91.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.925 | Acc: 49.691,75.762,91.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.931 | Acc: 49.639,75.630,91.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.251 | Acc: 39.844,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.387 | Acc: 40.104,58.110,64.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.370 | Acc: 40.511,58.117,64.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.387 | Acc: 39.895,57.467,64.498,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.696 | Acc: 56.250,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.819 | Acc: 50.372,77.232,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.833 | Acc: 50.305,76.867,92.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.804 | Acc: 50.538,77.177,93.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.818 | Acc: 50.338,76.929,92.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.826 | Acc: 50.565,76.841,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.831 | Acc: 50.355,76.756,92.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.845 | Acc: 50.089,76.690,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 50.073,76.383,92.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.866 | Acc: 49.970,76.269,92.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.878 | Acc: 49.798,76.123,92.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.880 | Acc: 49.537,76.121,92.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.879 | Acc: 49.582,76.131,92.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.886 | Acc: 49.623,76.015,92.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.889 | Acc: 49.697,76.026,92.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.898 | Acc: 49.730,75.955,92.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.900 | Acc: 49.822,75.910,92.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.910 | Acc: 49.810,75.763,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.916 | Acc: 49.818,75.682,91.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.921 | Acc: 49.840,75.601,91.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.142 | Acc: 45.312,59.375,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.334 | Acc: 39.918,59.115,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.332 | Acc: 39.634,58.765,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.323 | Acc: 40.036,59.183,65.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 3.107 | Acc: 46.094,74.219,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.900 | Acc: 50.149,76.935,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.874 | Acc: 50.305,76.162,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.845 | Acc: 50.589,76.857,92.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.819 | Acc: 51.090,76.977,92.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.828 | Acc: 50.859,76.787,92.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.848 | Acc: 50.594,76.498,92.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.850 | Acc: 50.543,76.585,92.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.869 | Acc: 50.412,76.339,92.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.883 | Acc: 50.220,76.131,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.895 | Acc: 49.996,76.081,92.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.901 | Acc: 49.915,76.025,92.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.900 | Acc: 49.919,75.998,92.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.905 | Acc: 49.826,76.003,92.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.907 | Acc: 49.883,75.981,91.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.917 | Acc: 49.847,75.846,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.925 | Acc: 49.856,75.757,91.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.933 | Acc: 49.787,75.687,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.941 | Acc: 49.784,75.530,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.943 | Acc: 49.910,75.496,91.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.256 | Acc: 42.188,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.329 | Acc: 40.216,60.417,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.291 | Acc: 40.206,60.137,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.274 | Acc: 40.202,60.015,66.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 3.106 | Acc: 46.094,68.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.845 | Acc: 51.042,75.967,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.841 | Acc: 50.915,76.124,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.806 | Acc: 50.897,76.703,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.807 | Acc: 50.936,76.755,92.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.817 | Acc: 50.781,76.733,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.811 | Acc: 50.865,76.801,92.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.816 | Acc: 50.787,76.751,92.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.835 | Acc: 50.631,76.490,92.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.838 | Acc: 50.604,76.515,92.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.844 | Acc: 50.494,76.458,92.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.854 | Acc: 50.431,76.368,92.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.862 | Acc: 50.386,76.274,92.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.876 | Acc: 50.293,76.039,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.887 | Acc: 50.186,75.940,92.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.890 | Acc: 50.234,75.934,92.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.897 | Acc: 50.299,75.869,91.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.904 | Acc: 50.243,75.797,91.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.907 | Acc: 50.262,75.731,91.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.912 | Acc: 50.215,75.675,91.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.877 | Acc: 43.750,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.289 | Acc: 43.118,59.263,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.357 | Acc: 42.378,58.822,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.332 | Acc: 41.983,58.760,65.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 3.114 | Acc: 47.656,70.312,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.837 | Acc: 50.409,76.265,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.865 | Acc: 50.629,75.724,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.843 | Acc: 50.602,76.268,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.838 | Acc: 50.878,76.264,92.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 50.696,76.021,93.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.845 | Acc: 50.484,75.910,92.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.855 | Acc: 50.499,75.920,92.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.859 | Acc: 50.325,75.927,92.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.852 | Acc: 50.574,76.127,92.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.856 | Acc: 50.556,76.049,92.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.869 | Acc: 50.399,75.863,92.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.877 | Acc: 50.279,75.726,92.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.883 | Acc: 50.204,75.745,92.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.892 | Acc: 50.161,75.614,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.898 | Acc: 50.052,75.524,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.901 | Acc: 50.027,75.572,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.903 | Acc: 49.975,75.607,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.909 | Acc: 49.948,75.602,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.921 | Acc: 49.912,75.496,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.991 | Acc: 43.750,55.469,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.330 | Acc: 41.629,59.338,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.325 | Acc: 41.711,58.498,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.350 | Acc: 41.214,58.030,65.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 2.880 | Acc: 50.000,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.908 | Acc: 49.368,75.967,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.892 | Acc: 49.619,76.239,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.855 | Acc: 50.384,76.550,92.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.852 | Acc: 50.328,76.553,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.859 | Acc: 50.147,76.501,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.864 | Acc: 50.077,76.401,92.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.871 | Acc: 50.072,76.391,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.873 | Acc: 50.058,76.305,92.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.872 | Acc: 50.177,76.260,92.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.872 | Acc: 50.175,76.329,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.870 | Acc: 50.265,76.350,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.873 | Acc: 50.178,76.313,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.880 | Acc: 50.177,76.215,91.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.885 | Acc: 50.183,76.123,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.893 | Acc: 50.151,76.069,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.899 | Acc: 50.239,75.959,91.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.905 | Acc: 50.275,75.894,91.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.915 | Acc: 50.234,75.764,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.927 | Acc: 50.148,75.607,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.227 | Acc: 41.406,61.719,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.507 | Acc: 39.249,58.333,65.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.505 | Acc: 39.024,57.851,65.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.487 | Acc: 39.280,58.210,64.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.268 | Acc: 53.906,85.156,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.911 | Acc: 48.735,76.935,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.860 | Acc: 49.524,77.630,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.848 | Acc: 49.795,77.369,91.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.825 | Acc: 50.077,77.585,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.818 | Acc: 50.449,77.421,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.836 | Acc: 50.278,77.131,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.848 | Acc: 50.349,77.061,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.855 | Acc: 50.408,76.990,92.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.858 | Acc: 50.294,76.891,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.864 | Acc: 50.342,76.726,92.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.866 | Acc: 50.445,76.601,92.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.864 | Acc: 50.528,76.637,92.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.870 | Acc: 50.566,76.521,91.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.872 | Acc: 50.564,76.454,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.868 | Acc: 50.594,76.505,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.877 | Acc: 50.511,76.358,91.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.889 | Acc: 50.369,76.214,91.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.900 | Acc: 50.253,76.080,91.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.913 | Acc: 50.152,75.892,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.071 | Acc: 38.281,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.514 | Acc: 38.318,59.412,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.428 | Acc: 38.948,59.585,66.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.400 | Acc: 38.589,59.477,66.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 2.576 | Acc: 53.906,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.820 | Acc: 51.339,76.674,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.713 | Acc: 52.763,77.382,93.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.719 | Acc: 52.049,77.984,93.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.751 | Acc: 51.302,77.749,93.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.755 | Acc: 51.207,77.630,93.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.771 | Acc: 51.343,77.473,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.772 | Acc: 51.197,77.455,92.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.780 | Acc: 51.126,77.397,92.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.790 | Acc: 51.006,77.184,92.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 50.867,77.041,92.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.814 | Acc: 50.774,76.962,92.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.819 | Acc: 50.720,76.890,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.826 | Acc: 50.623,76.769,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.829 | Acc: 50.581,76.649,92.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.843 | Acc: 50.542,76.443,92.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.851 | Acc: 50.470,76.412,92.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.858 | Acc: 50.497,76.336,92.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.865 | Acc: 50.558,76.270,92.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.880 | Acc: 50.535,76.091,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.695 | Acc: 42.969,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.526 | Acc: 37.128,58.743,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.585 | Acc: 36.738,57.774,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.601 | Acc: 36.117,57.877,64.985,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 2.770 | Acc: 51.562,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.856 | Acc: 49.963,75.670,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.793 | Acc: 50.286,77.077,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.794 | Acc: 50.320,76.870,93.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 50.125,76.630,93.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.826 | Acc: 50.093,76.717,92.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.835 | Acc: 50.387,76.717,92.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.839 | Acc: 50.332,76.623,92.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.856 | Acc: 50.146,76.354,92.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.865 | Acc: 50.134,76.222,92.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.864 | Acc: 50.218,76.189,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.880 | Acc: 50.064,76.000,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.880 | Acc: 50.088,76.011,92.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.885 | Acc: 50.054,75.976,92.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.887 | Acc: 50.183,75.943,91.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.896 | Acc: 50.130,75.857,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.904 | Acc: 50.044,75.801,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.907 | Acc: 50.053,75.751,91.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.913 | Acc: 50.032,75.667,91.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.916 | Acc: 50.107,75.646,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.757 | Acc: 48.438,64.062,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.146 | Acc: 41.443,61.086,66.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.133 | Acc: 42.073,60.861,66.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.125 | Acc: 41.624,60.553,66.112,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 3.161 | Acc: 45.312,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.908 | Acc: 49.554,76.711,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.852 | Acc: 50.000,77.363,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.850 | Acc: 50.090,77.100,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.851 | Acc: 49.884,77.045,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.845 | Acc: 49.977,77.158,92.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.843 | Acc: 50.187,77.085,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.854 | Acc: 50.161,76.900,92.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.856 | Acc: 50.112,76.844,92.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.858 | Acc: 50.324,76.774,92.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.857 | Acc: 50.393,76.823,92.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.868 | Acc: 50.343,76.679,92.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.866 | Acc: 50.395,76.699,92.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.875 | Acc: 50.278,76.562,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.882 | Acc: 50.242,76.518,91.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.895 | Acc: 50.174,76.324,91.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.907 | Acc: 50.200,76.112,91.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.910 | Acc: 50.188,76.010,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.915 | Acc: 50.143,75.922,91.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.916 | Acc: 50.148,75.927,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.928 | Acc: 46.094,59.375,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.338 | Acc: 40.141,59.152,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.313 | Acc: 39.844,58.670,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.264 | Acc: 40.241,58.876,66.124,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 3.021 | Acc: 50.000,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.861 | Acc: 49.368,77.493,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.821 | Acc: 49.581,77.687,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.806 | Acc: 50.435,77.267,93.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.789 | Acc: 50.588,77.517,93.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.774 | Acc: 50.480,77.630,93.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.773 | Acc: 50.568,77.344,93.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.778 | Acc: 50.460,77.155,93.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.793 | Acc: 50.442,77.135,93.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.805 | Acc: 50.462,77.003,93.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.817 | Acc: 50.404,76.854,92.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.825 | Acc: 50.382,76.849,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.831 | Acc: 50.379,76.780,92.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.835 | Acc: 50.350,76.685,92.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.841 | Acc: 50.370,76.626,92.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.851 | Acc: 50.361,76.500,92.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.860 | Acc: 50.358,76.399,92.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.866 | Acc: 50.399,76.317,92.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.879 | Acc: 50.439,76.123,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.883 | Acc: 50.506,76.056,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.505 | Acc: 40.625,60.156,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.321 | Acc: 41.853,59.598,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.315 | Acc: 41.120,59.299,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.322 | Acc: 40.881,59.388,66.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 3.029 | Acc: 49.219,74.219,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.871 | Acc: 49.665,77.232,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.831 | Acc: 50.095,77.077,93.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.806 | Acc: 50.397,77.638,93.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.777 | Acc: 51.128,77.672,93.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.774 | Acc: 51.245,77.638,93.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.772 | Acc: 51.304,77.621,93.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.781 | Acc: 51.164,77.482,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.797 | Acc: 51.077,77.329,92.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.801 | Acc: 50.885,77.370,92.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.810 | Acc: 50.925,77.149,92.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.818 | Acc: 50.951,76.962,92.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.821 | Acc: 50.989,76.825,92.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.829 | Acc: 50.856,76.751,92.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.838 | Acc: 50.826,76.674,92.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.845 | Acc: 50.688,76.612,92.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.850 | Acc: 50.608,76.577,92.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.859 | Acc: 50.527,76.420,92.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.866 | Acc: 50.420,76.350,92.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.879 | Acc: 50.385,76.210,92.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.037 | Acc: 43.750,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.439 | Acc: 40.365,59.152,65.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.368 | Acc: 40.091,58.594,66.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.346 | Acc: 40.254,58.568,65.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 2.506 | Acc: 52.344,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.757 | Acc: 50.372,79.167,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 50.705,78.487,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.760 | Acc: 51.025,78.304,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.754 | Acc: 51.215,78.385,92.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 50.828,78.133,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.748 | Acc: 50.846,78.215,93.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.758 | Acc: 50.748,78.036,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.771 | Acc: 50.592,77.824,93.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.782 | Acc: 50.622,77.624,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.790 | Acc: 50.571,77.526,93.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.802 | Acc: 50.534,77.358,92.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.807 | Acc: 50.642,77.282,92.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.813 | Acc: 50.611,77.137,92.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.826 | Acc: 50.589,77.010,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.836 | Acc: 50.555,76.794,92.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.846 | Acc: 50.496,76.626,92.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 50.449,76.530,92.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.864 | Acc: 50.409,76.443,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.873 | Acc: 50.318,76.341,92.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.576 | Acc: 40.625,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.583 | Acc: 38.356,58.259,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.631 | Acc: 37.557,57.832,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.633 | Acc: 37.423,57.864,66.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 2.578 | Acc: 53.906,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.774 | Acc: 49.926,76.972,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.804 | Acc: 50.076,76.753,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.777 | Acc: 50.295,77.536,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.777 | Acc: 50.559,77.623,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.807 | Acc: 50.394,77.150,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.804 | Acc: 50.646,77.131,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.820 | Acc: 50.460,76.795,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.827 | Acc: 50.442,76.791,92.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.834 | Acc: 50.263,76.757,92.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.836 | Acc: 50.299,76.632,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.856 | Acc: 50.191,76.471,91.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.875 | Acc: 49.958,76.225,91.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.884 | Acc: 49.931,76.090,91.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 49.850,76.020,91.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.895 | Acc: 49.992,75.953,91.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.898 | Acc: 50.056,75.937,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.896 | Acc: 50.176,75.965,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.904 | Acc: 50.082,75.922,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.907 | Acc: 50.137,75.902,91.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.040 | Acc: 40.625,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.148 | Acc: 42.262,60.714,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.161 | Acc: 41.044,60.823,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.141 | Acc: 40.420,60.861,66.790,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.757 | Acc: 49.219,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.912 | Acc: 49.926,76.600,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.865 | Acc: 49.581,76.467,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.833 | Acc: 50.499,76.703,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.825 | Acc: 50.733,76.688,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.820 | Acc: 50.750,76.508,92.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.799 | Acc: 51.136,76.879,92.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.807 | Acc: 50.920,76.784,92.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.829 | Acc: 50.898,76.490,92.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.845 | Acc: 50.738,76.282,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.850 | Acc: 50.746,76.150,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.853 | Acc: 50.739,76.064,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.853 | Acc: 50.655,76.138,92.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.865 | Acc: 50.521,76.096,91.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.865 | Acc: 50.514,76.179,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.875 | Acc: 50.511,76.010,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.884 | Acc: 50.428,75.910,91.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.888 | Acc: 50.396,75.955,91.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.891 | Acc: 50.474,75.924,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.898 | Acc: 50.457,75.859,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.817 | Acc: 45.312,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.078 | Acc: 44.085,59.896,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.085 | Acc: 44.017,60.080,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.067 | Acc: 43.622,60.400,67.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 2.698 | Acc: 58.594,73.438,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.778 | Acc: 51.972,76.860,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.759 | Acc: 51.372,77.553,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.755 | Acc: 51.255,77.677,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.768 | Acc: 51.244,77.585,93.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.789 | Acc: 51.207,77.336,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.822 | Acc: 50.600,76.814,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.831 | Acc: 50.560,76.817,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.829 | Acc: 50.645,76.868,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.835 | Acc: 50.704,76.895,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.830 | Acc: 50.855,76.838,92.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.832 | Acc: 50.887,76.757,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.846 | Acc: 50.723,76.605,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.850 | Acc: 50.721,76.554,92.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.854 | Acc: 50.731,76.507,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.860 | Acc: 50.662,76.409,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.875 | Acc: 50.574,76.195,91.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.889 | Acc: 50.483,76.026,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.897 | Acc: 50.422,75.937,91.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.906 | Acc: 50.431,75.851,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.077 | Acc: 46.094,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.071 | Acc: 42.113,60.640,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.044 | Acc: 42.588,60.823,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.071 | Acc: 42.213,60.899,67.546,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 3.205 | Acc: 43.750,71.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.804 | Acc: 51.488,76.749,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.749 | Acc: 51.410,77.477,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.749 | Acc: 51.165,77.664,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.757 | Acc: 51.003,77.498,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.771 | Acc: 50.557,77.328,93.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.789 | Acc: 50.387,77.092,93.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.796 | Acc: 50.465,77.133,92.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.800 | Acc: 50.437,76.994,92.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.802 | Acc: 50.578,76.882,93.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.813 | Acc: 50.482,76.734,92.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.818 | Acc: 50.435,76.821,92.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.815 | Acc: 50.538,76.890,92.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.821 | Acc: 50.488,76.904,92.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.823 | Acc: 50.489,76.879,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.832 | Acc: 50.594,76.672,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.848 | Acc: 50.509,76.533,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 50.518,76.420,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.855 | Acc: 50.567,76.405,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.857 | Acc: 50.566,76.378,92.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.178 | Acc: 47.656,62.500,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.053 | Acc: 43.266,61.272,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.024 | Acc: 42.778,61.147,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.999 | Acc: 42.495,61.130,67.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 2.901 | Acc: 49.219,75.000,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.655 | Acc: 51.228,79.204,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.718 | Acc: 51.143,79.097,94.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.723 | Acc: 51.511,78.650,93.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.755 | Acc: 50.993,78.019,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 51.013,78.024,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.755 | Acc: 51.330,78.170,93.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.775 | Acc: 51.363,77.815,92.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.786 | Acc: 51.242,77.518,92.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.792 | Acc: 51.282,77.460,92.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.819 | Acc: 51.014,77.130,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.830 | Acc: 50.909,77.001,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.839 | Acc: 50.879,76.909,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.854 | Acc: 50.650,76.736,92.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.861 | Acc: 50.712,76.696,91.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.870 | Acc: 50.636,76.537,91.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.873 | Acc: 50.623,76.409,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.880 | Acc: 50.614,76.343,91.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.886 | Acc: 50.645,76.266,91.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.889 | Acc: 50.650,76.292,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.132 | Acc: 44.531,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.466 | Acc: 38.542,59.859,64.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.412 | Acc: 38.415,59.546,64.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.360 | Acc: 38.204,59.759,65.177,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 2.958 | Acc: 44.531,75.000,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.821 | Acc: 49.330,77.530,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.790 | Acc: 50.191,77.248,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.786 | Acc: 50.115,77.907,93.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.784 | Acc: 50.116,78.000,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.797 | Acc: 50.108,77.614,93.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.821 | Acc: 50.000,77.286,93.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.828 | Acc: 50.144,77.105,92.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.835 | Acc: 50.199,76.786,92.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.848 | Acc: 50.121,76.649,92.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.848 | Acc: 50.249,76.524,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.849 | Acc: 50.247,76.460,92.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.850 | Acc: 50.295,76.456,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.850 | Acc: 50.524,76.542,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.849 | Acc: 50.553,76.560,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.857 | Acc: 50.483,76.433,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.873 | Acc: 50.380,76.268,91.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.884 | Acc: 50.394,76.148,91.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.882 | Acc: 50.532,76.147,91.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.886 | Acc: 50.615,76.066,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.960 | Acc: 41.406,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.892 | Acc: 44.680,63.504,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.930 | Acc: 44.226,62.157,67.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.940 | Acc: 43.750,61.424,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 2.822 | Acc: 53.906,74.219,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.746 | Acc: 51.786,78.311,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.718 | Acc: 51.734,78.296,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.723 | Acc: 51.588,78.394,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.747 | Acc: 51.264,77.913,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.757 | Acc: 51.160,77.769,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.760 | Acc: 51.149,77.544,92.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.779 | Acc: 51.042,77.366,92.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.777 | Acc: 51.140,77.349,92.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.776 | Acc: 51.027,77.357,92.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.774 | Acc: 51.143,77.402,92.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 51.121,77.174,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.803 | Acc: 50.973,76.987,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.815 | Acc: 50.847,76.898,92.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.832 | Acc: 50.726,76.665,92.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.848 | Acc: 50.607,76.474,91.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.860 | Acc: 50.492,76.429,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.869 | Acc: 50.373,76.329,91.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.875 | Acc: 50.355,76.234,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.879 | Acc: 50.363,76.179,91.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.929 | Acc: 42.188,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.156 | Acc: 39.732,60.826,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.150 | Acc: 40.758,60.861,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.123 | Acc: 40.830,60.899,68.033,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 2.845 | Acc: 51.562,71.875,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.732 | Acc: 50.298,77.418,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.756 | Acc: 50.591,77.458,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.707 | Acc: 51.101,78.163,93.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.709 | Acc: 51.466,77.951,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.713 | Acc: 51.454,77.963,93.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.729 | Acc: 51.375,77.802,93.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.741 | Acc: 51.247,77.621,93.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.756 | Acc: 51.116,77.455,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.777 | Acc: 50.941,77.076,92.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.794 | Acc: 50.863,76.943,92.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.802 | Acc: 50.838,76.912,92.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.810 | Acc: 50.849,76.880,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.813 | Acc: 50.856,76.841,92.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.824 | Acc: 50.820,76.713,92.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.830 | Acc: 50.794,76.643,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 50.672,76.480,92.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 50.717,76.457,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.855 | Acc: 50.656,76.324,91.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.863 | Acc: 50.584,76.243,91.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.132 | Acc: 38.281,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.272 | Acc: 39.583,61.198,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.313 | Acc: 39.367,60.137,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.345 | Acc: 39.178,59.862,67.034,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 2.859 | Acc: 44.531,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.761 | Acc: 50.707,77.567,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 51.010,78.125,92.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.742 | Acc: 50.602,78.496,93.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.743 | Acc: 50.637,78.356,93.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.757 | Acc: 50.774,77.847,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.756 | Acc: 50.968,77.621,93.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.764 | Acc: 50.831,77.532,93.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.771 | Acc: 50.903,77.455,92.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.788 | Acc: 50.786,77.326,92.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.791 | Acc: 50.832,77.297,92.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.796 | Acc: 50.898,77.231,92.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.801 | Acc: 51.005,77.101,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.807 | Acc: 50.964,77.014,92.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 50.959,76.838,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.832 | Acc: 50.771,76.643,92.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.837 | Acc: 50.740,76.570,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.847 | Acc: 50.575,76.434,92.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.853 | Acc: 50.576,76.363,92.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.861 | Acc: 50.550,76.325,91.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.887 | Acc: 44.531,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.335 | Acc: 40.439,60.268,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.333 | Acc: 39.729,60.271,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.330 | Acc: 39.024,60.207,65.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 3.006 | Acc: 45.312,71.875,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.760 | Acc: 51.004,77.530,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.745 | Acc: 51.372,77.134,92.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.737 | Acc: 51.767,77.152,93.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.747 | Acc: 51.418,77.267,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.757 | Acc: 51.400,77.189,93.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.751 | Acc: 51.285,77.318,93.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.765 | Acc: 51.341,77.233,93.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.766 | Acc: 51.373,77.252,93.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.785 | Acc: 51.183,76.977,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 51.038,76.986,93.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.796 | Acc: 51.096,76.920,93.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.799 | Acc: 51.144,76.857,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.805 | Acc: 51.075,76.799,92.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.813 | Acc: 51.084,76.690,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.823 | Acc: 51.056,76.633,92.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.828 | Acc: 50.952,76.562,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.839 | Acc: 50.944,76.409,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.843 | Acc: 50.831,76.407,92.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.853 | Acc: 50.753,76.325,92.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.858 | Acc: 42.969,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.146 | Acc: 41.518,59.784,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.146 | Acc: 41.883,59.775,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.159 | Acc: 41.893,59.285,66.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 2.900 | Acc: 49.219,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.788 | Acc: 50.744,77.009,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.756 | Acc: 51.353,77.229,92.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.731 | Acc: 51.562,77.280,93.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.749 | Acc: 51.177,77.103,93.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.755 | Acc: 50.967,77.336,93.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.760 | Acc: 51.175,77.421,93.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.777 | Acc: 51.202,77.261,92.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.773 | Acc: 51.354,77.305,92.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.779 | Acc: 51.377,77.244,92.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.792 | Acc: 51.267,77.146,92.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.804 | Acc: 51.103,77.011,92.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.815 | Acc: 51.008,76.848,92.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.821 | Acc: 50.943,76.757,92.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.829 | Acc: 50.854,76.657,92.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 51.020,76.601,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.835 | Acc: 51.005,76.455,92.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.849 | Acc: 50.896,76.276,92.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.860 | Acc: 50.801,76.177,91.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.868 | Acc: 50.740,76.095,91.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.610 | Acc: 45.312,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.169 | Acc: 42.708,60.528,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.179 | Acc: 42.092,60.061,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.151 | Acc: 41.739,60.592,67.149,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 2.520 | Acc: 54.688,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.690 | Acc: 52.195,79.501,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.716 | Acc: 51.753,78.716,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 51.844,78.650,93.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.737 | Acc: 51.514,78.086,93.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.730 | Acc: 51.454,78.125,93.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.731 | Acc: 51.362,78.177,93.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.738 | Acc: 51.369,78.119,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.755 | Acc: 51.038,77.834,92.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.769 | Acc: 50.997,77.702,92.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.785 | Acc: 50.878,77.480,92.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.806 | Acc: 50.714,77.255,92.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.813 | Acc: 50.707,77.101,92.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.821 | Acc: 50.673,76.880,92.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.828 | Acc: 50.637,76.757,92.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.836 | Acc: 50.644,76.594,92.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.844 | Acc: 50.669,76.480,92.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.846 | Acc: 50.669,76.528,92.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.853 | Acc: 50.632,76.398,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.863 | Acc: 50.558,76.310,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.274 | Acc: 45.312,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.110 | Acc: 42.001,61.682,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.131 | Acc: 42.702,60.957,65.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.107 | Acc: 42.226,61.168,66.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 3.180 | Acc: 46.094,72.656,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.716 | Acc: 52.604,77.790,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 51.620,77.973,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.752 | Acc: 51.703,77.664,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.776 | Acc: 51.341,77.411,92.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.739 | Acc: 51.949,77.831,92.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.769 | Acc: 51.259,77.699,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.776 | Acc: 51.247,77.748,92.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.771 | Acc: 51.305,77.747,92.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.782 | Acc: 51.191,77.646,92.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.799 | Acc: 51.092,77.394,92.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.804 | Acc: 51.036,77.259,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.815 | Acc: 50.940,77.159,92.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.817 | Acc: 50.919,77.089,92.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.824 | Acc: 50.840,76.968,92.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.831 | Acc: 50.766,76.812,92.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.835 | Acc: 50.798,76.726,91.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.843 | Acc: 50.738,76.604,91.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.849 | Acc: 50.664,76.558,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.852 | Acc: 50.658,76.456,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.367 | Acc: 45.312,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.132 | Acc: 42.374,60.268,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.186 | Acc: 41.997,60.232,66.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.170 | Acc: 42.277,60.387,66.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 2.452 | Acc: 55.469,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.788 | Acc: 50.074,77.604,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 50.572,78.106,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.740 | Acc: 50.871,78.125,93.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.730 | Acc: 51.254,78.482,92.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.733 | Acc: 51.439,78.210,92.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.735 | Acc: 51.324,78.028,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.749 | Acc: 50.925,77.937,92.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.762 | Acc: 50.728,77.761,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.780 | Acc: 50.552,77.551,92.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.788 | Acc: 50.540,77.429,92.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.793 | Acc: 50.640,77.241,92.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.805 | Acc: 50.668,77.068,92.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 50.799,76.964,92.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.816 | Acc: 50.795,76.910,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.827 | Acc: 50.638,76.819,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.830 | Acc: 50.718,76.823,92.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.832 | Acc: 50.848,76.771,92.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.832 | Acc: 50.965,76.727,92.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.846 | Acc: 50.830,76.536,92.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.775 | Acc: 41.406,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.984 | Acc: 42.560,63.542,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.021 | Acc: 42.054,61.890,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.060 | Acc: 41.778,61.270,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 2.234 | Acc: 61.719,87.500,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.660 | Acc: 52.158,78.943,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.654 | Acc: 52.534,78.697,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.703 | Acc: 51.895,78.023,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.722 | Acc: 51.678,77.768,93.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.712 | Acc: 51.918,77.978,93.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.724 | Acc: 51.530,78.086,93.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.743 | Acc: 51.357,77.854,93.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.745 | Acc: 51.407,77.931,93.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.748 | Acc: 51.463,77.810,93.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.758 | Acc: 51.434,77.659,92.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.777 | Acc: 51.273,77.383,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.783 | Acc: 51.284,77.263,92.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.792 | Acc: 51.248,77.173,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.808 | Acc: 51.148,77.007,92.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.824 | Acc: 50.979,76.786,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.833 | Acc: 50.969,76.616,92.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.836 | Acc: 50.958,76.505,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.843 | Acc: 50.881,76.376,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.850 | Acc: 50.828,76.290,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.242 | Acc: 40.625,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.513 | Acc: 40.476,59.189,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.506 | Acc: 40.339,58.346,64.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.486 | Acc: 39.895,58.286,64.575,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 3.024 | Acc: 50.781,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.799 | Acc: 51.153,77.753,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.746 | Acc: 52.039,78.430,92.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.771 | Acc: 51.614,77.946,92.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.787 | Acc: 51.582,77.758,92.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.800 | Acc: 51.230,77.599,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.792 | Acc: 51.349,77.647,92.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 51.202,77.571,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.802 | Acc: 51.000,77.480,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.811 | Acc: 50.881,77.283,92.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.807 | Acc: 50.882,77.320,92.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 50.898,77.216,92.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.821 | Acc: 50.846,77.007,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.821 | Acc: 50.838,77.080,92.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.826 | Acc: 50.728,77.002,92.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.838 | Acc: 50.618,76.848,92.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.844 | Acc: 50.589,76.774,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 50.545,76.654,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.863 | Acc: 50.517,76.519,91.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.863 | Acc: 50.586,76.548,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.907 | Acc: 45.312,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.075 | Acc: 44.048,61.570,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.125 | Acc: 43.883,60.709,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.088 | Acc: 43.609,60.387,66.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 2.643 | Acc: 53.906,82.812,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.725 | Acc: 53.013,78.571,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 52.496,78.201,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 52.216,78.048,93.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.759 | Acc: 51.804,77.749,93.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.786 | Acc: 51.330,77.382,92.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.785 | Acc: 51.117,77.337,92.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.788 | Acc: 51.402,77.244,92.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.795 | Acc: 51.237,77.106,92.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.802 | Acc: 51.174,76.990,92.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 51.127,76.870,92.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.804 | Acc: 51.188,76.792,92.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.812 | Acc: 51.125,76.657,92.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 51.102,76.673,92.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.811 | Acc: 51.159,76.699,92.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.814 | Acc: 51.098,76.661,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.815 | Acc: 51.173,76.667,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.821 | Acc: 51.136,76.654,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.824 | Acc: 51.115,76.627,92.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 51.077,76.638,92.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.865 | Acc: 42.188,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.288 | Acc: 40.104,60.491,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.249 | Acc: 40.072,60.633,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.198 | Acc: 40.177,60.464,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 2.489 | Acc: 56.250,81.250,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.732 | Acc: 50.967,78.125,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.690 | Acc: 50.972,79.402,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.724 | Acc: 50.704,78.573,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.742 | Acc: 50.106,78.376,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.735 | Acc: 50.309,78.249,93.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.758 | Acc: 50.271,77.951,93.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.790 | Acc: 50.127,77.521,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.799 | Acc: 50.087,77.484,92.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.796 | Acc: 50.211,77.339,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.798 | Acc: 50.253,77.235,92.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 50.382,77.043,92.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 50.480,76.955,92.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.796 | Acc: 50.700,77.062,92.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.803 | Acc: 50.639,76.924,92.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.806 | Acc: 50.659,76.882,92.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.815 | Acc: 50.699,76.806,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.822 | Acc: 50.630,76.723,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.828 | Acc: 50.660,76.682,92.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.841 | Acc: 50.568,76.530,92.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.888 | Acc: 43.750,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.106 | Acc: 43.192,60.789,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.132 | Acc: 43.350,60.137,66.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.138 | Acc: 43.046,60.233,66.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.385 | Acc: 55.469,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.766 | Acc: 51.637,78.609,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.792 | Acc: 50.896,78.582,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.752 | Acc: 51.422,78.420,93.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.737 | Acc: 51.235,78.520,93.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.751 | Acc: 51.060,78.636,93.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.764 | Acc: 51.104,78.480,93.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.768 | Acc: 51.103,78.308,93.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.766 | Acc: 51.102,78.144,92.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.783 | Acc: 51.088,77.901,92.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.792 | Acc: 51.119,77.787,92.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.805 | Acc: 51.124,77.556,92.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.809 | Acc: 51.011,77.328,92.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 50.934,77.308,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.820 | Acc: 50.842,77.157,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.828 | Acc: 50.836,77.053,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.839 | Acc: 50.713,76.979,92.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.843 | Acc: 50.774,76.920,91.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.845 | Acc: 50.708,76.941,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.853 | Acc: 50.662,76.835,91.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.260 | Acc: 40.625,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.492 | Acc: 38.765,57.775,65.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.525 | Acc: 38.453,58.117,65.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.509 | Acc: 38.256,58.145,65.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 3.106 | Acc: 41.406,72.656,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.806 | Acc: 50.149,76.860,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.800 | Acc: 50.800,77.458,92.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.780 | Acc: 50.768,77.843,93.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 50.704,77.836,93.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 50.781,77.986,93.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.769 | Acc: 50.814,77.860,93.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.769 | Acc: 50.870,77.671,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.774 | Acc: 50.762,77.528,92.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.779 | Acc: 50.660,77.421,92.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.782 | Acc: 50.715,77.453,92.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.788 | Acc: 50.682,77.372,92.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.794 | Acc: 50.661,77.415,92.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.798 | Acc: 50.706,77.356,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.806 | Acc: 50.703,77.283,92.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.809 | Acc: 50.745,77.201,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.812 | Acc: 50.793,77.227,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.822 | Acc: 50.708,77.115,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.832 | Acc: 50.718,76.917,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 50.658,76.759,91.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.215 | Acc: 46.875,59.375,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.077 | Acc: 43.229,59.375,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.058 | Acc: 43.236,59.604,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.059 | Acc: 42.277,59.541,65.868,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 2.794 | Acc: 51.562,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.775 | Acc: 50.000,77.009,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.716 | Acc: 51.124,78.087,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.722 | Acc: 51.447,78.163,93.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.730 | Acc: 51.312,78.009,93.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.735 | Acc: 51.230,77.885,93.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.732 | Acc: 51.175,77.964,93.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.734 | Acc: 51.213,77.981,93.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.751 | Acc: 51.320,77.567,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.754 | Acc: 51.308,77.374,93.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.763 | Acc: 51.388,77.231,92.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.780 | Acc: 51.280,77.121,92.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 51.216,76.913,92.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.802 | Acc: 51.173,76.826,92.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.809 | Acc: 51.109,76.749,92.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.815 | Acc: 51.197,76.651,92.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.825 | Acc: 51.190,76.545,92.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.830 | Acc: 51.178,76.471,92.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.841 | Acc: 51.082,76.428,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.854 | Acc: 50.972,76.302,91.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.272 | Acc: 48.438,72.656,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.039 | Acc: 43.192,60.714,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.077 | Acc: 43.083,60.271,65.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.064 | Acc: 43.417,60.387,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 2.500 | Acc: 58.594,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.813 | Acc: 51.414,77.121,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.775 | Acc: 51.334,78.239,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.782 | Acc: 50.858,77.830,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 51.032,77.614,92.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.757 | Acc: 51.114,77.847,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.764 | Acc: 51.143,77.873,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.781 | Acc: 51.247,77.477,92.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.778 | Acc: 51.344,77.426,92.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.784 | Acc: 51.342,77.314,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.782 | Acc: 51.430,77.293,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.778 | Acc: 51.506,77.259,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.789 | Acc: 51.417,77.097,92.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.789 | Acc: 51.428,77.116,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.801 | Acc: 51.318,76.949,92.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.803 | Acc: 51.350,76.905,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.813 | Acc: 51.339,76.801,92.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.823 | Acc: 51.272,76.689,91.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.838 | Acc: 51.112,76.506,91.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.850 | Acc: 51.038,76.353,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.993 | Acc: 40.625,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.314 | Acc: 41.034,59.673,65.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.310 | Acc: 40.796,59.566,65.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.270 | Acc: 40.318,59.977,66.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 2.981 | Acc: 53.906,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.715 | Acc: 51.637,78.162,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 51.353,78.068,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 51.793,78.624,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.725 | Acc: 51.900,78.212,93.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.724 | Acc: 51.887,78.063,93.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.726 | Acc: 51.963,78.022,93.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.725 | Acc: 51.906,77.992,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.734 | Acc: 51.776,78.033,93.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.730 | Acc: 51.925,78.138,93.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.739 | Acc: 51.800,78.016,93.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.754 | Acc: 51.686,77.782,93.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.763 | Acc: 51.647,77.606,92.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.776 | Acc: 51.503,77.425,92.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.785 | Acc: 51.332,77.324,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.792 | Acc: 51.290,77.227,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.799 | Acc: 51.095,77.142,92.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.806 | Acc: 51.017,77.108,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.811 | Acc: 51.086,77.049,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.818 | Acc: 51.111,77.005,92.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.610 | Acc: 46.875,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.884 | Acc: 43.452,63.839,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.910 | Acc: 42.912,63.053,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.896 | Acc: 43.122,62.999,68.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 2.982 | Acc: 52.344,75.781,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.706 | Acc: 51.042,77.976,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.704 | Acc: 51.372,78.697,93.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.719 | Acc: 51.217,78.548,93.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.711 | Acc: 51.186,78.627,93.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.692 | Acc: 51.470,78.782,93.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.694 | Acc: 51.291,78.738,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.704 | Acc: 51.180,78.463,93.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.702 | Acc: 51.276,78.377,93.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.713 | Acc: 51.304,78.116,93.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.724 | Acc: 51.228,78.036,93.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.730 | Acc: 51.244,77.899,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.741 | Acc: 51.063,77.733,93.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.759 | Acc: 50.955,77.604,93.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.762 | Acc: 51.120,77.622,93.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.776 | Acc: 51.103,77.515,92.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.786 | Acc: 51.017,77.358,92.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.801 | Acc: 50.907,77.195,92.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.812 | Acc: 50.931,77.065,92.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.821 | Acc: 50.968,76.975,92.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.910 | Acc: 42.188,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.197 | Acc: 40.997,61.086,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.211 | Acc: 41.178,60.918,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.213 | Acc: 41.278,61.014,66.662,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.866 | Acc: 49.219,78.906,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.796 | Acc: 50.707,78.051,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.721 | Acc: 51.848,78.468,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.679 | Acc: 52.651,78.291,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.702 | Acc: 52.392,77.826,93.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.729 | Acc: 51.942,77.630,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.737 | Acc: 51.582,77.589,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.756 | Acc: 51.518,77.377,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.764 | Acc: 51.470,77.407,92.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.761 | Acc: 51.463,77.469,92.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.766 | Acc: 51.442,77.460,92.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.771 | Acc: 51.382,77.429,92.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.783 | Acc: 51.290,77.328,92.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.793 | Acc: 51.257,77.134,92.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.806 | Acc: 51.159,76.963,92.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.816 | Acc: 51.184,76.858,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.816 | Acc: 51.214,76.893,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.822 | Acc: 51.187,76.844,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.826 | Acc: 51.047,76.846,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.835 | Acc: 50.953,76.766,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.728 | Acc: 42.969,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.250 | Acc: 42.113,60.677,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.293 | Acc: 41.997,60.271,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.305 | Acc: 41.752,60.297,66.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 2.315 | Acc: 58.594,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.645 | Acc: 52.493,79.278,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 53.468,80.793,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.469 | Acc: 53.970,81.839,95.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.444 | Acc: 54.012,82.292,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.416 | Acc: 54.115,82.751,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.393 | Acc: 54.139,83.129,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.373 | Acc: 54.350,83.466,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.350 | Acc: 54.663,83.725,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.336 | Acc: 54.666,83.741,96.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.319 | Acc: 54.862,83.944,96.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.301 | Acc: 55.189,84.166,96.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.284 | Acc: 55.397,84.414,96.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.268 | Acc: 55.541,84.599,96.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.258 | Acc: 55.744,84.656,97.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.252 | Acc: 55.837,84.725,97.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.250 | Acc: 55.749,84.706,97.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.238 | Acc: 55.886,84.808,97.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.232 | Acc: 55.895,84.907,97.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.225 | Acc: 55.916,84.998,97.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.826 | Acc: 49.219,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.071 | Acc: 51.004,69.085,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.086 | Acc: 51.220,68.921,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.064 | Acc: 50.704,69.070,74.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 2.192 | Acc: 56.250,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.091 | Acc: 56.324,87.798,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.036 | Acc: 57.698,87.881,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.033 | Acc: 58.222,87.833,98.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.022 | Acc: 57.957,88.030,98.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.019 | Acc: 57.983,88.088,98.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.029 | Acc: 58.103,87.732,98.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.027 | Acc: 58.095,87.616,98.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.033 | Acc: 57.779,87.621,98.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.034 | Acc: 57.787,87.539,98.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.028 | Acc: 57.809,87.679,98.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.026 | Acc: 57.777,87.776,98.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.026 | Acc: 57.709,87.746,98.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.027 | Acc: 57.762,87.716,98.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.025 | Acc: 57.707,87.728,98.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.029 | Acc: 57.737,87.682,98.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.030 | Acc: 57.676,87.663,98.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.026 | Acc: 57.693,87.725,98.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.025 | Acc: 57.659,87.779,98.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.027 | Acc: 57.609,87.750,98.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.893 | Acc: 52.344,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.025 | Acc: 50.670,70.201,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.058 | Acc: 51.239,69.455,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.022 | Acc: 50.858,69.749,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.796 | Acc: 57.812,94.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.985 | Acc: 56.771,88.393,99.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.961 | Acc: 57.470,88.891,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.948 | Acc: 57.697,89.127,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.956 | Acc: 58.073,88.860,99.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.957 | Acc: 57.929,88.830,99.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.969 | Acc: 57.522,88.804,99.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.971 | Acc: 57.696,88.725,99.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.974 | Acc: 57.633,88.771,99.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.973 | Acc: 57.631,88.851,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.970 | Acc: 57.700,88.860,99.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.970 | Acc: 57.728,88.801,99.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.962 | Acc: 57.981,88.868,99.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.967 | Acc: 57.836,88.778,99.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.967 | Acc: 57.885,88.723,99.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.968 | Acc: 57.911,88.613,99.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.966 | Acc: 57.898,88.671,99.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.965 | Acc: 57.945,88.723,99.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.960 | Acc: 58.009,88.727,99.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.961 | Acc: 57.985,88.710,99.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.861 | Acc: 53.125,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.032 | Acc: 51.228,69.754,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.055 | Acc: 51.524,69.207,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.027 | Acc: 51.063,69.595,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.988 | Acc: 55.469,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.960 | Acc: 57.924,88.616,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.928 | Acc: 57.965,89.291,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.920 | Acc: 58.133,89.344,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.926 | Acc: 57.803,89.439,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.927 | Acc: 57.727,89.542,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.937 | Acc: 57.503,89.450,99.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.942 | Acc: 57.580,89.323,99.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.938 | Acc: 57.618,89.329,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.939 | Acc: 57.696,89.239,99.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.929 | Acc: 57.867,89.342,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.926 | Acc: 57.915,89.299,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.926 | Acc: 57.910,89.322,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.927 | Acc: 57.869,89.326,99.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.923 | Acc: 57.935,89.338,99.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.924 | Acc: 57.916,89.335,99.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.923 | Acc: 57.973,89.260,99.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.918 | Acc: 58.019,89.367,99.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.920 | Acc: 57.979,89.348,99.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.920 | Acc: 58.013,89.393,99.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.909 | Acc: 52.344,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.016 | Acc: 51.376,70.275,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.049 | Acc: 51.277,69.303,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.024 | Acc: 50.845,69.659,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.927 | Acc: 54.688,89.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.873 | Acc: 58.222,89.769,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.860 | Acc: 58.613,90.187,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.844 | Acc: 58.940,90.279,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.848 | Acc: 58.825,90.104,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.852 | Acc: 58.795,90.130,99.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.858 | Acc: 58.975,89.973,99.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.860 | Acc: 58.826,90.032,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.863 | Acc: 58.734,90.154,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.861 | Acc: 58.818,90.133,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.862 | Acc: 58.765,89.988,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.865 | Acc: 58.753,89.936,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.867 | Acc: 58.743,89.918,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.874 | Acc: 58.588,89.847,99.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.875 | Acc: 58.660,89.796,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.881 | Acc: 58.563,89.693,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.886 | Acc: 58.419,89.693,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.883 | Acc: 58.495,89.738,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.883 | Acc: 58.481,89.774,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.885 | Acc: 58.376,89.799,99.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.842 | Acc: 53.125,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.022 | Acc: 51.935,69.754,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.048 | Acc: 51.982,69.131,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.017 | Acc: 51.575,69.403,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.991 | Acc: 55.469,89.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.842 | Acc: 58.296,91.183,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.832 | Acc: 59.013,90.854,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.828 | Acc: 59.247,90.971,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.835 | Acc: 59.066,90.943,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.837 | Acc: 59.042,90.950,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.840 | Acc: 58.897,90.806,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.838 | Acc: 59.137,90.752,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.834 | Acc: 59.186,90.756,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.838 | Acc: 59.086,90.647,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.843 | Acc: 59.021,90.559,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.844 | Acc: 58.993,90.505,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.851 | Acc: 58.954,90.450,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.853 | Acc: 58.926,90.418,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.858 | Acc: 58.913,90.405,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.859 | Acc: 58.853,90.428,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.854 | Acc: 58.939,90.486,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.853 | Acc: 58.914,90.499,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.853 | Acc: 58.899,90.465,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.857 | Acc: 58.836,90.410,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.892 | Acc: 52.344,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.038 | Acc: 51.042,69.494,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.063 | Acc: 51.505,69.226,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.042 | Acc: 51.050,69.493,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.842 | Acc: 60.938,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.820 | Acc: 59.859,90.551,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.826 | Acc: 59.013,90.511,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.823 | Acc: 58.863,90.651,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.832 | Acc: 58.912,90.596,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.833 | Acc: 58.810,90.610,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.838 | Acc: 58.794,90.515,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.837 | Acc: 58.638,90.559,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.838 | Acc: 58.628,90.475,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.833 | Acc: 58.585,90.625,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.827 | Acc: 58.679,90.726,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.827 | Acc: 58.693,90.724,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.823 | Acc: 58.714,90.764,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.824 | Acc: 58.767,90.775,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.827 | Acc: 58.705,90.783,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.825 | Acc: 58.765,90.814,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.828 | Acc: 58.781,90.778,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.832 | Acc: 58.740,90.737,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.830 | Acc: 58.773,90.779,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.836 | Acc: 58.700,90.756,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.880 | Acc: 52.344,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.054 | Acc: 51.265,69.196,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.078 | Acc: 51.315,68.960,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.050 | Acc: 50.845,69.339,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.709 | Acc: 63.281,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.719 | Acc: 60.938,92.299,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.756 | Acc: 60.118,92.035,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.779 | Acc: 59.785,91.752,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.785 | Acc: 59.713,91.406,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.805 | Acc: 59.383,91.128,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.809 | Acc: 59.097,91.174,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.818 | Acc: 58.937,91.024,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.821 | Acc: 58.914,90.984,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.825 | Acc: 58.758,90.897,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.819 | Acc: 58.889,90.959,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.822 | Acc: 58.778,90.982,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.822 | Acc: 58.756,90.965,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.818 | Acc: 58.821,91.002,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.819 | Acc: 58.863,90.920,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.819 | Acc: 58.877,90.861,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.826 | Acc: 58.767,90.759,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.825 | Acc: 58.795,90.751,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.824 | Acc: 58.806,90.722,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.824 | Acc: 58.842,90.676,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.957 | Acc: 53.906,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.033 | Acc: 51.376,70.164,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.090 | Acc: 51.639,69.379,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.063 | Acc: 51.114,69.851,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.683 | Acc: 63.281,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.794 | Acc: 59.747,90.811,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.795 | Acc: 59.280,91.330,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.795 | Acc: 59.209,91.291,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.799 | Acc: 59.240,91.291,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.800 | Acc: 59.104,91.275,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.785 | Acc: 59.478,91.361,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.801 | Acc: 59.309,91.190,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.805 | Acc: 59.234,91.130,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.805 | Acc: 59.207,91.152,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.803 | Acc: 59.142,91.192,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.806 | Acc: 59.120,91.162,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.805 | Acc: 59.142,91.114,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.804 | Acc: 59.103,91.191,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.807 | Acc: 59.066,91.112,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.807 | Acc: 59.004,91.160,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.806 | Acc: 59.022,91.182,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.806 | Acc: 58.947,91.177,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.803 | Acc: 58.970,91.175,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.805 | Acc: 58.928,91.172,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.929 | Acc: 53.125,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.028 | Acc: 51.897,69.754,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.069 | Acc: 52.191,69.188,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.032 | Acc: 51.627,69.621,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 2.025 | Acc: 53.906,87.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.767 | Acc: 59.375,91.592,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.784 | Acc: 59.089,91.578,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.786 | Acc: 58.876,91.445,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.783 | Acc: 59.221,91.358,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.773 | Acc: 59.390,91.553,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.771 | Acc: 59.498,91.477,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.779 | Acc: 59.325,91.434,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.787 | Acc: 59.152,91.421,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.789 | Acc: 59.129,91.359,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.786 | Acc: 59.223,91.360,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.787 | Acc: 59.283,91.392,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.791 | Acc: 59.287,91.361,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.788 | Acc: 59.330,91.361,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.786 | Acc: 59.414,91.442,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.789 | Acc: 59.313,91.440,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.792 | Acc: 59.280,91.414,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.789 | Acc: 59.343,91.425,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.791 | Acc: 59.301,91.315,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.791 | Acc: 59.244,91.308,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.983 | Acc: 52.344,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.064 | Acc: 52.344,69.271,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.103 | Acc: 51.925,68.579,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.066 | Acc: 51.165,69.147,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.967 | Acc: 55.469,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.742 | Acc: 59.970,92.188,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.781 | Acc: 58.822,91.749,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.760 | Acc: 59.119,91.995,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.753 | Acc: 59.558,92.072,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.750 | Acc: 59.329,92.203,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.745 | Acc: 59.388,92.181,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.747 | Acc: 59.419,92.165,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.742 | Acc: 59.574,92.071,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.743 | Acc: 59.591,91.967,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.745 | Acc: 59.612,91.950,99.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.748 | Acc: 59.658,91.901,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.752 | Acc: 59.553,91.902,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.753 | Acc: 59.435,91.858,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.755 | Acc: 59.531,91.812,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.758 | Acc: 59.442,91.751,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.759 | Acc: 59.460,91.725,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.758 | Acc: 59.588,91.700,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.759 | Acc: 59.585,91.688,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.763 | Acc: 59.510,91.607,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.951 | Acc: 53.125,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.065 | Acc: 51.525,69.122,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.104 | Acc: 52.020,69.055,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.066 | Acc: 51.447,69.557,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.903 | Acc: 57.812,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.728 | Acc: 60.007,91.220,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.754 | Acc: 60.118,91.178,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.761 | Acc: 59.247,91.586,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.768 | Acc: 59.346,91.590,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.745 | Acc: 59.855,91.994,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.751 | Acc: 59.582,91.962,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.750 | Acc: 59.547,91.927,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.755 | Acc: 59.424,91.862,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.757 | Acc: 59.435,91.829,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.758 | Acc: 59.359,91.775,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.762 | Acc: 59.290,91.756,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.761 | Acc: 59.310,91.773,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.760 | Acc: 59.366,91.786,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.761 | Acc: 59.253,91.823,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.760 | Acc: 59.315,91.827,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.761 | Acc: 59.341,91.830,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.762 | Acc: 59.368,91.789,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.762 | Acc: 59.364,91.796,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.760 | Acc: 59.422,91.788,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.965 | Acc: 52.344,68.750,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.065 | Acc: 51.451,69.494,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.108 | Acc: 51.696,69.131,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.077 | Acc: 51.332,69.390,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.551 | Acc: 61.719,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.714 | Acc: 60.417,92.448,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.689 | Acc: 61.433,92.664,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.684 | Acc: 60.886,92.559,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.711 | Acc: 60.503,92.448,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.712 | Acc: 60.048,92.389,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.717 | Acc: 60.079,92.426,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.722 | Acc: 60.084,92.442,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.728 | Acc: 59.841,92.382,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.732 | Acc: 59.833,92.334,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.735 | Acc: 59.760,92.273,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.733 | Acc: 59.884,92.202,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.728 | Acc: 59.887,92.226,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.732 | Acc: 59.827,92.164,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.733 | Acc: 59.773,92.126,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.733 | Acc: 59.814,92.102,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.738 | Acc: 59.662,92.056,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.740 | Acc: 59.625,92.018,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.741 | Acc: 59.578,91.969,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.748 | Acc: 59.502,91.866,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.947 | Acc: 55.469,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.074 | Acc: 51.711,68.899,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.112 | Acc: 51.982,69.245,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.082 | Acc: 51.306,69.403,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.397 | Acc: 71.875,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.736 | Acc: 59.338,91.332,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.716 | Acc: 60.099,92.207,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.720 | Acc: 59.541,92.520,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.732 | Acc: 59.587,92.467,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.719 | Acc: 59.793,92.559,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.720 | Acc: 59.517,92.459,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.723 | Acc: 59.552,92.476,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.728 | Acc: 59.433,92.352,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.731 | Acc: 59.340,92.347,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.724 | Acc: 59.340,92.421,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.727 | Acc: 59.294,92.364,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.727 | Acc: 59.385,92.379,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.727 | Acc: 59.465,92.304,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.730 | Acc: 59.506,92.274,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.733 | Acc: 59.453,92.232,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.734 | Acc: 59.392,92.192,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.736 | Acc: 59.398,92.208,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.736 | Acc: 59.362,92.192,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.738 | Acc: 59.367,92.134,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.977 | Acc: 53.906,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.106 | Acc: 52.083,69.345,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.128 | Acc: 52.420,69.169,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.087 | Acc: 51.652,69.608,75.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.527 | Acc: 61.719,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.751 | Acc: 59.263,92.411,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.743 | Acc: 59.394,92.550,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.726 | Acc: 59.529,92.520,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.727 | Acc: 59.375,92.429,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.726 | Acc: 59.715,92.334,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.727 | Acc: 59.595,92.317,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.732 | Acc: 59.591,92.232,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.728 | Acc: 59.598,92.319,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.728 | Acc: 59.565,92.295,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.725 | Acc: 59.663,92.359,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.726 | Acc: 59.675,92.347,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.726 | Acc: 59.680,92.343,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.725 | Acc: 59.629,92.310,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.722 | Acc: 59.622,92.385,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.723 | Acc: 59.567,92.382,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.722 | Acc: 59.665,92.353,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.723 | Acc: 59.693,92.279,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.721 | Acc: 59.680,92.309,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.723 | Acc: 59.609,92.284,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.975 | Acc: 52.344,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.076 | Acc: 52.121,69.754,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.118 | Acc: 52.134,69.207,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.088 | Acc: 51.550,69.506,75.307,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.686 | Acc: 60.938,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.642 | Acc: 61.979,93.304,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.660 | Acc: 61.395,92.912,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.668 | Acc: 61.219,93.020,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 60.667,92.843,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.680 | Acc: 60.613,92.961,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.682 | Acc: 60.466,92.949,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.681 | Acc: 60.395,92.991,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.689 | Acc: 60.355,92.896,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.697 | Acc: 60.104,92.852,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.697 | Acc: 60.075,92.868,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.704 | Acc: 59.969,92.771,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.703 | Acc: 59.946,92.742,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.704 | Acc: 59.923,92.681,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.705 | Acc: 59.964,92.646,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.708 | Acc: 59.876,92.647,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.711 | Acc: 59.854,92.599,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.713 | Acc: 59.801,92.566,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.716 | Acc: 59.803,92.506,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.719 | Acc: 59.773,92.475,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.021 | Acc: 53.906,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.125 | Acc: 51.414,68.824,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.140 | Acc: 51.353,68.617,75.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.099 | Acc: 50.807,69.224,75.282,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.692 | Acc: 57.031,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.652 | Acc: 61.086,93.490,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.656 | Acc: 60.690,93.407,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.673 | Acc: 60.643,93.046,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.677 | Acc: 60.513,93.113,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.675 | Acc: 60.365,93.108,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.678 | Acc: 60.402,93.098,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.675 | Acc: 60.361,93.002,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.681 | Acc: 60.151,92.920,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.683 | Acc: 60.040,92.869,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.687 | Acc: 59.962,92.825,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.691 | Acc: 59.948,92.735,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.700 | Acc: 59.783,92.671,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.699 | Acc: 59.833,92.672,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.702 | Acc: 59.792,92.646,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.698 | Acc: 59.834,92.701,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.698 | Acc: 59.828,92.684,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.699 | Acc: 59.881,92.621,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.703 | Acc: 59.752,92.592,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.704 | Acc: 59.744,92.567,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.072 | Acc: 54.688,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.122 | Acc: 52.269,68.824,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.145 | Acc: 51.867,68.483,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.105 | Acc: 51.562,68.955,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.528 | Acc: 58.594,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.686 | Acc: 60.454,92.485,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.662 | Acc: 60.995,92.854,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.672 | Acc: 61.078,92.853,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.684 | Acc: 60.745,92.824,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.670 | Acc: 60.767,92.992,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.674 | Acc: 60.460,92.982,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.675 | Acc: 60.472,92.996,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.677 | Acc: 60.297,93.076,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 60.277,93.176,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.676 | Acc: 60.203,93.132,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.679 | Acc: 60.142,93.114,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.674 | Acc: 60.322,93.141,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.680 | Acc: 60.171,93.082,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.682 | Acc: 60.059,93.066,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.688 | Acc: 59.946,93.049,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.689 | Acc: 59.896,93.039,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.688 | Acc: 59.948,93.008,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.688 | Acc: 59.951,92.980,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.691 | Acc: 59.951,92.946,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.074 | Acc: 53.125,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.077 | Acc: 52.083,69.122,76.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.121 | Acc: 52.344,68.712,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.103 | Acc: 51.742,68.981,75.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.765 | Acc: 62.500,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.633 | Acc: 60.863,93.155,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.667 | Acc: 60.042,93.197,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.675 | Acc: 59.964,93.110,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.673 | Acc: 60.320,93.056,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.665 | Acc: 60.613,93.216,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.667 | Acc: 60.331,93.066,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.667 | Acc: 60.300,93.091,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.671 | Acc: 60.064,93.139,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.669 | Acc: 60.083,93.185,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.675 | Acc: 60.036,93.109,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.678 | Acc: 60.110,93.068,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.681 | Acc: 60.062,92.975,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.684 | Acc: 60.040,92.891,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.686 | Acc: 60.037,92.858,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.683 | Acc: 60.138,92.834,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.683 | Acc: 60.190,92.815,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.681 | Acc: 60.163,92.898,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 60.106,92.858,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.683 | Acc: 60.132,92.854,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.035 | Acc: 54.688,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.126 | Acc: 51.637,69.048,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.168 | Acc: 51.601,68.826,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.123 | Acc: 51.242,69.173,75.320,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.604 | Acc: 59.375,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.617 | Acc: 61.458,93.713,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.668 | Acc: 60.061,93.845,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.666 | Acc: 59.977,93.993,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.655 | Acc: 60.349,93.875,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.662 | Acc: 60.017,93.588,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.672 | Acc: 59.924,93.453,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.664 | Acc: 60.173,93.462,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.669 | Acc: 60.035,93.449,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.668 | Acc: 60.001,93.474,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.666 | Acc: 59.997,93.497,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.665 | Acc: 59.997,93.467,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.666 | Acc: 60.053,93.436,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.667 | Acc: 60.081,93.406,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.671 | Acc: 60.020,93.347,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.672 | Acc: 60.071,93.324,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.676 | Acc: 60.054,93.285,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.674 | Acc: 60.030,93.301,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.675 | Acc: 60.055,93.296,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.677 | Acc: 60.041,93.235,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.048 | Acc: 56.250,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.100 | Acc: 51.935,69.159,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.142 | Acc: 52.096,68.769,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.115 | Acc: 51.639,69.160,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 1.618 | Acc: 57.031,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.684 | Acc: 59.338,93.155,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.671 | Acc: 59.546,93.807,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.656 | Acc: 60.259,93.686,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.648 | Acc: 60.561,93.750,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.655 | Acc: 60.497,93.603,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.645 | Acc: 60.802,93.576,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.652 | Acc: 60.660,93.456,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.649 | Acc: 60.729,93.532,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.648 | Acc: 60.627,93.478,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.649 | Acc: 60.700,93.404,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.654 | Acc: 60.510,93.312,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 60.416,93.254,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.660 | Acc: 60.408,93.187,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.662 | Acc: 60.298,93.158,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.665 | Acc: 60.211,93.140,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.665 | Acc: 60.227,93.134,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.665 | Acc: 60.246,93.129,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.664 | Acc: 60.241,93.122,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.666 | Acc: 60.222,93.075,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.962 | Acc: 50.000,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.149 | Acc: 51.376,69.308,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.176 | Acc: 52.039,68.864,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.133 | Acc: 51.306,69.365,75.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.425 | Acc: 67.188,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.661 | Acc: 60.640,93.601,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.652 | Acc: 60.290,93.750,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.642 | Acc: 60.592,93.840,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.651 | Acc: 60.513,93.711,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.646 | Acc: 60.690,93.649,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.648 | Acc: 60.647,93.582,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.648 | Acc: 60.600,93.611,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.642 | Acc: 60.690,93.672,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.635 | Acc: 60.769,93.690,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.636 | Acc: 60.899,93.637,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.641 | Acc: 60.824,93.570,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.643 | Acc: 60.704,93.513,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.645 | Acc: 60.620,93.478,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.646 | Acc: 60.543,93.464,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.644 | Acc: 60.579,93.433,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.652 | Acc: 60.436,93.414,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.655 | Acc: 60.431,93.372,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.653 | Acc: 60.515,93.373,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.653 | Acc: 60.505,93.367,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.962 | Acc: 53.906,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.136 | Acc: 51.749,69.382,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.168 | Acc: 52.248,69.055,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.129 | Acc: 51.870,69.352,75.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 2.101 | Acc: 52.344,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.651 | Acc: 61.049,94.196,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.676 | Acc: 59.794,93.941,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.651 | Acc: 60.579,94.032,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.656 | Acc: 60.532,93.846,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.656 | Acc: 60.311,93.812,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.658 | Acc: 60.363,93.731,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.659 | Acc: 60.334,93.689,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.656 | Acc: 60.384,93.580,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.660 | Acc: 60.333,93.530,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.663 | Acc: 60.156,93.575,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.666 | Acc: 60.146,93.506,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 60.322,93.543,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.663 | Acc: 60.333,93.484,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.658 | Acc: 60.484,93.480,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.660 | Acc: 60.424,93.407,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.663 | Acc: 60.370,93.361,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.661 | Acc: 60.369,93.361,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.660 | Acc: 60.440,93.356,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.659 | Acc: 60.480,93.346,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.101 | Acc: 54.688,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.128 | Acc: 51.823,68.787,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.183 | Acc: 52.096,68.407,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.147 | Acc: 51.537,68.558,75.038,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.594 | Acc: 60.938,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.680 | Acc: 58.408,94.085,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.690 | Acc: 59.070,93.807,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.666 | Acc: 59.721,93.788,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.660 | Acc: 60.098,93.576,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.651 | Acc: 60.365,93.417,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.647 | Acc: 60.511,93.356,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.645 | Acc: 60.572,93.323,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.645 | Acc: 60.544,93.381,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.642 | Acc: 60.657,93.413,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.639 | Acc: 60.712,93.408,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.638 | Acc: 60.619,93.389,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.646 | Acc: 60.477,93.345,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.647 | Acc: 60.506,93.310,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.650 | Acc: 60.470,93.288,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.652 | Acc: 60.499,93.270,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.651 | Acc: 60.492,93.275,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.649 | Acc: 60.461,93.344,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.651 | Acc: 60.425,93.334,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.652 | Acc: 60.507,93.287,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.044 | Acc: 55.469,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.141 | Acc: 51.562,69.829,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.176 | Acc: 52.248,69.379,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.141 | Acc: 51.691,69.659,75.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.721 | Acc: 58.594,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.663 | Acc: 59.970,94.196,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.609 | Acc: 60.766,94.245,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.607 | Acc: 61.014,94.365,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.617 | Acc: 60.831,94.261,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.622 | Acc: 60.651,94.059,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.621 | Acc: 60.621,94.028,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.629 | Acc: 60.600,93.872,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.628 | Acc: 60.690,93.832,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.630 | Acc: 60.549,93.823,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.632 | Acc: 60.518,93.801,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.632 | Acc: 60.584,93.799,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.634 | Acc: 60.668,93.750,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.635 | Acc: 60.707,93.684,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.634 | Acc: 60.760,93.678,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.636 | Acc: 60.735,93.641,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.636 | Acc: 60.704,93.563,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.635 | Acc: 60.720,93.603,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.633 | Acc: 60.767,93.646,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.637 | Acc: 60.704,93.580,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.149 | Acc: 52.344,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.142 | Acc: 51.786,69.048,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.190 | Acc: 52.077,68.369,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.166 | Acc: 51.627,68.801,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.326 | Acc: 62.500,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.575 | Acc: 61.644,94.568,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.597 | Acc: 60.804,94.398,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.589 | Acc: 61.296,94.288,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.595 | Acc: 61.179,94.194,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.609 | Acc: 60.791,94.152,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.613 | Acc: 60.537,94.131,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.615 | Acc: 60.566,94.199,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.618 | Acc: 60.452,94.192,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.619 | Acc: 60.575,94.113,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.620 | Acc: 60.498,94.166,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.624 | Acc: 60.524,94.040,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.625 | Acc: 60.607,94.022,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.623 | Acc: 60.680,94.016,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.628 | Acc: 60.459,93.953,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.626 | Acc: 60.512,93.984,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.630 | Acc: 60.436,93.891,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.629 | Acc: 60.498,93.901,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.631 | Acc: 60.535,93.880,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.632 | Acc: 60.429,93.859,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.120 | Acc: 49.219,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.195 | Acc: 51.042,69.680,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.207 | Acc: 51.524,69.017,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.168 | Acc: 51.012,69.480,75.448,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.440 | Acc: 64.062,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.555 | Acc: 61.012,94.308,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.623 | Acc: 59.699,94.207,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.622 | Acc: 59.593,94.288,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.622 | Acc: 59.857,94.020,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.630 | Acc: 59.754,94.106,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.638 | Acc: 59.711,94.002,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.628 | Acc: 60.084,93.983,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.620 | Acc: 60.316,94.046,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.616 | Acc: 60.553,93.970,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.613 | Acc: 60.549,93.956,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.615 | Acc: 60.513,93.959,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.619 | Acc: 60.399,93.906,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.621 | Acc: 60.372,93.858,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.624 | Acc: 60.337,93.822,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.623 | Acc: 60.460,93.846,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.625 | Acc: 60.482,93.796,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.625 | Acc: 60.443,93.745,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.625 | Acc: 60.453,93.750,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.628 | Acc: 60.374,93.756,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.115 | Acc: 50.781,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.205 | Acc: 51.190,69.196,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.218 | Acc: 51.429,68.598,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.186 | Acc: 51.101,68.814,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.356 | Acc: 64.844,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.494 | Acc: 64.769,94.680,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.531 | Acc: 63.148,94.779,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.565 | Acc: 62.154,94.787,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.580 | Acc: 61.863,94.502,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.590 | Acc: 61.541,94.431,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.593 | Acc: 61.331,94.441,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.604 | Acc: 61.192,94.337,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.607 | Acc: 61.005,94.361,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.619 | Acc: 60.778,94.203,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.614 | Acc: 60.801,94.267,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.612 | Acc: 60.920,94.245,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.613 | Acc: 60.938,94.220,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.613 | Acc: 60.946,94.223,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.614 | Acc: 60.918,94.192,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.613 | Acc: 60.948,94.194,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.616 | Acc: 60.867,94.154,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.616 | Acc: 60.811,94.151,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.619 | Acc: 60.762,94.116,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.621 | Acc: 60.693,94.062,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.094 | Acc: 53.906,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.197 | Acc: 51.711,69.234,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.209 | Acc: 51.810,69.017,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.170 | Acc: 51.242,69.454,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.539 | Acc: 60.156,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.626 | Acc: 60.863,93.601,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.618 | Acc: 60.842,93.941,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.607 | Acc: 60.784,94.045,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.606 | Acc: 60.696,94.117,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.608 | Acc: 60.558,94.144,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.609 | Acc: 60.628,93.995,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.611 | Acc: 60.611,94.149,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.617 | Acc: 60.540,94.075,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.613 | Acc: 60.713,94.095,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.612 | Acc: 60.774,94.135,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.612 | Acc: 60.676,94.121,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.614 | Acc: 60.604,94.116,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.614 | Acc: 60.695,94.103,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.613 | Acc: 60.746,94.128,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.609 | Acc: 60.823,94.145,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.610 | Acc: 60.789,94.103,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.615 | Acc: 60.715,94.078,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.615 | Acc: 60.710,94.059,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.618 | Acc: 60.730,94.027,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.134 | Acc: 54.688,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.191 | Acc: 52.716,68.899,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.212 | Acc: 52.401,68.902,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.173 | Acc: 51.755,69.211,75.218,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.486 | Acc: 63.281,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.605 | Acc: 59.821,94.680,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.621 | Acc: 59.851,94.569,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.608 | Acc: 60.310,94.442,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.607 | Acc: 60.619,94.416,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.606 | Acc: 60.628,94.245,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.605 | Acc: 60.634,94.299,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.601 | Acc: 60.904,94.271,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.604 | Acc: 60.938,94.211,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.604 | Acc: 60.907,94.212,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.606 | Acc: 60.786,94.236,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.608 | Acc: 60.796,94.195,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.605 | Acc: 60.882,94.207,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.606 | Acc: 60.818,94.196,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.604 | Acc: 60.860,94.186,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.604 | Acc: 60.862,94.150,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.606 | Acc: 60.855,94.144,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.611 | Acc: 60.777,94.059,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.609 | Acc: 60.818,94.105,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.609 | Acc: 60.788,94.080,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.094 | Acc: 56.250,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.185 | Acc: 51.674,68.713,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.209 | Acc: 51.715,68.216,75.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.180 | Acc: 51.153,68.776,75.512,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.536 | Acc: 58.594,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.611 | Acc: 60.714,94.680,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.595 | Acc: 61.300,94.264,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.598 | Acc: 61.245,94.198,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.590 | Acc: 61.314,94.097,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.591 | Acc: 61.255,94.230,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.583 | Acc: 61.389,94.247,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.585 | Acc: 61.397,94.232,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.591 | Acc: 61.267,94.143,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.594 | Acc: 61.089,94.100,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.598 | Acc: 60.984,94.096,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.604 | Acc: 60.860,94.050,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.601 | Acc: 60.908,94.071,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.601 | Acc: 60.887,94.097,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.599 | Acc: 60.946,94.117,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.599 | Acc: 61.005,94.124,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.602 | Acc: 60.981,94.057,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.602 | Acc: 61.038,94.073,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.605 | Acc: 60.955,94.072,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.606 | Acc: 60.946,94.033,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.094 | Acc: 56.250,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.202 | Acc: 51.228,68.973,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.226 | Acc: 51.925,68.845,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.190 | Acc: 51.678,68.878,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.705 | Acc: 61.719,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.531 | Acc: 62.054,95.350,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.541 | Acc: 61.947,95.046,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.561 | Acc: 61.565,94.954,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.577 | Acc: 61.381,94.724,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.585 | Acc: 61.247,94.554,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.593 | Acc: 61.080,94.415,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.588 | Acc: 61.242,94.343,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.586 | Acc: 61.267,94.284,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.588 | Acc: 61.184,94.242,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.590 | Acc: 61.151,94.244,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.592 | Acc: 61.174,94.238,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.596 | Acc: 61.122,94.214,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.595 | Acc: 61.192,94.223,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.600 | Acc: 61.068,94.156,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.605 | Acc: 60.961,94.116,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.607 | Acc: 60.933,94.096,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.608 | Acc: 60.979,94.062,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.606 | Acc: 60.979,94.088,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.604 | Acc: 60.935,94.103,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.086 | Acc: 56.250,76.562,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.181 | Acc: 51.711,69.978,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.209 | Acc: 51.925,68.883,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.188 | Acc: 51.409,69.006,75.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 1.706 | Acc: 56.250,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.586 | Acc: 60.900,95.052,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.606 | Acc: 60.423,94.588,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.584 | Acc: 61.053,94.711,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.588 | Acc: 60.995,94.637,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.585 | Acc: 61.185,94.640,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.596 | Acc: 61.125,94.499,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.601 | Acc: 61.015,94.498,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.610 | Acc: 60.918,94.458,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.607 | Acc: 60.890,94.423,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.605 | Acc: 60.860,94.461,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.600 | Acc: 60.941,94.475,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.603 | Acc: 60.782,94.392,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.600 | Acc: 60.785,94.370,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.599 | Acc: 60.854,94.395,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.599 | Acc: 60.844,94.386,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.600 | Acc: 60.823,94.393,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.598 | Acc: 60.885,94.375,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.598 | Acc: 60.905,94.373,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.602 | Acc: 60.870,94.302,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.153 | Acc: 53.125,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.199 | Acc: 52.083,68.527,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.253 | Acc: 52.191,67.873,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.218 | Acc: 51.524,68.315,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.349 | Acc: 66.406,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.527 | Acc: 62.574,94.978,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.559 | Acc: 62.043,94.627,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.554 | Acc: 62.013,94.570,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.554 | Acc: 61.834,94.898,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.560 | Acc: 61.726,94.817,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.564 | Acc: 61.848,94.718,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.572 | Acc: 61.697,94.725,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.569 | Acc: 61.753,94.677,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.572 | Acc: 61.645,94.635,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.573 | Acc: 61.672,94.640,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.579 | Acc: 61.546,94.602,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.582 | Acc: 61.427,94.538,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.580 | Acc: 61.440,94.525,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.583 | Acc: 61.374,94.498,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.587 | Acc: 61.265,94.438,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.588 | Acc: 61.183,94.473,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.589 | Acc: 61.146,94.387,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.589 | Acc: 61.085,94.367,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.594 | Acc: 60.964,94.365,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.128 | Acc: 53.906,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.223 | Acc: 52.232,68.155,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.270 | Acc: 52.153,67.931,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.232 | Acc: 51.601,68.071,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.471 | Acc: 61.719,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.511 | Acc: 62.574,94.308,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.532 | Acc: 62.081,94.646,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.521 | Acc: 62.718,94.877,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.541 | Acc: 62.375,94.715,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.554 | Acc: 61.812,94.524,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.552 | Acc: 61.932,94.460,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.562 | Acc: 61.763,94.443,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.567 | Acc: 61.748,94.361,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.567 | Acc: 61.667,94.367,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.568 | Acc: 61.695,94.399,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.577 | Acc: 61.475,94.354,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.579 | Acc: 61.440,94.343,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.582 | Acc: 61.327,94.295,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.585 | Acc: 61.371,94.245,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.587 | Acc: 61.249,94.269,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.587 | Acc: 61.215,94.322,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.589 | Acc: 61.137,94.286,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.589 | Acc: 61.108,94.293,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.589 | Acc: 61.132,94.287,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.207 | Acc: 50.781,75.000,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.286 | Acc: 51.637,69.680,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.295 | Acc: 52.020,69.169,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.257 | Acc: 51.370,69.326,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 1.550 | Acc: 65.625,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.545 | Acc: 61.012,94.680,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.507 | Acc: 61.776,95.008,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.508 | Acc: 62.103,94.890,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.507 | Acc: 62.375,94.801,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.521 | Acc: 62.160,94.771,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.533 | Acc: 61.951,94.647,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.542 | Acc: 61.841,94.603,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.551 | Acc: 61.699,94.599,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.556 | Acc: 61.706,94.544,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.568 | Acc: 61.509,94.562,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.571 | Acc: 61.415,94.549,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.573 | Acc: 61.310,94.505,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.575 | Acc: 61.294,94.471,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.576 | Acc: 61.271,94.478,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.576 | Acc: 61.236,94.425,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.576 | Acc: 61.222,94.407,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.576 | Acc: 61.219,94.389,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.573 | Acc: 61.271,94.397,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.578 | Acc: 61.194,94.306,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.239 | Acc: 52.344,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.241 | Acc: 52.455,68.229,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.261 | Acc: 52.344,68.197,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.228 | Acc: 51.614,68.468,75.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.690 | Acc: 53.906,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.601 | Acc: 59.561,94.792,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.587 | Acc: 60.385,94.588,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.560 | Acc: 61.463,94.826,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.568 | Acc: 61.188,94.801,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.557 | Acc: 61.317,94.833,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.553 | Acc: 61.260,94.802,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.552 | Acc: 61.325,94.808,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.559 | Acc: 61.102,94.687,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.559 | Acc: 61.089,94.721,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.561 | Acc: 61.027,94.671,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.565 | Acc: 61.082,94.602,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.565 | Acc: 61.096,94.606,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.568 | Acc: 61.144,94.522,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.574 | Acc: 60.990,94.470,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.576 | Acc: 61.083,94.425,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.574 | Acc: 61.210,94.414,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.573 | Acc: 61.247,94.449,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.576 | Acc: 61.195,94.419,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.579 | Acc: 61.104,94.453,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.250 | Acc: 50.000,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.254 | Acc: 51.339,68.080,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.288 | Acc: 51.658,68.407,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.254 | Acc: 51.319,68.507,75.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.635 | Acc: 61.719,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.554 | Acc: 60.714,95.275,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.545 | Acc: 61.166,95.160,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.549 | Acc: 61.245,95.095,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.548 | Acc: 61.439,94.994,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.555 | Acc: 61.363,94.949,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.557 | Acc: 61.428,94.899,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.556 | Acc: 61.508,94.897,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.553 | Acc: 61.593,94.852,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.551 | Acc: 61.762,94.829,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.550 | Acc: 61.781,94.799,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.551 | Acc: 61.669,94.789,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.558 | Acc: 61.560,94.680,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.564 | Acc: 61.425,94.648,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.561 | Acc: 61.457,94.615,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.567 | Acc: 61.371,94.562,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.570 | Acc: 61.259,94.560,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.571 | Acc: 61.256,94.511,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.574 | Acc: 61.132,94.479,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.578 | Acc: 61.073,94.459,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.120 | Acc: 56.250,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.231 | Acc: 51.451,68.973,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.263 | Acc: 51.467,68.502,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.231 | Acc: 51.114,68.648,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.636 | Acc: 60.156,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.529 | Acc: 63.318,95.536,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.573 | Acc: 61.662,95.351,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.549 | Acc: 62.141,95.389,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.536 | Acc: 62.172,95.149,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.546 | Acc: 61.796,95.127,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.548 | Acc: 61.712,95.177,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.549 | Acc: 61.802,95.091,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.547 | Acc: 61.738,95.094,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.550 | Acc: 61.559,95.118,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.553 | Acc: 61.509,95.068,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.557 | Acc: 61.489,95.026,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.558 | Acc: 61.469,95.005,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.555 | Acc: 61.557,94.938,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.558 | Acc: 61.444,94.901,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.559 | Acc: 61.446,94.843,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.565 | Acc: 61.339,94.811,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.568 | Acc: 61.281,94.753,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.570 | Acc: 61.279,94.685,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.572 | Acc: 61.231,94.669,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.189 | Acc: 52.344,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.195 | Acc: 52.493,68.490,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.232 | Acc: 52.572,68.483,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.205 | Acc: 52.139,68.468,75.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.385 | Acc: 66.406,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.555 | Acc: 62.016,94.903,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.572 | Acc: 61.242,94.817,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.566 | Acc: 61.642,94.672,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.549 | Acc: 61.719,94.763,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.546 | Acc: 61.966,94.678,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.547 | Acc: 61.945,94.667,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.546 | Acc: 61.951,94.830,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.548 | Acc: 61.816,94.852,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.546 | Acc: 61.857,94.864,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.549 | Acc: 61.746,94.831,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.549 | Acc: 61.772,94.811,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.548 | Acc: 61.780,94.846,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.551 | Acc: 61.698,94.783,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.554 | Acc: 61.677,94.781,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.555 | Acc: 61.615,94.762,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.561 | Acc: 61.485,94.767,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.561 | Acc: 61.462,94.701,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.565 | Acc: 61.349,94.711,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.567 | Acc: 61.296,94.683,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.154 | Acc: 55.469,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.226 | Acc: 51.972,68.601,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.249 | Acc: 52.096,68.407,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.222 | Acc: 51.422,68.507,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.393 | Acc: 62.500,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.556 | Acc: 61.496,95.722,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.543 | Acc: 61.300,95.541,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.550 | Acc: 61.142,95.082,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.530 | Acc: 61.825,95.014,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.520 | Acc: 62.067,95.166,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.524 | Acc: 62.100,95.112,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.525 | Acc: 62.134,95.152,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.541 | Acc: 61.767,94.910,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.542 | Acc: 61.766,94.799,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.543 | Acc: 61.773,94.815,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.547 | Acc: 61.751,94.772,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.552 | Acc: 61.605,94.732,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.555 | Acc: 61.551,94.741,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.559 | Acc: 61.432,94.684,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.561 | Acc: 61.361,94.674,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.561 | Acc: 61.359,94.653,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.562 | Acc: 61.393,94.669,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.562 | Acc: 61.396,94.652,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.562 | Acc: 61.446,94.660,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.227 | Acc: 52.344,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.266 | Acc: 51.600,68.899,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.300 | Acc: 51.562,68.426,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.261 | Acc: 51.063,68.648,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.613 | Acc: 60.156,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.525 | Acc: 61.830,95.796,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.530 | Acc: 61.757,95.636,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.539 | Acc: 61.668,95.300,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.541 | Acc: 61.786,95.370,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.542 | Acc: 61.773,95.305,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.536 | Acc: 61.951,95.319,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.544 | Acc: 61.940,95.130,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.550 | Acc: 61.593,95.031,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.552 | Acc: 61.464,95.006,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.553 | Acc: 61.423,94.955,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.558 | Acc: 61.333,94.849,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.557 | Acc: 61.301,94.865,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.558 | Acc: 61.273,94.840,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.551 | Acc: 61.391,94.854,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.552 | Acc: 61.324,94.889,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.555 | Acc: 61.312,94.840,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.558 | Acc: 61.233,94.802,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.559 | Acc: 61.217,94.754,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.560 | Acc: 61.249,94.745,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.178 | Acc: 53.125,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.302 | Acc: 52.195,68.676,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.311 | Acc: 52.001,68.121,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.288 | Acc: 51.370,68.238,74.629,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 1.705 | Acc: 60.156,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.485 | Acc: 63.542,94.754,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.510 | Acc: 62.138,95.122,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.527 | Acc: 61.770,95.248,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.528 | Acc: 61.979,95.216,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.529 | Acc: 62.013,95.196,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.533 | Acc: 61.783,95.041,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.544 | Acc: 61.541,95.058,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.539 | Acc: 61.510,95.138,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.539 | Acc: 61.628,95.179,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.542 | Acc: 61.587,95.118,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.545 | Acc: 61.528,95.054,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.550 | Acc: 61.492,94.972,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.549 | Acc: 61.470,94.986,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.556 | Acc: 61.332,94.932,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.556 | Acc: 61.381,94.895,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.553 | Acc: 61.441,94.899,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.556 | Acc: 61.359,94.850,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.556 | Acc: 61.325,94.858,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.556 | Acc: 61.356,94.872,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.305 | Acc: 53.906,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.261 | Acc: 51.935,68.118,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.280 | Acc: 52.134,67.835,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.258 | Acc: 51.767,67.956,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 1.464 | Acc: 62.500,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.557 | Acc: 60.938,95.052,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.545 | Acc: 61.643,94.950,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.543 | Acc: 61.488,95.044,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.544 | Acc: 61.256,94.965,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.557 | Acc: 61.092,94.918,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.559 | Acc: 61.028,94.957,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.559 | Acc: 60.998,94.991,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.557 | Acc: 60.971,95.075,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.557 | Acc: 61.132,95.131,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.555 | Acc: 61.295,95.134,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.552 | Acc: 61.422,95.150,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.550 | Acc: 61.404,95.180,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.547 | Acc: 61.506,95.151,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.546 | Acc: 61.585,95.168,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.551 | Acc: 61.516,95.154,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.551 | Acc: 61.475,95.152,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.553 | Acc: 61.485,95.106,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.553 | Acc: 61.513,95.040,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.554 | Acc: 61.467,95.005,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.298 | Acc: 53.125,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.355 | Acc: 52.046,68.043,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.381 | Acc: 51.753,67.740,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.355 | Acc: 51.306,67.789,74.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.388 | Acc: 65.625,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.492 | Acc: 62.984,94.680,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.507 | Acc: 62.748,94.817,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.525 | Acc: 61.872,94.928,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.530 | Acc: 62.133,95.100,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.528 | Acc: 62.129,95.212,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.527 | Acc: 62.164,95.222,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.532 | Acc: 61.990,95.085,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.538 | Acc: 61.743,95.089,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.534 | Acc: 61.857,95.097,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.538 | Acc: 61.758,95.110,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.539 | Acc: 61.648,95.079,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.540 | Acc: 61.657,95.086,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.540 | Acc: 61.734,95.064,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.540 | Acc: 61.810,95.009,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.542 | Acc: 61.760,95.014,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.546 | Acc: 61.612,95.025,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.547 | Acc: 61.568,95.003,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.549 | Acc: 61.481,94.975,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.551 | Acc: 61.411,94.970,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.124 | Acc: 55.469,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 50.670,68.155,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.368 | Acc: 51.105,67.645,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.323 | Acc: 50.909,67.802,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.328 | Acc: 69.531,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.457 | Acc: 64.211,95.387,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.486 | Acc: 62.919,95.389,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.532 | Acc: 61.411,95.300,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.525 | Acc: 61.545,95.428,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.537 | Acc: 61.533,95.320,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.526 | Acc: 61.912,95.338,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.524 | Acc: 62.029,95.307,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.532 | Acc: 61.884,95.274,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.530 | Acc: 61.982,95.287,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.530 | Acc: 61.987,95.305,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.533 | Acc: 61.896,95.281,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.532 | Acc: 61.868,95.248,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.536 | Acc: 61.850,95.232,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.540 | Acc: 61.752,95.154,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.538 | Acc: 61.856,95.102,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.541 | Acc: 61.838,95.091,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.543 | Acc: 61.774,95.049,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.539 | Acc: 61.838,95.074,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.540 | Acc: 61.840,95.077,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.051 | Acc: 54.688,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.306 | Acc: 51.228,67.932,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.326 | Acc: 51.467,67.721,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 51.204,67.623,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.447 | Acc: 59.375,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.476 | Acc: 62.351,95.350,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.489 | Acc: 61.814,95.541,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.478 | Acc: 62.538,95.466,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.497 | Acc: 62.442,95.351,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.510 | Acc: 62.106,95.227,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.520 | Acc: 62.054,95.093,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.525 | Acc: 62.007,94.969,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.531 | Acc: 61.879,94.983,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.537 | Acc: 61.710,94.928,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.541 | Acc: 61.750,94.920,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.545 | Acc: 61.567,94.984,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.541 | Acc: 61.602,94.972,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.542 | Acc: 61.608,94.950,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.544 | Acc: 61.549,94.959,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.541 | Acc: 61.592,94.991,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.545 | Acc: 61.524,94.964,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.547 | Acc: 61.485,94.925,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.551 | Acc: 61.450,94.890,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.550 | Acc: 61.460,94.896,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.278 | Acc: 53.906,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.240 | Acc: 52.418,68.118,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.313 | Acc: 52.439,67.264,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.295 | Acc: 51.793,67.533,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.493 | Acc: 64.062,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.487 | Acc: 62.835,94.754,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.487 | Acc: 62.519,95.370,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.504 | Acc: 62.564,95.146,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.512 | Acc: 62.510,95.042,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.522 | Acc: 62.345,94.957,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.526 | Acc: 61.938,95.112,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.524 | Acc: 61.957,95.074,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.534 | Acc: 61.578,95.080,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.534 | Acc: 61.585,95.131,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.530 | Acc: 61.758,95.145,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.532 | Acc: 61.736,95.139,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.531 | Acc: 61.784,95.128,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.534 | Acc: 61.746,95.106,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.540 | Acc: 61.577,95.093,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.546 | Acc: 61.402,95.030,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.545 | Acc: 61.415,95.025,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.545 | Acc: 61.435,94.978,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.545 | Acc: 61.485,94.975,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.543 | Acc: 61.469,94.976,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.039 | Acc: 53.125,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.292 | Acc: 52.418,68.155,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.319 | Acc: 52.458,67.626,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.282 | Acc: 51.934,67.828,75.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.711 | Acc: 60.938,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.492 | Acc: 62.798,95.722,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.514 | Acc: 62.633,95.370,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 62.513,95.287,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.505 | Acc: 62.336,95.419,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.513 | Acc: 62.028,95.382,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.517 | Acc: 61.854,95.287,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.520 | Acc: 61.902,95.257,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.516 | Acc: 61.990,95.293,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.516 | Acc: 62.042,95.304,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.521 | Acc: 61.917,95.250,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.524 | Acc: 61.835,95.175,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.523 | Acc: 61.793,95.186,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.524 | Acc: 61.797,95.181,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.523 | Acc: 61.838,95.151,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.526 | Acc: 61.773,95.128,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.527 | Acc: 61.828,95.086,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.532 | Acc: 61.668,95.077,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.536 | Acc: 61.632,95.074,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.535 | Acc: 61.651,95.044,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.271 | Acc: 53.125,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 51.228,68.415,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.341 | Acc: 51.448,67.912,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.312 | Acc: 51.076,67.994,74.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.409 | Acc: 66.406,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.475 | Acc: 61.830,96.726,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.474 | Acc: 62.062,96.303,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.489 | Acc: 61.911,95.978,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.499 | Acc: 62.076,95.747,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.507 | Acc: 61.866,95.676,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 62.093,95.648,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.503 | Acc: 62.068,95.656,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 62.029,95.604,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.504 | Acc: 62.064,95.658,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.505 | Acc: 62.037,95.616,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.507 | Acc: 62.065,95.518,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.506 | Acc: 62.124,95.478,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.513 | Acc: 61.910,95.417,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.518 | Acc: 61.791,95.432,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.523 | Acc: 61.776,95.338,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.526 | Acc: 61.738,95.261,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.531 | Acc: 61.590,95.251,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.529 | Acc: 61.678,95.213,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.533 | Acc: 61.651,95.144,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.334 | Acc: 51.562,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.334 | Acc: 50.707,67.560,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.362 | Acc: 50.819,67.492,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.316 | Acc: 50.845,67.649,75.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.702 | Acc: 58.594,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.549 | Acc: 62.574,95.052,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.537 | Acc: 62.633,95.389,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.544 | Acc: 62.154,95.274,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.541 | Acc: 62.317,95.255,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.537 | Acc: 62.399,95.258,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.528 | Acc: 62.442,95.229,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.534 | Acc: 62.256,95.157,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.526 | Acc: 62.335,95.225,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.523 | Acc: 62.276,95.308,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.529 | Acc: 62.088,95.211,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.529 | Acc: 62.129,95.214,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.527 | Acc: 62.114,95.280,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.529 | Acc: 62.033,95.247,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.529 | Acc: 62.027,95.212,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.531 | Acc: 62.002,95.180,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.533 | Acc: 61.948,95.181,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.532 | Acc: 61.964,95.143,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.535 | Acc: 61.907,95.105,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.535 | Acc: 61.875,95.089,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.486 | Acc: 53.125,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.299 | Acc: 52.269,68.118,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.333 | Acc: 52.096,67.797,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.317 | Acc: 51.627,67.866,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.440 | Acc: 64.844,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.454 | Acc: 63.095,95.908,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.460 | Acc: 62.976,95.789,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.484 | Acc: 62.756,95.684,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.502 | Acc: 62.432,95.573,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.507 | Acc: 62.307,95.467,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.510 | Acc: 62.164,95.409,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.517 | Acc: 62.001,95.362,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.520 | Acc: 61.952,95.361,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.520 | Acc: 62.004,95.304,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 62.170,95.328,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.520 | Acc: 62.051,95.256,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.526 | Acc: 61.923,95.202,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.527 | Acc: 61.794,95.208,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.527 | Acc: 61.674,95.182,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.524 | Acc: 61.791,95.185,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.528 | Acc: 61.794,95.123,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.527 | Acc: 61.822,95.093,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.529 | Acc: 61.753,95.083,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.532 | Acc: 61.711,95.091,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.378 | Acc: 53.906,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.286 | Acc: 51.935,68.415,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.342 | Acc: 51.505,68.140,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.313 | Acc: 51.165,68.148,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.407 | Acc: 64.062,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.517 | Acc: 62.984,94.829,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.502 | Acc: 62.443,95.255,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.508 | Acc: 62.116,95.261,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.513 | Acc: 62.259,95.255,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.511 | Acc: 62.121,95.328,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.507 | Acc: 62.280,95.384,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.511 | Acc: 62.118,95.423,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.514 | Acc: 62.034,95.322,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.524 | Acc: 61.814,95.243,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.526 | Acc: 61.765,95.165,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.526 | Acc: 61.800,95.146,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.528 | Acc: 61.751,95.131,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.527 | Acc: 61.764,95.160,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.525 | Acc: 61.802,95.171,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.523 | Acc: 61.895,95.165,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.522 | Acc: 61.904,95.174,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.522 | Acc: 61.939,95.097,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.522 | Acc: 61.922,95.051,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.524 | Acc: 61.868,95.021,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.169 | Acc: 54.688,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.288 | Acc: 51.823,68.229,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.346 | Acc: 51.639,67.721,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.315 | Acc: 51.255,67.469,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.556 | Acc: 60.156,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.486 | Acc: 63.728,95.424,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.486 | Acc: 63.205,95.446,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.496 | Acc: 62.910,95.274,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.508 | Acc: 62.645,95.216,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.510 | Acc: 62.577,95.289,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.512 | Acc: 62.610,95.274,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.513 | Acc: 62.555,95.240,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.516 | Acc: 62.325,95.249,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.518 | Acc: 62.310,95.170,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.519 | Acc: 62.201,95.196,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.516 | Acc: 62.132,95.132,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.521 | Acc: 62.023,95.112,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.525 | Acc: 61.958,95.124,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.526 | Acc: 61.877,95.110,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.523 | Acc: 62.004,95.126,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.527 | Acc: 61.969,95.079,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.529 | Acc: 61.884,95.049,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.531 | Acc: 61.853,95.055,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.530 | Acc: 61.879,95.064,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.216 | Acc: 54.688,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.309 | Acc: 51.451,68.341,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.351 | Acc: 51.524,67.740,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.319 | Acc: 51.178,67.764,74.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.483 | Acc: 72.656,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.480 | Acc: 63.356,95.908,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.484 | Acc: 63.186,95.770,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.477 | Acc: 63.115,95.812,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.471 | Acc: 63.416,95.843,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.465 | Acc: 63.451,95.854,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.475 | Acc: 63.204,95.790,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 62.927,95.684,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.496 | Acc: 62.558,95.536,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.501 | Acc: 62.586,95.459,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.504 | Acc: 62.504,95.410,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 62.560,95.429,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.505 | Acc: 62.591,95.416,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.505 | Acc: 62.440,95.462,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.511 | Acc: 62.233,95.435,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.515 | Acc: 62.064,95.406,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.515 | Acc: 62.040,95.393,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.516 | Acc: 61.964,95.374,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.517 | Acc: 61.968,95.377,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.520 | Acc: 61.948,95.351,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.298 | Acc: 53.906,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.321 | Acc: 51.339,68.824,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.368 | Acc: 51.505,68.426,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.338 | Acc: 50.973,68.251,74.898,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.380 | Acc: 60.938,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.482 | Acc: 62.202,95.796,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.499 | Acc: 61.280,96.075,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.495 | Acc: 61.744,96.132,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.499 | Acc: 61.526,95.939,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.505 | Acc: 61.641,95.738,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 61.861,95.513,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.498 | Acc: 62.007,95.479,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.511 | Acc: 61.777,95.419,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.517 | Acc: 61.589,95.412,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.518 | Acc: 61.633,95.363,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.525 | Acc: 61.623,95.327,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.527 | Acc: 61.738,95.283,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.527 | Acc: 61.749,95.259,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.527 | Acc: 61.744,95.226,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.527 | Acc: 61.765,95.188,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.526 | Acc: 61.860,95.196,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.525 | Acc: 61.879,95.175,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.526 | Acc: 61.818,95.168,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.528 | Acc: 61.752,95.161,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.388 | Acc: 51.562,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.321 | Acc: 51.228,68.341,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.370 | Acc: 51.772,67.797,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.342 | Acc: 51.204,67.738,74.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.310 | Acc: 66.406,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.424 | Acc: 64.621,96.280,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 63.148,95.560,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.491 | Acc: 62.218,95.594,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.503 | Acc: 61.815,95.476,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.511 | Acc: 61.711,95.351,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.509 | Acc: 61.745,95.461,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.519 | Acc: 61.674,95.268,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.521 | Acc: 61.651,95.356,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.524 | Acc: 61.563,95.317,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.522 | Acc: 61.668,95.285,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.517 | Acc: 61.751,95.309,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.520 | Acc: 61.712,95.290,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.524 | Acc: 61.665,95.259,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.524 | Acc: 61.735,95.210,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.523 | Acc: 61.737,95.206,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.523 | Acc: 61.782,95.166,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.524 | Acc: 61.730,95.109,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.524 | Acc: 61.790,95.098,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.523 | Acc: 61.858,95.142,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.276 | Acc: 51.562,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.330 | Acc: 51.749,67.708,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.382 | Acc: 51.848,67.550,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.358 | Acc: 51.319,67.649,74.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.438 | Acc: 64.844,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.544 | Acc: 61.049,95.871,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.537 | Acc: 61.204,95.808,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.531 | Acc: 61.283,95.850,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.523 | Acc: 61.545,95.737,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.511 | Acc: 61.796,95.684,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.506 | Acc: 61.983,95.797,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.508 | Acc: 61.818,95.806,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.508 | Acc: 61.884,95.701,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.504 | Acc: 62.068,95.774,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.501 | Acc: 62.201,95.721,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.501 | Acc: 62.291,95.613,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.504 | Acc: 62.130,95.611,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.506 | Acc: 62.180,95.618,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 62.125,95.549,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.508 | Acc: 62.105,95.499,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 62.137,95.502,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 62.230,95.530,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 62.184,95.509,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 62.151,95.462,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.520 | Acc: 52.344,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.327 | Acc: 51.600,68.118,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.363 | Acc: 51.258,68.121,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.349 | Acc: 50.858,68.161,74.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.444 | Acc: 60.938,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.506 | Acc: 62.723,95.164,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.503 | Acc: 62.976,95.179,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.506 | Acc: 62.615,94.826,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.500 | Acc: 62.442,94.907,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.503 | Acc: 62.252,94.933,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.518 | Acc: 61.945,94.886,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.514 | Acc: 62.107,95.008,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.506 | Acc: 62.364,95.114,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 62.202,95.097,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.515 | Acc: 62.100,95.048,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.517 | Acc: 62.026,95.093,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.512 | Acc: 62.108,95.108,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.513 | Acc: 62.144,95.082,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.513 | Acc: 62.214,95.054,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.517 | Acc: 62.139,95.050,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.519 | Acc: 62.089,95.045,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.518 | Acc: 62.131,95.086,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.517 | Acc: 62.139,95.046,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.519 | Acc: 62.073,95.027,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.241 | Acc: 54.688,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.329 | Acc: 51.562,67.894,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.358 | Acc: 51.715,67.759,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.323 | Acc: 51.434,67.828,74.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.387 | Acc: 62.500,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.417 | Acc: 65.141,96.317,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.464 | Acc: 63.338,95.941,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.480 | Acc: 63.192,95.594,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.483 | Acc: 62.664,95.650,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 62.771,95.777,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.502 | Acc: 62.339,95.642,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 62.240,95.656,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.500 | Acc: 62.403,95.638,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.499 | Acc: 62.414,95.723,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.499 | Acc: 62.484,95.627,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.504 | Acc: 62.352,95.535,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.508 | Acc: 62.218,95.513,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.505 | Acc: 62.299,95.540,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.506 | Acc: 62.297,95.493,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.509 | Acc: 62.204,95.481,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.512 | Acc: 62.150,95.405,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.515 | Acc: 62.051,95.370,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.518 | Acc: 62.048,95.317,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.517 | Acc: 62.102,95.310,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 53.125,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.405 | Acc: 50.744,67.746,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.413 | Acc: 51.105,67.454,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.376 | Acc: 50.781,67.418,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.373 | Acc: 63.281,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.471 | Acc: 61.868,95.499,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.458 | Acc: 62.576,95.732,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.479 | Acc: 62.244,95.633,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.479 | Acc: 62.413,95.660,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.478 | Acc: 62.423,95.645,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 62.332,95.687,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.493 | Acc: 62.267,95.601,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 62.374,95.599,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 62.461,95.580,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.488 | Acc: 62.383,95.631,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.491 | Acc: 62.291,95.624,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.496 | Acc: 62.169,95.572,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.498 | Acc: 62.150,95.567,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 62.194,95.560,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 62.152,95.541,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.503 | Acc: 62.140,95.461,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.506 | Acc: 62.083,95.390,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.510 | Acc: 62.013,95.362,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.510 | Acc: 62.008,95.319,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.453 | Acc: 54.688,67.188,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.372 | Acc: 52.307,67.522,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.389 | Acc: 52.572,67.702,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.360 | Acc: 52.152,67.943,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.560 | Acc: 53.125,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.492 | Acc: 61.793,95.982,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.484 | Acc: 62.576,95.808,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.496 | Acc: 62.231,95.889,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.492 | Acc: 62.317,95.833,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.499 | Acc: 62.291,95.676,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 62.255,95.610,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 62.123,95.567,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.509 | Acc: 62.136,95.473,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.507 | Acc: 62.202,95.455,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.500 | Acc: 62.337,95.460,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.500 | Acc: 62.260,95.521,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.497 | Acc: 62.280,95.530,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.501 | Acc: 62.249,95.462,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.501 | Acc: 62.336,95.468,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.505 | Acc: 62.264,95.427,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.506 | Acc: 62.220,95.417,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 62.264,95.429,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 62.216,95.423,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 62.170,95.386,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.366 | Acc: 56.250,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.341 | Acc: 52.083,68.192,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.391 | Acc: 51.982,67.702,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.369 | Acc: 51.511,67.828,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 1.369 | Acc: 63.281,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.498 | Acc: 61.607,95.573,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.494 | Acc: 61.338,96.037,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.493 | Acc: 61.757,95.876,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.491 | Acc: 61.970,95.843,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 62.245,95.753,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.484 | Acc: 62.268,95.790,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.486 | Acc: 62.212,95.839,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.494 | Acc: 62.068,95.798,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.495 | Acc: 62.068,95.792,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.499 | Acc: 61.901,95.736,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.499 | Acc: 61.885,95.715,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 61.858,95.637,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.503 | Acc: 61.880,95.591,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.502 | Acc: 62.030,95.543,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.502 | Acc: 62.085,95.502,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.503 | Acc: 62.135,95.468,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.506 | Acc: 62.083,95.434,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.507 | Acc: 62.059,95.408,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.509 | Acc: 62.016,95.384,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.367 | Acc: 55.469,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.412 | Acc: 51.079,68.043,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.440 | Acc: 51.353,67.511,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.419 | Acc: 50.935,67.354,73.770,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.317 | Acc: 68.750,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.502 | Acc: 62.426,96.503,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.513 | Acc: 62.195,95.808,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.507 | Acc: 62.141,95.863,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.480 | Acc: 62.558,96.036,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.479 | Acc: 62.562,96.047,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.487 | Acc: 62.351,96.003,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.492 | Acc: 62.428,95.911,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.489 | Acc: 62.466,95.866,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 62.470,95.830,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 62.387,95.794,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 62.320,95.754,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.496 | Acc: 62.289,95.676,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.494 | Acc: 62.264,95.681,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 62.222,95.671,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.498 | Acc: 62.170,95.640,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 61.996,95.609,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 62.067,95.613,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 62.072,95.544,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.504 | Acc: 62.069,95.505,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.500 | Acc: 54.688,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.391 | Acc: 51.414,67.820,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.416 | Acc: 51.524,67.530,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.387 | Acc: 51.230,67.828,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 1.643 | Acc: 54.688,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.479 | Acc: 62.946,95.945,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 62.862,95.655,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.491 | Acc: 62.538,95.735,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.486 | Acc: 62.635,95.602,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 62.925,95.637,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.489 | Acc: 62.952,95.551,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 62.932,95.418,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 62.927,95.376,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.489 | Acc: 62.970,95.377,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.494 | Acc: 62.819,95.328,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.497 | Acc: 62.641,95.330,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.500 | Acc: 62.526,95.338,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.498 | Acc: 62.539,95.310,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 62.503,95.260,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 62.534,95.222,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 62.420,95.174,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.508 | Acc: 62.413,95.129,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.508 | Acc: 62.422,95.116,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.508 | Acc: 62.404,95.079,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.430 | Acc: 53.125,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.338 | Acc: 51.376,68.043,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.379 | Acc: 51.524,67.473,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.364 | Acc: 51.178,67.649,74.296,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.606 | Acc: 65.625,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 63.839,95.945,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.489 | Acc: 62.138,95.960,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.471 | Acc: 63.089,95.786,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.473 | Acc: 63.204,95.737,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.494 | Acc: 62.392,95.668,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.492 | Acc: 62.377,95.629,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.490 | Acc: 62.511,95.518,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.488 | Acc: 62.607,95.550,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.495 | Acc: 62.349,95.528,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.501 | Acc: 62.158,95.507,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.502 | Acc: 62.146,95.454,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 62.156,95.429,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 62.228,95.384,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 62.150,95.379,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.503 | Acc: 62.272,95.333,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 62.225,95.291,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.504 | Acc: 62.182,95.296,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.504 | Acc: 62.271,95.250,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.503 | Acc: 62.352,95.278,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.434 | Acc: 57.812,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.325 | Acc: 51.972,68.936,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.364 | Acc: 52.248,68.236,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.348 | Acc: 51.742,68.263,74.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 1.518 | Acc: 60.156,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.478 | Acc: 62.835,95.610,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 61.890,95.484,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.483 | Acc: 62.436,95.453,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.477 | Acc: 62.664,95.534,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.486 | Acc: 62.570,95.405,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.500 | Acc: 62.397,95.280,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.499 | Acc: 62.345,95.224,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.502 | Acc: 62.427,95.211,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.502 | Acc: 62.254,95.312,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.504 | Acc: 62.162,95.301,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 62.182,95.334,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.501 | Acc: 62.137,95.351,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 62.225,95.307,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 62.105,95.287,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.507 | Acc: 62.105,95.279,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.507 | Acc: 62.140,95.286,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.506 | Acc: 62.115,95.308,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 62.182,95.297,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.503 | Acc: 62.217,95.290,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.359 | Acc: 51.562,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.386 | Acc: 51.749,67.076,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.433 | Acc: 51.410,67.035,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.412 | Acc: 50.973,66.919,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.461 | Acc: 62.500,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.563 | Acc: 60.045,95.833,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.521 | Acc: 61.604,95.560,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 61.860,95.517,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.502 | Acc: 62.133,95.438,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 62.554,95.452,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.482 | Acc: 62.726,95.455,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.481 | Acc: 62.832,95.484,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.473 | Acc: 62.888,95.550,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.473 | Acc: 62.798,95.554,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.481 | Acc: 62.531,95.534,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.486 | Acc: 62.493,95.433,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.489 | Acc: 62.532,95.384,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.492 | Acc: 62.410,95.351,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.494 | Acc: 62.358,95.365,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.496 | Acc: 62.287,95.380,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.497 | Acc: 62.274,95.337,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 62.195,95.358,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.501 | Acc: 62.212,95.336,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 62.272,95.292,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.485 | Acc: 57.031,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.448 | Acc: 52.679,66.629,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.468 | Acc: 52.153,66.635,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.437 | Acc: 51.358,66.944,74.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.493 | Acc: 61.719,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.498 | Acc: 62.314,95.908,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.463 | Acc: 63.110,95.903,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.473 | Acc: 62.692,95.799,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.460 | Acc: 63.098,95.718,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.466 | Acc: 62.825,95.761,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.469 | Acc: 62.965,95.726,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.475 | Acc: 62.866,95.606,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.471 | Acc: 62.961,95.628,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.480 | Acc: 62.768,95.528,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.478 | Acc: 62.826,95.542,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.479 | Acc: 62.818,95.503,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.478 | Acc: 62.873,95.504,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.483 | Acc: 62.727,95.459,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 62.656,95.438,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.488 | Acc: 62.666,95.414,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.491 | Acc: 62.612,95.405,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.491 | Acc: 62.569,95.404,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.490 | Acc: 62.580,95.416,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.492 | Acc: 62.514,95.405,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.245 | Acc: 53.906,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.415 | Acc: 50.521,67.113,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.435 | Acc: 51.124,67.283,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.401 | Acc: 50.973,67.380,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.763 | Acc: 57.812,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.492 | Acc: 63.170,95.945,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.492 | Acc: 62.862,95.922,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.483 | Acc: 62.795,95.761,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.479 | Acc: 62.963,95.775,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.486 | Acc: 62.601,95.715,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.487 | Acc: 62.487,95.732,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.489 | Acc: 62.478,95.650,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.491 | Acc: 62.403,95.686,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.489 | Acc: 62.453,95.666,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 62.477,95.588,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 62.564,95.581,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.487 | Acc: 62.591,95.585,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 62.503,95.585,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.493 | Acc: 62.347,95.579,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.493 | Acc: 62.212,95.577,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.494 | Acc: 62.271,95.570,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.496 | Acc: 62.275,95.512,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.499 | Acc: 62.229,95.486,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.500 | Acc: 62.213,95.468,99.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.320 | Acc: 50.781,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.388 | Acc: 50.930,67.820,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.409 | Acc: 51.810,67.530,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.393 | Acc: 51.345,67.495,74.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.349 | Acc: 63.281,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.449 | Acc: 63.021,96.057,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.452 | Acc: 63.472,95.998,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.449 | Acc: 63.294,95.966,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.461 | Acc: 62.857,95.872,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.471 | Acc: 62.608,95.823,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.471 | Acc: 62.836,95.590,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.472 | Acc: 62.805,95.617,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.478 | Acc: 62.680,95.579,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.481 | Acc: 62.677,95.666,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.482 | Acc: 62.776,95.627,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.483 | Acc: 62.765,95.595,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.478 | Acc: 62.840,95.620,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.482 | Acc: 62.727,95.594,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.488 | Acc: 62.636,95.563,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.489 | Acc: 62.586,95.507,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.490 | Acc: 62.575,95.476,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.491 | Acc: 62.569,95.445,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.496 | Acc: 62.509,95.410,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.496 | Acc: 62.514,95.380,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.506 | Acc: 53.125,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 49.851,66.481,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 49.409,66.463,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 49.283,66.778,74.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 1.223 | Acc: 67.969,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.427 | Acc: 62.760,96.689,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.441 | Acc: 62.557,96.341,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.450 | Acc: 62.538,96.452,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.475 | Acc: 62.143,96.354,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.486 | Acc: 61.881,96.009,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.475 | Acc: 62.106,96.094,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.472 | Acc: 62.140,96.094,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.475 | Acc: 62.262,95.948,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.473 | Acc: 62.414,95.912,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.476 | Acc: 62.278,95.837,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.476 | Acc: 62.309,95.751,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.481 | Acc: 62.293,95.731,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.483 | Acc: 62.302,95.735,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 62.353,95.677,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.486 | Acc: 62.373,95.616,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.490 | Acc: 62.308,95.588,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.490 | Acc: 62.340,95.560,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.492 | Acc: 62.303,95.540,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.494 | Acc: 62.262,95.511,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.388 | Acc: 56.250,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.446 | Acc: 50.521,67.746,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.464 | Acc: 50.838,67.416,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.447 | Acc: 50.666,67.149,74.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.354 | Acc: 69.531,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.509 | Acc: 61.868,96.503,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 62.005,96.418,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.495 | Acc: 62.334,96.081,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.492 | Acc: 62.490,96.055,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.489 | Acc: 62.376,96.032,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.489 | Acc: 62.132,95.939,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.488 | Acc: 62.206,95.800,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.493 | Acc: 62.170,95.749,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.493 | Acc: 62.276,95.718,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.496 | Acc: 62.232,95.631,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.500 | Acc: 62.196,95.532,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 62.199,95.468,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.501 | Acc: 62.207,95.429,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.500 | Acc: 62.253,95.399,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.502 | Acc: 62.116,95.338,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.503 | Acc: 62.130,95.325,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 62.094,95.308,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.504 | Acc: 62.095,95.300,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.504 | Acc: 62.151,95.220,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.235 | Acc: 57.812,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.417 | Acc: 51.674,67.001,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.441 | Acc: 51.505,66.711,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.426 | Acc: 50.858,66.714,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.507 | Acc: 64.844,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.484 | Acc: 63.207,95.833,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.508 | Acc: 62.367,95.427,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.491 | Acc: 62.692,95.300,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.496 | Acc: 62.741,95.139,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.487 | Acc: 62.786,95.227,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.491 | Acc: 62.636,95.177,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.492 | Acc: 62.594,95.279,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.495 | Acc: 62.408,95.298,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.494 | Acc: 62.487,95.269,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.498 | Acc: 62.449,95.266,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.499 | Acc: 62.405,95.302,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.501 | Acc: 62.331,95.248,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.500 | Acc: 62.386,95.247,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 62.347,95.215,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.502 | Acc: 62.329,95.191,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 62.386,95.120,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 62.392,95.115,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.502 | Acc: 62.307,95.118,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.505 | Acc: 62.246,95.114,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.301 | Acc: 53.125,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.350 | Acc: 52.641,68.118,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.414 | Acc: 52.077,67.302,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.396 | Acc: 51.793,67.264,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.428 | Acc: 67.188,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.447 | Acc: 64.249,95.387,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.460 | Acc: 63.777,95.713,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.468 | Acc: 63.794,95.453,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.476 | Acc: 63.329,95.255,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 63.041,95.251,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.489 | Acc: 62.868,95.248,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.488 | Acc: 62.777,95.202,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 62.752,95.254,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.486 | Acc: 62.819,95.218,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.485 | Acc: 62.826,95.297,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.489 | Acc: 62.656,95.288,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.492 | Acc: 62.552,95.257,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.499 | Acc: 62.503,95.241,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.497 | Acc: 62.553,95.257,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.499 | Acc: 62.474,95.206,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 62.330,95.208,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.504 | Acc: 62.321,95.223,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.506 | Acc: 62.238,95.211,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.504 | Acc: 62.322,95.226,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.490 | Acc: 52.344,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.489 | Acc: 52.269,66.555,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 51.696,66.235,73.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.505 | Acc: 51.383,66.432,73.975,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.383 | Acc: 59.375,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.435 | Acc: 63.095,96.503,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.428 | Acc: 63.567,96.246,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.413 | Acc: 64.050,96.491,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.418 | Acc: 63.735,96.586,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.417 | Acc: 63.761,96.558,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.415 | Acc: 63.707,96.636,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.410 | Acc: 63.835,96.709,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.409 | Acc: 63.674,96.749,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.409 | Acc: 63.648,96.733,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.407 | Acc: 63.736,96.805,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.403 | Acc: 63.758,96.829,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.402 | Acc: 63.823,96.869,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.401 | Acc: 63.790,96.911,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.405 | Acc: 63.704,96.933,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.401 | Acc: 63.808,96.976,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.401 | Acc: 63.839,96.972,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.397 | Acc: 63.923,97.010,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.393 | Acc: 64.037,97.042,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.393 | Acc: 64.036,97.055,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.212 | Acc: 56.250,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.269 | Acc: 53.571,69.271,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.293 | Acc: 53.296,68.998,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.261 | Acc: 52.856,68.891,75.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.385 | Acc: 58.594,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.363 | Acc: 64.062,97.842,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.335 | Acc: 64.596,97.847,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.334 | Acc: 64.985,97.720,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.333 | Acc: 65.162,97.637,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.349 | Acc: 64.844,97.502,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.357 | Acc: 64.669,97.514,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.365 | Acc: 64.417,97.562,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.364 | Acc: 64.504,97.569,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.362 | Acc: 64.524,97.492,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.363 | Acc: 64.622,97.450,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.366 | Acc: 64.473,97.430,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.363 | Acc: 64.536,97.433,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.364 | Acc: 64.550,97.447,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.362 | Acc: 64.582,97.498,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.363 | Acc: 64.608,97.482,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.360 | Acc: 64.676,97.476,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.358 | Acc: 64.741,97.494,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.358 | Acc: 64.718,97.496,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.358 | Acc: 64.749,97.515,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.269 | Acc: 55.469,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.245 | Acc: 53.460,68.973,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.274 | Acc: 53.468,68.617,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.245 | Acc: 53.061,68.673,75.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.144 | Acc: 67.188,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.294 | Acc: 65.923,97.917,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.334 | Acc: 65.434,97.713,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.335 | Acc: 65.113,97.823,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.347 | Acc: 64.786,97.791,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.352 | Acc: 64.697,97.633,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.344 | Acc: 64.979,97.643,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.342 | Acc: 64.966,97.684,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.351 | Acc: 64.795,97.714,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.350 | Acc: 64.632,97.747,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.347 | Acc: 64.739,97.808,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.347 | Acc: 64.738,97.794,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.349 | Acc: 64.714,97.786,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.347 | Acc: 64.850,97.815,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.346 | Acc: 64.852,97.809,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.348 | Acc: 64.774,97.794,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.346 | Acc: 64.783,97.802,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.347 | Acc: 64.759,97.796,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.347 | Acc: 64.781,97.788,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.346 | Acc: 64.850,97.796,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.168 | Acc: 55.469,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.243 | Acc: 53.385,69.271,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.268 | Acc: 53.335,68.941,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.239 | Acc: 52.907,68.891,75.307,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.307 | Acc: 67.969,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.308 | Acc: 65.885,98.103,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.322 | Acc: 65.473,97.885,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.340 | Acc: 64.921,97.759,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.333 | Acc: 65.162,97.820,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.349 | Acc: 64.650,97.718,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.353 | Acc: 64.624,97.721,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.348 | Acc: 64.816,97.739,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.343 | Acc: 64.917,97.753,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.339 | Acc: 65.077,97.717,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.343 | Acc: 64.976,97.792,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.346 | Acc: 64.925,97.815,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.347 | Acc: 64.892,97.844,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.348 | Acc: 64.922,97.827,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.347 | Acc: 64.963,97.831,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.346 | Acc: 64.942,97.835,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.345 | Acc: 64.973,97.841,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.347 | Acc: 64.979,97.837,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.346 | Acc: 64.885,97.827,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.348 | Acc: 64.821,97.837,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.233 | Acc: 54.688,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.237 | Acc: 53.162,69.048,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.265 | Acc: 53.430,68.636,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.240 | Acc: 53.035,68.801,75.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.396 | Acc: 66.406,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.334 | Acc: 65.476,97.917,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.350 | Acc: 64.577,97.618,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.336 | Acc: 64.857,97.810,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.345 | Acc: 64.805,97.762,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.342 | Acc: 64.821,97.834,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.345 | Acc: 64.773,97.869,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.343 | Acc: 64.766,97.834,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.344 | Acc: 64.849,97.831,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.348 | Acc: 64.839,97.838,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.348 | Acc: 64.708,97.851,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.345 | Acc: 64.759,97.854,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.345 | Acc: 64.802,97.857,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.344 | Acc: 64.877,97.848,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.348 | Acc: 64.774,97.840,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.343 | Acc: 64.818,97.822,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.342 | Acc: 64.785,97.812,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.342 | Acc: 64.814,97.798,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.341 | Acc: 64.833,97.793,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.343 | Acc: 64.731,97.792,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.248 | Acc: 54.688,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.242 | Acc: 52.865,68.452,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.270 | Acc: 53.144,68.388,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.243 | Acc: 52.766,68.635,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.306 | Acc: 66.406,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.309 | Acc: 65.588,97.768,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.321 | Acc: 65.206,97.904,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.330 | Acc: 65.215,97.836,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.322 | Acc: 65.548,97.859,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.322 | Acc: 65.486,97.850,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.325 | Acc: 65.380,97.863,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.317 | Acc: 65.675,97.795,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.319 | Acc: 65.649,97.845,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.325 | Acc: 65.500,97.833,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.331 | Acc: 65.333,97.858,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.332 | Acc: 65.307,97.868,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.333 | Acc: 65.307,97.870,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.335 | Acc: 65.170,97.848,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.336 | Acc: 65.133,97.868,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.336 | Acc: 65.121,97.856,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.337 | Acc: 65.036,97.849,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.337 | Acc: 65.077,97.862,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.337 | Acc: 65.093,97.875,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.337 | Acc: 65.061,97.882,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.288 | Acc: 54.688,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.263 | Acc: 53.125,68.862,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.292 | Acc: 52.973,68.598,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.259 | Acc: 52.510,68.622,75.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.425 | Acc: 66.406,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.311 | Acc: 65.179,97.619,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.320 | Acc: 65.492,97.790,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.318 | Acc: 65.510,97.912,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.307 | Acc: 65.683,97.994,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.315 | Acc: 65.517,98.074,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.316 | Acc: 65.444,98.063,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.322 | Acc: 65.165,98.044,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.326 | Acc: 65.174,98.020,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.325 | Acc: 65.163,98.027,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.326 | Acc: 65.096,97.994,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.326 | Acc: 65.176,98.010,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.320 | Acc: 65.320,98.000,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.326 | Acc: 65.071,98.015,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.326 | Acc: 65.052,98.015,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.327 | Acc: 65.023,97.983,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.326 | Acc: 65.090,97.980,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.329 | Acc: 65.009,97.970,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.332 | Acc: 64.891,97.951,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.336 | Acc: 64.833,97.919,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.212 | Acc: 54.688,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.245 | Acc: 53.348,68.601,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.277 | Acc: 53.316,68.521,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.251 | Acc: 52.792,68.596,75.231,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.294 | Acc: 63.281,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.315 | Acc: 65.588,97.991,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.327 | Acc: 65.072,97.980,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.309 | Acc: 65.535,98.040,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.318 | Acc: 65.461,97.946,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.323 | Acc: 65.424,97.950,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.321 | Acc: 65.438,97.889,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.318 | Acc: 65.470,97.850,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.321 | Acc: 65.266,97.870,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.323 | Acc: 65.314,97.863,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.327 | Acc: 65.170,97.843,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.328 | Acc: 65.137,97.879,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.329 | Acc: 65.077,97.854,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.329 | Acc: 65.053,97.881,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.329 | Acc: 65.024,97.873,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.330 | Acc: 64.976,97.872,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.330 | Acc: 65.051,97.890,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.333 | Acc: 64.970,97.885,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.330 | Acc: 65.045,97.899,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.329 | Acc: 65.043,97.923,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.290 | Acc: 54.688,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.273 | Acc: 52.865,68.564,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.303 | Acc: 53.125,68.426,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.269 | Acc: 52.741,68.391,75.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.283 | Acc: 64.844,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.316 | Acc: 64.621,98.214,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.341 | Acc: 64.082,98.190,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.327 | Acc: 64.588,98.245,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.322 | Acc: 64.815,98.225,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.324 | Acc: 64.929,98.213,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.325 | Acc: 64.902,98.199,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.329 | Acc: 64.816,98.111,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.325 | Acc: 64.994,98.088,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.325 | Acc: 65.029,98.053,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.325 | Acc: 65.073,98.014,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.327 | Acc: 64.992,98.073,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.324 | Acc: 65.090,98.091,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.330 | Acc: 64.919,98.084,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.329 | Acc: 64.986,98.087,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.331 | Acc: 64.961,98.064,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.331 | Acc: 64.948,98.046,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.329 | Acc: 65.066,98.057,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.328 | Acc: 65.127,98.059,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.328 | Acc: 65.125,98.060,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.271 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.260 | Acc: 53.311,68.750,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.293 | Acc: 53.296,68.559,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.264 | Acc: 52.792,68.635,75.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.407 | Acc: 63.281,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.277 | Acc: 67.039,97.805,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.279 | Acc: 66.463,98.075,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.294 | Acc: 66.048,98.028,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.309 | Acc: 65.654,98.013,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.328 | Acc: 65.145,97.981,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.325 | Acc: 65.218,97.966,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.330 | Acc: 65.110,97.944,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.331 | Acc: 65.043,97.909,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.331 | Acc: 65.003,97.963,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.333 | Acc: 65.030,97.991,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.333 | Acc: 64.946,97.957,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.331 | Acc: 65.006,97.993,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.332 | Acc: 65.011,98.003,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.331 | Acc: 65.024,98.018,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.328 | Acc: 65.114,98.001,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.328 | Acc: 65.136,97.990,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.329 | Acc: 65.144,97.998,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.329 | Acc: 65.149,98.000,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.328 | Acc: 65.145,97.978,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.285 | Acc: 56.250,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.251 | Acc: 52.976,68.936,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.285 | Acc: 52.915,68.426,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.257 | Acc: 52.549,68.584,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.313 | Acc: 64.062,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.310 | Acc: 64.397,98.326,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.315 | Acc: 65.320,98.056,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.320 | Acc: 65.087,98.053,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.329 | Acc: 64.738,98.061,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.329 | Acc: 64.766,98.043,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.322 | Acc: 64.947,98.089,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.327 | Acc: 64.883,98.061,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.330 | Acc: 64.844,98.044,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.334 | Acc: 64.757,98.053,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.335 | Acc: 64.743,98.037,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.336 | Acc: 64.727,98.003,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.342 | Acc: 64.669,97.997,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.340 | Acc: 64.703,97.989,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.337 | Acc: 64.755,97.973,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.336 | Acc: 64.794,97.986,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.335 | Acc: 64.815,97.985,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.336 | Acc: 64.764,97.975,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.332 | Acc: 64.876,98.007,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.331 | Acc: 64.946,97.976,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.247 | Acc: 53.906,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.248 | Acc: 53.423,68.787,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.282 | Acc: 53.392,68.579,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.260 | Acc: 52.843,68.673,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.254 | Acc: 68.750,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.339 | Acc: 64.100,97.954,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.350 | Acc: 63.948,97.866,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.360 | Acc: 63.896,97.836,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.346 | Acc: 64.255,97.965,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.348 | Acc: 64.356,97.950,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.338 | Acc: 64.657,98.069,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.329 | Acc: 65.071,98.039,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.336 | Acc: 64.965,97.996,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.335 | Acc: 64.874,97.989,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.329 | Acc: 64.995,97.998,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.330 | Acc: 65.098,98.017,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.328 | Acc: 65.174,98.000,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.327 | Acc: 65.218,97.997,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.326 | Acc: 65.250,98.001,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.327 | Acc: 65.254,98.001,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.328 | Acc: 65.177,98.009,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.332 | Acc: 65.048,98.000,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.329 | Acc: 65.173,98.020,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.331 | Acc: 65.108,98.013,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.271 | Acc: 53.906,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.268 | Acc: 52.641,68.527,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.290 | Acc: 53.144,68.331,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.263 | Acc: 52.754,68.622,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.155 | Acc: 75.781,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.237 | Acc: 67.783,98.475,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.270 | Acc: 67.035,98.228,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.298 | Acc: 66.112,98.181,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.307 | Acc: 65.856,98.216,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.315 | Acc: 65.579,98.244,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.319 | Acc: 65.405,98.192,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.320 | Acc: 65.304,98.260,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.319 | Acc: 65.411,98.277,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.318 | Acc: 65.543,98.226,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.316 | Acc: 65.574,98.193,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.318 | Acc: 65.462,98.169,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.324 | Acc: 65.259,98.107,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.324 | Acc: 65.254,98.081,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.326 | Acc: 65.161,98.101,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.328 | Acc: 65.129,98.105,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.329 | Acc: 65.048,98.099,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.329 | Acc: 65.052,98.073,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.328 | Acc: 65.082,98.083,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.328 | Acc: 65.045,98.073,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.259 | Acc: 55.469,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.266 | Acc: 52.865,68.638,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.293 | Acc: 53.125,68.407,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.263 | Acc: 52.805,68.660,75.038,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.283 | Acc: 70.312,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.300 | Acc: 65.216,98.214,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.307 | Acc: 65.530,98.304,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.311 | Acc: 65.433,98.373,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.313 | Acc: 65.365,98.225,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.320 | Acc: 65.200,98.291,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.312 | Acc: 65.444,98.263,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.309 | Acc: 65.525,98.293,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.312 | Acc: 65.368,98.253,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.316 | Acc: 65.241,98.204,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.319 | Acc: 65.116,98.220,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.320 | Acc: 65.028,98.208,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.320 | Acc: 65.041,98.204,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.322 | Acc: 64.975,98.165,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.320 | Acc: 65.030,98.151,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.318 | Acc: 65.083,98.152,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.320 | Acc: 65.048,98.170,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.321 | Acc: 65.052,98.156,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.324 | Acc: 64.924,98.137,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.326 | Acc: 64.815,98.144,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.259 | Acc: 54.688,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.260 | Acc: 53.199,68.936,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.297 | Acc: 53.487,68.369,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.266 | Acc: 53.048,68.571,75.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.240 | Acc: 67.188,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.302 | Acc: 65.774,98.475,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.333 | Acc: 65.015,98.056,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.311 | Acc: 65.407,98.130,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.313 | Acc: 65.307,98.187,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.315 | Acc: 65.215,98.167,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.313 | Acc: 65.386,98.134,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.320 | Acc: 65.315,98.094,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.325 | Acc: 65.305,98.044,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.317 | Acc: 65.483,98.023,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.319 | Acc: 65.446,98.022,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.318 | Acc: 65.452,98.010,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.322 | Acc: 65.349,98.016,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.326 | Acc: 65.125,98.012,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.328 | Acc: 65.022,98.026,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.326 | Acc: 65.044,98.040,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.326 | Acc: 65.068,98.063,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.327 | Acc: 65.057,98.062,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.326 | Acc: 65.041,98.070,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.328 | Acc: 64.961,98.073,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.210 | Acc: 56.250,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.256 | Acc: 53.199,69.382,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.288 | Acc: 53.316,68.845,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.259 | Acc: 53.010,68.904,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.368 | Acc: 57.812,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.324 | Acc: 64.211,98.586,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.316 | Acc: 65.111,98.457,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.319 | Acc: 65.241,98.181,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.315 | Acc: 65.345,98.177,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.312 | Acc: 65.238,98.190,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.314 | Acc: 65.425,98.076,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.307 | Acc: 65.597,98.144,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.311 | Acc: 65.489,98.108,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.309 | Acc: 65.431,98.170,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.310 | Acc: 65.411,98.173,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.313 | Acc: 65.282,98.183,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.318 | Acc: 65.217,98.185,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.320 | Acc: 65.137,98.174,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.320 | Acc: 65.150,98.165,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.321 | Acc: 65.098,98.129,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.322 | Acc: 65.073,98.141,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.324 | Acc: 65.066,98.114,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.323 | Acc: 65.075,98.102,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.325 | Acc: 65.041,98.118,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.264 | Acc: 54.688,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.259 | Acc: 53.423,68.899,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.299 | Acc: 53.316,68.502,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.272 | Acc: 53.087,68.571,75.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.376 | Acc: 58.594,98.438,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.297 | Acc: 65.960,98.698,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.311 | Acc: 65.511,98.438,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.307 | Acc: 65.382,98.271,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.302 | Acc: 65.596,98.293,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.299 | Acc: 65.811,98.291,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.300 | Acc: 65.767,98.270,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.304 | Acc: 65.747,98.172,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.304 | Acc: 65.717,98.171,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.307 | Acc: 65.599,98.174,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.307 | Acc: 65.551,98.158,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.308 | Acc: 65.576,98.155,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.309 | Acc: 65.609,98.100,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.315 | Acc: 65.445,98.084,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.314 | Acc: 65.353,98.126,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.316 | Acc: 65.288,98.118,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.316 | Acc: 65.279,98.141,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.319 | Acc: 65.245,98.144,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.321 | Acc: 65.235,98.122,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.323 | Acc: 65.164,98.116,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.217 | Acc: 55.469,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.273 | Acc: 53.162,68.973,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.301 | Acc: 53.163,68.598,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.276 | Acc: 52.843,68.558,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.483 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.293 | Acc: 66.704,98.140,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.326 | Acc: 64.920,97.980,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.329 | Acc: 64.677,98.092,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.323 | Acc: 64.892,98.052,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.330 | Acc: 64.774,98.074,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.329 | Acc: 64.708,98.024,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.317 | Acc: 65.054,98.055,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.318 | Acc: 65.004,98.074,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.322 | Acc: 64.913,98.066,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.325 | Acc: 64.782,98.057,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.326 | Acc: 64.745,98.056,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.326 | Acc: 64.792,98.042,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.325 | Acc: 64.853,98.006,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.321 | Acc: 65.044,98.012,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.322 | Acc: 65.031,97.983,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.323 | Acc: 65.000,97.987,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.321 | Acc: 65.006,98.007,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.322 | Acc: 64.935,98.022,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.321 | Acc: 64.965,98.040,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.289 | Acc: 53.906,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.269 | Acc: 52.902,68.452,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.299 | Acc: 53.258,68.350,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.276 | Acc: 52.920,68.468,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.509 | Acc: 56.250,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.281 | Acc: 66.109,98.065,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.310 | Acc: 64.806,98.323,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.306 | Acc: 65.561,98.309,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.312 | Acc: 65.403,98.254,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.303 | Acc: 65.540,98.399,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.304 | Acc: 65.470,98.386,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.301 | Acc: 65.592,98.371,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.305 | Acc: 65.509,98.350,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.304 | Acc: 65.690,98.312,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.306 | Acc: 65.660,98.274,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.311 | Acc: 65.448,98.293,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.312 | Acc: 65.424,98.305,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.313 | Acc: 65.329,98.303,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.312 | Acc: 65.416,98.293,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.313 | Acc: 65.415,98.256,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.317 | Acc: 65.316,98.238,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.316 | Acc: 65.332,98.229,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.319 | Acc: 65.233,98.234,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.321 | Acc: 65.164,98.212,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.231 | Acc: 55.469,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.257 | Acc: 53.423,69.048,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.297 | Acc: 53.430,68.579,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.271 | Acc: 52.933,68.827,74.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.536 | Acc: 57.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.345 | Acc: 63.876,98.400,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.352 | Acc: 64.139,98.285,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.341 | Acc: 64.613,98.040,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.341 | Acc: 64.670,98.148,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.335 | Acc: 64.442,98.252,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.328 | Acc: 64.753,98.263,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.324 | Acc: 64.988,98.255,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.317 | Acc: 65.159,98.263,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.312 | Acc: 65.336,98.304,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.316 | Acc: 65.135,98.309,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.315 | Acc: 65.077,98.296,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.314 | Acc: 65.181,98.282,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.316 | Acc: 65.143,98.321,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.318 | Acc: 65.100,98.257,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.317 | Acc: 65.090,98.232,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.320 | Acc: 65.009,98.214,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.321 | Acc: 65.009,98.202,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.318 | Acc: 65.127,98.212,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.320 | Acc: 65.104,98.212,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.236 | Acc: 54.688,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.268 | Acc: 53.199,68.899,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.306 | Acc: 53.163,68.464,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.278 | Acc: 52.920,68.660,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.206 | Acc: 68.750,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.305 | Acc: 65.848,98.289,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.289 | Acc: 66.387,98.323,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.293 | Acc: 66.150,98.322,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.309 | Acc: 65.741,98.235,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.305 | Acc: 65.416,98.128,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.305 | Acc: 65.631,98.082,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.308 | Acc: 65.320,98.183,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.314 | Acc: 65.082,98.209,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.322 | Acc: 64.878,98.187,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.321 | Acc: 64.875,98.231,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.320 | Acc: 64.939,98.236,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.322 | Acc: 64.873,98.204,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.321 | Acc: 64.919,98.180,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.324 | Acc: 64.822,98.176,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.324 | Acc: 64.828,98.191,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.322 | Acc: 64.844,98.177,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.319 | Acc: 64.940,98.160,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.319 | Acc: 64.971,98.167,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.317 | Acc: 65.022,98.173,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.234 | Acc: 53.125,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 52.939,68.713,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.308 | Acc: 53.049,68.502,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.282 | Acc: 52.715,68.596,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.331 | Acc: 64.062,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.307 | Acc: 64.174,97.954,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.311 | Acc: 64.958,98.018,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.297 | Acc: 65.548,98.079,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.313 | Acc: 65.046,98.110,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.317 | Acc: 65.084,98.089,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.314 | Acc: 65.315,98.140,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.312 | Acc: 65.154,98.166,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.310 | Acc: 65.179,98.161,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.305 | Acc: 65.237,98.187,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.302 | Acc: 65.361,98.200,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.302 | Acc: 65.360,98.190,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.307 | Acc: 65.259,98.185,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.307 | Acc: 65.335,98.162,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.308 | Acc: 65.353,98.182,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.308 | Acc: 65.386,98.196,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.307 | Acc: 65.408,98.211,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.307 | Acc: 65.375,98.208,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.310 | Acc: 65.305,98.202,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.311 | Acc: 65.258,98.200,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.214 | Acc: 54.688,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.282 | Acc: 52.865,68.676,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.304 | Acc: 53.258,68.540,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.279 | Acc: 52.766,68.686,75.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.519 | Acc: 58.594,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.301 | Acc: 64.397,98.177,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.291 | Acc: 65.530,98.438,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.287 | Acc: 65.676,98.450,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.288 | Acc: 65.509,98.544,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.301 | Acc: 65.362,98.438,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.299 | Acc: 65.548,98.379,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.304 | Acc: 65.619,98.305,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.300 | Acc: 65.698,98.306,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.302 | Acc: 65.668,98.299,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.301 | Acc: 65.676,98.278,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.307 | Acc: 65.540,98.275,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.307 | Acc: 65.430,98.256,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.309 | Acc: 65.272,98.273,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.311 | Acc: 65.230,98.268,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.313 | Acc: 65.124,98.266,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.315 | Acc: 65.146,98.248,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.314 | Acc: 65.224,98.243,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.317 | Acc: 65.149,98.219,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.314 | Acc: 65.231,98.234,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.229 | Acc: 56.250,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.288 | Acc: 53.423,68.601,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.318 | Acc: 53.316,68.350,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.285 | Acc: 52.946,68.532,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.148 | Acc: 71.094,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.292 | Acc: 65.885,98.475,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.282 | Acc: 66.044,98.399,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.299 | Acc: 65.459,98.297,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.292 | Acc: 65.664,98.351,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.298 | Acc: 65.633,98.345,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.294 | Acc: 65.754,98.399,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.299 | Acc: 65.531,98.432,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.295 | Acc: 65.557,98.462,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.295 | Acc: 65.595,98.390,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.300 | Acc: 65.493,98.375,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.301 | Acc: 65.540,98.356,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.303 | Acc: 65.499,98.314,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.303 | Acc: 65.478,98.330,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.303 | Acc: 65.511,98.301,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.304 | Acc: 65.558,98.292,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.305 | Acc: 65.491,98.304,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.311 | Acc: 65.279,98.289,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.312 | Acc: 65.283,98.267,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.313 | Acc: 65.233,98.269,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.191 | Acc: 54.688,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.268 | Acc: 53.051,68.490,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.312 | Acc: 53.411,68.407,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.286 | Acc: 52.997,68.494,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.330 | Acc: 66.406,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.358 | Acc: 63.690,98.363,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.328 | Acc: 64.558,98.342,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.310 | Acc: 64.805,98.425,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.325 | Acc: 64.371,98.438,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.315 | Acc: 64.913,98.376,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.312 | Acc: 65.044,98.354,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.313 | Acc: 65.143,98.360,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.313 | Acc: 65.203,98.297,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.313 | Acc: 65.189,98.312,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.310 | Acc: 65.201,98.301,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.319 | Acc: 65.063,98.225,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.318 | Acc: 65.110,98.227,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.322 | Acc: 64.993,98.207,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.321 | Acc: 65.024,98.196,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.317 | Acc: 65.129,98.214,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.316 | Acc: 65.189,98.218,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.315 | Acc: 65.291,98.220,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.315 | Acc: 65.270,98.228,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.316 | Acc: 65.293,98.224,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.220 | Acc: 56.250,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 53.199,68.527,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.318 | Acc: 53.182,68.350,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.286 | Acc: 52.984,68.507,75.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.420 | Acc: 63.281,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.292 | Acc: 65.625,98.586,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.296 | Acc: 65.739,98.380,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.303 | Acc: 65.266,98.245,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.315 | Acc: 65.066,98.312,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.318 | Acc: 64.882,98.275,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.307 | Acc: 65.328,98.270,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.310 | Acc: 65.337,98.321,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.308 | Acc: 65.411,98.321,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.312 | Acc: 65.375,98.312,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.313 | Acc: 65.372,98.348,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.314 | Acc: 65.360,98.314,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.310 | Acc: 65.518,98.314,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.309 | Acc: 65.520,98.288,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.307 | Acc: 65.508,98.307,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.309 | Acc: 65.423,98.323,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.308 | Acc: 65.365,98.330,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.307 | Acc: 65.426,98.330,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.308 | Acc: 65.380,98.316,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.308 | Acc: 65.299,98.302,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.219 | Acc: 57.031,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 53.199,68.341,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.325 | Acc: 53.106,68.312,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.298 | Acc: 52.805,68.507,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.094 | Acc: 71.094,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.325 | Acc: 65.737,98.326,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.323 | Acc: 65.644,98.285,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.328 | Acc: 65.241,98.271,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.335 | Acc: 65.345,98.235,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.325 | Acc: 65.648,98.275,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.330 | Acc: 65.173,98.224,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.327 | Acc: 65.215,98.194,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.326 | Acc: 65.217,98.209,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.319 | Acc: 65.344,98.179,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.317 | Acc: 65.462,98.111,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.317 | Acc: 65.434,98.105,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.314 | Acc: 65.456,98.078,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.315 | Acc: 65.430,98.090,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.318 | Acc: 65.350,98.068,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.319 | Acc: 65.337,98.077,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.321 | Acc: 65.275,98.104,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.321 | Acc: 65.277,98.092,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.318 | Acc: 65.352,98.100,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.318 | Acc: 65.395,98.101,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.280 | Acc: 54.688,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 53.311,68.415,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.322 | Acc: 53.239,68.464,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.290 | Acc: 52.959,68.660,74.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.310 | Acc: 64.062,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.324 | Acc: 64.769,98.065,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.338 | Acc: 64.444,98.323,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.341 | Acc: 64.485,98.181,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.331 | Acc: 64.805,98.216,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.317 | Acc: 65.316,98.376,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.306 | Acc: 65.677,98.399,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.311 | Acc: 65.470,98.354,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.308 | Acc: 65.610,98.321,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.305 | Acc: 65.763,98.317,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.311 | Acc: 65.532,98.286,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.310 | Acc: 65.558,98.307,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.319 | Acc: 65.265,98.269,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.316 | Acc: 65.386,98.261,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.316 | Acc: 65.375,98.279,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.316 | Acc: 65.293,98.300,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.314 | Acc: 65.326,98.301,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.312 | Acc: 65.313,98.316,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.313 | Acc: 65.257,98.318,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.314 | Acc: 65.283,98.319,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.231 | Acc: 56.250,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 52.976,68.824,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.326 | Acc: 53.316,68.464,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.289 | Acc: 52.907,68.571,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.307 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.294 | Acc: 65.774,98.475,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.334 | Acc: 64.348,98.209,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.320 | Acc: 65.087,98.284,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.320 | Acc: 65.017,98.225,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.324 | Acc: 64.867,98.244,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.316 | Acc: 65.076,98.283,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.313 | Acc: 65.337,98.271,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.315 | Acc: 65.188,98.277,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.314 | Acc: 65.185,98.278,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.316 | Acc: 65.213,98.282,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.313 | Acc: 65.236,98.310,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.312 | Acc: 65.268,98.292,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.315 | Acc: 65.086,98.273,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.316 | Acc: 65.061,98.301,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.314 | Acc: 65.106,98.326,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.312 | Acc: 65.184,98.333,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.310 | Acc: 65.231,98.323,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.310 | Acc: 65.227,98.331,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.312 | Acc: 65.166,98.312,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.216 | Acc: 53.125,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 53.125,68.564,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.317 | Acc: 53.163,68.369,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.290 | Acc: 52.946,68.532,75.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.216 | Acc: 65.625,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.315 | Acc: 65.551,98.289,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.318 | Acc: 64.920,98.361,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.320 | Acc: 64.754,98.284,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.303 | Acc: 65.075,98.389,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.294 | Acc: 65.354,98.453,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.295 | Acc: 65.599,98.431,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.298 | Acc: 65.570,98.421,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.299 | Acc: 65.509,98.408,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.299 | Acc: 65.452,98.377,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.304 | Acc: 65.345,98.344,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.305 | Acc: 65.381,98.324,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.306 | Acc: 65.346,98.331,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.305 | Acc: 65.412,98.342,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.306 | Acc: 65.436,98.318,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.312 | Acc: 65.228,98.290,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.311 | Acc: 65.294,98.279,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.311 | Acc: 65.327,98.273,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.313 | Acc: 65.320,98.258,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.313 | Acc: 65.301,98.276,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.227 | Acc: 55.469,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.281 | Acc: 53.274,68.824,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.314 | Acc: 53.125,68.407,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.293 | Acc: 52.651,68.443,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.351 | Acc: 65.625,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.323 | Acc: 65.067,98.103,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.307 | Acc: 65.682,98.018,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.304 | Acc: 65.548,98.117,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.307 | Acc: 65.856,98.206,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.308 | Acc: 65.741,98.298,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.306 | Acc: 65.709,98.373,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.302 | Acc: 65.752,98.371,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.298 | Acc: 65.717,98.389,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.300 | Acc: 65.720,98.377,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.303 | Acc: 65.765,98.403,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.300 | Acc: 65.844,98.377,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.299 | Acc: 65.781,98.382,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.301 | Acc: 65.745,98.384,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.301 | Acc: 65.697,98.396,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.304 | Acc: 65.651,98.391,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.305 | Acc: 65.615,98.374,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.305 | Acc: 65.655,98.378,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.306 | Acc: 65.577,98.338,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.307 | Acc: 65.494,98.321,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.301 | Acc: 55.469,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.285 | Acc: 53.237,68.787,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.317 | Acc: 53.220,68.407,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.292 | Acc: 52.894,68.507,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.367 | Acc: 62.500,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.277 | Acc: 65.625,98.624,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.272 | Acc: 65.930,98.552,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.281 | Acc: 65.817,98.425,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.281 | Acc: 65.905,98.360,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.287 | Acc: 65.942,98.306,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.285 | Acc: 65.999,98.302,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.293 | Acc: 65.836,98.305,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.299 | Acc: 65.790,98.273,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.297 | Acc: 65.858,98.286,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.299 | Acc: 65.835,98.266,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.304 | Acc: 65.724,98.243,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.305 | Acc: 65.771,98.243,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.308 | Acc: 65.619,98.228,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.309 | Acc: 65.555,98.254,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.308 | Acc: 65.498,98.245,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.309 | Acc: 65.442,98.216,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.309 | Acc: 65.398,98.215,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.309 | Acc: 65.378,98.210,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.309 | Acc: 65.434,98.208,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.292 | Acc: 54.688,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.288 | Acc: 52.939,68.527,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.317 | Acc: 53.068,68.350,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.289 | Acc: 52.933,68.519,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.192 | Acc: 67.188,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.292 | Acc: 65.588,98.772,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.304 | Acc: 65.492,98.685,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.300 | Acc: 65.625,98.604,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.309 | Acc: 65.297,98.582,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.305 | Acc: 65.370,98.507,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.301 | Acc: 65.683,98.521,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.301 | Acc: 65.592,98.449,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.300 | Acc: 65.596,98.496,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.301 | Acc: 65.595,98.468,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.299 | Acc: 65.683,98.461,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.303 | Acc: 65.689,98.441,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.300 | Acc: 65.693,98.444,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.302 | Acc: 65.691,98.426,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.299 | Acc: 65.720,98.451,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.299 | Acc: 65.692,98.427,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.301 | Acc: 65.659,98.418,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.303 | Acc: 65.588,98.408,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.304 | Acc: 65.580,98.379,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.304 | Acc: 65.580,98.378,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.254 | Acc: 56.250,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 53.534,68.266,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.324 | Acc: 53.373,68.293,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.293 | Acc: 52.882,68.494,75.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.391 | Acc: 63.281,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.280 | Acc: 64.993,98.289,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.292 | Acc: 65.377,98.399,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.293 | Acc: 65.356,98.399,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.312 | Acc: 64.959,98.360,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.306 | Acc: 65.045,98.368,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.309 | Acc: 65.115,98.347,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.313 | Acc: 65.038,98.365,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.311 | Acc: 65.096,98.331,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.312 | Acc: 65.073,98.325,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.315 | Acc: 65.108,98.282,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.315 | Acc: 65.066,98.285,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.311 | Acc: 65.100,98.301,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.310 | Acc: 65.149,98.306,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.308 | Acc: 65.125,98.304,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.307 | Acc: 65.223,98.318,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.310 | Acc: 65.102,98.301,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.308 | Acc: 65.132,98.314,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.308 | Acc: 65.123,98.308,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.306 | Acc: 65.225,98.314,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.307 | Acc: 54.688,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.306 | Acc: 52.939,69.159,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.338 | Acc: 53.030,68.636,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.303 | Acc: 52.830,68.776,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.391 | Acc: 66.406,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.240 | Acc: 67.448,98.400,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.270 | Acc: 66.635,98.342,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.287 | Acc: 66.304,98.450,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.286 | Acc: 66.049,98.447,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.293 | Acc: 65.996,98.329,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.294 | Acc: 66.012,98.366,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.291 | Acc: 66.046,98.404,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.291 | Acc: 65.916,98.394,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.290 | Acc: 65.988,98.446,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.290 | Acc: 66.045,98.441,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.289 | Acc: 66.010,98.466,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.290 | Acc: 65.930,98.454,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.292 | Acc: 65.799,98.440,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.293 | Acc: 65.725,98.429,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.294 | Acc: 65.726,98.419,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.295 | Acc: 65.720,98.394,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.298 | Acc: 65.707,98.360,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.299 | Acc: 65.740,98.364,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.300 | Acc: 65.717,98.364,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.309 | Acc: 55.469,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.293 | Acc: 52.716,68.936,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 53.049,68.674,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 52.894,68.801,74.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 1.137 | Acc: 68.750,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.261 | Acc: 66.295,98.363,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.294 | Acc: 65.320,98.457,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.295 | Acc: 65.305,98.386,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.307 | Acc: 65.143,98.409,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.309 | Acc: 65.060,98.422,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.308 | Acc: 65.276,98.457,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.312 | Acc: 65.176,98.415,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.308 | Acc: 65.271,98.370,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.302 | Acc: 65.366,98.330,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.300 | Acc: 65.337,98.340,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.298 | Acc: 65.353,98.335,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.298 | Acc: 65.239,98.321,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.298 | Acc: 65.278,98.336,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.300 | Acc: 65.333,98.368,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.299 | Acc: 65.293,98.378,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.298 | Acc: 65.352,98.367,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.299 | Acc: 65.387,98.353,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.300 | Acc: 65.370,98.370,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.301 | Acc: 65.356,98.362,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.266 | Acc: 57.031,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.292 | Acc: 53.088,68.676,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.324 | Acc: 52.954,68.331,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.294 | Acc: 52.843,68.468,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.266 | Acc: 66.406,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.335 | Acc: 64.881,97.879,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.306 | Acc: 65.034,98.133,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.316 | Acc: 65.113,98.015,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.323 | Acc: 64.931,98.061,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.309 | Acc: 65.161,98.190,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.306 | Acc: 65.218,98.192,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.310 | Acc: 65.215,98.088,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.312 | Acc: 65.378,98.151,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.309 | Acc: 65.366,98.170,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.305 | Acc: 65.590,98.165,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.307 | Acc: 65.597,98.165,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.306 | Acc: 65.593,98.178,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.304 | Acc: 65.664,98.189,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.304 | Acc: 65.631,98.207,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.303 | Acc: 65.682,98.212,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.304 | Acc: 65.606,98.206,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.304 | Acc: 65.620,98.218,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.306 | Acc: 65.532,98.206,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.308 | Acc: 65.459,98.226,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.277 | Acc: 54.688,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.299 | Acc: 52.902,68.452,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.335 | Acc: 52.782,68.350,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.304 | Acc: 52.549,68.494,75.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.097 | Acc: 69.531,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.282 | Acc: 65.439,98.512,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.281 | Acc: 65.320,98.704,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.280 | Acc: 65.663,98.694,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.284 | Acc: 65.750,98.669,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.287 | Acc: 65.687,98.662,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.288 | Acc: 65.619,98.663,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.291 | Acc: 65.564,98.576,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.291 | Acc: 65.693,98.535,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.292 | Acc: 65.729,98.459,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.292 | Acc: 65.644,98.476,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.292 | Acc: 65.703,98.487,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.292 | Acc: 65.667,98.483,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.290 | Acc: 65.670,98.500,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.292 | Acc: 65.675,98.501,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.290 | Acc: 65.731,98.476,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.288 | Acc: 65.752,98.491,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.289 | Acc: 65.714,98.490,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.290 | Acc: 65.653,98.476,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.291 | Acc: 65.598,98.452,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.212 | Acc: 57.031,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.292 | Acc: 52.939,68.973,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.325 | Acc: 53.087,68.598,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.293 | Acc: 52.830,68.712,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.520 | Acc: 60.938,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.257 | Acc: 66.741,98.214,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.291 | Acc: 65.339,98.304,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.288 | Acc: 65.446,98.438,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.279 | Acc: 65.943,98.515,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.283 | Acc: 65.795,98.561,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.283 | Acc: 65.793,98.612,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.282 | Acc: 65.808,98.543,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.282 | Acc: 65.766,98.544,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.286 | Acc: 65.638,98.520,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.290 | Acc: 65.582,98.507,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.290 | Acc: 65.551,98.501,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.290 | Acc: 65.469,98.480,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.288 | Acc: 65.457,98.473,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.288 | Acc: 65.564,98.457,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.291 | Acc: 65.490,98.461,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.291 | Acc: 65.501,98.476,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.293 | Acc: 65.499,98.449,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.292 | Acc: 65.510,98.442,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.292 | Acc: 65.531,98.415,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.239 | Acc: 57.031,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 53.199,68.638,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.323 | Acc: 53.182,68.521,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.294 | Acc: 52.843,68.712,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.016 | Acc: 72.656,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.259 | Acc: 67.001,98.996,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.254 | Acc: 67.168,98.685,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.278 | Acc: 66.086,98.604,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.279 | Acc: 66.049,98.563,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.269 | Acc: 66.282,98.600,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.269 | Acc: 66.284,98.573,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.277 | Acc: 66.096,98.471,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.283 | Acc: 65.945,98.442,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.280 | Acc: 65.966,98.450,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.285 | Acc: 65.955,98.441,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.289 | Acc: 65.777,98.420,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.288 | Acc: 65.687,98.402,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.287 | Acc: 65.679,98.387,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.288 | Acc: 65.686,98.387,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.288 | Acc: 65.687,98.406,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.285 | Acc: 65.810,98.433,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.285 | Acc: 65.822,98.405,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.286 | Acc: 65.805,98.403,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.285 | Acc: 65.871,98.399,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.297 | Acc: 53.906,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 52.418,68.452,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 52.706,68.274,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.295 | Acc: 52.523,68.443,74.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.494 | Acc: 59.375,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.265 | Acc: 66.629,98.549,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.277 | Acc: 65.835,98.552,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.281 | Acc: 65.984,98.450,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.291 | Acc: 65.934,98.466,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.304 | Acc: 65.664,98.399,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.300 | Acc: 65.748,98.450,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.295 | Acc: 65.858,98.410,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.289 | Acc: 65.868,98.452,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.291 | Acc: 65.867,98.420,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.291 | Acc: 65.792,98.438,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.290 | Acc: 65.713,98.434,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.291 | Acc: 65.612,98.415,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.289 | Acc: 65.763,98.408,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.288 | Acc: 65.817,98.396,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.289 | Acc: 65.830,98.396,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.290 | Acc: 65.798,98.347,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.290 | Acc: 65.785,98.346,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.290 | Acc: 65.759,98.353,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.288 | Acc: 65.820,98.366,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.292 | Acc: 55.469,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.303 | Acc: 53.274,68.564,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 53.316,68.445,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.294 | Acc: 52.933,68.545,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.414 | Acc: 65.625,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.343 | Acc: 64.286,98.140,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.325 | Acc: 64.386,98.266,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.296 | Acc: 65.138,98.373,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.298 | Acc: 65.143,98.409,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.298 | Acc: 65.254,98.422,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.304 | Acc: 65.121,98.463,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.300 | Acc: 65.198,98.415,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.297 | Acc: 65.431,98.389,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.296 | Acc: 65.448,98.377,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.297 | Acc: 65.403,98.395,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.298 | Acc: 65.413,98.409,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.292 | Acc: 65.547,98.441,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.291 | Acc: 65.640,98.438,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.291 | Acc: 65.667,98.424,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.290 | Acc: 65.646,98.409,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.291 | Acc: 65.608,98.413,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.290 | Acc: 65.698,98.401,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.289 | Acc: 65.683,98.401,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.288 | Acc: 65.707,98.409,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.302 | Acc: 55.469,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.291 | Acc: 53.237,68.601,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 53.125,68.274,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.289 | Acc: 52.997,68.584,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.051 | Acc: 74.219,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.285 | Acc: 65.997,98.400,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.280 | Acc: 66.482,98.418,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.275 | Acc: 66.419,98.425,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.284 | Acc: 66.117,98.428,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.287 | Acc: 65.888,98.407,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.294 | Acc: 65.438,98.418,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.299 | Acc: 65.348,98.421,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.296 | Acc: 65.421,98.481,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.297 | Acc: 65.487,98.485,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.294 | Acc: 65.574,98.465,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.290 | Acc: 65.664,98.459,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.290 | Acc: 65.735,98.473,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.293 | Acc: 65.700,98.443,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.289 | Acc: 65.756,98.471,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.290 | Acc: 65.687,98.466,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.290 | Acc: 65.669,98.469,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.287 | Acc: 65.804,98.440,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.287 | Acc: 65.798,98.446,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.287 | Acc: 65.769,98.442,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.276 | Acc: 56.250,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.296 | Acc: 52.865,68.676,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.320 | Acc: 53.163,68.464,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.290 | Acc: 52.946,68.699,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.434 | Acc: 60.156,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.384 | Acc: 62.946,98.586,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.333 | Acc: 64.386,98.495,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.323 | Acc: 64.690,98.271,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.307 | Acc: 64.911,98.312,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.309 | Acc: 64.821,98.291,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.308 | Acc: 64.889,98.334,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.308 | Acc: 64.866,98.327,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.303 | Acc: 64.931,98.326,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.300 | Acc: 64.982,98.360,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.305 | Acc: 64.910,98.340,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.300 | Acc: 65.056,98.356,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.298 | Acc: 65.200,98.360,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.297 | Acc: 65.257,98.372,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.296 | Acc: 65.355,98.374,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.295 | Acc: 65.454,98.367,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.293 | Acc: 65.528,98.394,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.295 | Acc: 65.490,98.399,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.294 | Acc: 65.486,98.377,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.292 | Acc: 65.537,98.378,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.288 | Acc: 53.906,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.296 | Acc: 53.348,68.601,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 53.296,68.407,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 52.907,68.648,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 1.125 | Acc: 71.875,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.298 | Acc: 64.769,98.363,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.302 | Acc: 65.015,98.304,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.292 | Acc: 65.651,98.335,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.282 | Acc: 65.664,98.476,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.275 | Acc: 65.710,98.492,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.282 | Acc: 65.554,98.483,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.285 | Acc: 65.431,98.498,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.288 | Acc: 65.411,98.520,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.293 | Acc: 65.392,98.532,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.290 | Acc: 65.442,98.511,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.289 | Acc: 65.402,98.551,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.291 | Acc: 65.460,98.535,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.291 | Acc: 65.487,98.527,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.289 | Acc: 65.544,98.543,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.285 | Acc: 65.646,98.534,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.287 | Acc: 65.581,98.532,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.287 | Acc: 65.636,98.525,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.290 | Acc: 65.588,98.507,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.291 | Acc: 65.576,98.485,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.237 | Acc: 55.469,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.297 | Acc: 52.902,68.415,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.323 | Acc: 52.973,68.216,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.291 | Acc: 52.971,68.455,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.471 | Acc: 60.156,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.269 | Acc: 66.183,98.921,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.288 | Acc: 66.044,98.533,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.283 | Acc: 66.355,98.630,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.280 | Acc: 66.030,98.698,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.282 | Acc: 65.702,98.646,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.281 | Acc: 65.774,98.676,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.287 | Acc: 65.525,98.709,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.286 | Acc: 65.499,98.680,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.287 | Acc: 65.530,98.675,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.285 | Acc: 65.609,98.671,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.285 | Acc: 65.643,98.639,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.288 | Acc: 65.609,98.638,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.291 | Acc: 65.538,98.650,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.293 | Acc: 65.489,98.613,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.292 | Acc: 65.511,98.598,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.291 | Acc: 65.520,98.596,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.293 | Acc: 65.531,98.568,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.293 | Acc: 65.530,98.570,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.291 | Acc: 65.633,98.563,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.250 | Acc: 56.250,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.296 | Acc: 53.013,68.676,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.324 | Acc: 53.373,68.502,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.293 | Acc: 53.138,68.584,74.936,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.426 | Acc: 64.062,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.335 | Acc: 65.104,98.661,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.297 | Acc: 66.063,98.399,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.294 | Acc: 65.996,98.399,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.295 | Acc: 65.905,98.360,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.293 | Acc: 65.873,98.399,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.288 | Acc: 66.012,98.444,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.289 | Acc: 65.902,98.487,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.293 | Acc: 65.848,98.486,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.297 | Acc: 65.819,98.515,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.293 | Acc: 65.994,98.492,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.293 | Acc: 65.890,98.512,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.292 | Acc: 65.852,98.509,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.290 | Acc: 65.930,98.488,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.291 | Acc: 65.836,98.488,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.289 | Acc: 65.898,98.474,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.290 | Acc: 65.941,98.474,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.289 | Acc: 65.895,98.488,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.290 | Acc: 65.870,98.468,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.291 | Acc: 65.844,98.464,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.298 | Acc: 56.250,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.305 | Acc: 52.902,68.304,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.331 | Acc: 53.144,68.216,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 53.010,68.366,74.898,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.503 | Acc: 63.281,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.290 | Acc: 65.960,97.991,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.294 | Acc: 65.720,98.323,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.307 | Acc: 65.010,98.335,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.306 | Acc: 65.104,98.322,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.295 | Acc: 65.370,98.414,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.294 | Acc: 65.386,98.360,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.294 | Acc: 65.470,98.371,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.294 | Acc: 65.513,98.379,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.293 | Acc: 65.616,98.403,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.291 | Acc: 65.664,98.441,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.290 | Acc: 65.667,98.441,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.292 | Acc: 65.609,98.438,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.292 | Acc: 65.661,98.432,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.291 | Acc: 65.733,98.424,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.290 | Acc: 65.757,98.427,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.288 | Acc: 65.773,98.445,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.289 | Acc: 65.728,98.435,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.288 | Acc: 65.789,98.435,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.289 | Acc: 65.807,98.425,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.286 | Acc: 54.688,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 53.013,68.973,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.317 | Acc: 53.049,68.636,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.286 | Acc: 52.959,68.712,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.313 | Acc: 64.062,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.269 | Acc: 66.778,98.289,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.262 | Acc: 66.540,98.457,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.268 | Acc: 65.996,98.450,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.276 | Acc: 66.165,98.418,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.274 | Acc: 66.352,98.407,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.282 | Acc: 66.051,98.438,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.286 | Acc: 65.930,98.421,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.288 | Acc: 65.751,98.447,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.290 | Acc: 65.651,98.481,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.292 | Acc: 65.625,98.496,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.291 | Acc: 65.650,98.462,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.293 | Acc: 65.596,98.450,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.289 | Acc: 65.730,98.482,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.289 | Acc: 65.664,98.446,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.288 | Acc: 65.698,98.453,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.291 | Acc: 65.691,98.457,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.289 | Acc: 65.680,98.465,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.290 | Acc: 65.705,98.468,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.289 | Acc: 65.689,98.474,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.258 | Acc: 57.031,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 53.348,68.601,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.328 | Acc: 53.106,68.274,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 52.920,68.468,74.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.218 | Acc: 67.969,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.292 | Acc: 66.406,98.698,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.278 | Acc: 66.044,98.647,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.291 | Acc: 65.612,98.514,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.298 | Acc: 65.268,98.438,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.289 | Acc: 65.671,98.422,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.290 | Acc: 65.657,98.450,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.281 | Acc: 65.919,98.515,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.282 | Acc: 65.921,98.520,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.286 | Acc: 65.759,98.524,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.288 | Acc: 65.629,98.484,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.288 | Acc: 65.759,98.455,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.290 | Acc: 65.713,98.483,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.291 | Acc: 65.706,98.467,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.292 | Acc: 65.745,98.465,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.290 | Acc: 65.737,98.461,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.291 | Acc: 65.783,98.442,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.292 | Acc: 65.742,98.456,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.288 | Acc: 65.867,98.485,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.287 | Acc: 65.859,98.487,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.250 | Acc: 53.906,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.293 | Acc: 53.237,68.341,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.319 | Acc: 53.296,68.216,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.291 | Acc: 52.959,68.404,74.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.211 | Acc: 69.531,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.286 | Acc: 64.918,98.512,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.280 | Acc: 65.720,98.571,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.279 | Acc: 65.766,98.553,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.283 | Acc: 65.721,98.389,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.286 | Acc: 65.602,98.414,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.292 | Acc: 65.606,98.418,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.293 | Acc: 65.531,98.388,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.295 | Acc: 65.576,98.404,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.294 | Acc: 65.513,98.412,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.295 | Acc: 65.388,98.387,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.293 | Acc: 65.367,98.420,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.292 | Acc: 65.460,98.428,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.295 | Acc: 65.454,98.423,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.294 | Acc: 65.475,98.401,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.295 | Acc: 65.451,98.422,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.295 | Acc: 65.496,98.450,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.295 | Acc: 65.570,98.456,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.293 | Acc: 65.634,98.448,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.293 | Acc: 65.594,98.448,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.288 | Acc: 56.250,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.307 | Acc: 53.199,68.155,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.336 | Acc: 53.277,68.140,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.307 | Acc: 53.074,68.430,74.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.333 | Acc: 64.844,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.304 | Acc: 65.662,97.879,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.300 | Acc: 65.587,98.037,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.307 | Acc: 65.843,98.015,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.297 | Acc: 65.895,98.148,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.300 | Acc: 65.571,98.198,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.302 | Acc: 65.341,98.237,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.296 | Acc: 65.426,98.244,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.299 | Acc: 65.358,98.253,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.302 | Acc: 65.344,98.269,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.295 | Acc: 65.431,98.329,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.293 | Acc: 65.491,98.328,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.296 | Acc: 65.456,98.347,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.295 | Acc: 65.490,98.366,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.290 | Acc: 65.622,98.410,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.290 | Acc: 65.654,98.443,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.286 | Acc: 65.798,98.462,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.287 | Acc: 65.767,98.449,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.286 | Acc: 65.792,98.461,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.285 | Acc: 65.820,98.452,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.263 | Acc: 55.469,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 53.051,68.676,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 53.163,68.236,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.291 | Acc: 52.997,68.391,74.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.407 | Acc: 61.719,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.299 | Acc: 65.885,98.289,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.332 | Acc: 65.053,98.266,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.309 | Acc: 65.318,98.361,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.302 | Acc: 65.606,98.438,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.293 | Acc: 65.865,98.430,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.288 | Acc: 65.864,98.457,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.284 | Acc: 65.836,98.465,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.289 | Acc: 65.601,98.404,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.287 | Acc: 65.707,98.399,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.290 | Acc: 65.711,98.399,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.291 | Acc: 65.653,98.392,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.286 | Acc: 65.690,98.392,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.287 | Acc: 65.583,98.432,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.288 | Acc: 65.625,98.426,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.289 | Acc: 65.534,98.448,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.289 | Acc: 65.559,98.430,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.289 | Acc: 65.554,98.428,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.290 | Acc: 65.551,98.446,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.292 | Acc: 65.539,98.425,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.280 | Acc: 55.469,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.281 | Acc: 52.939,68.676,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.320 | Acc: 52.915,68.312,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.290 | Acc: 52.702,68.468,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.593 | Acc: 64.844,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.293 | Acc: 66.741,98.661,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.294 | Acc: 66.330,98.723,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.294 | Acc: 66.278,98.617,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.286 | Acc: 66.213,98.640,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.288 | Acc: 66.228,98.569,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.284 | Acc: 66.309,98.592,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.287 | Acc: 66.262,98.532,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.289 | Acc: 66.183,98.525,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.282 | Acc: 66.272,98.541,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.284 | Acc: 66.220,98.527,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.286 | Acc: 66.131,98.522,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.287 | Acc: 66.102,98.532,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.288 | Acc: 66.005,98.488,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.288 | Acc: 65.975,98.518,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.289 | Acc: 65.895,98.497,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.293 | Acc: 65.808,98.498,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.290 | Acc: 65.927,98.527,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.292 | Acc: 65.878,98.533,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.291 | Acc: 65.916,98.540,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.276 | Acc: 54.688,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.307 | Acc: 52.827,68.266,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.335 | Acc: 53.030,68.236,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.301 | Acc: 52.779,68.366,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.380 | Acc: 64.062,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.308 | Acc: 65.476,98.772,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.304 | Acc: 65.606,98.552,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.292 | Acc: 65.945,98.591,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.300 | Acc: 65.509,98.573,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.295 | Acc: 65.540,98.584,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.289 | Acc: 65.612,98.592,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.290 | Acc: 65.592,98.587,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.295 | Acc: 65.436,98.569,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.296 | Acc: 65.366,98.515,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.294 | Acc: 65.372,98.515,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.295 | Acc: 65.303,98.512,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.297 | Acc: 65.317,98.470,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.297 | Acc: 65.290,98.494,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.294 | Acc: 65.286,98.496,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.295 | Acc: 65.288,98.495,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.294 | Acc: 65.367,98.491,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.290 | Acc: 65.449,98.506,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.287 | Acc: 65.534,98.511,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.288 | Acc: 65.518,98.511,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.250 | Acc: 53.906,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.297 | Acc: 53.013,68.750,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 53.106,68.426,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.289 | Acc: 52.830,68.571,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.165 | Acc: 69.531,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.285 | Acc: 65.551,98.289,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.267 | Acc: 65.911,98.457,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.265 | Acc: 66.124,98.450,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.255 | Acc: 66.300,98.524,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.258 | Acc: 66.383,98.507,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.269 | Acc: 66.187,98.483,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.270 | Acc: 66.107,98.498,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.274 | Acc: 65.950,98.471,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.277 | Acc: 65.970,98.459,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.283 | Acc: 65.683,98.445,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.286 | Acc: 65.625,98.427,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.285 | Acc: 65.622,98.425,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.283 | Acc: 65.745,98.420,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.286 | Acc: 65.728,98.410,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.291 | Acc: 65.545,98.419,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.286 | Acc: 65.722,98.430,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.287 | Acc: 65.724,98.426,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.287 | Acc: 65.733,98.442,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.287 | Acc: 65.715,98.433,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.278 | Acc: 54.688,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.297 | Acc: 52.976,68.601,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.330 | Acc: 53.125,68.369,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 52.959,68.584,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.295 | Acc: 64.844,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.299 | Acc: 64.435,98.810,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.301 | Acc: 65.072,98.514,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.304 | Acc: 64.818,98.591,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.297 | Acc: 64.988,98.582,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.291 | Acc: 65.308,98.592,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.287 | Acc: 65.631,98.612,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.288 | Acc: 65.586,98.543,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.286 | Acc: 65.824,98.530,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.279 | Acc: 66.061,98.563,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.281 | Acc: 65.948,98.507,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.279 | Acc: 66.074,98.508,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.281 | Acc: 65.978,98.509,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.283 | Acc: 65.930,98.512,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.282 | Acc: 65.950,98.513,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.282 | Acc: 65.942,98.510,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.282 | Acc: 65.917,98.515,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.284 | Acc: 65.799,98.504,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.286 | Acc: 65.826,98.511,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.283 | Acc: 65.879,98.515,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.295 | Acc: 54.688,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.299 | Acc: 53.385,68.638,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.328 | Acc: 53.182,68.426,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.294 | Acc: 52.997,68.622,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 1.280 | Acc: 72.656,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.283 | Acc: 66.183,98.140,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.270 | Acc: 66.101,98.247,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.271 | Acc: 66.189,98.412,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.267 | Acc: 66.069,98.360,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.271 | Acc: 65.865,98.430,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.286 | Acc: 65.573,98.276,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.288 | Acc: 65.498,98.360,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.284 | Acc: 65.538,98.370,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.277 | Acc: 65.888,98.407,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.276 | Acc: 66.002,98.426,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 65.986,98.406,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.278 | Acc: 65.884,98.428,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.278 | Acc: 65.897,98.443,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 65.975,98.468,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.280 | Acc: 65.804,98.482,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.282 | Acc: 65.764,98.489,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.283 | Acc: 65.756,98.465,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.286 | Acc: 65.746,98.455,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.286 | Acc: 65.691,98.444,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.265 | Acc: 53.125,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.291 | Acc: 52.902,68.750,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.326 | Acc: 52.954,68.521,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.292 | Acc: 52.728,68.648,74.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.349 | Acc: 67.969,99.219,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.269 | Acc: 65.811,98.549,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.282 | Acc: 65.816,98.304,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.281 | Acc: 65.740,98.373,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.280 | Acc: 65.635,98.457,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.285 | Acc: 65.463,98.383,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.278 | Acc: 65.715,98.450,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.277 | Acc: 65.764,98.482,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.277 | Acc: 65.921,98.496,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.283 | Acc: 65.694,98.515,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.284 | Acc: 65.679,98.480,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.285 | Acc: 65.703,98.448,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.287 | Acc: 65.667,98.447,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.283 | Acc: 65.796,98.485,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.285 | Acc: 65.720,98.485,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.286 | Acc: 65.680,98.492,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.285 | Acc: 65.652,98.486,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.285 | Acc: 65.673,98.499,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.287 | Acc: 65.642,98.498,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.288 | Acc: 65.588,98.487,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.247 | Acc: 54.688,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.310 | Acc: 52.865,68.824,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.335 | Acc: 53.049,68.502,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 52.856,68.596,75.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.246 | Acc: 63.281,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.255 | Acc: 66.704,98.661,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.276 | Acc: 66.159,98.514,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.279 | Acc: 65.868,98.438,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.269 | Acc: 66.146,98.524,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.267 | Acc: 66.360,98.546,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.270 | Acc: 66.296,98.521,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.271 | Acc: 66.334,98.537,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.280 | Acc: 66.135,98.544,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.280 | Acc: 66.095,98.576,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.277 | Acc: 66.056,98.554,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.280 | Acc: 65.936,98.512,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.286 | Acc: 65.839,98.454,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.288 | Acc: 65.799,98.467,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.284 | Acc: 65.967,98.446,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.284 | Acc: 65.962,98.435,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.285 | Acc: 65.890,98.433,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.286 | Acc: 65.905,98.438,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.287 | Acc: 65.872,98.440,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.287 | Acc: 65.885,98.450,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.305 | Acc: 53.906,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.305 | Acc: 52.902,68.750,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.338 | Acc: 52.973,68.388,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.306 | Acc: 52.754,68.468,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.155 | Acc: 66.406,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.275 | Acc: 65.848,98.624,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.290 | Acc: 65.320,98.457,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.289 | Acc: 65.407,98.450,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.295 | Acc: 65.210,98.447,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.292 | Acc: 65.300,98.492,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.289 | Acc: 65.354,98.541,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.289 | Acc: 65.392,98.526,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.285 | Acc: 65.455,98.564,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.285 | Acc: 65.534,98.545,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.286 | Acc: 65.547,98.542,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.288 | Acc: 65.512,98.529,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.288 | Acc: 65.518,98.554,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.290 | Acc: 65.523,98.536,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.291 | Acc: 65.522,98.515,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.291 | Acc: 65.542,98.469,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.293 | Acc: 65.498,98.464,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.292 | Acc: 65.563,98.467,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.291 | Acc: 65.657,98.481,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.291 | Acc: 65.662,98.474,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.247 | Acc: 54.688,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.294 | Acc: 53.162,68.452,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.328 | Acc: 53.106,68.197,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.300 | Acc: 52.882,68.417,74.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.122 | Acc: 74.219,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.254 | Acc: 66.629,98.698,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.268 | Acc: 66.349,98.590,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.278 | Acc: 66.201,98.450,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.279 | Acc: 66.020,98.466,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.286 | Acc: 65.811,98.499,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.282 | Acc: 65.851,98.502,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.290 | Acc: 65.631,98.510,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.289 | Acc: 65.620,98.510,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.292 | Acc: 65.547,98.520,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.294 | Acc: 65.493,98.472,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.297 | Acc: 65.399,98.476,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.294 | Acc: 65.440,98.463,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.297 | Acc: 65.442,98.408,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.295 | Acc: 65.575,98.443,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.294 | Acc: 65.542,98.453,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.292 | Acc: 65.644,98.457,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.290 | Acc: 65.666,98.470,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.290 | Acc: 65.729,98.468,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.287 | Acc: 65.777,98.470,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.250 | Acc: 55.469,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.313 | Acc: 53.125,68.564,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.339 | Acc: 53.258,68.388,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.304 | Acc: 52.971,68.545,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.445 | Acc: 67.188,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.310 | Acc: 63.914,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.291 | Acc: 65.473,98.342,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.293 | Acc: 65.394,98.373,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.296 | Acc: 65.230,98.360,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.291 | Acc: 65.470,98.476,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.289 | Acc: 65.715,98.470,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.283 | Acc: 65.919,98.460,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.282 | Acc: 65.931,98.481,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.281 | Acc: 65.996,98.463,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.281 | Acc: 65.901,98.441,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.283 | Acc: 65.883,98.423,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.283 | Acc: 65.943,98.438,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.282 | Acc: 65.978,98.423,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.284 | Acc: 65.903,98.429,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.285 | Acc: 65.934,98.425,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.284 | Acc: 65.995,98.447,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.289 | Acc: 65.829,98.456,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.287 | Acc: 65.889,98.448,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.286 | Acc: 65.947,98.464,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.296 | Acc: 54.688,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.289 | Acc: 53.088,68.824,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.324 | Acc: 53.373,68.369,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.296 | Acc: 53.074,68.545,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.185 | Acc: 64.062,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.285 | Acc: 66.034,98.103,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.285 | Acc: 65.987,98.266,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.289 | Acc: 65.932,98.412,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.291 | Acc: 65.760,98.515,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.296 | Acc: 65.486,98.438,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.289 | Acc: 65.548,98.379,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.296 | Acc: 65.381,98.343,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.295 | Acc: 65.310,98.345,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.298 | Acc: 65.258,98.304,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.300 | Acc: 65.310,98.274,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.295 | Acc: 65.480,98.285,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.294 | Acc: 65.499,98.272,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.292 | Acc: 65.547,98.300,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.288 | Acc: 65.636,98.329,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.288 | Acc: 65.630,98.362,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.288 | Acc: 65.666,98.401,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.289 | Acc: 65.710,98.405,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.287 | Acc: 65.753,98.418,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.289 | Acc: 65.719,98.403,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.254 | Acc: 56.250,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.296 | Acc: 52.976,68.824,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.330 | Acc: 53.239,68.388,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 53.023,68.571,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.264 | Acc: 65.625,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.315 | Acc: 64.509,98.289,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.285 | Acc: 65.320,98.457,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.283 | Acc: 65.407,98.514,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.292 | Acc: 65.287,98.601,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.281 | Acc: 65.656,98.623,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.283 | Acc: 65.735,98.592,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.286 | Acc: 65.625,98.537,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.286 | Acc: 65.615,98.501,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.289 | Acc: 65.547,98.520,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.286 | Acc: 65.563,98.539,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.285 | Acc: 65.590,98.522,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.283 | Acc: 65.599,98.528,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.284 | Acc: 65.532,98.524,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.286 | Acc: 65.528,98.518,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.286 | Acc: 65.560,98.518,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.287 | Acc: 65.525,98.508,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.287 | Acc: 65.545,98.522,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.286 | Acc: 65.588,98.520,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.286 | Acc: 65.568,98.515,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.261 | Acc: 55.469,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.306 | Acc: 52.939,68.713,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.334 | Acc: 52.973,68.331,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.300 | Acc: 52.818,68.443,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.300 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.285 | Acc: 65.513,98.214,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.267 | Acc: 66.654,98.399,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.287 | Acc: 66.163,98.373,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.271 | Acc: 66.377,98.351,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.268 | Acc: 66.476,98.422,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.260 | Acc: 66.813,98.470,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.261 | Acc: 66.772,98.465,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.265 | Acc: 66.595,98.496,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.269 | Acc: 66.436,98.494,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.267 | Acc: 66.511,98.515,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.275 | Acc: 66.336,98.498,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.277 | Acc: 66.173,98.470,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.278 | Acc: 66.137,98.470,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.281 | Acc: 66.056,98.432,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.281 | Acc: 66.032,98.406,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.284 | Acc: 65.980,98.391,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.286 | Acc: 65.943,98.403,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.286 | Acc: 65.967,98.409,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.286 | Acc: 65.959,98.415,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.264 | Acc: 54.688,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 53.348,68.713,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 53.335,68.369,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.296 | Acc: 52.997,68.635,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.321 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.278 | Acc: 65.737,98.475,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.274 | Acc: 65.701,98.704,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.275 | Acc: 66.060,98.642,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.273 | Acc: 65.924,98.698,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.287 | Acc: 65.517,98.662,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.282 | Acc: 65.690,98.644,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.283 | Acc: 65.730,98.604,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.280 | Acc: 65.868,98.588,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.279 | Acc: 65.931,98.563,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.278 | Acc: 65.901,98.554,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.278 | Acc: 65.841,98.565,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.279 | Acc: 65.807,98.557,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.279 | Acc: 65.832,98.536,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.278 | Acc: 65.845,98.496,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.284 | Acc: 65.674,98.495,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.287 | Acc: 65.618,98.479,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.287 | Acc: 65.584,98.449,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.286 | Acc: 65.627,98.444,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.287 | Acc: 65.660,98.458,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.244 | Acc: 55.469,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.297 | Acc: 53.460,68.415,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.325 | Acc: 53.316,68.331,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.294 | Acc: 52.971,68.545,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.189 | Acc: 65.625,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.269 | Acc: 65.513,98.475,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.286 | Acc: 65.777,98.495,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.272 | Acc: 66.432,98.630,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.273 | Acc: 66.262,98.573,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.272 | Acc: 66.445,98.523,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.281 | Acc: 66.012,98.515,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.278 | Acc: 65.924,98.487,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.282 | Acc: 65.887,98.467,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.283 | Acc: 65.871,98.450,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.282 | Acc: 65.913,98.449,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.282 | Acc: 65.766,98.469,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.281 | Acc: 65.719,98.499,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.281 | Acc: 65.772,98.500,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.285 | Acc: 65.745,98.476,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.282 | Acc: 65.848,98.461,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.284 | Acc: 65.868,98.442,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.286 | Acc: 65.801,98.438,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.285 | Acc: 65.833,98.440,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.287 | Acc: 65.855,98.448,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.328 | Acc: 54.688,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.288 | Acc: 53.125,68.899,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 53.316,68.388,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.298 | Acc: 53.061,68.584,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.318 | Acc: 65.625,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.290 | Acc: 65.811,97.768,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.296 | Acc: 65.873,98.095,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.294 | Acc: 66.253,98.373,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.291 | Acc: 65.943,98.399,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.283 | Acc: 66.136,98.453,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.283 | Acc: 66.006,98.489,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.282 | Acc: 66.113,98.543,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.281 | Acc: 66.135,98.525,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.288 | Acc: 65.949,98.485,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.289 | Acc: 65.967,98.484,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.285 | Acc: 65.961,98.515,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.289 | Acc: 65.790,98.486,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.288 | Acc: 65.787,98.512,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.286 | Acc: 65.834,98.515,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.289 | Acc: 65.770,98.500,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.288 | Acc: 65.800,98.530,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.286 | Acc: 65.847,98.525,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.288 | Acc: 65.764,98.522,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.288 | Acc: 65.771,98.517,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.224 | Acc: 57.031,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.301 | Acc: 52.753,68.564,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.330 | Acc: 53.125,68.350,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.296 | Acc: 53.010,68.519,74.898,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.441 | Acc: 57.031,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.284 | Acc: 66.295,98.586,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.259 | Acc: 66.349,98.609,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.266 | Acc: 66.278,98.502,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.268 | Acc: 66.262,98.457,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.272 | Acc: 66.128,98.461,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.283 | Acc: 65.677,98.405,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.286 | Acc: 65.592,98.399,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.290 | Acc: 65.591,98.442,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.285 | Acc: 65.802,98.442,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.284 | Acc: 65.901,98.426,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.286 | Acc: 65.901,98.416,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.287 | Acc: 65.884,98.418,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.290 | Acc: 65.811,98.402,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.290 | Acc: 65.867,98.401,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.288 | Acc: 65.923,98.404,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.289 | Acc: 65.917,98.357,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.289 | Acc: 65.850,98.373,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.289 | Acc: 65.872,98.383,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.288 | Acc: 65.892,98.403,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.297 | Acc: 55.469,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.304 | Acc: 53.274,68.787,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.331 | Acc: 53.239,68.350,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.300 | Acc: 53.074,68.519,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.297 | Acc: 65.625,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.271 | Acc: 66.704,98.326,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.278 | Acc: 66.273,98.171,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.273 | Acc: 66.662,98.412,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.283 | Acc: 66.397,98.331,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.284 | Acc: 66.012,98.352,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.282 | Acc: 65.916,98.431,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.284 | Acc: 65.996,98.388,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.278 | Acc: 66.232,98.379,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.276 | Acc: 66.238,98.420,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.274 | Acc: 66.274,98.406,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.274 | Acc: 66.251,98.409,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.279 | Acc: 66.085,98.412,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.282 | Acc: 65.939,98.426,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.285 | Acc: 65.897,98.418,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.285 | Acc: 65.872,98.396,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.286 | Acc: 65.834,98.394,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.285 | Acc: 65.863,98.399,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.286 | Acc: 65.807,98.425,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.287 | Acc: 65.754,98.396,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.261 | Acc: 54.688,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.301 | Acc: 53.013,68.787,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.331 | Acc: 52.954,68.540,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 52.766,68.622,74.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.393 | Acc: 57.812,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.255 | Acc: 66.183,98.400,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.266 | Acc: 66.330,98.438,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.277 | Acc: 65.894,98.489,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.285 | Acc: 65.885,98.466,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.292 | Acc: 65.486,98.476,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.288 | Acc: 65.509,98.483,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.284 | Acc: 65.703,98.482,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.281 | Acc: 65.839,98.486,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.282 | Acc: 65.957,98.468,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.285 | Acc: 65.839,98.476,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.285 | Acc: 65.865,98.476,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.287 | Acc: 65.820,98.470,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.288 | Acc: 65.808,98.488,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.288 | Acc: 65.825,98.485,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.288 | Acc: 65.776,98.458,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.288 | Acc: 65.764,98.430,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.291 | Acc: 65.698,98.421,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.288 | Acc: 65.744,98.433,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.289 | Acc: 65.701,98.458,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.311 | Acc: 54.688,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 53.013,68.713,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.320 | Acc: 53.106,68.236,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.296 | Acc: 52.894,68.494,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.180 | Acc: 71.875,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.273 | Acc: 65.327,98.512,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.300 | Acc: 64.596,98.552,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.290 | Acc: 65.471,98.578,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.279 | Acc: 66.098,98.611,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.274 | Acc: 66.221,98.515,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.272 | Acc: 66.206,98.534,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.272 | Acc: 66.174,98.587,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.277 | Acc: 65.989,98.530,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.282 | Acc: 65.931,98.520,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.284 | Acc: 65.928,98.492,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.283 | Acc: 65.929,98.491,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.282 | Acc: 66.040,98.493,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.285 | Acc: 65.891,98.491,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.286 | Acc: 65.889,98.490,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.285 | Acc: 65.892,98.482,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.284 | Acc: 65.983,98.484,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.283 | Acc: 65.962,98.490,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.283 | Acc: 65.958,98.485,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.285 | Acc: 65.939,98.476,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.251 | Acc: 54.688,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.305 | Acc: 52.790,68.862,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.333 | Acc: 52.858,68.388,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.302 | Acc: 52.728,68.609,74.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.659 | Acc: 51.562,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.273 | Acc: 65.513,97.954,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.307 | Acc: 64.958,98.171,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.292 | Acc: 65.433,98.309,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.290 | Acc: 65.422,98.293,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.288 | Acc: 65.633,98.314,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.287 | Acc: 65.657,98.354,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.290 | Acc: 65.486,98.332,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.287 | Acc: 65.552,98.365,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.286 | Acc: 65.590,98.416,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.289 | Acc: 65.633,98.391,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.289 | Acc: 65.643,98.392,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.291 | Acc: 65.609,98.415,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.290 | Acc: 65.607,98.408,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.289 | Acc: 65.656,98.426,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.287 | Acc: 65.661,98.422,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.286 | Acc: 65.662,98.445,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.288 | Acc: 65.632,98.408,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.288 | Acc: 65.631,98.412,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.287 | Acc: 65.648,98.411,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.267 | Acc: 54.688,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.303 | Acc: 52.716,68.601,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.325 | Acc: 52.915,68.350,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.293 | Acc: 52.754,68.532,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 1.471 | Acc: 66.406,99.219,100.000,% | Adaptive Acc: 93.750% | clf_exit: 0.578 0.406 0.016
Batch: 20 | Loss: 1.317 | Acc: 64.993,98.400,100.000,% | Adaptive Acc: 90.476% | clf_exit: 0.564 0.420 0.016
Batch: 40 | Loss: 1.305 | Acc: 65.701,98.209,99.981,% | Adaptive Acc: 90.930% | clf_exit: 0.569 0.417 0.015
Batch: 60 | Loss: 1.291 | Acc: 65.651,98.220,99.987,% | Adaptive Acc: 90.971% | clf_exit: 0.570 0.418 0.012
Batch: 80 | Loss: 1.291 | Acc: 65.712,98.254,99.990,% | Adaptive Acc: 91.011% | clf_exit: 0.568 0.420 0.012
Batch: 100 | Loss: 1.289 | Acc: 65.633,98.306,99.985,% | Adaptive Acc: 90.996% | clf_exit: 0.566 0.422 0.012
Batch: 120 | Loss: 1.292 | Acc: 65.496,98.315,99.981,% | Adaptive Acc: 91.303% | clf_exit: 0.563 0.426 0.012
Batch: 140 | Loss: 1.291 | Acc: 65.575,98.305,99.972,% | Adaptive Acc: 91.345% | clf_exit: 0.560 0.428 0.012
Batch: 160 | Loss: 1.290 | Acc: 65.547,98.302,99.966,% | Adaptive Acc: 91.382% | clf_exit: 0.560 0.429 0.012
Batch: 180 | Loss: 1.289 | Acc: 65.595,98.338,99.965,% | Adaptive Acc: 91.424% | clf_exit: 0.560 0.429 0.011
Batch: 200 | Loss: 1.286 | Acc: 65.641,98.352,99.969,% | Adaptive Acc: 91.418% | clf_exit: 0.560 0.429 0.011
Batch: 220 | Loss: 1.285 | Acc: 65.674,98.342,99.968,% | Adaptive Acc: 91.431% | clf_exit: 0.561 0.428 0.011
Batch: 240 | Loss: 1.285 | Acc: 65.606,98.360,99.968,% | Adaptive Acc: 91.455% | clf_exit: 0.560 0.429 0.011
Batch: 260 | Loss: 1.283 | Acc: 65.682,98.393,99.970,% | Adaptive Acc: 91.445% | clf_exit: 0.563 0.426 0.011
Batch: 280 | Loss: 1.283 | Acc: 65.786,98.368,99.967,% | Adaptive Acc: 91.434% | clf_exit: 0.564 0.426 0.011
Batch: 300 | Loss: 1.282 | Acc: 65.789,98.404,99.966,% | Adaptive Acc: 91.469% | clf_exit: 0.564 0.426 0.011
Batch: 320 | Loss: 1.286 | Acc: 65.700,98.416,99.966,% | Adaptive Acc: 91.467% | clf_exit: 0.563 0.427 0.011
Batch: 340 | Loss: 1.283 | Acc: 65.717,98.426,99.966,% | Adaptive Acc: 91.496% | clf_exit: 0.563 0.427 0.011
Batch: 360 | Loss: 1.283 | Acc: 65.729,98.429,99.965,% | Adaptive Acc: 91.521% | clf_exit: 0.563 0.426 0.011
Batch: 380 | Loss: 1.284 | Acc: 65.730,98.423,99.965,% | Adaptive Acc: 91.581% | clf_exit: 0.562 0.427 0.011
Batch: 0 | Loss: 4.248 | Acc: 57.031,72.656,78.125,% | Adaptive Acc: 72.656% | clf_exit: 0.547 0.406 0.047
Batch: 20 | Loss: 4.297 | Acc: 53.311,68.899,75.112,% | Adaptive Acc: 66.332% | clf_exit: 0.555 0.369 0.076
Batch: 40 | Loss: 4.332 | Acc: 53.277,68.712,74.676,% | Adaptive Acc: 66.120% | clf_exit: 0.555 0.362 0.083
Batch: 60 | Loss: 4.303 | Acc: 52.984,68.814,74.962,% | Adaptive Acc: 66.124% | clf_exit: 0.552 0.363 0.085
Evaluate with different circles:
circles: 0
Batch: 0 | Loss: 10.306 | Acc: 26.562,25.000,16.406,% | Adaptive Acc: 23.438% | clf_exit: 0.117 0.000 0.883
Batch: 20 | Loss: 10.333 | Acc: 24.256,18.676,15.327,% | Adaptive Acc: 19.420% | clf_exit: 0.112 0.000 0.888
Batch: 40 | Loss: 10.342 | Acc: 23.723,19.474,15.015,% | Adaptive Acc: 19.207% | clf_exit: 0.104 0.000 0.896
Batch: 60 | Loss: 10.355 | Acc: 24.027,18.955,14.703,% | Adaptive Acc: 18.699% | clf_exit: 0.101 0.000 0.898
circles: 1
Batch: 0 | Loss: 8.905 | Acc: 32.031,45.312,41.406,% | Adaptive Acc: 42.969% | clf_exit: 0.133 0.008 0.859
Batch: 20 | Loss: 8.994 | Acc: 28.720,39.211,38.207,% | Adaptive Acc: 39.323% | clf_exit: 0.127 0.013 0.860
Batch: 40 | Loss: 9.014 | Acc: 28.335,39.691,37.538,% | Adaptive Acc: 38.758% | clf_exit: 0.118 0.014 0.868
Batch: 60 | Loss: 9.031 | Acc: 28.548,39.216,37.526,% | Adaptive Acc: 38.947% | clf_exit: 0.115 0.013 0.873
circles: 2
Batch: 0 | Loss: 7.730 | Acc: 34.375,57.031,60.156,% | Adaptive Acc: 60.156% | clf_exit: 0.172 0.062 0.766
Batch: 20 | Loss: 7.852 | Acc: 33.557,51.488,53.237,% | Adaptive Acc: 52.530% | clf_exit: 0.154 0.064 0.783
Batch: 40 | Loss: 7.877 | Acc: 33.441,51.448,52.687,% | Adaptive Acc: 52.287% | clf_exit: 0.146 0.063 0.791
Batch: 60 | Loss: 7.893 | Acc: 33.530,51.396,52.613,% | Adaptive Acc: 52.510% | clf_exit: 0.145 0.063 0.793
circles: 3
Batch: 0 | Loss: 6.696 | Acc: 42.188,60.938,67.188,% | Adaptive Acc: 63.281% | clf_exit: 0.203 0.172 0.625
Batch: 20 | Loss: 6.839 | Acc: 38.802,59.003,62.351,% | Adaptive Acc: 60.417% | clf_exit: 0.198 0.127 0.675
Batch: 40 | Loss: 6.864 | Acc: 38.739,58.784,61.319,% | Adaptive Acc: 60.194% | clf_exit: 0.189 0.134 0.677
Batch: 60 | Loss: 6.878 | Acc: 38.819,58.876,61.424,% | Adaptive Acc: 60.553% | clf_exit: 0.187 0.135 0.678
circles: 4
Batch: 0 | Loss: 5.813 | Acc: 47.656,63.281,71.875,% | Adaptive Acc: 64.844% | clf_exit: 0.266 0.281 0.453
Batch: 20 | Loss: 5.961 | Acc: 43.750,63.132,68.080,% | Adaptive Acc: 65.476% | clf_exit: 0.252 0.211 0.537
Batch: 40 | Loss: 5.985 | Acc: 43.579,63.091,67.149,% | Adaptive Acc: 65.168% | clf_exit: 0.248 0.216 0.537
Batch: 60 | Loss: 5.994 | Acc: 43.417,63.076,67.456,% | Adaptive Acc: 65.766% | clf_exit: 0.243 0.213 0.543
circles: 5
Batch: 0 | Loss: 5.098 | Acc: 49.219,64.062,72.656,% | Adaptive Acc: 68.750% | clf_exit: 0.312 0.336 0.352
Batch: 20 | Loss: 5.230 | Acc: 47.433,65.848,71.763,% | Adaptive Acc: 68.490% | clf_exit: 0.313 0.272 0.415
Batch: 40 | Loss: 5.255 | Acc: 47.237,65.434,71.303,% | Adaptive Acc: 68.312% | clf_exit: 0.311 0.280 0.409
Batch: 60 | Loss: 5.258 | Acc: 47.054,65.651,71.350,% | Adaptive Acc: 68.648% | clf_exit: 0.307 0.279 0.414
circles: 6
Batch: 0 | Loss: 4.572 | Acc: 50.781,65.625,74.219,% | Adaptive Acc: 69.531% | clf_exit: 0.406 0.336 0.258
Batch: 20 | Loss: 4.668 | Acc: 49.851,67.225,73.921,% | Adaptive Acc: 69.680% | clf_exit: 0.374 0.319 0.307
Batch: 40 | Loss: 4.697 | Acc: 49.771,66.787,73.399,% | Adaptive Acc: 69.627% | clf_exit: 0.376 0.317 0.306
Batch: 60 | Loss: 4.692 | Acc: 49.475,67.085,73.386,% | Adaptive Acc: 69.698% | clf_exit: 0.371 0.321 0.308
circles: 7
Batch: 0 | Loss: 4.234 | Acc: 51.562,68.750,75.000,% | Adaptive Acc: 70.312% | clf_exit: 0.430 0.359 0.211
Batch: 20 | Loss: 4.293 | Acc: 51.897,68.192,74.554,% | Adaptive Acc: 69.345% | clf_exit: 0.421 0.349 0.230
Batch: 40 | Loss: 4.327 | Acc: 51.829,67.835,74.314,% | Adaptive Acc: 69.169% | clf_exit: 0.427 0.345 0.227
Batch: 60 | Loss: 4.314 | Acc: 51.230,68.097,74.219,% | Adaptive Acc: 69.237% | clf_exit: 0.424 0.349 0.227
circles: 8
Batch: 0 | Loss: 4.090 | Acc: 53.906,71.094,75.781,% | Adaptive Acc: 69.531% | clf_exit: 0.461 0.430 0.109
Batch: 20 | Loss: 4.117 | Acc: 53.051,68.192,75.186,% | Adaptive Acc: 68.824% | clf_exit: 0.468 0.371 0.161
Batch: 40 | Loss: 4.152 | Acc: 52.801,68.007,74.676,% | Adaptive Acc: 68.617% | clf_exit: 0.474 0.363 0.163
Batch: 60 | Loss: 4.134 | Acc: 52.459,68.276,74.616,% | Adaptive Acc: 68.712% | clf_exit: 0.471 0.364 0.165
circles: 9
Batch: 0 | Loss: 4.111 | Acc: 53.906,71.875,77.344,% | Adaptive Acc: 71.875% | clf_exit: 0.492 0.430 0.078
Batch: 20 | Loss: 4.130 | Acc: 53.869,68.490,75.446,% | Adaptive Acc: 67.336% | clf_exit: 0.519 0.372 0.109
Batch: 40 | Loss: 4.165 | Acc: 53.430,68.274,74.886,% | Adaptive Acc: 67.550% | clf_exit: 0.518 0.365 0.117
Batch: 60 | Loss: 4.142 | Acc: 53.061,68.404,74.987,% | Adaptive Acc: 67.585% | clf_exit: 0.515 0.367 0.118
circles: 10
Batch: 0 | Loss: 4.248 | Acc: 57.031,72.656,78.125,% | Adaptive Acc: 72.656% | clf_exit: 0.547 0.406 0.047
Batch: 20 | Loss: 4.297 | Acc: 53.311,68.899,75.112,% | Adaptive Acc: 66.332% | clf_exit: 0.555 0.369 0.076
Batch: 40 | Loss: 4.332 | Acc: 53.277,68.712,74.676,% | Adaptive Acc: 66.120% | clf_exit: 0.555 0.362 0.083
Batch: 60 | Loss: 4.303 | Acc: 52.984,68.814,74.962,% | Adaptive Acc: 66.124% | clf_exit: 0.552 0.363 0.085

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 12.448 |  Acc: 5.300,7.634,8.744,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=0 | Loss: 11.784 |  Acc: 7.420,10.460,10.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 11.046 |  Acc: 9.140,13.714,15.646,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=1 | Loss: 10.933 |  Acc: 9.000,13.850,17.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 10.016 |  Acc: 12.694,19.478,23.152,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=2 | Loss: 9.873 |  Acc: 13.370,20.540,23.520,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 9.154 |  Acc: 17.138,24.356,29.368,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=3 | Loss: 8.976 |  Acc: 18.210,23.160,31.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 8.460 |  Acc: 20.490,28.480,35.302,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=4 | Loss: 8.691 |  Acc: 17.780,26.370,35.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 7.880 |  Acc: 22.968,32.582,40.624,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=5 | Loss: 8.300 |  Acc: 16.600,30.230,40.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 7.407 |  Acc: 25.400,35.750,45.118,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=6 | Loss: 7.532 |  Acc: 24.080,34.370,45.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 7.003 |  Acc: 27.278,39.096,49.144,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=7 | Loss: 7.330 |  Acc: 22.740,36.180,48.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 6.636 |  Acc: 29.188,42.018,52.620,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=8 | Loss: 7.047 |  Acc: 24.380,40.640,50.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 6.341 |  Acc: 30.728,44.450,55.432,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=9 | Loss: 6.858 |  Acc: 27.020,40.280,52.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 6.066 |  Acc: 32.066,46.516,58.304,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=10 | Loss: 6.842 |  Acc: 25.130,42.830,54.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 5.846 |  Acc: 33.152,48.670,60.446,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=11 | Loss: 6.370 |  Acc: 28.410,45.210,55.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 5.640 |  Acc: 33.842,50.566,62.806,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=12 | Loss: 6.151 |  Acc: 30.530,46.990,58.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 5.436 |  Acc: 34.946,52.238,65.140,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=13 | Loss: 6.120 |  Acc: 30.450,47.670,58.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 5.265 |  Acc: 35.712,53.690,67.054,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=14 | Loss: 5.869 |  Acc: 30.600,50.550,61.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 5.123 |  Acc: 36.386,54.614,68.568,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=15 | Loss: 6.257 |  Acc: 27.950,48.820,60.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 4.974 |  Acc: 37.040,56.306,70.232,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=16 | Loss: 6.131 |  Acc: 27.220,49.570,61.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 4.853 |  Acc: 37.752,57.310,71.542,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=17 | Loss: 5.668 |  Acc: 33.360,53.010,62.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.735 |  Acc: 38.248,58.254,72.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=18 | Loss: 5.908 |  Acc: 29.640,51.890,63.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.631 |  Acc: 38.838,59.162,74.208,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=19 | Loss: 5.716 |  Acc: 30.470,53.450,63.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.527 |  Acc: 39.222,60.156,75.618,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=20 | Loss: 5.640 |  Acc: 33.020,53.390,63.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.445 |  Acc: 39.712,60.976,76.300,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=21 | Loss: 5.626 |  Acc: 31.740,54.010,64.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 4.364 |  Acc: 40.266,61.582,77.220,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=22 | Loss: 5.575 |  Acc: 33.310,55.050,65.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 4.285 |  Acc: 40.442,62.256,78.620,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=23 | Loss: 5.575 |  Acc: 33.780,54.800,65.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 4.213 |  Acc: 40.932,62.852,78.998,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=24 | Loss: 5.374 |  Acc: 35.570,55.040,64.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 4.158 |  Acc: 41.280,63.316,80.066,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=25 | Loss: 5.483 |  Acc: 33.970,54.910,66.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 4.074 |  Acc: 41.698,64.036,80.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=26 | Loss: 5.490 |  Acc: 35.780,54.410,65.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 4.052 |  Acc: 42.000,64.100,80.996,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=27 | Loss: 5.554 |  Acc: 34.890,53.890,64.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 3.998 |  Acc: 42.164,64.892,81.656,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=28 | Loss: 5.549 |  Acc: 34.540,53.880,65.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 3.938 |  Acc: 42.454,65.376,82.374,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=29 | Loss: 5.255 |  Acc: 38.110,56.950,64.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 3.911 |  Acc: 42.618,65.442,82.550,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=30 | Loss: 5.391 |  Acc: 36.340,55.200,66.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 3.862 |  Acc: 43.028,66.038,83.198,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=31 | Loss: 5.598 |  Acc: 35.320,55.400,64.530,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 3.812 |  Acc: 43.030,66.610,84.046,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=32 | Loss: 5.341 |  Acc: 38.230,56.140,65.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 3.787 |  Acc: 43.248,66.748,84.214,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=33 | Loss: 5.382 |  Acc: 35.720,57.240,66.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 3.751 |  Acc: 43.368,66.712,84.672,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=34 | Loss: 5.489 |  Acc: 35.250,56.530,66.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 3.745 |  Acc: 43.484,67.068,84.424,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=35 | Loss: 5.336 |  Acc: 37.430,55.740,66.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.688 |  Acc: 43.916,67.614,85.282,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=36 | Loss: 5.423 |  Acc: 35.440,55.850,65.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.650 |  Acc: 43.762,67.816,85.896,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=37 | Loss: 5.144 |  Acc: 38.950,58.160,66.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.618 |  Acc: 44.288,68.124,86.396,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=38 | Loss: 5.204 |  Acc: 39.740,56.930,66.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.604 |  Acc: 44.434,68.178,86.152,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=39 | Loss: 5.282 |  Acc: 36.740,57.880,65.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.568 |  Acc: 44.822,68.604,86.422,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=40 | Loss: 5.262 |  Acc: 38.240,57.450,66.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.544 |  Acc: 44.798,68.670,87.096,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=41 | Loss: 5.284 |  Acc: 38.290,57.770,65.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.546 |  Acc: 44.802,68.888,86.802,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=42 | Loss: 5.303 |  Acc: 36.680,57.470,66.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.493 |  Acc: 45.268,69.386,87.482,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=43 | Loss: 5.289 |  Acc: 37.160,58.990,66.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.475 |  Acc: 45.428,69.738,87.590,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=44 | Loss: 5.349 |  Acc: 36.870,57.630,65.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.483 |  Acc: 45.320,69.296,87.594,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=45 | Loss: 5.505 |  Acc: 35.960,56.560,65.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.429 |  Acc: 45.452,70.246,87.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=46 | Loss: 5.362 |  Acc: 36.600,58.410,66.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.431 |  Acc: 45.558,69.730,88.106,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=47 | Loss: 5.240 |  Acc: 39.590,57.930,66.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.411 |  Acc: 45.946,69.990,88.128,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=48 | Loss: 5.391 |  Acc: 35.690,58.010,65.530,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.401 |  Acc: 45.842,70.232,88.116,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=49 | Loss: 5.272 |  Acc: 38.790,57.700,66.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.384 |  Acc: 45.896,70.746,88.296,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=50 | Loss: 5.183 |  Acc: 41.030,58.060,65.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.346 |  Acc: 46.326,70.942,88.996,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=51 | Loss: 5.417 |  Acc: 36.740,57.850,66.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.356 |  Acc: 46.106,70.908,88.698,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=52 | Loss: 5.279 |  Acc: 36.560,59.400,66.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.356 |  Acc: 46.464,70.710,88.464,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=53 | Loss: 5.166 |  Acc: 38.610,58.770,66.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.359 |  Acc: 46.320,70.816,88.600,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=54 | Loss: 5.321 |  Acc: 38.980,57.390,65.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.298 |  Acc: 46.578,71.128,89.276,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=55 | Loss: 5.319 |  Acc: 39.480,57.940,65.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.279 |  Acc: 46.930,71.752,89.378,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=56 | Loss: 5.054 |  Acc: 41.430,58.450,66.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.297 |  Acc: 46.660,71.408,89.150,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=57 | Loss: 5.547 |  Acc: 34.580,57.080,65.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.275 |  Acc: 46.854,71.716,89.314,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=58 | Loss: 5.387 |  Acc: 37.960,57.230,65.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.257 |  Acc: 47.100,72.004,89.458,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=59 | Loss: 4.980 |  Acc: 41.660,60.720,67.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.251 |  Acc: 47.164,71.752,89.656,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=60 | Loss: 5.048 |  Acc: 41.390,59.400,66.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.248 |  Acc: 47.086,71.774,89.342,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=61 | Loss: 5.393 |  Acc: 38.400,58.040,65.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.240 |  Acc: 47.138,72.066,89.662,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=62 | Loss: 5.155 |  Acc: 41.030,58.310,66.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.215 |  Acc: 47.192,72.422,89.836,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=63 | Loss: 5.307 |  Acc: 38.250,59.620,66.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 3.197 |  Acc: 47.250,72.440,90.054,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=64 | Loss: 5.336 |  Acc: 38.220,58.280,64.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 3.213 |  Acc: 47.488,72.492,89.736,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=65 | Loss: 5.443 |  Acc: 35.480,58.370,66.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 3.218 |  Acc: 47.498,72.380,89.592,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=66 | Loss: 5.330 |  Acc: 40.780,56.570,65.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 3.166 |  Acc: 47.680,72.746,90.184,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=67 | Loss: 5.220 |  Acc: 39.300,58.910,66.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 3.190 |  Acc: 47.640,72.638,89.922,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=68 | Loss: 5.521 |  Acc: 35.590,57.160,66.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 3.178 |  Acc: 47.732,72.786,90.016,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=69 | Loss: 5.274 |  Acc: 41.120,58.380,65.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 3.132 |  Acc: 47.866,73.248,90.558,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=70 | Loss: 5.496 |  Acc: 36.580,58.360,65.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 3.152 |  Acc: 47.816,73.032,90.198,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=71 | Loss: 5.116 |  Acc: 40.580,58.970,67.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 3.148 |  Acc: 48.258,72.834,90.202,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=72 | Loss: 5.398 |  Acc: 37.120,59.300,65.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 3.131 |  Acc: 48.010,73.238,90.490,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=73 | Loss: 5.639 |  Acc: 37.380,57.760,64.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 3.161 |  Acc: 47.878,72.938,89.910,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=74 | Loss: 5.191 |  Acc: 39.840,59.730,66.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 3.111 |  Acc: 48.330,73.550,90.366,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=75 | Loss: 5.215 |  Acc: 39.840,59.390,66.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 3.126 |  Acc: 48.128,73.374,90.220,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=76 | Loss: 5.014 |  Acc: 42.960,59.670,66.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 3.094 |  Acc: 48.314,73.906,90.802,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=77 | Loss: 5.120 |  Acc: 39.920,59.390,67.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 3.104 |  Acc: 48.438,73.586,90.424,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=78 | Loss: 5.567 |  Acc: 37.220,58.040,65.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 3.117 |  Acc: 48.082,73.650,90.242,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=79 | Loss: 5.065 |  Acc: 40.990,60.110,66.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 3.092 |  Acc: 48.446,73.704,90.732,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=80 | Loss: 5.173 |  Acc: 39.550,59.940,67.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 3.091 |  Acc: 48.438,73.662,90.514,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=81 | Loss: 5.317 |  Acc: 41.580,58.370,64.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 3.085 |  Acc: 48.286,73.636,90.870,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=82 | Loss: 5.172 |  Acc: 40.360,59.150,66.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 3.094 |  Acc: 48.492,73.778,90.278,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=83 | Loss: 5.243 |  Acc: 39.450,59.120,66.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 3.063 |  Acc: 48.528,74.058,90.882,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=84 | Loss: 5.350 |  Acc: 39.430,58.710,65.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 3.033 |  Acc: 48.968,74.160,91.268,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=85 | Loss: 5.825 |  Acc: 38.120,54.160,64.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 3.057 |  Acc: 48.840,74.114,90.586,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=86 | Loss: 5.293 |  Acc: 40.580,58.620,66.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 3.078 |  Acc: 48.604,73.946,90.450,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=87 | Loss: 5.413 |  Acc: 39.380,57.340,65.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 3.044 |  Acc: 48.846,74.126,90.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=88 | Loss: 5.144 |  Acc: 39.460,61.220,67.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 3.041 |  Acc: 48.834,74.304,90.854,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=89 | Loss: 5.375 |  Acc: 38.690,60.460,66.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 3.015 |  Acc: 49.134,74.588,91.304,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=90 | Loss: 5.318 |  Acc: 38.530,58.470,66.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 3.053 |  Acc: 48.798,74.132,90.644,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=91 | Loss: 5.211 |  Acc: 40.190,58.590,66.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 3.016 |  Acc: 49.120,74.600,90.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=92 | Loss: 5.373 |  Acc: 40.430,58.030,64.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 3.019 |  Acc: 49.058,74.514,90.988,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=93 | Loss: 5.314 |  Acc: 40.510,58.470,66.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 3.008 |  Acc: 49.264,74.808,90.904,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=94 | Loss: 5.221 |  Acc: 41.530,59.270,65.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 2.997 |  Acc: 49.234,74.696,91.344,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=95 | Loss: 5.154 |  Acc: 41.680,59.930,66.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 3.012 |  Acc: 49.126,74.740,90.878,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=96 | Loss: 5.226 |  Acc: 41.530,59.460,65.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 2.997 |  Acc: 49.290,74.792,91.166,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=97 | Loss: 5.161 |  Acc: 40.680,61.220,66.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 2.992 |  Acc: 49.378,74.856,91.256,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=98 | Loss: 5.101 |  Acc: 40.320,59.690,66.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 2.973 |  Acc: 49.192,75.032,91.502,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=99 | Loss: 5.135 |  Acc: 41.630,60.710,66.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 2.979 |  Acc: 49.270,74.950,91.372,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=100 | Loss: 5.457 |  Acc: 38.470,58.110,65.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 3.000 |  Acc: 49.510,75.204,91.006,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=101 | Loss: 5.612 |  Acc: 38.390,57.940,66.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 2.970 |  Acc: 49.310,75.082,91.342,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=102 | Loss: 5.114 |  Acc: 41.710,61.000,67.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 2.951 |  Acc: 49.670,75.290,91.452,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=103 | Loss: 5.330 |  Acc: 41.850,59.510,64.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 2.977 |  Acc: 49.566,75.046,91.134,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=104 | Loss: 5.130 |  Acc: 40.650,60.760,67.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 2.970 |  Acc: 49.440,75.112,91.328,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=105 | Loss: 5.229 |  Acc: 40.040,60.460,67.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 2.949 |  Acc: 49.576,75.420,91.430,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=106 | Loss: 5.084 |  Acc: 41.840,61.080,66.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 2.946 |  Acc: 49.644,75.180,91.564,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=107 | Loss: 5.233 |  Acc: 42.500,59.560,64.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 2.963 |  Acc: 49.356,75.270,91.206,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=108 | Loss: 5.528 |  Acc: 39.750,57.530,64.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 2.951 |  Acc: 49.852,75.432,91.360,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=109 | Loss: 5.057 |  Acc: 42.920,60.030,67.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 2.950 |  Acc: 49.740,75.374,91.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=110 | Loss: 5.262 |  Acc: 39.440,59.270,66.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 2.947 |  Acc: 49.846,75.564,91.396,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=111 | Loss: 5.247 |  Acc: 40.470,59.610,67.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 2.935 |  Acc: 49.620,75.588,91.464,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=112 | Loss: 5.361 |  Acc: 39.970,57.690,64.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 2.921 |  Acc: 49.878,75.602,91.780,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=113 | Loss: 5.295 |  Acc: 40.230,59.410,66.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 2.946 |  Acc: 49.866,75.432,91.312,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=114 | Loss: 5.274 |  Acc: 40.320,60.010,66.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 2.915 |  Acc: 50.206,75.666,91.670,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=115 | Loss: 5.313 |  Acc: 42.110,58.870,65.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 2.927 |  Acc: 49.926,75.424,91.738,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=116 | Loss: 5.338 |  Acc: 41.200,58.280,65.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 2.930 |  Acc: 50.134,75.558,91.280,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=117 | Loss: 5.451 |  Acc: 39.470,58.350,65.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 2.918 |  Acc: 50.162,75.808,91.398,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=118 | Loss: 5.349 |  Acc: 39.100,59.720,66.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 2.887 |  Acc: 50.458,76.056,91.810,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=119 | Loss: 5.561 |  Acc: 36.570,58.040,65.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 2.922 |  Acc: 50.054,75.574,91.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=120 | Loss: 5.101 |  Acc: 41.630,60.810,66.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 2.926 |  Acc: 50.082,75.836,91.396,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=121 | Loss: 5.258 |  Acc: 40.460,59.260,66.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 2.887 |  Acc: 50.474,76.032,91.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=122 | Loss: 5.290 |  Acc: 40.890,59.630,66.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 2.883 |  Acc: 50.410,76.164,92.230,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=123 | Loss: 5.300 |  Acc: 40.280,58.790,66.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 2.875 |  Acc: 50.308,76.262,92.172,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=124 | Loss: 5.593 |  Acc: 37.430,58.220,66.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 2.911 |  Acc: 50.102,75.874,91.362,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=125 | Loss: 5.091 |  Acc: 40.880,61.430,67.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 2.901 |  Acc: 50.484,75.800,91.532,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=126 | Loss: 5.021 |  Acc: 43.590,61.000,67.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 2.909 |  Acc: 50.434,75.814,91.432,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=127 | Loss: 5.043 |  Acc: 42.190,61.140,67.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 2.859 |  Acc: 50.560,76.352,92.318,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=128 | Loss: 4.960 |  Acc: 42.890,61.440,67.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 2.891 |  Acc: 50.602,76.238,91.518,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=129 | Loss: 5.317 |  Acc: 38.430,60.230,65.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 2.888 |  Acc: 50.610,76.070,91.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=130 | Loss: 4.910 |  Acc: 43.920,61.490,68.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 2.882 |  Acc: 50.338,76.142,91.600,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=131 | Loss: 5.098 |  Acc: 41.170,61.140,68.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 2.871 |  Acc: 50.540,76.194,91.790,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=132 | Loss: 5.284 |  Acc: 39.550,60.030,67.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 2.864 |  Acc: 50.542,76.284,91.910,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=133 | Loss: 5.306 |  Acc: 39.350,60.450,66.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 2.857 |  Acc: 50.698,76.286,91.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=134 | Loss: 5.152 |  Acc: 42.090,59.240,67.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 2.869 |  Acc: 50.712,76.148,91.734,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=135 | Loss: 5.093 |  Acc: 42.050,60.880,67.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 2.867 |  Acc: 50.538,76.246,91.924,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=136 | Loss: 5.081 |  Acc: 42.470,61.250,66.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 2.856 |  Acc: 50.582,76.392,91.748,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=137 | Loss: 5.112 |  Acc: 42.490,60.900,67.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 2.852 |  Acc: 50.806,76.462,91.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=138 | Loss: 5.029 |  Acc: 41.610,61.560,66.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 2.853 |  Acc: 50.824,76.260,91.886,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=139 | Loss: 5.459 |  Acc: 39.800,58.380,65.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 2.864 |  Acc: 50.610,76.520,91.852,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=140 | Loss: 5.029 |  Acc: 43.660,60.880,66.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 2.829 |  Acc: 51.040,76.572,92.194,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=141 | Loss: 5.184 |  Acc: 40.210,60.540,66.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 2.842 |  Acc: 50.576,76.508,92.234,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=142 | Loss: 5.099 |  Acc: 42.860,60.610,66.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 2.857 |  Acc: 50.616,76.772,91.828,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=143 | Loss: 5.443 |  Acc: 38.500,58.300,65.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 2.850 |  Acc: 50.650,76.728,91.898,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=144 | Loss: 5.014 |  Acc: 42.700,60.090,66.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 2.855 |  Acc: 50.988,76.272,91.876,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=145 | Loss: 5.031 |  Acc: 43.800,60.800,65.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 2.851 |  Acc: 51.058,76.344,91.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=146 | Loss: 5.220 |  Acc: 40.500,60.400,66.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 2.818 |  Acc: 51.158,76.982,92.200,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=147 | Loss: 4.865 |  Acc: 43.160,63.160,68.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 2.825 |  Acc: 50.952,76.926,92.244,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=148 | Loss: 5.156 |  Acc: 41.470,61.400,66.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 2.839 |  Acc: 50.946,76.720,91.930,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=149 | Loss: 5.285 |  Acc: 41.710,60.540,66.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.219 |  Acc: 55.960,85.054,97.378,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=150 | Loss: 4.034 |  Acc: 50.870,69.180,74.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 2.027 |  Acc: 57.640,87.744,98.890,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=151 | Loss: 3.990 |  Acc: 51.120,69.790,74.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.959 |  Acc: 58.028,88.774,99.274,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=152 | Loss: 3.995 |  Acc: 51.250,69.780,74.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.920 |  Acc: 58.018,89.380,99.406,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=153 | Loss: 3.994 |  Acc: 51.160,69.740,74.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.885 |  Acc: 58.392,89.820,99.514,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=154 | Loss: 3.987 |  Acc: 51.770,69.620,74.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.858 |  Acc: 58.846,90.376,99.568,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=155 | Loss: 4.006 |  Acc: 51.150,69.710,74.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.840 |  Acc: 58.658,90.706,99.556,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=156 | Loss: 4.019 |  Acc: 51.280,69.650,74.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.822 |  Acc: 58.892,90.682,99.632,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=157 | Loss: 4.033 |  Acc: 51.500,70.050,74.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.805 |  Acc: 58.914,91.166,99.682,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=158 | Loss: 4.001 |  Acc: 52.070,69.760,75.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.791 |  Acc: 59.262,91.298,99.698,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=159 | Loss: 4.038 |  Acc: 51.430,69.390,75.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 1.764 |  Acc: 59.530,91.600,99.714,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=160 | Loss: 4.046 |  Acc: 51.650,69.760,75.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.758 |  Acc: 59.462,91.814,99.746,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=161 | Loss: 4.049 |  Acc: 51.600,69.480,74.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.747 |  Acc: 59.490,91.890,99.804,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=162 | Loss: 4.053 |  Acc: 51.790,69.530,75.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.739 |  Acc: 59.332,92.124,99.778,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=163 | Loss: 4.062 |  Acc: 51.880,69.720,75.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.723 |  Acc: 59.580,92.272,99.776,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=164 | Loss: 4.062 |  Acc: 51.730,69.540,75.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.719 |  Acc: 59.764,92.462,99.798,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=165 | Loss: 4.071 |  Acc: 51.190,69.330,75.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.704 |  Acc: 59.752,92.556,99.810,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=166 | Loss: 4.071 |  Acc: 51.780,69.060,75.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.691 |  Acc: 59.974,92.960,99.812,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=167 | Loss: 4.073 |  Acc: 51.850,69.200,75.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.684 |  Acc: 60.112,92.852,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=168 | Loss: 4.095 |  Acc: 51.570,69.200,75.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.678 |  Acc: 60.022,93.220,99.802,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=169 | Loss: 4.091 |  Acc: 51.850,69.250,74.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.667 |  Acc: 60.184,93.058,99.840,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=170 | Loss: 4.100 |  Acc: 51.540,69.570,75.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.654 |  Acc: 60.490,93.384,99.840,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=171 | Loss: 4.103 |  Acc: 52.070,69.450,75.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.658 |  Acc: 60.494,93.370,99.838,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=172 | Loss: 4.116 |  Acc: 51.820,68.830,75.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.653 |  Acc: 60.476,93.274,99.842,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=173 | Loss: 4.107 |  Acc: 51.890,69.750,75.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.639 |  Acc: 60.730,93.558,99.842,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=174 | Loss: 4.134 |  Acc: 51.730,69.090,75.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.633 |  Acc: 60.424,93.848,99.834,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=175 | Loss: 4.138 |  Acc: 51.240,69.540,75.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.628 |  Acc: 60.398,93.728,99.856,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=176 | Loss: 4.162 |  Acc: 51.460,68.910,75.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.620 |  Acc: 60.666,94.074,99.862,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=177 | Loss: 4.137 |  Acc: 51.560,69.450,75.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.618 |  Acc: 60.744,94.012,99.832,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=178 | Loss: 4.137 |  Acc: 52.100,69.360,75.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.610 |  Acc: 60.782,94.078,99.856,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=179 | Loss: 4.149 |  Acc: 51.320,68.920,75.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.606 |  Acc: 60.960,94.026,99.880,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=180 | Loss: 4.155 |  Acc: 51.820,68.940,75.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.603 |  Acc: 60.936,94.126,99.856,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=181 | Loss: 4.158 |  Acc: 51.620,69.060,75.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.603 |  Acc: 60.852,94.294,99.842,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=182 | Loss: 4.185 |  Acc: 51.820,68.480,75.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.593 |  Acc: 61.030,94.382,99.862,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=183 | Loss: 4.188 |  Acc: 51.930,68.440,74.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.592 |  Acc: 61.100,94.274,99.872,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=184 | Loss: 4.219 |  Acc: 51.580,69.220,74.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.578 |  Acc: 61.222,94.294,99.880,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=185 | Loss: 4.185 |  Acc: 51.950,68.600,75.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.580 |  Acc: 61.076,94.438,99.868,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=186 | Loss: 4.217 |  Acc: 51.480,68.640,75.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.578 |  Acc: 61.064,94.456,99.876,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=187 | Loss: 4.195 |  Acc: 51.390,68.770,74.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.572 |  Acc: 61.226,94.668,99.882,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=188 | Loss: 4.171 |  Acc: 52.150,68.730,75.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.568 |  Acc: 61.260,94.686,99.870,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=189 | Loss: 4.199 |  Acc: 51.750,68.780,75.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.562 |  Acc: 61.488,94.644,99.874,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=190 | Loss: 4.229 |  Acc: 51.230,68.880,74.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.562 |  Acc: 61.194,94.728,99.838,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=191 | Loss: 4.250 |  Acc: 51.440,68.430,74.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.556 |  Acc: 61.380,94.860,99.874,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=192 | Loss: 4.239 |  Acc: 51.880,68.190,74.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.553 |  Acc: 61.548,95.000,99.884,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=193 | Loss: 4.322 |  Acc: 51.280,68.110,74.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.552 |  Acc: 61.404,94.954,99.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=194 | Loss: 4.288 |  Acc: 51.280,68.100,74.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.542 |  Acc: 61.776,95.052,99.862,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=195 | Loss: 4.268 |  Acc: 51.560,68.080,75.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.552 |  Acc: 61.414,94.876,99.882,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=196 | Loss: 4.262 |  Acc: 52.030,67.860,74.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.543 |  Acc: 61.476,94.964,99.878,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=197 | Loss: 4.259 |  Acc: 52.100,67.980,75.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.536 |  Acc: 61.682,95.028,99.858,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=198 | Loss: 4.282 |  Acc: 51.120,68.270,74.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.535 |  Acc: 61.614,95.102,99.884,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=199 | Loss: 4.293 |  Acc: 50.980,67.980,74.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.534 |  Acc: 61.922,95.074,99.890,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=200 | Loss: 4.296 |  Acc: 51.660,68.200,74.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.529 |  Acc: 61.752,95.100,99.866,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=201 | Loss: 4.279 |  Acc: 51.310,68.300,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.525 |  Acc: 61.840,95.026,99.864,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=202 | Loss: 4.290 |  Acc: 51.390,67.820,74.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.531 |  Acc: 61.866,95.052,99.858,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=203 | Loss: 4.294 |  Acc: 51.370,68.000,74.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.520 |  Acc: 61.982,95.326,99.890,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=204 | Loss: 4.313 |  Acc: 51.210,68.250,74.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.527 |  Acc: 61.790,95.136,99.868,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=205 | Loss: 4.306 |  Acc: 51.360,67.970,74.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.524 |  Acc: 61.784,95.136,99.866,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=206 | Loss: 4.326 |  Acc: 51.300,67.880,74.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.510 |  Acc: 62.072,95.436,99.894,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=207 | Loss: 4.312 |  Acc: 51.000,68.330,74.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.521 |  Acc: 62.032,95.006,99.874,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=208 | Loss: 4.280 |  Acc: 51.690,68.110,74.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.517 |  Acc: 62.120,95.326,99.878,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=209 | Loss: 4.344 |  Acc: 51.000,67.560,74.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.510 |  Acc: 62.038,95.308,99.874,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=210 | Loss: 4.308 |  Acc: 52.270,68.240,74.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.509 |  Acc: 62.146,95.396,99.906,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=211 | Loss: 4.334 |  Acc: 51.490,68.100,74.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.509 |  Acc: 62.012,95.390,99.890,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=212 | Loss: 4.381 |  Acc: 51.110,67.660,74.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.505 |  Acc: 62.024,95.488,99.888,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=213 | Loss: 4.348 |  Acc: 51.350,68.060,74.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.510 |  Acc: 62.360,95.074,99.860,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=214 | Loss: 4.336 |  Acc: 51.420,67.980,74.530,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.505 |  Acc: 62.280,95.258,99.882,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=215 | Loss: 4.306 |  Acc: 51.940,68.570,74.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.504 |  Acc: 62.186,95.278,99.884,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=216 | Loss: 4.374 |  Acc: 51.050,67.380,74.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.504 |  Acc: 62.242,95.290,99.864,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=217 | Loss: 4.390 |  Acc: 51.690,67.270,74.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.492 |  Acc: 62.478,95.428,99.892,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=218 | Loss: 4.373 |  Acc: 51.240,67.600,74.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.500 |  Acc: 62.280,95.462,99.902,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=219 | Loss: 4.359 |  Acc: 51.590,67.950,74.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.496 |  Acc: 62.512,95.372,99.862,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=220 | Loss: 4.529 |  Acc: 49.460,67.160,74.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.497 |  Acc: 62.210,95.498,99.866,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=221 | Loss: 4.410 |  Acc: 50.990,67.390,74.130,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.505 |  Acc: 62.184,95.208,99.860,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=222 | Loss: 4.393 |  Acc: 50.910,67.120,74.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.507 |  Acc: 62.214,95.088,99.862,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=223 | Loss: 4.379 |  Acc: 51.860,67.390,74.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.504 |  Acc: 62.350,95.204,99.858,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=224 | Loss: 4.469 |  Acc: 51.430,66.860,74.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.393 |  Acc: 64.040,97.054,99.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=225 | Loss: 4.231 |  Acc: 52.970,69.200,75.130,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.357 |  Acc: 64.776,97.504,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=226 | Loss: 4.219 |  Acc: 53.150,69.020,75.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.347 |  Acc: 64.850,97.774,99.922,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=227 | Loss: 4.213 |  Acc: 53.150,69.240,75.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.348 |  Acc: 64.792,97.834,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=228 | Loss: 4.216 |  Acc: 53.220,69.120,75.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.344 |  Acc: 64.702,97.790,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=229 | Loss: 4.221 |  Acc: 53.000,69.040,75.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.338 |  Acc: 65.062,97.884,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=230 | Loss: 4.235 |  Acc: 52.760,68.980,75.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.334 |  Acc: 64.880,97.906,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=231 | Loss: 4.225 |  Acc: 52.920,68.950,75.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.330 |  Acc: 65.004,97.938,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=232 | Loss: 4.242 |  Acc: 52.940,68.730,75.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.329 |  Acc: 65.052,98.050,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=233 | Loss: 4.240 |  Acc: 52.970,68.960,75.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.328 |  Acc: 65.166,97.976,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=234 | Loss: 4.234 |  Acc: 52.830,68.940,75.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.330 |  Acc: 64.960,97.988,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=235 | Loss: 4.232 |  Acc: 53.060,69.040,74.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.334 |  Acc: 65.068,98.014,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=236 | Loss: 4.237 |  Acc: 52.940,69.030,75.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.329 |  Acc: 65.006,98.068,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=237 | Loss: 4.243 |  Acc: 53.020,68.960,75.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.325 |  Acc: 64.804,98.138,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=238 | Loss: 4.246 |  Acc: 53.150,68.820,74.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.328 |  Acc: 65.012,98.074,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=239 | Loss: 4.234 |  Acc: 53.240,69.130,74.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.324 |  Acc: 65.058,98.136,99.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=240 | Loss: 4.252 |  Acc: 53.240,68.900,74.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.322 |  Acc: 65.198,98.118,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=241 | Loss: 4.250 |  Acc: 53.080,68.860,74.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.320 |  Acc: 64.990,98.046,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=242 | Loss: 4.256 |  Acc: 53.140,68.750,74.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.320 |  Acc: 65.168,98.208,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=243 | Loss: 4.247 |  Acc: 53.120,69.010,74.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.320 |  Acc: 65.100,98.196,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=244 | Loss: 4.257 |  Acc: 53.020,68.810,75.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.317 |  Acc: 65.020,98.172,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=245 | Loss: 4.256 |  Acc: 53.010,68.910,74.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.312 |  Acc: 65.224,98.198,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=246 | Loss: 4.254 |  Acc: 52.960,68.920,75.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.315 |  Acc: 65.232,98.220,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=247 | Loss: 4.260 |  Acc: 53.030,68.920,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.314 |  Acc: 65.218,98.274,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=248 | Loss: 4.263 |  Acc: 53.160,68.760,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.316 |  Acc: 65.268,98.224,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=249 | Loss: 4.268 |  Acc: 53.130,68.840,75.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.311 |  Acc: 65.268,98.268,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=250 | Loss: 4.275 |  Acc: 52.960,68.770,75.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.317 |  Acc: 65.418,98.108,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=251 | Loss: 4.267 |  Acc: 53.110,68.860,74.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.313 |  Acc: 65.324,98.314,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=252 | Loss: 4.267 |  Acc: 52.990,68.910,74.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.312 |  Acc: 65.160,98.310,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=253 | Loss: 4.264 |  Acc: 53.040,68.790,75.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.313 |  Acc: 65.298,98.284,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=254 | Loss: 4.270 |  Acc: 52.850,68.800,74.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.306 |  Acc: 65.490,98.322,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=255 | Loss: 4.274 |  Acc: 53.120,68.830,74.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.309 |  Acc: 65.466,98.194,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=256 | Loss: 4.269 |  Acc: 53.050,68.770,74.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.303 |  Acc: 65.614,98.384,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=257 | Loss: 4.272 |  Acc: 53.140,68.770,74.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.307 |  Acc: 65.276,98.306,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=258 | Loss: 4.280 |  Acc: 52.940,68.980,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.300 |  Acc: 65.682,98.348,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=259 | Loss: 4.275 |  Acc: 53.070,69.080,74.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.303 |  Acc: 65.290,98.346,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=260 | Loss: 4.270 |  Acc: 53.090,68.860,74.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.307 |  Acc: 65.520,98.240,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=261 | Loss: 4.281 |  Acc: 52.850,68.790,75.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.292 |  Acc: 65.614,98.464,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=262 | Loss: 4.269 |  Acc: 53.140,68.920,74.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.294 |  Acc: 65.474,98.420,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=263 | Loss: 4.277 |  Acc: 53.060,68.940,74.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.286 |  Acc: 65.858,98.390,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=264 | Loss: 4.275 |  Acc: 52.790,68.670,74.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.290 |  Acc: 65.794,98.360,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=265 | Loss: 4.277 |  Acc: 53.120,68.790,74.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.289 |  Acc: 65.728,98.404,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=266 | Loss: 4.269 |  Acc: 53.210,68.890,74.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.288 |  Acc: 65.720,98.446,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=267 | Loss: 4.269 |  Acc: 53.150,68.980,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.292 |  Acc: 65.548,98.378,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=268 | Loss: 4.275 |  Acc: 53.180,68.910,74.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.290 |  Acc: 65.592,98.482,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=269 | Loss: 4.268 |  Acc: 53.150,68.780,74.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.290 |  Acc: 65.664,98.554,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=270 | Loss: 4.272 |  Acc: 53.300,68.810,74.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.293 |  Acc: 65.780,98.468,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=271 | Loss: 4.274 |  Acc: 53.200,68.630,74.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.290 |  Acc: 65.790,98.428,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=272 | Loss: 4.266 |  Acc: 53.200,68.940,75.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.289 |  Acc: 65.730,98.474,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=273 | Loss: 4.276 |  Acc: 53.120,68.820,74.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.287 |  Acc: 65.838,98.484,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=274 | Loss: 4.269 |  Acc: 53.190,68.730,74.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.291 |  Acc: 65.684,98.422,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=275 | Loss: 4.286 |  Acc: 53.210,68.760,74.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.286 |  Acc: 65.800,98.462,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=276 | Loss: 4.269 |  Acc: 53.260,68.750,74.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.291 |  Acc: 65.592,98.436,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=277 | Loss: 4.267 |  Acc: 52.980,68.820,74.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.290 |  Acc: 65.930,98.540,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=278 | Loss: 4.279 |  Acc: 52.990,68.700,74.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.287 |  Acc: 65.552,98.526,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=279 | Loss: 4.267 |  Acc: 53.040,68.810,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.286 |  Acc: 65.730,98.448,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=280 | Loss: 4.278 |  Acc: 53.150,68.870,74.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.285 |  Acc: 65.788,98.522,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=281 | Loss: 4.270 |  Acc: 53.220,68.860,74.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.285 |  Acc: 65.738,98.458,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=282 | Loss: 4.272 |  Acc: 52.990,68.930,74.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.289 |  Acc: 65.546,98.498,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=283 | Loss: 4.279 |  Acc: 53.030,68.830,75.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.287 |  Acc: 65.882,98.454,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=284 | Loss: 4.284 |  Acc: 53.020,68.750,74.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.291 |  Acc: 65.658,98.478,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=285 | Loss: 4.279 |  Acc: 53.070,68.690,74.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.289 |  Acc: 65.752,98.456,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=286 | Loss: 4.279 |  Acc: 53.150,68.830,74.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.287 |  Acc: 65.910,98.476,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=287 | Loss: 4.276 |  Acc: 53.180,68.860,74.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.287 |  Acc: 65.736,98.422,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=288 | Loss: 4.277 |  Acc: 53.260,68.840,74.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.284 |  Acc: 65.634,98.512,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=289 | Loss: 4.276 |  Acc: 52.990,68.750,74.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.287 |  Acc: 65.944,98.420,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=290 | Loss: 4.274 |  Acc: 53.210,68.930,74.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.287 |  Acc: 65.630,98.460,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=291 | Loss: 4.272 |  Acc: 53.200,68.810,74.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.286 |  Acc: 65.868,98.440,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=292 | Loss: 4.276 |  Acc: 53.290,68.790,74.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.288 |  Acc: 65.774,98.506,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=293 | Loss: 4.275 |  Acc: 53.200,68.800,74.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.287 |  Acc: 65.896,98.414,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=294 | Loss: 4.278 |  Acc: 53.220,68.820,74.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.287 |  Acc: 65.778,98.398,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=295 | Loss: 4.277 |  Acc: 53.010,68.950,74.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.290 |  Acc: 65.696,98.464,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=296 | Loss: 4.275 |  Acc: 53.060,68.770,74.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.283 |  Acc: 65.916,98.488,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=297 | Loss: 4.280 |  Acc: 53.030,68.860,74.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.287 |  Acc: 65.660,98.400,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=298 | Loss: 4.273 |  Acc: 52.980,68.830,74.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.283 |  Acc: 65.756,98.428,99.964,% | Adaptive Acc:91.580% | clf_exit: 0.563 0.427 0.011 
Testing: Epoch=299 | Loss: 4.283 |  Acc: 53.210,69.060,74.950,% | Adaptive Acc:66.300% | clf_exit: 0.552 0.366 0.083 
Testing: Epoch=299 | Loss: 10.332 |  Acc: 24.070,18.970,14.710,% | Adaptive Acc:18.690% | clf_exit: 0.102 0.001 0.897 
Testing: Epoch=299 | Loss: 9.006 |  Acc: 28.580,39.740,37.420,% | Adaptive Acc:38.840% | clf_exit: 0.117 0.013 0.870 
Testing: Epoch=299 | Loss: 7.864 |  Acc: 33.820,52.030,53.020,% | Adaptive Acc:52.900% | clf_exit: 0.146 0.063 0.791 
Testing: Epoch=299 | Loss: 6.846 |  Acc: 38.760,59.430,61.810,% | Adaptive Acc:60.880% | clf_exit: 0.188 0.136 0.676 
Testing: Epoch=299 | Loss: 5.961 |  Acc: 43.390,63.610,67.740,% | Adaptive Acc:66.110% | clf_exit: 0.245 0.213 0.541 
Testing: Epoch=299 | Loss: 5.225 |  Acc: 47.150,66.050,71.660,% | Adaptive Acc:69.070% | clf_exit: 0.306 0.282 0.411 
Testing: Epoch=299 | Loss: 4.662 |  Acc: 49.540,67.450,73.670,% | Adaptive Acc:70.090% | clf_exit: 0.369 0.324 0.307 
Testing: Epoch=299 | Loss: 4.287 |  Acc: 51.340,68.370,74.470,% | Adaptive Acc:69.540% | clf_exit: 0.425 0.351 0.224 
Testing: Epoch=299 | Loss: 4.110 |  Acc: 52.570,68.550,74.800,% | Adaptive Acc:68.840% | clf_exit: 0.471 0.366 0.162 
Testing: Epoch=299 | Loss: 4.120 |  Acc: 53.190,68.710,75.020,% | Adaptive Acc:67.720% | clf_exit: 0.514 0.370 0.115 
Testing: Epoch=299 | Loss: 4.283 |  Acc: 53.210,69.060,74.950,% | Adaptive Acc:66.300% | clf_exit: 0.552 0.366 0.083 
