==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=128, out_features=32, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=128, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=32, out_features=100, bias=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=288, out_features=64, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64])
      (linear_bw): Linear(in_features=64, out_features=288, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=64, out_features=100, bias=True)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=576, out_features=64, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64])
      (linear_bw): Linear(in_features=64, out_features=576, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=64, out_features=100, bias=True)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 14.103 | Acc: 0.781,3.125,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.759 | Acc: 1.488,2.232,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.559 | Acc: 2.077,3.277,3.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.436 | Acc: 2.485,3.624,4.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.314 | Acc: 2.903,4.321,5.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.210 | Acc: 3.187,4.788,6.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.118 | Acc: 3.480,5.223,6.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.030 | Acc: 3.679,5.668,7.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.951 | Acc: 3.911,5.988,7.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.869 | Acc: 4.083,6.444,8.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.801 | Acc: 4.237,6.814,8.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.732 | Acc: 4.426,7.208,8.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.661 | Acc: 4.603,7.469,9.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.593 | Acc: 4.837,7.824,9.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.534 | Acc: 5.013,8.113,9.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.474 | Acc: 5.225,8.342,10.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.422 | Acc: 5.335,8.526,10.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.365 | Acc: 5.478,8.756,10.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.309 | Acc: 5.586,8.981,10.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.253 | Acc: 5.733,9.197,11.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.148 | Acc: 9.375,14.062,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.346 | Acc: 8.482,13.542,14.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.316 | Acc: 8.117,13.377,15.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.309 | Acc: 8.504,13.435,15.126,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 11.027 | Acc: 7.812,8.594,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.187 | Acc: 8.929,12.351,15.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.105 | Acc: 9.108,13.853,17.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.034 | Acc: 9.324,14.139,17.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.011 | Acc: 9.616,14.236,17.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.972 | Acc: 9.677,14.403,17.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.959 | Acc: 9.685,14.379,18.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.917 | Acc: 9.935,14.727,18.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.881 | Acc: 10.171,15.033,18.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.843 | Acc: 10.126,15.262,19.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.796 | Acc: 10.238,15.493,19.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.751 | Acc: 10.506,15.770,19.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.710 | Acc: 10.643,16.017,20.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.674 | Acc: 10.740,16.152,20.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.643 | Acc: 10.871,16.328,20.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.610 | Acc: 11.018,16.507,20.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.572 | Acc: 11.181,16.703,21.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.545 | Acc: 11.290,16.874,21.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.522 | Acc: 11.323,16.991,21.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.489 | Acc: 11.368,17.192,21.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.886 | Acc: 12.500,21.875,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.044 | Acc: 12.016,18.118,24.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.996 | Acc: 11.566,18.883,24.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.005 | Acc: 11.860,18.660,23.937,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 9.666 | Acc: 17.188,24.219,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.833 | Acc: 14.025,21.205,25.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.707 | Acc: 14.215,21.589,26.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.692 | Acc: 14.088,21.350,26.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.700 | Acc: 13.850,21.296,26.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.668 | Acc: 14.179,21.589,27.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.630 | Acc: 14.301,21.707,27.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.607 | Acc: 14.506,21.842,27.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.580 | Acc: 14.688,21.933,27.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.558 | Acc: 14.844,21.957,27.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.537 | Acc: 15.007,22.135,27.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.516 | Acc: 15.091,22.225,28.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.486 | Acc: 15.249,22.429,28.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.459 | Acc: 15.359,22.540,28.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.437 | Acc: 15.400,22.620,28.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.412 | Acc: 15.480,22.799,28.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.392 | Acc: 15.591,22.834,28.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.378 | Acc: 15.689,22.872,28.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.357 | Acc: 15.785,23.013,29.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.330 | Acc: 15.976,23.212,29.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.106 | Acc: 17.188,26.562,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.134 | Acc: 17.894,24.107,31.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.071 | Acc: 17.683,24.352,31.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.084 | Acc: 17.316,24.129,31.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 8.223 | Acc: 26.562,34.375,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.694 | Acc: 18.341,27.121,34.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.759 | Acc: 18.102,26.277,34.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.772 | Acc: 17.994,26.294,34.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.776 | Acc: 18.210,26.534,34.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.750 | Acc: 18.247,27.034,34.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.724 | Acc: 18.434,27.098,34.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.699 | Acc: 18.440,27.144,34.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.696 | Acc: 18.663,27.276,34.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.663 | Acc: 18.828,27.473,35.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.649 | Acc: 18.917,27.480,35.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.639 | Acc: 18.870,27.531,35.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.613 | Acc: 19.039,27.726,35.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.600 | Acc: 19.124,27.835,35.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.594 | Acc: 19.117,27.855,35.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.584 | Acc: 19.113,27.850,35.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.574 | Acc: 19.093,27.833,35.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.561 | Acc: 19.139,27.951,35.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.549 | Acc: 19.140,28.004,35.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.525 | Acc: 19.240,28.160,35.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.681 | Acc: 13.281,25.781,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.799 | Acc: 14.397,27.418,36.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.789 | Acc: 13.891,27.382,35.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.793 | Acc: 13.870,27.049,35.745,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 8.574 | Acc: 18.750,28.125,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.947 | Acc: 22.321,31.659,40.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.988 | Acc: 22.332,31.364,40.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.958 | Acc: 22.541,31.481,40.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.008 | Acc: 22.087,31.163,40.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.010 | Acc: 21.991,31.227,40.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.001 | Acc: 22.017,31.457,40.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.010 | Acc: 21.936,31.466,40.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.999 | Acc: 21.778,31.425,40.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.991 | Acc: 21.767,31.449,40.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.988 | Acc: 21.778,31.499,40.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.975 | Acc: 21.949,31.646,41.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.975 | Acc: 22.011,31.681,41.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.966 | Acc: 22.031,31.693,41.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.961 | Acc: 22.067,31.675,41.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.956 | Acc: 22.137,31.785,41.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.966 | Acc: 21.994,31.751,41.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.949 | Acc: 22.109,31.882,41.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.934 | Acc: 22.182,31.951,41.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.925 | Acc: 22.269,32.052,41.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.842 | Acc: 24.219,41.406,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.091 | Acc: 20.350,30.580,43.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.109 | Acc: 19.646,30.450,42.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.098 | Acc: 19.531,30.366,42.495,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 7.297 | Acc: 28.125,35.156,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.475 | Acc: 24.554,34.524,46.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.513 | Acc: 23.971,34.223,45.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.489 | Acc: 24.488,34.926,45.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.509 | Acc: 24.633,34.520,45.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.513 | Acc: 24.466,34.677,44.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.520 | Acc: 24.161,34.433,44.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.513 | Acc: 24.202,34.685,44.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.515 | Acc: 24.253,34.720,45.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.538 | Acc: 23.990,34.366,44.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.538 | Acc: 23.943,34.387,44.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.529 | Acc: 23.968,34.555,44.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.520 | Acc: 24.008,34.676,44.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.507 | Acc: 24.045,34.806,45.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.500 | Acc: 24.158,34.898,45.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.488 | Acc: 24.265,34.985,45.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.486 | Acc: 24.270,34.969,45.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.474 | Acc: 24.283,35.060,45.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.462 | Acc: 24.385,35.139,45.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.449 | Acc: 24.471,35.326,45.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.326 | Acc: 24.219,40.625,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.886 | Acc: 22.545,31.064,45.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.813 | Acc: 22.523,31.860,45.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.817 | Acc: 22.298,32.275,44.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 7.375 | Acc: 22.656,29.688,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.112 | Acc: 25.707,37.984,48.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.124 | Acc: 25.762,38.338,48.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.130 | Acc: 25.807,37.666,48.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.129 | Acc: 25.637,37.616,48.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.115 | Acc: 25.789,37.925,48.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.109 | Acc: 26.065,38.120,48.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.114 | Acc: 25.947,38.115,48.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.111 | Acc: 26.068,38.383,48.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.112 | Acc: 26.057,38.350,48.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.127 | Acc: 25.906,38.211,48.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.121 | Acc: 26.032,38.271,48.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.102 | Acc: 26.015,38.349,48.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.086 | Acc: 26.167,38.410,49.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.086 | Acc: 26.215,38.303,49.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.077 | Acc: 26.269,38.369,49.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.071 | Acc: 26.258,38.369,49.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.075 | Acc: 26.228,38.219,49.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.073 | Acc: 26.260,38.225,49.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.063 | Acc: 26.388,38.363,49.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.493 | Acc: 17.188,37.500,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.473 | Acc: 22.731,35.454,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.473 | Acc: 22.523,34.928,46.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.470 | Acc: 22.669,35.259,46.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 5.901 | Acc: 34.375,50.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.768 | Acc: 26.674,41.927,53.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.701 | Acc: 27.572,41.959,53.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.703 | Acc: 28.215,42.162,53.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.680 | Acc: 28.308,42.274,53.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.720 | Acc: 27.908,41.739,53.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.715 | Acc: 27.880,41.516,53.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.712 | Acc: 27.981,41.567,53.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.717 | Acc: 27.921,41.397,53.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.719 | Acc: 27.931,41.389,52.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.710 | Acc: 27.923,41.398,52.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.702 | Acc: 28.086,41.516,52.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.711 | Acc: 27.943,41.442,52.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.714 | Acc: 27.874,41.373,52.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.717 | Acc: 27.853,41.292,52.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.718 | Acc: 27.785,41.238,52.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.713 | Acc: 27.894,41.270,52.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.714 | Acc: 27.939,41.308,52.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.703 | Acc: 27.976,41.400,52.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.703 | Acc: 27.998,41.406,52.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.685 | Acc: 28.906,43.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.092 | Acc: 25.595,38.579,51.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.043 | Acc: 25.229,39.158,51.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.063 | Acc: 24.872,38.858,51.844,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 5.960 | Acc: 36.719,47.656,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.446 | Acc: 28.906,42.597,55.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.372 | Acc: 29.535,43.540,57.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.363 | Acc: 29.841,43.212,56.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.344 | Acc: 29.967,43.605,57.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.381 | Acc: 29.571,43.649,56.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.390 | Acc: 29.739,43.756,56.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.403 | Acc: 29.737,43.617,56.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.402 | Acc: 29.809,43.604,56.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.410 | Acc: 29.847,43.517,56.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.420 | Acc: 29.711,43.365,55.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.426 | Acc: 29.666,43.389,55.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.430 | Acc: 29.532,43.406,55.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.434 | Acc: 29.541,43.397,55.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.441 | Acc: 29.448,43.355,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.428 | Acc: 29.488,43.503,55.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.422 | Acc: 29.527,43.538,55.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.416 | Acc: 29.550,43.624,55.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.404 | Acc: 29.694,43.739,55.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.401 | Acc: 29.733,43.750,55.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.120 | Acc: 25.781,49.219,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.644 | Acc: 27.158,43.080,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.671 | Acc: 26.848,42.588,53.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.670 | Acc: 26.883,42.572,53.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 6.461 | Acc: 25.781,39.844,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.052 | Acc: 30.692,46.726,60.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.109 | Acc: 31.117,46.284,59.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.134 | Acc: 30.904,45.825,59.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.152 | Acc: 30.739,45.428,59.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.165 | Acc: 31.095,45.343,58.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.164 | Acc: 31.069,45.384,58.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.145 | Acc: 31.028,45.656,58.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.147 | Acc: 31.041,45.866,58.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.146 | Acc: 31.172,45.861,58.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.149 | Acc: 30.838,45.771,58.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.141 | Acc: 30.833,45.956,58.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.134 | Acc: 30.780,45.980,58.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.126 | Acc: 30.879,46.031,58.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.130 | Acc: 30.964,46.027,58.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.132 | Acc: 30.970,46.115,58.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.128 | Acc: 30.943,46.121,58.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.129 | Acc: 30.989,46.089,58.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.123 | Acc: 31.066,46.113,58.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.122 | Acc: 31.024,46.118,58.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.168 | Acc: 27.344,46.875,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.548 | Acc: 29.688,41.369,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.520 | Acc: 29.688,41.521,55.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.538 | Acc: 29.329,41.329,55.584,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 5.419 | Acc: 33.594,52.344,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.842 | Acc: 33.668,49.740,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.771 | Acc: 33.136,49.162,62.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.784 | Acc: 33.107,48.911,62.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.794 | Acc: 32.890,48.881,61.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.806 | Acc: 32.743,48.786,61.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.816 | Acc: 32.470,48.670,61.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.835 | Acc: 32.303,48.526,61.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.834 | Acc: 32.468,48.622,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.844 | Acc: 32.359,48.627,61.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.847 | Acc: 32.354,48.628,61.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.866 | Acc: 32.226,48.374,61.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.877 | Acc: 32.239,48.266,61.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.870 | Acc: 32.277,48.303,61.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.880 | Acc: 32.243,48.229,61.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.892 | Acc: 32.086,48.126,61.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.888 | Acc: 32.077,48.243,61.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.891 | Acc: 32.043,48.183,61.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.888 | Acc: 32.103,48.195,61.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.894 | Acc: 32.105,48.222,61.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.116 | Acc: 35.156,47.656,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.537 | Acc: 26.190,44.494,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.535 | Acc: 26.715,44.912,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.534 | Acc: 26.498,44.672,56.007,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 5.845 | Acc: 23.438,44.531,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.610 | Acc: 32.775,50.149,64.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.607 | Acc: 32.755,50.076,64.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.624 | Acc: 32.697,49.795,64.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.627 | Acc: 32.735,50.096,64.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.637 | Acc: 33.006,50.364,64.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.623 | Acc: 33.168,50.575,64.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.622 | Acc: 33.067,50.715,64.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.623 | Acc: 33.186,50.616,63.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.623 | Acc: 33.210,50.656,63.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.624 | Acc: 33.259,50.645,63.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.645 | Acc: 33.106,50.368,63.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.660 | Acc: 33.026,50.188,63.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.679 | Acc: 32.983,50.066,63.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.684 | Acc: 33.040,50.003,63.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.692 | Acc: 33.023,49.917,63.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.698 | Acc: 33.053,49.808,63.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.695 | Acc: 33.090,49.757,63.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.688 | Acc: 33.150,49.758,63.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.692 | Acc: 33.145,49.694,63.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.873 | Acc: 35.938,56.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.432 | Acc: 26.972,45.201,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.468 | Acc: 27.344,44.703,58.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.470 | Acc: 27.203,44.762,57.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 5.740 | Acc: 33.594,50.000,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.318 | Acc: 33.780,51.376,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.405 | Acc: 33.594,51.086,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.424 | Acc: 33.094,51.050,66.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.401 | Acc: 33.594,51.620,66.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.410 | Acc: 33.965,51.717,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.417 | Acc: 34.155,51.782,66.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.437 | Acc: 33.976,51.668,65.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.437 | Acc: 34.016,51.713,65.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.447 | Acc: 34.051,51.571,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.462 | Acc: 34.025,51.489,65.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.461 | Acc: 34.138,51.548,65.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.458 | Acc: 34.294,51.699,65.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.470 | Acc: 34.145,51.655,65.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.471 | Acc: 34.219,51.626,65.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.470 | Acc: 34.292,51.581,65.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.470 | Acc: 34.346,51.694,65.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.472 | Acc: 34.302,51.650,65.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.475 | Acc: 34.375,51.634,65.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.474 | Acc: 34.383,51.688,65.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.436 | Acc: 33.594,58.594,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.020 | Acc: 31.771,47.954,60.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.018 | Acc: 31.383,47.999,59.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.032 | Acc: 31.109,48.066,59.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 4.755 | Acc: 44.531,57.031,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.225 | Acc: 36.049,53.571,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.298 | Acc: 35.023,52.191,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.316 | Acc: 34.836,52.190,67.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.256 | Acc: 35.822,52.758,68.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.257 | Acc: 35.466,52.924,67.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.259 | Acc: 35.324,52.809,67.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.258 | Acc: 35.411,52.914,67.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.283 | Acc: 35.282,52.751,67.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.292 | Acc: 35.286,52.788,67.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.290 | Acc: 35.257,52.814,67.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.289 | Acc: 35.291,52.924,67.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.300 | Acc: 35.192,52.765,67.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.303 | Acc: 35.174,52.823,67.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.303 | Acc: 35.262,52.922,67.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.302 | Acc: 35.211,52.834,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.309 | Acc: 35.268,52.799,67.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.317 | Acc: 35.241,52.754,67.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.318 | Acc: 35.180,52.703,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.317 | Acc: 35.244,52.772,67.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.116 | Acc: 30.469,52.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.089 | Acc: 31.213,47.247,59.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.077 | Acc: 31.574,46.456,59.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.054 | Acc: 30.802,46.632,59.926,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 4.938 | Acc: 32.812,57.031,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.026 | Acc: 35.045,55.246,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.058 | Acc: 35.042,54.840,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.047 | Acc: 35.989,55.161,70.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.015 | Acc: 36.449,55.401,70.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.043 | Acc: 36.262,55.229,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.047 | Acc: 36.163,55.088,70.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.061 | Acc: 36.059,55.003,70.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.057 | Acc: 36.156,54.988,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.067 | Acc: 36.196,55.158,70.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.082 | Acc: 36.058,54.948,69.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.092 | Acc: 36.075,54.924,69.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.120 | Acc: 35.879,54.704,69.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.118 | Acc: 35.869,54.741,69.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.129 | Acc: 35.849,54.590,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.128 | Acc: 35.909,54.649,69.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.141 | Acc: 35.843,54.481,68.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.146 | Acc: 35.860,54.440,68.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.152 | Acc: 35.849,54.337,68.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.160 | Acc: 35.837,54.245,68.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.911 | Acc: 30.469,53.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.077 | Acc: 29.725,48.958,61.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.071 | Acc: 29.402,48.399,61.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.085 | Acc: 29.009,48.015,60.835,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 5.343 | Acc: 35.156,53.125,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.055 | Acc: 34.077,56.138,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.981 | Acc: 35.537,56.669,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.929 | Acc: 36.078,56.596,72.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.958 | Acc: 36.034,56.086,72.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.974 | Acc: 36.023,55.732,71.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.956 | Acc: 36.293,56.192,71.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.965 | Acc: 36.181,55.995,71.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.982 | Acc: 36.277,55.867,71.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.981 | Acc: 36.447,55.784,70.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.985 | Acc: 36.458,55.819,70.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.992 | Acc: 36.404,55.755,70.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.987 | Acc: 36.456,55.705,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.992 | Acc: 36.452,55.702,70.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.992 | Acc: 36.552,55.713,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.998 | Acc: 36.529,55.684,70.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.992 | Acc: 36.582,55.834,70.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.994 | Acc: 36.604,55.824,70.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.004 | Acc: 36.593,55.763,70.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.007 | Acc: 36.528,55.705,70.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.857 | Acc: 35.938,58.594,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.893 | Acc: 32.068,50.409,62.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.918 | Acc: 31.974,49.867,61.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.931 | Acc: 31.621,49.475,60.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 4.983 | Acc: 37.500,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.829 | Acc: 37.240,56.845,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.896 | Acc: 36.509,56.441,72.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.910 | Acc: 36.603,56.545,72.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.884 | Acc: 37.133,56.848,72.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.845 | Acc: 37.392,57.209,72.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.827 | Acc: 37.448,57.244,73.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.862 | Acc: 37.284,56.954,72.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.873 | Acc: 37.248,56.774,72.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.853 | Acc: 37.319,56.984,72.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.861 | Acc: 37.317,56.880,72.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.864 | Acc: 37.334,56.915,72.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.872 | Acc: 37.325,56.898,72.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.871 | Acc: 37.374,56.888,72.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.871 | Acc: 37.347,56.870,72.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.869 | Acc: 37.394,56.855,71.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.865 | Acc: 37.502,56.841,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.873 | Acc: 37.374,56.807,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.886 | Acc: 37.294,56.681,71.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.881 | Acc: 37.356,56.705,71.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.534 | Acc: 32.812,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.740 | Acc: 33.519,51.153,62.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.737 | Acc: 33.194,51.277,62.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.733 | Acc: 32.966,51.447,61.975,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 4.166 | Acc: 46.875,62.500,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.656 | Acc: 38.579,58.036,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.643 | Acc: 38.796,58.155,75.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.649 | Acc: 38.601,58.056,75.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.634 | Acc: 38.735,58.594,75.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.642 | Acc: 38.800,58.586,75.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.658 | Acc: 38.753,58.387,74.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.672 | Acc: 38.514,58.306,74.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.692 | Acc: 38.500,58.186,74.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.696 | Acc: 38.488,58.093,74.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.708 | Acc: 38.437,57.976,74.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.702 | Acc: 38.529,58.049,74.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.714 | Acc: 38.362,58.001,73.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.725 | Acc: 38.413,57.917,73.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.728 | Acc: 38.340,57.893,73.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.741 | Acc: 38.245,57.815,73.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.744 | Acc: 38.284,57.795,73.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.741 | Acc: 38.270,57.785,73.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.747 | Acc: 38.249,57.793,73.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.754 | Acc: 38.181,57.774,73.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.409 | Acc: 34.375,56.250,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.793 | Acc: 32.552,50.818,63.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.802 | Acc: 32.489,50.991,62.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.803 | Acc: 32.531,50.897,62.897,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 5.120 | Acc: 35.938,54.688,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.686 | Acc: 37.091,58.259,76.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 38.053,59.127,76.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.549 | Acc: 38.576,59.682,76.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.569 | Acc: 38.532,59.510,76.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.574 | Acc: 38.699,59.182,76.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.573 | Acc: 38.843,59.394,76.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.578 | Acc: 38.846,59.425,76.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.593 | Acc: 38.757,59.278,75.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.604 | Acc: 38.717,59.233,75.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.612 | Acc: 38.783,59.274,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.617 | Acc: 38.727,59.219,75.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.629 | Acc: 38.557,59.119,75.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.626 | Acc: 38.614,59.139,75.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.630 | Acc: 38.554,59.130,75.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.635 | Acc: 38.588,59.069,75.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.633 | Acc: 38.559,59.081,74.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.637 | Acc: 38.437,59.079,74.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.645 | Acc: 38.428,58.942,74.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.650 | Acc: 38.421,58.926,74.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.470 | Acc: 38.281,56.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.744 | Acc: 34.189,51.376,62.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.743 | Acc: 33.803,50.915,62.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.763 | Acc: 33.325,50.384,62.718,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 4.336 | Acc: 35.938,58.594,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.441 | Acc: 38.690,61.607,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.459 | Acc: 39.101,61.319,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.444 | Acc: 39.139,60.861,77.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.449 | Acc: 39.198,60.571,77.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.474 | Acc: 38.954,60.326,76.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.490 | Acc: 39.037,60.124,76.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.500 | Acc: 39.018,59.968,76.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.513 | Acc: 38.917,59.826,76.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.518 | Acc: 39.002,59.738,76.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.529 | Acc: 38.864,59.659,76.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.521 | Acc: 38.918,59.877,76.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.526 | Acc: 38.962,59.819,76.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.532 | Acc: 38.892,59.776,76.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.533 | Acc: 38.915,59.761,76.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.537 | Acc: 38.902,59.686,76.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.542 | Acc: 38.934,59.638,75.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.548 | Acc: 38.852,59.561,75.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.551 | Acc: 38.885,59.561,75.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.553 | Acc: 38.935,59.568,75.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.048 | Acc: 40.625,56.250,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.502 | Acc: 35.565,54.241,64.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.500 | Acc: 34.909,53.754,64.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.502 | Acc: 34.631,53.881,63.653,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 4.463 | Acc: 39.844,57.031,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.387 | Acc: 40.290,60.938,79.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.381 | Acc: 39.463,60.747,79.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.353 | Acc: 39.472,61.155,79.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.363 | Acc: 39.545,61.391,79.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.395 | Acc: 39.124,60.891,78.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.423 | Acc: 38.966,60.486,78.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.424 | Acc: 38.996,60.444,78.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.427 | Acc: 38.980,60.321,78.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.445 | Acc: 38.993,60.109,78.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.456 | Acc: 39.074,60.036,77.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.451 | Acc: 39.349,60.011,77.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.461 | Acc: 39.273,59.923,77.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.463 | Acc: 39.317,59.806,77.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.460 | Acc: 39.363,59.834,77.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.457 | Acc: 39.434,59.930,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.465 | Acc: 39.420,59.908,77.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.471 | Acc: 39.395,59.900,77.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.469 | Acc: 39.476,60.057,76.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.470 | Acc: 39.481,60.007,76.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.794 | Acc: 36.719,52.344,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.651 | Acc: 34.635,51.674,63.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.602 | Acc: 35.575,52.039,63.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.615 | Acc: 35.156,51.844,63.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 4.279 | Acc: 40.625,59.375,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.382 | Acc: 38.616,59.561,79.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.333 | Acc: 39.710,61.185,79.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.285 | Acc: 39.857,61.693,79.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.285 | Acc: 39.699,61.892,79.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.300 | Acc: 39.681,61.866,79.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.318 | Acc: 39.585,61.635,78.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.319 | Acc: 39.772,61.702,78.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.329 | Acc: 39.849,61.500,78.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.324 | Acc: 40.029,61.477,78.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.345 | Acc: 39.863,61.213,78.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.355 | Acc: 39.918,61.227,78.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.351 | Acc: 39.977,61.203,78.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.352 | Acc: 39.969,61.189,78.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.360 | Acc: 39.949,61.049,78.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.360 | Acc: 40.057,60.943,78.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.368 | Acc: 40.051,60.928,78.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.373 | Acc: 40.038,60.880,77.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.378 | Acc: 39.997,60.918,77.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.378 | Acc: 39.989,60.966,77.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.442 | Acc: 39.062,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.499 | Acc: 34.301,53.571,64.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.487 | Acc: 34.775,53.601,63.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.501 | Acc: 34.375,53.727,63.998,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 4.444 | Acc: 43.750,60.938,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.131 | Acc: 41.146,64.100,81.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.167 | Acc: 40.758,63.377,81.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.159 | Acc: 41.150,63.986,81.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.136 | Acc: 41.474,63.783,81.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.173 | Acc: 41.058,63.235,80.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.197 | Acc: 40.851,63.075,80.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.209 | Acc: 40.758,62.805,80.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.214 | Acc: 40.523,62.646,80.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.226 | Acc: 40.470,62.539,80.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.239 | Acc: 40.450,62.426,79.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.247 | Acc: 40.519,62.422,79.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.253 | Acc: 40.609,62.305,79.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.258 | Acc: 40.448,62.281,79.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.263 | Acc: 40.450,62.233,79.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.274 | Acc: 40.420,62.204,79.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.277 | Acc: 40.486,62.191,79.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.285 | Acc: 40.476,62.133,79.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.295 | Acc: 40.424,62.022,78.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.296 | Acc: 40.514,61.959,78.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.293 | Acc: 38.281,57.031,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.344 | Acc: 36.161,54.948,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.315 | Acc: 36.681,55.107,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.321 | Acc: 36.578,55.033,65.958,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 4.502 | Acc: 37.500,61.719,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.100 | Acc: 40.774,63.914,81.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.160 | Acc: 40.739,63.662,81.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.150 | Acc: 40.407,63.217,81.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.177 | Acc: 40.287,62.722,81.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.159 | Acc: 40.563,63.119,81.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.172 | Acc: 40.573,62.907,81.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.180 | Acc: 40.570,62.855,80.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.172 | Acc: 40.727,62.840,80.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.166 | Acc: 40.884,62.996,80.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.167 | Acc: 41.014,62.963,80.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.173 | Acc: 41.003,62.924,80.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.188 | Acc: 40.868,62.743,80.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.196 | Acc: 40.906,62.698,79.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.200 | Acc: 40.925,62.664,79.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.197 | Acc: 41.035,62.643,79.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.204 | Acc: 40.988,62.622,79.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.210 | Acc: 41.008,62.571,79.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.220 | Acc: 41.041,62.511,79.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.227 | Acc: 40.959,62.477,79.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.300 | Acc: 40.625,56.250,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.487 | Acc: 34.710,55.246,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.443 | Acc: 35.404,55.793,64.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.446 | Acc: 35.195,55.571,64.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 4.297 | Acc: 40.625,61.719,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.053 | Acc: 41.183,63.318,82.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.059 | Acc: 41.387,64.062,82.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.050 | Acc: 41.201,64.178,82.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.061 | Acc: 41.503,64.014,82.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.095 | Acc: 41.329,63.529,81.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.101 | Acc: 41.006,63.520,81.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.123 | Acc: 40.919,63.121,81.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.121 | Acc: 40.979,63.150,81.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.129 | Acc: 40.733,63.100,81.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.122 | Acc: 40.882,63.207,81.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.127 | Acc: 40.862,63.218,81.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.126 | Acc: 41.037,63.213,80.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.134 | Acc: 41.050,63.135,80.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.146 | Acc: 41.031,62.973,80.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.149 | Acc: 41.116,62.926,80.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.154 | Acc: 41.134,62.877,80.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.164 | Acc: 41.074,62.834,80.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.166 | Acc: 41.062,62.784,80.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.169 | Acc: 41.052,62.826,80.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.053 | Acc: 35.938,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.409 | Acc: 36.682,56.994,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.420 | Acc: 36.147,56.364,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.437 | Acc: 35.771,55.930,64.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 3.338 | Acc: 50.781,68.750,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.874 | Acc: 41.481,65.290,84.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.931 | Acc: 41.463,64.520,84.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.962 | Acc: 41.650,64.562,83.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.973 | Acc: 41.696,64.468,83.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.956 | Acc: 41.762,64.813,83.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.965 | Acc: 41.955,64.695,83.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.975 | Acc: 41.755,64.605,83.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.987 | Acc: 41.595,64.504,83.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.998 | Acc: 41.635,64.347,82.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.006 | Acc: 41.783,64.370,82.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.020 | Acc: 41.760,64.186,82.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.036 | Acc: 41.610,64.017,82.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.047 | Acc: 41.523,63.817,82.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.050 | Acc: 41.476,63.887,82.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.057 | Acc: 41.456,63.852,81.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.062 | Acc: 41.455,63.841,81.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.062 | Acc: 41.427,63.879,81.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.071 | Acc: 41.411,63.790,81.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.076 | Acc: 41.437,63.749,81.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.432 | Acc: 41.406,52.344,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.487 | Acc: 35.565,54.464,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.523 | Acc: 35.899,54.306,65.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.547 | Acc: 34.785,54.201,64.972,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 3.783 | Acc: 45.312,60.938,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.906 | Acc: 42.411,65.067,83.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.878 | Acc: 42.473,64.996,84.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.917 | Acc: 42.059,64.703,83.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.913 | Acc: 42.178,64.892,83.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.926 | Acc: 42.149,64.774,83.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.929 | Acc: 42.136,64.669,83.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.952 | Acc: 41.905,64.478,83.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.956 | Acc: 42.105,64.475,83.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.952 | Acc: 42.183,64.580,83.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.967 | Acc: 42.125,64.389,83.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.972 | Acc: 42.053,64.324,83.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.976 | Acc: 42.055,64.387,82.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.981 | Acc: 42.128,64.404,82.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.995 | Acc: 42.040,64.229,82.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.001 | Acc: 42.078,64.140,82.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.013 | Acc: 41.993,64.092,82.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.026 | Acc: 41.942,63.973,82.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.033 | Acc: 41.852,63.881,81.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.035 | Acc: 41.939,63.874,81.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.915 | Acc: 42.188,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.354 | Acc: 36.198,56.176,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.345 | Acc: 36.338,56.079,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.357 | Acc: 36.219,56.007,65.074,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 3.892 | Acc: 43.750,64.844,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.879 | Acc: 42.262,65.439,84.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.828 | Acc: 42.168,66.482,84.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.838 | Acc: 41.906,66.099,84.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.849 | Acc: 42.245,66.059,84.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.851 | Acc: 41.793,65.787,84.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.872 | Acc: 41.665,65.702,84.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.871 | Acc: 41.617,65.653,84.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.879 | Acc: 41.605,65.494,84.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.892 | Acc: 41.708,65.310,83.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.900 | Acc: 41.795,65.291,83.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.916 | Acc: 41.760,65.183,83.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.926 | Acc: 41.763,65.184,83.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.935 | Acc: 41.786,65.008,83.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.940 | Acc: 41.834,65.038,83.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.948 | Acc: 41.793,64.955,83.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.948 | Acc: 41.825,64.900,83.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.950 | Acc: 41.910,64.901,82.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.956 | Acc: 41.921,64.852,82.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.965 | Acc: 41.935,64.758,82.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.225 | Acc: 42.188,57.812,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.315 | Acc: 36.161,56.473,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.280 | Acc: 36.966,56.479,64.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.272 | Acc: 36.783,57.082,65.113,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 3.771 | Acc: 40.625,67.969,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.852 | Acc: 42.894,66.667,84.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.765 | Acc: 44.226,67.416,85.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.768 | Acc: 43.545,67.175,85.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.758 | Acc: 43.499,66.917,85.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.781 | Acc: 43.410,66.468,85.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.805 | Acc: 42.975,66.083,85.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.807 | Acc: 42.880,66.046,85.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.804 | Acc: 43.114,65.897,85.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.815 | Acc: 43.120,65.957,85.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.820 | Acc: 43.128,65.944,85.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.835 | Acc: 42.916,65.841,84.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.839 | Acc: 43.008,65.871,84.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.851 | Acc: 42.978,65.730,84.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.860 | Acc: 42.894,65.692,84.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.861 | Acc: 42.935,65.648,84.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.869 | Acc: 42.869,65.576,84.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.879 | Acc: 42.811,65.403,84.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.890 | Acc: 42.705,65.337,84.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.901 | Acc: 42.610,65.266,83.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.497 | Acc: 34.375,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.573 | Acc: 33.036,55.320,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.567 | Acc: 33.746,54.554,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.600 | Acc: 33.197,54.380,65.740,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 3.643 | Acc: 43.750,65.625,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.756 | Acc: 43.415,66.555,85.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.736 | Acc: 43.388,67.378,86.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.751 | Acc: 43.071,66.906,85.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.771 | Acc: 42.670,66.744,85.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.797 | Acc: 42.744,66.476,85.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.810 | Acc: 42.833,66.277,85.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.799 | Acc: 42.891,66.356,85.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.795 | Acc: 43.095,66.498,85.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.797 | Acc: 43.206,66.540,85.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.804 | Acc: 43.198,66.360,85.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.810 | Acc: 43.167,66.244,84.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.824 | Acc: 43.131,66.050,84.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.834 | Acc: 43.017,65.912,84.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.841 | Acc: 43.041,65.711,84.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.850 | Acc: 42.917,65.685,84.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.853 | Acc: 42.905,65.615,84.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.857 | Acc: 42.900,65.538,84.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.866 | Acc: 42.910,65.456,84.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.871 | Acc: 42.928,65.477,84.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.432 | Acc: 31.250,52.344,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.706 | Acc: 32.738,52.790,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.742 | Acc: 33.422,53.144,64.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.731 | Acc: 33.017,53.356,64.562,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 3.899 | Acc: 42.969,63.281,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.797 | Acc: 42.708,65.439,86.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.684 | Acc: 44.569,66.635,86.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.671 | Acc: 44.595,66.790,86.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.686 | Acc: 44.435,66.860,86.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.720 | Acc: 43.982,66.576,86.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.724 | Acc: 43.950,66.522,86.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.724 | Acc: 43.850,66.667,85.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.734 | Acc: 43.672,66.639,85.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.750 | Acc: 43.539,66.354,85.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.751 | Acc: 43.532,66.309,85.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.755 | Acc: 43.478,66.261,85.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.763 | Acc: 43.332,66.209,85.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.773 | Acc: 43.223,66.071,85.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.769 | Acc: 43.286,66.181,85.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.787 | Acc: 43.182,66.061,85.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.786 | Acc: 43.178,66.036,84.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.795 | Acc: 43.212,65.969,84.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.801 | Acc: 43.285,65.917,84.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.813 | Acc: 43.209,65.805,84.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.238 | Acc: 36.719,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.350 | Acc: 35.751,57.552,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.390 | Acc: 35.442,57.222,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.407 | Acc: 34.990,56.711,66.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 3.699 | Acc: 43.750,68.750,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.650 | Acc: 42.671,67.225,87.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.626 | Acc: 43.064,67.435,87.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.619 | Acc: 43.199,67.623,87.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.627 | Acc: 43.634,67.930,87.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.651 | Acc: 43.580,67.698,87.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.653 | Acc: 43.518,67.601,87.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.676 | Acc: 43.235,67.426,86.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.676 | Acc: 43.444,67.352,86.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.691 | Acc: 43.383,67.231,86.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.702 | Acc: 43.373,67.168,86.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.721 | Acc: 43.234,67.039,85.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.738 | Acc: 43.060,66.837,85.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.747 | Acc: 43.080,66.792,85.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.755 | Acc: 43.091,66.673,85.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.759 | Acc: 43.143,66.611,85.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.774 | Acc: 43.039,66.506,85.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.778 | Acc: 43.033,66.496,85.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.788 | Acc: 43.012,66.389,84.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.786 | Acc: 43.024,66.343,84.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.073 | Acc: 49.219,59.375,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.202 | Acc: 40.439,57.068,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.238 | Acc: 39.901,56.498,66.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.272 | Acc: 39.075,56.224,66.176,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 3.000 | Acc: 46.875,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.688 | Acc: 42.597,66.071,86.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.686 | Acc: 43.445,66.368,86.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.661 | Acc: 43.122,66.637,87.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.668 | Acc: 43.451,66.937,87.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.669 | Acc: 43.410,67.002,87.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.666 | Acc: 43.285,67.246,87.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.680 | Acc: 43.257,67.176,86.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.688 | Acc: 43.333,67.173,86.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.687 | Acc: 43.392,67.080,86.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.699 | Acc: 43.280,67.028,86.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.703 | Acc: 43.368,67.011,86.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.712 | Acc: 43.335,66.944,86.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.711 | Acc: 43.412,66.960,86.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.717 | Acc: 43.427,66.998,86.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.715 | Acc: 43.511,66.975,86.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.717 | Acc: 43.485,66.927,86.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.729 | Acc: 43.418,66.839,85.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.737 | Acc: 43.395,66.731,85.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.746 | Acc: 43.360,66.677,85.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.276 | Acc: 37.500,57.812,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.409 | Acc: 34.226,57.143,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.429 | Acc: 34.623,56.764,65.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.439 | Acc: 34.567,56.749,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 3.130 | Acc: 48.438,71.094,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.509 | Acc: 44.792,68.750,87.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.512 | Acc: 44.607,68.350,88.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.490 | Acc: 44.775,68.571,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.518 | Acc: 44.579,68.412,88.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.529 | Acc: 44.485,68.371,88.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.547 | Acc: 44.267,68.292,88.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.562 | Acc: 44.238,68.129,88.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.583 | Acc: 43.915,68.080,87.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.588 | Acc: 44.044,68.176,87.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.605 | Acc: 43.843,67.992,87.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.624 | Acc: 43.764,67.711,87.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.646 | Acc: 43.666,67.521,86.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.649 | Acc: 43.819,67.535,86.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.653 | Acc: 43.856,67.502,86.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.663 | Acc: 43.740,67.372,86.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.684 | Acc: 43.604,67.231,86.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.697 | Acc: 43.560,67.061,86.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.704 | Acc: 43.601,67.062,86.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.707 | Acc: 43.551,67.067,86.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.077 | Acc: 40.625,56.250,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.227 | Acc: 36.868,59.003,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.270 | Acc: 37.100,58.003,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.288 | Acc: 36.668,57.877,65.740,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 3.330 | Acc: 47.656,73.438,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.566 | Acc: 44.717,68.899,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.594 | Acc: 43.502,68.312,88.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.550 | Acc: 44.057,68.788,88.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.538 | Acc: 44.155,68.586,88.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.552 | Acc: 44.160,68.348,88.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.547 | Acc: 44.092,68.382,88.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.570 | Acc: 43.889,68.118,88.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.569 | Acc: 43.968,68.279,88.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.584 | Acc: 43.754,68.016,88.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.597 | Acc: 43.773,67.895,87.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.611 | Acc: 43.679,67.725,87.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.613 | Acc: 43.662,67.671,87.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.622 | Acc: 43.603,67.595,87.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.630 | Acc: 43.578,67.468,87.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.632 | Acc: 43.698,67.491,87.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.634 | Acc: 43.738,67.424,87.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.641 | Acc: 43.711,67.380,86.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.647 | Acc: 43.774,67.289,86.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.659 | Acc: 43.693,67.157,86.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.807 | Acc: 41.406,58.594,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.405 | Acc: 36.124,55.580,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.409 | Acc: 37.138,55.183,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.436 | Acc: 36.642,55.072,66.124,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 3.747 | Acc: 42.188,63.281,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.602 | Acc: 43.452,68.750,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.544 | Acc: 44.055,69.284,88.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.583 | Acc: 43.481,68.878,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.543 | Acc: 43.798,69.213,89.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.548 | Acc: 43.951,68.998,88.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.542 | Acc: 44.202,68.937,88.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.542 | Acc: 44.359,68.927,88.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.545 | Acc: 44.284,68.930,88.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.554 | Acc: 44.268,68.897,88.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.568 | Acc: 44.100,68.699,88.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.568 | Acc: 44.043,68.715,88.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.570 | Acc: 43.964,68.614,87.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.581 | Acc: 43.983,68.475,87.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.589 | Acc: 43.995,68.430,87.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.602 | Acc: 43.955,68.221,87.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.610 | Acc: 43.974,68.093,87.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.621 | Acc: 43.908,67.999,86.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.628 | Acc: 43.901,67.882,86.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.632 | Acc: 43.900,67.848,86.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.094 | Acc: 41.406,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.344 | Acc: 35.677,56.845,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.354 | Acc: 36.242,56.079,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.363 | Acc: 35.669,55.635,66.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 3.664 | Acc: 46.875,67.188,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.418 | Acc: 46.280,71.131,88.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.497 | Acc: 44.722,69.836,88.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.473 | Acc: 44.672,69.839,89.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.472 | Acc: 44.782,69.830,88.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.495 | Acc: 44.748,69.554,88.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.504 | Acc: 44.647,69.609,88.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.510 | Acc: 44.498,69.404,88.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.523 | Acc: 44.308,69.192,88.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.540 | Acc: 44.259,68.888,88.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.544 | Acc: 44.306,68.812,87.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.551 | Acc: 44.273,68.803,87.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.560 | Acc: 44.256,68.637,87.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.570 | Acc: 44.199,68.537,87.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.583 | Acc: 44.136,68.383,87.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.584 | Acc: 44.132,68.350,87.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.588 | Acc: 44.103,68.341,87.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.589 | Acc: 44.089,68.328,87.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.589 | Acc: 44.049,68.326,87.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.598 | Acc: 43.974,68.207,87.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.779 | Acc: 39.844,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.213 | Acc: 36.942,58.743,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.206 | Acc: 37.290,58.251,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.223 | Acc: 37.129,58.030,66.842,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 3.370 | Acc: 49.219,66.406,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.504 | Acc: 43.899,69.196,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.481 | Acc: 43.750,69.398,89.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.446 | Acc: 44.378,69.826,89.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.453 | Acc: 44.541,69.734,89.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.446 | Acc: 44.740,69.872,89.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.443 | Acc: 44.899,69.880,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.451 | Acc: 44.770,69.875,88.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.460 | Acc: 44.740,69.638,88.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.461 | Acc: 44.829,69.643,88.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.482 | Acc: 44.706,69.422,88.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.491 | Acc: 44.644,69.305,88.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.506 | Acc: 44.625,69.077,88.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.510 | Acc: 44.618,69.046,88.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.514 | Acc: 44.656,68.964,88.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.526 | Acc: 44.560,68.815,87.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.537 | Acc: 44.475,68.713,87.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.543 | Acc: 44.490,68.603,87.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.545 | Acc: 44.536,68.631,87.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.555 | Acc: 44.441,68.508,87.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.129 | Acc: 42.188,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.429 | Acc: 36.793,56.920,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.461 | Acc: 36.757,56.745,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.454 | Acc: 36.373,56.609,65.548,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.432 | Acc: 53.125,61.719,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.494 | Acc: 44.420,66.109,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.510 | Acc: 44.036,67.530,89.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.473 | Acc: 44.326,68.263,89.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.455 | Acc: 44.628,68.914,89.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.459 | Acc: 44.593,68.982,89.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.472 | Acc: 44.628,68.970,89.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.478 | Acc: 44.880,68.883,89.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.483 | Acc: 44.696,68.886,89.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.499 | Acc: 44.518,68.836,88.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.494 | Acc: 44.481,68.882,88.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.501 | Acc: 44.461,68.842,88.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.490 | Acc: 44.716,69.035,88.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.497 | Acc: 44.693,69.064,88.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.500 | Acc: 44.723,68.997,88.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.500 | Acc: 44.843,68.937,88.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.507 | Acc: 44.879,68.923,88.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.520 | Acc: 44.804,68.814,88.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.528 | Acc: 44.830,68.737,88.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.536 | Acc: 44.724,68.699,87.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.142 | Acc: 39.062,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.318 | Acc: 37.760,58.259,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.320 | Acc: 37.938,57.069,65.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.304 | Acc: 37.897,56.634,65.049,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 3.440 | Acc: 47.656,67.188,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.440 | Acc: 46.168,69.420,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.436 | Acc: 44.989,69.931,88.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.385 | Acc: 45.543,70.325,89.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.398 | Acc: 45.544,69.907,89.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.392 | Acc: 45.722,70.003,89.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.399 | Acc: 45.487,69.906,89.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.413 | Acc: 45.445,69.697,89.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.428 | Acc: 45.458,69.492,89.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.440 | Acc: 45.541,69.471,89.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.446 | Acc: 45.320,69.508,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.450 | Acc: 45.259,69.489,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.447 | Acc: 45.309,69.599,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.452 | Acc: 45.226,69.555,89.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.456 | Acc: 45.179,69.517,88.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.465 | Acc: 45.165,69.456,88.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.481 | Acc: 44.986,69.227,88.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.488 | Acc: 45.060,69.151,88.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.495 | Acc: 45.066,68.995,88.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.505 | Acc: 44.960,68.906,88.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.843 | Acc: 38.281,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.383 | Acc: 37.165,57.440,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.370 | Acc: 37.157,56.898,65.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.396 | Acc: 36.860,56.583,65.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.133 | Acc: 51.562,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.386 | Acc: 46.838,70.908,89.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.391 | Acc: 46.246,70.636,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.338 | Acc: 46.145,71.183,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.337 | Acc: 45.814,71.345,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.331 | Acc: 45.769,71.179,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.331 | Acc: 46.113,71.074,90.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.347 | Acc: 46.077,70.905,90.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.369 | Acc: 45.827,70.710,89.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.376 | Acc: 45.645,70.507,89.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.390 | Acc: 45.643,70.421,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.410 | Acc: 45.433,70.182,89.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.416 | Acc: 45.364,70.102,89.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.437 | Acc: 45.265,69.890,88.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.451 | Acc: 45.168,69.745,88.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.461 | Acc: 45.211,69.609,88.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.475 | Acc: 45.174,69.417,88.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.481 | Acc: 45.143,69.403,88.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.489 | Acc: 45.161,69.280,88.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.494 | Acc: 45.083,69.203,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.386 | Acc: 37.500,56.250,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.414 | Acc: 37.240,56.101,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.483 | Acc: 37.633,55.069,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.487 | Acc: 36.924,55.430,66.393,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 3.168 | Acc: 49.219,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.320 | Acc: 45.499,71.168,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.331 | Acc: 45.008,71.151,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.345 | Acc: 45.415,70.594,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.350 | Acc: 45.476,70.631,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.346 | Acc: 45.622,70.483,90.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.360 | Acc: 45.693,70.461,89.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.362 | Acc: 45.523,70.252,90.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.373 | Acc: 45.579,69.992,89.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.373 | Acc: 45.615,69.872,89.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.378 | Acc: 45.585,69.858,89.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.401 | Acc: 45.546,69.609,89.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.410 | Acc: 45.439,69.573,89.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.426 | Acc: 45.387,69.450,89.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.436 | Acc: 45.368,69.300,89.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.447 | Acc: 45.235,69.238,89.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.458 | Acc: 45.191,69.169,88.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.463 | Acc: 45.152,69.142,88.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.472 | Acc: 45.116,69.053,88.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.479 | Acc: 45.073,68.935,88.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.812 | Acc: 39.844,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.284 | Acc: 38.393,57.403,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.313 | Acc: 38.262,56.536,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.332 | Acc: 38.115,56.224,67.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.149 | Acc: 41.406,72.656,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.414 | Acc: 44.382,69.866,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.383 | Acc: 44.855,69.931,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.349 | Acc: 45.338,69.903,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.337 | Acc: 45.631,69.965,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.344 | Acc: 45.653,70.034,90.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.336 | Acc: 45.810,70.132,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.348 | Acc: 45.717,70.274,90.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.353 | Acc: 45.798,70.254,90.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.351 | Acc: 45.779,70.196,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.367 | Acc: 45.662,70.064,90.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.378 | Acc: 45.585,69.917,90.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.387 | Acc: 45.517,69.820,89.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.395 | Acc: 45.453,69.786,89.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.405 | Acc: 45.371,69.731,89.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.413 | Acc: 45.344,69.625,89.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.420 | Acc: 45.364,69.592,89.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.428 | Acc: 45.335,69.456,89.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.437 | Acc: 45.315,69.388,89.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.443 | Acc: 45.327,69.330,88.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.645 | Acc: 42.188,60.938,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.445 | Acc: 37.314,56.696,66.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.422 | Acc: 38.034,56.231,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.422 | Acc: 37.795,56.327,65.625,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 3.573 | Acc: 43.750,67.188,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.357 | Acc: 45.387,71.205,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.300 | Acc: 45.541,71.704,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.296 | Acc: 45.543,71.760,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.317 | Acc: 45.361,71.345,90.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.325 | Acc: 45.413,71.372,90.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.334 | Acc: 45.151,71.094,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.333 | Acc: 45.207,71.066,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.338 | Acc: 45.143,70.997,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.339 | Acc: 45.248,71.068,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.344 | Acc: 45.235,70.969,90.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.349 | Acc: 45.443,70.776,90.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.354 | Acc: 45.465,70.711,90.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.369 | Acc: 45.348,70.534,89.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.372 | Acc: 45.357,70.554,89.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.382 | Acc: 45.338,70.409,89.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.394 | Acc: 45.286,70.220,89.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.393 | Acc: 45.363,70.207,89.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.408 | Acc: 45.232,70.092,89.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.416 | Acc: 45.319,69.954,89.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.042 | Acc: 40.625,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.318 | Acc: 37.463,56.957,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.301 | Acc: 37.767,56.974,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.321 | Acc: 37.295,57.082,66.573,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 3.554 | Acc: 50.781,66.406,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.308 | Acc: 47.024,69.978,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.249 | Acc: 46.608,70.979,91.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.261 | Acc: 46.017,71.401,91.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.240 | Acc: 46.181,71.547,91.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.266 | Acc: 46.163,71.349,90.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.264 | Acc: 46.287,71.300,90.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.262 | Acc: 46.332,71.205,90.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.276 | Acc: 46.259,71.006,90.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.297 | Acc: 46.241,70.865,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.304 | Acc: 46.144,70.896,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.323 | Acc: 45.832,70.602,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.337 | Acc: 45.786,70.484,90.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.344 | Acc: 45.821,70.435,90.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.350 | Acc: 45.813,70.438,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.364 | Acc: 45.676,70.268,89.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.373 | Acc: 45.544,70.169,89.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.381 | Acc: 45.466,70.186,89.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.391 | Acc: 45.375,70.096,89.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.398 | Acc: 45.407,69.962,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.603 | Acc: 42.969,64.844,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.074 | Acc: 39.174,59.747,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.127 | Acc: 39.272,58.670,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.184 | Acc: 38.704,58.210,67.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 3.273 | Acc: 44.531,71.094,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.309 | Acc: 46.243,71.949,89.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.303 | Acc: 46.246,71.361,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.306 | Acc: 45.517,70.966,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.312 | Acc: 45.737,70.968,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.344 | Acc: 45.359,70.753,90.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.343 | Acc: 45.493,70.584,90.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.327 | Acc: 45.678,70.789,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.325 | Acc: 45.817,70.720,90.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.324 | Acc: 45.822,70.757,90.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.325 | Acc: 45.884,70.794,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.325 | Acc: 45.896,70.744,90.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.322 | Acc: 46.000,70.786,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.324 | Acc: 46.139,70.720,90.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.324 | Acc: 46.236,70.746,90.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.330 | Acc: 46.182,70.671,90.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.336 | Acc: 46.106,70.597,90.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.350 | Acc: 46.018,70.448,89.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.359 | Acc: 45.970,70.403,89.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.369 | Acc: 45.880,70.323,89.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.012 | Acc: 39.062,56.250,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.400 | Acc: 37.500,57.143,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.377 | Acc: 37.538,56.955,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.387 | Acc: 37.193,56.634,66.201,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 3.235 | Acc: 45.312,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.295 | Acc: 45.238,70.945,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.294 | Acc: 44.817,71.456,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.266 | Acc: 45.517,71.568,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.239 | Acc: 45.939,71.653,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.249 | Acc: 46.156,71.790,90.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.251 | Acc: 46.333,71.662,90.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.266 | Acc: 46.232,71.393,90.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.266 | Acc: 46.399,71.327,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.280 | Acc: 46.202,71.107,90.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.290 | Acc: 46.074,71.090,90.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.299 | Acc: 46.030,70.868,90.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.305 | Acc: 46.013,70.808,90.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.314 | Acc: 45.857,70.696,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.321 | Acc: 45.902,70.549,89.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.331 | Acc: 45.826,70.476,89.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.345 | Acc: 45.731,70.398,89.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.357 | Acc: 45.716,70.251,89.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.363 | Acc: 45.687,70.226,89.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.371 | Acc: 45.659,70.148,89.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.969 | Acc: 40.625,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.327 | Acc: 36.235,59.301,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.354 | Acc: 36.585,58.803,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.352 | Acc: 36.347,58.632,66.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 3.200 | Acc: 52.344,73.438,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.239 | Acc: 47.284,71.949,90.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.215 | Acc: 46.704,72.752,90.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.222 | Acc: 46.683,72.823,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.215 | Acc: 46.885,72.791,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.227 | Acc: 46.643,72.734,90.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.247 | Acc: 46.275,72.443,90.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.261 | Acc: 46.271,72.080,90.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.261 | Acc: 46.293,72.030,90.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.257 | Acc: 46.301,72.035,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.260 | Acc: 46.444,72.011,90.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.271 | Acc: 46.267,71.804,90.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.280 | Acc: 46.259,71.700,90.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.293 | Acc: 46.097,71.465,90.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.301 | Acc: 46.091,71.327,90.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.305 | Acc: 46.102,71.187,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.316 | Acc: 46.035,70.994,90.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.319 | Acc: 46.098,71.025,89.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.327 | Acc: 46.074,70.970,89.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.328 | Acc: 46.110,70.995,89.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.307 | Acc: 37.500,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.365 | Acc: 37.686,58.594,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.349 | Acc: 36.947,58.213,65.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.368 | Acc: 36.770,58.081,65.945,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.224 | Acc: 46.094,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.331 | Acc: 45.164,71.094,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.306 | Acc: 45.713,71.170,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.279 | Acc: 45.991,71.683,91.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.250 | Acc: 46.460,71.952,91.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.251 | Acc: 46.403,71.774,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.242 | Acc: 46.300,71.739,91.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.248 | Acc: 46.227,71.526,91.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.251 | Acc: 46.234,71.443,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.259 | Acc: 46.081,71.383,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.270 | Acc: 46.125,71.183,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.276 | Acc: 46.062,71.217,90.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.281 | Acc: 46.123,71.155,90.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.293 | Acc: 46.097,71.079,90.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.305 | Acc: 46.030,70.985,90.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.317 | Acc: 45.917,70.878,90.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.325 | Acc: 45.848,70.819,90.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.328 | Acc: 45.931,70.794,89.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.332 | Acc: 45.981,70.799,89.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.337 | Acc: 45.942,70.716,89.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.515 | Acc: 37.500,53.906,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.721 | Acc: 35.379,54.688,65.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.724 | Acc: 36.204,54.554,64.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.732 | Acc: 36.168,54.431,64.242,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 3.338 | Acc: 46.094,69.531,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.181 | Acc: 48.624,71.726,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.171 | Acc: 47.675,72.466,92.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.175 | Acc: 47.374,72.413,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.186 | Acc: 47.608,72.531,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.188 | Acc: 47.532,72.509,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.214 | Acc: 46.991,72.288,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.212 | Acc: 46.958,72.440,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.230 | Acc: 46.710,72.186,91.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.224 | Acc: 46.849,72.294,91.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.228 | Acc: 46.875,72.252,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.245 | Acc: 46.762,71.889,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.250 | Acc: 46.713,71.778,91.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.253 | Acc: 46.740,71.704,91.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.260 | Acc: 46.755,71.566,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.269 | Acc: 46.670,71.455,90.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.283 | Acc: 46.554,71.303,90.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.297 | Acc: 46.426,71.133,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.301 | Acc: 46.390,71.111,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.316 | Acc: 46.260,70.965,90.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.869 | Acc: 37.500,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.204 | Acc: 38.095,59.710,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.185 | Acc: 38.472,59.356,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.210 | Acc: 38.345,58.709,66.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 3.346 | Acc: 49.219,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.217 | Acc: 47.359,71.838,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.208 | Acc: 47.351,72.370,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.201 | Acc: 47.080,72.234,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.180 | Acc: 47.049,72.463,91.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.186 | Acc: 46.952,72.424,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.179 | Acc: 47.288,72.269,91.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.190 | Acc: 47.102,72.241,91.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.204 | Acc: 46.962,72.055,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.213 | Acc: 46.871,72.004,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.222 | Acc: 46.902,71.875,91.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.223 | Acc: 46.932,71.826,91.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.233 | Acc: 46.881,71.687,91.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.242 | Acc: 46.869,71.594,91.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.249 | Acc: 46.822,71.530,90.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.258 | Acc: 46.859,71.439,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.270 | Acc: 46.724,71.340,90.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.279 | Acc: 46.650,71.195,90.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.293 | Acc: 46.542,71.079,90.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.302 | Acc: 46.512,71.008,90.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.678 | Acc: 41.406,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.066 | Acc: 39.583,61.272,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.124 | Acc: 39.539,59.756,66.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.144 | Acc: 39.255,59.298,66.522,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 3.459 | Acc: 43.750,66.406,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.174 | Acc: 47.284,72.545,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.192 | Acc: 46.780,72.409,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.188 | Acc: 46.862,72.759,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.211 | Acc: 46.721,72.222,92.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.208 | Acc: 46.767,72.177,92.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.213 | Acc: 46.707,71.998,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.204 | Acc: 46.881,72.091,91.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.206 | Acc: 46.894,72.220,91.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.207 | Acc: 46.901,72.061,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.218 | Acc: 46.871,71.894,91.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.232 | Acc: 46.674,71.769,91.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.240 | Acc: 46.583,71.606,91.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.253 | Acc: 46.468,71.426,90.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.257 | Acc: 46.597,71.363,90.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.260 | Acc: 46.621,71.346,90.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.269 | Acc: 46.549,71.259,90.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.277 | Acc: 46.469,71.215,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.279 | Acc: 46.488,71.273,90.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.285 | Acc: 46.453,71.202,90.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.980 | Acc: 43.750,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.228 | Acc: 38.095,58.743,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.238 | Acc: 38.853,57.812,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.252 | Acc: 38.345,57.428,66.586,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.370 | Acc: 46.875,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.198 | Acc: 46.838,73.810,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.159 | Acc: 46.932,73.552,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.156 | Acc: 47.221,73.335,92.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.159 | Acc: 46.846,73.110,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.164 | Acc: 46.921,72.973,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.160 | Acc: 47.069,72.940,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.178 | Acc: 46.725,72.590,92.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.180 | Acc: 46.700,72.574,92.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.184 | Acc: 46.612,72.440,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.182 | Acc: 46.817,72.481,91.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.201 | Acc: 46.635,72.200,91.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.208 | Acc: 46.674,71.992,91.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.219 | Acc: 46.653,71.890,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.222 | Acc: 46.692,71.786,91.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.229 | Acc: 46.730,71.696,91.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.238 | Acc: 46.697,71.598,91.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.248 | Acc: 46.557,71.504,90.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.254 | Acc: 46.527,71.442,90.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.259 | Acc: 46.492,71.397,90.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.739 | Acc: 39.844,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.971 | Acc: 41.146,61.049,65.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.956 | Acc: 42.245,60.175,65.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.963 | Acc: 42.034,60.118,65.958,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 3.022 | Acc: 50.781,66.406,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.035 | Acc: 47.582,73.363,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.076 | Acc: 47.085,73.476,92.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.127 | Acc: 46.837,73.284,92.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.128 | Acc: 47.039,73.486,92.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.134 | Acc: 47.308,73.167,92.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.142 | Acc: 47.333,73.011,92.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.153 | Acc: 47.224,72.767,91.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.170 | Acc: 47.122,72.467,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.175 | Acc: 47.039,72.579,91.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.185 | Acc: 46.992,72.489,91.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.192 | Acc: 46.907,72.416,91.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.202 | Acc: 46.677,72.267,91.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.210 | Acc: 46.692,72.207,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.214 | Acc: 46.725,72.170,91.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.221 | Acc: 46.763,72.028,91.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.226 | Acc: 46.778,72.021,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.230 | Acc: 46.825,71.912,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.232 | Acc: 46.823,71.962,90.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.237 | Acc: 46.828,71.879,90.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.164 | Acc: 43.750,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.278 | Acc: 37.835,59.003,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.323 | Acc: 38.110,58.175,65.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.341 | Acc: 38.089,57.723,65.625,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 2.906 | Acc: 57.812,71.875,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.177 | Acc: 48.140,72.768,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.153 | Acc: 47.713,73.342,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.124 | Acc: 47.643,73.630,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.130 | Acc: 47.531,73.167,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.111 | Acc: 47.649,73.376,91.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.106 | Acc: 47.805,73.366,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.126 | Acc: 47.468,73.166,91.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.147 | Acc: 47.389,72.865,91.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.162 | Acc: 47.190,72.816,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.166 | Acc: 47.275,72.812,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.164 | Acc: 47.207,72.766,91.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.172 | Acc: 47.125,72.634,91.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.189 | Acc: 46.953,72.441,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.199 | Acc: 46.897,72.317,90.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.211 | Acc: 46.815,72.205,90.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.212 | Acc: 46.865,72.165,90.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.221 | Acc: 46.790,72.063,90.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.229 | Acc: 46.767,71.998,90.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.237 | Acc: 46.686,71.875,90.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.874 | Acc: 43.750,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.009 | Acc: 40.699,60.454,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.016 | Acc: 41.082,60.442,68.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.054 | Acc: 40.548,60.323,68.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 2.742 | Acc: 53.906,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.117 | Acc: 47.693,73.624,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.121 | Acc: 46.913,73.800,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.102 | Acc: 47.413,73.860,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.122 | Acc: 47.049,73.409,91.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.137 | Acc: 47.169,73.089,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.131 | Acc: 47.392,73.011,91.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.136 | Acc: 47.340,72.856,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.130 | Acc: 47.540,72.841,91.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.138 | Acc: 47.531,72.816,91.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.148 | Acc: 47.341,72.660,91.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.164 | Acc: 47.193,72.525,91.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.176 | Acc: 47.014,72.433,91.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.188 | Acc: 47.019,72.414,91.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.194 | Acc: 46.931,72.323,91.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.197 | Acc: 47.039,72.264,91.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.213 | Acc: 46.899,72.109,90.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.218 | Acc: 46.889,72.054,90.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.225 | Acc: 46.843,71.979,90.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.231 | Acc: 46.877,71.885,90.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.414 | Acc: 31.250,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.733 | Acc: 32.961,56.027,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.712 | Acc: 33.232,56.536,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.711 | Acc: 32.941,56.404,66.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 2.953 | Acc: 45.312,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.261 | Acc: 46.763,72.061,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.129 | Acc: 47.370,73.380,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.089 | Acc: 47.695,73.796,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.077 | Acc: 47.975,74.055,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.107 | Acc: 47.749,73.484,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.131 | Acc: 47.656,73.128,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.127 | Acc: 47.734,73.199,91.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.130 | Acc: 47.792,73.098,91.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.154 | Acc: 47.501,72.768,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.163 | Acc: 47.299,72.660,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.183 | Acc: 47.080,72.377,91.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.185 | Acc: 47.060,72.345,91.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.189 | Acc: 46.944,72.258,91.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.198 | Acc: 46.925,72.198,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.202 | Acc: 46.852,72.161,91.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.204 | Acc: 46.907,72.123,91.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.212 | Acc: 46.923,72.109,90.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.215 | Acc: 46.968,72.076,90.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.217 | Acc: 46.980,72.039,90.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.293 | Acc: 33.594,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.293 | Acc: 36.533,60.417,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.260 | Acc: 36.509,59.966,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.287 | Acc: 36.335,59.695,66.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 3.055 | Acc: 48.438,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.047 | Acc: 48.958,74.777,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.017 | Acc: 48.514,74.867,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.017 | Acc: 48.578,74.603,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.035 | Acc: 48.399,74.122,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.065 | Acc: 48.136,73.693,92.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.097 | Acc: 47.689,73.302,92.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.111 | Acc: 47.523,73.172,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.110 | Acc: 47.656,73.224,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.111 | Acc: 47.643,73.230,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.111 | Acc: 47.648,73.220,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.115 | Acc: 47.465,73.116,92.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.126 | Acc: 47.374,72.873,92.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.132 | Acc: 47.426,72.830,91.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.141 | Acc: 47.320,72.690,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.150 | Acc: 47.353,72.643,91.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.160 | Acc: 47.296,72.547,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.162 | Acc: 47.269,72.464,91.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.165 | Acc: 47.245,72.461,91.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.175 | Acc: 47.279,72.365,91.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.223 | Acc: 42.188,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.986 | Acc: 40.476,60.714,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.009 | Acc: 40.911,59.985,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.035 | Acc: 40.587,59.644,67.469,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.088 | Acc: 53.125,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 48.028,75.967,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.029 | Acc: 47.599,74.638,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.076 | Acc: 46.785,74.155,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.069 | Acc: 47.068,73.958,92.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.079 | Acc: 47.076,73.677,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.117 | Acc: 46.733,73.244,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.120 | Acc: 46.919,73.166,92.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.129 | Acc: 46.933,73.049,92.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.130 | Acc: 47.017,73.071,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.140 | Acc: 47.069,72.921,91.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.145 | Acc: 47.084,72.801,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.162 | Acc: 46.972,72.685,91.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.160 | Acc: 47.028,72.641,91.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.160 | Acc: 47.097,72.612,91.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.159 | Acc: 47.197,72.591,91.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.169 | Acc: 47.281,72.500,91.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.178 | Acc: 47.209,72.416,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.187 | Acc: 47.223,72.252,91.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.190 | Acc: 47.209,72.244,90.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.090 | Acc: 39.844,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.222 | Acc: 38.876,57.999,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.240 | Acc: 39.082,57.870,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.237 | Acc: 38.845,57.761,67.469,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 2.892 | Acc: 52.344,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.067 | Acc: 48.958,74.293,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.056 | Acc: 49.238,73.838,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.056 | Acc: 48.758,73.822,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.081 | Acc: 48.119,73.630,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.093 | Acc: 48.159,73.623,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.082 | Acc: 48.199,73.877,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.104 | Acc: 47.944,73.504,92.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.099 | Acc: 48.059,73.636,92.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.099 | Acc: 47.902,73.666,92.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.099 | Acc: 48.025,73.713,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.114 | Acc: 47.925,73.469,92.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.123 | Acc: 47.835,73.389,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.121 | Acc: 47.917,73.312,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.129 | Acc: 47.815,73.276,91.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.131 | Acc: 47.734,73.206,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.141 | Acc: 47.632,73.087,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.150 | Acc: 47.516,72.913,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.154 | Acc: 47.373,72.810,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.161 | Acc: 47.302,72.710,91.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.182 | Acc: 38.281,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.329 | Acc: 40.365,57.589,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.279 | Acc: 40.301,57.546,65.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.267 | Acc: 40.074,57.774,65.881,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 3.130 | Acc: 46.094,70.312,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.105 | Acc: 47.768,73.698,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.099 | Acc: 47.008,73.647,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.058 | Acc: 47.643,73.988,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.065 | Acc: 47.627,73.987,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.066 | Acc: 47.424,74.080,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.068 | Acc: 47.430,74.025,92.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.074 | Acc: 47.507,73.953,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.067 | Acc: 47.632,73.835,92.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.078 | Acc: 47.652,73.727,92.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.087 | Acc: 47.474,73.678,92.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.095 | Acc: 47.437,73.533,92.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.103 | Acc: 47.348,73.418,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.105 | Acc: 47.303,73.330,92.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.116 | Acc: 47.248,73.187,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.117 | Acc: 47.311,73.121,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.121 | Acc: 47.398,73.089,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.123 | Acc: 47.429,73.055,91.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.130 | Acc: 47.407,72.927,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.142 | Acc: 47.316,72.730,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.137 | Acc: 38.281,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.145 | Acc: 40.179,59.263,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.122 | Acc: 41.044,58.689,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.154 | Acc: 40.625,58.389,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 3.792 | Acc: 40.625,66.406,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.126 | Acc: 46.503,73.772,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.117 | Acc: 47.504,73.571,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.077 | Acc: 47.426,74.039,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.085 | Acc: 47.531,73.630,93.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.084 | Acc: 47.594,73.530,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.094 | Acc: 47.424,73.386,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.087 | Acc: 47.584,73.327,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.091 | Acc: 47.671,73.209,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.093 | Acc: 47.622,73.183,92.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.086 | Acc: 47.742,73.333,92.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.088 | Acc: 47.780,73.381,92.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.097 | Acc: 47.841,73.285,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.102 | Acc: 47.746,73.147,92.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.113 | Acc: 47.742,72.995,92.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.123 | Acc: 47.713,72.924,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.134 | Acc: 47.651,72.793,91.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.142 | Acc: 47.539,72.755,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.145 | Acc: 47.561,72.706,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.148 | Acc: 47.529,72.650,91.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.562 | Acc: 33.594,53.906,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.367 | Acc: 37.574,57.552,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.410 | Acc: 38.186,57.069,66.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.397 | Acc: 38.025,57.108,66.598,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 3.161 | Acc: 46.875,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.016 | Acc: 48.996,75.484,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.020 | Acc: 48.857,74.886,92.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.070 | Acc: 47.938,74.257,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.042 | Acc: 48.380,74.691,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.067 | Acc: 47.935,74.196,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.066 | Acc: 48.102,73.902,92.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.064 | Acc: 48.299,73.920,92.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.064 | Acc: 48.112,73.903,92.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.084 | Acc: 47.816,73.597,92.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.092 | Acc: 47.878,73.399,92.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.111 | Acc: 47.706,73.201,92.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.120 | Acc: 47.682,73.100,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.130 | Acc: 47.504,73.066,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.134 | Acc: 47.445,73.032,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.139 | Acc: 47.472,72.939,91.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.147 | Acc: 47.391,72.870,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.147 | Acc: 47.379,72.823,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.148 | Acc: 47.503,72.782,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.151 | Acc: 47.562,72.724,91.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.770 | Acc: 39.844,57.812,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.057 | Acc: 40.476,59.301,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.083 | Acc: 39.977,58.460,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.120 | Acc: 40.126,58.133,66.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 3.048 | Acc: 53.125,73.438,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.119 | Acc: 47.061,74.070,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.078 | Acc: 47.847,74.295,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.047 | Acc: 48.361,74.308,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.039 | Acc: 48.013,74.334,92.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.053 | Acc: 47.904,74.010,92.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.040 | Acc: 48.199,74.193,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.037 | Acc: 48.282,74.202,92.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.050 | Acc: 48.287,74.034,92.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.062 | Acc: 48.153,73.813,92.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.068 | Acc: 48.107,73.768,92.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.079 | Acc: 47.939,73.597,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.080 | Acc: 47.893,73.580,91.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.091 | Acc: 47.860,73.411,91.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.111 | Acc: 47.670,73.159,91.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.121 | Acc: 47.630,72.994,91.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.129 | Acc: 47.610,72.866,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.139 | Acc: 47.590,72.821,91.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.145 | Acc: 47.613,72.764,91.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.156 | Acc: 47.601,72.660,91.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.676 | Acc: 40.625,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.213 | Acc: 39.062,60.305,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.221 | Acc: 38.548,59.318,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.224 | Acc: 38.256,59.119,67.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 2.956 | Acc: 51.562,75.000,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.010 | Acc: 49.814,74.926,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.996 | Acc: 48.857,74.867,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.018 | Acc: 48.809,74.449,92.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.024 | Acc: 48.466,74.228,92.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.035 | Acc: 48.236,74.366,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.030 | Acc: 48.192,74.406,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.047 | Acc: 48.127,74.075,92.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.046 | Acc: 48.103,74.030,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.044 | Acc: 48.015,74.081,92.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.051 | Acc: 48.018,73.982,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.048 | Acc: 48.268,73.957,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.051 | Acc: 48.211,73.791,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.062 | Acc: 48.117,73.701,92.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.075 | Acc: 48.087,73.538,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.086 | Acc: 48.025,73.443,92.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.096 | Acc: 47.929,73.291,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.095 | Acc: 47.904,73.268,91.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.103 | Acc: 47.881,73.143,91.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.109 | Acc: 47.861,73.062,91.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.871 | Acc: 37.500,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.010 | Acc: 40.365,61.756,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.031 | Acc: 41.044,61.185,67.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.068 | Acc: 40.254,60.579,67.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 2.810 | Acc: 54.688,75.000,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.930 | Acc: 48.214,75.670,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.911 | Acc: 49.028,75.305,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.923 | Acc: 49.014,75.653,93.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.949 | Acc: 48.920,75.338,92.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.975 | Acc: 48.484,74.814,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.996 | Acc: 48.334,74.613,92.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.003 | Acc: 48.288,74.474,92.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.012 | Acc: 48.112,74.194,92.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.017 | Acc: 48.105,74.141,92.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.030 | Acc: 48.006,74.137,92.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.050 | Acc: 47.861,73.939,92.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.056 | Acc: 47.818,73.946,92.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.062 | Acc: 47.878,73.839,92.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.070 | Acc: 47.826,73.632,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.075 | Acc: 47.825,73.580,92.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.079 | Acc: 47.922,73.566,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.091 | Acc: 47.851,73.460,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.108 | Acc: 47.713,73.249,91.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.116 | Acc: 47.728,73.132,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.067 | Acc: 41.406,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.471 | Acc: 35.975,56.994,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.489 | Acc: 36.452,56.231,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.482 | Acc: 36.309,55.648,66.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 3.074 | Acc: 39.062,75.000,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.029 | Acc: 49.479,74.107,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.008 | Acc: 49.657,75.191,92.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.006 | Acc: 49.116,74.910,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.014 | Acc: 49.093,74.595,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.026 | Acc: 48.894,74.544,92.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.029 | Acc: 48.638,74.367,92.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.048 | Acc: 48.249,74.130,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.043 | Acc: 48.297,74.204,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.055 | Acc: 48.235,74.072,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.060 | Acc: 48.259,73.986,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.065 | Acc: 48.229,73.773,91.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.070 | Acc: 48.211,73.648,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.081 | Acc: 47.968,73.578,91.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.089 | Acc: 47.937,73.507,91.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.094 | Acc: 47.804,73.469,91.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.097 | Acc: 47.822,73.430,91.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.098 | Acc: 47.814,73.444,91.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.101 | Acc: 47.842,73.360,91.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.110 | Acc: 47.779,73.251,91.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.475 | Acc: 39.062,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.212 | Acc: 41.257,58.929,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.259 | Acc: 40.053,57.984,66.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.264 | Acc: 39.652,58.222,66.201,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 3.230 | Acc: 40.625,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.080 | Acc: 47.359,74.182,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.033 | Acc: 48.152,74.543,92.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 48.886,74.731,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.006 | Acc: 48.650,74.633,93.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.011 | Acc: 48.422,74.760,93.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.008 | Acc: 48.263,74.845,93.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.016 | Acc: 48.299,74.729,93.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.013 | Acc: 48.578,74.748,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.025 | Acc: 48.468,74.629,92.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.028 | Acc: 48.480,74.487,92.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.042 | Acc: 48.406,74.304,92.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.044 | Acc: 48.431,74.300,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.046 | Acc: 48.464,74.273,92.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.061 | Acc: 48.198,74.160,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.068 | Acc: 48.183,73.938,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.070 | Acc: 48.165,73.863,92.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.078 | Acc: 48.114,73.731,92.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.081 | Acc: 48.150,73.697,91.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.090 | Acc: 48.118,73.632,91.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.539 | Acc: 33.594,55.469,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.351 | Acc: 37.574,57.775,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.393 | Acc: 37.424,57.641,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.404 | Acc: 37.359,57.736,65.663,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 3.123 | Acc: 49.219,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.945 | Acc: 48.958,75.298,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.966 | Acc: 48.800,75.038,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.966 | Acc: 48.655,75.551,92.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.978 | Acc: 48.688,75.251,92.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.983 | Acc: 48.530,75.170,93.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.980 | Acc: 48.425,75.084,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.988 | Acc: 48.426,75.017,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.000 | Acc: 48.447,74.888,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.008 | Acc: 48.343,74.771,92.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.016 | Acc: 48.348,74.604,92.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.029 | Acc: 48.222,74.498,92.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.041 | Acc: 48.198,74.326,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.049 | Acc: 48.219,74.150,92.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.065 | Acc: 48.132,73.905,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.072 | Acc: 48.077,73.809,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.084 | Acc: 48.029,73.669,91.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.087 | Acc: 48.032,73.628,91.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.086 | Acc: 48.130,73.617,91.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.091 | Acc: 48.095,73.561,91.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.824 | Acc: 44.531,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.263 | Acc: 41.034,58.333,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.257 | Acc: 40.415,58.098,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.251 | Acc: 40.010,58.030,66.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 2.834 | Acc: 51.562,75.000,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.994 | Acc: 48.698,75.595,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.002 | Acc: 47.828,75.495,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.033 | Acc: 47.912,74.898,92.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.042 | Acc: 47.830,74.479,92.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.038 | Acc: 48.275,74.428,92.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.012 | Acc: 48.450,74.658,92.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.015 | Acc: 48.548,74.501,92.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.017 | Acc: 48.598,74.481,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.011 | Acc: 48.649,74.439,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.025 | Acc: 48.527,74.250,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.022 | Acc: 48.674,74.258,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.028 | Acc: 48.619,74.183,92.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.035 | Acc: 48.560,74.036,92.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.042 | Acc: 48.407,74.032,92.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.046 | Acc: 48.362,74.024,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.058 | Acc: 48.267,73.854,92.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.061 | Acc: 48.309,73.907,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.063 | Acc: 48.396,73.883,91.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.064 | Acc: 48.405,73.850,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.313 | Acc: 42.188,60.156,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.568 | Acc: 35.491,57.106,65.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.489 | Acc: 36.966,57.679,65.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.472 | Acc: 37.308,57.659,65.394,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 2.495 | Acc: 58.594,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.910 | Acc: 48.847,76.190,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.901 | Acc: 49.447,76.029,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.913 | Acc: 49.769,75.897,93.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.906 | Acc: 49.961,75.849,93.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.931 | Acc: 49.729,75.356,93.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.924 | Acc: 49.748,75.452,93.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.933 | Acc: 49.418,75.327,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.950 | Acc: 49.384,75.087,93.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.961 | Acc: 49.344,74.940,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.965 | Acc: 49.234,74.926,93.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.977 | Acc: 49.169,74.774,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.989 | Acc: 49.053,74.673,92.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.989 | Acc: 49.114,74.677,92.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.003 | Acc: 48.991,74.433,92.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.014 | Acc: 48.835,74.297,92.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.021 | Acc: 48.659,74.236,92.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.035 | Acc: 48.593,74.019,92.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.042 | Acc: 48.548,73.940,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.058 | Acc: 48.450,73.710,92.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.042 | Acc: 39.844,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.228 | Acc: 39.137,59.561,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.181 | Acc: 39.996,59.242,66.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.166 | Acc: 39.805,59.439,66.509,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 2.710 | Acc: 48.438,76.562,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.014 | Acc: 48.586,75.484,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 47.980,75.667,93.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.978 | Acc: 47.836,75.256,93.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.963 | Acc: 47.946,75.424,93.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.969 | Acc: 47.927,75.209,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.963 | Acc: 48.257,75.374,93.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.970 | Acc: 48.282,75.305,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.979 | Acc: 48.452,75.058,93.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.984 | Acc: 48.334,74.914,93.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.992 | Acc: 48.301,74.767,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.002 | Acc: 48.240,74.597,92.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.005 | Acc: 48.246,74.608,92.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.011 | Acc: 48.282,74.518,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.020 | Acc: 48.196,74.294,92.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.024 | Acc: 48.269,74.250,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.036 | Acc: 48.218,74.087,92.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.044 | Acc: 48.192,74.008,92.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.052 | Acc: 48.191,73.972,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.056 | Acc: 48.237,73.858,91.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.171 | Acc: 40.625,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.483 | Acc: 36.533,59.301,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.451 | Acc: 36.357,58.460,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.449 | Acc: 36.104,58.440,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 2.998 | Acc: 50.781,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.076 | Acc: 47.210,74.330,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.944 | Acc: 49.009,75.724,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.941 | Acc: 48.476,75.730,93.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.922 | Acc: 48.399,75.868,93.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.906 | Acc: 48.731,75.982,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.924 | Acc: 48.573,75.691,93.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.944 | Acc: 48.449,75.454,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.957 | Acc: 48.408,75.306,93.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.967 | Acc: 48.338,75.112,93.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.969 | Acc: 48.500,75.012,92.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.983 | Acc: 48.430,74.848,92.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.996 | Acc: 48.366,74.637,92.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.005 | Acc: 48.414,74.410,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.001 | Acc: 48.510,74.441,92.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.008 | Acc: 48.534,74.315,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.006 | Acc: 48.593,74.323,92.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.016 | Acc: 48.470,74.214,92.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.025 | Acc: 48.388,74.108,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.036 | Acc: 48.360,73.944,91.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.407 | Acc: 41.406,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.541 | Acc: 37.016,56.994,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.570 | Acc: 37.005,57.241,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.579 | Acc: 36.629,57.467,65.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 2.795 | Acc: 52.344,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.015 | Acc: 48.028,73.214,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.020 | Acc: 48.247,74.009,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.991 | Acc: 48.463,74.475,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.989 | Acc: 48.544,74.450,93.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.971 | Acc: 48.878,74.652,93.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.971 | Acc: 48.793,74.522,93.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.968 | Acc: 49.047,74.507,93.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.969 | Acc: 48.947,74.505,93.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.961 | Acc: 49.037,74.832,93.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.968 | Acc: 48.966,74.747,92.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.969 | Acc: 49.000,74.753,92.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.977 | Acc: 48.898,74.650,92.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.983 | Acc: 48.806,74.605,92.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.984 | Acc: 48.866,74.577,92.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.990 | Acc: 48.887,74.554,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.009 | Acc: 48.761,74.311,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.020 | Acc: 48.635,74.157,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.031 | Acc: 48.541,74.020,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.040 | Acc: 48.483,73.862,92.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.825 | Acc: 39.062,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.246 | Acc: 38.802,58.445,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.229 | Acc: 39.310,58.498,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.227 | Acc: 39.075,58.594,65.663,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 3.287 | Acc: 43.750,70.312,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.976 | Acc: 48.475,75.372,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.961 | Acc: 48.761,75.972,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.927 | Acc: 49.232,75.897,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.923 | Acc: 49.537,76.003,93.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.911 | Acc: 49.335,76.075,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.922 | Acc: 49.309,75.910,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.935 | Acc: 49.335,75.659,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.944 | Acc: 49.418,75.616,93.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.943 | Acc: 49.292,75.505,93.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.948 | Acc: 49.320,75.490,93.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.957 | Acc: 49.194,75.325,93.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.968 | Acc: 49.222,75.207,92.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.977 | Acc: 49.132,74.985,92.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.983 | Acc: 49.021,74.967,92.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.991 | Acc: 48.892,74.824,92.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.992 | Acc: 48.907,74.810,92.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.000 | Acc: 48.841,74.638,92.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.012 | Acc: 48.734,74.478,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.018 | Acc: 48.671,74.426,92.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.596 | Acc: 39.844,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.128 | Acc: 38.951,57.924,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.133 | Acc: 39.825,58.213,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.150 | Acc: 39.600,58.914,66.611,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 2.911 | Acc: 46.094,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.830 | Acc: 51.376,76.749,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.922 | Acc: 49.657,75.591,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.925 | Acc: 49.654,75.295,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.908 | Acc: 49.470,75.627,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.904 | Acc: 49.304,75.611,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.913 | Acc: 49.186,75.497,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.921 | Acc: 49.180,75.299,93.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.928 | Acc: 49.034,75.286,93.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.939 | Acc: 48.835,75.224,93.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.944 | Acc: 48.919,75.295,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.956 | Acc: 48.717,75.194,93.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.955 | Acc: 48.820,75.130,92.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.965 | Acc: 48.695,74.961,92.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.970 | Acc: 48.766,74.972,92.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.977 | Acc: 48.741,74.860,92.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.982 | Acc: 48.654,74.788,92.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.988 | Acc: 48.602,74.766,92.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.003 | Acc: 48.438,74.587,92.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.011 | Acc: 48.487,74.504,92.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.088 | Acc: 41.406,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.315 | Acc: 39.695,59.077,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.254 | Acc: 40.244,58.861,66.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.276 | Acc: 39.793,58.530,66.086,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 3.253 | Acc: 50.000,67.188,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.911 | Acc: 50.930,75.670,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.891 | Acc: 50.248,75.648,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.913 | Acc: 49.872,75.538,93.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.919 | Acc: 49.846,75.637,93.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.946 | Acc: 49.257,75.348,93.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.951 | Acc: 49.257,75.387,93.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.950 | Acc: 49.291,75.332,92.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.958 | Acc: 49.194,75.252,92.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.963 | Acc: 49.171,75.099,92.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.954 | Acc: 49.343,75.163,92.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.961 | Acc: 49.275,75.064,92.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.970 | Acc: 49.131,74.951,92.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.979 | Acc: 49.108,74.817,92.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.990 | Acc: 49.088,74.739,92.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.005 | Acc: 48.900,74.600,92.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.013 | Acc: 48.910,74.445,91.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.020 | Acc: 48.822,74.331,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.025 | Acc: 48.805,74.253,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.037 | Acc: 48.753,74.135,91.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.907 | Acc: 46.094,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.384 | Acc: 40.960,57.217,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.396 | Acc: 40.434,56.822,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.400 | Acc: 40.164,56.852,65.266,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 3.473 | Acc: 40.625,72.656,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.077 | Acc: 46.689,73.698,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.989 | Acc: 48.075,74.543,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.996 | Acc: 48.143,74.488,92.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.004 | Acc: 48.312,74.142,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.978 | Acc: 48.739,74.575,92.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.961 | Acc: 48.689,74.974,92.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.965 | Acc: 48.781,74.767,92.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.959 | Acc: 48.957,74.786,92.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.965 | Acc: 48.943,74.879,92.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.970 | Acc: 48.943,74.775,92.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.976 | Acc: 48.894,74.583,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.981 | Acc: 48.878,74.579,92.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.988 | Acc: 48.845,74.461,92.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.996 | Acc: 48.852,74.336,92.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.008 | Acc: 48.765,74.164,92.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.020 | Acc: 48.666,74.041,92.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.020 | Acc: 48.706,73.971,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.030 | Acc: 48.624,73.864,91.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.035 | Acc: 48.657,73.817,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.832 | Acc: 44.531,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.243 | Acc: 41.629,58.371,65.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.233 | Acc: 41.540,58.251,65.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.239 | Acc: 41.342,57.953,65.868,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 2.683 | Acc: 46.094,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.967 | Acc: 47.879,76.637,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.923 | Acc: 49.085,76.620,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.880 | Acc: 49.885,76.652,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.899 | Acc: 49.662,76.302,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.931 | Acc: 49.459,75.673,93.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.951 | Acc: 49.329,75.220,93.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.971 | Acc: 49.058,74.945,92.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.973 | Acc: 49.015,74.961,92.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.974 | Acc: 49.020,74.901,92.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.972 | Acc: 49.114,74.992,92.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.975 | Acc: 49.077,74.802,92.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.972 | Acc: 49.141,74.760,92.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.971 | Acc: 49.093,74.773,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.982 | Acc: 48.980,74.594,92.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.984 | Acc: 49.009,74.543,92.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.988 | Acc: 49.005,74.508,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.991 | Acc: 49.054,74.491,92.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.999 | Acc: 49.022,74.461,92.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.011 | Acc: 48.919,74.303,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.955 | Acc: 35.156,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.547 | Acc: 35.900,57.664,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.552 | Acc: 36.357,58.098,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.572 | Acc: 35.848,57.672,65.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 2.925 | Acc: 49.219,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.901 | Acc: 51.228,75.186,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.887 | Acc: 50.324,75.553,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.890 | Acc: 49.923,75.858,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.885 | Acc: 49.711,76.022,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.884 | Acc: 49.737,76.207,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.886 | Acc: 49.548,76.059,93.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.893 | Acc: 49.463,75.947,93.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.904 | Acc: 49.296,75.752,93.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.901 | Acc: 49.547,75.850,93.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.901 | Acc: 49.452,75.863,93.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.904 | Acc: 49.431,75.757,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.915 | Acc: 49.280,75.619,93.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.928 | Acc: 49.261,75.431,93.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.933 | Acc: 49.291,75.417,93.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.937 | Acc: 49.364,75.335,93.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.946 | Acc: 49.221,75.204,93.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.961 | Acc: 49.113,74.984,92.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.967 | Acc: 49.169,74.937,92.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.975 | Acc: 49.159,74.770,92.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.599 | Acc: 46.875,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.134 | Acc: 42.671,58.743,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.154 | Acc: 42.130,58.899,66.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.139 | Acc: 41.637,58.965,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 3.060 | Acc: 50.000,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.885 | Acc: 49.405,74.926,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.914 | Acc: 48.571,74.790,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.867 | Acc: 49.539,75.525,93.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.846 | Acc: 49.904,75.945,93.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.860 | Acc: 49.621,76.006,93.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.889 | Acc: 49.348,75.678,93.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.900 | Acc: 49.108,75.604,93.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.909 | Acc: 49.180,75.485,93.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.917 | Acc: 49.232,75.445,93.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.928 | Acc: 49.168,75.346,93.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.934 | Acc: 49.049,75.226,93.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.944 | Acc: 48.946,75.065,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.946 | Acc: 49.033,75.087,93.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.951 | Acc: 49.027,75.006,93.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.962 | Acc: 48.894,74.883,92.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.964 | Acc: 48.893,74.830,92.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.975 | Acc: 48.818,74.714,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.988 | Acc: 48.732,74.604,92.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.998 | Acc: 48.727,74.453,92.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.229 | Acc: 42.969,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.729 | Acc: 37.202,56.138,65.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.721 | Acc: 37.005,56.841,64.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.692 | Acc: 36.796,57.351,64.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 2.978 | Acc: 53.906,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.940 | Acc: 49.405,76.190,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.870 | Acc: 49.714,76.582,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.880 | Acc: 49.296,76.025,93.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.904 | Acc: 48.900,75.820,93.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.907 | Acc: 49.180,75.541,93.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.912 | Acc: 49.251,75.420,93.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.927 | Acc: 49.080,75.271,93.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.923 | Acc: 49.374,75.301,93.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.932 | Acc: 49.245,75.160,93.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.932 | Acc: 49.300,75.222,93.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.932 | Acc: 49.431,75.106,92.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.943 | Acc: 49.368,75.003,92.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.953 | Acc: 49.210,74.925,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.962 | Acc: 49.113,74.753,92.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.966 | Acc: 49.169,74.727,92.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.970 | Acc: 49.197,74.686,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.972 | Acc: 49.237,74.606,92.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.976 | Acc: 49.162,74.602,92.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.985 | Acc: 49.172,74.524,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.442 | Acc: 37.500,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.132 | Acc: 32.180,55.841,64.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.124 | Acc: 32.431,55.259,64.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.095 | Acc: 32.518,55.059,63.678,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 3.005 | Acc: 48.438,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.874 | Acc: 49.554,76.190,93.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.849 | Acc: 49.848,76.524,93.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.824 | Acc: 50.679,76.793,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.809 | Acc: 50.694,76.968,94.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.807 | Acc: 50.634,76.988,94.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.815 | Acc: 50.730,76.795,94.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.823 | Acc: 50.682,76.662,93.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.833 | Acc: 50.446,76.533,93.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 50.164,76.329,93.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.869 | Acc: 49.961,76.014,93.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.892 | Acc: 49.777,75.746,93.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.903 | Acc: 49.553,75.648,93.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.913 | Acc: 49.551,75.608,93.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.924 | Acc: 49.519,75.470,92.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.934 | Acc: 49.395,75.379,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.939 | Acc: 49.370,75.287,92.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.941 | Acc: 49.397,75.231,92.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.950 | Acc: 49.325,75.167,92.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.961 | Acc: 49.301,75.092,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.867 | Acc: 42.969,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.156 | Acc: 40.960,58.036,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.160 | Acc: 41.482,58.194,66.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.174 | Acc: 41.329,58.069,66.624,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 2.858 | Acc: 49.219,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.854 | Acc: 50.632,76.823,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.882 | Acc: 49.676,76.658,93.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.901 | Acc: 49.603,75.807,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.893 | Acc: 49.537,75.752,93.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.895 | Acc: 49.636,75.719,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.890 | Acc: 49.593,75.852,93.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.893 | Acc: 49.335,75.776,93.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.887 | Acc: 49.389,75.728,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.894 | Acc: 49.236,75.626,93.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.909 | Acc: 49.184,75.494,93.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.914 | Acc: 49.169,75.452,93.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.917 | Acc: 49.261,75.512,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.926 | Acc: 49.099,75.479,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.934 | Acc: 49.057,75.370,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.935 | Acc: 49.050,75.363,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.936 | Acc: 49.078,75.282,92.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.947 | Acc: 49.061,75.156,92.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.952 | Acc: 48.963,75.063,92.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.954 | Acc: 48.969,75.049,92.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.908 | Acc: 39.844,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.591 | Acc: 35.231,58.743,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.589 | Acc: 35.137,57.641,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.597 | Acc: 35.425,57.198,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 2.762 | Acc: 52.344,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.848 | Acc: 51.079,77.455,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.860 | Acc: 50.076,77.210,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.859 | Acc: 50.102,77.036,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.866 | Acc: 50.029,76.977,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.858 | Acc: 49.969,76.926,93.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.851 | Acc: 50.006,76.724,93.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.862 | Acc: 49.983,76.490,93.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.869 | Acc: 49.835,76.199,93.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.883 | Acc: 49.590,76.027,93.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.894 | Acc: 49.452,75.910,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.885 | Acc: 49.604,76.025,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.895 | Acc: 49.426,75.911,93.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.893 | Acc: 49.467,75.895,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.900 | Acc: 49.494,75.787,93.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.910 | Acc: 49.473,75.719,92.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.925 | Acc: 49.309,75.506,92.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.925 | Acc: 49.352,75.499,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.938 | Acc: 49.249,75.329,92.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.948 | Acc: 49.208,75.217,92.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.010 | Acc: 42.969,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.067 | Acc: 41.146,61.049,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.087 | Acc: 41.197,60.671,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.065 | Acc: 40.907,60.515,67.239,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 2.929 | Acc: 51.562,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.846 | Acc: 49.926,77.232,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.809 | Acc: 50.610,77.077,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.812 | Acc: 50.090,77.152,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.837 | Acc: 49.884,76.755,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.843 | Acc: 49.776,76.864,93.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.830 | Acc: 49.884,76.989,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.837 | Acc: 49.778,76.906,93.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.849 | Acc: 49.743,76.674,93.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.847 | Acc: 49.974,76.537,93.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.860 | Acc: 49.914,76.329,93.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.873 | Acc: 49.802,76.152,93.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.879 | Acc: 49.793,76.086,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.885 | Acc: 49.814,75.931,93.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.888 | Acc: 49.805,75.917,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.901 | Acc: 49.567,75.735,92.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.908 | Acc: 49.545,75.599,92.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.915 | Acc: 49.439,75.467,92.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.925 | Acc: 49.351,75.316,92.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.933 | Acc: 49.270,75.271,92.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.794 | Acc: 42.969,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.117 | Acc: 40.067,61.421,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.140 | Acc: 40.244,60.976,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.163 | Acc: 39.818,60.412,67.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 2.808 | Acc: 53.125,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.861 | Acc: 50.484,77.195,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.865 | Acc: 49.524,76.505,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.842 | Acc: 50.077,76.716,93.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.835 | Acc: 49.932,77.016,93.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.844 | Acc: 49.768,76.748,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.861 | Acc: 49.574,76.517,93.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.872 | Acc: 49.690,76.335,93.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.866 | Acc: 49.869,76.315,93.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.877 | Acc: 49.719,76.070,93.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.882 | Acc: 49.607,76.026,93.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.885 | Acc: 49.586,75.969,93.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.891 | Acc: 49.481,75.904,93.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.898 | Acc: 49.413,75.790,93.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.898 | Acc: 49.444,75.759,93.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.900 | Acc: 49.496,75.740,93.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.904 | Acc: 49.535,75.723,93.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.918 | Acc: 49.466,75.525,92.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.930 | Acc: 49.450,75.379,92.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.942 | Acc: 49.334,75.199,92.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.729 | Acc: 39.062,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.449 | Acc: 36.942,58.705,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.471 | Acc: 37.309,58.670,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.455 | Acc: 37.436,59.298,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.201 | Acc: 50.000,68.750,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.854 | Acc: 50.372,75.446,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 49.600,75.152,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.884 | Acc: 50.051,75.359,93.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.894 | Acc: 49.788,75.203,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.870 | Acc: 50.170,75.696,93.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.857 | Acc: 50.065,75.885,93.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.862 | Acc: 50.055,75.648,93.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.868 | Acc: 49.966,75.723,93.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.869 | Acc: 50.142,75.781,93.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.874 | Acc: 49.973,75.735,93.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.881 | Acc: 49.919,75.601,93.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.885 | Acc: 49.874,75.515,93.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.886 | Acc: 49.991,75.428,93.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.890 | Acc: 50.000,75.389,93.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.902 | Acc: 49.849,75.298,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.911 | Acc: 49.776,75.190,92.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.914 | Acc: 49.762,75.170,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.923 | Acc: 49.740,75.117,92.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.928 | Acc: 49.717,75.029,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.747 | Acc: 42.969,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.181 | Acc: 41.443,60.751,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.209 | Acc: 40.854,60.118,66.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.211 | Acc: 40.753,60.464,66.650,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 2.856 | Acc: 52.344,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.856 | Acc: 50.856,76.823,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.815 | Acc: 51.562,77.268,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.809 | Acc: 50.909,77.561,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.805 | Acc: 50.839,77.411,93.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.816 | Acc: 50.673,77.220,93.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.841 | Acc: 50.258,76.750,93.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.855 | Acc: 49.939,76.457,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.848 | Acc: 50.000,76.461,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.849 | Acc: 49.918,76.364,93.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.850 | Acc: 49.883,76.399,93.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.856 | Acc: 49.961,76.283,93.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.864 | Acc: 49.929,76.021,93.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.869 | Acc: 49.919,75.952,92.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.882 | Acc: 49.861,75.806,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.895 | Acc: 49.699,75.654,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.896 | Acc: 49.757,75.611,92.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.909 | Acc: 49.624,75.483,92.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.917 | Acc: 49.485,75.441,92.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.931 | Acc: 49.399,75.277,92.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.880 | Acc: 39.844,58.594,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.101 | Acc: 42.708,58.185,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.151 | Acc: 42.816,58.498,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.190 | Acc: 42.328,58.338,66.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 2.800 | Acc: 51.562,77.344,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 49.330,77.083,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.909 | Acc: 50.286,76.772,93.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.867 | Acc: 50.397,77.088,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.859 | Acc: 50.666,76.833,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.847 | Acc: 50.572,76.918,93.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.848 | Acc: 50.407,76.885,93.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.850 | Acc: 50.161,76.900,93.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.857 | Acc: 50.034,76.795,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.873 | Acc: 49.888,76.545,93.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.879 | Acc: 49.778,76.454,93.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.890 | Acc: 49.593,76.269,93.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.896 | Acc: 49.630,76.170,93.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.899 | Acc: 49.569,75.991,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.905 | Acc: 49.586,75.945,93.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.914 | Acc: 49.551,75.802,93.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.917 | Acc: 49.516,75.669,93.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.922 | Acc: 49.480,75.614,93.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.934 | Acc: 49.429,75.428,92.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.943 | Acc: 49.352,75.349,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.337 | Acc: 44.531,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.069 | Acc: 42.150,59.710,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.063 | Acc: 41.864,59.718,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.069 | Acc: 41.752,59.836,66.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 2.858 | Acc: 50.000,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.783 | Acc: 50.632,77.902,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.780 | Acc: 50.953,77.706,93.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.789 | Acc: 50.397,77.331,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.772 | Acc: 50.723,77.566,94.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.779 | Acc: 50.712,77.290,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.798 | Acc: 50.433,76.898,94.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.802 | Acc: 50.421,76.945,94.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.807 | Acc: 50.461,76.834,94.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.814 | Acc: 50.475,76.739,94.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.816 | Acc: 50.532,76.730,94.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.828 | Acc: 50.442,76.555,93.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.848 | Acc: 50.295,76.430,93.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.854 | Acc: 50.227,76.374,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.865 | Acc: 50.106,76.287,93.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.872 | Acc: 50.065,76.181,93.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.882 | Acc: 49.990,75.964,93.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.884 | Acc: 49.995,75.944,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.898 | Acc: 49.812,75.801,93.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.911 | Acc: 49.699,75.621,92.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.049 | Acc: 41.406,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.256 | Acc: 41.741,58.594,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.257 | Acc: 41.063,58.918,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.223 | Acc: 40.894,58.824,67.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 2.917 | Acc: 46.094,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.758 | Acc: 51.897,77.790,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 50.724,77.306,93.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.760 | Acc: 50.666,77.497,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.777 | Acc: 50.762,77.296,93.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.807 | Acc: 50.379,76.856,93.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.834 | Acc: 49.961,76.537,93.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.848 | Acc: 49.900,76.513,93.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.865 | Acc: 49.728,76.417,93.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.873 | Acc: 49.581,76.308,93.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.875 | Acc: 49.514,76.248,93.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.879 | Acc: 49.491,76.209,93.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.891 | Acc: 49.439,76.067,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.887 | Acc: 49.551,76.096,93.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.889 | Acc: 49.680,75.981,93.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.891 | Acc: 49.699,75.901,93.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.895 | Acc: 49.732,75.784,92.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.896 | Acc: 49.759,75.770,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.900 | Acc: 49.742,75.747,92.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.907 | Acc: 49.692,75.636,92.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.681 | Acc: 36.719,60.938,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.028 | Acc: 41.890,60.900,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.984 | Acc: 42.188,60.880,67.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.975 | Acc: 42.290,61.027,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 2.643 | Acc: 48.438,78.125,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.786 | Acc: 50.409,76.079,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.785 | Acc: 50.610,76.601,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.777 | Acc: 50.359,76.537,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.790 | Acc: 50.453,76.505,93.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.798 | Acc: 50.131,76.694,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.798 | Acc: 50.136,76.776,93.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.799 | Acc: 50.133,76.790,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.814 | Acc: 50.107,76.582,93.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.832 | Acc: 49.845,76.390,93.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.839 | Acc: 49.705,76.294,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.859 | Acc: 49.597,76.075,93.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.870 | Acc: 49.627,75.966,93.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.877 | Acc: 49.641,75.668,93.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.878 | Acc: 49.714,75.709,93.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.885 | Acc: 49.699,75.613,93.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.901 | Acc: 49.623,75.445,92.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.906 | Acc: 49.620,75.360,92.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.909 | Acc: 49.628,75.331,92.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.915 | Acc: 49.694,75.221,92.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.789 | Acc: 43.750,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.308 | Acc: 39.769,58.705,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.365 | Acc: 39.939,58.327,66.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.389 | Acc: 39.997,57.992,65.727,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 2.833 | Acc: 52.344,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.764 | Acc: 50.000,76.600,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.776 | Acc: 50.457,76.715,93.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.777 | Acc: 50.410,76.844,93.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 49.990,76.427,93.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.825 | Acc: 49.938,76.369,93.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.835 | Acc: 49.729,76.001,93.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.834 | Acc: 49.845,76.080,93.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.845 | Acc: 49.835,75.844,93.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.868 | Acc: 49.676,75.600,93.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.875 | Acc: 49.646,75.599,92.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.889 | Acc: 49.544,75.488,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.896 | Acc: 49.462,75.528,92.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.908 | Acc: 49.392,75.389,92.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.907 | Acc: 49.450,75.281,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.912 | Acc: 49.421,75.309,92.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.918 | Acc: 49.404,75.290,92.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.929 | Acc: 49.395,75.190,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.933 | Acc: 49.431,75.154,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.939 | Acc: 49.389,75.103,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.858 | Acc: 38.281,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.120 | Acc: 40.774,59.487,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.182 | Acc: 40.339,59.680,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.169 | Acc: 40.305,59.375,66.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 2.684 | Acc: 46.875,77.344,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.766 | Acc: 52.307,76.935,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.769 | Acc: 51.829,76.963,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.755 | Acc: 50.986,77.369,94.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.777 | Acc: 50.685,77.160,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.782 | Acc: 50.619,77.158,94.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.786 | Acc: 50.497,77.260,94.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.791 | Acc: 50.393,77.161,94.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.795 | Acc: 50.349,77.048,94.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.803 | Acc: 50.289,76.895,94.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.805 | Acc: 50.264,76.706,94.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.814 | Acc: 50.145,76.495,94.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.821 | Acc: 50.097,76.449,93.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.826 | Acc: 50.117,76.446,93.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 50.136,76.343,93.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.842 | Acc: 50.195,76.233,93.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.848 | Acc: 50.110,76.236,93.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 49.984,76.210,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.858 | Acc: 49.998,76.140,93.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.869 | Acc: 49.920,75.947,93.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.794 | Acc: 46.875,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.184 | Acc: 41.667,59.970,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.149 | Acc: 41.806,60.023,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.147 | Acc: 41.509,59.759,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 2.797 | Acc: 49.219,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.873 | Acc: 50.298,76.228,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.807 | Acc: 50.267,76.791,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.799 | Acc: 50.154,76.985,94.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 49.971,76.669,94.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.810 | Acc: 49.930,76.748,94.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.817 | Acc: 49.774,76.795,94.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.819 | Acc: 50.083,76.646,94.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.829 | Acc: 49.981,76.422,94.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.829 | Acc: 50.013,76.485,93.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.843 | Acc: 49.903,76.353,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.847 | Acc: 49.951,76.138,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.845 | Acc: 50.049,76.083,93.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.859 | Acc: 49.922,75.928,93.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.868 | Acc: 49.914,75.759,93.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.873 | Acc: 49.964,75.688,93.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.883 | Acc: 49.929,75.562,93.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.881 | Acc: 49.982,75.623,93.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.882 | Acc: 50.017,75.656,93.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.886 | Acc: 50.053,75.646,92.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.044 | Acc: 37.500,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.047 | Acc: 41.592,61.979,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.075 | Acc: 41.768,61.395,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.084 | Acc: 41.483,61.232,67.149,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 2.912 | Acc: 42.969,71.875,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.803 | Acc: 50.074,77.902,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.806 | Acc: 50.133,77.877,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.772 | Acc: 50.243,78.496,93.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.774 | Acc: 50.135,78.183,93.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.794 | Acc: 49.822,77.847,93.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.794 | Acc: 50.052,77.757,93.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.819 | Acc: 49.861,77.394,93.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.836 | Acc: 49.719,77.087,93.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.845 | Acc: 49.551,76.929,93.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.855 | Acc: 49.584,76.784,93.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.864 | Acc: 49.675,76.559,93.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 49.757,76.481,93.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.872 | Acc: 49.790,76.473,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.877 | Acc: 49.797,76.410,92.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.888 | Acc: 49.748,76.241,92.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.900 | Acc: 49.630,76.049,92.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.907 | Acc: 49.549,75.960,92.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.910 | Acc: 49.606,75.931,92.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.913 | Acc: 49.623,75.890,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.099 | Acc: 43.750,61.719,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.238 | Acc: 41.071,60.454,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.288 | Acc: 40.968,58.670,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.301 | Acc: 40.497,58.402,64.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.965 | Acc: 51.562,76.562,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.851 | Acc: 50.818,75.893,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.860 | Acc: 50.629,76.143,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.849 | Acc: 50.512,76.652,93.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.829 | Acc: 50.685,76.997,93.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.827 | Acc: 50.541,77.027,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.845 | Acc: 50.374,77.047,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.856 | Acc: 50.244,76.690,93.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.853 | Acc: 50.301,76.640,93.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 50.306,76.545,93.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.857 | Acc: 50.183,76.473,93.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.866 | Acc: 50.120,76.266,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.866 | Acc: 50.084,76.235,93.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.870 | Acc: 50.117,76.200,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.877 | Acc: 50.036,76.143,92.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.884 | Acc: 49.977,76.017,92.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.886 | Acc: 49.939,75.978,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.894 | Acc: 49.888,75.889,92.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.900 | Acc: 49.846,75.822,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.909 | Acc: 49.785,75.716,92.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.703 | Acc: 44.531,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.982 | Acc: 43.006,61.198,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.998 | Acc: 42.473,60.976,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.032 | Acc: 42.418,60.207,67.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 2.762 | Acc: 50.000,76.562,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.841 | Acc: 49.926,75.781,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.859 | Acc: 49.524,76.391,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.864 | Acc: 49.142,76.076,93.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.842 | Acc: 49.585,76.447,93.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 49.768,76.578,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.832 | Acc: 49.742,76.730,93.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.812 | Acc: 50.139,76.950,93.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.807 | Acc: 50.257,76.825,93.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.810 | Acc: 50.298,76.623,93.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.813 | Acc: 50.389,76.543,93.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.818 | Acc: 50.509,76.435,93.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.829 | Acc: 50.386,76.342,93.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.836 | Acc: 50.353,76.263,93.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.841 | Acc: 50.323,76.240,93.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.843 | Acc: 50.348,76.173,93.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.864 | Acc: 50.146,75.969,93.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.872 | Acc: 50.202,75.834,93.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.880 | Acc: 50.102,75.744,92.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.888 | Acc: 50.078,75.634,92.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.649 | Acc: 42.188,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.191 | Acc: 40.030,59.859,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.184 | Acc: 40.187,59.432,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.213 | Acc: 39.575,59.055,66.598,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 2.709 | Acc: 53.125,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.771 | Acc: 50.521,77.865,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.765 | Acc: 50.667,77.934,94.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.755 | Acc: 50.704,77.754,94.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.784 | Acc: 50.280,77.498,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.792 | Acc: 50.364,77.266,94.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.794 | Acc: 50.471,77.150,94.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.794 | Acc: 50.432,77.194,94.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.804 | Acc: 50.345,77.038,94.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 50.501,76.947,93.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.826 | Acc: 50.412,76.695,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.838 | Acc: 50.237,76.697,93.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.838 | Acc: 50.314,76.734,93.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.838 | Acc: 50.320,76.655,93.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.847 | Acc: 50.311,76.540,93.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.853 | Acc: 50.291,76.461,93.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.859 | Acc: 50.290,76.392,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.869 | Acc: 50.186,76.246,93.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.871 | Acc: 50.201,76.177,93.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.875 | Acc: 50.191,76.079,93.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.500 | Acc: 41.406,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.002 | Acc: 41.443,61.644,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.065 | Acc: 41.311,60.461,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.073 | Acc: 40.920,60.323,67.392,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.332 | Acc: 58.594,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.637 | Acc: 53.088,78.981,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.706 | Acc: 52.001,78.030,94.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.739 | Acc: 51.127,77.792,94.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.769 | Acc: 50.617,77.344,94.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.759 | Acc: 50.603,77.599,94.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.763 | Acc: 50.581,77.479,94.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.788 | Acc: 50.327,76.984,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.806 | Acc: 50.146,76.626,94.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.811 | Acc: 50.237,76.468,93.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.824 | Acc: 50.078,76.287,93.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.829 | Acc: 50.148,76.273,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.841 | Acc: 49.958,76.280,93.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.849 | Acc: 49.997,76.125,93.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.852 | Acc: 50.100,76.123,93.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.864 | Acc: 50.039,75.997,93.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.866 | Acc: 50.080,75.942,93.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.869 | Acc: 50.128,75.905,93.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.874 | Acc: 50.126,75.842,93.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.883 | Acc: 50.029,75.757,92.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.038 | Acc: 35.156,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.209 | Acc: 38.728,59.040,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.255 | Acc: 38.739,58.632,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.287 | Acc: 38.537,58.517,66.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.598 | Acc: 49.219,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.864 | Acc: 50.074,76.451,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.838 | Acc: 50.534,76.448,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.816 | Acc: 50.615,76.960,93.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.796 | Acc: 50.723,77.459,93.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.791 | Acc: 50.619,77.460,93.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.800 | Acc: 50.600,77.228,93.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 50.493,77.227,93.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.807 | Acc: 50.461,77.004,93.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.805 | Acc: 50.527,76.934,93.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 50.494,76.893,93.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.817 | Acc: 50.300,76.743,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.824 | Acc: 50.250,76.731,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.832 | Acc: 50.063,76.625,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.844 | Acc: 50.075,76.493,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.844 | Acc: 50.166,76.451,93.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.852 | Acc: 50.119,76.370,93.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.856 | Acc: 50.092,76.349,93.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.864 | Acc: 50.084,76.184,93.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.875 | Acc: 50.035,76.085,92.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.540 | Acc: 42.969,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.256 | Acc: 38.579,58.668,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.208 | Acc: 38.891,58.708,67.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.204 | Acc: 38.858,58.914,67.034,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 3.012 | Acc: 45.312,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.851 | Acc: 49.963,75.893,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.833 | Acc: 50.133,76.620,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.817 | Acc: 50.038,77.241,93.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.790 | Acc: 50.424,77.537,94.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.794 | Acc: 50.487,77.638,94.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.795 | Acc: 50.510,77.608,93.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 50.410,77.432,93.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.802 | Acc: 50.267,77.198,93.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.803 | Acc: 50.164,77.011,93.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 50.284,77.021,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 50.237,76.831,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.818 | Acc: 50.104,76.689,93.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.830 | Acc: 50.066,76.506,93.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.832 | Acc: 50.156,76.532,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 50.192,76.531,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.838 | Acc: 50.168,76.470,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 50.245,76.370,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.848 | Acc: 50.210,76.348,93.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.853 | Acc: 50.164,76.245,93.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.783 | Acc: 37.500,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.122 | Acc: 41.443,60.082,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.131 | Acc: 41.654,58.975,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.124 | Acc: 41.355,59.375,66.829,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 2.889 | Acc: 46.875,72.656,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.800 | Acc: 49.442,77.530,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.770 | Acc: 50.000,77.611,94.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.769 | Acc: 50.013,77.344,94.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.753 | Acc: 50.125,77.546,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 50.248,77.452,93.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.758 | Acc: 50.381,77.479,94.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.758 | Acc: 50.316,77.626,93.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.762 | Acc: 50.325,77.494,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 50.065,77.257,93.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.784 | Acc: 50.229,77.196,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.786 | Acc: 50.346,77.185,93.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.799 | Acc: 50.272,77.020,93.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.810 | Acc: 50.087,76.910,93.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.813 | Acc: 50.181,76.843,93.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.816 | Acc: 50.171,76.697,93.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 50.212,76.711,93.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.832 | Acc: 50.190,76.634,93.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 50.121,76.560,93.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.850 | Acc: 50.092,76.425,93.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.957 | Acc: 42.188,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.245 | Acc: 41.927,58.705,65.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.220 | Acc: 42.207,58.422,65.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.253 | Acc: 42.034,57.851,65.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 2.799 | Acc: 45.312,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.797 | Acc: 50.298,77.716,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.815 | Acc: 50.781,77.611,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.792 | Acc: 50.781,77.536,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.820 | Acc: 50.453,77.083,93.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.818 | Acc: 50.487,76.949,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.805 | Acc: 50.839,76.892,93.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.808 | Acc: 50.726,76.956,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.813 | Acc: 50.621,76.931,93.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 50.721,76.757,93.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.819 | Acc: 50.513,76.679,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.831 | Acc: 50.445,76.584,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.835 | Acc: 50.447,76.550,93.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.844 | Acc: 50.413,76.419,93.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.851 | Acc: 50.334,76.368,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.849 | Acc: 50.374,76.300,93.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.855 | Acc: 50.402,76.212,92.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.861 | Acc: 50.444,76.139,92.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.863 | Acc: 50.428,76.132,92.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.868 | Acc: 50.396,75.982,92.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.331 | Acc: 39.844,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.607 | Acc: 37.240,58.445,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.648 | Acc: 37.729,57.298,64.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.641 | Acc: 37.013,57.262,64.511,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 2.618 | Acc: 56.250,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.734 | Acc: 51.674,77.753,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.762 | Acc: 50.743,77.401,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.752 | Acc: 50.820,77.574,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.769 | Acc: 50.588,77.334,93.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.762 | Acc: 51.106,77.498,93.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.762 | Acc: 51.014,77.589,93.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.776 | Acc: 50.892,77.383,93.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.774 | Acc: 50.898,77.286,94.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.777 | Acc: 50.967,77.184,93.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.790 | Acc: 50.750,77.002,93.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.793 | Acc: 50.795,76.969,93.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.796 | Acc: 50.823,76.977,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.803 | Acc: 50.685,76.922,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.818 | Acc: 50.537,76.693,93.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 50.457,76.643,93.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.833 | Acc: 50.392,76.507,93.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.838 | Acc: 50.371,76.496,93.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.842 | Acc: 50.364,76.459,93.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.849 | Acc: 50.324,76.401,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.089 | Acc: 46.094,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.124 | Acc: 41.369,59.152,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.170 | Acc: 40.892,58.175,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.206 | Acc: 40.804,57.723,66.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 2.397 | Acc: 57.031,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.727 | Acc: 51.451,78.051,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.791 | Acc: 51.124,77.458,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.785 | Acc: 50.858,77.741,93.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.785 | Acc: 50.868,77.749,93.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.777 | Acc: 51.060,77.847,93.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.786 | Acc: 50.839,77.660,93.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.800 | Acc: 50.665,77.377,93.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.811 | Acc: 50.563,77.286,93.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.817 | Acc: 50.673,77.188,93.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.825 | Acc: 50.536,77.072,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.830 | Acc: 50.573,77.153,93.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.829 | Acc: 50.548,77.133,93.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.835 | Acc: 50.536,77.006,93.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.846 | Acc: 50.411,76.793,92.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.851 | Acc: 50.470,76.627,92.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.858 | Acc: 50.523,76.497,92.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.858 | Acc: 50.502,76.420,92.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.865 | Acc: 50.498,76.329,92.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.872 | Acc: 50.412,76.220,92.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.276 | Acc: 39.844,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.423 | Acc: 38.393,57.701,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.423 | Acc: 39.425,57.698,65.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.446 | Acc: 39.114,57.659,65.663,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.571 | Acc: 53.125,78.125,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.799 | Acc: 50.893,77.939,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.758 | Acc: 50.800,78.239,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.755 | Acc: 50.525,78.035,94.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.785 | Acc: 50.145,77.257,94.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.793 | Acc: 50.356,77.150,93.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.788 | Acc: 50.523,77.234,93.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.792 | Acc: 50.560,77.133,93.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.799 | Acc: 50.432,76.844,93.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.787 | Acc: 50.652,77.076,93.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.788 | Acc: 50.665,77.017,93.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.785 | Acc: 50.636,77.206,93.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.799 | Acc: 50.525,76.968,93.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.809 | Acc: 50.365,76.922,93.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.812 | Acc: 50.323,76.854,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 50.356,76.794,93.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.818 | Acc: 50.414,76.765,93.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.821 | Acc: 50.451,76.727,93.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.831 | Acc: 50.377,76.599,93.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.836 | Acc: 50.303,76.497,93.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.609 | Acc: 42.188,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.173 | Acc: 39.211,59.375,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.214 | Acc: 39.806,59.623,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.210 | Acc: 39.818,59.477,66.086,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 2.762 | Acc: 50.781,76.562,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.758 | Acc: 51.600,78.348,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.741 | Acc: 51.277,77.915,93.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.757 | Acc: 51.306,77.510,93.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.773 | Acc: 50.926,77.324,93.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.774 | Acc: 50.959,77.266,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.775 | Acc: 50.710,77.111,93.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.774 | Acc: 50.859,77.272,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.766 | Acc: 50.893,77.358,93.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.769 | Acc: 50.699,77.387,93.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.775 | Acc: 50.688,77.332,93.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.785 | Acc: 50.665,77.248,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.794 | Acc: 50.671,77.084,93.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.797 | Acc: 50.685,77.035,93.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.798 | Acc: 50.678,77.027,93.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.806 | Acc: 50.568,76.991,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.813 | Acc: 50.492,76.928,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.817 | Acc: 50.417,76.824,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.822 | Acc: 50.383,76.723,93.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.835 | Acc: 50.289,76.515,92.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.648 | Acc: 40.625,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.376 | Acc: 41.183,57.515,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.329 | Acc: 41.120,57.927,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.298 | Acc: 41.406,58.350,66.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 2.963 | Acc: 46.875,75.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.750 | Acc: 50.112,78.013,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 51.048,78.258,94.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.731 | Acc: 51.230,78.010,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.730 | Acc: 51.273,78.038,94.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.735 | Acc: 51.153,77.761,94.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.741 | Acc: 51.130,77.628,94.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.752 | Acc: 50.975,77.421,93.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.761 | Acc: 50.835,77.271,93.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.761 | Acc: 50.893,77.137,93.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.777 | Acc: 50.762,76.971,93.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 50.728,76.884,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.799 | Acc: 50.690,76.783,93.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 50.560,76.655,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.827 | Acc: 50.484,76.435,93.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 50.618,76.441,93.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.835 | Acc: 50.567,76.399,93.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.836 | Acc: 50.625,76.352,93.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 50.686,76.316,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.847 | Acc: 50.560,76.202,92.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.832 | Acc: 46.094,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.082 | Acc: 42.597,62.202,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.110 | Acc: 42.492,60.976,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.073 | Acc: 41.995,61.232,66.598,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 2.669 | Acc: 50.000,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 50.372,78.460,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.717 | Acc: 51.067,77.744,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.694 | Acc: 51.089,77.920,94.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.707 | Acc: 51.225,77.922,94.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.733 | Acc: 50.712,77.522,94.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.730 | Acc: 50.717,77.596,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.741 | Acc: 50.659,77.482,93.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.755 | Acc: 50.728,77.383,93.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.761 | Acc: 50.729,77.348,93.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.759 | Acc: 50.882,77.305,93.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.769 | Acc: 50.806,77.213,93.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.768 | Acc: 50.849,77.178,93.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.774 | Acc: 50.796,77.128,93.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.775 | Acc: 50.890,77.132,93.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.782 | Acc: 50.841,77.188,93.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.795 | Acc: 50.796,77.100,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.805 | Acc: 50.729,76.968,93.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.816 | Acc: 50.703,76.779,93.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.824 | Acc: 50.599,76.665,92.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.480 | Acc: 44.531,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.030 | Acc: 43.564,60.677,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.056 | Acc: 43.197,60.309,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.049 | Acc: 43.148,60.297,67.034,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 2.510 | Acc: 54.688,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.824 | Acc: 49.330,77.455,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.788 | Acc: 49.638,77.649,93.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.765 | Acc: 50.295,77.792,94.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.768 | Acc: 50.530,77.951,94.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 50.418,77.754,93.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.782 | Acc: 50.323,77.505,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.770 | Acc: 50.593,77.704,93.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.775 | Acc: 50.713,77.669,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.777 | Acc: 50.725,77.551,93.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.787 | Acc: 50.762,77.301,93.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.792 | Acc: 50.551,77.270,93.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.797 | Acc: 50.616,77.110,93.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.805 | Acc: 50.560,76.928,93.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.813 | Acc: 50.498,76.841,93.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.819 | Acc: 50.457,76.786,93.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.818 | Acc: 50.458,76.833,93.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.823 | Acc: 50.438,76.769,93.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.829 | Acc: 50.502,76.651,93.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.836 | Acc: 50.533,76.593,93.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.540 | Acc: 46.094,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.028 | Acc: 41.927,60.751,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.978 | Acc: 41.978,60.271,67.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.980 | Acc: 42.354,60.643,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 2.542 | Acc: 52.344,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.688 | Acc: 52.530,79.613,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.665 | Acc: 52.210,79.249,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.638 | Acc: 52.203,79.777,94.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.634 | Acc: 52.488,79.369,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.647 | Acc: 52.266,79.146,94.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.659 | Acc: 52.182,78.803,94.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.682 | Acc: 52.006,78.369,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.692 | Acc: 52.053,78.271,94.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.706 | Acc: 51.696,78.000,94.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.722 | Acc: 51.652,77.740,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.731 | Acc: 51.446,77.658,94.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.743 | Acc: 51.332,77.551,94.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.756 | Acc: 51.233,77.314,93.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.766 | Acc: 51.084,77.196,93.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.770 | Acc: 51.111,77.115,93.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.775 | Acc: 51.027,77.078,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.787 | Acc: 50.969,76.970,93.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.796 | Acc: 50.866,76.850,93.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.812 | Acc: 50.812,76.667,93.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.850 | Acc: 45.312,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.403 | Acc: 39.360,57.403,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.440 | Acc: 37.862,56.745,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.476 | Acc: 37.628,56.224,65.881,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 3.034 | Acc: 50.781,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.833 | Acc: 50.967,77.046,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.814 | Acc: 51.429,76.905,93.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.790 | Acc: 50.884,77.690,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.776 | Acc: 50.733,77.517,93.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 50.835,77.382,93.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.759 | Acc: 50.730,77.428,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.758 | Acc: 50.870,77.466,93.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.760 | Acc: 50.990,77.484,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.761 | Acc: 50.975,77.478,93.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.763 | Acc: 50.933,77.456,93.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.769 | Acc: 50.905,77.319,93.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.781 | Acc: 50.823,77.117,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.791 | Acc: 50.757,76.982,93.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.795 | Acc: 50.723,76.893,93.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.812 | Acc: 50.631,76.651,93.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.824 | Acc: 50.487,76.514,93.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.829 | Acc: 50.433,76.489,93.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.833 | Acc: 50.502,76.459,92.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.837 | Acc: 50.498,76.349,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.214 | Acc: 38.281,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.530 | Acc: 38.653,58.519,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.520 | Acc: 38.319,58.117,65.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.541 | Acc: 38.217,57.761,64.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 2.819 | Acc: 51.562,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.832 | Acc: 50.744,75.930,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.799 | Acc: 51.124,76.562,93.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.779 | Acc: 51.268,76.921,93.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.781 | Acc: 50.579,77.450,93.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.784 | Acc: 50.642,77.290,93.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.785 | Acc: 50.839,77.402,93.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.788 | Acc: 50.792,77.305,93.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.794 | Acc: 50.825,77.198,93.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.798 | Acc: 50.773,77.055,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.801 | Acc: 50.913,77.044,93.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.803 | Acc: 50.891,76.990,93.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 50.836,76.796,93.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.808 | Acc: 50.874,76.742,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.812 | Acc: 50.845,76.663,93.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.819 | Acc: 50.885,76.562,93.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.823 | Acc: 50.903,76.507,93.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.827 | Acc: 50.852,76.544,93.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.831 | Acc: 50.790,76.526,92.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.836 | Acc: 50.757,76.515,92.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.466 | Acc: 36.719,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.231 | Acc: 38.802,59.784,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.246 | Acc: 39.653,59.737,65.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.229 | Acc: 39.882,59.541,65.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 2.953 | Acc: 49.219,79.688,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.772 | Acc: 50.186,78.237,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.751 | Acc: 51.067,77.839,93.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.732 | Acc: 50.973,78.048,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.713 | Acc: 51.148,78.337,93.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.714 | Acc: 51.145,78.195,94.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.721 | Acc: 51.278,78.048,93.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.736 | Acc: 50.920,77.848,93.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.745 | Acc: 50.815,77.674,93.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.751 | Acc: 50.855,77.603,93.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.756 | Acc: 50.738,77.546,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.760 | Acc: 50.728,77.376,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.776 | Acc: 50.567,77.350,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.781 | Acc: 50.482,77.191,93.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.783 | Acc: 50.528,77.132,93.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.787 | Acc: 50.524,77.053,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.795 | Acc: 50.455,76.991,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.804 | Acc: 50.435,76.911,93.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.802 | Acc: 50.541,76.941,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.807 | Acc: 50.556,76.866,93.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.465 | Acc: 44.531,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.177 | Acc: 40.588,60.826,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.125 | Acc: 40.720,59.832,66.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.150 | Acc: 40.740,59.759,66.522,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 2.926 | Acc: 45.312,75.781,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.765 | Acc: 49.442,77.269,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.712 | Acc: 50.857,77.744,94.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.717 | Acc: 50.615,77.843,94.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.705 | Acc: 50.598,77.836,94.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.681 | Acc: 51.207,78.102,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.686 | Acc: 51.227,78.086,94.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.694 | Acc: 51.280,78.064,94.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.710 | Acc: 51.092,77.887,94.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.700 | Acc: 51.278,78.069,94.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.703 | Acc: 51.368,77.880,94.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.719 | Acc: 51.099,77.683,94.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.737 | Acc: 51.070,77.435,94.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.746 | Acc: 51.075,77.278,94.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.756 | Acc: 51.079,77.188,93.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.765 | Acc: 51.077,77.014,93.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.771 | Acc: 51.015,76.920,93.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.777 | Acc: 50.960,76.908,93.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.782 | Acc: 50.961,76.818,93.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.791 | Acc: 50.878,76.739,93.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.496 | Acc: 43.750,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.002 | Acc: 43.155,62.091,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.938 | Acc: 43.388,62.062,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.921 | Acc: 43.046,61.834,66.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 2.806 | Acc: 49.219,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.747 | Acc: 50.000,79.241,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.760 | Acc: 49.505,78.487,94.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.725 | Acc: 50.717,78.176,94.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.707 | Acc: 51.466,78.144,94.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.692 | Acc: 51.547,78.465,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.704 | Acc: 51.265,78.487,94.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.716 | Acc: 51.075,78.330,94.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.717 | Acc: 51.068,78.266,94.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.714 | Acc: 51.135,78.242,94.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.728 | Acc: 51.147,78.001,93.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.734 | Acc: 51.135,77.853,93.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.745 | Acc: 51.067,77.700,93.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.757 | Acc: 50.955,77.535,93.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.775 | Acc: 50.870,77.310,93.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.779 | Acc: 50.914,77.227,93.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.785 | Acc: 50.901,77.113,93.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.792 | Acc: 50.857,77.044,93.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.801 | Acc: 50.773,76.967,93.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.807 | Acc: 50.722,76.860,93.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.584 | Acc: 40.625,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.236 | Acc: 42.522,59.375,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.245 | Acc: 42.149,58.308,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.251 | Acc: 41.970,58.594,65.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.816 | Acc: 49.219,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.757 | Acc: 51.749,76.972,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.722 | Acc: 51.562,78.125,92.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.684 | Acc: 51.921,78.560,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.698 | Acc: 51.755,78.520,93.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.698 | Acc: 51.555,78.620,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.703 | Acc: 51.001,78.680,93.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.709 | Acc: 50.887,78.568,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.718 | Acc: 50.767,78.392,93.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.724 | Acc: 50.773,78.224,93.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.738 | Acc: 50.645,77.966,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.737 | Acc: 50.728,78.015,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.739 | Acc: 50.833,77.960,93.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.744 | Acc: 50.676,77.877,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.752 | Acc: 50.776,77.736,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.761 | Acc: 50.701,77.585,93.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.769 | Acc: 50.711,77.560,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.778 | Acc: 50.719,77.394,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.792 | Acc: 50.610,77.231,93.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.795 | Acc: 50.632,77.186,93.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.959 | Acc: 42.969,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.254 | Acc: 41.853,58.371,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.323 | Acc: 40.758,57.393,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.374 | Acc: 40.471,57.198,65.164,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 3.363 | Acc: 42.969,69.531,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.779 | Acc: 51.153,77.530,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.804 | Acc: 50.629,77.401,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.771 | Acc: 50.922,77.433,93.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.747 | Acc: 51.408,77.556,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.737 | Acc: 51.524,77.638,93.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.751 | Acc: 51.233,77.370,93.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.756 | Acc: 51.208,77.355,93.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.766 | Acc: 51.126,77.281,93.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.765 | Acc: 51.191,77.396,93.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.778 | Acc: 51.046,77.317,93.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.785 | Acc: 50.986,77.248,93.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 50.963,77.143,93.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.796 | Acc: 50.952,77.056,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.801 | Acc: 51.045,76.982,92.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.809 | Acc: 50.973,76.864,92.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.814 | Acc: 50.886,76.840,92.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.818 | Acc: 50.790,76.778,92.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.826 | Acc: 50.755,76.649,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.828 | Acc: 50.718,76.618,92.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.369 | Acc: 46.875,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.091 | Acc: 42.225,60.305,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.113 | Acc: 42.416,59.928,67.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.098 | Acc: 42.085,59.874,67.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 2.814 | Acc: 48.438,75.781,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.653 | Acc: 52.083,77.939,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.641 | Acc: 52.458,78.430,94.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.640 | Acc: 52.485,78.509,94.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.662 | Acc: 52.440,78.289,94.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.682 | Acc: 52.212,78.117,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.689 | Acc: 52.034,78.073,94.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.700 | Acc: 51.795,77.998,94.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.709 | Acc: 51.626,77.892,94.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.714 | Acc: 51.610,77.767,94.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.732 | Acc: 51.287,77.554,94.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.740 | Acc: 51.248,77.535,94.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.738 | Acc: 51.297,77.642,94.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.747 | Acc: 51.230,77.535,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.751 | Acc: 51.165,77.505,93.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.760 | Acc: 51.145,77.320,93.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.762 | Acc: 51.195,77.329,93.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.761 | Acc: 51.244,77.387,93.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.762 | Acc: 51.203,77.348,93.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.772 | Acc: 51.103,77.221,93.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.211 | Acc: 46.094,57.812,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.304 | Acc: 42.299,59.673,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.356 | Acc: 41.502,58.689,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.349 | Acc: 41.573,58.773,65.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.468 | Acc: 51.562,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.668 | Acc: 51.339,79.501,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.647 | Acc: 51.677,79.973,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.655 | Acc: 51.806,79.444,94.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.644 | Acc: 51.977,79.485,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.650 | Acc: 52.135,79.301,94.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.676 | Acc: 51.956,78.874,94.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.687 | Acc: 51.745,78.729,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.691 | Acc: 51.645,78.513,94.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.694 | Acc: 51.502,78.397,94.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.705 | Acc: 51.430,78.312,94.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.723 | Acc: 51.333,77.980,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.733 | Acc: 51.154,77.824,93.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.743 | Acc: 51.099,77.715,93.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.747 | Acc: 51.062,77.597,93.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.752 | Acc: 51.116,77.562,93.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.760 | Acc: 51.047,77.436,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.767 | Acc: 51.049,77.312,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.774 | Acc: 51.008,77.205,93.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.782 | Acc: 50.857,77.120,93.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.467 | Acc: 45.312,58.594,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.362 | Acc: 40.625,58.147,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.282 | Acc: 40.739,57.984,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.306 | Acc: 40.753,58.030,66.124,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 2.843 | Acc: 49.219,76.562,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.639 | Acc: 53.051,78.051,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.619 | Acc: 52.611,79.154,94.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.637 | Acc: 52.293,78.740,94.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.648 | Acc: 51.939,78.906,94.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.646 | Acc: 52.003,78.806,94.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.663 | Acc: 51.788,78.642,94.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.679 | Acc: 51.707,78.324,94.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.685 | Acc: 51.747,78.193,94.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.704 | Acc: 51.653,77.952,93.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.722 | Acc: 51.500,77.771,93.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.735 | Acc: 51.301,77.609,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.739 | Acc: 51.310,77.535,93.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.750 | Acc: 51.206,77.347,93.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.755 | Acc: 51.173,77.233,93.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.763 | Acc: 51.043,77.162,93.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.766 | Acc: 51.100,77.100,93.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.771 | Acc: 51.015,77.060,93.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.775 | Acc: 51.030,77.008,93.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.779 | Acc: 51.052,76.985,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.951 | Acc: 44.531,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.262 | Acc: 42.411,59.524,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.286 | Acc: 42.130,58.975,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.271 | Acc: 42.162,59.401,66.688,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 2.386 | Acc: 56.250,80.469,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.757 | Acc: 51.302,76.935,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.738 | Acc: 50.953,77.820,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.731 | Acc: 50.832,77.741,93.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.755 | Acc: 50.685,77.479,93.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.747 | Acc: 50.835,77.622,93.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.747 | Acc: 50.826,77.712,93.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.743 | Acc: 50.964,77.826,93.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.745 | Acc: 50.922,77.756,93.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.751 | Acc: 50.717,77.633,93.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.750 | Acc: 50.777,77.620,93.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.753 | Acc: 50.866,77.619,93.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.760 | Acc: 50.859,77.593,93.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.766 | Acc: 50.880,77.514,93.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.773 | Acc: 50.945,77.299,93.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.779 | Acc: 50.781,77.157,93.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.785 | Acc: 50.718,77.035,93.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.796 | Acc: 50.637,76.911,92.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.807 | Acc: 50.619,76.705,92.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.809 | Acc: 50.656,76.659,92.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.967 | Acc: 39.062,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.610 | Acc: 37.760,59.524,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.619 | Acc: 36.986,58.327,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.626 | Acc: 36.719,57.838,65.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 2.324 | Acc: 60.156,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.709 | Acc: 50.781,77.269,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.701 | Acc: 50.934,78.087,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.699 | Acc: 51.345,78.176,94.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.693 | Acc: 51.447,78.241,94.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.703 | Acc: 51.122,78.063,94.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.705 | Acc: 51.227,78.157,94.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.709 | Acc: 51.136,78.042,94.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.725 | Acc: 50.951,77.776,94.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.726 | Acc: 51.045,77.806,94.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.729 | Acc: 51.081,77.748,93.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.723 | Acc: 51.230,77.849,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.735 | Acc: 51.141,77.648,93.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.741 | Acc: 51.167,77.592,93.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.749 | Acc: 51.048,77.497,93.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.765 | Acc: 50.908,77.352,93.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.773 | Acc: 50.937,77.283,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.783 | Acc: 50.965,77.186,93.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.796 | Acc: 50.842,77.049,93.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.807 | Acc: 50.726,76.903,92.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.560 | Acc: 43.750,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.128 | Acc: 42.448,59.859,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.137 | Acc: 42.588,59.470,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.171 | Acc: 42.226,59.375,65.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 2.259 | Acc: 57.812,86.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.728 | Acc: 52.307,77.381,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.714 | Acc: 51.372,77.325,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.684 | Acc: 51.639,77.651,94.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.685 | Acc: 51.591,78.019,94.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.710 | Acc: 51.416,77.854,94.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.721 | Acc: 51.459,77.776,94.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.723 | Acc: 51.352,77.687,94.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.730 | Acc: 51.388,77.659,93.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.740 | Acc: 51.260,77.542,93.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.741 | Acc: 51.333,77.534,93.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.750 | Acc: 51.248,77.414,93.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.754 | Acc: 51.264,77.366,93.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.752 | Acc: 51.266,77.374,93.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.754 | Acc: 51.279,77.413,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.762 | Acc: 51.145,77.367,93.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.772 | Acc: 51.081,77.263,93.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.781 | Acc: 51.058,77.133,93.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.789 | Acc: 51.026,76.997,93.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.795 | Acc: 50.992,76.952,92.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.671 | Acc: 43.750,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.096 | Acc: 42.708,60.714,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.119 | Acc: 42.397,60.042,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.172 | Acc: 41.893,59.670,66.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.799 | Acc: 54.688,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.710 | Acc: 52.455,78.460,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.675 | Acc: 52.001,78.697,94.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.675 | Acc: 51.562,78.906,94.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.679 | Acc: 51.900,78.636,94.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.685 | Acc: 51.787,78.759,94.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.708 | Acc: 51.646,78.357,93.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.712 | Acc: 51.612,78.313,93.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.720 | Acc: 51.456,78.125,93.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.726 | Acc: 51.282,78.086,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.741 | Acc: 51.123,77.970,93.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.746 | Acc: 51.163,77.902,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.754 | Acc: 51.135,77.752,93.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.759 | Acc: 51.027,77.745,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.762 | Acc: 51.040,77.700,93.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.774 | Acc: 50.955,77.596,93.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.782 | Acc: 50.981,77.422,93.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.783 | Acc: 51.079,77.367,93.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.785 | Acc: 51.132,77.359,92.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.790 | Acc: 51.130,77.303,92.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.690 | Acc: 43.750,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.052 | Acc: 42.448,59.859,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.096 | Acc: 42.302,58.556,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.119 | Acc: 41.765,58.363,66.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 3.091 | Acc: 48.438,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 51.302,78.497,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.720 | Acc: 51.143,78.277,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.700 | Acc: 51.793,77.946,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.705 | Acc: 51.572,77.855,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.726 | Acc: 51.284,77.684,93.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.724 | Acc: 51.285,77.841,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.724 | Acc: 51.280,77.698,93.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.722 | Acc: 51.470,77.620,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.726 | Acc: 51.403,77.585,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.733 | Acc: 51.407,77.519,93.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.742 | Acc: 51.361,77.513,93.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.749 | Acc: 51.203,77.357,93.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.745 | Acc: 51.299,77.434,93.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.755 | Acc: 51.196,77.333,93.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.764 | Acc: 51.103,77.268,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.766 | Acc: 51.056,77.227,93.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.776 | Acc: 50.983,77.057,93.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.780 | Acc: 50.983,77.030,93.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.788 | Acc: 50.937,76.907,93.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.696 | Acc: 43.750,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.161 | Acc: 41.741,60.082,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.129 | Acc: 41.349,59.356,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.129 | Acc: 41.099,59.541,66.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 3.114 | Acc: 48.438,75.781,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.794 | Acc: 49.554,77.455,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.756 | Acc: 50.305,77.420,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.692 | Acc: 51.473,78.099,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.671 | Acc: 51.389,78.598,94.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.644 | Acc: 51.795,78.728,95.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.633 | Acc: 51.879,78.926,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.649 | Acc: 51.529,78.640,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.663 | Acc: 51.465,78.440,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.669 | Acc: 51.265,78.332,95.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.670 | Acc: 51.263,78.448,94.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.677 | Acc: 51.421,78.220,94.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.689 | Acc: 51.245,78.099,94.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.703 | Acc: 51.125,78.014,94.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.713 | Acc: 51.109,77.905,94.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.719 | Acc: 51.100,77.928,94.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.723 | Acc: 51.085,77.865,94.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.728 | Acc: 51.175,77.710,94.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.732 | Acc: 51.227,77.623,94.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.742 | Acc: 51.156,77.485,94.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.808 | Acc: 39.062,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.161 | Acc: 41.481,60.342,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.208 | Acc: 41.216,60.137,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.193 | Acc: 40.804,59.926,67.354,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 2.583 | Acc: 50.000,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.653 | Acc: 52.716,79.762,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.688 | Acc: 51.296,79.116,93.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.664 | Acc: 51.537,79.226,93.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.669 | Acc: 51.350,78.964,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.677 | Acc: 51.060,78.937,94.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.671 | Acc: 50.917,78.932,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.669 | Acc: 50.997,78.956,94.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.672 | Acc: 51.145,78.950,94.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.683 | Acc: 50.932,78.785,94.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.685 | Acc: 51.018,78.720,94.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.693 | Acc: 51.121,78.577,94.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.703 | Acc: 51.024,78.430,94.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.709 | Acc: 51.084,78.332,94.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.715 | Acc: 51.145,78.211,93.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.725 | Acc: 51.152,78.063,93.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.730 | Acc: 51.180,77.989,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.741 | Acc: 51.134,77.878,93.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.749 | Acc: 51.110,77.751,93.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.760 | Acc: 51.087,77.575,93.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.020 | Acc: 45.312,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.088 | Acc: 42.932,59.226,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.092 | Acc: 42.854,59.223,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.084 | Acc: 43.238,59.209,66.765,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 2.603 | Acc: 53.125,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.713 | Acc: 51.749,78.497,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.687 | Acc: 51.467,78.544,93.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.685 | Acc: 51.550,78.471,94.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.675 | Acc: 51.630,78.289,94.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.690 | Acc: 51.129,78.210,94.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.692 | Acc: 51.278,78.177,94.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.700 | Acc: 51.313,78.136,94.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.705 | Acc: 51.247,78.038,94.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.699 | Acc: 51.411,78.151,93.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.709 | Acc: 51.275,77.919,93.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.716 | Acc: 51.191,77.916,93.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.721 | Acc: 51.164,77.853,93.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.730 | Acc: 51.072,77.745,93.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.734 | Acc: 51.062,77.633,93.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.741 | Acc: 51.028,77.606,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.745 | Acc: 50.991,77.538,93.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.748 | Acc: 50.948,77.538,93.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.757 | Acc: 50.920,77.441,93.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.769 | Acc: 50.849,77.319,93.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.460 | Acc: 45.312,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.276 | Acc: 40.365,59.412,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.267 | Acc: 40.454,59.051,65.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.281 | Acc: 40.676,58.876,65.113,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 2.570 | Acc: 51.562,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.689 | Acc: 53.162,78.051,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.659 | Acc: 52.420,79.021,93.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.642 | Acc: 52.510,79.162,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.645 | Acc: 52.305,78.945,93.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.666 | Acc: 52.011,78.744,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.672 | Acc: 51.956,78.351,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.681 | Acc: 51.973,78.313,94.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.681 | Acc: 51.975,78.300,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.691 | Acc: 51.800,78.280,93.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.707 | Acc: 51.675,77.857,93.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.716 | Acc: 51.605,77.740,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.725 | Acc: 51.520,77.661,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.725 | Acc: 51.643,77.562,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.726 | Acc: 51.607,77.633,93.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.732 | Acc: 51.505,77.505,93.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.743 | Acc: 51.368,77.346,93.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.748 | Acc: 51.336,77.268,93.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.757 | Acc: 51.244,77.203,93.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.765 | Acc: 51.267,77.083,93.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.731 | Acc: 40.625,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.153 | Acc: 42.001,59.152,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.119 | Acc: 41.139,59.966,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.139 | Acc: 40.561,59.477,67.956,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 2.670 | Acc: 51.562,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.668 | Acc: 50.670,79.167,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.672 | Acc: 51.239,78.582,93.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.680 | Acc: 51.230,78.624,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.680 | Acc: 51.399,78.443,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.684 | Acc: 51.369,78.102,93.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.672 | Acc: 51.705,78.403,93.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.684 | Acc: 51.773,78.175,93.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.701 | Acc: 51.562,77.887,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.706 | Acc: 51.580,77.870,93.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.717 | Acc: 51.310,77.764,93.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.727 | Acc: 51.170,77.641,93.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.731 | Acc: 51.274,77.632,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.737 | Acc: 51.224,77.625,93.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.741 | Acc: 51.284,77.552,93.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.752 | Acc: 51.246,77.403,93.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.755 | Acc: 51.217,77.426,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.757 | Acc: 51.233,77.429,93.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.759 | Acc: 51.199,77.352,93.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.762 | Acc: 51.165,77.305,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.403 | Acc: 50.000,60.938,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.141 | Acc: 44.196,59.933,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.099 | Acc: 43.979,59.813,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.091 | Acc: 43.494,59.682,67.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 2.545 | Acc: 53.906,82.031,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.619 | Acc: 52.753,79.613,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.599 | Acc: 52.306,79.535,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.577 | Acc: 52.523,79.623,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.591 | Acc: 52.276,79.437,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.638 | Acc: 51.632,78.937,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.649 | Acc: 51.821,78.784,94.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.639 | Acc: 51.856,78.867,94.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.642 | Acc: 51.825,78.770,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.651 | Acc: 51.787,78.574,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.659 | Acc: 51.609,78.459,94.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.670 | Acc: 51.502,78.422,94.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.673 | Acc: 51.478,78.420,94.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.677 | Acc: 51.604,78.409,94.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.691 | Acc: 51.465,78.225,94.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.703 | Acc: 51.326,78.050,94.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.709 | Acc: 51.224,77.962,93.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.720 | Acc: 51.143,77.862,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.729 | Acc: 51.190,77.714,93.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.739 | Acc: 51.181,77.598,93.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.330 | Acc: 45.312,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.110 | Acc: 43.229,60.826,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.143 | Acc: 42.702,59.928,65.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.129 | Acc: 42.636,59.964,65.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 2.761 | Acc: 47.656,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.680 | Acc: 52.641,78.162,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.633 | Acc: 52.725,79.059,94.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.619 | Acc: 52.395,79.162,94.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.656 | Acc: 51.775,78.906,94.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.662 | Acc: 51.702,78.798,94.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.671 | Acc: 51.556,78.551,94.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.679 | Acc: 51.651,78.446,94.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.682 | Acc: 51.669,78.154,94.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.694 | Acc: 51.329,78.030,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.692 | Acc: 51.458,78.152,94.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.700 | Acc: 51.499,78.132,94.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.703 | Acc: 51.598,78.115,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.713 | Acc: 51.577,77.924,94.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.715 | Acc: 51.635,77.814,93.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.723 | Acc: 51.474,77.756,93.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.731 | Acc: 51.482,77.653,93.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.733 | Acc: 51.638,77.589,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.738 | Acc: 51.584,77.521,93.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.748 | Acc: 51.450,77.465,93.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.966 | Acc: 42.188,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.293 | Acc: 40.104,59.747,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.293 | Acc: 39.482,58.956,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.298 | Acc: 39.793,58.965,66.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 2.777 | Acc: 52.344,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.614 | Acc: 52.641,80.320,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.623 | Acc: 52.782,79.478,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.619 | Acc: 52.792,79.623,94.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.620 | Acc: 52.479,79.456,94.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.636 | Acc: 52.166,79.100,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.653 | Acc: 51.995,78.764,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.658 | Acc: 52.011,78.701,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.662 | Acc: 52.135,78.620,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.683 | Acc: 51.839,78.501,94.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.694 | Acc: 51.889,78.428,93.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.698 | Acc: 51.980,78.277,93.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.700 | Acc: 52.007,78.096,93.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.703 | Acc: 52.065,78.047,93.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.709 | Acc: 52.016,77.930,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.721 | Acc: 51.791,77.803,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.724 | Acc: 51.769,77.736,93.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.736 | Acc: 51.613,77.568,93.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.740 | Acc: 51.537,77.526,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.750 | Acc: 51.470,77.479,93.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.656 | Acc: 45.312,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.998 | Acc: 44.085,61.458,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.011 | Acc: 43.521,61.604,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.017 | Acc: 43.212,61.232,66.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 2.621 | Acc: 57.812,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.621 | Acc: 52.604,79.427,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.626 | Acc: 52.687,78.906,94.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.614 | Acc: 53.099,79.047,94.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.612 | Acc: 52.652,79.128,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.627 | Acc: 52.460,78.782,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.641 | Acc: 52.118,78.861,94.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.645 | Acc: 52.033,78.812,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.654 | Acc: 51.873,78.596,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.654 | Acc: 52.003,78.574,94.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.664 | Acc: 51.936,78.479,94.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.679 | Acc: 51.746,78.231,94.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.688 | Acc: 51.517,78.206,94.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.698 | Acc: 51.440,78.194,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.707 | Acc: 51.479,78.036,93.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.716 | Acc: 51.402,77.959,93.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.723 | Acc: 51.392,77.947,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.730 | Acc: 51.384,77.843,93.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.736 | Acc: 51.368,77.790,93.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.746 | Acc: 51.247,77.723,93.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.715 | Acc: 42.969,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.094 | Acc: 43.713,61.682,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.071 | Acc: 42.797,61.319,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.081 | Acc: 42.789,60.720,66.931,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 2.960 | Acc: 54.688,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.655 | Acc: 53.497,79.315,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.605 | Acc: 53.125,79.707,94.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.601 | Acc: 52.907,79.867,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.613 | Acc: 52.595,79.417,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.631 | Acc: 52.205,79.285,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.633 | Acc: 52.434,79.010,94.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.641 | Acc: 52.238,78.934,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.644 | Acc: 52.344,78.799,94.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.646 | Acc: 52.288,78.665,94.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.647 | Acc: 52.344,78.580,94.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.656 | Acc: 52.312,78.401,94.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.663 | Acc: 52.282,78.365,94.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.671 | Acc: 52.263,78.275,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.679 | Acc: 52.202,78.183,94.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.695 | Acc: 52.004,77.941,94.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.704 | Acc: 51.981,77.869,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.707 | Acc: 51.975,77.795,93.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.722 | Acc: 51.876,77.608,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.734 | Acc: 51.727,77.440,93.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.032 | Acc: 45.312,58.594,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.264 | Acc: 41.778,58.036,65.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.243 | Acc: 41.521,57.946,65.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.216 | Acc: 41.496,58.466,65.356,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 2.494 | Acc: 60.938,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.678 | Acc: 52.158,78.051,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.667 | Acc: 51.200,78.963,94.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.660 | Acc: 51.434,79.073,94.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.642 | Acc: 51.784,79.244,94.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.657 | Acc: 51.702,78.914,94.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.666 | Acc: 51.659,78.642,94.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.669 | Acc: 51.646,78.685,94.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.667 | Acc: 51.791,78.644,94.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.672 | Acc: 51.990,78.647,94.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.685 | Acc: 51.803,78.397,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.695 | Acc: 51.683,78.174,94.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.717 | Acc: 51.368,77.927,93.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.725 | Acc: 51.326,77.760,93.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.733 | Acc: 51.179,77.658,93.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.736 | Acc: 51.274,77.632,93.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.743 | Acc: 51.295,77.504,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.753 | Acc: 51.285,77.456,93.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.767 | Acc: 51.160,77.305,92.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.773 | Acc: 51.167,77.245,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.851 | Acc: 36.719,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.103 | Acc: 40.067,61.049,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.123 | Acc: 40.187,59.985,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.124 | Acc: 40.036,59.862,66.765,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 2.730 | Acc: 53.906,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.614 | Acc: 51.823,79.241,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.653 | Acc: 51.486,79.021,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.655 | Acc: 51.153,78.778,94.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.652 | Acc: 51.611,78.926,94.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.644 | Acc: 51.709,78.960,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.636 | Acc: 51.814,79.016,94.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.634 | Acc: 51.773,79.045,94.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.638 | Acc: 51.771,79.062,94.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.644 | Acc: 51.709,79.006,94.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.650 | Acc: 51.788,78.817,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.659 | Acc: 51.782,78.570,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.669 | Acc: 51.747,78.482,94.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.676 | Acc: 51.787,78.338,94.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.683 | Acc: 51.679,78.195,94.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.693 | Acc: 51.588,78.089,93.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.707 | Acc: 51.536,77.957,93.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.716 | Acc: 51.496,77.859,93.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.726 | Acc: 51.435,77.705,93.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.733 | Acc: 51.419,77.625,93.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.685 | Acc: 47.656,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.092 | Acc: 44.010,61.458,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.126 | Acc: 43.636,60.690,65.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.133 | Acc: 43.558,60.259,66.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 3.161 | Acc: 43.750,70.312,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.740 | Acc: 50.558,77.344,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.669 | Acc: 51.162,79.002,94.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.665 | Acc: 51.729,78.791,94.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.658 | Acc: 51.929,78.636,94.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.642 | Acc: 52.073,78.906,94.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.633 | Acc: 52.034,78.971,94.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.644 | Acc: 51.967,78.707,94.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.668 | Acc: 51.888,78.411,94.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.675 | Acc: 51.709,78.380,94.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.679 | Acc: 51.737,78.319,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.683 | Acc: 51.789,78.273,93.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.689 | Acc: 51.725,78.271,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.698 | Acc: 51.712,78.158,93.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.707 | Acc: 51.674,78.003,93.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.710 | Acc: 51.635,77.925,93.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.720 | Acc: 51.499,77.765,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.726 | Acc: 51.430,77.690,93.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.730 | Acc: 51.513,77.653,93.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.744 | Acc: 51.433,77.524,93.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.396 | Acc: 46.094,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.171 | Acc: 43.266,59.673,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.166 | Acc: 42.969,59.566,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.205 | Acc: 42.777,59.388,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 2.426 | Acc: 60.938,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.673 | Acc: 52.046,77.939,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.689 | Acc: 51.734,77.839,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.641 | Acc: 51.806,78.753,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.659 | Acc: 51.746,78.723,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.669 | Acc: 51.462,78.597,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.680 | Acc: 51.414,78.390,94.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.684 | Acc: 51.507,78.264,94.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.689 | Acc: 51.596,78.067,94.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.692 | Acc: 51.783,78.073,94.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.705 | Acc: 51.562,77.962,94.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.703 | Acc: 51.672,77.920,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.711 | Acc: 51.605,77.846,94.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.714 | Acc: 51.577,77.802,93.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.726 | Acc: 51.451,77.630,93.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.735 | Acc: 51.433,77.546,93.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.744 | Acc: 51.375,77.407,93.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.749 | Acc: 51.365,77.344,93.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.752 | Acc: 51.348,77.294,93.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.761 | Acc: 51.271,77.198,93.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.266 | Acc: 42.969,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.438 | Acc: 42.857,58.073,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.477 | Acc: 42.073,57.603,64.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.522 | Acc: 41.624,57.390,64.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 2.354 | Acc: 49.219,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.644 | Acc: 52.381,78.646,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.635 | Acc: 52.248,79.402,94.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.634 | Acc: 52.228,79.316,94.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.621 | Acc: 52.315,79.186,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.620 | Acc: 52.553,79.169,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.632 | Acc: 52.266,79.165,94.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.647 | Acc: 52.178,78.973,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.661 | Acc: 52.155,78.780,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.668 | Acc: 52.055,78.652,94.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.680 | Acc: 51.866,78.463,94.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.682 | Acc: 51.927,78.468,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.688 | Acc: 51.887,78.433,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.692 | Acc: 51.874,78.397,94.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.699 | Acc: 51.796,78.347,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.707 | Acc: 51.773,78.211,93.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.715 | Acc: 51.772,78.050,93.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.720 | Acc: 51.798,77.946,93.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.730 | Acc: 51.643,77.783,93.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.735 | Acc: 51.597,77.711,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.798 | Acc: 46.875,60.156,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.965 | Acc: 44.792,60.268,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.002 | Acc: 44.150,59.794,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.021 | Acc: 43.929,59.836,67.034,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.486 | Acc: 50.781,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.608 | Acc: 52.344,79.762,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.628 | Acc: 52.077,79.249,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.634 | Acc: 52.203,79.495,94.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.619 | Acc: 52.508,79.417,94.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.618 | Acc: 52.529,79.517,94.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.623 | Acc: 52.273,79.442,94.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.619 | Acc: 52.355,79.410,94.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.621 | Acc: 52.247,79.372,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.641 | Acc: 52.059,79.079,94.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.643 | Acc: 51.971,79.015,94.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.651 | Acc: 51.891,78.952,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.670 | Acc: 51.718,78.705,94.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.683 | Acc: 51.682,78.550,94.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.681 | Acc: 51.754,78.553,94.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.679 | Acc: 51.895,78.468,94.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.684 | Acc: 51.823,78.373,93.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.688 | Acc: 51.705,78.272,93.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.699 | Acc: 51.632,78.181,93.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.705 | Acc: 51.630,78.076,93.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.624 | Acc: 40.625,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.121 | Acc: 42.634,60.938,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.163 | Acc: 41.997,60.385,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.158 | Acc: 41.560,60.400,66.586,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.842 | Acc: 47.656,75.000,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.655 | Acc: 52.009,79.539,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.643 | Acc: 52.115,78.792,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.605 | Acc: 52.395,79.265,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.611 | Acc: 52.431,79.196,94.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.611 | Acc: 52.506,79.200,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.629 | Acc: 52.370,78.919,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.640 | Acc: 52.183,78.590,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.655 | Acc: 51.980,78.523,94.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.662 | Acc: 51.878,78.496,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.670 | Acc: 51.885,78.413,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.670 | Acc: 51.895,78.369,94.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.686 | Acc: 51.783,78.219,93.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.688 | Acc: 51.880,78.155,93.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.700 | Acc: 51.774,78.039,93.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.707 | Acc: 51.773,77.930,93.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.716 | Acc: 51.689,77.772,93.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.731 | Acc: 51.562,77.541,93.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.736 | Acc: 51.528,77.523,93.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.741 | Acc: 51.562,77.473,93.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.782 | Acc: 42.188,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.051 | Acc: 44.048,61.272,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.066 | Acc: 43.159,60.633,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.085 | Acc: 42.956,60.425,66.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 2.478 | Acc: 57.812,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.748 | Acc: 50.595,78.162,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.653 | Acc: 52.801,78.754,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.652 | Acc: 52.664,79.034,94.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.633 | Acc: 52.498,79.437,94.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.639 | Acc: 52.251,79.409,94.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.650 | Acc: 52.286,79.113,94.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.644 | Acc: 52.078,79.050,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.644 | Acc: 52.286,79.028,94.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.649 | Acc: 52.210,79.100,94.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.654 | Acc: 52.270,78.863,94.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.673 | Acc: 52.072,78.662,94.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.682 | Acc: 51.984,78.540,93.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.688 | Acc: 52.000,78.502,93.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.696 | Acc: 51.996,78.392,93.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.704 | Acc: 52.012,78.247,93.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.715 | Acc: 51.903,78.093,93.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.725 | Acc: 51.778,78.015,93.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.735 | Acc: 51.677,77.857,93.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.743 | Acc: 51.638,77.752,93.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.788 | Acc: 42.188,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.309 | Acc: 41.481,57.924,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.290 | Acc: 41.692,57.393,65.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.291 | Acc: 41.829,57.595,65.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 2.501 | Acc: 52.344,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.583 | Acc: 52.009,79.762,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.624 | Acc: 51.944,78.830,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.608 | Acc: 52.228,78.893,94.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.615 | Acc: 52.238,78.665,94.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.622 | Acc: 52.104,78.550,94.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.626 | Acc: 52.092,78.428,94.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.622 | Acc: 52.250,78.618,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.632 | Acc: 52.072,78.431,94.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.634 | Acc: 52.137,78.419,94.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.640 | Acc: 52.149,78.475,94.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.650 | Acc: 52.011,78.334,94.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.656 | Acc: 51.987,78.261,94.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.661 | Acc: 51.925,78.218,94.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.668 | Acc: 51.882,78.172,94.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.678 | Acc: 51.866,78.078,93.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.692 | Acc: 51.721,77.938,93.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.704 | Acc: 51.608,77.823,93.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.715 | Acc: 51.532,77.688,93.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.715 | Acc: 51.608,77.670,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.571 | Acc: 42.188,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.982 | Acc: 43.155,61.235,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.946 | Acc: 43.540,60.995,68.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.965 | Acc: 43.699,60.976,67.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 2.495 | Acc: 55.469,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.635 | Acc: 51.897,78.832,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.607 | Acc: 52.725,79.249,94.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.611 | Acc: 52.715,79.290,94.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.624 | Acc: 52.218,79.051,94.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.615 | Acc: 52.468,79.084,94.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.619 | Acc: 52.454,78.945,94.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.621 | Acc: 52.344,78.757,94.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.632 | Acc: 52.082,78.702,94.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.639 | Acc: 52.011,78.686,94.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.647 | Acc: 52.033,78.525,94.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.650 | Acc: 51.951,78.457,94.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.657 | Acc: 51.952,78.394,94.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.668 | Acc: 51.901,78.305,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.689 | Acc: 51.765,78.097,93.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.696 | Acc: 51.726,78.068,93.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.703 | Acc: 51.696,77.957,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.716 | Acc: 51.574,77.788,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.729 | Acc: 51.452,77.619,93.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.737 | Acc: 51.427,77.530,93.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.534 | Acc: 48.438,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.024 | Acc: 43.452,60.751,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.036 | Acc: 43.140,60.575,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.060 | Acc: 43.084,60.323,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 2.540 | Acc: 54.688,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.584 | Acc: 53.795,79.204,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.608 | Acc: 53.449,79.192,94.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.625 | Acc: 52.357,79.201,94.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.604 | Acc: 52.585,79.707,94.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.619 | Acc: 52.545,79.440,94.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.619 | Acc: 52.415,79.300,94.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.619 | Acc: 52.482,79.255,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.630 | Acc: 52.412,79.081,94.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.648 | Acc: 52.262,78.772,94.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.663 | Acc: 52.138,78.541,94.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.662 | Acc: 52.216,78.479,94.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.666 | Acc: 51.987,78.446,94.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.664 | Acc: 52.095,78.517,94.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.665 | Acc: 52.069,78.442,94.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.680 | Acc: 51.928,78.252,93.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.688 | Acc: 51.850,78.166,93.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.692 | Acc: 51.847,78.130,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.697 | Acc: 51.727,78.025,93.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.701 | Acc: 51.755,77.969,93.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.045 | Acc: 45.312,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.395 | Acc: 41.704,58.854,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.422 | Acc: 41.559,57.832,65.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.403 | Acc: 41.291,57.608,64.767,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.261 | Acc: 62.500,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.612 | Acc: 52.195,79.167,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.612 | Acc: 51.543,79.573,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.618 | Acc: 51.793,79.495,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.630 | Acc: 51.476,79.311,94.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.630 | Acc: 51.423,79.076,94.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.640 | Acc: 51.420,78.829,94.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.649 | Acc: 51.280,78.690,94.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.653 | Acc: 51.334,78.576,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.657 | Acc: 51.265,78.557,94.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.658 | Acc: 51.395,78.595,94.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.673 | Acc: 51.280,78.510,94.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.671 | Acc: 51.494,78.508,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.681 | Acc: 51.554,78.314,94.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.692 | Acc: 51.551,78.183,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.692 | Acc: 51.687,78.234,93.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.701 | Acc: 51.623,78.142,93.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.710 | Acc: 51.569,78.020,93.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.723 | Acc: 51.424,77.813,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.727 | Acc: 51.405,77.768,93.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.891 | Acc: 45.312,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.576 | Acc: 39.769,56.176,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.598 | Acc: 39.558,55.564,65.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.621 | Acc: 39.101,55.661,65.138,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 2.819 | Acc: 50.781,77.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.527 | Acc: 53.311,80.469,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.403 | Acc: 54.668,82.336,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.381 | Acc: 54.303,82.377,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.333 | Acc: 55.015,83.063,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.301 | Acc: 55.128,83.524,96.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.270 | Acc: 55.449,84.020,97.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.260 | Acc: 55.519,84.309,97.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.240 | Acc: 55.673,84.555,97.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.221 | Acc: 55.892,84.707,97.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.206 | Acc: 56.052,84.826,97.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.189 | Acc: 56.296,85.068,97.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.189 | Acc: 56.140,85.179,97.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.178 | Acc: 56.247,85.348,97.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.172 | Acc: 56.311,85.409,97.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.163 | Acc: 56.325,85.631,97.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.158 | Acc: 56.338,85.723,97.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.151 | Acc: 56.397,85.855,97.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.146 | Acc: 56.462,85.963,98.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.144 | Acc: 56.418,86.009,98.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.449 | Acc: 53.906,78.125,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.987 | Acc: 51.004,69.754,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.977 | Acc: 51.391,68.845,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.983 | Acc: 51.050,68.712,73.655,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 2.041 | Acc: 55.469,89.062,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.975 | Acc: 57.924,88.765,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.981 | Acc: 58.022,88.986,99.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.984 | Acc: 57.620,88.934,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.981 | Acc: 57.629,88.908,99.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.970 | Acc: 57.766,88.807,99.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.980 | Acc: 57.457,88.540,99.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.972 | Acc: 57.785,88.680,99.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.964 | Acc: 57.803,88.805,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.965 | Acc: 57.804,88.756,99.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.966 | Acc: 57.910,88.612,99.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.965 | Acc: 57.883,88.660,99.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.971 | Acc: 57.816,88.599,99.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.971 | Acc: 57.750,88.718,99.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.971 | Acc: 57.696,88.746,99.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.971 | Acc: 57.698,88.681,99.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.970 | Acc: 57.727,88.693,99.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.973 | Acc: 57.645,88.657,99.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.972 | Acc: 57.674,88.658,99.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.968 | Acc: 57.755,88.700,99.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.415 | Acc: 52.344,75.781,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.920 | Acc: 51.860,70.126,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.924 | Acc: 52.020,69.150,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.930 | Acc: 51.511,69.160,74.244,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.977 | Acc: 59.375,85.156,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.925 | Acc: 58.631,89.025,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.927 | Acc: 58.422,89.177,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.898 | Acc: 59.337,89.626,99.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.921 | Acc: 58.738,89.545,99.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.925 | Acc: 58.400,89.364,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.927 | Acc: 58.297,89.385,99.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.919 | Acc: 58.306,89.495,99.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.922 | Acc: 58.298,89.533,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.926 | Acc: 58.132,89.576,99.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.924 | Acc: 58.201,89.471,99.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.922 | Acc: 58.198,89.543,99.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.922 | Acc: 58.218,89.546,99.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.922 | Acc: 58.214,89.532,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.925 | Acc: 58.116,89.541,99.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.925 | Acc: 58.069,89.519,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.920 | Acc: 58.168,89.552,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.922 | Acc: 58.184,89.530,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.917 | Acc: 58.232,89.595,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.912 | Acc: 58.342,89.661,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.487 | Acc: 53.906,75.000,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.901 | Acc: 51.228,69.940,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.922 | Acc: 51.543,69.341,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.934 | Acc: 51.178,69.390,74.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 2.028 | Acc: 51.562,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.803 | Acc: 58.891,90.960,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.838 | Acc: 58.918,90.816,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.831 | Acc: 59.273,91.035,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.836 | Acc: 59.134,91.078,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.849 | Acc: 58.973,90.834,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.841 | Acc: 59.168,90.883,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.845 | Acc: 58.982,90.824,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.850 | Acc: 58.890,90.814,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.848 | Acc: 58.883,90.836,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.847 | Acc: 58.990,90.831,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.854 | Acc: 58.908,90.710,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.855 | Acc: 58.830,90.657,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.856 | Acc: 58.893,90.631,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.857 | Acc: 58.841,90.636,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.858 | Acc: 58.786,90.625,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.861 | Acc: 58.725,90.615,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.863 | Acc: 58.637,90.616,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.864 | Acc: 58.613,90.610,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.865 | Acc: 58.627,90.613,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.485 | Acc: 51.562,75.781,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.909 | Acc: 51.600,70.238,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.918 | Acc: 51.734,69.055,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.913 | Acc: 51.524,68.916,74.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.912 | Acc: 60.156,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.852 | Acc: 59.263,91.183,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.862 | Acc: 58.918,90.835,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.869 | Acc: 58.056,90.689,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.858 | Acc: 58.420,90.982,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.850 | Acc: 58.632,91.012,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.859 | Acc: 58.374,90.870,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.850 | Acc: 58.671,90.935,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.850 | Acc: 58.574,91.018,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.847 | Acc: 58.693,90.988,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.843 | Acc: 58.703,90.959,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.844 | Acc: 58.647,90.975,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.845 | Acc: 58.672,90.936,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.842 | Acc: 58.722,90.924,99.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.838 | Acc: 58.799,90.925,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.836 | Acc: 58.830,90.952,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.835 | Acc: 58.871,90.946,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.833 | Acc: 58.969,90.943,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.833 | Acc: 58.934,90.926,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.834 | Acc: 58.875,90.924,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.518 | Acc: 50.000,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.911 | Acc: 51.265,70.089,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.927 | Acc: 51.772,68.617,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.924 | Acc: 51.575,68.827,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.641 | Acc: 64.062,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.773 | Acc: 59.561,91.555,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.771 | Acc: 60.194,91.044,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.773 | Acc: 60.118,91.176,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.786 | Acc: 59.799,91.117,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.802 | Acc: 59.236,91.166,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.791 | Acc: 59.524,91.432,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.795 | Acc: 59.441,91.395,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.801 | Acc: 59.220,91.348,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.799 | Acc: 59.379,91.320,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.802 | Acc: 59.255,91.395,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.804 | Acc: 59.106,91.420,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.805 | Acc: 59.109,91.439,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.802 | Acc: 59.133,91.481,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.803 | Acc: 59.116,91.456,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.805 | Acc: 59.025,91.427,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.809 | Acc: 58.925,91.394,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.813 | Acc: 58.937,91.335,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.812 | Acc: 58.949,91.380,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.811 | Acc: 58.977,91.388,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.438 | Acc: 49.219,75.000,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.918 | Acc: 51.674,70.089,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.922 | Acc: 52.096,68.826,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.915 | Acc: 51.870,68.968,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.441 | Acc: 68.750,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.776 | Acc: 59.226,92.225,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.789 | Acc: 58.918,91.825,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.792 | Acc: 59.106,91.739,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.792 | Acc: 59.192,91.792,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.795 | Acc: 59.213,91.847,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.799 | Acc: 59.162,91.878,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.792 | Acc: 59.309,91.822,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.789 | Acc: 59.472,91.756,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.790 | Acc: 59.479,91.752,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.789 | Acc: 59.503,91.709,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.793 | Acc: 59.421,91.700,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.791 | Acc: 59.498,91.675,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.793 | Acc: 59.462,91.649,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.798 | Acc: 59.350,91.562,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.796 | Acc: 59.284,91.559,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.796 | Acc: 59.295,91.572,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.794 | Acc: 59.256,91.622,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.790 | Acc: 59.301,91.646,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.791 | Acc: 59.297,91.650,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.369 | Acc: 53.125,75.000,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.929 | Acc: 51.972,70.312,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.939 | Acc: 52.058,68.979,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.936 | Acc: 51.703,69.057,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.721 | Acc: 55.469,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.687 | Acc: 60.677,92.708,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.710 | Acc: 60.118,92.435,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.711 | Acc: 60.553,92.585,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.726 | Acc: 60.243,92.525,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.730 | Acc: 60.357,92.412,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.738 | Acc: 60.266,92.252,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.741 | Acc: 60.189,92.154,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.750 | Acc: 59.982,92.115,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.746 | Acc: 60.135,92.088,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.746 | Acc: 60.117,92.149,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.752 | Acc: 60.146,92.007,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.756 | Acc: 60.036,92.022,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.760 | Acc: 60.007,92.041,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.761 | Acc: 60.012,92.037,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.762 | Acc: 59.923,92.078,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.762 | Acc: 59.889,92.114,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.761 | Acc: 59.824,92.094,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.764 | Acc: 59.728,92.086,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.766 | Acc: 59.666,92.089,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.567 | Acc: 53.906,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.942 | Acc: 51.153,70.126,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.935 | Acc: 51.448,69.017,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.933 | Acc: 51.140,68.993,74.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.648 | Acc: 62.500,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.721 | Acc: 60.938,92.448,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.702 | Acc: 60.461,92.778,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.707 | Acc: 60.464,92.661,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.713 | Acc: 60.513,92.602,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.711 | Acc: 60.667,92.659,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.719 | Acc: 60.505,92.497,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.722 | Acc: 60.367,92.481,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.728 | Acc: 60.210,92.343,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.733 | Acc: 59.923,92.339,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.736 | Acc: 59.857,92.296,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.734 | Acc: 59.898,92.290,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.737 | Acc: 59.715,92.314,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.739 | Acc: 59.704,92.358,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.743 | Acc: 59.689,92.324,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.748 | Acc: 59.570,92.304,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.750 | Acc: 59.638,92.258,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.754 | Acc: 59.547,92.206,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.752 | Acc: 59.617,92.196,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.753 | Acc: 59.574,92.188,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.467 | Acc: 53.125,76.562,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.946 | Acc: 51.562,70.387,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.942 | Acc: 51.658,69.226,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.936 | Acc: 51.447,69.173,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 1.750 | Acc: 57.812,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.674 | Acc: 60.565,93.006,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.699 | Acc: 60.137,92.492,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.717 | Acc: 59.849,92.482,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 59.674,92.535,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.713 | Acc: 59.978,92.690,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.717 | Acc: 59.969,92.730,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.722 | Acc: 59.957,92.686,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.722 | Acc: 59.889,92.678,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.722 | Acc: 60.027,92.671,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.722 | Acc: 60.071,92.693,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.724 | Acc: 60.078,92.668,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.724 | Acc: 60.098,92.716,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.727 | Acc: 60.051,92.657,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.730 | Acc: 60.003,92.580,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.732 | Acc: 60.047,92.600,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.730 | Acc: 60.088,92.574,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.732 | Acc: 60.044,92.556,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.734 | Acc: 59.907,92.532,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.734 | Acc: 59.886,92.516,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.515 | Acc: 51.562,75.781,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.905 | Acc: 51.711,70.164,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.913 | Acc: 51.982,68.902,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.916 | Acc: 51.601,68.801,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.707 | Acc: 63.281,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.711 | Acc: 59.598,92.671,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.714 | Acc: 60.004,92.759,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.710 | Acc: 59.926,92.943,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.713 | Acc: 60.176,93.007,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.702 | Acc: 60.357,93.185,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.705 | Acc: 60.363,93.046,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.700 | Acc: 60.439,93.152,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.703 | Acc: 60.423,93.143,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.705 | Acc: 60.398,93.146,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.710 | Acc: 60.207,93.113,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.713 | Acc: 60.280,93.096,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.714 | Acc: 60.305,93.102,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.719 | Acc: 60.147,93.014,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.722 | Acc: 60.120,92.985,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.720 | Acc: 60.063,92.953,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.721 | Acc: 60.000,92.910,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.725 | Acc: 59.945,92.850,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.726 | Acc: 59.925,92.815,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.724 | Acc: 59.888,92.803,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.518 | Acc: 53.906,75.781,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.943 | Acc: 51.749,69.978,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.939 | Acc: 51.963,68.693,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.933 | Acc: 51.729,68.801,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.418 | Acc: 60.156,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.645 | Acc: 61.347,93.787,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.687 | Acc: 60.042,93.331,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.688 | Acc: 60.182,93.507,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.688 | Acc: 60.137,93.393,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.695 | Acc: 60.009,93.363,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.700 | Acc: 59.872,93.304,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.708 | Acc: 59.702,93.229,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.707 | Acc: 59.967,93.148,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.708 | Acc: 59.871,93.072,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.704 | Acc: 59.939,93.000,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.705 | Acc: 59.941,93.008,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.702 | Acc: 59.965,93.056,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.701 | Acc: 60.031,93.017,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.705 | Acc: 59.978,93.008,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.709 | Acc: 59.873,92.997,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.710 | Acc: 59.998,92.959,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.709 | Acc: 60.012,93.001,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.712 | Acc: 60.048,92.930,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.713 | Acc: 60.000,92.936,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.541 | Acc: 53.125,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.945 | Acc: 52.418,70.238,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.939 | Acc: 52.248,68.674,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.934 | Acc: 51.678,68.801,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.686 | Acc: 59.375,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.737 | Acc: 58.929,93.229,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.696 | Acc: 60.004,93.579,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.656 | Acc: 61.155,93.788,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.660 | Acc: 61.101,93.605,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 60.775,93.410,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.678 | Acc: 60.582,93.434,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.676 | Acc: 60.699,93.451,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.681 | Acc: 60.627,93.415,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.685 | Acc: 60.510,93.267,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.687 | Acc: 60.436,93.252,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.692 | Acc: 60.460,93.195,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.695 | Acc: 60.403,93.131,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.692 | Acc: 60.390,93.160,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.696 | Acc: 60.273,93.144,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.700 | Acc: 60.154,93.104,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.700 | Acc: 60.134,93.129,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.703 | Acc: 60.067,93.131,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.703 | Acc: 60.048,93.127,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.703 | Acc: 60.041,93.102,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.365 | Acc: 53.906,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.944 | Acc: 51.972,69.606,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.949 | Acc: 51.829,68.788,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.943 | Acc: 51.639,68.878,74.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.999 | Acc: 57.812,86.719,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.700 | Acc: 60.603,92.671,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 60.595,93.121,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.643 | Acc: 61.552,93.327,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.648 | Acc: 61.188,93.393,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.652 | Acc: 61.170,93.495,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.657 | Acc: 60.938,93.453,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.664 | Acc: 60.716,93.323,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.669 | Acc: 60.467,93.367,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 60.325,93.336,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.679 | Acc: 60.327,93.322,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.682 | Acc: 60.340,93.276,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.685 | Acc: 60.228,93.277,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.686 | Acc: 60.225,93.271,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.688 | Acc: 60.215,93.300,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.691 | Acc: 60.123,93.301,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.688 | Acc: 60.222,93.324,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.687 | Acc: 60.262,93.312,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.686 | Acc: 60.271,93.296,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.689 | Acc: 60.224,93.244,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.590 | Acc: 53.125,75.781,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.961 | Acc: 51.935,69.382,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.967 | Acc: 51.829,68.388,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.961 | Acc: 51.409,68.507,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.709 | Acc: 53.906,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.730 | Acc: 59.115,93.266,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.726 | Acc: 58.575,93.045,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.694 | Acc: 59.529,93.417,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.710 | Acc: 59.221,93.374,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.704 | Acc: 59.522,93.371,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.699 | Acc: 59.814,93.388,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.689 | Acc: 60.068,93.429,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.686 | Acc: 60.147,93.478,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.681 | Acc: 60.251,93.487,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.680 | Acc: 60.238,93.528,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.680 | Acc: 60.192,93.549,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.678 | Acc: 60.189,93.594,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.675 | Acc: 60.255,93.579,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.680 | Acc: 60.212,93.478,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.682 | Acc: 60.208,93.483,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.684 | Acc: 60.149,93.475,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.683 | Acc: 60.195,93.489,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.684 | Acc: 60.161,93.434,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.685 | Acc: 60.121,93.418,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.599 | Acc: 57.031,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.980 | Acc: 51.823,69.234,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.959 | Acc: 51.791,68.426,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.953 | Acc: 51.422,68.571,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.685 | Acc: 57.812,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.575 | Acc: 62.686,94.308,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.614 | Acc: 61.700,93.998,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.640 | Acc: 61.475,93.801,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.651 | Acc: 61.227,93.702,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.651 | Acc: 61.255,93.704,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.647 | Acc: 61.215,93.750,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.657 | Acc: 60.910,93.805,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.654 | Acc: 60.894,93.779,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.658 | Acc: 60.812,93.724,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.662 | Acc: 60.681,93.703,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.661 | Acc: 60.814,93.708,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.664 | Acc: 60.775,93.718,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.665 | Acc: 60.722,93.660,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.660 | Acc: 60.760,93.728,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.663 | Acc: 60.688,93.734,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.660 | Acc: 60.701,93.772,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.663 | Acc: 60.612,93.725,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.665 | Acc: 60.598,93.709,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.667 | Acc: 60.550,93.668,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.575 | Acc: 50.781,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.977 | Acc: 50.930,69.420,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.978 | Acc: 51.410,68.445,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.968 | Acc: 51.306,68.404,74.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.882 | Acc: 54.688,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.615 | Acc: 60.900,94.680,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.596 | Acc: 61.871,94.779,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.608 | Acc: 61.488,94.480,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.621 | Acc: 60.966,94.348,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.637 | Acc: 60.760,94.129,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.637 | Acc: 60.705,94.176,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.648 | Acc: 60.389,94.116,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.653 | Acc: 60.370,94.046,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.655 | Acc: 60.325,94.031,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.656 | Acc: 60.463,94.038,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.655 | Acc: 60.527,93.983,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.656 | Acc: 60.536,93.967,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.655 | Acc: 60.623,93.897,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.654 | Acc: 60.743,93.847,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.656 | Acc: 60.725,93.802,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 60.697,93.791,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 60.637,93.743,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.662 | Acc: 60.593,93.726,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.660 | Acc: 60.636,93.766,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.488 | Acc: 52.344,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.961 | Acc: 51.711,69.531,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.957 | Acc: 51.963,68.331,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.948 | Acc: 51.691,68.622,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.674 | Acc: 58.594,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.637 | Acc: 60.640,94.531,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.642 | Acc: 60.499,94.588,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.647 | Acc: 60.694,94.275,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.645 | Acc: 60.870,94.145,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.646 | Acc: 60.891,93.951,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.648 | Acc: 60.795,93.989,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.647 | Acc: 60.799,94.027,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.647 | Acc: 60.700,94.070,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.645 | Acc: 60.838,94.026,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.651 | Acc: 60.712,94.026,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.653 | Acc: 60.605,93.994,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.657 | Acc: 60.526,93.925,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.653 | Acc: 60.665,93.843,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.651 | Acc: 60.790,93.803,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.649 | Acc: 60.875,93.802,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.650 | Acc: 60.816,93.777,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.650 | Acc: 60.759,93.807,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.653 | Acc: 60.749,93.789,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.656 | Acc: 60.704,93.727,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.452 | Acc: 50.000,76.562,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.972 | Acc: 52.158,69.643,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.971 | Acc: 52.344,68.579,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.973 | Acc: 51.870,68.673,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.773 | Acc: 57.812,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.614 | Acc: 61.644,93.973,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.639 | Acc: 60.614,93.845,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.642 | Acc: 60.284,94.070,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.637 | Acc: 60.359,94.039,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.638 | Acc: 60.404,94.106,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.642 | Acc: 60.376,94.079,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.641 | Acc: 60.428,94.049,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.638 | Acc: 60.564,94.148,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.639 | Acc: 60.566,94.056,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.638 | Acc: 60.630,93.995,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.635 | Acc: 60.732,94.015,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.635 | Acc: 60.665,94.003,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.634 | Acc: 60.665,94.016,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.639 | Acc: 60.509,94.011,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.640 | Acc: 60.527,93.973,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.638 | Acc: 60.577,94.006,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.639 | Acc: 60.626,94.016,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.642 | Acc: 60.619,93.997,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.643 | Acc: 60.583,93.994,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.514 | Acc: 53.906,75.000,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.955 | Acc: 51.935,69.717,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.959 | Acc: 52.210,68.636,75.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.963 | Acc: 51.819,68.519,75.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.760 | Acc: 57.812,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.639 | Acc: 59.635,94.754,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.626 | Acc: 60.880,94.684,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.622 | Acc: 60.899,94.634,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.620 | Acc: 60.754,94.753,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.616 | Acc: 60.829,94.694,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.620 | Acc: 60.744,94.615,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.624 | Acc: 60.860,94.592,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.629 | Acc: 60.792,94.400,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.626 | Acc: 60.920,94.389,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.622 | Acc: 61.011,94.442,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.626 | Acc: 60.938,94.379,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.630 | Acc: 60.860,94.304,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.632 | Acc: 60.791,94.328,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.631 | Acc: 60.854,94.317,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.634 | Acc: 60.813,94.267,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.633 | Acc: 60.816,94.249,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.633 | Acc: 60.782,94.238,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.635 | Acc: 60.823,94.196,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.633 | Acc: 60.804,94.228,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.497 | Acc: 54.688,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.967 | Acc: 51.414,69.531,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.981 | Acc: 51.982,68.636,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.980 | Acc: 51.524,68.596,74.898,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 1.385 | Acc: 68.750,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.618 | Acc: 61.124,94.866,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.589 | Acc: 61.376,94.912,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.606 | Acc: 61.450,94.749,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.621 | Acc: 61.005,94.734,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.624 | Acc: 60.860,94.624,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.626 | Acc: 61.073,94.576,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.624 | Acc: 61.048,94.542,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.633 | Acc: 60.773,94.361,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.630 | Acc: 60.860,94.389,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.630 | Acc: 60.852,94.345,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.631 | Acc: 60.736,94.347,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.632 | Acc: 60.749,94.343,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.634 | Acc: 60.794,94.313,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.634 | Acc: 60.732,94.259,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.630 | Acc: 60.873,94.282,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.631 | Acc: 60.833,94.242,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.630 | Acc: 60.880,94.192,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.630 | Acc: 60.816,94.213,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.630 | Acc: 60.862,94.191,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.442 | Acc: 59.375,75.781,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.962 | Acc: 52.195,69.420,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.967 | Acc: 52.229,68.216,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.972 | Acc: 51.895,68.135,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.350 | Acc: 67.188,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.547 | Acc: 62.463,95.201,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.568 | Acc: 62.309,95.027,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.575 | Acc: 62.116,95.005,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.572 | Acc: 62.404,94.821,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.582 | Acc: 62.013,94.717,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.584 | Acc: 62.048,94.667,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.595 | Acc: 61.807,94.603,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.597 | Acc: 61.728,94.560,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.602 | Acc: 61.619,94.510,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.603 | Acc: 61.606,94.477,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.610 | Acc: 61.450,94.514,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.613 | Acc: 61.391,94.496,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.616 | Acc: 61.312,94.459,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.615 | Acc: 61.357,94.456,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.617 | Acc: 61.355,94.412,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.616 | Acc: 61.298,94.400,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.616 | Acc: 61.247,94.387,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.617 | Acc: 61.180,94.362,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.619 | Acc: 61.145,94.371,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.482 | Acc: 53.906,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.977 | Acc: 52.195,69.271,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.974 | Acc: 52.420,68.255,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.968 | Acc: 52.036,68.404,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 1.454 | Acc: 65.625,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.632 | Acc: 60.789,94.680,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.594 | Acc: 61.814,94.722,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.594 | Acc: 61.603,94.762,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.604 | Acc: 61.372,94.734,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.611 | Acc: 61.332,94.748,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.617 | Acc: 61.247,94.744,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.610 | Acc: 61.353,94.731,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.612 | Acc: 61.170,94.682,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.609 | Acc: 61.201,94.592,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.615 | Acc: 61.011,94.512,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.614 | Acc: 61.104,94.485,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.616 | Acc: 60.908,94.437,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.617 | Acc: 60.914,94.385,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.619 | Acc: 60.826,94.351,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.618 | Acc: 60.841,94.350,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.618 | Acc: 60.869,94.315,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.615 | Acc: 60.896,94.353,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.615 | Acc: 60.970,94.334,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.615 | Acc: 60.983,94.347,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.485 | Acc: 54.688,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.992 | Acc: 51.711,68.973,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.002 | Acc: 51.677,67.988,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.986 | Acc: 51.601,68.315,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.654 | Acc: 55.469,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.601 | Acc: 61.384,95.275,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.602 | Acc: 61.509,94.989,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.612 | Acc: 61.219,94.851,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.605 | Acc: 61.285,94.821,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.622 | Acc: 60.760,94.694,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.620 | Acc: 60.860,94.706,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.613 | Acc: 60.921,94.697,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.613 | Acc: 61.078,94.633,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.616 | Acc: 60.968,94.631,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.614 | Acc: 60.976,94.566,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.614 | Acc: 60.945,94.521,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.609 | Acc: 60.931,94.577,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.610 | Acc: 60.985,94.591,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.612 | Acc: 60.996,94.528,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.611 | Acc: 61.088,94.516,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.612 | Acc: 61.052,94.480,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.612 | Acc: 60.974,94.531,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.612 | Acc: 60.927,94.492,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.614 | Acc: 60.964,94.439,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.687 | Acc: 51.562,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.022 | Acc: 51.228,68.266,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.021 | Acc: 51.715,67.664,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.013 | Acc: 51.383,67.866,74.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.692 | Acc: 57.031,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.616 | Acc: 60.751,94.643,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.614 | Acc: 61.109,94.950,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.592 | Acc: 61.270,95.108,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.597 | Acc: 61.265,95.139,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.591 | Acc: 61.703,94.980,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.602 | Acc: 61.422,94.951,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.601 | Acc: 61.270,94.941,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.607 | Acc: 61.117,94.842,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.607 | Acc: 61.089,94.816,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.607 | Acc: 61.167,94.733,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.604 | Acc: 61.199,94.733,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.603 | Acc: 61.200,94.713,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.604 | Acc: 61.159,94.729,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.604 | Acc: 61.110,94.756,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.606 | Acc: 61.018,94.754,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.606 | Acc: 61.098,94.687,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.605 | Acc: 61.105,94.653,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.605 | Acc: 61.115,94.650,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.605 | Acc: 61.048,94.681,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.469 | Acc: 55.469,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.007 | Acc: 51.562,69.457,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.030 | Acc: 52.096,68.540,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.021 | Acc: 51.434,68.609,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.666 | Acc: 60.156,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.576 | Acc: 61.310,95.164,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.624 | Acc: 60.633,94.836,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.604 | Acc: 60.925,94.941,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.605 | Acc: 60.899,94.907,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.608 | Acc: 60.651,94.949,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.599 | Acc: 60.750,95.061,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.599 | Acc: 60.832,95.013,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.599 | Acc: 60.899,94.871,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.598 | Acc: 60.886,94.885,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.595 | Acc: 61.081,94.893,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.594 | Acc: 61.104,94.902,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.593 | Acc: 61.151,94.855,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.597 | Acc: 61.138,94.843,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.597 | Acc: 61.196,94.815,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.597 | Acc: 61.163,94.814,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.596 | Acc: 61.147,94.784,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.599 | Acc: 61.132,94.747,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.595 | Acc: 61.238,94.780,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.599 | Acc: 61.161,94.728,99.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.504 | Acc: 57.031,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.009 | Acc: 51.674,68.713,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.993 | Acc: 52.153,68.121,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.986 | Acc: 51.844,68.276,74.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.890 | Acc: 54.688,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.576 | Acc: 61.198,94.940,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.587 | Acc: 60.957,95.312,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.587 | Acc: 61.181,95.159,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.586 | Acc: 61.265,94.965,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.586 | Acc: 61.255,94.964,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.591 | Acc: 61.080,94.848,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.587 | Acc: 61.154,94.764,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.586 | Acc: 61.117,94.842,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.588 | Acc: 61.002,94.864,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.583 | Acc: 61.163,94.838,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.585 | Acc: 61.224,94.775,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.587 | Acc: 61.242,94.781,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.585 | Acc: 61.126,94.792,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.583 | Acc: 61.210,94.793,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.582 | Acc: 61.150,94.840,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.585 | Acc: 61.178,94.779,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.585 | Acc: 61.254,94.719,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.587 | Acc: 61.160,94.676,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.590 | Acc: 61.141,94.654,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.544 | Acc: 53.906,72.656,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.991 | Acc: 52.195,68.973,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.986 | Acc: 52.268,68.083,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.985 | Acc: 52.088,68.186,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.433 | Acc: 64.844,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.527 | Acc: 62.463,95.387,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.536 | Acc: 62.652,95.103,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.567 | Acc: 61.872,94.890,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.554 | Acc: 61.979,94.985,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.561 | Acc: 62.005,95.096,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.561 | Acc: 61.835,95.080,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.564 | Acc: 61.697,95.035,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.573 | Acc: 61.568,94.919,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.570 | Acc: 61.637,94.950,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.572 | Acc: 61.633,94.947,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.574 | Acc: 61.574,94.924,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.573 | Acc: 61.589,94.933,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.573 | Acc: 61.698,94.950,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.580 | Acc: 61.544,94.873,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.582 | Acc: 61.529,94.871,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.581 | Acc: 61.631,94.855,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.583 | Acc: 61.590,94.841,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.582 | Acc: 61.608,94.819,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.583 | Acc: 61.596,94.818,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.569 | Acc: 54.688,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.005 | Acc: 52.493,69.122,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.011 | Acc: 52.191,68.426,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.001 | Acc: 51.819,68.558,74.898,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.621 | Acc: 59.375,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.579 | Acc: 62.016,95.685,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.559 | Acc: 61.871,95.560,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.557 | Acc: 62.013,95.633,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.566 | Acc: 61.970,95.438,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.563 | Acc: 61.765,95.390,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.557 | Acc: 61.777,95.474,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.553 | Acc: 61.863,95.484,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.559 | Acc: 61.612,95.385,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.562 | Acc: 61.421,95.369,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.563 | Acc: 61.381,95.312,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.563 | Acc: 61.348,95.259,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.568 | Acc: 61.278,95.186,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.566 | Acc: 61.321,95.187,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.567 | Acc: 61.335,95.168,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.569 | Acc: 61.278,95.157,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.570 | Acc: 61.251,95.147,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.574 | Acc: 61.160,95.099,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.574 | Acc: 61.085,95.109,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.576 | Acc: 61.095,95.126,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.565 | Acc: 54.688,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.996 | Acc: 52.418,68.899,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.020 | Acc: 52.172,67.759,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.024 | Acc: 51.486,67.815,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.246 | Acc: 71.094,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.540 | Acc: 62.314,95.685,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.553 | Acc: 62.157,95.598,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.542 | Acc: 62.282,95.658,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.546 | Acc: 62.240,95.698,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.543 | Acc: 62.361,95.459,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.542 | Acc: 62.132,95.409,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.547 | Acc: 62.062,95.385,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.553 | Acc: 62.063,95.308,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.550 | Acc: 62.206,95.265,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.553 | Acc: 62.166,95.200,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.559 | Acc: 61.991,95.125,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.564 | Acc: 61.813,95.030,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.570 | Acc: 61.644,94.977,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.578 | Acc: 61.413,94.937,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.577 | Acc: 61.438,94.952,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.578 | Acc: 61.395,94.918,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.578 | Acc: 61.448,94.918,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.578 | Acc: 61.472,94.936,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.579 | Acc: 61.432,94.956,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.629 | Acc: 53.906,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.039 | Acc: 50.446,68.527,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.035 | Acc: 51.162,67.645,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.032 | Acc: 50.973,67.789,74.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.269 | Acc: 67.188,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.594 | Acc: 59.710,95.685,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.586 | Acc: 59.851,95.465,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.558 | Acc: 60.822,95.441,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.547 | Acc: 61.420,95.602,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.559 | Acc: 61.378,95.421,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.568 | Acc: 61.170,95.345,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.567 | Acc: 61.253,95.329,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.572 | Acc: 61.180,95.308,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.573 | Acc: 61.214,95.334,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.571 | Acc: 61.311,95.305,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.566 | Acc: 61.471,95.298,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.565 | Acc: 61.485,95.257,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.568 | Acc: 61.443,95.208,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.568 | Acc: 61.438,95.168,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.569 | Acc: 61.519,95.136,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.569 | Acc: 61.529,95.142,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.569 | Acc: 61.595,95.113,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.571 | Acc: 61.576,95.064,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.574 | Acc: 61.542,95.044,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.612 | Acc: 54.688,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.034 | Acc: 52.009,68.862,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.026 | Acc: 52.058,68.140,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.030 | Acc: 51.831,68.251,74.629,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.406 | Acc: 68.750,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.573 | Acc: 61.384,95.052,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.557 | Acc: 62.119,95.408,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.552 | Acc: 62.129,95.223,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.552 | Acc: 62.143,95.206,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.555 | Acc: 62.106,95.227,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.550 | Acc: 62.190,95.300,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.549 | Acc: 62.112,95.335,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.545 | Acc: 62.151,95.317,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.543 | Acc: 62.263,95.325,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.549 | Acc: 62.142,95.285,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.557 | Acc: 62.005,95.263,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.559 | Acc: 61.952,95.254,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.564 | Acc: 61.832,95.181,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.568 | Acc: 61.591,95.249,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.569 | Acc: 61.529,95.237,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.569 | Acc: 61.565,95.184,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.572 | Acc: 61.535,95.150,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.572 | Acc: 61.548,95.118,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.572 | Acc: 61.549,95.095,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.782 | Acc: 52.344,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.087 | Acc: 50.967,68.378,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.077 | Acc: 51.353,67.969,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.064 | Acc: 50.884,68.071,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 1.493 | Acc: 62.500,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.547 | Acc: 62.463,95.573,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.557 | Acc: 62.195,95.198,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.542 | Acc: 62.308,95.594,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.550 | Acc: 61.960,95.640,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.552 | Acc: 62.075,95.537,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.558 | Acc: 61.848,95.590,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.554 | Acc: 61.758,95.567,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.561 | Acc: 61.593,95.521,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.561 | Acc: 61.412,95.550,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.561 | Acc: 61.536,95.499,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.564 | Acc: 61.567,95.426,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.563 | Acc: 61.579,95.381,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.562 | Acc: 61.692,95.372,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.566 | Acc: 61.627,95.304,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.565 | Acc: 61.573,95.318,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.564 | Acc: 61.565,95.320,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.564 | Acc: 61.568,95.322,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.566 | Acc: 61.435,95.269,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.570 | Acc: 61.348,95.222,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.610 | Acc: 55.469,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.053 | Acc: 52.158,68.936,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 52.229,67.797,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.042 | Acc: 51.678,68.020,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.401 | Acc: 68.750,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.526 | Acc: 63.170,95.685,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.549 | Acc: 61.909,95.636,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.556 | Acc: 61.360,95.645,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.539 | Acc: 61.613,95.640,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.539 | Acc: 61.843,95.606,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.546 | Acc: 61.635,95.526,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.543 | Acc: 61.724,95.473,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.542 | Acc: 61.796,95.439,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.542 | Acc: 61.926,95.507,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.545 | Acc: 61.789,95.468,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.550 | Acc: 61.694,95.433,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.547 | Acc: 61.829,95.426,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.544 | Acc: 61.913,95.447,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.546 | Acc: 61.927,95.390,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.548 | Acc: 61.874,95.359,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.552 | Acc: 61.855,95.315,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.552 | Acc: 61.861,95.299,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.554 | Acc: 61.777,95.289,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.554 | Acc: 61.741,95.327,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.620 | Acc: 55.469,72.656,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.077 | Acc: 51.972,68.118,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.077 | Acc: 51.791,67.569,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.066 | Acc: 51.473,67.802,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.740 | Acc: 57.812,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.530 | Acc: 62.277,96.019,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.540 | Acc: 62.443,95.732,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.525 | Acc: 62.795,95.748,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.523 | Acc: 62.799,95.824,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.515 | Acc: 62.802,95.916,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.519 | Acc: 62.526,95.997,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.522 | Acc: 62.478,95.922,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.522 | Acc: 62.427,95.909,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.528 | Acc: 62.297,95.757,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.531 | Acc: 62.181,95.783,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.532 | Acc: 62.065,95.726,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.531 | Acc: 62.101,95.702,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.531 | Acc: 62.060,95.678,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.535 | Acc: 61.947,95.582,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.539 | Acc: 61.916,95.556,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.542 | Acc: 61.928,95.522,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.548 | Acc: 61.794,95.450,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.551 | Acc: 61.790,95.377,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.550 | Acc: 61.784,95.376,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.670 | Acc: 53.906,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.049 | Acc: 52.046,68.824,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.037 | Acc: 52.115,68.064,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.031 | Acc: 52.024,68.199,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 1.429 | Acc: 61.719,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.509 | Acc: 61.756,95.685,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.537 | Acc: 61.528,95.579,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.546 | Acc: 61.936,95.517,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.541 | Acc: 61.941,95.515,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.535 | Acc: 62.059,95.583,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.527 | Acc: 62.255,95.629,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.527 | Acc: 62.140,95.662,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.532 | Acc: 62.024,95.584,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.532 | Acc: 62.017,95.546,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.529 | Acc: 62.224,95.526,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.535 | Acc: 62.058,95.500,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.538 | Acc: 61.968,95.543,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.546 | Acc: 61.856,95.519,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.546 | Acc: 61.822,95.521,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.545 | Acc: 61.906,95.528,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.547 | Acc: 61.826,95.490,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.544 | Acc: 61.900,95.512,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.546 | Acc: 61.842,95.455,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.548 | Acc: 61.803,95.444,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.691 | Acc: 55.469,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.061 | Acc: 51.823,68.787,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.074 | Acc: 51.524,68.178,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.072 | Acc: 51.498,68.135,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.246 | Acc: 67.969,98.438,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.498 | Acc: 62.500,96.131,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.511 | Acc: 62.043,95.941,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.526 | Acc: 61.949,95.927,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.522 | Acc: 61.989,95.833,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.517 | Acc: 62.214,95.784,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.525 | Acc: 62.054,95.713,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.528 | Acc: 61.946,95.689,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.529 | Acc: 61.908,95.613,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.523 | Acc: 62.060,95.602,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.525 | Acc: 61.960,95.561,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.530 | Acc: 61.853,95.486,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.538 | Acc: 61.628,95.413,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.540 | Acc: 61.614,95.441,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.540 | Acc: 61.610,95.468,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.538 | Acc: 61.773,95.455,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.542 | Acc: 61.626,95.502,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.542 | Acc: 61.584,95.473,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.545 | Acc: 61.617,95.438,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.544 | Acc: 61.647,95.409,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.566 | Acc: 53.906,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.076 | Acc: 52.418,68.304,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.087 | Acc: 51.886,67.588,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.080 | Acc: 51.691,67.905,74.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.538 | Acc: 63.281,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.513 | Acc: 63.058,95.685,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.497 | Acc: 62.729,95.636,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.507 | Acc: 62.410,95.774,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.518 | Acc: 62.008,95.862,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.516 | Acc: 61.997,95.746,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.516 | Acc: 62.145,95.610,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.521 | Acc: 62.068,95.678,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.522 | Acc: 62.029,95.599,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.520 | Acc: 62.185,95.606,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.526 | Acc: 62.065,95.542,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.530 | Acc: 61.952,95.489,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.533 | Acc: 61.913,95.462,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.534 | Acc: 61.827,95.462,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.537 | Acc: 61.838,95.401,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.540 | Acc: 61.776,95.367,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.537 | Acc: 61.911,95.403,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.540 | Acc: 61.891,95.363,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.543 | Acc: 61.870,95.351,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.544 | Acc: 61.842,95.382,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.632 | Acc: 50.781,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.056 | Acc: 52.083,68.378,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.037 | Acc: 52.382,67.912,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.038 | Acc: 52.011,68.353,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.403 | Acc: 61.719,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.560 | Acc: 61.384,95.945,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.520 | Acc: 62.576,95.922,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.511 | Acc: 62.577,95.812,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.494 | Acc: 63.069,95.930,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.505 | Acc: 62.724,95.792,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 62.803,95.629,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.508 | Acc: 62.627,95.562,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.514 | Acc: 62.418,95.536,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.525 | Acc: 62.271,95.464,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.525 | Acc: 62.321,95.472,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.523 | Acc: 62.309,95.521,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.527 | Acc: 62.302,95.536,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.525 | Acc: 62.356,95.579,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.528 | Acc: 62.266,95.566,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.528 | Acc: 62.227,95.606,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.531 | Acc: 62.169,95.597,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.531 | Acc: 62.092,95.624,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.534 | Acc: 62.009,95.555,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.533 | Acc: 62.014,95.583,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.704 | Acc: 55.469,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.034 | Acc: 52.269,68.899,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.053 | Acc: 51.696,67.893,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.054 | Acc: 51.537,67.789,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.356 | Acc: 66.406,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.500 | Acc: 63.170,95.908,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 63.110,96.132,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.493 | Acc: 63.089,96.145,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.495 | Acc: 63.098,96.287,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.506 | Acc: 62.655,96.125,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.520 | Acc: 62.390,96.087,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.525 | Acc: 62.223,96.155,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.526 | Acc: 62.049,96.045,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.519 | Acc: 62.185,96.055,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.521 | Acc: 62.146,95.981,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.519 | Acc: 62.341,96.009,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.519 | Acc: 62.328,95.977,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.518 | Acc: 62.437,95.968,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.521 | Acc: 62.297,95.849,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.522 | Acc: 62.235,95.860,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.523 | Acc: 62.227,95.828,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.523 | Acc: 62.204,95.773,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.527 | Acc: 62.139,95.715,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.530 | Acc: 62.057,95.696,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.740 | Acc: 54.688,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.036 | Acc: 52.567,68.899,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.049 | Acc: 52.020,68.293,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.056 | Acc: 51.755,68.212,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.472 | Acc: 65.625,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.494 | Acc: 62.054,96.131,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 62.881,96.189,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.497 | Acc: 62.244,96.222,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.502 | Acc: 62.182,96.084,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.502 | Acc: 62.299,96.086,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.502 | Acc: 62.351,96.152,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 62.417,96.055,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.509 | Acc: 62.364,95.958,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.510 | Acc: 62.293,95.960,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.515 | Acc: 62.189,95.923,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.516 | Acc: 62.072,95.896,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.522 | Acc: 62.030,95.831,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.523 | Acc: 62.000,95.851,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.525 | Acc: 61.986,95.830,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.527 | Acc: 62.012,95.767,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.529 | Acc: 61.950,95.724,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.529 | Acc: 61.964,95.709,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.527 | Acc: 62.059,95.702,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.528 | Acc: 62.119,95.663,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.658 | Acc: 56.250,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.023 | Acc: 52.344,68.304,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.039 | Acc: 52.325,67.569,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.038 | Acc: 52.126,67.892,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.631 | Acc: 59.375,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.495 | Acc: 62.426,96.094,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.490 | Acc: 62.862,96.303,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.504 | Acc: 62.398,96.273,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.500 | Acc: 62.558,96.267,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.500 | Acc: 62.724,96.163,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.494 | Acc: 62.862,96.287,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.503 | Acc: 62.644,96.171,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.505 | Acc: 62.558,96.162,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.505 | Acc: 62.517,96.133,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.509 | Acc: 62.434,96.113,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.514 | Acc: 62.433,96.044,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.517 | Acc: 62.283,96.045,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.520 | Acc: 62.177,96.004,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.524 | Acc: 62.077,95.969,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.523 | Acc: 62.072,95.894,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.524 | Acc: 62.052,95.858,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.527 | Acc: 62.026,95.826,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.529 | Acc: 62.017,95.830,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.526 | Acc: 62.104,95.839,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.584 | Acc: 54.688,71.094,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.071 | Acc: 52.158,68.192,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.075 | Acc: 52.153,67.188,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.075 | Acc: 51.793,67.546,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 1.435 | Acc: 60.156,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.448 | Acc: 63.318,97.024,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.453 | Acc: 63.605,96.494,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.485 | Acc: 62.871,96.247,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.500 | Acc: 62.693,96.103,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.495 | Acc: 62.825,96.032,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.506 | Acc: 62.229,96.055,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 62.494,96.083,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.510 | Acc: 62.393,96.002,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.516 | Acc: 62.336,95.917,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.510 | Acc: 62.434,95.931,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.508 | Acc: 62.514,95.977,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.514 | Acc: 62.406,95.925,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.515 | Acc: 62.392,95.926,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.513 | Acc: 62.511,95.885,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.515 | Acc: 62.487,95.871,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.516 | Acc: 62.439,95.850,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.520 | Acc: 62.292,95.810,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.523 | Acc: 62.245,95.786,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.522 | Acc: 62.240,95.757,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.752 | Acc: 53.125,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.078 | Acc: 52.046,68.676,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.097 | Acc: 52.191,67.759,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.090 | Acc: 51.678,67.751,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 1.572 | Acc: 59.375,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.448 | Acc: 63.988,95.759,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.460 | Acc: 63.415,96.113,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.470 | Acc: 63.064,95.991,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.473 | Acc: 62.973,96.055,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.484 | Acc: 62.593,96.063,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.495 | Acc: 62.584,96.003,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.498 | Acc: 62.422,95.994,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.502 | Acc: 62.335,96.045,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.500 | Acc: 62.444,96.102,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.500 | Acc: 62.473,96.039,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.503 | Acc: 62.486,95.995,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.505 | Acc: 62.461,95.990,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 62.374,96.022,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 62.339,95.977,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.511 | Acc: 62.240,95.943,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.509 | Acc: 62.271,95.967,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.512 | Acc: 62.257,95.924,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.513 | Acc: 62.178,95.934,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.514 | Acc: 62.199,95.878,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.687 | Acc: 51.562,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.079 | Acc: 51.376,68.006,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.109 | Acc: 51.391,67.588,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.116 | Acc: 50.935,67.687,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.202 | Acc: 72.656,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.484 | Acc: 63.914,95.871,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.460 | Acc: 64.043,95.998,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.473 | Acc: 63.486,96.068,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.470 | Acc: 63.706,96.007,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.481 | Acc: 63.274,96.047,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 63.262,96.016,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 63.021,96.033,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.494 | Acc: 62.796,95.968,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.501 | Acc: 62.586,95.891,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.504 | Acc: 62.679,95.849,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 62.525,95.846,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.509 | Acc: 62.390,95.877,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.510 | Acc: 62.362,95.836,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 62.461,95.821,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.514 | Acc: 62.311,95.821,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.513 | Acc: 62.247,95.804,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.515 | Acc: 62.225,95.821,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.517 | Acc: 62.206,95.817,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.519 | Acc: 62.129,95.788,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.816 | Acc: 53.125,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.177 | Acc: 50.856,67.671,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.200 | Acc: 50.381,66.692,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.196 | Acc: 50.307,66.906,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.615 | Acc: 61.719,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.500 | Acc: 62.723,96.391,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.514 | Acc: 62.100,96.132,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.524 | Acc: 61.808,95.748,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.518 | Acc: 61.883,95.814,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.515 | Acc: 62.028,95.792,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.516 | Acc: 61.996,95.790,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.514 | Acc: 61.979,95.833,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.512 | Acc: 62.078,95.880,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 62.146,95.891,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.517 | Acc: 62.076,95.899,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.520 | Acc: 62.076,95.952,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.519 | Acc: 62.169,95.971,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.518 | Acc: 62.108,95.965,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.516 | Acc: 62.122,95.996,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.517 | Acc: 62.160,95.951,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.514 | Acc: 62.196,95.936,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.518 | Acc: 62.166,95.901,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.517 | Acc: 62.206,95.890,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.518 | Acc: 62.178,95.889,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.796 | Acc: 52.344,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.091 | Acc: 51.860,68.601,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.100 | Acc: 51.905,67.721,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.107 | Acc: 51.511,67.661,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.332 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.453 | Acc: 62.760,95.833,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.462 | Acc: 62.767,96.132,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.455 | Acc: 63.281,96.209,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.465 | Acc: 63.243,96.094,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.478 | Acc: 62.902,96.125,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.476 | Acc: 62.784,96.262,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.493 | Acc: 62.400,96.266,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 62.616,96.220,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.497 | Acc: 62.371,96.202,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.501 | Acc: 62.422,96.063,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.508 | Acc: 62.274,96.041,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.511 | Acc: 62.247,96.013,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.508 | Acc: 62.359,96.013,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 62.266,96.010,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.510 | Acc: 62.248,95.969,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.513 | Acc: 62.184,95.957,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.515 | Acc: 62.078,95.936,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.518 | Acc: 62.106,95.903,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.517 | Acc: 62.127,95.866,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.701 | Acc: 55.469,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.108 | Acc: 52.009,68.601,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.112 | Acc: 51.963,67.893,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.113 | Acc: 51.332,67.930,74.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.782 | Acc: 57.031,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.492 | Acc: 63.207,96.094,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.507 | Acc: 62.481,95.922,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.501 | Acc: 62.846,95.710,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.494 | Acc: 62.857,95.891,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.509 | Acc: 62.384,95.893,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 62.577,95.945,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.505 | Acc: 62.539,96.016,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.500 | Acc: 62.602,96.036,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.502 | Acc: 62.595,96.059,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.498 | Acc: 62.558,96.094,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.504 | Acc: 62.475,96.069,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.502 | Acc: 62.494,96.068,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.504 | Acc: 62.437,96.088,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.503 | Acc: 62.405,96.058,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.502 | Acc: 62.381,96.003,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 62.371,96.006,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 62.445,96.004,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 62.485,95.973,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.504 | Acc: 62.453,95.967,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.705 | Acc: 55.469,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.031 | Acc: 51.786,68.787,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.057 | Acc: 52.096,67.626,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.071 | Acc: 51.486,67.572,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.494 | Acc: 61.719,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.421 | Acc: 63.467,96.838,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.455 | Acc: 63.529,96.513,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.453 | Acc: 63.678,96.440,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.467 | Acc: 63.513,96.364,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.475 | Acc: 63.243,96.295,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.476 | Acc: 63.075,96.281,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.485 | Acc: 62.799,96.177,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.493 | Acc: 62.539,96.113,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.495 | Acc: 62.474,96.102,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.498 | Acc: 62.519,96.082,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.499 | Acc: 62.489,96.080,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.499 | Acc: 62.425,96.084,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.497 | Acc: 62.476,96.073,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.496 | Acc: 62.458,96.074,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.499 | Acc: 62.420,96.078,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.497 | Acc: 62.483,96.055,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 62.340,95.988,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 62.351,95.964,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.505 | Acc: 62.328,95.922,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.802 | Acc: 56.250,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.096 | Acc: 53.125,68.304,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.108 | Acc: 52.458,67.511,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.114 | Acc: 52.216,67.546,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.193 | Acc: 69.531,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.456 | Acc: 63.244,96.615,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.472 | Acc: 62.786,96.418,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.459 | Acc: 63.179,96.619,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.462 | Acc: 63.378,96.634,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.469 | Acc: 62.972,96.658,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.463 | Acc: 63.139,96.604,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.468 | Acc: 63.137,96.537,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.474 | Acc: 63.010,96.492,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.475 | Acc: 62.992,96.499,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.477 | Acc: 62.959,96.428,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.478 | Acc: 63.020,96.394,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.479 | Acc: 62.967,96.379,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.478 | Acc: 63.000,96.393,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.482 | Acc: 62.914,96.363,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.485 | Acc: 62.824,96.322,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.488 | Acc: 62.751,96.288,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.492 | Acc: 62.631,96.236,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.497 | Acc: 62.576,96.204,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.500 | Acc: 62.607,96.157,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.756 | Acc: 57.031,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.091 | Acc: 52.418,68.118,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.090 | Acc: 52.553,67.530,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.086 | Acc: 52.177,67.725,74.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.404 | Acc: 64.844,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.480 | Acc: 62.202,96.317,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.489 | Acc: 62.043,96.227,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.506 | Acc: 61.783,96.145,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.506 | Acc: 62.037,96.152,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.494 | Acc: 62.492,96.357,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.492 | Acc: 62.603,96.365,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.490 | Acc: 62.611,96.343,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.492 | Acc: 62.529,96.322,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.496 | Acc: 62.362,96.249,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.498 | Acc: 62.383,96.308,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.500 | Acc: 62.443,96.292,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.498 | Acc: 62.506,96.220,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.495 | Acc: 62.620,96.237,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 62.517,96.185,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 62.401,96.179,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 62.356,96.111,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.501 | Acc: 62.296,96.117,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.504 | Acc: 62.277,96.079,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.501 | Acc: 62.363,96.083,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.825 | Acc: 51.562,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.124 | Acc: 52.455,67.671,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.102 | Acc: 52.325,67.168,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.122 | Acc: 51.947,67.380,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.511 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.479 | Acc: 62.649,96.317,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.479 | Acc: 62.957,96.227,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.469 | Acc: 63.140,96.286,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.472 | Acc: 63.349,96.142,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.477 | Acc: 63.157,96.256,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.478 | Acc: 63.120,96.313,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 62.860,96.326,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.488 | Acc: 62.733,96.254,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.490 | Acc: 62.617,96.228,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.493 | Acc: 62.407,96.171,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 62.542,96.168,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.492 | Acc: 62.539,96.178,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.496 | Acc: 62.383,96.133,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 62.386,96.138,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.497 | Acc: 62.388,96.140,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.499 | Acc: 62.337,96.130,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 62.369,96.075,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.500 | Acc: 62.329,96.074,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.501 | Acc: 62.385,96.014,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.839 | Acc: 55.469,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.093 | Acc: 52.418,67.857,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.112 | Acc: 51.562,66.845,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.114 | Acc: 51.447,67.252,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.216 | Acc: 71.094,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.451 | Acc: 64.546,97.135,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.441 | Acc: 64.177,97.027,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.468 | Acc: 63.256,96.811,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.466 | Acc: 63.522,96.750,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.470 | Acc: 63.366,96.658,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.474 | Acc: 63.191,96.707,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.478 | Acc: 62.982,96.631,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.482 | Acc: 62.811,96.540,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.485 | Acc: 62.768,96.439,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.488 | Acc: 62.539,96.416,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.488 | Acc: 62.528,96.405,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 62.591,96.324,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.491 | Acc: 62.554,96.294,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.491 | Acc: 62.583,96.280,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.491 | Acc: 62.643,96.281,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.490 | Acc: 62.656,96.252,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.490 | Acc: 62.644,96.254,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.492 | Acc: 62.636,96.219,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.495 | Acc: 62.547,96.166,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.887 | Acc: 53.125,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.151 | Acc: 52.009,68.155,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.148 | Acc: 51.696,67.264,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.151 | Acc: 51.089,67.213,74.142,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.334 | Acc: 68.750,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.433 | Acc: 64.397,97.061,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.432 | Acc: 63.453,96.989,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.453 | Acc: 63.102,96.734,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.459 | Acc: 63.137,96.644,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.466 | Acc: 62.995,96.651,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.482 | Acc: 62.526,96.552,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 62.428,96.543,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.481 | Acc: 62.660,96.564,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.474 | Acc: 62.772,96.556,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.478 | Acc: 62.710,96.552,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.479 | Acc: 62.680,96.546,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.480 | Acc: 62.720,96.554,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.482 | Acc: 62.644,96.588,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.483 | Acc: 62.631,96.516,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.484 | Acc: 62.606,96.480,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.481 | Acc: 62.675,96.473,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.479 | Acc: 62.711,96.453,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 62.675,96.429,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.487 | Acc: 62.562,96.414,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.048 | Acc: 48.438,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.116 | Acc: 51.451,68.229,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.130 | Acc: 51.143,67.454,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.141 | Acc: 50.858,67.316,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.278 | Acc: 64.844,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.433 | Acc: 63.467,96.131,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.452 | Acc: 63.758,96.227,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.462 | Acc: 63.512,96.171,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.463 | Acc: 63.194,96.306,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.467 | Acc: 62.972,96.303,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.474 | Acc: 62.829,96.307,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 62.932,96.365,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.475 | Acc: 62.951,96.351,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.471 | Acc: 63.083,96.361,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.476 | Acc: 62.935,96.296,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.476 | Acc: 62.850,96.306,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.480 | Acc: 62.889,96.288,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.478 | Acc: 62.943,96.273,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.476 | Acc: 62.911,96.305,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.480 | Acc: 62.814,96.255,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.485 | Acc: 62.729,96.250,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.488 | Acc: 62.692,96.222,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.490 | Acc: 62.680,96.187,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.493 | Acc: 62.644,96.153,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.882 | Acc: 54.688,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.133 | Acc: 51.265,67.783,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.145 | Acc: 50.953,67.397,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.164 | Acc: 50.730,67.520,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.276 | Acc: 67.188,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.453 | Acc: 62.649,97.321,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.454 | Acc: 63.377,96.799,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.469 | Acc: 62.910,96.683,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.477 | Acc: 62.934,96.480,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.490 | Acc: 62.655,96.388,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.494 | Acc: 62.597,96.333,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.496 | Acc: 62.395,96.332,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.489 | Acc: 62.549,96.356,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.485 | Acc: 62.573,96.400,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.488 | Acc: 62.492,96.370,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.486 | Acc: 62.500,96.384,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 62.526,96.379,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 62.518,96.339,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.483 | Acc: 62.570,96.352,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.482 | Acc: 62.653,96.338,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.485 | Acc: 62.607,96.298,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.486 | Acc: 62.580,96.275,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.486 | Acc: 62.569,96.234,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 62.574,96.204,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.887 | Acc: 53.125,65.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.143 | Acc: 52.009,67.894,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.138 | Acc: 51.315,67.264,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.151 | Acc: 50.884,67.123,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.536 | Acc: 59.375,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.479 | Acc: 63.876,96.131,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.452 | Acc: 64.482,96.437,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.446 | Acc: 64.191,96.696,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.464 | Acc: 63.619,96.595,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.457 | Acc: 63.622,96.589,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.458 | Acc: 63.598,96.436,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.461 | Acc: 63.447,96.437,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.464 | Acc: 63.213,96.463,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.468 | Acc: 63.143,96.435,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.467 | Acc: 63.238,96.440,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.473 | Acc: 63.016,96.380,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.474 | Acc: 62.967,96.347,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.476 | Acc: 62.925,96.330,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.478 | Acc: 62.784,96.299,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.483 | Acc: 62.625,96.278,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.479 | Acc: 62.741,96.264,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.480 | Acc: 62.688,96.300,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 62.636,96.273,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.482 | Acc: 62.693,96.268,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.779 | Acc: 54.688,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.189 | Acc: 51.376,67.560,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.182 | Acc: 51.124,67.264,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.175 | Acc: 50.679,67.149,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.605 | Acc: 58.594,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.476 | Acc: 64.062,96.429,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.463 | Acc: 63.434,96.665,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.468 | Acc: 63.320,96.824,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.456 | Acc: 63.426,96.740,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.457 | Acc: 63.413,96.736,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.461 | Acc: 63.410,96.617,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.460 | Acc: 63.442,96.592,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.466 | Acc: 63.204,96.506,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.469 | Acc: 63.035,96.474,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.470 | Acc: 63.048,96.471,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.471 | Acc: 63.126,96.419,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.470 | Acc: 63.025,96.398,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.472 | Acc: 62.973,96.342,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.475 | Acc: 62.856,96.333,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.473 | Acc: 62.889,96.356,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.472 | Acc: 62.887,96.327,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.474 | Acc: 62.825,96.293,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.477 | Acc: 62.825,96.273,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 62.715,96.221,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.824 | Acc: 52.344,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.210 | Acc: 51.265,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.211 | Acc: 50.915,67.207,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.202 | Acc: 50.820,67.136,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.292 | Acc: 62.500,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.448 | Acc: 63.393,96.912,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.466 | Acc: 62.938,96.608,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.465 | Acc: 62.820,96.555,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.464 | Acc: 62.760,96.692,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.471 | Acc: 62.639,96.682,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.470 | Acc: 62.868,96.688,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.476 | Acc: 62.589,96.626,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.478 | Acc: 62.456,96.589,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.480 | Acc: 62.340,96.547,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.484 | Acc: 62.220,96.506,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.483 | Acc: 62.192,96.511,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.482 | Acc: 62.224,96.483,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.478 | Acc: 62.500,96.474,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.479 | Acc: 62.581,96.377,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 62.632,96.369,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.478 | Acc: 62.624,96.349,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.474 | Acc: 62.786,96.321,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.477 | Acc: 62.682,96.299,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.477 | Acc: 62.789,96.297,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.802 | Acc: 53.906,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.099 | Acc: 51.860,68.304,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.093 | Acc: 52.153,67.588,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.110 | Acc: 51.486,67.585,74.629,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.502 | Acc: 61.719,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.479 | Acc: 61.868,96.689,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.440 | Acc: 63.415,96.742,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.457 | Acc: 62.743,96.849,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.448 | Acc: 62.895,96.711,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.445 | Acc: 62.794,96.713,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.449 | Acc: 62.713,96.655,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.452 | Acc: 62.683,96.659,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.453 | Acc: 62.718,96.671,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.462 | Acc: 62.547,96.633,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.461 | Acc: 62.675,96.653,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.464 | Acc: 62.603,96.663,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.468 | Acc: 62.545,96.570,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.469 | Acc: 62.650,96.528,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.472 | Acc: 62.583,96.508,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.471 | Acc: 62.526,96.548,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.470 | Acc: 62.644,96.507,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.475 | Acc: 62.624,96.479,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.478 | Acc: 62.582,96.429,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.478 | Acc: 62.594,96.405,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.741 | Acc: 55.469,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.143 | Acc: 52.083,68.118,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.150 | Acc: 51.905,67.168,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.149 | Acc: 51.396,67.456,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.538 | Acc: 64.062,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.448 | Acc: 62.537,96.875,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.463 | Acc: 63.338,96.646,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.451 | Acc: 63.601,96.504,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.455 | Acc: 63.349,96.508,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.451 | Acc: 63.513,96.550,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.440 | Acc: 63.798,96.655,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.447 | Acc: 63.641,96.570,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.450 | Acc: 63.538,96.555,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.448 | Acc: 63.467,96.543,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.451 | Acc: 63.476,96.506,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.455 | Acc: 63.426,96.468,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.460 | Acc: 63.349,96.441,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.461 | Acc: 63.311,96.435,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.464 | Acc: 63.201,96.441,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.464 | Acc: 63.115,96.431,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.469 | Acc: 62.992,96.391,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.470 | Acc: 62.965,96.362,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.470 | Acc: 62.967,96.364,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.474 | Acc: 62.883,96.358,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.957 | Acc: 53.125,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.180 | Acc: 52.381,68.155,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.216 | Acc: 51.448,67.130,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.214 | Acc: 50.922,67.059,74.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.645 | Acc: 58.594,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.466 | Acc: 62.835,96.615,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.466 | Acc: 62.881,96.570,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.457 | Acc: 62.871,96.798,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.457 | Acc: 62.828,96.827,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.457 | Acc: 62.817,96.635,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.460 | Acc: 62.707,96.462,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.456 | Acc: 62.816,96.443,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.455 | Acc: 62.956,96.438,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.456 | Acc: 62.940,96.512,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.457 | Acc: 62.920,96.529,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.460 | Acc: 63.009,96.479,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.462 | Acc: 62.967,96.473,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.464 | Acc: 62.991,96.471,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.462 | Acc: 63.045,96.497,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.465 | Acc: 63.001,96.439,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.466 | Acc: 63.023,96.408,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.467 | Acc: 63.022,96.380,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.468 | Acc: 63.071,96.321,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.472 | Acc: 63.021,96.284,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.791 | Acc: 57.812,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.153 | Acc: 52.604,68.006,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.167 | Acc: 52.553,66.711,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.166 | Acc: 52.126,67.123,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 1.336 | Acc: 64.062,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.466 | Acc: 62.574,96.540,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.462 | Acc: 62.348,96.265,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.460 | Acc: 63.025,96.119,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.464 | Acc: 62.616,96.171,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.466 | Acc: 62.755,96.101,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.457 | Acc: 62.862,96.158,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.460 | Acc: 62.760,96.121,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.462 | Acc: 62.786,96.186,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.468 | Acc: 62.711,96.232,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.462 | Acc: 62.877,96.335,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.462 | Acc: 62.967,96.348,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.465 | Acc: 62.847,96.311,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.468 | Acc: 62.874,96.276,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.469 | Acc: 62.709,96.280,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.471 | Acc: 62.661,96.296,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.474 | Acc: 62.619,96.323,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.472 | Acc: 62.699,96.339,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.471 | Acc: 62.734,96.317,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.470 | Acc: 62.828,96.313,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.871 | Acc: 53.906,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.152 | Acc: 51.451,68.155,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.154 | Acc: 51.315,67.550,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.161 | Acc: 51.089,67.482,74.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.332 | Acc: 62.500,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.455 | Acc: 62.723,96.838,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.436 | Acc: 63.281,97.085,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.446 | Acc: 63.140,97.054,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.453 | Acc: 62.867,96.914,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.455 | Acc: 62.848,96.883,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.448 | Acc: 63.017,96.881,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.444 | Acc: 63.026,96.892,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.446 | Acc: 63.126,96.880,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.449 | Acc: 63.160,96.858,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.450 | Acc: 63.184,96.840,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.454 | Acc: 63.122,96.758,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.453 | Acc: 63.074,96.726,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.452 | Acc: 63.006,96.716,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.455 | Acc: 62.962,96.683,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.456 | Acc: 62.998,96.652,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.456 | Acc: 63.099,96.632,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.460 | Acc: 63.050,96.529,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.462 | Acc: 63.039,96.492,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.464 | Acc: 63.021,96.475,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.987 | Acc: 56.250,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.149 | Acc: 52.455,68.415,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.144 | Acc: 52.268,67.854,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.152 | Acc: 51.691,67.930,74.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 1.237 | Acc: 67.188,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.399 | Acc: 64.174,96.726,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.418 | Acc: 63.624,96.704,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.423 | Acc: 63.794,96.747,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.442 | Acc: 63.407,96.740,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.444 | Acc: 63.150,96.890,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.442 | Acc: 63.100,96.888,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.450 | Acc: 62.893,96.698,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.453 | Acc: 62.903,96.691,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.448 | Acc: 63.130,96.651,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.448 | Acc: 63.071,96.634,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.451 | Acc: 63.136,96.582,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.455 | Acc: 63.074,96.570,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.462 | Acc: 62.910,96.522,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.463 | Acc: 62.911,96.458,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.462 | Acc: 62.993,96.465,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.462 | Acc: 63.062,96.466,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.463 | Acc: 63.077,96.490,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.466 | Acc: 62.998,96.505,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.466 | Acc: 62.972,96.487,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.873 | Acc: 53.906,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.132 | Acc: 52.307,67.820,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.169 | Acc: 52.191,67.111,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.170 | Acc: 51.857,67.290,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.393 | Acc: 66.406,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.449 | Acc: 62.835,96.838,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.435 | Acc: 63.319,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.450 | Acc: 63.358,96.760,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.452 | Acc: 62.915,96.721,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.454 | Acc: 62.918,96.597,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.453 | Acc: 62.952,96.526,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.453 | Acc: 62.877,96.471,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.456 | Acc: 62.883,96.414,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.458 | Acc: 62.759,96.439,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.458 | Acc: 62.772,96.479,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.459 | Acc: 62.832,96.454,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.462 | Acc: 62.750,96.463,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.460 | Acc: 62.853,96.510,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.459 | Acc: 62.889,96.466,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.460 | Acc: 62.900,96.457,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.465 | Acc: 62.850,96.398,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.466 | Acc: 62.802,96.378,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.465 | Acc: 62.890,96.403,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.468 | Acc: 62.836,96.369,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.723 | Acc: 53.125,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.157 | Acc: 52.418,67.820,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.180 | Acc: 51.658,67.340,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.172 | Acc: 51.178,67.520,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 1.396 | Acc: 66.406,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.458 | Acc: 63.839,96.987,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.422 | Acc: 64.082,97.046,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.412 | Acc: 64.114,97.234,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.430 | Acc: 63.783,96.981,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.438 | Acc: 63.482,96.906,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.441 | Acc: 63.417,96.849,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.447 | Acc: 63.121,96.753,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.452 | Acc: 63.073,96.666,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.453 | Acc: 63.065,96.625,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.452 | Acc: 63.122,96.634,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.452 | Acc: 63.158,96.606,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.453 | Acc: 63.161,96.596,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.452 | Acc: 63.221,96.618,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.453 | Acc: 63.203,96.566,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.455 | Acc: 63.120,96.527,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.459 | Acc: 63.011,96.515,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.462 | Acc: 63.020,96.488,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.464 | Acc: 62.976,96.464,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.465 | Acc: 62.968,96.448,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.054 | Acc: 52.344,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.200 | Acc: 51.451,67.411,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.190 | Acc: 51.639,67.378,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.199 | Acc: 51.101,67.085,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.494 | Acc: 57.031,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.453 | Acc: 62.909,96.168,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.468 | Acc: 63.167,96.265,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.456 | Acc: 63.640,96.376,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.456 | Acc: 63.551,96.402,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.463 | Acc: 63.397,96.272,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.463 | Acc: 63.417,96.397,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.458 | Acc: 63.359,96.382,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.461 | Acc: 63.276,96.370,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.460 | Acc: 63.251,96.396,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.460 | Acc: 63.250,96.420,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.460 | Acc: 63.211,96.433,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.458 | Acc: 63.226,96.428,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.460 | Acc: 63.159,96.378,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.464 | Acc: 63.114,96.386,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.466 | Acc: 63.014,96.400,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.463 | Acc: 63.101,96.386,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.463 | Acc: 63.125,96.334,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.463 | Acc: 63.125,96.334,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.464 | Acc: 63.130,96.328,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.937 | Acc: 56.250,66.406,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.213 | Acc: 52.418,67.188,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.188 | Acc: 52.134,67.092,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.184 | Acc: 51.652,67.290,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.197 | Acc: 66.406,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.370 | Acc: 64.881,97.359,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.368 | Acc: 65.244,97.085,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.385 | Acc: 64.959,97.003,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.397 | Acc: 64.554,96.962,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.407 | Acc: 64.117,96.890,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.414 | Acc: 63.901,96.830,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.423 | Acc: 63.603,96.786,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.429 | Acc: 63.635,96.754,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.436 | Acc: 63.497,96.754,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.440 | Acc: 63.371,96.704,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.441 | Acc: 63.507,96.606,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.444 | Acc: 63.424,96.629,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.446 | Acc: 63.365,96.609,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.447 | Acc: 63.253,96.566,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.449 | Acc: 63.250,96.558,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.451 | Acc: 63.223,96.537,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.453 | Acc: 63.183,96.534,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.457 | Acc: 63.117,96.511,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.458 | Acc: 63.093,96.473,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.818 | Acc: 53.125,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.201 | Acc: 50.707,68.006,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.197 | Acc: 50.667,67.473,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.205 | Acc: 50.628,67.469,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.423 | Acc: 66.406,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.483 | Acc: 62.798,96.949,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.473 | Acc: 62.843,96.742,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.459 | Acc: 62.884,96.773,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.452 | Acc: 63.011,96.798,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.446 | Acc: 63.335,96.751,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.446 | Acc: 63.307,96.804,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.444 | Acc: 63.254,96.731,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.447 | Acc: 63.165,96.695,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.448 | Acc: 63.160,96.668,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.453 | Acc: 63.056,96.618,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.451 | Acc: 63.062,96.617,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.453 | Acc: 62.999,96.596,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.450 | Acc: 63.168,96.600,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.454 | Acc: 63.126,96.572,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.451 | Acc: 63.227,96.535,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.451 | Acc: 63.174,96.554,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.455 | Acc: 63.141,96.508,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.457 | Acc: 63.121,96.527,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.459 | Acc: 63.033,96.498,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.073 | Acc: 57.812,67.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.208 | Acc: 51.525,67.560,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.202 | Acc: 51.315,66.673,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.227 | Acc: 50.743,66.790,74.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.416 | Acc: 67.188,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.420 | Acc: 63.690,96.875,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.440 | Acc: 63.262,96.856,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.427 | Acc: 63.691,96.785,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.435 | Acc: 63.609,96.701,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.431 | Acc: 63.637,96.697,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.435 | Acc: 63.417,96.668,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.439 | Acc: 63.414,96.648,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.450 | Acc: 63.165,96.598,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.447 | Acc: 63.182,96.586,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.451 | Acc: 63.009,96.549,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.452 | Acc: 62.924,96.536,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.453 | Acc: 62.996,96.473,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.455 | Acc: 62.979,96.471,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.452 | Acc: 63.012,96.491,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.452 | Acc: 63.042,96.491,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.452 | Acc: 63.087,96.517,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.454 | Acc: 63.045,96.520,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.457 | Acc: 62.963,96.475,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.458 | Acc: 62.972,96.481,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.951 | Acc: 53.906,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.240 | Acc: 51.488,66.481,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.237 | Acc: 51.258,66.311,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.231 | Acc: 50.858,66.611,74.193,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 1.533 | Acc: 59.375,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 63.244,96.726,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.440 | Acc: 63.396,96.665,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.431 | Acc: 63.614,96.747,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.415 | Acc: 63.879,96.885,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.419 | Acc: 63.699,96.860,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.432 | Acc: 63.397,96.823,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.431 | Acc: 63.614,96.759,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.440 | Acc: 63.495,96.666,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.440 | Acc: 63.363,96.664,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.447 | Acc: 63.161,96.618,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.450 | Acc: 63.133,96.543,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.447 | Acc: 63.145,96.564,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.445 | Acc: 63.185,96.579,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.445 | Acc: 63.228,96.544,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.448 | Acc: 63.196,96.543,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.453 | Acc: 63.050,96.505,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.456 | Acc: 63.054,96.463,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.459 | Acc: 62.998,96.444,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.460 | Acc: 63.029,96.430,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.796 | Acc: 53.906,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.168 | Acc: 51.972,67.746,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.174 | Acc: 51.658,67.435,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.184 | Acc: 51.473,67.405,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.340 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.458 | Acc: 62.463,96.726,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.446 | Acc: 63.129,96.684,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.461 | Acc: 62.769,96.734,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.452 | Acc: 63.117,96.769,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.449 | Acc: 63.459,96.774,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.453 | Acc: 63.191,96.798,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.448 | Acc: 63.425,96.797,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.450 | Acc: 63.335,96.744,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.452 | Acc: 63.229,96.646,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.449 | Acc: 63.238,96.669,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.447 | Acc: 63.295,96.656,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.448 | Acc: 63.353,96.609,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.448 | Acc: 63.317,96.609,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.448 | Acc: 63.276,96.600,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.449 | Acc: 63.266,96.571,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.451 | Acc: 63.199,96.551,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.453 | Acc: 63.158,96.529,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.455 | Acc: 63.089,96.520,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.459 | Acc: 62.988,96.516,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.070 | Acc: 54.688,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.231 | Acc: 51.414,67.374,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.205 | Acc: 52.210,67.111,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.222 | Acc: 51.639,67.008,74.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.316 | Acc: 71.875,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 62.984,96.354,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.429 | Acc: 63.510,96.646,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.429 | Acc: 63.678,96.824,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.423 | Acc: 63.561,96.943,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.415 | Acc: 63.838,96.976,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.423 | Acc: 63.701,96.888,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.421 | Acc: 63.841,96.919,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.427 | Acc: 63.558,96.875,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.438 | Acc: 63.316,96.905,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.437 | Acc: 63.402,96.937,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.442 | Acc: 63.246,96.879,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.442 | Acc: 63.265,96.862,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.444 | Acc: 63.263,96.800,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.447 | Acc: 63.178,96.783,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.445 | Acc: 63.216,96.727,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.447 | Acc: 63.186,96.748,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.450 | Acc: 63.146,96.724,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.448 | Acc: 63.151,96.721,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.449 | Acc: 63.119,96.693,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.046 | Acc: 52.344,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.249 | Acc: 51.153,68.006,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.261 | Acc: 50.800,66.864,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.278 | Acc: 50.128,66.906,74.334,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.553 | Acc: 53.125,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.449 | Acc: 62.016,96.689,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.433 | Acc: 63.072,96.932,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.443 | Acc: 63.025,96.926,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.431 | Acc: 63.291,96.914,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.434 | Acc: 63.258,96.929,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.437 | Acc: 63.294,96.972,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.439 | Acc: 63.281,96.936,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.433 | Acc: 63.354,97.001,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.434 | Acc: 63.398,96.953,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.438 | Acc: 63.320,96.929,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.439 | Acc: 63.281,96.886,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.440 | Acc: 63.320,96.830,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.444 | Acc: 63.150,96.818,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.446 | Acc: 63.134,96.783,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.451 | Acc: 62.996,96.719,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.452 | Acc: 62.948,96.707,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.454 | Acc: 62.935,96.667,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.456 | Acc: 62.944,96.628,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.452 | Acc: 63.037,96.645,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.831 | Acc: 58.594,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.130 | Acc: 52.455,67.932,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.156 | Acc: 51.696,66.997,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.181 | Acc: 51.396,66.919,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.256 | Acc: 64.844,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.438 | Acc: 63.356,97.135,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.412 | Acc: 64.367,97.180,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.403 | Acc: 64.447,97.413,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.397 | Acc: 64.400,97.415,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.397 | Acc: 64.449,97.447,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.389 | Acc: 64.637,97.488,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.393 | Acc: 64.511,97.518,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.392 | Acc: 64.669,97.525,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.389 | Acc: 64.727,97.574,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.384 | Acc: 64.832,97.594,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.382 | Acc: 64.992,97.575,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.378 | Acc: 64.944,97.630,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.373 | Acc: 64.978,97.659,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.369 | Acc: 65.063,97.690,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.369 | Acc: 65.002,97.703,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.367 | Acc: 65.077,97.710,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.365 | Acc: 65.075,97.718,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.364 | Acc: 65.119,97.734,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.361 | Acc: 65.186,97.771,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.747 | Acc: 57.812,69.531,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.018 | Acc: 54.427,68.638,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.031 | Acc: 53.887,67.759,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.046 | Acc: 53.227,68.007,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.316 | Acc: 69.531,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.331 | Acc: 65.439,97.619,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.303 | Acc: 66.330,97.732,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.314 | Acc: 65.894,97.976,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.324 | Acc: 65.673,98.003,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.328 | Acc: 65.633,97.973,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.326 | Acc: 65.748,97.921,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.329 | Acc: 65.581,97.922,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.330 | Acc: 65.475,97.952,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.326 | Acc: 65.552,97.993,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.325 | Acc: 65.571,98.033,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.326 | Acc: 65.544,98.056,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.329 | Acc: 65.460,98.052,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.331 | Acc: 65.439,98.084,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.334 | Acc: 65.308,98.071,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.339 | Acc: 65.194,98.074,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.338 | Acc: 65.167,98.068,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.338 | Acc: 65.151,98.055,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.338 | Acc: 65.077,98.057,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.338 | Acc: 65.116,98.073,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.777 | Acc: 57.812,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.025 | Acc: 53.460,68.713,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.028 | Acc: 53.487,67.950,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.046 | Acc: 53.061,68.148,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.253 | Acc: 70.312,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.360 | Acc: 65.216,98.103,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.319 | Acc: 66.082,98.152,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.308 | Acc: 65.856,98.373,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.314 | Acc: 65.606,98.264,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.315 | Acc: 65.579,98.252,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.319 | Acc: 65.347,98.283,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.319 | Acc: 65.475,98.271,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.316 | Acc: 65.402,98.258,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.314 | Acc: 65.625,98.209,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.317 | Acc: 65.532,98.154,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.322 | Acc: 65.378,98.194,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.322 | Acc: 65.388,98.178,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.321 | Acc: 65.341,98.165,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.325 | Acc: 65.266,98.179,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.323 | Acc: 65.306,98.201,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.324 | Acc: 65.240,98.172,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.327 | Acc: 65.208,98.130,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.327 | Acc: 65.188,98.122,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.329 | Acc: 65.168,98.138,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.758 | Acc: 60.156,69.531,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.016 | Acc: 53.720,68.638,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.026 | Acc: 53.392,67.988,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.036 | Acc: 52.984,68.007,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.252 | Acc: 63.281,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.362 | Acc: 64.174,98.177,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.323 | Acc: 64.806,98.514,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.330 | Acc: 64.664,98.463,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.323 | Acc: 65.172,98.438,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.325 | Acc: 65.145,98.337,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.331 | Acc: 64.992,98.205,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.327 | Acc: 65.099,98.238,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.330 | Acc: 65.149,98.248,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.331 | Acc: 65.111,98.243,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.332 | Acc: 65.100,98.274,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.331 | Acc: 65.215,98.293,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.328 | Acc: 65.327,98.305,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.327 | Acc: 65.293,98.336,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.323 | Acc: 65.339,98.360,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.325 | Acc: 65.298,98.321,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.323 | Acc: 65.367,98.309,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.321 | Acc: 65.497,98.337,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.318 | Acc: 65.610,98.329,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.316 | Acc: 65.672,98.323,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.739 | Acc: 56.250,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.017 | Acc: 54.167,68.155,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.027 | Acc: 53.944,67.664,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.036 | Acc: 53.394,67.892,74.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.232 | Acc: 64.844,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.285 | Acc: 67.374,98.624,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.295 | Acc: 66.883,98.247,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.313 | Acc: 66.573,98.194,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.318 | Acc: 65.934,98.187,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.320 | Acc: 65.671,98.205,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.315 | Acc: 65.722,98.263,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.308 | Acc: 65.957,98.266,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.311 | Acc: 65.829,98.258,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.314 | Acc: 65.802,98.248,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.319 | Acc: 65.625,98.185,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.319 | Acc: 65.629,98.247,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.315 | Acc: 65.664,98.275,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.315 | Acc: 65.637,98.282,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.314 | Acc: 65.775,98.276,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.317 | Acc: 65.651,98.240,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.315 | Acc: 65.686,98.257,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.318 | Acc: 65.630,98.263,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.321 | Acc: 65.560,98.264,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.319 | Acc: 65.609,98.269,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.767 | Acc: 57.812,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.032 | Acc: 53.981,68.415,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.034 | Acc: 53.830,67.969,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.044 | Acc: 53.291,68.148,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.424 | Acc: 60.938,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.323 | Acc: 65.476,98.177,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.307 | Acc: 66.139,98.171,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.301 | Acc: 66.637,98.169,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.308 | Acc: 66.464,98.148,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.307 | Acc: 66.538,98.159,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.313 | Acc: 66.342,98.186,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.311 | Acc: 66.262,98.199,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.310 | Acc: 66.309,98.239,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.313 | Acc: 66.221,98.286,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.316 | Acc: 66.154,98.309,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.319 | Acc: 66.074,98.303,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.320 | Acc: 65.939,98.288,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.319 | Acc: 65.960,98.294,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.319 | Acc: 65.936,98.262,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.322 | Acc: 65.763,98.256,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.319 | Acc: 65.727,98.257,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.318 | Acc: 65.774,98.254,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.320 | Acc: 65.753,98.238,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.318 | Acc: 65.832,98.232,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.786 | Acc: 58.594,67.969,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.035 | Acc: 53.311,68.192,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.047 | Acc: 53.506,67.664,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.057 | Acc: 53.163,67.789,74.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.466 | Acc: 62.500,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.284 | Acc: 67.708,98.475,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.286 | Acc: 66.635,98.457,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.288 | Acc: 66.137,98.489,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.311 | Acc: 65.606,98.312,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.312 | Acc: 65.687,98.321,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.318 | Acc: 65.399,98.334,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.319 | Acc: 65.448,98.321,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.315 | Acc: 65.644,98.370,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.313 | Acc: 65.720,98.377,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.314 | Acc: 65.734,98.403,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.313 | Acc: 65.830,98.416,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.313 | Acc: 65.751,98.441,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.312 | Acc: 65.718,98.423,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.316 | Acc: 65.611,98.415,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.315 | Acc: 65.498,98.438,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.315 | Acc: 65.535,98.418,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.314 | Acc: 65.543,98.412,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.314 | Acc: 65.586,98.405,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.311 | Acc: 65.687,98.403,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.757 | Acc: 57.031,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.037 | Acc: 53.683,68.118,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.043 | Acc: 53.525,67.702,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.050 | Acc: 53.125,67.828,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.296 | Acc: 67.188,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.275 | Acc: 67.225,98.251,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.302 | Acc: 66.330,98.304,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.306 | Acc: 66.189,98.425,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.304 | Acc: 66.213,98.312,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.310 | Acc: 66.259,98.252,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.310 | Acc: 66.148,98.205,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.308 | Acc: 66.201,98.293,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.312 | Acc: 66.047,98.302,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.313 | Acc: 66.104,98.343,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.314 | Acc: 66.115,98.294,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.315 | Acc: 65.975,98.293,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.316 | Acc: 65.933,98.305,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.313 | Acc: 65.963,98.288,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.315 | Acc: 65.875,98.312,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.316 | Acc: 65.799,98.310,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.313 | Acc: 65.900,98.313,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.313 | Acc: 65.895,98.318,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.315 | Acc: 65.878,98.323,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.315 | Acc: 65.896,98.325,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.747 | Acc: 59.375,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.043 | Acc: 53.348,68.006,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.049 | Acc: 53.354,67.683,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.057 | Acc: 52.856,67.905,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.154 | Acc: 69.531,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.329 | Acc: 65.104,98.363,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.295 | Acc: 66.159,98.514,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.290 | Acc: 66.368,98.527,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.303 | Acc: 66.059,98.515,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.302 | Acc: 66.105,98.546,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.307 | Acc: 66.012,98.509,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.310 | Acc: 65.924,98.454,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.305 | Acc: 65.979,98.476,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.311 | Acc: 65.841,98.455,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.309 | Acc: 65.882,98.472,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.307 | Acc: 65.865,98.483,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.307 | Acc: 65.894,98.480,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.305 | Acc: 65.948,98.473,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.309 | Acc: 65.889,98.449,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.308 | Acc: 65.874,98.453,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.307 | Acc: 65.915,98.455,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.307 | Acc: 65.868,98.456,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.309 | Acc: 65.839,98.420,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.306 | Acc: 65.943,98.425,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.771 | Acc: 57.031,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.041 | Acc: 53.832,68.266,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.049 | Acc: 53.735,67.626,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.061 | Acc: 52.997,67.751,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.349 | Acc: 64.844,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.315 | Acc: 64.621,98.363,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.300 | Acc: 65.225,98.342,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.312 | Acc: 65.343,98.309,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.312 | Acc: 65.490,98.322,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.311 | Acc: 65.408,98.329,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.306 | Acc: 65.664,98.360,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.308 | Acc: 65.775,98.327,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.307 | Acc: 65.746,98.321,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.312 | Acc: 65.521,98.321,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.309 | Acc: 65.714,98.352,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.309 | Acc: 65.735,98.360,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.308 | Acc: 65.657,98.366,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.304 | Acc: 65.855,98.387,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.304 | Acc: 65.870,98.374,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.304 | Acc: 65.877,98.341,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.304 | Acc: 65.895,98.345,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.306 | Acc: 65.808,98.346,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.307 | Acc: 65.846,98.338,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.305 | Acc: 65.869,98.331,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.821 | Acc: 56.250,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.037 | Acc: 53.497,68.415,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.051 | Acc: 53.449,67.778,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.060 | Acc: 52.946,67.994,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.250 | Acc: 62.500,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.286 | Acc: 64.881,98.475,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.294 | Acc: 65.415,98.438,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.317 | Acc: 64.869,98.476,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.323 | Acc: 64.834,98.322,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.316 | Acc: 65.076,98.383,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.309 | Acc: 65.302,98.360,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.304 | Acc: 65.503,98.404,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.309 | Acc: 65.470,98.399,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.305 | Acc: 65.608,98.438,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.309 | Acc: 65.621,98.430,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.310 | Acc: 65.604,98.445,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.310 | Acc: 65.537,98.483,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.308 | Acc: 65.646,98.497,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.310 | Acc: 65.664,98.471,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.307 | Acc: 65.765,98.471,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.307 | Acc: 65.705,98.469,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.308 | Acc: 65.701,98.479,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.309 | Acc: 65.751,98.472,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.310 | Acc: 65.764,98.446,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.705 | Acc: 58.594,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.043 | Acc: 53.311,68.527,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.048 | Acc: 53.296,67.854,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.055 | Acc: 52.894,67.994,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.062 | Acc: 73.438,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.313 | Acc: 65.030,98.438,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.300 | Acc: 65.758,98.399,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.301 | Acc: 65.830,98.438,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.295 | Acc: 65.934,98.505,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.292 | Acc: 66.151,98.546,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.293 | Acc: 66.148,98.509,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.297 | Acc: 65.946,98.454,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.298 | Acc: 65.887,98.418,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.303 | Acc: 65.703,98.446,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.300 | Acc: 65.831,98.484,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.301 | Acc: 65.841,98.452,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.303 | Acc: 65.803,98.467,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.303 | Acc: 65.876,98.488,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.308 | Acc: 65.722,98.463,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.307 | Acc: 65.674,98.456,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.309 | Acc: 65.640,98.455,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.308 | Acc: 65.673,98.470,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.309 | Acc: 65.725,98.463,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.309 | Acc: 65.734,98.456,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.779 | Acc: 56.250,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.023 | Acc: 53.646,68.899,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.045 | Acc: 53.373,68.045,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.056 | Acc: 52.920,68.148,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.208 | Acc: 70.312,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.330 | Acc: 66.257,98.475,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.326 | Acc: 65.701,98.399,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.306 | Acc: 66.483,98.309,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.307 | Acc: 66.242,98.274,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.315 | Acc: 65.973,98.182,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.318 | Acc: 65.941,98.212,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.320 | Acc: 65.963,98.216,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.318 | Acc: 65.974,98.253,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.318 | Acc: 66.005,98.213,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.316 | Acc: 65.955,98.274,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.318 | Acc: 65.862,98.278,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.315 | Acc: 65.875,98.298,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.313 | Acc: 65.912,98.282,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.312 | Acc: 65.889,98.304,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.309 | Acc: 65.934,98.310,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.310 | Acc: 65.825,98.306,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.310 | Acc: 65.850,98.316,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.309 | Acc: 65.883,98.329,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.311 | Acc: 65.846,98.312,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.786 | Acc: 56.250,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.033 | Acc: 53.757,68.415,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.049 | Acc: 53.639,67.835,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.061 | Acc: 53.061,68.071,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 0.991 | Acc: 72.656,99.219,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.308 | Acc: 65.402,98.251,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.301 | Acc: 65.796,98.228,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.311 | Acc: 65.548,98.309,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.313 | Acc: 65.654,98.293,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.302 | Acc: 66.027,98.376,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.301 | Acc: 66.025,98.386,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.300 | Acc: 66.107,98.426,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.302 | Acc: 66.037,98.404,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.302 | Acc: 65.944,98.416,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.306 | Acc: 65.850,98.441,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.309 | Acc: 65.848,98.448,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.309 | Acc: 65.894,98.450,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.302 | Acc: 66.089,98.458,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.302 | Acc: 66.067,98.474,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.300 | Acc: 66.108,98.500,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.302 | Acc: 65.995,98.489,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.302 | Acc: 65.957,98.495,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.303 | Acc: 65.880,98.500,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.303 | Acc: 65.865,98.491,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.828 | Acc: 55.469,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.036 | Acc: 53.237,68.118,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.043 | Acc: 53.316,67.569,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.055 | Acc: 52.946,68.020,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.534 | Acc: 57.812,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.311 | Acc: 65.402,98.661,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.295 | Acc: 65.968,98.761,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.299 | Acc: 66.060,98.540,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.292 | Acc: 66.069,98.553,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.296 | Acc: 66.004,98.476,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.302 | Acc: 65.838,98.431,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.296 | Acc: 65.963,98.460,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.293 | Acc: 66.105,98.447,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.293 | Acc: 66.242,98.442,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.290 | Acc: 66.251,98.469,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.293 | Acc: 66.254,98.476,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.293 | Acc: 66.199,98.467,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.294 | Acc: 66.188,98.464,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.293 | Acc: 66.231,98.460,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.297 | Acc: 66.204,98.461,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.301 | Acc: 66.085,98.469,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.298 | Acc: 66.152,98.460,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.300 | Acc: 66.075,98.444,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.304 | Acc: 65.996,98.431,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.754 | Acc: 57.812,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.040 | Acc: 53.460,68.638,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 53.449,67.873,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.062 | Acc: 52.754,68.071,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.086 | Acc: 69.531,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.271 | Acc: 66.220,98.735,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.296 | Acc: 65.072,98.571,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.298 | Acc: 65.484,98.386,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.295 | Acc: 65.625,98.466,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.292 | Acc: 65.803,98.484,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.292 | Acc: 65.819,98.450,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.294 | Acc: 66.079,98.476,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.300 | Acc: 65.926,98.442,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.298 | Acc: 66.001,98.425,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.300 | Acc: 65.940,98.449,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.297 | Acc: 65.925,98.476,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.298 | Acc: 65.930,98.493,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.297 | Acc: 65.936,98.497,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.297 | Acc: 65.984,98.485,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.298 | Acc: 66.009,98.474,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.300 | Acc: 66.002,98.481,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.302 | Acc: 65.914,98.488,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.302 | Acc: 65.924,98.481,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.301 | Acc: 65.947,98.501,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.773 | Acc: 55.469,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.036 | Acc: 53.869,68.601,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.047 | Acc: 53.639,67.778,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.057 | Acc: 53.112,67.969,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.382 | Acc: 68.750,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.324 | Acc: 65.588,98.698,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.299 | Acc: 65.892,98.895,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.306 | Acc: 65.932,98.822,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.310 | Acc: 66.098,98.708,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.311 | Acc: 65.950,98.662,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.308 | Acc: 66.096,98.657,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.305 | Acc: 66.079,98.637,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.305 | Acc: 66.023,98.588,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.300 | Acc: 66.134,98.623,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.300 | Acc: 66.068,98.632,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.304 | Acc: 65.940,98.575,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.301 | Acc: 66.033,98.564,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.298 | Acc: 66.137,98.569,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.296 | Acc: 66.170,98.577,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.297 | Acc: 66.183,98.549,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.295 | Acc: 66.158,98.554,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.300 | Acc: 66.081,98.522,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.303 | Acc: 65.973,98.524,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.302 | Acc: 65.959,98.548,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.741 | Acc: 57.812,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.035 | Acc: 53.757,68.527,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 53.449,67.569,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.062 | Acc: 52.766,67.969,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.164 | Acc: 67.969,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.297 | Acc: 65.885,98.512,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.291 | Acc: 65.930,98.361,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.300 | Acc: 65.920,98.527,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.299 | Acc: 65.828,98.573,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.294 | Acc: 65.811,98.530,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.294 | Acc: 65.896,98.528,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.296 | Acc: 65.935,98.521,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.299 | Acc: 65.970,98.520,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.301 | Acc: 65.811,98.528,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.300 | Acc: 65.843,98.523,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.302 | Acc: 65.855,98.501,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.302 | Acc: 65.904,98.499,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.297 | Acc: 66.041,98.521,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.297 | Acc: 66.073,98.535,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.301 | Acc: 65.999,98.508,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.300 | Acc: 66.000,98.518,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.299 | Acc: 66.106,98.502,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.298 | Acc: 66.103,98.515,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.297 | Acc: 66.093,98.530,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.754 | Acc: 59.375,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.052 | Acc: 53.757,68.229,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.062 | Acc: 53.449,67.645,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.071 | Acc: 53.099,67.853,74.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.185 | Acc: 67.969,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.297 | Acc: 67.113,98.698,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.307 | Acc: 66.216,98.514,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.299 | Acc: 66.470,98.566,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.290 | Acc: 66.474,98.457,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.296 | Acc: 66.460,98.368,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.295 | Acc: 66.258,98.347,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.293 | Acc: 66.323,98.399,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.294 | Acc: 66.266,98.462,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.301 | Acc: 66.143,98.450,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.300 | Acc: 66.095,98.438,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.301 | Acc: 66.049,98.430,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.304 | Acc: 65.991,98.434,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.302 | Acc: 66.083,98.446,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.301 | Acc: 66.009,98.496,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.305 | Acc: 65.955,98.471,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.304 | Acc: 65.968,98.479,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.304 | Acc: 65.980,98.502,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.303 | Acc: 66.021,98.505,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.302 | Acc: 66.027,98.483,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.716 | Acc: 57.031,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.034 | Acc: 53.497,68.415,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.046 | Acc: 53.468,67.835,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.055 | Acc: 52.984,67.892,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.499 | Acc: 58.594,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.297 | Acc: 66.183,98.363,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.285 | Acc: 65.892,98.495,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.276 | Acc: 66.086,98.604,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.283 | Acc: 66.001,98.544,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.287 | Acc: 65.610,98.577,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.290 | Acc: 65.780,98.547,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.295 | Acc: 65.703,98.482,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.295 | Acc: 65.785,98.462,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.293 | Acc: 65.836,98.429,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.292 | Acc: 65.893,98.426,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.294 | Acc: 65.830,98.413,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.298 | Acc: 65.722,98.421,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.297 | Acc: 65.847,98.396,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.296 | Acc: 65.884,98.415,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.298 | Acc: 65.843,98.435,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.298 | Acc: 65.883,98.435,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.299 | Acc: 65.879,98.444,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.299 | Acc: 65.891,98.446,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.298 | Acc: 65.928,98.454,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.765 | Acc: 56.250,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.043 | Acc: 53.423,68.378,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.053 | Acc: 53.430,67.702,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.063 | Acc: 52.984,67.815,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.035 | Acc: 71.875,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.257 | Acc: 67.671,98.549,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.281 | Acc: 66.825,98.495,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.274 | Acc: 66.842,98.527,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.290 | Acc: 66.551,98.457,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.285 | Acc: 66.592,98.461,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.277 | Acc: 66.684,98.470,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.280 | Acc: 66.617,98.493,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.284 | Acc: 66.503,98.505,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.283 | Acc: 66.531,98.520,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.283 | Acc: 66.430,98.550,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.283 | Acc: 66.367,98.536,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.287 | Acc: 66.202,98.535,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.289 | Acc: 66.218,98.500,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.292 | Acc: 66.031,98.546,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.294 | Acc: 65.949,98.549,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.294 | Acc: 65.937,98.542,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.298 | Acc: 65.843,98.529,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.295 | Acc: 65.898,98.528,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.296 | Acc: 65.873,98.530,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.741 | Acc: 57.812,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.041 | Acc: 53.720,68.527,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.049 | Acc: 53.659,67.702,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.063 | Acc: 53.035,67.777,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.317 | Acc: 65.625,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.281 | Acc: 67.262,98.549,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.302 | Acc: 66.997,98.285,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.303 | Acc: 66.765,98.425,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.304 | Acc: 66.705,98.302,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.298 | Acc: 66.638,98.321,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.295 | Acc: 66.671,98.373,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.295 | Acc: 66.312,98.438,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.296 | Acc: 66.202,98.457,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.293 | Acc: 66.307,98.489,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.301 | Acc: 66.212,98.438,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.298 | Acc: 66.247,98.452,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.302 | Acc: 66.124,98.460,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.300 | Acc: 66.155,98.461,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.300 | Acc: 66.175,98.463,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.301 | Acc: 66.116,98.469,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.301 | Acc: 66.100,98.452,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.302 | Acc: 66.060,98.454,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.301 | Acc: 66.084,98.457,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.302 | Acc: 66.060,98.425,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.794 | Acc: 57.812,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.035 | Acc: 54.055,68.564,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.051 | Acc: 53.868,67.683,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.062 | Acc: 53.061,68.007,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.498 | Acc: 61.719,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.300 | Acc: 66.295,98.661,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.312 | Acc: 65.434,98.571,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.297 | Acc: 65.753,98.489,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.302 | Acc: 65.702,98.495,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.303 | Acc: 65.942,98.453,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.305 | Acc: 65.890,98.379,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.301 | Acc: 65.991,98.421,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.303 | Acc: 66.033,98.452,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.299 | Acc: 65.996,98.494,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.298 | Acc: 66.014,98.542,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.298 | Acc: 65.950,98.554,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.298 | Acc: 65.926,98.525,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.295 | Acc: 66.041,98.521,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.293 | Acc: 66.087,98.529,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.296 | Acc: 66.012,98.515,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.296 | Acc: 66.000,98.508,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.296 | Acc: 66.049,98.511,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.297 | Acc: 66.041,98.505,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.296 | Acc: 66.105,98.520,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.811 | Acc: 59.375,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.055 | Acc: 54.055,68.601,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.065 | Acc: 53.773,67.988,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.080 | Acc: 53.099,68.020,74.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.323 | Acc: 63.281,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.283 | Acc: 67.262,98.586,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.287 | Acc: 66.921,98.571,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.285 | Acc: 67.059,98.617,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.292 | Acc: 66.667,98.621,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.300 | Acc: 66.375,98.530,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.304 | Acc: 66.264,98.592,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.305 | Acc: 66.196,98.582,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.302 | Acc: 66.013,98.573,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.303 | Acc: 65.957,98.593,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.298 | Acc: 66.095,98.601,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.298 | Acc: 66.134,98.614,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.297 | Acc: 66.114,98.635,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.299 | Acc: 66.053,98.599,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.298 | Acc: 66.017,98.579,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.301 | Acc: 65.960,98.562,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.302 | Acc: 65.937,98.559,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.302 | Acc: 65.930,98.580,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.300 | Acc: 65.999,98.593,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.298 | Acc: 66.127,98.591,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.756 | Acc: 56.250,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.057 | Acc: 53.348,68.229,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.055 | Acc: 53.239,67.702,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.065 | Acc: 53.010,67.725,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.316 | Acc: 67.188,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.295 | Acc: 65.216,98.289,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.308 | Acc: 65.377,98.514,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.303 | Acc: 65.215,98.450,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.291 | Acc: 65.509,98.573,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.297 | Acc: 65.726,98.592,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.293 | Acc: 65.767,98.547,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.293 | Acc: 65.769,98.543,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.291 | Acc: 65.960,98.588,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.298 | Acc: 65.832,98.545,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.301 | Acc: 65.804,98.562,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.301 | Acc: 65.823,98.540,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.301 | Acc: 65.939,98.535,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.300 | Acc: 65.948,98.560,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.299 | Acc: 65.950,98.543,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.300 | Acc: 65.965,98.528,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.299 | Acc: 65.968,98.523,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.298 | Acc: 65.976,98.518,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.298 | Acc: 65.982,98.494,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.297 | Acc: 66.000,98.515,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.796 | Acc: 56.250,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.049 | Acc: 54.055,68.266,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.057 | Acc: 53.773,67.740,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.070 | Acc: 53.163,67.879,74.629,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.322 | Acc: 66.406,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.297 | Acc: 66.369,98.884,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.298 | Acc: 66.673,98.552,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.296 | Acc: 66.855,98.463,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.300 | Acc: 66.368,98.495,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.298 | Acc: 66.460,98.538,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.300 | Acc: 66.232,98.470,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.298 | Acc: 66.251,98.487,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.303 | Acc: 65.979,98.457,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.304 | Acc: 65.957,98.450,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.299 | Acc: 66.088,98.472,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.302 | Acc: 65.911,98.498,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.300 | Acc: 65.917,98.525,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.297 | Acc: 66.026,98.539,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.296 | Acc: 66.078,98.538,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.296 | Acc: 66.077,98.526,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.297 | Acc: 65.983,98.525,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.298 | Acc: 65.886,98.495,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.300 | Acc: 65.850,98.485,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.301 | Acc: 65.793,98.481,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.744 | Acc: 57.031,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.046 | Acc: 53.534,68.192,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.060 | Acc: 53.296,67.607,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.073 | Acc: 52.946,67.802,74.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.250 | Acc: 70.312,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.308 | Acc: 65.439,98.475,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.302 | Acc: 65.739,98.590,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.292 | Acc: 66.291,98.604,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.277 | Acc: 66.715,98.659,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.275 | Acc: 66.747,98.670,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.283 | Acc: 66.665,98.638,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.281 | Acc: 66.744,98.615,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.282 | Acc: 66.605,98.598,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.284 | Acc: 66.583,98.602,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.287 | Acc: 66.375,98.605,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.288 | Acc: 66.371,98.600,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.287 | Acc: 66.341,98.635,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.291 | Acc: 66.236,98.620,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.291 | Acc: 66.173,98.596,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.292 | Acc: 66.170,98.588,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.291 | Acc: 66.180,98.579,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.294 | Acc: 66.145,98.582,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.296 | Acc: 66.077,98.585,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.295 | Acc: 66.125,98.558,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.798 | Acc: 57.812,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.040 | Acc: 53.869,68.490,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.057 | Acc: 53.792,67.797,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.066 | Acc: 53.317,68.071,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.102 | Acc: 72.656,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.284 | Acc: 66.667,98.624,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.274 | Acc: 66.806,98.647,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.267 | Acc: 66.765,98.655,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.262 | Acc: 66.753,98.717,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.266 | Acc: 66.623,98.700,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.265 | Acc: 66.703,98.728,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.268 | Acc: 66.545,98.692,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.273 | Acc: 66.382,98.680,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.282 | Acc: 66.216,98.653,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.285 | Acc: 66.150,98.655,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.284 | Acc: 66.201,98.632,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.286 | Acc: 66.153,98.626,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.288 | Acc: 66.101,98.611,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.290 | Acc: 66.023,98.627,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.289 | Acc: 66.066,98.640,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.288 | Acc: 66.097,98.603,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.287 | Acc: 66.147,98.580,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.289 | Acc: 66.071,98.585,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.289 | Acc: 66.117,98.579,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.765 | Acc: 57.031,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.044 | Acc: 53.274,68.155,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.060 | Acc: 53.125,67.340,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.073 | Acc: 52.818,67.546,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.201 | Acc: 65.625,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.250 | Acc: 67.522,98.698,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.288 | Acc: 66.349,98.418,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.277 | Acc: 66.432,98.489,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.282 | Acc: 66.223,98.524,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.282 | Acc: 66.252,98.584,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.276 | Acc: 66.606,98.580,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.280 | Acc: 66.362,98.559,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.288 | Acc: 66.251,98.462,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.294 | Acc: 66.190,98.459,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.291 | Acc: 66.259,98.472,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.296 | Acc: 66.131,98.469,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.294 | Acc: 66.196,98.450,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.294 | Acc: 66.191,98.479,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.294 | Acc: 66.192,98.474,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.294 | Acc: 66.253,98.476,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.296 | Acc: 66.168,98.464,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.297 | Acc: 66.118,98.451,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.295 | Acc: 66.183,98.446,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.294 | Acc: 66.193,98.444,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.799 | Acc: 55.469,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.058 | Acc: 53.869,68.043,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.066 | Acc: 53.830,67.454,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.078 | Acc: 53.227,67.725,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.278 | Acc: 64.844,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.275 | Acc: 66.890,98.996,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.267 | Acc: 66.616,98.990,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.263 | Acc: 66.931,98.988,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.266 | Acc: 66.705,98.978,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.267 | Acc: 66.754,98.886,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.270 | Acc: 66.600,98.818,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.273 | Acc: 66.500,98.809,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.272 | Acc: 66.426,98.777,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.273 | Acc: 66.424,98.770,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.278 | Acc: 66.255,98.733,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.280 | Acc: 66.233,98.664,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.282 | Acc: 66.179,98.684,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.285 | Acc: 66.122,98.671,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.286 | Acc: 66.073,98.665,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.287 | Acc: 66.139,98.645,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.285 | Acc: 66.192,98.657,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.284 | Acc: 66.209,98.678,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.286 | Acc: 66.103,98.669,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.286 | Acc: 66.138,98.684,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.851 | Acc: 56.250,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.060 | Acc: 53.423,68.341,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.065 | Acc: 53.563,67.473,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.081 | Acc: 52.907,67.725,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.228 | Acc: 67.969,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.275 | Acc: 65.848,98.326,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.261 | Acc: 66.749,98.247,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.275 | Acc: 66.675,98.373,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.277 | Acc: 66.850,98.351,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.287 | Acc: 66.569,98.399,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.294 | Acc: 66.335,98.438,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.295 | Acc: 66.201,98.443,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.291 | Acc: 66.246,98.442,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.290 | Acc: 66.367,98.433,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.289 | Acc: 66.348,98.438,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.292 | Acc: 66.321,98.466,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.294 | Acc: 66.192,98.470,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.294 | Acc: 66.182,98.494,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.295 | Acc: 66.061,98.488,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.297 | Acc: 65.975,98.495,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.296 | Acc: 66.041,98.481,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.295 | Acc: 66.092,98.502,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.291 | Acc: 66.201,98.513,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.293 | Acc: 66.168,98.528,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.841 | Acc: 57.812,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.062 | Acc: 53.646,67.857,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.065 | Acc: 53.563,67.226,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.078 | Acc: 53.061,67.520,74.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.242 | Acc: 71.094,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.308 | Acc: 65.104,98.512,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.296 | Acc: 65.777,98.457,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.302 | Acc: 65.459,98.476,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.304 | Acc: 65.490,98.515,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.298 | Acc: 65.579,98.523,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.295 | Acc: 65.560,98.541,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.301 | Acc: 65.475,98.504,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.298 | Acc: 65.572,98.535,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.299 | Acc: 65.582,98.550,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.302 | Acc: 65.481,98.519,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.303 | Acc: 65.416,98.526,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.303 | Acc: 65.521,98.512,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.299 | Acc: 65.589,98.530,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.295 | Acc: 65.747,98.549,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.295 | Acc: 65.807,98.557,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.293 | Acc: 65.842,98.564,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.291 | Acc: 65.877,98.554,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.289 | Acc: 65.898,98.580,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.290 | Acc: 65.904,98.597,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.781 | Acc: 56.250,71.094,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.047 | Acc: 53.460,68.155,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.051 | Acc: 53.544,67.588,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.064 | Acc: 53.010,67.853,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.344 | Acc: 67.969,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.334 | Acc: 65.848,98.438,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.295 | Acc: 66.940,98.628,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.298 | Acc: 66.688,98.668,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.308 | Acc: 66.155,98.611,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.298 | Acc: 66.313,98.592,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.306 | Acc: 65.987,98.541,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.298 | Acc: 66.190,98.537,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.294 | Acc: 66.241,98.549,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.297 | Acc: 66.165,98.541,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.296 | Acc: 66.220,98.535,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.292 | Acc: 66.300,98.551,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.287 | Acc: 66.296,98.574,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.288 | Acc: 66.248,98.581,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.285 | Acc: 66.245,98.602,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.287 | Acc: 66.219,98.601,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.288 | Acc: 66.263,98.615,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.291 | Acc: 66.120,98.609,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.293 | Acc: 66.077,98.639,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.289 | Acc: 66.177,98.632,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.827 | Acc: 57.812,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.046 | Acc: 53.125,68.155,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.058 | Acc: 53.125,67.607,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.073 | Acc: 52.779,67.789,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.338 | Acc: 66.406,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.280 | Acc: 66.220,98.586,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.284 | Acc: 66.044,98.571,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.276 | Acc: 66.304,98.591,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.290 | Acc: 66.262,98.389,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.292 | Acc: 66.298,98.368,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.292 | Acc: 66.355,98.438,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.293 | Acc: 66.223,98.471,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.294 | Acc: 66.314,98.467,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.298 | Acc: 66.091,98.485,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.297 | Acc: 66.088,98.519,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.295 | Acc: 66.095,98.554,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.293 | Acc: 66.102,98.541,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.290 | Acc: 66.182,98.569,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.288 | Acc: 66.234,98.593,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.290 | Acc: 66.191,98.572,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.289 | Acc: 66.221,98.591,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.290 | Acc: 66.166,98.586,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.291 | Acc: 66.188,98.593,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.290 | Acc: 66.203,98.587,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.777 | Acc: 56.250,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.044 | Acc: 53.869,68.676,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 53.582,67.931,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.066 | Acc: 52.984,68.007,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.211 | Acc: 69.531,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.261 | Acc: 68.043,98.698,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.269 | Acc: 67.340,98.514,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.282 | Acc: 66.419,98.578,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.286 | Acc: 66.155,98.447,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.291 | Acc: 65.996,98.438,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.297 | Acc: 65.702,98.463,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.298 | Acc: 65.752,98.476,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.291 | Acc: 65.877,98.496,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.289 | Acc: 65.927,98.498,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.287 | Acc: 65.959,98.488,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.287 | Acc: 65.996,98.519,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.287 | Acc: 66.085,98.532,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.289 | Acc: 66.068,98.530,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.287 | Acc: 66.078,98.551,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.285 | Acc: 66.222,98.562,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.285 | Acc: 66.156,98.588,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.285 | Acc: 66.159,98.577,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.288 | Acc: 66.079,98.565,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.288 | Acc: 66.134,98.558,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.821 | Acc: 57.031,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.054 | Acc: 53.720,68.192,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.061 | Acc: 53.563,67.778,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.076 | Acc: 53.074,68.020,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 1.178 | Acc: 67.969,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.270 | Acc: 66.778,98.512,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.315 | Acc: 65.149,98.418,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.301 | Acc: 65.702,98.527,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.290 | Acc: 65.943,98.621,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.284 | Acc: 65.981,98.685,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.281 | Acc: 66.019,98.709,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.275 | Acc: 66.174,98.720,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.273 | Acc: 66.353,98.704,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.275 | Acc: 66.333,98.696,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.273 | Acc: 66.383,98.721,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 66.297,98.674,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.278 | Acc: 66.351,98.677,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.279 | Acc: 66.310,98.629,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.279 | Acc: 66.334,98.632,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.282 | Acc: 66.279,98.591,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.281 | Acc: 66.338,98.610,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.283 | Acc: 66.225,98.582,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.285 | Acc: 66.201,98.563,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.286 | Acc: 66.250,98.552,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.752 | Acc: 57.812,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.055 | Acc: 53.609,68.118,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.066 | Acc: 53.277,67.588,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.074 | Acc: 52.869,67.905,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.092 | Acc: 73.438,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.299 | Acc: 64.732,98.549,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.283 | Acc: 65.568,98.609,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.281 | Acc: 66.112,98.578,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.280 | Acc: 66.281,98.573,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.274 | Acc: 66.406,98.600,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.270 | Acc: 66.535,98.560,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.276 | Acc: 66.506,98.554,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.277 | Acc: 66.329,98.559,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.276 | Acc: 66.424,98.558,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.279 | Acc: 66.449,98.531,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.282 | Acc: 66.424,98.515,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.288 | Acc: 66.228,98.519,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.287 | Acc: 66.191,98.542,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.291 | Acc: 66.011,98.532,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.291 | Acc: 66.030,98.539,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.292 | Acc: 65.995,98.566,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.289 | Acc: 66.097,98.575,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.290 | Acc: 66.108,98.576,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.290 | Acc: 66.123,98.581,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.831 | Acc: 56.250,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.066 | Acc: 53.162,67.969,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.073 | Acc: 53.277,67.473,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.085 | Acc: 52.818,67.853,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.344 | Acc: 66.406,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.285 | Acc: 65.848,98.512,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.294 | Acc: 65.606,98.552,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.290 | Acc: 65.830,98.617,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.287 | Acc: 66.078,98.601,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.285 | Acc: 66.282,98.584,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.278 | Acc: 66.477,98.567,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.282 | Acc: 66.373,98.565,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.283 | Acc: 66.309,98.505,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.281 | Acc: 66.272,98.593,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.283 | Acc: 66.227,98.609,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.284 | Acc: 66.191,98.604,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.281 | Acc: 66.296,98.635,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.283 | Acc: 66.236,98.620,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.280 | Acc: 66.328,98.604,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.280 | Acc: 66.362,98.619,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.277 | Acc: 66.404,98.605,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.277 | Acc: 66.411,98.637,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.279 | Acc: 66.339,98.628,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.280 | Acc: 66.298,98.630,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.814 | Acc: 57.812,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.056 | Acc: 53.237,68.266,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.065 | Acc: 53.258,67.626,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.079 | Acc: 52.792,67.969,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.163 | Acc: 71.875,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.261 | Acc: 66.406,98.884,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.283 | Acc: 65.492,98.647,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.279 | Acc: 66.150,98.591,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.288 | Acc: 65.856,98.679,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.287 | Acc: 65.849,98.639,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.287 | Acc: 66.051,98.638,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.286 | Acc: 66.046,98.670,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.286 | Acc: 65.984,98.661,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.283 | Acc: 66.147,98.658,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.278 | Acc: 66.367,98.632,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.280 | Acc: 66.283,98.597,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.280 | Acc: 66.254,98.613,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.280 | Acc: 66.260,98.602,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.279 | Acc: 66.348,98.590,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.275 | Acc: 66.445,98.606,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.278 | Acc: 66.336,98.627,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 66.425,98.639,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.276 | Acc: 66.374,98.639,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.278 | Acc: 66.343,98.659,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.791 | Acc: 57.031,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.063 | Acc: 53.460,68.192,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.074 | Acc: 53.449,67.645,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.086 | Acc: 52.971,67.943,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.404 | Acc: 66.406,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.335 | Acc: 64.509,98.772,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.296 | Acc: 65.701,98.933,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.296 | Acc: 66.124,98.642,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.284 | Acc: 66.165,98.679,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.288 | Acc: 65.826,98.685,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.288 | Acc: 65.870,98.735,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.281 | Acc: 66.041,98.731,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.282 | Acc: 66.067,98.729,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.284 | Acc: 66.104,98.753,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.280 | Acc: 66.259,98.690,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 66.477,98.699,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.278 | Acc: 66.468,98.694,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.276 | Acc: 66.523,98.656,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 66.420,98.613,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.277 | Acc: 66.354,98.643,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.276 | Acc: 66.338,98.661,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.278 | Acc: 66.321,98.671,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.277 | Acc: 66.413,98.667,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.276 | Acc: 66.447,98.665,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.770 | Acc: 57.031,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.045 | Acc: 53.497,68.229,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.058 | Acc: 53.449,67.588,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.072 | Acc: 52.971,67.777,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.473 | Acc: 55.469,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.304 | Acc: 65.625,98.586,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.305 | Acc: 65.892,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.295 | Acc: 66.253,98.502,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.282 | Acc: 66.570,98.650,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.282 | Acc: 66.638,98.654,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.285 | Acc: 66.464,98.644,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.282 | Acc: 66.561,98.654,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.283 | Acc: 66.484,98.632,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.281 | Acc: 66.454,98.606,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.279 | Acc: 66.620,98.605,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 66.615,98.600,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.273 | Acc: 66.760,98.616,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.272 | Acc: 66.777,98.611,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.271 | Acc: 66.795,98.618,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.272 | Acc: 66.692,98.601,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.276 | Acc: 66.543,98.620,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.275 | Acc: 66.573,98.625,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.273 | Acc: 66.662,98.624,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.274 | Acc: 66.566,98.612,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.818 | Acc: 57.031,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.081 | Acc: 53.646,68.118,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.085 | Acc: 53.296,67.607,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.091 | Acc: 52.728,67.764,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.532 | Acc: 60.938,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.304 | Acc: 65.699,98.586,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.302 | Acc: 65.873,98.666,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.304 | Acc: 66.009,98.617,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.295 | Acc: 66.127,98.640,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.295 | Acc: 66.275,98.639,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.294 | Acc: 66.213,98.696,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.286 | Acc: 66.318,98.737,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.281 | Acc: 66.367,98.738,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.281 | Acc: 66.441,98.735,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.278 | Acc: 66.496,98.733,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.280 | Acc: 66.424,98.696,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.285 | Acc: 66.358,98.690,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.281 | Acc: 66.556,98.689,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.281 | Acc: 66.526,98.710,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.279 | Acc: 66.526,98.723,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.276 | Acc: 66.564,98.722,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 66.622,98.717,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.276 | Acc: 66.633,98.723,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.274 | Acc: 66.671,98.735,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.791 | Acc: 57.812,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.055 | Acc: 53.199,68.080,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.063 | Acc: 53.373,67.473,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.074 | Acc: 52.984,67.828,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.471 | Acc: 63.281,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.285 | Acc: 66.741,98.847,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.276 | Acc: 66.482,98.895,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.280 | Acc: 66.265,98.873,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.273 | Acc: 66.676,98.872,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.266 | Acc: 66.793,98.886,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.264 | Acc: 66.826,98.883,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.271 | Acc: 66.639,98.836,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.272 | Acc: 66.571,98.840,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.272 | Acc: 66.566,98.817,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.271 | Acc: 66.535,98.811,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.270 | Acc: 66.558,98.784,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.273 | Acc: 66.465,98.755,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.274 | Acc: 66.508,98.731,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.275 | Acc: 66.481,98.741,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.274 | Acc: 66.518,98.762,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.273 | Acc: 66.599,98.742,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.271 | Acc: 66.645,98.740,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.270 | Acc: 66.672,98.745,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.272 | Acc: 66.636,98.741,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.808 | Acc: 57.031,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.055 | Acc: 53.274,67.969,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.065 | Acc: 53.430,67.378,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.077 | Acc: 52.984,67.674,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.208 | Acc: 69.531,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.256 | Acc: 67.411,98.400,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.270 | Acc: 67.035,98.590,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.291 | Acc: 66.586,98.540,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.278 | Acc: 66.956,98.553,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.279 | Acc: 66.925,98.608,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.274 | Acc: 67.116,98.612,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.275 | Acc: 67.049,98.604,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.272 | Acc: 67.212,98.598,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.274 | Acc: 67.049,98.632,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.269 | Acc: 67.141,98.663,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.269 | Acc: 67.120,98.692,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.271 | Acc: 67.006,98.710,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.270 | Acc: 67.032,98.710,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.270 | Acc: 67.001,98.688,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.270 | Acc: 66.956,98.702,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.270 | Acc: 66.852,98.700,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.270 | Acc: 66.812,98.680,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.272 | Acc: 66.720,98.658,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.273 | Acc: 66.699,98.667,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.784 | Acc: 57.031,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.049 | Acc: 53.460,68.043,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.061 | Acc: 53.563,67.511,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.072 | Acc: 53.125,67.777,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 1.193 | Acc: 67.188,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.250 | Acc: 67.411,98.549,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.261 | Acc: 66.654,98.666,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.260 | Acc: 66.688,98.758,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.272 | Acc: 66.252,98.775,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.265 | Acc: 66.654,98.786,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.268 | Acc: 66.632,98.793,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.267 | Acc: 66.617,98.798,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.267 | Acc: 66.683,98.792,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.270 | Acc: 66.579,98.787,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.270 | Acc: 66.589,98.776,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.273 | Acc: 66.480,98.749,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.272 | Acc: 66.448,98.768,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.276 | Acc: 66.403,98.764,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 66.426,98.757,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 66.526,98.767,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.275 | Acc: 66.555,98.781,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.275 | Acc: 66.654,98.735,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.274 | Acc: 66.640,98.760,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.273 | Acc: 66.628,98.764,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.781 | Acc: 57.031,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.054 | Acc: 53.423,68.341,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.069 | Acc: 53.582,67.511,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.081 | Acc: 53.048,67.777,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.128 | Acc: 68.750,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.260 | Acc: 66.778,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.254 | Acc: 67.283,98.533,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.254 | Acc: 67.264,98.527,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.275 | Acc: 66.782,98.553,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.290 | Acc: 66.429,98.492,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.287 | Acc: 66.535,98.509,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.290 | Acc: 66.517,98.521,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.285 | Acc: 66.586,98.559,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.281 | Acc: 66.657,98.610,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.283 | Acc: 66.566,98.620,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.279 | Acc: 66.579,98.660,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.281 | Acc: 66.481,98.651,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.279 | Acc: 66.574,98.686,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.279 | Acc: 66.604,98.693,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.278 | Acc: 66.559,98.697,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.277 | Acc: 66.620,98.686,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 66.610,98.692,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.276 | Acc: 66.605,98.695,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.277 | Acc: 66.652,98.677,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.799 | Acc: 57.031,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.060 | Acc: 53.125,68.155,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.066 | Acc: 53.296,67.569,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.077 | Acc: 52.933,67.892,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.276 | Acc: 68.750,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.262 | Acc: 67.336,98.772,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.246 | Acc: 67.073,98.857,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.262 | Acc: 66.983,98.783,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.262 | Acc: 66.917,98.785,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.271 | Acc: 66.422,98.801,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.270 | Acc: 66.380,98.793,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.273 | Acc: 66.295,98.787,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.273 | Acc: 66.241,98.734,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.272 | Acc: 66.350,98.731,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.269 | Acc: 66.515,98.752,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.268 | Acc: 66.576,98.784,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.270 | Acc: 66.526,98.752,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.269 | Acc: 66.577,98.752,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.269 | Acc: 66.601,98.741,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.271 | Acc: 66.585,98.739,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.270 | Acc: 66.560,98.759,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.271 | Acc: 66.498,98.779,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.271 | Acc: 66.501,98.786,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.273 | Acc: 66.511,98.774,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.754 | Acc: 57.031,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.057 | Acc: 52.976,67.634,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.063 | Acc: 53.201,67.378,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.071 | Acc: 52.933,67.738,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.236 | Acc: 70.312,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.299 | Acc: 65.699,98.884,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.270 | Acc: 66.521,98.723,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.271 | Acc: 66.419,98.796,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.266 | Acc: 66.406,98.756,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.275 | Acc: 66.174,98.778,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.282 | Acc: 66.064,98.709,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.273 | Acc: 66.207,98.709,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.276 | Acc: 66.178,98.704,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.274 | Acc: 66.238,98.714,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.273 | Acc: 66.325,98.733,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.273 | Acc: 66.357,98.720,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.277 | Acc: 66.247,98.710,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.278 | Acc: 66.206,98.695,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.277 | Acc: 66.234,98.674,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.275 | Acc: 66.326,98.679,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.274 | Acc: 66.387,98.676,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.275 | Acc: 66.370,98.667,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.274 | Acc: 66.356,98.673,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.275 | Acc: 66.330,98.682,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.765 | Acc: 57.812,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.051 | Acc: 53.534,68.229,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.057 | Acc: 53.544,67.588,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.068 | Acc: 53.087,67.687,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.259 | Acc: 67.969,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.249 | Acc: 67.671,99.070,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.270 | Acc: 67.168,98.914,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.279 | Acc: 66.534,98.783,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.274 | Acc: 66.387,98.765,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.270 | Acc: 66.569,98.623,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.271 | Acc: 66.522,98.683,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.277 | Acc: 66.456,98.698,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.269 | Acc: 66.571,98.709,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.271 | Acc: 66.493,98.714,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.271 | Acc: 66.484,98.745,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.272 | Acc: 66.473,98.734,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.274 | Acc: 66.380,98.742,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.271 | Acc: 66.391,98.728,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.272 | Acc: 66.351,98.724,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.268 | Acc: 66.469,98.710,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.269 | Acc: 66.431,98.730,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.271 | Acc: 66.457,98.731,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.272 | Acc: 66.447,98.721,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.271 | Acc: 66.474,98.716,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.765 | Acc: 57.812,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.059 | Acc: 53.460,68.192,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.067 | Acc: 53.430,67.702,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.082 | Acc: 52.882,67.905,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.309 | Acc: 66.406,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.265 | Acc: 66.964,98.772,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.268 | Acc: 66.883,98.628,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.264 | Acc: 66.790,98.668,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.278 | Acc: 66.570,98.630,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.287 | Acc: 66.190,98.623,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.292 | Acc: 65.916,98.586,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.292 | Acc: 65.952,98.643,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.290 | Acc: 66.071,98.636,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.285 | Acc: 66.307,98.653,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.283 | Acc: 66.301,98.651,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.278 | Acc: 66.392,98.674,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.280 | Acc: 66.432,98.671,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.278 | Acc: 66.478,98.656,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.277 | Acc: 66.565,98.627,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.275 | Acc: 66.580,98.640,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.274 | Acc: 66.521,98.649,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.274 | Acc: 66.601,98.667,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.273 | Acc: 66.610,98.697,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.275 | Acc: 66.540,98.677,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.807 | Acc: 57.812,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.055 | Acc: 53.720,68.638,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.066 | Acc: 53.659,67.778,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.077 | Acc: 53.061,67.905,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.112 | Acc: 70.312,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.288 | Acc: 65.737,98.438,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.294 | Acc: 65.739,98.742,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.285 | Acc: 65.766,98.668,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.279 | Acc: 65.992,98.679,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.268 | Acc: 66.375,98.685,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.263 | Acc: 66.535,98.663,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.268 | Acc: 66.484,98.654,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.273 | Acc: 66.358,98.700,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.275 | Acc: 66.182,98.714,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.277 | Acc: 66.150,98.671,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.275 | Acc: 66.123,98.724,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.272 | Acc: 66.189,98.720,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.273 | Acc: 66.203,98.737,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.273 | Acc: 66.228,98.732,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.273 | Acc: 66.204,98.775,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.273 | Acc: 66.248,98.781,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 66.168,98.745,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.276 | Acc: 66.157,98.745,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.277 | Acc: 66.156,98.749,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.814 | Acc: 57.031,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.052 | Acc: 53.832,68.564,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.065 | Acc: 53.716,67.759,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.077 | Acc: 53.035,67.943,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.390 | Acc: 58.594,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.254 | Acc: 66.778,98.847,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.275 | Acc: 66.311,98.761,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.285 | Acc: 66.163,98.540,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.288 | Acc: 66.107,98.563,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.287 | Acc: 66.182,98.554,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.282 | Acc: 66.593,98.592,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.278 | Acc: 66.467,98.648,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.277 | Acc: 66.537,98.690,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.273 | Acc: 66.695,98.671,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.273 | Acc: 66.706,98.694,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.274 | Acc: 66.756,98.681,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.274 | Acc: 66.620,98.671,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.275 | Acc: 66.535,98.650,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 66.568,98.635,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.275 | Acc: 66.596,98.606,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.272 | Acc: 66.625,98.632,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.272 | Acc: 66.601,98.632,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.271 | Acc: 66.636,98.632,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.272 | Acc: 66.609,98.638,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.781 | Acc: 57.031,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.059 | Acc: 53.571,68.155,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.064 | Acc: 53.601,67.416,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.075 | Acc: 53.176,67.764,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.385 | Acc: 63.281,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.276 | Acc: 66.332,98.847,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.282 | Acc: 66.406,98.742,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.257 | Acc: 66.931,98.873,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.266 | Acc: 66.763,98.958,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.271 | Acc: 66.662,99.002,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.271 | Acc: 66.710,98.928,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.278 | Acc: 66.550,98.886,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.278 | Acc: 66.557,98.831,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.279 | Acc: 66.600,98.796,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.276 | Acc: 66.620,98.764,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.278 | Acc: 66.615,98.752,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.279 | Acc: 66.539,98.736,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.281 | Acc: 66.460,98.728,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.279 | Acc: 66.512,98.691,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.278 | Acc: 66.539,98.648,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.276 | Acc: 66.540,98.644,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.272 | Acc: 66.612,98.680,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.273 | Acc: 66.588,98.682,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.272 | Acc: 66.554,98.679,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.816 | Acc: 57.031,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.047 | Acc: 53.571,68.378,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.066 | Acc: 53.563,67.702,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.080 | Acc: 53.023,67.892,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.098 | Acc: 71.094,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.266 | Acc: 66.853,98.512,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.264 | Acc: 66.635,98.857,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.279 | Acc: 66.662,98.847,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.273 | Acc: 66.889,98.814,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.266 | Acc: 67.002,98.832,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.260 | Acc: 67.084,98.851,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.263 | Acc: 67.104,98.787,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.263 | Acc: 66.930,98.767,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.264 | Acc: 66.976,98.778,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.263 | Acc: 67.083,98.807,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.262 | Acc: 67.195,98.787,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.271 | Acc: 66.922,98.749,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.272 | Acc: 66.894,98.746,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.271 | Acc: 66.909,98.743,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.269 | Acc: 66.956,98.757,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.269 | Acc: 66.954,98.781,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.268 | Acc: 66.974,98.781,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.265 | Acc: 67.025,98.779,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.267 | Acc: 66.923,98.776,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.803 | Acc: 58.594,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.058 | Acc: 53.981,68.006,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.067 | Acc: 53.887,67.435,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.079 | Acc: 53.266,67.764,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.439 | Acc: 59.375,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.265 | Acc: 66.518,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.264 | Acc: 66.597,98.571,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.274 | Acc: 66.355,98.566,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.275 | Acc: 66.078,98.621,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.271 | Acc: 66.306,98.577,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.274 | Acc: 66.348,98.534,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.273 | Acc: 66.495,98.587,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.275 | Acc: 66.372,98.598,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.273 | Acc: 66.493,98.632,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.276 | Acc: 66.383,98.620,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.276 | Acc: 66.371,98.632,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.275 | Acc: 66.335,98.664,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.278 | Acc: 66.313,98.689,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 66.462,98.702,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.274 | Acc: 66.632,98.720,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.274 | Acc: 66.613,98.705,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.273 | Acc: 66.564,98.696,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.272 | Acc: 66.618,98.702,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.273 | Acc: 66.572,98.710,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.798 | Acc: 57.031,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.050 | Acc: 53.423,68.043,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.058 | Acc: 53.335,67.607,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.068 | Acc: 52.959,67.892,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.286 | Acc: 65.625,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.268 | Acc: 66.927,98.661,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.296 | Acc: 66.444,98.685,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.288 | Acc: 66.688,98.642,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.281 | Acc: 66.522,98.688,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.287 | Acc: 66.491,98.708,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.282 | Acc: 66.684,98.618,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.272 | Acc: 66.755,98.631,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.275 | Acc: 66.775,98.573,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.274 | Acc: 66.803,98.563,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.272 | Acc: 66.807,98.609,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.269 | Acc: 66.862,98.625,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.272 | Acc: 66.776,98.596,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.271 | Acc: 66.744,98.605,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.271 | Acc: 66.709,98.632,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.268 | Acc: 66.814,98.663,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.270 | Acc: 66.783,98.659,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.271 | Acc: 66.766,98.671,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.269 | Acc: 66.804,98.654,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.271 | Acc: 66.714,98.643,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.800 | Acc: 57.031,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.054 | Acc: 53.497,68.452,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.064 | Acc: 53.639,67.588,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.078 | Acc: 53.266,67.815,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.371 | Acc: 67.188,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.270 | Acc: 66.295,98.884,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.282 | Acc: 66.597,98.780,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.267 | Acc: 66.867,98.809,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.265 | Acc: 66.831,98.717,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.271 | Acc: 66.801,98.801,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.273 | Acc: 66.606,98.838,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.270 | Acc: 66.645,98.770,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.267 | Acc: 66.746,98.787,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.264 | Acc: 66.842,98.804,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.264 | Acc: 66.818,98.822,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.265 | Acc: 66.820,98.823,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.265 | Acc: 66.821,98.804,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.265 | Acc: 66.774,98.797,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.269 | Acc: 66.673,98.813,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.269 | Acc: 66.661,98.809,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.269 | Acc: 66.662,98.829,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.270 | Acc: 66.638,98.832,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.272 | Acc: 66.595,98.834,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.272 | Acc: 66.658,98.837,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.771 | Acc: 57.031,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.055 | Acc: 53.609,68.229,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.064 | Acc: 53.563,67.778,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.077 | Acc: 53.074,67.892,74.475,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 1.384 | Acc: 66.406,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.290 | Acc: 66.555,98.363,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.273 | Acc: 67.130,98.457,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.268 | Acc: 66.944,98.502,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.268 | Acc: 66.898,98.553,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.267 | Acc: 67.033,98.639,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.266 | Acc: 66.987,98.670,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.268 | Acc: 66.905,98.698,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.266 | Acc: 66.998,98.690,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.268 | Acc: 66.976,98.727,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.268 | Acc: 66.954,98.710,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.274 | Acc: 66.806,98.696,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.273 | Acc: 66.834,98.664,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.269 | Acc: 66.975,98.668,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.272 | Acc: 66.887,98.668,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.274 | Acc: 66.775,98.671,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.272 | Acc: 66.740,98.693,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.271 | Acc: 66.828,98.703,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.271 | Acc: 66.804,98.719,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.269 | Acc: 66.818,98.729,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.804 | Acc: 57.031,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.064 | Acc: 53.497,67.857,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.066 | Acc: 53.754,67.492,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.080 | Acc: 53.227,67.661,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.166 | Acc: 67.188,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.209 | Acc: 67.225,98.735,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.238 | Acc: 66.482,98.761,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.256 | Acc: 66.317,98.809,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.266 | Acc: 66.300,98.708,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.261 | Acc: 66.383,98.793,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.263 | Acc: 66.445,98.773,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.263 | Acc: 66.789,98.803,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.267 | Acc: 66.634,98.767,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.269 | Acc: 66.622,98.722,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.270 | Acc: 66.558,98.729,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.268 | Acc: 66.587,98.780,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.270 | Acc: 66.526,98.788,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.268 | Acc: 66.580,98.794,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.267 | Acc: 66.665,98.771,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.269 | Acc: 66.554,98.762,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.269 | Acc: 66.599,98.761,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.269 | Acc: 66.585,98.761,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.271 | Acc: 66.530,98.751,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.272 | Acc: 66.478,98.761,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.831 | Acc: 57.031,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.055 | Acc: 53.571,68.118,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.065 | Acc: 53.716,67.626,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.076 | Acc: 53.163,67.841,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.272 | Acc: 64.844,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.273 | Acc: 66.629,99.070,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.268 | Acc: 66.502,98.990,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.273 | Acc: 66.265,98.899,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.270 | Acc: 66.551,98.717,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.271 | Acc: 66.677,98.716,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.271 | Acc: 66.742,98.702,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.268 | Acc: 66.822,98.715,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.272 | Acc: 66.770,98.709,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.273 | Acc: 66.622,98.718,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.273 | Acc: 66.566,98.729,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.274 | Acc: 66.435,98.727,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.274 | Acc: 66.380,98.732,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.274 | Acc: 66.340,98.731,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.270 | Acc: 66.506,98.732,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.269 | Acc: 66.531,98.718,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.270 | Acc: 66.496,98.717,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.270 | Acc: 66.473,98.733,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.270 | Acc: 66.504,98.727,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.268 | Acc: 66.562,98.716,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.794 | Acc: 57.031,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.056 | Acc: 53.757,68.266,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.064 | Acc: 53.601,67.702,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.073 | Acc: 53.087,67.892,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.112 | Acc: 70.312,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.256 | Acc: 67.113,98.772,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.273 | Acc: 66.883,98.838,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.280 | Acc: 66.176,98.706,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.273 | Acc: 66.397,98.669,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.276 | Acc: 66.306,98.631,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.267 | Acc: 66.426,98.683,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.271 | Acc: 66.478,98.665,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.269 | Acc: 66.620,98.666,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.272 | Acc: 66.648,98.692,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.273 | Acc: 66.639,98.721,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.272 | Acc: 66.650,98.717,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.271 | Acc: 66.669,98.723,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.268 | Acc: 66.807,98.722,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.270 | Acc: 66.740,98.704,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.270 | Acc: 66.697,98.720,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.269 | Acc: 66.691,98.737,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.268 | Acc: 66.743,98.719,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.270 | Acc: 66.642,98.719,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.271 | Acc: 66.630,98.718,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.796 | Acc: 57.031,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.060 | Acc: 53.534,67.857,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.065 | Acc: 53.620,67.378,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.075 | Acc: 53.125,67.725,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.126 | Acc: 73.438,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.256 | Acc: 67.188,98.810,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.262 | Acc: 66.864,98.800,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.277 | Acc: 66.624,98.694,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.273 | Acc: 66.618,98.736,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.271 | Acc: 66.453,98.793,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.269 | Acc: 66.290,98.812,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.267 | Acc: 66.417,98.798,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.268 | Acc: 66.484,98.748,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.271 | Acc: 66.475,98.744,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.271 | Acc: 66.546,98.741,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.276 | Acc: 66.456,98.710,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.278 | Acc: 66.290,98.713,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.279 | Acc: 66.340,98.713,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.279 | Acc: 66.392,98.691,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.277 | Acc: 66.432,98.700,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.277 | Acc: 66.450,98.708,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.277 | Acc: 66.381,98.708,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.276 | Acc: 66.398,98.712,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.276 | Acc: 66.375,98.714,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.772 | Acc: 57.031,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.055 | Acc: 53.348,68.043,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.056 | Acc: 53.582,67.473,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.067 | Acc: 53.138,67.777,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.176 | Acc: 68.750,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.283 | Acc: 66.406,98.363,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.267 | Acc: 66.940,98.571,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.261 | Acc: 66.970,98.553,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.249 | Acc: 67.332,98.582,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.255 | Acc: 67.041,98.716,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.249 | Acc: 67.149,98.793,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.257 | Acc: 67.038,98.775,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.257 | Acc: 67.100,98.797,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.261 | Acc: 66.937,98.783,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.262 | Acc: 66.900,98.768,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.262 | Acc: 66.894,98.777,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.263 | Acc: 66.870,98.720,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.265 | Acc: 66.861,98.707,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.266 | Acc: 66.829,98.718,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.267 | Acc: 66.809,98.684,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.272 | Acc: 66.645,98.683,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.271 | Acc: 66.617,98.694,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.271 | Acc: 66.605,98.699,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.268 | Acc: 66.708,98.704,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.799 | Acc: 57.031,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.038 | Acc: 53.571,68.415,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.052 | Acc: 53.430,67.721,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.065 | Acc: 52.997,67.879,74.475,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.232 | Acc: 67.969,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.300 | Acc: 65.179,98.884,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.279 | Acc: 66.197,98.876,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.270 | Acc: 66.189,98.899,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.253 | Acc: 66.522,98.891,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.261 | Acc: 66.329,98.824,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.265 | Acc: 66.161,98.806,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.267 | Acc: 66.251,98.787,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.266 | Acc: 66.464,98.806,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.266 | Acc: 66.462,98.822,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.264 | Acc: 66.488,98.838,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.265 | Acc: 66.530,98.844,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.267 | Acc: 66.526,98.862,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.268 | Acc: 66.454,98.830,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.268 | Acc: 66.456,98.796,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.268 | Acc: 66.385,98.780,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.268 | Acc: 66.384,98.786,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.267 | Acc: 66.445,98.788,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.268 | Acc: 66.452,98.751,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.268 | Acc: 66.517,98.745,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.817 | Acc: 57.031,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.049 | Acc: 53.683,68.266,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.064 | Acc: 53.468,67.397,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.079 | Acc: 52.894,67.623,74.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.280 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.285 | Acc: 66.034,98.772,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.274 | Acc: 66.216,98.876,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.280 | Acc: 66.381,98.847,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.281 | Acc: 66.319,98.814,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.283 | Acc: 66.252,98.809,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.276 | Acc: 66.497,98.786,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.284 | Acc: 66.257,98.715,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.284 | Acc: 66.309,98.695,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.279 | Acc: 66.350,98.722,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.273 | Acc: 66.515,98.733,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.269 | Acc: 66.647,98.706,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.267 | Acc: 66.623,98.700,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.271 | Acc: 66.505,98.659,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.271 | Acc: 66.470,98.677,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.273 | Acc: 66.422,98.669,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.274 | Acc: 66.397,98.657,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 66.308,98.653,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.278 | Acc: 66.222,98.667,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.276 | Acc: 66.355,98.663,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.812 | Acc: 56.250,68.750,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.056 | Acc: 53.534,68.192,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.066 | Acc: 53.373,67.645,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.082 | Acc: 52.869,67.853,74.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.176 | Acc: 67.969,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.329 | Acc: 65.141,98.661,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.312 | Acc: 66.349,98.418,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.280 | Acc: 66.778,98.553,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.279 | Acc: 66.474,98.601,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.277 | Acc: 66.352,98.600,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.273 | Acc: 66.555,98.592,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.274 | Acc: 66.500,98.637,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.271 | Acc: 66.668,98.656,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.267 | Acc: 66.842,98.627,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.269 | Acc: 66.799,98.644,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.265 | Acc: 66.859,98.653,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.265 | Acc: 66.782,98.648,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.265 | Acc: 66.807,98.683,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.266 | Acc: 66.762,98.668,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.266 | Acc: 66.788,98.681,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.263 | Acc: 66.915,98.698,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.264 | Acc: 66.828,98.696,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.264 | Acc: 66.850,98.680,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.264 | Acc: 66.802,98.712,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.788 | Acc: 56.250,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.060 | Acc: 53.571,68.118,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.069 | Acc: 53.449,67.664,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.078 | Acc: 53.099,67.879,74.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.103 | Acc: 70.312,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.262 | Acc: 66.555,98.512,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.286 | Acc: 66.063,98.666,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.281 | Acc: 65.920,98.694,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.293 | Acc: 65.779,98.736,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.294 | Acc: 65.780,98.747,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.296 | Acc: 65.631,98.696,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.288 | Acc: 65.858,98.698,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.289 | Acc: 65.897,98.709,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.285 | Acc: 65.927,98.731,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.279 | Acc: 66.049,98.768,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.274 | Acc: 66.155,98.770,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.273 | Acc: 66.221,98.781,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.275 | Acc: 66.161,98.773,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.275 | Acc: 66.251,98.768,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 66.199,98.767,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.277 | Acc: 66.192,98.781,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.278 | Acc: 66.154,98.751,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.275 | Acc: 66.237,98.758,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.274 | Acc: 66.337,98.761,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.774 | Acc: 57.812,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.060 | Acc: 53.423,68.266,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.069 | Acc: 53.468,67.569,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.075 | Acc: 52.933,67.892,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.411 | Acc: 63.281,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.263 | Acc: 66.220,98.624,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.281 | Acc: 66.559,98.704,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.280 | Acc: 66.829,98.642,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.284 | Acc: 66.599,98.621,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.278 | Acc: 66.484,98.700,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.277 | Acc: 66.484,98.676,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.275 | Acc: 66.550,98.709,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.275 | Acc: 66.406,98.714,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.277 | Acc: 66.333,98.705,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.279 | Acc: 66.387,98.702,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.278 | Acc: 66.445,98.720,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.276 | Acc: 66.458,98.736,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.275 | Acc: 66.583,98.728,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 66.479,98.724,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 66.427,98.687,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.275 | Acc: 66.484,98.666,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.274 | Acc: 66.489,98.678,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.273 | Acc: 66.499,98.689,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.272 | Acc: 66.499,98.696,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.803 | Acc: 57.812,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.045 | Acc: 53.460,68.378,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.055 | Acc: 53.468,67.626,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.067 | Acc: 52.882,67.879,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.108 | Acc: 70.312,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.272 | Acc: 66.555,98.512,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.251 | Acc: 67.740,98.647,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.271 | Acc: 67.059,98.655,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.263 | Acc: 66.956,98.708,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.264 | Acc: 67.010,98.724,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.270 | Acc: 66.865,98.709,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.266 | Acc: 66.971,98.659,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.271 | Acc: 66.659,98.666,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.269 | Acc: 66.795,98.679,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.271 | Acc: 66.764,98.659,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.272 | Acc: 66.724,98.671,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.276 | Acc: 66.643,98.655,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.278 | Acc: 66.592,98.656,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.275 | Acc: 66.684,98.660,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 66.650,98.666,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.274 | Acc: 66.635,98.678,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.273 | Acc: 66.656,98.694,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.272 | Acc: 66.657,98.719,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.269 | Acc: 66.716,98.727,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.778 | Acc: 56.250,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.054 | Acc: 53.497,68.266,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.067 | Acc: 53.411,67.626,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.077 | Acc: 52.843,67.841,74.475,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.317 | Acc: 67.188,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.221 | Acc: 68.527,99.107,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.238 | Acc: 67.530,99.104,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.250 | Acc: 67.226,98.950,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.248 | Acc: 67.351,98.872,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.258 | Acc: 66.878,98.863,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.258 | Acc: 66.748,98.864,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.262 | Acc: 66.722,98.842,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.264 | Acc: 66.576,98.801,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.268 | Acc: 66.454,98.791,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.268 | Acc: 66.476,98.776,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.269 | Acc: 66.431,98.763,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.269 | Acc: 66.523,98.739,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.267 | Acc: 66.538,98.761,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.267 | Acc: 66.570,98.746,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.265 | Acc: 66.679,98.744,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.265 | Acc: 66.672,98.732,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.266 | Acc: 66.677,98.719,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.268 | Acc: 66.620,98.719,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.268 | Acc: 66.611,98.698,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.817 | Acc: 57.812,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.070 | Acc: 53.497,68.006,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.077 | Acc: 53.430,67.511,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.091 | Acc: 52.933,67.687,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.080 | Acc: 71.094,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.235 | Acc: 67.634,98.772,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.246 | Acc: 67.435,98.685,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.251 | Acc: 67.123,98.796,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.248 | Acc: 67.120,98.746,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.248 | Acc: 66.932,98.786,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.254 | Acc: 66.832,98.689,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.255 | Acc: 66.905,98.737,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.260 | Acc: 66.824,98.734,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.264 | Acc: 66.864,98.714,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.269 | Acc: 66.639,98.690,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.267 | Acc: 66.742,98.685,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.266 | Acc: 66.831,98.668,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.267 | Acc: 66.843,98.665,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.268 | Acc: 66.801,98.660,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.268 | Acc: 66.767,98.669,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.269 | Acc: 66.703,98.676,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.270 | Acc: 66.690,98.694,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.272 | Acc: 66.608,98.699,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.270 | Acc: 66.585,98.706,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.813 | Acc: 57.812,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.059 | Acc: 53.757,68.415,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.069 | Acc: 53.525,67.530,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.079 | Acc: 53.048,67.853,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.298 | Acc: 60.938,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.240 | Acc: 66.518,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.239 | Acc: 67.035,98.819,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.259 | Acc: 66.893,98.860,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.264 | Acc: 66.406,98.794,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.260 | Acc: 66.692,98.786,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.264 | Acc: 66.723,98.741,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.262 | Acc: 66.705,98.698,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.264 | Acc: 66.693,98.704,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.269 | Acc: 66.583,98.658,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.272 | Acc: 66.441,98.671,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.274 | Acc: 66.456,98.657,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.274 | Acc: 66.387,98.638,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.276 | Acc: 66.340,98.638,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.275 | Acc: 66.331,98.640,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.272 | Acc: 66.466,98.666,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.270 | Acc: 66.543,98.674,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.272 | Acc: 66.475,98.662,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.272 | Acc: 66.497,98.647,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.272 | Acc: 66.519,98.653,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.815 | Acc: 56.250,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.058 | Acc: 53.423,68.118,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.071 | Acc: 53.411,67.511,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.086 | Acc: 52.984,67.853,74.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.167 | Acc: 71.094,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.257 | Acc: 66.518,98.698,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.269 | Acc: 66.692,98.742,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.275 | Acc: 66.816,98.719,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.270 | Acc: 66.618,98.794,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.267 | Acc: 66.723,98.716,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.264 | Acc: 66.755,98.702,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.259 | Acc: 66.783,98.731,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.268 | Acc: 66.508,98.724,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.271 | Acc: 66.484,98.709,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.272 | Acc: 66.383,98.690,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 66.226,98.685,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.277 | Acc: 66.234,98.707,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.272 | Acc: 66.418,98.704,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.272 | Acc: 66.437,98.718,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.272 | Acc: 66.479,98.726,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.276 | Acc: 66.450,98.715,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 66.406,98.696,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.276 | Acc: 66.413,98.682,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.273 | Acc: 66.494,98.682,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.814 | Acc: 57.812,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.062 | Acc: 53.832,67.969,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.071 | Acc: 53.582,67.454,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.084 | Acc: 52.997,67.738,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.599 | Acc: 57.812,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.303 | Acc: 65.737,98.921,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.283 | Acc: 66.159,98.857,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.261 | Acc: 66.778,98.899,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.251 | Acc: 66.802,98.910,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.259 | Acc: 66.600,98.894,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.267 | Acc: 66.342,98.831,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.274 | Acc: 66.295,98.848,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.270 | Acc: 66.523,98.845,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.267 | Acc: 66.626,98.843,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.266 | Acc: 66.628,98.865,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.265 | Acc: 66.703,98.855,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.267 | Acc: 66.559,98.839,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.266 | Acc: 66.523,98.857,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.265 | Acc: 66.601,98.857,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.266 | Acc: 66.539,98.840,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.268 | Acc: 66.477,98.800,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.269 | Acc: 66.461,98.786,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.269 | Acc: 66.441,98.795,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.269 | Acc: 66.423,98.802,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.807 | Acc: 57.812,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.068 | Acc: 53.720,68.118,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.074 | Acc: 53.601,67.511,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.082 | Acc: 53.151,67.815,74.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 1.204 | Acc: 63.281,96.875,100.000,% | Adaptive Acc: 87.500% | clf_exit: 0.586 0.398 0.016
Batch: 20 | Loss: 1.261 | Acc: 66.295,98.698,99.963,% | Adaptive Acc: 92.076% | clf_exit: 0.562 0.424 0.014
Batch: 40 | Loss: 1.281 | Acc: 66.540,98.704,99.981,% | Adaptive Acc: 92.264% | clf_exit: 0.562 0.424 0.014
Batch: 60 | Loss: 1.275 | Acc: 66.560,98.783,99.974,% | Adaptive Acc: 92.047% | clf_exit: 0.563 0.423 0.014
Batch: 80 | Loss: 1.267 | Acc: 67.043,98.804,99.981,% | Adaptive Acc: 92.245% | clf_exit: 0.565 0.420 0.015
Batch: 100 | Loss: 1.272 | Acc: 66.886,98.863,99.977,% | Adaptive Acc: 92.056% | clf_exit: 0.568 0.418 0.014
Batch: 120 | Loss: 1.274 | Acc: 66.936,98.851,99.981,% | Adaptive Acc: 91.949% | clf_exit: 0.570 0.416 0.014
Batch: 140 | Loss: 1.276 | Acc: 66.811,98.798,99.967,% | Adaptive Acc: 91.922% | clf_exit: 0.570 0.416 0.014
Batch: 160 | Loss: 1.276 | Acc: 66.702,98.801,99.966,% | Adaptive Acc: 91.964% | clf_exit: 0.568 0.418 0.014
Batch: 180 | Loss: 1.272 | Acc: 66.786,98.809,99.970,% | Adaptive Acc: 91.976% | clf_exit: 0.569 0.417 0.014
Batch: 200 | Loss: 1.273 | Acc: 66.826,98.807,99.973,% | Adaptive Acc: 91.989% | clf_exit: 0.569 0.416 0.015
Batch: 220 | Loss: 1.271 | Acc: 66.799,98.837,99.972,% | Adaptive Acc: 91.961% | clf_exit: 0.569 0.417 0.014
Batch: 240 | Loss: 1.270 | Acc: 66.721,98.810,99.971,% | Adaptive Acc: 91.899% | clf_exit: 0.569 0.416 0.014
Batch: 260 | Loss: 1.274 | Acc: 66.670,98.824,99.973,% | Adaptive Acc: 91.921% | clf_exit: 0.569 0.417 0.014
Batch: 280 | Loss: 1.273 | Acc: 66.723,98.813,99.975,% | Adaptive Acc: 91.934% | clf_exit: 0.569 0.417 0.014
Batch: 300 | Loss: 1.275 | Acc: 66.684,98.819,99.977,% | Adaptive Acc: 91.886% | clf_exit: 0.569 0.417 0.014
Batch: 320 | Loss: 1.273 | Acc: 66.664,98.815,99.976,% | Adaptive Acc: 91.869% | clf_exit: 0.570 0.416 0.014
Batch: 340 | Loss: 1.273 | Acc: 66.651,98.806,99.975,% | Adaptive Acc: 91.906% | clf_exit: 0.569 0.417 0.014
Batch: 360 | Loss: 1.271 | Acc: 66.694,98.795,99.972,% | Adaptive Acc: 91.947% | clf_exit: 0.569 0.417 0.014
Batch: 380 | Loss: 1.270 | Acc: 66.708,98.784,99.973,% | Adaptive Acc: 91.913% | clf_exit: 0.570 0.416 0.014
Batch: 0 | Loss: 3.816 | Acc: 57.031,70.312,78.125,% | Adaptive Acc: 66.406% | clf_exit: 0.609 0.305 0.086
Batch: 20 | Loss: 4.054 | Acc: 53.571,68.415,74.963,% | Adaptive Acc: 66.369% | clf_exit: 0.559 0.328 0.113
Batch: 40 | Loss: 4.061 | Acc: 53.487,67.797,74.581,% | Adaptive Acc: 66.330% | clf_exit: 0.555 0.323 0.122
Batch: 60 | Loss: 4.070 | Acc: 52.971,67.892,74.590,% | Adaptive Acc: 66.189% | clf_exit: 0.552 0.327 0.121
Evaluate with different circles:
circles: 0
Batch: 0 | Loss: 10.543 | Acc: 19.531,17.969,21.094,% | Adaptive Acc: 22.656% | clf_exit: 0.078 0.008 0.914
Batch: 20 | Loss: 10.966 | Acc: 15.774,16.704,20.201,% | Adaptive Acc: 22.024% | clf_exit: 0.087 0.026 0.887
Batch: 40 | Loss: 10.941 | Acc: 15.644,17.454,20.808,% | Adaptive Acc: 22.370% | clf_exit: 0.089 0.027 0.884
Batch: 60 | Loss: 10.955 | Acc: 15.356,17.213,20.838,% | Adaptive Acc: 22.349% | clf_exit: 0.089 0.025 0.886
circles: 1
Batch: 0 | Loss: 7.246 | Acc: 35.938,48.438,57.812,% | Adaptive Acc: 60.156% | clf_exit: 0.148 0.117 0.734
Batch: 20 | Loss: 7.838 | Acc: 29.129,43.266,53.571,% | Adaptive Acc: 54.390% | clf_exit: 0.140 0.116 0.744
Batch: 40 | Loss: 7.838 | Acc: 29.535,42.912,52.973,% | Adaptive Acc: 53.487% | clf_exit: 0.139 0.119 0.742
Batch: 60 | Loss: 7.860 | Acc: 29.290,42.853,52.754,% | Adaptive Acc: 53.343% | clf_exit: 0.136 0.116 0.748
circles: 2
Batch: 0 | Loss: 4.730 | Acc: 46.875,63.281,71.875,% | Adaptive Acc: 71.875% | clf_exit: 0.328 0.281 0.391
Batch: 20 | Loss: 5.254 | Acc: 43.676,61.682,70.275,% | Adaptive Acc: 67.560% | clf_exit: 0.280 0.264 0.456
Batch: 40 | Loss: 5.260 | Acc: 44.093,61.871,69.931,% | Adaptive Acc: 67.054% | clf_exit: 0.281 0.269 0.450
Batch: 60 | Loss: 5.273 | Acc: 43.724,61.591,69.698,% | Adaptive Acc: 66.944% | clf_exit: 0.280 0.266 0.453
circles: 3
Batch: 0 | Loss: 3.759 | Acc: 55.469,69.531,76.562,% | Adaptive Acc: 70.312% | clf_exit: 0.477 0.320 0.203
Batch: 20 | Loss: 4.114 | Acc: 52.232,67.411,74.554,% | Adaptive Acc: 69.345% | clf_exit: 0.440 0.338 0.221
Batch: 40 | Loss: 4.127 | Acc: 51.963,66.711,74.200,% | Adaptive Acc: 69.055% | clf_exit: 0.439 0.331 0.230
Batch: 60 | Loss: 4.134 | Acc: 51.306,66.893,74.065,% | Adaptive Acc: 69.032% | clf_exit: 0.436 0.332 0.232
circles: 4
Batch: 0 | Loss: 3.816 | Acc: 57.031,70.312,78.125,% | Adaptive Acc: 66.406% | clf_exit: 0.609 0.305 0.086
Batch: 20 | Loss: 4.054 | Acc: 53.571,68.415,74.963,% | Adaptive Acc: 66.369% | clf_exit: 0.559 0.328 0.113
Batch: 40 | Loss: 4.061 | Acc: 53.487,67.797,74.581,% | Adaptive Acc: 66.330% | clf_exit: 0.555 0.323 0.122
Batch: 60 | Loss: 4.070 | Acc: 52.971,67.892,74.590,% | Adaptive Acc: 66.189% | clf_exit: 0.552 0.327 0.121

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 12.225 |  Acc: 5.832,9.304,11.258,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=0 | Loss: 11.282 |  Acc: 8.530,13.280,14.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 10.474 |  Acc: 11.436,17.308,21.794,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=1 | Loss: 9.997 |  Acc: 11.830,18.620,23.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 9.319 |  Acc: 16.018,23.256,29.478,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=2 | Loss: 9.069 |  Acc: 17.120,23.950,31.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 8.518 |  Acc: 19.280,28.220,36.028,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=3 | Loss: 8.777 |  Acc: 14.160,27.110,35.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 7.927 |  Acc: 22.266,32.070,41.446,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=4 | Loss: 8.085 |  Acc: 19.520,30.520,42.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 7.446 |  Acc: 24.522,35.352,45.672,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=5 | Loss: 7.776 |  Acc: 22.310,32.720,44.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 7.067 |  Acc: 26.422,38.326,49.240,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=6 | Loss: 7.450 |  Acc: 22.810,35.330,46.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 6.703 |  Acc: 28.030,41.454,52.790,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=7 | Loss: 7.027 |  Acc: 25.110,38.920,52.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 6.395 |  Acc: 29.744,43.806,55.758,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=8 | Loss: 6.680 |  Acc: 26.950,42.090,53.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 6.120 |  Acc: 31.042,46.128,58.624,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=9 | Loss: 6.526 |  Acc: 29.460,41.380,55.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 5.896 |  Acc: 32.120,48.246,61.068,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=10 | Loss: 6.528 |  Acc: 26.360,44.550,56.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 5.692 |  Acc: 33.140,49.682,63.002,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=11 | Loss: 6.455 |  Acc: 27.150,44.820,58.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 5.476 |  Acc: 34.366,51.670,65.106,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=12 | Loss: 6.010 |  Acc: 31.410,48.260,59.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 5.317 |  Acc: 35.272,52.746,67.086,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=13 | Loss: 6.019 |  Acc: 31.300,46.770,60.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 5.165 |  Acc: 35.788,54.194,68.692,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=14 | Loss: 6.062 |  Acc: 29.400,48.050,61.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 5.009 |  Acc: 36.506,55.646,70.450,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=15 | Loss: 5.918 |  Acc: 31.790,49.520,61.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 4.877 |  Acc: 37.358,56.776,71.778,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=16 | Loss: 5.711 |  Acc: 33.110,51.130,62.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 4.760 |  Acc: 38.170,57.704,72.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=17 | Loss: 5.771 |  Acc: 32.860,51.110,63.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.649 |  Acc: 38.438,58.954,74.744,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=18 | Loss: 5.753 |  Acc: 33.390,50.450,62.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.557 |  Acc: 38.916,59.554,75.582,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=19 | Loss: 5.498 |  Acc: 34.610,53.900,63.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.470 |  Acc: 39.482,60.036,76.878,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=20 | Loss: 5.574 |  Acc: 35.240,51.970,63.520,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.377 |  Acc: 39.976,61.006,77.796,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=21 | Loss: 5.484 |  Acc: 34.240,53.880,64.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 4.295 |  Acc: 40.558,61.950,78.834,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=22 | Loss: 5.300 |  Acc: 36.970,55.180,66.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 4.224 |  Acc: 41.016,62.476,79.498,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=23 | Loss: 5.403 |  Acc: 35.170,55.760,65.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 4.172 |  Acc: 41.070,62.802,80.244,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=24 | Loss: 5.424 |  Acc: 35.770,56.120,65.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 4.076 |  Acc: 41.496,63.710,81.434,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=25 | Loss: 5.516 |  Acc: 35.130,54.300,65.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 4.038 |  Acc: 41.918,63.832,81.872,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=26 | Loss: 5.323 |  Acc: 36.600,56.460,65.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 3.970 |  Acc: 41.902,64.678,82.656,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=27 | Loss: 5.249 |  Acc: 36.930,57.410,65.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 3.903 |  Acc: 42.576,65.266,83.852,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=28 | Loss: 5.577 |  Acc: 33.580,54.500,65.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 3.877 |  Acc: 42.872,65.446,84.000,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=29 | Loss: 5.689 |  Acc: 33.270,53.560,64.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 3.817 |  Acc: 43.170,65.750,84.694,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=30 | Loss: 5.371 |  Acc: 35.100,57.230,66.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 3.789 |  Acc: 43.030,66.348,84.842,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=31 | Loss: 5.231 |  Acc: 39.480,56.570,66.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 3.750 |  Acc: 43.342,66.640,85.552,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=32 | Loss: 5.423 |  Acc: 35.070,56.890,65.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 3.708 |  Acc: 43.544,67.060,86.124,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=33 | Loss: 5.251 |  Acc: 37.040,58.290,66.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 3.660 |  Acc: 43.708,67.162,86.692,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=34 | Loss: 5.414 |  Acc: 37.120,55.560,66.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 3.636 |  Acc: 43.858,67.770,86.732,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=35 | Loss: 5.346 |  Acc: 35.850,55.820,66.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.605 |  Acc: 43.914,68.146,87.020,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=36 | Loss: 5.213 |  Acc: 36.890,58.230,66.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.556 |  Acc: 44.450,68.502,87.586,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=37 | Loss: 5.449 |  Acc: 36.400,56.650,65.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.541 |  Acc: 44.682,68.666,87.846,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=38 | Loss: 5.272 |  Acc: 38.160,57.160,65.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.510 |  Acc: 44.952,68.792,88.172,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=39 | Loss: 5.374 |  Acc: 37.080,56.870,65.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.495 |  Acc: 45.082,69.208,88.140,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=40 | Loss: 5.435 |  Acc: 36.820,55.740,66.530,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.481 |  Acc: 45.068,68.956,88.494,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=41 | Loss: 5.321 |  Acc: 38.090,56.650,67.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.448 |  Acc: 45.320,69.324,88.868,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=42 | Loss: 5.375 |  Acc: 37.860,56.690,65.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.417 |  Acc: 45.330,69.946,89.196,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=43 | Loss: 5.294 |  Acc: 37.290,57.540,66.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.401 |  Acc: 45.414,69.950,89.290,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=44 | Loss: 5.141 |  Acc: 39.220,58.860,67.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.375 |  Acc: 45.802,70.262,89.578,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=45 | Loss: 5.345 |  Acc: 37.320,57.220,66.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.377 |  Acc: 45.640,70.066,89.200,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=46 | Loss: 5.339 |  Acc: 36.460,59.130,66.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.331 |  Acc: 46.106,70.958,89.748,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=47 | Loss: 5.341 |  Acc: 36.890,58.480,66.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.343 |  Acc: 45.844,70.650,89.662,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=48 | Loss: 5.680 |  Acc: 36.150,54.710,64.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.320 |  Acc: 46.234,70.922,90.140,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=49 | Loss: 5.187 |  Acc: 38.360,58.880,67.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.306 |  Acc: 46.506,70.936,90.062,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=50 | Loss: 5.132 |  Acc: 39.290,59.610,66.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.286 |  Acc: 46.450,71.144,90.238,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=51 | Loss: 5.206 |  Acc: 38.620,57.800,66.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.260 |  Acc: 46.500,71.400,90.666,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=52 | Loss: 4.934 |  Acc: 42.430,60.440,66.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.241 |  Acc: 46.774,71.878,90.706,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=53 | Loss: 5.286 |  Acc: 38.370,58.400,65.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.242 |  Acc: 46.656,71.820,90.364,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=54 | Loss: 5.036 |  Acc: 40.740,60.620,68.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.235 |  Acc: 46.848,71.858,90.570,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=55 | Loss: 5.693 |  Acc: 33.260,56.280,66.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.220 |  Acc: 46.990,72.000,90.764,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=56 | Loss: 5.249 |  Acc: 36.800,60.090,66.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.176 |  Acc: 47.310,72.358,91.330,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=57 | Loss: 5.002 |  Acc: 40.510,60.010,67.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.197 |  Acc: 47.158,72.144,90.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=58 | Loss: 5.220 |  Acc: 38.880,58.230,67.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.163 |  Acc: 47.348,72.676,91.474,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=59 | Loss: 5.246 |  Acc: 40.080,58.330,65.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.146 |  Acc: 47.292,72.728,91.534,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=60 | Loss: 5.103 |  Acc: 41.040,58.710,67.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.148 |  Acc: 47.544,72.658,91.498,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=61 | Loss: 5.365 |  Acc: 38.150,57.670,66.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.152 |  Acc: 47.544,72.694,91.296,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=62 | Loss: 5.108 |  Acc: 40.270,58.530,67.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.161 |  Acc: 47.584,72.632,91.044,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=63 | Loss: 5.214 |  Acc: 38.450,59.240,67.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 3.112 |  Acc: 47.828,73.032,91.670,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=64 | Loss: 5.048 |  Acc: 40.290,60.810,67.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 3.120 |  Acc: 47.708,73.094,91.492,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=65 | Loss: 5.437 |  Acc: 36.420,56.170,66.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 3.113 |  Acc: 47.756,73.216,91.222,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=66 | Loss: 5.236 |  Acc: 39.720,58.890,66.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 3.094 |  Acc: 48.088,73.580,91.718,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=67 | Loss: 5.360 |  Acc: 37.700,58.180,65.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 3.096 |  Acc: 48.038,73.522,91.524,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=68 | Loss: 5.210 |  Acc: 40.230,58.260,66.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 3.064 |  Acc: 48.372,73.828,91.886,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=69 | Loss: 5.447 |  Acc: 37.540,57.840,65.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 3.062 |  Acc: 48.446,73.684,92.024,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=70 | Loss: 5.140 |  Acc: 40.080,59.630,66.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 3.061 |  Acc: 48.228,73.812,91.700,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=71 | Loss: 5.417 |  Acc: 36.510,58.550,66.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 3.041 |  Acc: 48.346,73.904,91.900,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=72 | Loss: 5.519 |  Acc: 37.090,57.790,65.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 3.045 |  Acc: 48.444,73.814,91.980,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=73 | Loss: 5.179 |  Acc: 39.530,59.010,65.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 3.022 |  Acc: 48.654,74.382,92.212,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=74 | Loss: 5.098 |  Acc: 39.860,59.160,66.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 3.013 |  Acc: 48.502,74.462,92.132,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=75 | Loss: 5.226 |  Acc: 39.640,59.070,66.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 3.041 |  Acc: 48.720,74.082,91.546,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=76 | Loss: 5.361 |  Acc: 40.770,57.140,65.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 3.040 |  Acc: 48.604,73.754,91.734,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=77 | Loss: 5.197 |  Acc: 41.590,58.490,66.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 3.012 |  Acc: 48.924,74.302,91.904,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=78 | Loss: 5.535 |  Acc: 36.300,57.910,66.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 2.978 |  Acc: 49.184,74.698,92.748,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=79 | Loss: 5.110 |  Acc: 41.780,59.270,66.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 3.003 |  Acc: 48.740,74.382,92.290,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=80 | Loss: 5.674 |  Acc: 36.810,57.210,64.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 2.991 |  Acc: 49.126,74.424,92.276,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=81 | Loss: 6.065 |  Acc: 32.440,55.220,64.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 2.964 |  Acc: 49.298,75.042,92.370,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=82 | Loss: 5.155 |  Acc: 41.640,58.500,66.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 2.958 |  Acc: 48.982,75.016,92.448,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=83 | Loss: 5.578 |  Acc: 35.420,57.680,66.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 2.949 |  Acc: 49.242,75.232,92.586,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=84 | Loss: 5.024 |  Acc: 41.220,61.070,67.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 2.939 |  Acc: 49.272,75.180,92.646,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=85 | Loss: 5.121 |  Acc: 39.840,60.600,67.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 2.950 |  Acc: 49.334,75.086,92.508,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=86 | Loss: 5.418 |  Acc: 37.770,59.560,66.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 2.934 |  Acc: 49.708,75.010,92.612,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=87 | Loss: 5.190 |  Acc: 40.850,60.850,67.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 2.936 |  Acc: 49.362,75.274,92.398,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=88 | Loss: 5.159 |  Acc: 42.450,58.300,66.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 2.946 |  Acc: 49.338,75.318,92.736,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=89 | Loss: 5.049 |  Acc: 42.000,60.250,67.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 2.916 |  Acc: 49.648,75.548,92.888,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=90 | Loss: 5.200 |  Acc: 41.140,58.940,66.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 2.912 |  Acc: 49.666,75.582,92.754,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=91 | Loss: 4.934 |  Acc: 42.730,61.250,67.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 2.919 |  Acc: 49.696,75.200,92.626,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=92 | Loss: 5.331 |  Acc: 40.190,58.410,66.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 2.942 |  Acc: 49.354,75.088,92.258,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=93 | Loss: 5.137 |  Acc: 40.630,59.620,66.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 2.872 |  Acc: 49.914,75.914,93.212,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=94 | Loss: 5.094 |  Acc: 41.720,60.100,66.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 2.889 |  Acc: 50.002,75.644,92.930,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=95 | Loss: 5.048 |  Acc: 41.550,61.290,67.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 2.918 |  Acc: 49.614,75.806,92.464,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=96 | Loss: 5.262 |  Acc: 40.860,58.620,65.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 2.909 |  Acc: 49.802,75.686,92.534,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=97 | Loss: 4.988 |  Acc: 42.430,60.440,67.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 2.887 |  Acc: 50.124,75.664,92.690,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=98 | Loss: 5.189 |  Acc: 39.790,59.040,66.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 2.880 |  Acc: 50.160,76.042,93.086,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=99 | Loss: 5.051 |  Acc: 41.190,60.810,67.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 2.888 |  Acc: 49.958,75.670,92.894,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=100 | Loss: 5.247 |  Acc: 38.820,58.840,66.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 2.875 |  Acc: 50.068,76.082,92.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=101 | Loss: 5.170 |  Acc: 39.290,59.490,67.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 2.854 |  Acc: 50.170,76.242,93.120,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=102 | Loss: 5.072 |  Acc: 41.590,59.590,67.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 2.855 |  Acc: 50.078,76.344,92.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=103 | Loss: 5.222 |  Acc: 42.230,58.210,65.590,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 2.875 |  Acc: 50.274,75.914,92.676,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=104 | Loss: 5.633 |  Acc: 37.310,57.580,64.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 2.852 |  Acc: 50.268,76.376,93.018,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=105 | Loss: 5.172 |  Acc: 41.020,58.420,67.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 2.875 |  Acc: 50.400,76.182,92.540,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=106 | Loss: 5.422 |  Acc: 39.180,57.540,65.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 2.839 |  Acc: 50.314,76.442,92.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=107 | Loss: 5.188 |  Acc: 40.000,59.850,66.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 2.838 |  Acc: 50.294,76.490,92.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=108 | Loss: 5.255 |  Acc: 41.460,58.370,66.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 2.845 |  Acc: 50.560,76.246,92.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=109 | Loss: 5.052 |  Acc: 42.540,61.430,66.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 2.828 |  Acc: 50.600,76.584,92.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=110 | Loss: 5.031 |  Acc: 43.090,60.290,67.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 2.837 |  Acc: 50.536,76.544,92.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=111 | Loss: 4.937 |  Acc: 42.140,61.020,67.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 2.821 |  Acc: 50.768,76.578,93.184,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=112 | Loss: 5.469 |  Acc: 37.770,56.410,65.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 2.842 |  Acc: 50.528,76.262,92.716,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=113 | Loss: 5.494 |  Acc: 38.570,57.980,64.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 2.841 |  Acc: 50.776,76.424,92.856,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=114 | Loss: 5.188 |  Acc: 40.310,60.010,66.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 2.809 |  Acc: 50.516,76.848,93.032,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=115 | Loss: 5.118 |  Acc: 40.740,59.850,66.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 2.796 |  Acc: 50.848,76.656,93.436,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=116 | Loss: 4.884 |  Acc: 43.080,61.820,67.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 2.810 |  Acc: 50.728,76.802,93.102,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=117 | Loss: 5.231 |  Acc: 41.940,58.730,66.130,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 2.801 |  Acc: 50.600,77.100,93.014,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=118 | Loss: 5.339 |  Acc: 40.510,57.610,65.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 2.825 |  Acc: 50.748,76.630,92.794,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=119 | Loss: 5.077 |  Acc: 42.150,59.990,67.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 2.777 |  Acc: 51.042,77.168,93.620,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=120 | Loss: 5.304 |  Acc: 41.770,58.950,65.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 2.784 |  Acc: 50.918,77.084,93.272,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=121 | Loss: 5.287 |  Acc: 40.600,58.200,66.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 2.785 |  Acc: 51.038,76.944,93.178,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=122 | Loss: 5.238 |  Acc: 42.170,59.630,66.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 2.813 |  Acc: 50.618,76.624,92.782,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=123 | Loss: 5.636 |  Acc: 36.790,57.890,65.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 2.812 |  Acc: 50.694,76.838,92.800,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=124 | Loss: 5.120 |  Acc: 42.520,59.700,65.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 2.804 |  Acc: 50.904,76.874,92.848,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=125 | Loss: 5.134 |  Acc: 41.940,59.830,66.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 2.794 |  Acc: 51.116,77.218,92.892,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=126 | Loss: 5.079 |  Acc: 42.080,58.980,67.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 2.793 |  Acc: 50.906,76.812,93.152,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=127 | Loss: 5.080 |  Acc: 41.560,59.780,67.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 2.746 |  Acc: 51.152,77.400,94.000,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=128 | Loss: 5.145 |  Acc: 41.150,60.360,67.520,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 2.766 |  Acc: 51.006,77.536,93.390,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=129 | Loss: 5.035 |  Acc: 43.320,59.560,67.130,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 2.774 |  Acc: 50.878,77.262,93.214,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=130 | Loss: 5.236 |  Acc: 41.150,59.370,65.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 2.770 |  Acc: 51.238,77.020,93.156,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=131 | Loss: 5.097 |  Acc: 40.780,59.660,68.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 2.763 |  Acc: 51.176,77.304,93.140,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=132 | Loss: 5.069 |  Acc: 43.510,59.810,67.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 2.743 |  Acc: 51.190,77.522,93.540,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=133 | Loss: 5.075 |  Acc: 43.010,60.120,66.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 2.751 |  Acc: 51.450,77.434,93.388,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=134 | Loss: 5.260 |  Acc: 40.260,59.550,66.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 2.754 |  Acc: 51.460,77.420,93.374,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=135 | Loss: 4.988 |  Acc: 43.430,61.240,67.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 2.750 |  Acc: 51.274,77.664,93.586,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=136 | Loss: 5.030 |  Acc: 43.010,61.190,67.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 2.743 |  Acc: 51.668,77.354,93.620,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=137 | Loss: 5.176 |  Acc: 41.590,58.900,65.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 2.778 |  Acc: 51.104,77.198,92.884,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=138 | Loss: 5.084 |  Acc: 40.450,60.270,67.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 2.737 |  Acc: 51.358,77.608,93.446,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=139 | Loss: 5.108 |  Acc: 43.680,60.440,66.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 2.750 |  Acc: 51.394,77.474,93.296,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=140 | Loss: 5.163 |  Acc: 42.840,59.570,66.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 2.761 |  Acc: 51.310,77.180,93.234,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=141 | Loss: 5.476 |  Acc: 41.680,57.470,64.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 2.738 |  Acc: 51.600,77.690,93.538,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=142 | Loss: 4.981 |  Acc: 44.070,60.210,67.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 2.711 |  Acc: 51.612,78.030,93.732,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=143 | Loss: 5.110 |  Acc: 41.840,60.710,66.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 2.742 |  Acc: 51.592,77.454,93.196,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=144 | Loss: 5.064 |  Acc: 43.290,60.670,67.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 2.748 |  Acc: 51.588,77.682,93.296,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=145 | Loss: 5.262 |  Acc: 42.170,58.030,66.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 2.721 |  Acc: 51.560,77.596,93.474,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=146 | Loss: 4.925 |  Acc: 43.990,60.980,67.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 2.737 |  Acc: 51.482,77.480,93.334,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=147 | Loss: 5.000 |  Acc: 43.430,60.640,67.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 2.709 |  Acc: 51.740,77.880,93.616,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=148 | Loss: 5.376 |  Acc: 41.200,57.830,65.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 2.727 |  Acc: 51.382,77.778,93.486,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=149 | Loss: 5.598 |  Acc: 39.360,56.060,65.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.143 |  Acc: 56.384,86.026,98.086,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=150 | Loss: 3.952 |  Acc: 51.230,68.990,73.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 1.969 |  Acc: 57.716,88.682,99.314,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=151 | Loss: 3.900 |  Acc: 51.660,69.400,74.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.911 |  Acc: 58.394,89.686,99.506,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=152 | Loss: 3.900 |  Acc: 51.520,69.530,74.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.868 |  Acc: 58.600,90.534,99.622,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=153 | Loss: 3.883 |  Acc: 51.820,69.250,74.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.834 |  Acc: 58.884,90.934,99.704,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=154 | Loss: 3.894 |  Acc: 51.800,69.170,74.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.813 |  Acc: 58.994,91.384,99.758,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=155 | Loss: 3.881 |  Acc: 52.100,69.240,74.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.792 |  Acc: 59.274,91.662,99.766,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=156 | Loss: 3.910 |  Acc: 51.930,69.170,74.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.767 |  Acc: 59.650,92.070,99.820,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=157 | Loss: 3.902 |  Acc: 51.360,69.230,74.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.753 |  Acc: 59.588,92.184,99.802,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=158 | Loss: 3.906 |  Acc: 51.770,69.310,75.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.734 |  Acc: 59.886,92.484,99.844,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=159 | Loss: 3.887 |  Acc: 51.840,69.140,75.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 1.726 |  Acc: 59.868,92.774,99.860,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=160 | Loss: 3.901 |  Acc: 51.930,69.050,74.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.714 |  Acc: 59.976,92.908,99.836,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=161 | Loss: 3.901 |  Acc: 51.970,69.040,74.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.703 |  Acc: 60.042,93.062,99.842,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=162 | Loss: 3.912 |  Acc: 51.900,69.150,74.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.692 |  Acc: 60.196,93.238,99.846,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=163 | Loss: 3.925 |  Acc: 51.690,68.930,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.685 |  Acc: 60.122,93.398,99.862,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=164 | Loss: 3.917 |  Acc: 51.730,68.830,75.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.666 |  Acc: 60.584,93.688,99.872,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=165 | Loss: 3.932 |  Acc: 51.760,68.840,75.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.662 |  Acc: 60.610,93.756,99.894,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=166 | Loss: 3.913 |  Acc: 52.070,68.880,75.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.656 |  Acc: 60.668,93.716,99.894,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=167 | Loss: 3.933 |  Acc: 52.140,69.010,75.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.643 |  Acc: 60.580,93.990,99.906,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=168 | Loss: 3.918 |  Acc: 52.200,68.920,75.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.637 |  Acc: 60.720,94.190,99.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=169 | Loss: 3.944 |  Acc: 51.960,68.740,75.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.632 |  Acc: 60.774,94.186,99.886,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=170 | Loss: 3.941 |  Acc: 52.120,68.490,75.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.620 |  Acc: 61.104,94.366,99.900,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=171 | Loss: 3.930 |  Acc: 52.210,68.760,75.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.616 |  Acc: 60.924,94.360,99.902,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=172 | Loss: 3.946 |  Acc: 51.800,68.700,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.615 |  Acc: 60.978,94.428,99.880,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=173 | Loss: 3.972 |  Acc: 51.400,68.270,74.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.608 |  Acc: 61.010,94.664,99.906,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=174 | Loss: 3.984 |  Acc: 51.690,68.830,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.600 |  Acc: 61.150,94.722,99.902,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=175 | Loss: 3.945 |  Acc: 52.010,68.600,75.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.589 |  Acc: 61.190,94.652,99.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=176 | Loss: 3.954 |  Acc: 52.340,68.400,75.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.585 |  Acc: 61.550,94.808,99.912,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=177 | Loss: 3.961 |  Acc: 52.180,68.850,75.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.578 |  Acc: 61.068,95.134,99.910,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=178 | Loss: 3.983 |  Acc: 51.880,68.350,75.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.578 |  Acc: 61.422,94.968,99.914,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=179 | Loss: 3.990 |  Acc: 51.250,68.050,75.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.574 |  Acc: 61.480,95.048,99.910,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=180 | Loss: 3.985 |  Acc: 52.050,68.590,75.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.572 |  Acc: 61.532,95.082,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=181 | Loss: 4.020 |  Acc: 51.320,68.290,75.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.571 |  Acc: 61.340,95.244,99.914,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=182 | Loss: 4.009 |  Acc: 51.940,68.310,75.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.556 |  Acc: 61.718,95.298,99.924,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=183 | Loss: 4.027 |  Acc: 51.410,68.220,74.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.549 |  Acc: 61.816,95.384,99.916,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=184 | Loss: 3.993 |  Acc: 52.270,68.540,75.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.547 |  Acc: 61.800,95.444,99.896,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=185 | Loss: 4.025 |  Acc: 51.780,68.500,75.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.543 |  Acc: 61.674,95.428,99.926,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=186 | Loss: 4.029 |  Acc: 51.940,68.110,75.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.544 |  Acc: 61.854,95.376,99.912,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=187 | Loss: 3.995 |  Acc: 52.180,68.630,75.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.537 |  Acc: 61.922,95.532,99.920,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=188 | Loss: 4.010 |  Acc: 51.770,68.160,75.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.530 |  Acc: 62.082,95.680,99.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=189 | Loss: 4.015 |  Acc: 51.930,68.470,75.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.529 |  Acc: 62.126,95.650,99.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=190 | Loss: 3.993 |  Acc: 52.390,68.260,74.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.526 |  Acc: 62.116,95.846,99.920,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=191 | Loss: 4.026 |  Acc: 52.180,67.880,75.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.522 |  Acc: 62.226,95.744,99.930,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=192 | Loss: 4.039 |  Acc: 52.060,68.150,75.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.515 |  Acc: 62.192,95.878,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=193 | Loss: 4.070 |  Acc: 51.330,68.000,74.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.519 |  Acc: 62.140,95.768,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=194 | Loss: 4.144 |  Acc: 50.780,67.480,74.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.522 |  Acc: 62.146,95.858,99.916,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=195 | Loss: 4.057 |  Acc: 51.820,68.160,75.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.518 |  Acc: 62.094,95.862,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=196 | Loss: 4.072 |  Acc: 51.600,68.170,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.504 |  Acc: 62.454,95.978,99.918,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=197 | Loss: 4.027 |  Acc: 51.860,68.010,75.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.506 |  Acc: 62.300,95.896,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=198 | Loss: 4.079 |  Acc: 52.450,67.880,74.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.501 |  Acc: 62.578,96.136,99.914,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=199 | Loss: 4.051 |  Acc: 52.290,67.820,75.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.499 |  Acc: 62.386,96.092,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=200 | Loss: 4.077 |  Acc: 52.110,67.790,74.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.502 |  Acc: 62.372,96.016,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=201 | Loss: 4.067 |  Acc: 51.960,67.660,74.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.494 |  Acc: 62.616,96.146,99.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=202 | Loss: 4.111 |  Acc: 51.300,67.450,74.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.487 |  Acc: 62.536,96.404,99.926,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=203 | Loss: 4.091 |  Acc: 51.060,67.860,74.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.493 |  Acc: 62.600,96.140,99.922,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=204 | Loss: 4.125 |  Acc: 51.270,67.730,74.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.489 |  Acc: 62.558,96.164,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=205 | Loss: 4.105 |  Acc: 51.280,67.290,74.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.486 |  Acc: 62.624,96.246,99.924,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=206 | Loss: 4.141 |  Acc: 51.150,67.390,74.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.483 |  Acc: 62.654,96.206,99.920,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=207 | Loss: 4.156 |  Acc: 51.110,67.330,74.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.477 |  Acc: 62.824,96.302,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=208 | Loss: 4.068 |  Acc: 51.650,67.910,75.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.477 |  Acc: 62.584,96.410,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=209 | Loss: 4.101 |  Acc: 51.820,67.700,74.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.475 |  Acc: 62.864,96.344,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=210 | Loss: 4.182 |  Acc: 51.110,67.410,74.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.475 |  Acc: 63.016,96.240,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=211 | Loss: 4.119 |  Acc: 52.330,67.360,74.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.471 |  Acc: 62.848,96.304,99.930,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=212 | Loss: 4.117 |  Acc: 51.380,67.800,74.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.464 |  Acc: 62.996,96.468,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=213 | Loss: 4.106 |  Acc: 51.740,68.070,74.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.467 |  Acc: 62.922,96.476,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=214 | Loss: 4.129 |  Acc: 52.010,67.530,74.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.469 |  Acc: 62.874,96.366,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=215 | Loss: 4.131 |  Acc: 51.310,67.820,74.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.467 |  Acc: 62.946,96.442,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=216 | Loss: 4.149 |  Acc: 51.300,67.340,74.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.465 |  Acc: 63.084,96.330,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=217 | Loss: 4.136 |  Acc: 51.960,67.570,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.458 |  Acc: 63.066,96.464,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=218 | Loss: 4.153 |  Acc: 51.130,67.720,74.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.462 |  Acc: 62.958,96.460,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=219 | Loss: 4.191 |  Acc: 50.750,67.060,74.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.459 |  Acc: 62.968,96.466,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=220 | Loss: 4.185 |  Acc: 51.040,66.920,74.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.459 |  Acc: 63.086,96.428,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=221 | Loss: 4.147 |  Acc: 51.790,67.560,74.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.459 |  Acc: 62.994,96.508,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=222 | Loss: 4.177 |  Acc: 51.590,67.200,74.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.449 |  Acc: 63.128,96.672,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=223 | Loss: 4.227 |  Acc: 50.410,67.230,74.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.451 |  Acc: 63.076,96.648,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=224 | Loss: 4.125 |  Acc: 51.770,67.360,74.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.360 |  Acc: 65.186,97.796,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=225 | Loss: 3.997 |  Acc: 53.370,68.320,75.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.338 |  Acc: 65.112,98.078,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=226 | Loss: 3.998 |  Acc: 53.390,68.460,75.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.329 |  Acc: 65.168,98.138,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=227 | Loss: 3.987 |  Acc: 53.320,68.300,75.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.317 |  Acc: 65.642,98.328,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=228 | Loss: 3.988 |  Acc: 53.680,68.270,75.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.319 |  Acc: 65.608,98.272,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=229 | Loss: 3.999 |  Acc: 53.540,68.410,75.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.319 |  Acc: 65.788,98.236,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=230 | Loss: 4.009 |  Acc: 53.440,68.160,75.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.311 |  Acc: 65.684,98.404,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=231 | Loss: 4.000 |  Acc: 53.350,68.150,74.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.315 |  Acc: 65.910,98.324,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=232 | Loss: 4.005 |  Acc: 53.060,68.300,75.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.306 |  Acc: 65.940,98.410,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=233 | Loss: 4.015 |  Acc: 53.300,68.030,75.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.306 |  Acc: 65.866,98.334,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=234 | Loss: 4.011 |  Acc: 53.350,68.290,74.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.310 |  Acc: 65.744,98.428,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=235 | Loss: 4.009 |  Acc: 53.220,68.320,75.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.309 |  Acc: 65.754,98.460,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=236 | Loss: 4.007 |  Acc: 53.310,68.400,75.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.313 |  Acc: 65.792,98.310,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=237 | Loss: 4.016 |  Acc: 53.390,68.300,74.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.304 |  Acc: 65.890,98.476,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=238 | Loss: 4.008 |  Acc: 53.260,68.280,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.307 |  Acc: 65.920,98.428,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=239 | Loss: 4.016 |  Acc: 52.940,68.300,75.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.302 |  Acc: 65.950,98.490,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=240 | Loss: 4.010 |  Acc: 53.400,68.260,75.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.302 |  Acc: 65.930,98.540,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=241 | Loss: 4.018 |  Acc: 53.130,68.240,74.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.299 |  Acc: 66.084,98.530,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=242 | Loss: 4.021 |  Acc: 53.440,68.080,74.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.303 |  Acc: 65.980,98.478,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=243 | Loss: 4.009 |  Acc: 53.200,68.180,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.300 |  Acc: 65.880,98.440,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=244 | Loss: 4.015 |  Acc: 53.330,68.160,75.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.295 |  Acc: 65.932,98.522,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=245 | Loss: 4.016 |  Acc: 53.260,68.110,75.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.301 |  Acc: 66.082,98.432,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=246 | Loss: 4.017 |  Acc: 53.360,68.270,74.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.296 |  Acc: 66.104,98.534,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=247 | Loss: 4.032 |  Acc: 53.400,68.290,74.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.297 |  Acc: 66.164,98.576,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=248 | Loss: 4.019 |  Acc: 53.320,67.930,74.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.296 |  Acc: 66.008,98.504,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=249 | Loss: 4.024 |  Acc: 53.510,68.060,75.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.302 |  Acc: 65.776,98.480,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=250 | Loss: 4.025 |  Acc: 53.360,68.160,75.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.295 |  Acc: 66.142,98.548,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=251 | Loss: 4.021 |  Acc: 53.510,68.230,75.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.289 |  Acc: 66.108,98.596,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=252 | Loss: 4.024 |  Acc: 53.200,67.930,74.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.293 |  Acc: 66.238,98.448,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=253 | Loss: 4.034 |  Acc: 53.450,67.930,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.286 |  Acc: 66.108,98.678,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=254 | Loss: 4.035 |  Acc: 53.230,68.030,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.292 |  Acc: 66.170,98.528,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=255 | Loss: 4.031 |  Acc: 53.370,67.780,75.130,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.291 |  Acc: 65.858,98.586,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=256 | Loss: 4.016 |  Acc: 53.360,68.080,74.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.290 |  Acc: 66.178,98.624,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=257 | Loss: 4.029 |  Acc: 53.080,68.010,75.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.291 |  Acc: 66.200,98.582,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=258 | Loss: 4.020 |  Acc: 53.370,68.240,75.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.288 |  Acc: 66.110,98.564,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=259 | Loss: 4.029 |  Acc: 53.490,68.160,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.287 |  Acc: 66.186,98.554,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=260 | Loss: 4.025 |  Acc: 53.230,68.210,74.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.289 |  Acc: 66.118,98.582,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=261 | Loss: 4.036 |  Acc: 53.310,68.010,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.281 |  Acc: 66.280,98.624,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=262 | Loss: 4.031 |  Acc: 53.280,68.100,74.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.278 |  Acc: 66.362,98.660,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=263 | Loss: 4.040 |  Acc: 53.380,68.120,75.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.276 |  Acc: 66.478,98.664,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=264 | Loss: 4.026 |  Acc: 53.420,68.100,74.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.273 |  Acc: 66.618,98.602,99.982,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=265 | Loss: 4.041 |  Acc: 53.140,68.030,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.274 |  Acc: 66.660,98.728,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=266 | Loss: 4.026 |  Acc: 53.270,68.120,75.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.273 |  Acc: 66.606,98.746,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=267 | Loss: 4.031 |  Acc: 53.380,67.920,75.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.274 |  Acc: 66.646,98.664,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=268 | Loss: 4.025 |  Acc: 53.500,68.020,74.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.274 |  Acc: 66.594,98.742,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=269 | Loss: 4.034 |  Acc: 53.410,68.160,74.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.276 |  Acc: 66.666,98.688,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=270 | Loss: 4.027 |  Acc: 53.330,68.090,75.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.271 |  Acc: 66.550,98.788,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=271 | Loss: 4.025 |  Acc: 53.300,68.060,75.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.275 |  Acc: 66.324,98.684,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=272 | Loss: 4.025 |  Acc: 53.420,67.930,74.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.270 |  Acc: 66.508,98.706,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=273 | Loss: 4.034 |  Acc: 53.310,68.130,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.273 |  Acc: 66.636,98.676,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=274 | Loss: 4.031 |  Acc: 53.450,68.150,75.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.277 |  Acc: 66.160,98.742,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=275 | Loss: 4.030 |  Acc: 53.440,68.260,75.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.273 |  Acc: 66.590,98.640,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=276 | Loss: 4.028 |  Acc: 53.630,68.060,74.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.273 |  Acc: 66.526,98.680,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=277 | Loss: 4.035 |  Acc: 53.370,68.120,74.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.268 |  Acc: 66.862,98.764,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=278 | Loss: 4.033 |  Acc: 53.630,68.030,74.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.271 |  Acc: 66.612,98.722,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=279 | Loss: 4.021 |  Acc: 53.300,68.080,74.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.273 |  Acc: 66.660,98.636,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=280 | Loss: 4.029 |  Acc: 53.670,68.060,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.271 |  Acc: 66.656,98.820,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=281 | Loss: 4.032 |  Acc: 53.480,68.060,74.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.270 |  Acc: 66.806,98.730,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=282 | Loss: 4.034 |  Acc: 53.640,67.990,74.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.272 |  Acc: 66.472,98.758,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=283 | Loss: 4.030 |  Acc: 53.580,68.020,75.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.268 |  Acc: 66.552,98.720,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=284 | Loss: 4.024 |  Acc: 53.460,68.030,74.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.271 |  Acc: 66.628,98.714,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=285 | Loss: 4.027 |  Acc: 53.500,67.970,74.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.275 |  Acc: 66.430,98.718,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=286 | Loss: 4.021 |  Acc: 53.540,68.090,74.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.267 |  Acc: 66.688,98.700,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=287 | Loss: 4.018 |  Acc: 53.400,68.180,74.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.266 |  Acc: 66.582,98.740,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=288 | Loss: 4.034 |  Acc: 53.300,67.840,75.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.275 |  Acc: 66.356,98.660,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=289 | Loss: 4.037 |  Acc: 53.220,68.100,74.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.264 |  Acc: 66.800,98.712,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=290 | Loss: 4.033 |  Acc: 53.450,68.050,74.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.273 |  Acc: 66.362,98.766,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=291 | Loss: 4.027 |  Acc: 53.370,68.060,74.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.272 |  Acc: 66.490,98.704,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=292 | Loss: 4.021 |  Acc: 53.300,68.040,74.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.268 |  Acc: 66.716,98.734,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=293 | Loss: 4.030 |  Acc: 53.230,68.080,74.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.268 |  Acc: 66.602,98.702,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=294 | Loss: 4.043 |  Acc: 53.300,67.840,75.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.270 |  Acc: 66.622,98.688,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=295 | Loss: 4.031 |  Acc: 53.470,68.080,74.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.272 |  Acc: 66.528,98.658,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=296 | Loss: 4.038 |  Acc: 53.400,68.050,74.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.274 |  Acc: 66.474,98.676,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=297 | Loss: 4.036 |  Acc: 53.410,67.930,74.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.269 |  Acc: 66.446,98.802,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=298 | Loss: 4.035 |  Acc: 53.560,67.990,75.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelC_h_dp2', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.270 |  Acc: 66.670,98.780,99.970,% | Adaptive Acc:91.902% | clf_exit: 0.570 0.416 0.014 
Testing: Epoch=299 | Loss: 4.024 |  Acc: 53.350,68.080,74.910,% | Adaptive Acc:66.500% | clf_exit: 0.556 0.324 0.120 
Testing: Epoch=299 | Loss: 10.917 |  Acc: 15.740,17.080,20.960,% | Adaptive Acc:22.540% | clf_exit: 0.091 0.025 0.883 
Testing: Epoch=299 | Loss: 7.814 |  Acc: 29.420,43.260,53.150,% | Adaptive Acc:53.720% | clf_exit: 0.141 0.115 0.744 
Testing: Epoch=299 | Loss: 5.224 |  Acc: 43.810,61.830,70.150,% | Adaptive Acc:67.470% | clf_exit: 0.284 0.265 0.451 
Testing: Epoch=299 | Loss: 4.090 |  Acc: 51.570,67.200,74.370,% | Adaptive Acc:69.170% | clf_exit: 0.441 0.330 0.228 
Testing: Epoch=299 | Loss: 4.024 |  Acc: 53.350,68.080,74.910,% | Adaptive Acc:66.500% | clf_exit: 0.556 0.324 0.120 
