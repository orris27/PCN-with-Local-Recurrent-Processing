==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=128, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=128, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=356, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=356, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=612, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=612, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 15.151 | Acc: 1.562,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.066 | Acc: 1.786,2.567,2.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.730 | Acc: 2.401,3.125,3.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.475 | Acc: 2.805,3.740,4.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.274 | Acc: 3.501,4.080,5.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.122 | Acc: 3.782,4.556,5.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.989 | Acc: 3.990,4.985,6.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.887 | Acc: 4.222,5.380,6.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.792 | Acc: 4.503,5.823,7.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.692 | Acc: 4.778,6.121,7.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.609 | Acc: 4.901,6.452,8.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.533 | Acc: 5.108,6.851,8.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.460 | Acc: 5.307,7.167,8.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.397 | Acc: 5.496,7.390,9.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.348 | Acc: 5.702,7.621,9.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.287 | Acc: 5.915,7.903,9.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.227 | Acc: 6.155,8.178,10.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.176 | Acc: 6.362,8.390,10.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.125 | Acc: 6.620,8.713,10.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.069 | Acc: 6.826,8.996,10.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.579 | Acc: 11.719,8.594,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.346 | Acc: 8.817,12.426,15.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.350 | Acc: 8.136,12.043,14.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.340 | Acc: 8.299,12.244,15.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 10.808 | Acc: 10.156,15.625,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.925 | Acc: 10.863,14.509,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.917 | Acc: 11.109,14.768,16.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.922 | Acc: 11.027,14.767,17.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.919 | Acc: 11.179,14.583,17.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.904 | Acc: 11.417,14.790,17.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.873 | Acc: 11.622,15.063,18.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.840 | Acc: 11.763,15.287,18.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.812 | Acc: 11.942,15.445,18.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.785 | Acc: 12.021,15.612,18.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.748 | Acc: 12.158,15.765,19.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.720 | Acc: 12.238,15.809,19.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.695 | Acc: 12.328,15.888,19.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.661 | Acc: 12.503,16.107,19.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.636 | Acc: 12.589,16.303,20.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.607 | Acc: 12.674,16.432,20.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.582 | Acc: 12.775,16.564,20.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.555 | Acc: 12.880,16.667,20.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.528 | Acc: 13.017,16.830,21.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.504 | Acc: 13.052,16.929,21.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.254 | Acc: 11.719,20.312,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.217 | Acc: 13.207,17.150,25.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.226 | Acc: 12.786,17.035,25.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.213 | Acc: 13.076,17.098,24.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 9.888 | Acc: 12.500,24.219,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.686 | Acc: 15.960,22.098,27.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.768 | Acc: 16.292,21.799,28.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.819 | Acc: 15.984,21.440,27.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.818 | Acc: 15.972,21.306,27.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.786 | Acc: 16.290,21.303,27.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.750 | Acc: 16.497,21.578,27.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.719 | Acc: 16.633,21.731,27.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.712 | Acc: 16.741,21.885,28.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.690 | Acc: 16.946,22.026,28.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.683 | Acc: 16.919,21.984,28.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.635 | Acc: 17.110,22.186,28.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.626 | Acc: 17.103,22.151,28.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.607 | Acc: 17.211,22.276,28.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.585 | Acc: 17.263,22.367,28.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.574 | Acc: 17.307,22.438,28.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.557 | Acc: 17.338,22.532,28.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.550 | Acc: 17.300,22.533,29.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.540 | Acc: 17.322,22.606,29.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.519 | Acc: 17.409,22.790,29.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.167 | Acc: 14.844,19.531,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.569 | Acc: 11.533,16.146,29.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.536 | Acc: 11.338,16.559,29.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.537 | Acc: 11.437,16.586,29.060,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 8.477 | Acc: 27.344,28.906,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.865 | Acc: 21.652,25.818,34.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.870 | Acc: 20.770,26.353,34.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.895 | Acc: 20.428,26.127,34.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.913 | Acc: 20.312,26.128,34.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.927 | Acc: 19.980,26.052,34.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.922 | Acc: 19.932,26.007,34.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.915 | Acc: 20.013,26.119,34.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.906 | Acc: 20.031,26.262,34.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.900 | Acc: 20.002,26.334,34.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.892 | Acc: 20.075,26.415,34.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.895 | Acc: 20.111,26.421,34.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.875 | Acc: 20.231,26.533,35.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.874 | Acc: 20.202,26.521,35.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.874 | Acc: 20.215,26.499,35.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.864 | Acc: 20.258,26.521,35.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.852 | Acc: 20.281,26.558,35.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.842 | Acc: 20.358,26.615,35.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.828 | Acc: 20.399,26.682,35.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.809 | Acc: 20.546,26.860,35.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.663 | Acc: 20.312,32.031,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.877 | Acc: 16.964,25.149,37.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.837 | Acc: 17.588,26.029,37.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.850 | Acc: 17.252,25.615,37.116,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 8.511 | Acc: 23.438,28.125,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.473 | Acc: 22.061,27.827,39.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.452 | Acc: 22.237,28.544,39.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.445 | Acc: 22.131,28.560,39.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.384 | Acc: 22.820,29.321,39.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.389 | Acc: 22.548,29.154,39.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.371 | Acc: 22.605,29.119,39.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.345 | Acc: 22.717,29.338,40.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.345 | Acc: 22.748,29.348,40.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.330 | Acc: 22.932,29.506,40.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.315 | Acc: 23.033,29.505,40.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.304 | Acc: 23.095,29.553,40.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.304 | Acc: 23.107,29.652,40.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.286 | Acc: 23.144,29.840,40.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.285 | Acc: 23.098,29.838,40.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.278 | Acc: 23.095,29.835,40.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.259 | Acc: 23.189,30.011,40.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.244 | Acc: 23.213,30.127,40.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.231 | Acc: 23.338,30.207,40.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.213 | Acc: 23.425,30.323,40.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.313 | Acc: 21.875,32.812,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.682 | Acc: 17.969,27.865,41.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.617 | Acc: 18.502,28.258,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.626 | Acc: 18.186,27.561,41.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 8.265 | Acc: 19.531,32.031,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.883 | Acc: 23.624,32.701,43.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.853 | Acc: 24.276,32.431,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.850 | Acc: 24.577,32.480,44.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.832 | Acc: 24.470,32.417,44.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.849 | Acc: 24.319,32.101,44.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.844 | Acc: 24.496,32.348,44.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.855 | Acc: 24.429,32.264,44.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.850 | Acc: 24.437,32.318,44.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.848 | Acc: 24.456,32.402,44.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.842 | Acc: 24.448,32.459,44.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.829 | Acc: 24.533,32.586,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.828 | Acc: 24.562,32.566,44.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.824 | Acc: 24.668,32.630,44.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.812 | Acc: 24.686,32.673,44.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.802 | Acc: 24.816,32.784,44.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.802 | Acc: 24.832,32.744,44.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.792 | Acc: 24.927,32.893,44.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.790 | Acc: 24.978,32.875,44.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.780 | Acc: 25.119,33.073,45.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.547 | Acc: 26.562,42.188,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.964 | Acc: 22.210,33.445,44.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.908 | Acc: 22.161,33.651,44.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.925 | Acc: 21.913,33.350,44.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 7.159 | Acc: 27.344,42.188,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.416 | Acc: 26.451,35.751,49.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.391 | Acc: 27.020,35.823,49.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.399 | Acc: 27.024,35.809,49.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.399 | Acc: 27.402,35.995,49.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.397 | Acc: 27.460,36.131,48.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.413 | Acc: 27.221,36.002,49.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.416 | Acc: 27.366,36.137,48.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.415 | Acc: 27.344,36.005,48.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.416 | Acc: 27.314,36.063,48.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.421 | Acc: 27.181,36.019,48.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.421 | Acc: 27.103,35.969,48.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.405 | Acc: 27.195,36.067,48.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.402 | Acc: 27.260,36.144,48.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.386 | Acc: 27.366,36.199,48.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.385 | Acc: 27.305,36.176,48.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.381 | Acc: 27.327,36.244,48.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.383 | Acc: 27.250,36.183,48.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.372 | Acc: 27.361,36.260,48.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.368 | Acc: 27.383,36.346,48.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.651 | Acc: 24.219,39.062,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.821 | Acc: 24.107,34.487,47.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.782 | Acc: 24.276,34.318,46.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.778 | Acc: 24.052,34.016,47.029,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 7.504 | Acc: 26.562,34.375,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.143 | Acc: 28.423,37.165,50.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.096 | Acc: 28.944,38.510,51.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.006 | Acc: 29.431,39.434,52.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.976 | Acc: 29.408,39.593,52.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.009 | Acc: 29.308,39.318,52.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.030 | Acc: 29.236,39.101,52.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.032 | Acc: 29.039,39.118,51.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.039 | Acc: 29.110,39.062,51.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.040 | Acc: 29.113,39.097,51.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.020 | Acc: 29.338,39.420,52.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.002 | Acc: 29.401,39.596,52.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.009 | Acc: 29.214,39.426,52.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.004 | Acc: 29.125,39.452,52.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.005 | Acc: 29.215,39.485,52.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.012 | Acc: 29.184,39.403,51.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.005 | Acc: 29.257,39.396,51.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.999 | Acc: 29.282,39.395,51.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.997 | Acc: 29.268,39.333,51.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.001 | Acc: 29.255,39.300,51.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.105 | Acc: 25.000,39.062,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.442 | Acc: 23.214,38.542,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.446 | Acc: 22.713,38.281,51.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.431 | Acc: 22.515,38.268,51.409,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 7.000 | Acc: 26.562,41.406,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.731 | Acc: 29.055,39.993,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.718 | Acc: 29.211,40.796,55.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.726 | Acc: 29.252,40.817,54.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.699 | Acc: 29.794,40.876,55.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.744 | Acc: 29.425,40.478,54.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.754 | Acc: 29.520,40.470,54.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.751 | Acc: 29.743,40.570,54.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.734 | Acc: 29.882,40.916,54.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.724 | Acc: 29.864,41.022,54.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.726 | Acc: 30.010,41.154,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.715 | Acc: 30.161,41.272,54.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.717 | Acc: 30.261,41.283,54.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.717 | Acc: 30.346,41.287,54.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.713 | Acc: 30.527,41.378,54.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.713 | Acc: 30.583,41.450,54.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.707 | Acc: 30.656,41.523,54.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.723 | Acc: 30.586,41.482,54.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.725 | Acc: 30.562,41.493,54.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.721 | Acc: 30.604,41.622,54.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.019 | Acc: 27.344,43.750,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.184 | Acc: 26.414,38.765,52.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.203 | Acc: 27.020,38.224,51.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.158 | Acc: 27.228,38.922,52.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 5.956 | Acc: 35.938,54.688,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.410 | Acc: 31.622,44.196,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.454 | Acc: 31.288,43.921,57.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.470 | Acc: 31.621,43.673,57.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.454 | Acc: 31.829,43.904,57.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.461 | Acc: 31.900,43.619,57.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.463 | Acc: 31.825,43.776,57.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.453 | Acc: 32.042,43.866,57.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.459 | Acc: 31.968,43.692,57.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.459 | Acc: 31.962,43.612,57.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.464 | Acc: 32.097,43.563,56.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.477 | Acc: 32.003,43.421,56.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.470 | Acc: 32.177,43.523,56.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.478 | Acc: 32.100,43.481,56.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.479 | Acc: 32.106,43.383,56.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.481 | Acc: 32.075,43.291,56.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.470 | Acc: 32.165,43.419,56.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.465 | Acc: 32.196,43.432,56.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.457 | Acc: 32.222,43.560,56.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.444 | Acc: 32.335,43.654,56.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.699 | Acc: 32.812,46.875,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.929 | Acc: 26.823,41.481,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.973 | Acc: 25.953,41.063,55.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.999 | Acc: 25.692,40.766,55.482,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 6.362 | Acc: 28.906,42.188,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.240 | Acc: 32.701,44.680,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.166 | Acc: 33.384,45.655,59.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.158 | Acc: 33.555,45.722,60.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.139 | Acc: 33.459,46.161,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.170 | Acc: 33.470,46.047,60.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.209 | Acc: 33.181,45.655,59.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.201 | Acc: 33.317,45.645,59.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.207 | Acc: 33.021,45.468,59.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.208 | Acc: 33.184,45.623,59.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.199 | Acc: 33.318,45.670,59.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.206 | Acc: 33.293,45.599,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.205 | Acc: 33.373,45.627,59.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.200 | Acc: 33.426,45.681,59.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.203 | Acc: 33.508,45.638,59.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.198 | Acc: 33.586,45.606,59.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.201 | Acc: 33.501,45.588,59.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.198 | Acc: 33.413,45.626,59.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.194 | Acc: 33.390,45.685,59.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.194 | Acc: 33.376,45.680,59.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.136 | Acc: 31.250,51.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.615 | Acc: 28.199,46.205,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.569 | Acc: 28.316,45.732,58.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.564 | Acc: 28.381,45.428,58.491,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 5.979 | Acc: 34.375,47.656,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.825 | Acc: 36.049,48.661,63.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.897 | Acc: 35.271,48.285,62.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.879 | Acc: 35.336,48.476,62.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.887 | Acc: 35.176,48.524,62.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.915 | Acc: 34.978,48.252,62.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.949 | Acc: 34.691,47.792,62.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.939 | Acc: 34.752,47.911,62.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.954 | Acc: 34.555,47.782,61.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.952 | Acc: 34.660,47.820,61.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.959 | Acc: 34.740,47.711,61.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.963 | Acc: 34.774,47.798,61.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.957 | Acc: 34.783,47.809,61.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.953 | Acc: 34.788,47.884,61.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.958 | Acc: 34.725,47.790,61.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.958 | Acc: 34.699,47.739,61.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.965 | Acc: 34.579,47.661,61.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.968 | Acc: 34.567,47.638,61.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.967 | Acc: 34.555,47.632,61.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.968 | Acc: 34.498,47.578,61.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.802 | Acc: 31.250,47.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.333 | Acc: 31.101,45.945,60.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.342 | Acc: 31.040,45.960,59.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.363 | Acc: 30.597,45.825,59.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 5.390 | Acc: 42.969,53.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.610 | Acc: 36.830,50.000,65.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.725 | Acc: 35.633,49.314,64.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.715 | Acc: 35.861,49.577,64.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.703 | Acc: 36.015,49.961,64.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.728 | Acc: 35.721,49.567,64.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.735 | Acc: 35.737,49.432,64.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.739 | Acc: 35.882,49.618,63.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.750 | Acc: 35.913,49.490,63.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.764 | Acc: 35.843,49.279,63.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.768 | Acc: 35.883,49.230,63.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.769 | Acc: 35.920,49.046,63.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.774 | Acc: 35.691,48.982,63.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.776 | Acc: 35.659,48.970,63.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.783 | Acc: 35.626,48.902,63.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.786 | Acc: 35.605,48.918,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.789 | Acc: 35.563,48.936,63.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.790 | Acc: 35.559,48.905,63.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.786 | Acc: 35.576,48.940,63.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.776 | Acc: 35.638,49.003,63.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.248 | Acc: 30.469,50.000,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.355 | Acc: 31.027,46.577,58.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.351 | Acc: 31.917,46.913,58.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.374 | Acc: 31.621,46.644,58.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 5.313 | Acc: 39.062,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.644 | Acc: 36.496,49.479,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.581 | Acc: 36.871,50.324,65.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.585 | Acc: 36.796,50.525,65.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.581 | Acc: 36.391,50.646,65.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.566 | Acc: 36.533,50.866,65.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.582 | Acc: 36.312,50.910,65.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.585 | Acc: 36.431,50.909,65.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.587 | Acc: 36.345,50.864,65.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.590 | Acc: 36.317,50.799,65.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.587 | Acc: 36.381,50.832,64.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.591 | Acc: 36.372,50.802,64.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.595 | Acc: 36.505,50.729,64.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.595 | Acc: 36.494,50.751,64.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.589 | Acc: 36.446,50.845,65.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.580 | Acc: 36.540,50.893,65.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.582 | Acc: 36.617,50.864,65.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.585 | Acc: 36.620,50.772,65.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.579 | Acc: 36.662,50.857,65.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.583 | Acc: 36.637,50.806,65.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.668 | Acc: 25.000,46.875,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.575 | Acc: 28.646,46.615,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.535 | Acc: 28.925,45.427,59.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.508 | Acc: 28.970,45.569,59.554,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 6.086 | Acc: 35.156,46.875,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.301 | Acc: 37.463,52.939,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.375 | Acc: 36.452,52.248,68.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.369 | Acc: 37.001,52.421,68.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.342 | Acc: 37.577,52.566,68.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.396 | Acc: 37.446,52.065,67.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.383 | Acc: 37.513,52.221,67.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.377 | Acc: 37.583,52.294,67.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.400 | Acc: 37.350,52.101,67.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.401 | Acc: 37.336,52.068,67.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.417 | Acc: 37.146,51.788,67.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.417 | Acc: 37.164,51.803,67.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.425 | Acc: 37.156,51.819,67.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.419 | Acc: 37.281,51.901,67.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.434 | Acc: 37.250,51.704,66.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.430 | Acc: 37.357,51.778,66.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.441 | Acc: 37.288,51.650,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.446 | Acc: 37.188,51.579,66.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.448 | Acc: 37.232,51.586,66.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.449 | Acc: 37.295,51.630,66.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.810 | Acc: 35.156,53.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.312 | Acc: 29.167,47.061,62.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.337 | Acc: 29.497,46.780,62.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.373 | Acc: 29.137,46.721,61.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 5.306 | Acc: 39.062,57.031,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.098 | Acc: 39.435,56.101,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.130 | Acc: 39.348,55.526,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.141 | Acc: 39.280,54.841,70.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.190 | Acc: 38.725,53.974,69.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.202 | Acc: 38.699,53.767,69.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.229 | Acc: 38.262,53.487,69.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.241 | Acc: 38.209,53.391,68.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.240 | Acc: 38.252,53.494,68.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.245 | Acc: 38.277,53.496,68.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.258 | Acc: 38.075,53.580,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.268 | Acc: 37.984,53.425,68.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.277 | Acc: 37.983,53.446,68.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.290 | Acc: 37.976,53.412,68.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.299 | Acc: 37.934,53.353,68.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.292 | Acc: 37.970,53.387,68.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.306 | Acc: 37.853,53.242,67.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.313 | Acc: 37.793,53.120,67.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.318 | Acc: 37.747,53.069,67.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.315 | Acc: 37.773,53.033,67.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.736 | Acc: 37.500,51.562,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.119 | Acc: 32.403,48.065,62.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.087 | Acc: 32.317,48.571,62.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.112 | Acc: 32.006,48.527,62.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 5.276 | Acc: 37.500,52.344,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.919 | Acc: 41.183,55.804,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.970 | Acc: 39.691,55.469,71.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.009 | Acc: 39.229,55.072,71.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.032 | Acc: 38.966,54.842,71.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.052 | Acc: 38.854,54.742,71.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.060 | Acc: 38.888,54.688,70.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.064 | Acc: 38.664,54.643,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.075 | Acc: 38.669,54.571,70.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.089 | Acc: 38.510,54.441,70.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.095 | Acc: 38.612,54.415,70.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.109 | Acc: 38.649,54.267,70.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.121 | Acc: 38.576,54.172,70.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.127 | Acc: 38.602,54.161,70.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.137 | Acc: 38.484,54.112,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.144 | Acc: 38.445,54.028,69.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.146 | Acc: 38.522,54.043,69.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.158 | Acc: 38.451,53.934,69.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.155 | Acc: 38.595,54.006,69.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.157 | Acc: 38.663,54.003,69.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.057 | Acc: 32.812,48.438,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.338 | Acc: 30.246,47.991,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.302 | Acc: 30.640,47.428,61.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.299 | Acc: 30.635,48.028,61.283,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 5.090 | Acc: 45.312,54.688,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.892 | Acc: 40.811,55.804,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.900 | Acc: 40.434,55.812,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.917 | Acc: 40.382,56.045,72.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.938 | Acc: 40.162,55.710,72.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.971 | Acc: 39.573,55.237,71.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.980 | Acc: 39.431,55.249,71.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.985 | Acc: 39.345,55.308,71.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.996 | Acc: 39.339,55.323,71.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.003 | Acc: 39.265,55.214,71.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.012 | Acc: 39.234,54.991,71.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.007 | Acc: 39.232,55.069,71.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.008 | Acc: 39.322,55.070,71.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.008 | Acc: 39.362,55.142,71.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.011 | Acc: 39.352,55.043,71.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.027 | Acc: 39.255,54.978,71.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.031 | Acc: 39.323,55.009,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.034 | Acc: 39.278,55.059,70.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.040 | Acc: 39.285,55.088,70.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.042 | Acc: 39.284,55.104,70.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.132 | Acc: 34.375,50.000,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.384 | Acc: 31.138,47.879,62.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.412 | Acc: 30.945,47.409,62.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.426 | Acc: 30.584,47.272,62.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 4.892 | Acc: 35.156,52.344,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.894 | Acc: 39.769,55.729,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.876 | Acc: 39.844,56.441,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.907 | Acc: 39.600,56.519,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.899 | Acc: 39.689,56.443,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.922 | Acc: 39.472,56.111,73.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.917 | Acc: 39.418,56.050,73.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.914 | Acc: 39.594,56.045,72.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.918 | Acc: 39.567,55.901,72.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.930 | Acc: 39.395,55.866,72.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.940 | Acc: 39.300,55.787,72.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.939 | Acc: 39.434,55.865,72.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.944 | Acc: 39.413,55.913,72.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.930 | Acc: 39.559,56.040,72.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.930 | Acc: 39.552,56.064,72.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.930 | Acc: 39.688,56.066,72.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.936 | Acc: 39.666,56.011,72.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.932 | Acc: 39.727,56.044,72.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.937 | Acc: 39.712,56.014,72.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.943 | Acc: 39.786,56.020,71.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.869 | Acc: 35.938,51.562,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.042 | Acc: 35.231,50.930,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.039 | Acc: 34.889,49.867,63.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.032 | Acc: 34.849,49.795,63.486,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 4.341 | Acc: 42.188,59.375,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.610 | Acc: 41.034,57.999,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.683 | Acc: 40.339,57.031,75.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.715 | Acc: 39.985,57.147,75.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.752 | Acc: 39.979,56.993,74.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.766 | Acc: 39.968,56.791,74.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.763 | Acc: 40.205,57.251,74.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.776 | Acc: 40.160,57.336,74.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.793 | Acc: 39.921,57.133,74.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.811 | Acc: 40.012,56.902,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.825 | Acc: 39.925,56.771,73.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.837 | Acc: 40.031,56.635,73.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.852 | Acc: 40.064,56.564,73.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.867 | Acc: 40.047,56.388,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.871 | Acc: 39.994,56.292,72.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.865 | Acc: 40.054,56.426,72.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.857 | Acc: 40.184,56.518,72.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.859 | Acc: 40.224,56.546,72.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.863 | Acc: 40.218,56.499,72.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.861 | Acc: 40.287,56.549,72.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.388 | Acc: 32.031,45.312,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.297 | Acc: 30.283,47.210,63.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.294 | Acc: 30.221,47.351,62.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.312 | Acc: 29.841,47.720,62.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 4.615 | Acc: 41.406,62.500,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.741 | Acc: 40.402,57.812,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.687 | Acc: 41.235,58.746,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.675 | Acc: 40.843,58.555,74.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.650 | Acc: 41.213,58.796,75.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.657 | Acc: 41.290,58.748,75.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.670 | Acc: 41.374,58.710,74.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.700 | Acc: 41.046,58.289,74.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.724 | Acc: 40.868,58.050,74.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.725 | Acc: 40.893,57.903,74.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.733 | Acc: 40.924,57.851,74.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.747 | Acc: 40.678,57.795,74.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.739 | Acc: 40.771,57.868,74.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.743 | Acc: 40.802,57.908,74.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.748 | Acc: 40.683,57.718,73.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.748 | Acc: 40.731,57.745,73.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.750 | Acc: 40.776,57.805,73.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.755 | Acc: 40.767,57.723,73.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.762 | Acc: 40.731,57.618,73.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.760 | Acc: 40.803,57.663,73.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.106 | Acc: 41.406,55.469,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.835 | Acc: 36.644,50.446,63.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.832 | Acc: 36.185,50.534,63.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.839 | Acc: 35.425,50.717,63.435,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 4.470 | Acc: 41.406,57.031,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.538 | Acc: 41.890,58.929,76.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.549 | Acc: 41.616,59.508,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 41.227,59.285,76.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.594 | Acc: 41.175,59.201,76.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.592 | Acc: 41.429,58.996,76.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.599 | Acc: 41.658,59.123,75.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.603 | Acc: 41.722,59.043,75.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.612 | Acc: 41.649,58.943,75.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.620 | Acc: 41.579,58.861,75.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.632 | Acc: 41.472,58.800,75.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.634 | Acc: 41.470,58.756,75.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.641 | Acc: 41.481,58.675,75.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.646 | Acc: 41.406,58.567,75.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.660 | Acc: 41.387,58.424,74.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.671 | Acc: 41.251,58.298,74.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.679 | Acc: 41.272,58.170,74.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.678 | Acc: 41.283,58.248,74.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.687 | Acc: 41.237,58.183,74.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.697 | Acc: 41.193,58.057,74.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.851 | Acc: 33.594,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.959 | Acc: 32.552,52.604,65.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.008 | Acc: 31.326,52.725,64.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.057 | Acc: 31.429,52.485,64.255,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 4.390 | Acc: 43.750,59.375,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 41.815,58.743,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.420 | Acc: 42.188,59.794,78.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.453 | Acc: 41.790,59.503,78.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.482 | Acc: 41.763,59.684,77.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.501 | Acc: 41.878,59.135,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.520 | Acc: 41.774,59.168,77.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.529 | Acc: 41.883,58.998,76.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.517 | Acc: 42.037,59.205,76.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.524 | Acc: 42.114,59.030,76.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.543 | Acc: 41.779,58.823,76.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.540 | Acc: 41.922,58.947,76.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.548 | Acc: 41.974,58.960,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.553 | Acc: 41.939,58.920,76.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.563 | Acc: 41.807,58.861,76.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.566 | Acc: 41.832,58.921,76.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.576 | Acc: 41.757,58.869,76.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.592 | Acc: 41.619,58.747,75.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.592 | Acc: 41.668,58.773,75.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.599 | Acc: 41.685,58.799,75.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.378 | Acc: 39.844,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.485 | Acc: 38.542,56.436,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.510 | Acc: 38.205,55.964,65.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.527 | Acc: 37.615,55.597,65.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 4.001 | Acc: 46.094,63.281,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.508 | Acc: 41.890,60.565,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.494 | Acc: 42.149,60.423,77.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.480 | Acc: 42.047,60.092,77.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.481 | Acc: 42.062,59.867,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.505 | Acc: 42.126,59.777,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.499 | Acc: 42.226,59.762,77.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.497 | Acc: 42.165,59.713,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.482 | Acc: 42.416,59.889,77.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.470 | Acc: 42.498,60.001,77.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.483 | Acc: 42.467,59.803,77.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.488 | Acc: 42.467,59.767,77.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.501 | Acc: 42.350,59.644,76.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.507 | Acc: 42.355,59.647,76.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.507 | Acc: 42.354,59.631,76.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.507 | Acc: 42.343,59.661,76.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.513 | Acc: 42.287,59.606,76.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.519 | Acc: 42.245,59.590,76.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.521 | Acc: 42.224,59.561,76.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.533 | Acc: 42.122,59.424,76.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.260 | Acc: 45.312,53.906,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.830 | Acc: 36.012,53.609,65.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.816 | Acc: 35.918,52.706,64.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.848 | Acc: 35.784,52.754,64.319,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 4.216 | Acc: 44.531,63.281,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.441 | Acc: 42.522,59.524,78.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.427 | Acc: 42.378,59.794,77.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.384 | Acc: 42.661,60.310,78.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.394 | Acc: 42.390,60.060,78.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.396 | Acc: 42.683,60.063,78.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.392 | Acc: 42.672,59.988,78.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.395 | Acc: 42.653,60.023,78.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.392 | Acc: 42.673,60.069,78.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.398 | Acc: 42.731,60.018,78.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.401 | Acc: 42.747,59.970,78.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.417 | Acc: 42.537,59.912,77.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.423 | Acc: 42.444,59.855,77.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.430 | Acc: 42.346,59.842,77.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.430 | Acc: 42.513,59.853,77.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.437 | Acc: 42.509,59.803,77.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.446 | Acc: 42.380,59.674,77.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.464 | Acc: 42.249,59.586,77.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.469 | Acc: 42.268,59.600,77.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.472 | Acc: 42.290,59.625,76.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.835 | Acc: 34.375,53.125,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.179 | Acc: 32.106,51.600,63.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.245 | Acc: 31.536,51.296,62.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.265 | Acc: 30.738,50.897,62.666,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 4.823 | Acc: 45.312,57.812,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.308 | Acc: 42.485,61.272,79.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.248 | Acc: 42.893,62.462,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.251 | Acc: 43.148,62.321,79.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.271 | Acc: 42.998,61.979,79.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.283 | Acc: 42.922,61.595,79.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.290 | Acc: 42.969,61.525,79.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.317 | Acc: 42.725,61.087,79.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.314 | Acc: 42.974,61.204,79.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.320 | Acc: 43.072,61.231,79.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.329 | Acc: 43.124,61.085,78.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.328 | Acc: 43.121,61.065,78.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.344 | Acc: 43.047,60.860,78.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.354 | Acc: 43.103,60.815,78.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.367 | Acc: 42.972,60.673,78.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.372 | Acc: 43.002,60.597,78.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.380 | Acc: 42.901,60.543,78.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.390 | Acc: 42.948,60.431,77.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.400 | Acc: 42.876,60.403,77.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.409 | Acc: 42.819,60.312,77.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.668 | Acc: 35.938,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.578 | Acc: 36.682,55.320,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.629 | Acc: 36.452,54.668,64.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.672 | Acc: 36.309,54.508,64.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 4.266 | Acc: 45.312,58.594,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.218 | Acc: 43.936,61.942,79.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.234 | Acc: 43.598,61.700,79.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.236 | Acc: 43.673,61.744,79.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.240 | Acc: 43.827,61.941,79.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.254 | Acc: 43.758,61.966,79.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.261 | Acc: 43.408,61.680,79.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.261 | Acc: 43.357,61.796,79.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.276 | Acc: 43.240,61.617,79.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.293 | Acc: 43.124,61.486,79.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.295 | Acc: 43.163,61.521,79.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.311 | Acc: 43.096,61.394,79.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.316 | Acc: 43.047,61.391,79.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.337 | Acc: 42.882,61.093,78.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.345 | Acc: 42.821,60.979,78.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.354 | Acc: 42.759,60.948,78.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.365 | Acc: 42.735,60.869,78.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.370 | Acc: 42.726,60.791,78.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.370 | Acc: 42.793,60.862,78.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.373 | Acc: 42.823,60.804,78.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.165 | Acc: 42.969,58.594,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.755 | Acc: 35.454,53.571,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.710 | Acc: 36.090,53.163,65.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.732 | Acc: 36.053,53.215,64.895,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 4.471 | Acc: 39.062,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.140 | Acc: 42.857,62.909,80.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.169 | Acc: 43.579,62.691,80.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.217 | Acc: 43.660,61.975,79.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.232 | Acc: 43.769,61.593,79.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.256 | Acc: 43.495,61.425,79.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.254 | Acc: 43.447,61.396,79.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.248 | Acc: 43.733,61.536,79.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.234 | Acc: 43.920,61.631,79.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.236 | Acc: 43.966,61.404,79.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.232 | Acc: 44.026,61.505,79.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.233 | Acc: 43.941,61.577,79.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.247 | Acc: 43.828,61.443,79.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.255 | Acc: 43.747,61.428,79.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.262 | Acc: 43.728,61.407,79.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.271 | Acc: 43.779,61.366,79.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.279 | Acc: 43.711,61.356,79.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.289 | Acc: 43.693,61.231,78.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.296 | Acc: 43.685,61.212,78.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.302 | Acc: 43.588,61.194,78.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.278 | Acc: 44.531,50.781,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.662 | Acc: 37.388,54.725,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.628 | Acc: 37.748,54.916,65.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.651 | Acc: 37.167,54.905,65.330,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 4.572 | Acc: 46.875,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.136 | Acc: 44.010,63.951,81.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.112 | Acc: 43.960,63.034,81.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.106 | Acc: 43.942,63.051,81.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.106 | Acc: 44.068,63.214,81.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.115 | Acc: 44.315,62.941,81.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.129 | Acc: 44.389,62.597,81.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.157 | Acc: 44.188,62.522,81.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.161 | Acc: 44.347,62.393,80.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.177 | Acc: 44.281,62.168,80.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.182 | Acc: 44.349,62.197,80.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.189 | Acc: 44.316,62.058,80.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.197 | Acc: 44.259,62.072,80.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.213 | Acc: 44.232,61.862,80.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.213 | Acc: 44.239,61.916,80.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.220 | Acc: 44.147,61.874,79.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.232 | Acc: 43.979,61.719,79.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.241 | Acc: 43.954,61.616,79.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.245 | Acc: 44.012,61.539,79.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.246 | Acc: 44.047,61.594,79.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.410 | Acc: 43.750,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.536 | Acc: 38.951,56.324,65.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.533 | Acc: 38.510,55.926,65.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.534 | Acc: 38.230,56.058,65.087,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 4.427 | Acc: 39.062,59.375,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.011 | Acc: 44.234,64.286,82.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.075 | Acc: 43.864,63.319,82.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.065 | Acc: 43.699,63.371,81.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.061 | Acc: 43.702,63.609,82.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.086 | Acc: 43.765,63.513,81.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.085 | Acc: 43.970,63.178,81.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.116 | Acc: 43.855,62.882,81.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.116 | Acc: 43.930,62.830,81.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.125 | Acc: 43.923,62.850,81.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.142 | Acc: 43.902,62.718,80.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.144 | Acc: 43.927,62.762,80.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.146 | Acc: 43.938,62.779,80.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.167 | Acc: 43.828,62.527,80.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.177 | Acc: 43.769,62.389,80.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.178 | Acc: 43.760,62.404,80.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.186 | Acc: 43.794,62.308,80.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.199 | Acc: 43.752,62.207,79.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.213 | Acc: 43.715,62.076,79.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.214 | Acc: 43.773,62.121,79.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.051 | Acc: 41.406,53.125,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.691 | Acc: 36.905,54.799,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.666 | Acc: 36.109,54.516,65.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.665 | Acc: 36.232,54.547,65.190,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 3.857 | Acc: 48.438,61.719,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.993 | Acc: 45.499,64.025,82.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.971 | Acc: 45.122,64.139,83.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.980 | Acc: 45.441,63.909,82.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.008 | Acc: 45.139,63.706,82.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.032 | Acc: 44.910,63.374,82.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.056 | Acc: 44.932,63.294,81.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.064 | Acc: 44.819,63.442,81.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.099 | Acc: 44.522,63.014,81.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.121 | Acc: 44.324,62.703,81.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.136 | Acc: 44.302,62.554,81.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.151 | Acc: 44.231,62.408,80.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.150 | Acc: 44.188,62.432,80.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.159 | Acc: 44.163,62.377,80.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.162 | Acc: 44.212,62.328,80.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.162 | Acc: 44.233,62.404,80.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.166 | Acc: 44.181,62.386,80.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.174 | Acc: 44.176,62.340,80.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.179 | Acc: 44.159,62.301,80.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.184 | Acc: 44.191,62.301,80.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.378 | Acc: 37.500,57.031,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.563 | Acc: 37.909,55.394,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.538 | Acc: 38.186,54.992,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.572 | Acc: 37.602,54.956,65.484,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 3.524 | Acc: 50.000,65.625,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.086 | Acc: 44.234,63.728,81.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.088 | Acc: 43.941,63.681,81.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.043 | Acc: 44.518,63.768,82.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.032 | Acc: 45.052,63.561,82.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.039 | Acc: 44.887,63.475,82.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.047 | Acc: 44.744,63.533,82.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.048 | Acc: 44.975,63.536,82.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.060 | Acc: 44.682,63.257,82.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.076 | Acc: 44.471,63.104,82.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.091 | Acc: 44.341,62.994,81.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.093 | Acc: 44.347,62.935,81.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.099 | Acc: 44.356,62.814,81.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.115 | Acc: 44.268,62.790,81.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.126 | Acc: 44.339,62.600,81.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.130 | Acc: 44.274,62.565,81.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.137 | Acc: 44.302,62.544,80.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.143 | Acc: 44.309,62.523,80.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.148 | Acc: 44.360,62.481,80.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.152 | Acc: 44.306,62.457,80.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.432 | Acc: 37.500,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.596 | Acc: 38.170,54.911,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.584 | Acc: 38.186,54.897,66.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.601 | Acc: 38.064,54.559,66.201,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 3.603 | Acc: 50.000,71.875,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.941 | Acc: 45.238,65.923,84.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.904 | Acc: 45.370,65.663,84.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.961 | Acc: 45.364,65.074,83.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.963 | Acc: 45.390,64.747,83.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.964 | Acc: 45.382,64.689,83.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.968 | Acc: 45.254,64.482,83.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.990 | Acc: 45.152,64.123,82.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.014 | Acc: 44.997,63.742,82.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.026 | Acc: 45.006,63.816,82.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.031 | Acc: 45.002,63.627,82.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.037 | Acc: 45.030,63.500,82.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.045 | Acc: 44.982,63.505,82.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.049 | Acc: 44.968,63.536,81.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.058 | Acc: 44.879,63.412,81.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.061 | Acc: 44.879,63.372,81.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.065 | Acc: 44.853,63.332,81.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.073 | Acc: 44.802,63.174,81.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.083 | Acc: 44.743,63.061,81.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.084 | Acc: 44.771,63.041,81.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.762 | Acc: 35.156,63.281,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.828 | Acc: 33.705,54.948,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.805 | Acc: 33.975,55.240,65.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.808 | Acc: 33.145,55.277,65.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 3.812 | Acc: 37.500,70.312,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.945 | Acc: 44.940,64.100,82.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.922 | Acc: 46.037,64.615,82.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.908 | Acc: 45.940,64.946,82.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.915 | Acc: 45.910,64.458,83.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.936 | Acc: 45.738,64.186,82.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.953 | Acc: 45.584,64.127,82.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.971 | Acc: 45.224,63.819,82.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.977 | Acc: 45.356,63.752,82.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.987 | Acc: 45.317,63.557,82.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.991 | Acc: 45.316,63.616,82.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.997 | Acc: 45.263,63.652,82.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.005 | Acc: 45.280,63.531,82.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.020 | Acc: 45.193,63.497,82.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.029 | Acc: 45.254,63.445,81.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.042 | Acc: 45.084,63.289,81.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.048 | Acc: 45.120,63.345,81.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.054 | Acc: 45.056,63.245,81.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.060 | Acc: 45.031,63.177,81.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.068 | Acc: 44.986,63.138,81.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.265 | Acc: 41.406,58.594,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.701 | Acc: 36.905,55.060,66.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.677 | Acc: 37.176,54.383,65.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.715 | Acc: 36.808,54.239,65.484,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 4.294 | Acc: 42.188,63.281,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.839 | Acc: 46.726,65.625,83.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.860 | Acc: 46.246,65.168,83.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.877 | Acc: 45.966,64.844,83.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.916 | Acc: 45.592,64.207,83.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.926 | Acc: 45.514,63.985,83.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.913 | Acc: 45.571,64.192,83.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.918 | Acc: 45.484,64.234,83.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.917 | Acc: 45.638,64.373,83.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.930 | Acc: 45.666,64.395,83.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.949 | Acc: 45.682,64.241,82.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.971 | Acc: 45.496,63.939,82.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.983 | Acc: 45.306,63.845,82.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.990 | Acc: 45.268,63.805,82.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.002 | Acc: 45.249,63.809,82.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.007 | Acc: 45.167,63.748,82.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.014 | Acc: 45.149,63.615,81.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.020 | Acc: 45.205,63.636,81.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.024 | Acc: 45.222,63.560,81.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.033 | Acc: 45.208,63.451,81.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.676 | Acc: 39.062,55.469,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.557 | Acc: 37.016,55.952,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.564 | Acc: 37.843,55.640,64.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.573 | Acc: 37.807,55.507,64.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 3.597 | Acc: 50.000,67.969,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.820 | Acc: 46.391,65.811,84.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.851 | Acc: 45.979,65.587,84.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.837 | Acc: 46.683,65.804,84.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.848 | Acc: 46.528,65.500,84.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.835 | Acc: 46.829,65.602,84.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.858 | Acc: 46.404,65.289,83.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.864 | Acc: 46.315,65.287,83.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.876 | Acc: 46.268,64.980,83.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.903 | Acc: 46.098,64.684,83.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.920 | Acc: 45.997,64.475,83.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.934 | Acc: 45.864,64.388,83.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.950 | Acc: 45.734,64.267,82.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.967 | Acc: 45.597,64.086,82.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.973 | Acc: 45.588,64.060,82.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.982 | Acc: 45.471,63.966,82.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.985 | Acc: 45.480,63.953,82.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.991 | Acc: 45.443,63.920,82.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.992 | Acc: 45.440,63.956,82.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.998 | Acc: 45.312,63.901,82.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.399 | Acc: 39.062,55.469,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.597 | Acc: 36.384,56.064,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.582 | Acc: 36.719,56.155,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.623 | Acc: 36.130,55.507,65.868,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 3.666 | Acc: 44.531,65.625,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.744 | Acc: 47.359,65.476,84.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.741 | Acc: 47.618,65.492,84.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.775 | Acc: 46.939,65.638,84.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.795 | Acc: 46.701,65.461,84.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.820 | Acc: 46.132,65.114,84.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.829 | Acc: 46.287,65.179,84.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.829 | Acc: 46.604,65.193,84.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.839 | Acc: 46.574,65.101,84.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.863 | Acc: 46.297,64.969,83.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.874 | Acc: 46.308,64.731,83.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.891 | Acc: 46.108,64.579,83.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.907 | Acc: 45.948,64.458,83.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.923 | Acc: 45.911,64.317,83.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.935 | Acc: 45.866,64.132,83.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.942 | Acc: 45.834,64.127,82.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.950 | Acc: 45.814,64.045,82.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.959 | Acc: 45.693,63.971,82.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.966 | Acc: 45.784,63.885,82.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.975 | Acc: 45.714,63.876,82.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.169 | Acc: 38.281,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.718 | Acc: 36.198,55.283,65.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.727 | Acc: 36.509,55.678,64.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.733 | Acc: 36.053,55.661,64.793,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 3.619 | Acc: 51.562,71.094,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.704 | Acc: 48.177,67.374,84.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.731 | Acc: 47.466,66.616,85.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.761 | Acc: 47.413,66.253,84.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.755 | Acc: 47.512,66.204,84.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.744 | Acc: 47.571,66.228,84.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.786 | Acc: 47.327,65.845,84.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.817 | Acc: 47.163,65.592,84.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.823 | Acc: 47.021,65.552,84.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.831 | Acc: 46.979,65.590,83.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.846 | Acc: 46.859,65.388,83.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.852 | Acc: 46.822,65.342,83.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.861 | Acc: 46.817,65.191,83.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.882 | Acc: 46.612,64.925,83.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.893 | Acc: 46.603,64.749,83.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.902 | Acc: 46.509,64.610,83.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.912 | Acc: 46.459,64.537,83.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.923 | Acc: 46.327,64.473,83.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.929 | Acc: 46.276,64.441,82.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.941 | Acc: 46.182,64.317,82.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.419 | Acc: 40.625,54.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.564 | Acc: 37.686,55.208,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.652 | Acc: 37.843,54.421,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.681 | Acc: 37.167,54.918,65.113,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.847 | Acc: 46.094,69.531,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.795 | Acc: 47.210,67.001,84.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.808 | Acc: 46.723,66.711,84.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.818 | Acc: 46.183,66.176,84.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.843 | Acc: 45.939,65.538,84.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.866 | Acc: 45.823,65.022,84.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.849 | Acc: 45.978,65.263,84.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.845 | Acc: 46.326,65.193,84.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.869 | Acc: 46.074,64.946,84.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.869 | Acc: 46.167,65.060,84.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.877 | Acc: 46.195,64.929,83.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.881 | Acc: 46.094,64.830,83.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.891 | Acc: 46.116,64.789,83.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.898 | Acc: 46.199,64.739,83.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.911 | Acc: 46.197,64.696,83.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.905 | Acc: 46.260,64.743,83.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.909 | Acc: 46.191,64.649,83.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.915 | Acc: 46.245,64.560,83.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.916 | Acc: 46.273,64.573,83.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.922 | Acc: 46.202,64.505,82.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.543 | Acc: 42.969,60.156,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.974 | Acc: 33.966,54.948,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.934 | Acc: 34.070,55.373,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.959 | Acc: 33.709,55.200,66.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 3.809 | Acc: 44.531,67.969,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.662 | Acc: 47.656,67.039,85.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.692 | Acc: 47.370,66.425,85.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.712 | Acc: 46.875,65.971,85.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.737 | Acc: 46.788,65.529,85.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.754 | Acc: 46.419,65.625,85.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.776 | Acc: 46.275,65.502,85.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.781 | Acc: 46.321,65.547,84.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.779 | Acc: 46.336,65.635,84.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.796 | Acc: 46.383,65.344,84.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.806 | Acc: 46.377,65.314,84.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.796 | Acc: 46.582,65.434,84.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.803 | Acc: 46.716,65.437,84.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.817 | Acc: 46.624,65.293,84.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.832 | Acc: 46.619,65.227,83.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.848 | Acc: 46.574,64.989,83.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.856 | Acc: 46.486,64.880,83.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.866 | Acc: 46.504,64.821,83.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.878 | Acc: 46.416,64.783,83.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.889 | Acc: 46.420,64.713,83.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.482 | Acc: 39.062,61.719,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.819 | Acc: 35.938,54.725,64.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.839 | Acc: 35.347,54.040,65.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.833 | Acc: 35.041,54.252,65.612,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.662 | Acc: 48.438,67.188,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.748 | Acc: 46.466,67.188,85.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.677 | Acc: 47.599,66.902,85.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.674 | Acc: 47.887,66.970,85.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.710 | Acc: 47.598,66.570,85.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.727 | Acc: 47.401,66.607,85.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.750 | Acc: 47.230,66.335,85.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.752 | Acc: 47.097,66.229,85.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.779 | Acc: 46.865,65.989,85.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.777 | Acc: 46.970,66.057,85.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.789 | Acc: 46.751,66.045,84.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.794 | Acc: 46.758,65.986,84.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.805 | Acc: 46.836,65.865,84.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.817 | Acc: 46.758,65.616,84.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.825 | Acc: 46.680,65.536,84.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.836 | Acc: 46.618,65.467,84.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.842 | Acc: 46.559,65.309,84.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.843 | Acc: 46.504,65.304,84.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.849 | Acc: 46.498,65.244,83.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.855 | Acc: 46.522,65.114,83.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.394 | Acc: 41.406,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.644 | Acc: 36.310,57.217,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.615 | Acc: 36.947,56.402,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.641 | Acc: 36.591,56.263,66.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 4.285 | Acc: 42.188,56.250,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.659 | Acc: 47.619,66.853,85.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.665 | Acc: 47.370,67.359,85.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.725 | Acc: 46.465,66.522,85.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.751 | Acc: 46.123,65.934,85.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.751 | Acc: 46.218,66.120,85.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.760 | Acc: 46.346,65.935,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.773 | Acc: 46.238,65.841,85.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.773 | Acc: 46.332,65.839,84.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.777 | Acc: 46.357,65.897,84.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.784 | Acc: 46.393,65.920,84.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.799 | Acc: 46.334,65.667,84.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.811 | Acc: 46.324,65.599,84.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.818 | Acc: 46.282,65.529,84.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.829 | Acc: 46.224,65.572,84.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.841 | Acc: 46.161,65.397,84.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.841 | Acc: 46.240,65.413,84.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.849 | Acc: 46.240,65.291,83.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.863 | Acc: 46.157,65.088,83.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.867 | Acc: 46.168,65.059,83.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.357 | Acc: 41.406,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.560 | Acc: 38.244,55.878,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.558 | Acc: 38.567,55.945,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.607 | Acc: 38.742,55.264,66.137,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.546 | Acc: 46.094,64.844,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.636 | Acc: 47.507,67.001,86.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.609 | Acc: 47.904,66.864,85.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.621 | Acc: 48.028,66.906,85.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.661 | Acc: 47.820,66.387,85.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.677 | Acc: 47.734,66.406,85.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.672 | Acc: 47.559,66.510,85.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.701 | Acc: 47.346,66.451,85.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.715 | Acc: 47.263,66.280,85.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.735 | Acc: 47.160,66.005,85.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.745 | Acc: 47.089,65.920,85.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.759 | Acc: 46.939,65.766,85.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.757 | Acc: 47.031,65.839,85.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.765 | Acc: 47.013,65.754,84.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.774 | Acc: 46.970,65.647,84.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.786 | Acc: 46.844,65.552,84.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.795 | Acc: 46.824,65.411,84.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.803 | Acc: 46.873,65.378,84.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.811 | Acc: 46.788,65.339,84.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.814 | Acc: 46.787,65.291,84.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.427 | Acc: 35.156,54.688,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.838 | Acc: 36.235,54.799,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.871 | Acc: 36.662,54.383,66.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.917 | Acc: 36.360,54.252,65.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 3.929 | Acc: 41.406,61.719,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.690 | Acc: 47.507,67.671,85.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.698 | Acc: 47.828,66.768,85.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.712 | Acc: 47.515,66.739,85.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.750 | Acc: 46.981,66.136,85.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.764 | Acc: 46.968,65.842,85.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.759 | Acc: 46.952,65.864,85.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.738 | Acc: 47.119,66.151,85.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.741 | Acc: 47.224,66.198,85.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.754 | Acc: 47.052,66.026,85.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.764 | Acc: 47.003,65.850,84.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.777 | Acc: 46.882,65.671,84.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.781 | Acc: 46.820,65.560,84.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.778 | Acc: 46.920,65.622,84.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.791 | Acc: 46.864,65.447,84.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.796 | Acc: 46.784,65.459,84.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.798 | Acc: 46.846,65.462,84.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.796 | Acc: 46.864,65.526,84.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.799 | Acc: 46.910,65.560,84.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.808 | Acc: 46.857,65.467,84.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.274 | Acc: 45.312,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.582 | Acc: 37.835,57.366,65.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.596 | Acc: 38.662,56.460,65.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.588 | Acc: 37.807,56.801,65.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 3.540 | Acc: 51.562,67.969,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.671 | Acc: 47.879,66.778,84.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.698 | Acc: 47.485,66.616,85.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.666 | Acc: 47.579,66.675,86.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.696 | Acc: 47.608,66.503,85.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.701 | Acc: 47.571,66.259,85.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.699 | Acc: 47.521,66.238,85.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.702 | Acc: 47.412,66.439,85.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.700 | Acc: 47.448,66.343,85.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.706 | Acc: 47.320,66.393,85.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.714 | Acc: 47.318,66.251,85.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.726 | Acc: 47.306,66.056,85.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.733 | Acc: 47.283,66.072,85.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.743 | Acc: 47.228,66.029,85.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.735 | Acc: 47.286,66.103,85.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.732 | Acc: 47.425,66.214,85.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.735 | Acc: 47.437,66.160,84.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.747 | Acc: 47.354,66.060,84.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.752 | Acc: 47.327,65.995,84.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.758 | Acc: 47.310,65.945,84.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.307 | Acc: 35.156,53.906,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.417 | Acc: 31.808,51.488,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.423 | Acc: 32.260,51.658,63.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.476 | Acc: 31.942,51.345,63.794,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 3.573 | Acc: 46.094,71.094,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.569 | Acc: 48.661,69.308,86.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.609 | Acc: 47.942,67.797,86.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.647 | Acc: 47.695,67.264,86.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.644 | Acc: 47.714,67.197,86.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.666 | Acc: 47.687,67.064,86.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.665 | Acc: 47.766,66.936,86.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.680 | Acc: 47.684,66.617,86.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.698 | Acc: 47.622,66.382,85.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.715 | Acc: 47.440,66.229,85.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.715 | Acc: 47.536,66.161,85.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.724 | Acc: 47.568,66.074,85.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.730 | Acc: 47.556,65.988,85.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.737 | Acc: 47.408,65.936,85.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.743 | Acc: 47.392,65.884,84.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.751 | Acc: 47.353,65.791,84.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.763 | Acc: 47.291,65.771,84.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.773 | Acc: 47.267,65.717,84.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.777 | Acc: 47.310,65.653,84.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.786 | Acc: 47.248,65.537,84.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.113 | Acc: 41.406,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.496 | Acc: 38.876,56.659,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.551 | Acc: 38.834,55.640,65.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.611 | Acc: 38.409,55.123,64.882,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 3.683 | Acc: 49.219,67.969,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.512 | Acc: 48.140,68.601,86.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.515 | Acc: 48.323,68.026,86.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.530 | Acc: 48.630,67.982,86.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.553 | Acc: 48.438,67.679,86.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.577 | Acc: 48.167,67.505,86.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.622 | Acc: 47.792,67.071,86.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.635 | Acc: 47.568,66.960,86.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.634 | Acc: 47.559,67.027,86.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.654 | Acc: 47.475,66.881,85.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.669 | Acc: 47.458,66.869,85.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.681 | Acc: 47.441,66.739,85.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.694 | Acc: 47.423,66.565,85.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.706 | Acc: 47.477,66.457,85.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.717 | Acc: 47.353,66.323,85.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.726 | Acc: 47.295,66.266,85.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.731 | Acc: 47.325,66.241,84.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.740 | Acc: 47.212,66.191,84.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.749 | Acc: 47.178,66.131,84.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.758 | Acc: 47.131,66.052,84.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.778 | Acc: 44.531,53.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.722 | Acc: 36.979,54.985,65.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.771 | Acc: 36.738,54.440,64.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.800 | Acc: 36.360,54.675,64.319,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 3.119 | Acc: 58.594,75.781,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.568 | Acc: 48.363,69.680,87.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.594 | Acc: 48.533,68.579,86.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.608 | Acc: 48.873,67.918,86.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.616 | Acc: 48.225,67.631,86.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.614 | Acc: 48.337,67.543,86.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.630 | Acc: 48.334,67.472,86.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.644 | Acc: 48.316,67.304,85.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.642 | Acc: 48.243,67.285,85.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.656 | Acc: 48.049,67.153,85.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.670 | Acc: 47.839,66.974,85.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.683 | Acc: 47.695,66.792,85.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.692 | Acc: 47.627,66.659,85.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.699 | Acc: 47.677,66.595,85.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.706 | Acc: 47.684,66.568,85.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.715 | Acc: 47.519,66.453,85.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.725 | Acc: 47.496,66.438,84.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.733 | Acc: 47.519,66.358,84.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.744 | Acc: 47.483,66.190,84.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.752 | Acc: 47.418,66.136,84.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.079 | Acc: 39.844,57.031,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.505 | Acc: 36.979,58.147,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.583 | Acc: 36.776,56.460,66.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.635 | Acc: 36.488,55.840,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.245 | Acc: 52.344,71.875,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.640 | Acc: 48.586,67.225,86.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.587 | Acc: 48.495,68.521,86.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.612 | Acc: 47.912,68.225,86.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.593 | Acc: 48.515,68.355,86.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.600 | Acc: 48.430,67.876,86.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.608 | Acc: 48.373,67.898,86.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.614 | Acc: 48.288,67.692,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.625 | Acc: 48.171,67.547,86.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.624 | Acc: 48.097,67.481,86.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.622 | Acc: 48.014,67.444,86.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.637 | Acc: 47.837,67.237,86.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.654 | Acc: 47.679,67.175,86.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.655 | Acc: 47.761,67.137,86.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.662 | Acc: 47.706,67.065,86.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.671 | Acc: 47.654,66.972,86.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.683 | Acc: 47.537,66.849,85.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.690 | Acc: 47.549,66.750,85.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.695 | Acc: 47.535,66.642,85.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.709 | Acc: 47.529,66.472,85.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.376 | Acc: 32.031,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.886 | Acc: 32.924,55.432,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.874 | Acc: 33.689,55.221,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.914 | Acc: 33.722,55.315,65.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 3.611 | Acc: 46.875,67.188,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.468 | Acc: 50.149,69.382,87.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.478 | Acc: 49.505,69.207,87.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.518 | Acc: 48.412,68.596,87.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.564 | Acc: 48.032,67.998,87.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.568 | Acc: 47.958,67.729,87.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.577 | Acc: 47.960,67.853,87.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.591 | Acc: 47.734,67.742,86.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.597 | Acc: 47.700,67.639,86.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.611 | Acc: 47.820,67.408,86.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.626 | Acc: 47.656,67.273,86.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.628 | Acc: 47.787,67.357,86.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.626 | Acc: 47.916,67.333,86.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.639 | Acc: 47.857,67.116,86.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.646 | Acc: 47.840,67.062,86.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.660 | Acc: 47.752,67.040,85.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.667 | Acc: 47.788,66.988,85.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.681 | Acc: 47.654,66.782,85.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.688 | Acc: 47.704,66.724,85.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.697 | Acc: 47.593,66.591,85.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.473 | Acc: 45.312,63.281,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.700 | Acc: 37.277,56.994,65.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.714 | Acc: 37.252,56.860,65.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.742 | Acc: 36.744,56.878,65.087,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 3.677 | Acc: 45.312,67.188,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.559 | Acc: 46.838,68.676,87.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.549 | Acc: 47.790,68.274,86.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.583 | Acc: 47.323,67.585,86.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.564 | Acc: 47.820,67.728,86.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.544 | Acc: 48.097,67.899,86.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.548 | Acc: 48.140,67.775,86.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.559 | Acc: 48.199,67.742,86.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.586 | Acc: 48.103,67.517,86.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.610 | Acc: 47.932,67.304,86.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.619 | Acc: 47.913,67.137,86.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.635 | Acc: 47.826,66.997,86.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.635 | Acc: 47.906,66.967,86.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.642 | Acc: 47.863,66.903,85.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.653 | Acc: 47.868,66.768,85.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.661 | Acc: 47.789,66.697,85.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.670 | Acc: 47.690,66.628,85.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.679 | Acc: 47.688,66.580,85.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.685 | Acc: 47.593,66.566,85.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.683 | Acc: 47.753,66.566,85.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.024 | Acc: 42.969,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.575 | Acc: 38.281,57.775,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.587 | Acc: 38.700,57.355,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.604 | Acc: 38.717,57.390,66.457,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 3.515 | Acc: 47.656,70.312,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.604 | Acc: 47.582,67.299,86.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.549 | Acc: 48.380,67.950,87.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.551 | Acc: 48.258,68.174,86.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.532 | Acc: 48.746,68.210,86.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.543 | Acc: 48.569,67.969,86.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.555 | Acc: 48.696,67.807,86.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.562 | Acc: 48.792,67.708,86.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.586 | Acc: 48.525,67.551,86.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.611 | Acc: 48.338,67.291,86.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.612 | Acc: 48.387,67.188,86.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.619 | Acc: 48.314,67.230,86.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.632 | Acc: 48.159,67.158,86.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.634 | Acc: 48.135,67.137,85.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.641 | Acc: 48.059,67.021,85.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.651 | Acc: 47.864,66.847,85.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.665 | Acc: 47.829,66.659,85.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.675 | Acc: 47.752,66.576,85.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.681 | Acc: 47.773,66.499,85.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.685 | Acc: 47.849,66.470,85.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.618 | Acc: 42.969,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.908 | Acc: 36.458,54.353,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.926 | Acc: 37.271,54.421,65.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.956 | Acc: 37.141,54.201,65.100,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.418 | Acc: 50.781,78.125,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.472 | Acc: 48.586,68.750,86.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.514 | Acc: 48.457,68.255,87.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.530 | Acc: 48.540,68.161,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.528 | Acc: 48.650,68.432,86.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.543 | Acc: 48.631,68.147,86.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.566 | Acc: 48.386,67.814,86.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.572 | Acc: 48.327,67.747,86.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.574 | Acc: 48.374,67.639,86.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.586 | Acc: 48.179,67.658,86.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.585 | Acc: 48.247,67.673,86.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.596 | Acc: 48.240,67.541,86.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.610 | Acc: 48.233,67.405,86.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.622 | Acc: 48.225,67.316,86.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.622 | Acc: 48.315,67.313,85.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.639 | Acc: 48.336,67.159,85.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.652 | Acc: 48.189,67.044,85.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.661 | Acc: 48.160,67.020,85.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.672 | Acc: 48.020,66.880,85.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.681 | Acc: 47.999,66.757,85.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.572 | Acc: 42.188,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.628 | Acc: 36.458,58.259,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.676 | Acc: 36.909,57.584,65.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.705 | Acc: 36.616,57.531,65.420,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 3.385 | Acc: 46.094,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.522 | Acc: 49.368,68.750,87.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.492 | Acc: 49.333,69.074,87.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.492 | Acc: 49.219,68.955,87.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.536 | Acc: 48.920,68.441,87.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.551 | Acc: 48.700,68.139,87.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.560 | Acc: 48.470,68.111,87.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.567 | Acc: 48.199,67.902,87.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.579 | Acc: 47.986,67.736,87.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.585 | Acc: 47.980,67.762,86.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.597 | Acc: 47.901,67.677,86.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.606 | Acc: 47.784,67.555,86.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.614 | Acc: 47.776,67.450,86.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.622 | Acc: 47.785,67.442,86.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.624 | Acc: 47.759,67.354,86.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.622 | Acc: 47.846,67.351,86.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.638 | Acc: 47.824,67.127,86.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.643 | Acc: 47.869,67.064,86.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.653 | Acc: 47.838,66.978,85.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.660 | Acc: 47.804,66.907,85.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.375 | Acc: 38.281,58.594,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.600 | Acc: 38.579,57.143,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.591 | Acc: 39.120,56.669,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.591 | Acc: 38.998,56.801,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 3.407 | Acc: 50.781,67.188,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.508 | Acc: 49.591,68.415,87.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.539 | Acc: 48.780,68.140,87.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.528 | Acc: 48.668,68.161,87.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.502 | Acc: 49.209,68.355,87.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.522 | Acc: 49.134,68.363,87.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.535 | Acc: 48.980,68.066,86.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.540 | Acc: 48.886,67.908,86.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.552 | Acc: 48.787,67.833,86.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.558 | Acc: 48.662,67.762,86.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.573 | Acc: 48.566,67.638,86.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.576 | Acc: 48.462,67.516,86.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.586 | Acc: 48.467,67.369,86.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.603 | Acc: 48.312,67.119,86.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.606 | Acc: 48.368,67.146,86.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.611 | Acc: 48.339,67.058,86.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.616 | Acc: 48.306,67.041,86.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.625 | Acc: 48.286,66.972,85.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.628 | Acc: 48.288,66.941,85.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.630 | Acc: 48.296,66.933,85.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.400 | Acc: 38.281,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.602 | Acc: 37.016,58.519,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.593 | Acc: 36.890,57.774,65.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.594 | Acc: 36.693,57.992,65.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 2.992 | Acc: 54.688,75.000,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.503 | Acc: 49.554,68.341,87.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.521 | Acc: 48.800,68.312,87.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.503 | Acc: 48.668,68.148,87.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.532 | Acc: 48.823,67.978,87.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.527 | Acc: 48.994,68.147,87.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.526 | Acc: 48.980,67.962,87.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.524 | Acc: 48.870,67.880,87.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.525 | Acc: 48.903,67.872,87.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.545 | Acc: 48.822,67.710,87.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.567 | Acc: 48.640,67.487,86.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.571 | Acc: 48.727,67.530,86.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.588 | Acc: 48.655,67.343,86.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.607 | Acc: 48.452,67.232,86.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.618 | Acc: 48.315,67.137,86.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.629 | Acc: 48.336,67.032,86.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.629 | Acc: 48.231,67.059,86.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.636 | Acc: 48.185,66.984,85.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.636 | Acc: 48.236,67.008,85.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.636 | Acc: 48.267,67.034,85.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.902 | Acc: 46.875,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.653 | Acc: 38.281,55.543,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.658 | Acc: 37.710,55.659,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.651 | Acc: 37.679,55.725,65.625,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 3.828 | Acc: 44.531,64.062,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.497 | Acc: 48.772,68.973,87.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.475 | Acc: 48.857,68.731,87.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.479 | Acc: 49.027,68.763,87.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.487 | Acc: 48.534,68.567,87.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.498 | Acc: 48.584,68.232,87.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.515 | Acc: 48.560,68.124,86.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.532 | Acc: 48.482,68.102,86.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.548 | Acc: 48.515,67.901,86.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.555 | Acc: 48.481,67.710,86.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.564 | Acc: 48.476,67.600,86.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.569 | Acc: 48.561,67.654,86.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.570 | Acc: 48.752,67.680,86.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.575 | Acc: 48.788,67.610,86.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.574 | Acc: 48.838,67.635,86.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.588 | Acc: 48.739,67.504,86.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.599 | Acc: 48.622,67.399,86.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.607 | Acc: 48.515,67.330,85.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.617 | Acc: 48.438,67.190,85.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.625 | Acc: 48.372,67.099,85.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.670 | Acc: 39.062,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.716 | Acc: 38.430,55.320,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.715 | Acc: 38.567,55.545,65.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.725 | Acc: 38.384,55.353,65.663,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 3.525 | Acc: 46.094,70.312,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.475 | Acc: 49.702,69.010,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.524 | Acc: 48.704,68.579,86.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.516 | Acc: 48.860,68.391,86.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.516 | Acc: 48.688,68.509,86.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.508 | Acc: 48.878,68.572,87.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.505 | Acc: 48.915,68.769,87.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.510 | Acc: 48.809,68.822,86.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.534 | Acc: 48.636,68.430,86.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.536 | Acc: 48.748,68.331,86.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.533 | Acc: 48.748,68.284,86.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.529 | Acc: 48.932,68.333,86.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.539 | Acc: 48.852,68.228,86.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.548 | Acc: 48.767,68.178,86.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.553 | Acc: 48.782,68.097,86.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.558 | Acc: 48.770,67.995,86.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.569 | Acc: 48.683,67.905,86.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.578 | Acc: 48.728,67.829,86.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.587 | Acc: 48.686,67.698,86.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.597 | Acc: 48.587,67.602,85.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.989 | Acc: 44.531,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.486 | Acc: 38.281,58.445,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.534 | Acc: 38.510,57.622,66.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.579 | Acc: 38.089,56.878,66.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.682 | Acc: 45.312,68.750,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.403 | Acc: 49.963,69.680,87.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.446 | Acc: 50.267,68.845,87.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.465 | Acc: 49.475,68.532,87.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.480 | Acc: 49.035,68.191,86.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.471 | Acc: 49.428,68.348,86.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.470 | Acc: 49.174,68.382,87.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.483 | Acc: 49.014,68.434,87.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.502 | Acc: 48.777,68.192,87.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.506 | Acc: 48.899,68.064,87.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.505 | Acc: 48.846,68.171,87.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.501 | Acc: 48.975,68.206,87.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.513 | Acc: 48.985,68.076,86.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.524 | Acc: 48.925,67.873,86.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.536 | Acc: 48.966,67.713,86.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.541 | Acc: 48.928,67.675,86.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.557 | Acc: 48.795,67.521,86.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.555 | Acc: 48.882,67.543,86.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.560 | Acc: 48.892,67.503,86.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.571 | Acc: 48.864,67.391,86.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.146 | Acc: 40.625,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.856 | Acc: 38.616,55.357,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.887 | Acc: 38.453,54.707,63.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.852 | Acc: 38.742,55.072,64.075,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 3.409 | Acc: 49.219,71.094,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.462 | Acc: 49.107,69.643,87.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.368 | Acc: 50.152,69.646,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.395 | Acc: 49.526,69.493,88.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.392 | Acc: 49.614,69.425,88.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.416 | Acc: 49.389,68.943,88.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.433 | Acc: 49.509,68.802,87.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.443 | Acc: 49.557,68.567,87.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.460 | Acc: 49.258,68.444,87.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.481 | Acc: 49.223,68.280,87.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.503 | Acc: 49.071,67.996,87.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.516 | Acc: 48.971,67.870,87.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.525 | Acc: 48.966,67.726,87.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.534 | Acc: 48.791,67.714,87.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.542 | Acc: 48.688,67.621,87.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.548 | Acc: 48.614,67.574,86.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.554 | Acc: 48.520,67.531,86.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.556 | Acc: 48.541,67.538,86.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.567 | Acc: 48.459,67.397,86.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.570 | Acc: 48.536,67.397,86.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.217 | Acc: 38.281,53.906,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.480 | Acc: 31.250,51.228,63.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.480 | Acc: 31.269,51.067,63.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.485 | Acc: 31.263,51.063,63.307,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 3.178 | Acc: 53.906,70.312,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.409 | Acc: 49.814,69.680,87.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.408 | Acc: 49.943,69.836,87.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.462 | Acc: 49.296,69.032,87.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.470 | Acc: 49.219,68.779,87.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.475 | Acc: 48.994,68.526,87.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.482 | Acc: 48.818,68.524,87.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.494 | Acc: 48.964,68.346,87.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.502 | Acc: 49.054,68.333,87.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.509 | Acc: 49.042,68.271,87.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.521 | Acc: 49.067,68.202,87.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.534 | Acc: 48.964,68.096,87.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.535 | Acc: 49.102,68.082,87.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.542 | Acc: 48.967,67.984,86.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.547 | Acc: 48.855,67.896,86.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.549 | Acc: 48.920,67.860,86.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.551 | Acc: 48.941,67.784,86.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.559 | Acc: 48.884,67.779,86.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.562 | Acc: 48.905,67.718,86.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.576 | Acc: 48.768,67.536,86.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.437 | Acc: 38.281,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.866 | Acc: 32.143,55.841,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.923 | Acc: 32.184,55.583,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.933 | Acc: 32.070,55.482,65.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 4.029 | Acc: 43.750,63.281,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.398 | Acc: 49.628,69.382,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.414 | Acc: 48.990,69.817,88.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.444 | Acc: 49.091,69.070,87.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.452 | Acc: 49.007,69.174,87.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.467 | Acc: 48.677,68.866,87.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.477 | Acc: 48.786,68.905,87.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.468 | Acc: 49.036,69.088,87.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.474 | Acc: 49.005,69.158,87.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.474 | Acc: 49.119,69.113,87.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.479 | Acc: 49.044,69.049,87.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.482 | Acc: 49.070,68.962,87.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.495 | Acc: 49.076,68.744,86.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.517 | Acc: 48.916,68.475,86.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.520 | Acc: 48.988,68.422,86.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.534 | Acc: 48.876,68.148,86.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.542 | Acc: 48.897,68.083,86.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.549 | Acc: 48.861,67.918,86.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.557 | Acc: 48.786,67.832,86.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.562 | Acc: 48.759,67.792,86.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.150 | Acc: 39.062,58.594,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.446 | Acc: 39.881,57.068,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.471 | Acc: 39.977,56.402,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.511 | Acc: 39.805,56.570,67.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 2.880 | Acc: 57.812,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.324 | Acc: 51.153,69.048,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.339 | Acc: 49.962,68.883,89.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.375 | Acc: 49.680,68.699,89.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.427 | Acc: 49.277,68.393,88.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.446 | Acc: 49.420,68.325,88.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.470 | Acc: 49.135,68.143,88.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.481 | Acc: 49.147,68.246,87.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.482 | Acc: 49.219,68.381,87.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.469 | Acc: 49.469,68.444,87.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.475 | Acc: 49.425,68.470,87.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.482 | Acc: 49.275,68.354,87.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.486 | Acc: 49.335,68.290,87.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.490 | Acc: 49.383,68.253,87.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.500 | Acc: 49.313,68.094,87.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.509 | Acc: 49.260,68.005,87.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.520 | Acc: 49.160,67.959,86.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.525 | Acc: 49.198,68.005,86.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.532 | Acc: 49.186,67.967,86.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.538 | Acc: 49.108,67.887,86.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.123 | Acc: 46.094,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.600 | Acc: 37.574,56.436,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.578 | Acc: 38.053,57.184,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.588 | Acc: 38.128,56.878,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 3.325 | Acc: 48.438,74.219,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.382 | Acc: 50.074,69.903,88.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.411 | Acc: 49.943,69.646,87.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.453 | Acc: 49.552,69.416,87.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.457 | Acc: 49.248,69.232,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.431 | Acc: 49.776,69.562,87.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.430 | Acc: 49.638,69.602,87.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.450 | Acc: 49.363,69.376,87.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.446 | Acc: 49.534,69.366,87.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.464 | Acc: 49.396,69.108,87.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.465 | Acc: 49.561,69.026,87.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.486 | Acc: 49.321,68.796,87.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.500 | Acc: 49.271,68.640,86.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.509 | Acc: 49.273,68.621,86.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.518 | Acc: 49.255,68.491,86.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.533 | Acc: 49.164,68.374,86.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.545 | Acc: 49.068,68.351,86.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.542 | Acc: 49.123,68.395,86.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.549 | Acc: 49.074,68.371,86.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.554 | Acc: 49.014,68.264,86.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.537 | Acc: 39.062,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.714 | Acc: 36.384,56.138,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.738 | Acc: 36.700,56.536,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.772 | Acc: 36.911,56.122,65.535,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 3.323 | Acc: 50.000,68.750,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.353 | Acc: 49.293,69.382,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.385 | Acc: 49.352,69.455,88.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.379 | Acc: 49.693,69.506,88.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.406 | Acc: 49.672,69.068,88.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.430 | Acc: 49.783,68.773,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.443 | Acc: 49.367,68.718,88.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.448 | Acc: 49.413,68.678,88.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.455 | Acc: 49.340,68.624,88.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.457 | Acc: 49.283,68.681,87.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.457 | Acc: 49.347,68.688,87.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.463 | Acc: 49.350,68.658,87.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.464 | Acc: 49.274,68.688,87.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.467 | Acc: 49.255,68.702,87.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.474 | Acc: 49.285,68.605,87.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.481 | Acc: 49.102,68.496,87.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.492 | Acc: 49.056,68.373,87.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.497 | Acc: 48.980,68.365,87.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.497 | Acc: 49.028,68.322,87.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.505 | Acc: 49.036,68.278,87.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.340 | Acc: 42.969,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.851 | Acc: 37.649,55.022,66.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.802 | Acc: 37.538,55.202,65.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.870 | Acc: 36.834,54.790,65.190,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 3.415 | Acc: 44.531,74.219,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.461 | Acc: 49.665,69.457,88.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.437 | Acc: 48.933,69.303,88.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.464 | Acc: 48.847,68.865,88.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.428 | Acc: 49.624,69.155,88.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.433 | Acc: 49.327,69.160,88.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.442 | Acc: 49.161,69.060,88.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.427 | Acc: 49.490,69.099,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.432 | Acc: 49.345,69.109,88.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.443 | Acc: 49.314,68.918,88.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.447 | Acc: 49.250,68.968,87.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.459 | Acc: 49.229,68.821,87.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.464 | Acc: 49.199,68.831,87.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.470 | Acc: 49.261,68.795,87.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.474 | Acc: 49.255,68.820,87.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.484 | Acc: 49.320,68.677,87.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.490 | Acc: 49.265,68.665,87.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.499 | Acc: 49.219,68.519,87.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.510 | Acc: 49.169,68.434,87.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.514 | Acc: 49.225,68.391,86.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.128 | Acc: 36.719,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.547 | Acc: 38.430,58.705,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.521 | Acc: 38.357,58.537,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.560 | Acc: 38.166,58.248,66.406,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 3.541 | Acc: 43.750,70.312,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.426 | Acc: 49.033,69.494,88.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.411 | Acc: 49.390,69.417,88.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.403 | Acc: 49.603,69.787,88.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.426 | Acc: 49.624,69.348,88.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.427 | Acc: 49.544,69.346,88.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.424 | Acc: 49.690,69.467,88.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.433 | Acc: 49.579,69.387,88.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.438 | Acc: 49.631,69.371,88.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.446 | Acc: 49.491,69.225,88.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.455 | Acc: 49.436,69.197,87.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.458 | Acc: 49.463,69.089,87.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.466 | Acc: 49.485,68.863,87.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.470 | Acc: 49.524,68.864,87.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.482 | Acc: 49.450,68.736,87.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.483 | Acc: 49.463,68.734,87.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.490 | Acc: 49.545,68.631,87.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.500 | Acc: 49.425,68.500,87.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.508 | Acc: 49.329,68.369,87.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.509 | Acc: 49.299,68.373,87.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.271 | Acc: 38.281,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.733 | Acc: 38.058,56.771,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.763 | Acc: 38.167,56.421,65.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.841 | Acc: 37.513,55.469,65.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 3.088 | Acc: 53.906,73.438,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.432 | Acc: 48.847,69.568,87.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.434 | Acc: 49.238,69.303,87.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.448 | Acc: 48.886,69.288,87.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.437 | Acc: 48.958,69.252,87.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.421 | Acc: 49.273,69.500,88.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.432 | Acc: 49.199,69.441,88.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.431 | Acc: 49.219,69.537,87.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.427 | Acc: 49.476,69.546,87.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.433 | Acc: 49.551,69.423,87.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.423 | Acc: 49.619,69.446,87.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.439 | Acc: 49.562,69.210,87.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.443 | Acc: 49.504,69.113,87.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.457 | Acc: 49.264,68.873,87.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.464 | Acc: 49.274,68.781,87.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.473 | Acc: 49.286,68.675,87.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.488 | Acc: 49.272,68.565,87.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.485 | Acc: 49.370,68.571,87.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.492 | Acc: 49.388,68.505,87.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.499 | Acc: 49.301,68.510,86.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.614 | Acc: 38.281,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.921 | Acc: 34.189,53.869,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.908 | Acc: 35.137,53.963,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.916 | Acc: 35.041,54.252,66.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 3.585 | Acc: 46.875,66.406,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.411 | Acc: 48.512,68.936,89.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.369 | Acc: 49.219,69.398,88.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.343 | Acc: 49.872,70.044,88.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.343 | Acc: 50.077,70.197,88.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.360 | Acc: 49.853,70.181,88.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.375 | Acc: 49.813,70.003,88.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.390 | Acc: 49.645,69.670,88.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.397 | Acc: 49.680,69.648,88.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.391 | Acc: 49.935,69.708,88.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.400 | Acc: 49.872,69.558,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.414 | Acc: 49.848,69.344,87.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.433 | Acc: 49.669,69.214,87.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.441 | Acc: 49.725,69.097,87.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.457 | Acc: 49.700,68.908,87.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.468 | Acc: 49.663,68.794,87.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.468 | Acc: 49.752,68.821,87.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.478 | Acc: 49.627,68.727,87.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.483 | Acc: 49.589,68.692,87.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.493 | Acc: 49.510,68.531,87.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.557 | Acc: 39.844,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.832 | Acc: 36.830,55.097,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.752 | Acc: 37.824,55.335,65.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.785 | Acc: 37.372,54.828,65.241,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 3.181 | Acc: 57.031,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.286 | Acc: 50.223,71.763,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.304 | Acc: 50.400,71.018,88.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.340 | Acc: 49.910,70.658,88.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.351 | Acc: 50.077,70.284,88.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.372 | Acc: 49.838,69.841,88.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.381 | Acc: 49.664,69.725,88.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.387 | Acc: 49.562,69.720,88.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.386 | Acc: 49.786,69.720,88.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.397 | Acc: 49.823,69.626,88.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.403 | Acc: 49.868,69.609,88.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.420 | Acc: 49.827,69.379,87.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.427 | Acc: 49.919,69.285,87.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.436 | Acc: 49.802,69.181,87.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.444 | Acc: 49.766,68.939,87.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.456 | Acc: 49.740,68.799,87.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.464 | Acc: 49.671,68.777,87.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.473 | Acc: 49.633,68.686,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.484 | Acc: 49.474,68.534,87.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.492 | Acc: 49.358,68.469,86.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.579 | Acc: 36.719,56.250,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.087 | Acc: 33.817,55.580,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.092 | Acc: 33.899,55.621,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.083 | Acc: 33.799,55.264,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 3.270 | Acc: 50.000,73.438,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.318 | Acc: 50.595,71.391,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.344 | Acc: 49.981,70.579,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.367 | Acc: 49.885,70.082,88.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.386 | Acc: 49.923,69.763,88.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.407 | Acc: 49.590,69.477,88.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.408 | Acc: 49.645,69.338,88.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.406 | Acc: 49.618,69.321,88.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.395 | Acc: 49.811,69.594,88.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.386 | Acc: 49.745,69.652,88.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.385 | Acc: 49.802,69.652,88.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.390 | Acc: 49.795,69.669,88.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.402 | Acc: 49.757,69.525,88.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.421 | Acc: 49.740,69.382,88.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.428 | Acc: 49.655,69.289,87.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.431 | Acc: 49.668,69.300,87.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.444 | Acc: 49.625,69.113,87.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.445 | Acc: 49.652,69.050,87.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.446 | Acc: 49.734,69.049,87.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.458 | Acc: 49.590,68.922,87.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.449 | Acc: 39.062,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.719 | Acc: 38.876,56.808,65.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.688 | Acc: 39.196,56.936,64.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.693 | Acc: 39.101,56.967,64.652,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 2.814 | Acc: 56.250,72.656,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.294 | Acc: 50.260,70.312,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.329 | Acc: 49.924,69.665,89.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.324 | Acc: 50.051,69.800,89.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.329 | Acc: 50.000,70.004,89.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.334 | Acc: 49.985,69.980,88.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.338 | Acc: 50.084,70.028,88.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.354 | Acc: 50.033,69.991,88.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.360 | Acc: 50.146,69.822,88.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.370 | Acc: 50.035,69.713,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.395 | Acc: 49.911,69.419,88.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.405 | Acc: 49.897,69.390,87.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.419 | Acc: 49.737,69.243,87.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.429 | Acc: 49.767,69.148,87.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.438 | Acc: 49.691,69.009,87.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.437 | Acc: 49.839,69.046,87.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.442 | Acc: 49.737,69.008,87.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.444 | Acc: 49.759,68.988,87.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.456 | Acc: 49.725,68.869,87.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.463 | Acc: 49.694,68.809,87.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.493 | Acc: 44.531,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.515 | Acc: 40.402,58.371,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.551 | Acc: 40.530,57.489,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.589 | Acc: 40.151,57.108,65.817,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 3.440 | Acc: 50.000,69.531,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.367 | Acc: 49.888,69.420,88.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.285 | Acc: 50.191,70.427,88.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.338 | Acc: 49.616,70.184,88.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.349 | Acc: 49.672,69.840,88.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.347 | Acc: 49.373,69.941,89.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.362 | Acc: 49.471,69.622,88.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.366 | Acc: 49.623,69.653,88.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.374 | Acc: 49.622,69.589,88.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.373 | Acc: 49.892,69.587,88.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.394 | Acc: 49.732,69.329,88.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.397 | Acc: 49.767,69.351,88.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.408 | Acc: 49.708,69.236,88.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.420 | Acc: 49.626,69.181,87.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.429 | Acc: 49.541,69.136,87.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.440 | Acc: 49.600,68.958,87.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.451 | Acc: 49.640,68.804,87.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.457 | Acc: 49.558,68.773,87.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.460 | Acc: 49.691,68.759,87.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.469 | Acc: 49.600,68.672,87.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.110 | Acc: 41.406,58.594,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.486 | Acc: 40.402,57.924,65.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.535 | Acc: 41.425,56.822,64.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.534 | Acc: 41.419,56.352,64.562,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 3.444 | Acc: 54.688,71.094,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.369 | Acc: 51.525,70.461,87.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.351 | Acc: 50.629,70.446,88.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.338 | Acc: 50.576,70.338,88.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.343 | Acc: 50.791,70.380,88.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.339 | Acc: 50.774,70.235,88.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.343 | Acc: 50.568,70.099,88.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.331 | Acc: 50.477,70.174,88.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.337 | Acc: 50.641,69.968,88.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.352 | Acc: 50.531,69.605,88.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.359 | Acc: 50.610,69.617,88.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.367 | Acc: 50.544,69.609,88.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.371 | Acc: 50.548,69.560,88.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.377 | Acc: 50.515,69.516,88.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.389 | Acc: 50.406,69.434,88.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.390 | Acc: 50.433,69.430,88.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.398 | Acc: 50.402,69.351,88.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.405 | Acc: 50.362,69.263,87.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.412 | Acc: 50.273,69.183,87.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.425 | Acc: 50.152,68.980,87.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.642 | Acc: 35.156,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.843 | Acc: 36.607,56.362,65.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.786 | Acc: 37.405,56.345,64.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.774 | Acc: 37.590,56.186,65.164,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 3.175 | Acc: 55.469,68.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.356 | Acc: 51.190,70.052,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.304 | Acc: 51.753,70.694,90.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.303 | Acc: 50.948,70.786,89.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.323 | Acc: 50.289,70.341,89.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.321 | Acc: 50.480,70.374,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.345 | Acc: 50.349,70.041,88.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.336 | Acc: 50.471,70.096,89.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.351 | Acc: 50.412,69.905,88.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.365 | Acc: 50.207,69.881,88.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.374 | Acc: 50.109,69.640,88.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.381 | Acc: 50.007,69.489,88.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.388 | Acc: 49.912,69.466,88.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.394 | Acc: 49.934,69.361,88.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.401 | Acc: 49.986,69.317,88.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.407 | Acc: 49.860,69.259,87.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.414 | Acc: 49.766,69.135,87.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.420 | Acc: 49.773,69.114,87.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.428 | Acc: 49.810,68.990,87.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.439 | Acc: 49.774,68.853,87.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.377 | Acc: 40.625,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.751 | Acc: 39.174,57.440,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.861 | Acc: 38.910,56.059,65.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.886 | Acc: 38.704,55.328,65.113,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 3.209 | Acc: 51.562,71.094,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.295 | Acc: 51.376,69.048,88.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.346 | Acc: 50.076,69.055,88.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.324 | Acc: 50.320,69.608,88.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.315 | Acc: 50.270,69.753,88.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.326 | Acc: 50.093,69.771,88.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.331 | Acc: 50.187,69.770,88.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.347 | Acc: 50.017,69.692,88.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.350 | Acc: 49.922,69.808,88.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.365 | Acc: 49.935,69.704,88.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.373 | Acc: 49.984,69.691,88.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.389 | Acc: 49.915,69.531,87.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.391 | Acc: 49.925,69.534,87.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.403 | Acc: 49.838,69.513,87.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.408 | Acc: 49.905,69.473,87.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.409 | Acc: 49.896,69.422,87.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.423 | Acc: 49.844,69.239,87.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.432 | Acc: 49.817,69.112,87.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.437 | Acc: 49.864,69.049,87.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.441 | Acc: 49.859,68.994,87.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.145 | Acc: 39.844,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.840 | Acc: 39.100,55.171,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.813 | Acc: 39.710,54.897,64.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.836 | Acc: 39.139,54.739,64.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 3.212 | Acc: 50.781,72.656,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.443 | Acc: 49.554,70.387,87.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.373 | Acc: 49.524,70.675,88.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.349 | Acc: 49.872,70.774,88.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.336 | Acc: 49.855,70.824,88.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.361 | Acc: 49.482,70.367,88.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.364 | Acc: 49.548,70.248,88.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.371 | Acc: 49.756,70.163,88.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.369 | Acc: 49.816,69.983,88.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.381 | Acc: 49.715,69.743,88.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.393 | Acc: 49.654,69.753,88.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.401 | Acc: 49.494,69.697,88.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.408 | Acc: 49.530,69.577,88.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.418 | Acc: 49.428,69.492,87.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.425 | Acc: 49.436,69.423,87.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.437 | Acc: 49.372,69.326,87.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.438 | Acc: 49.472,69.310,87.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.443 | Acc: 49.464,69.227,87.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.453 | Acc: 49.442,69.161,87.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.454 | Acc: 49.502,69.119,87.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.139 | Acc: 46.094,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.187 | Acc: 42.820,58.705,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.216 | Acc: 42.416,58.403,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.245 | Acc: 42.610,58.184,67.277,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 3.219 | Acc: 47.656,66.406,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.245 | Acc: 50.930,71.205,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.290 | Acc: 50.457,70.636,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.286 | Acc: 50.499,70.517,89.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.301 | Acc: 50.559,70.245,89.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.285 | Acc: 50.944,70.490,89.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.290 | Acc: 50.807,70.506,89.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.296 | Acc: 50.887,70.639,89.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.312 | Acc: 50.820,70.327,89.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.321 | Acc: 50.786,70.287,89.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.328 | Acc: 50.766,70.184,88.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.334 | Acc: 50.629,70.069,88.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.346 | Acc: 50.473,69.917,88.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.361 | Acc: 50.347,69.804,88.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.372 | Acc: 50.261,69.679,88.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.381 | Acc: 50.200,69.568,88.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.385 | Acc: 50.195,69.475,88.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.391 | Acc: 50.197,69.339,88.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.402 | Acc: 50.182,69.183,87.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.405 | Acc: 50.156,69.144,87.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.146 | Acc: 44.531,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.581 | Acc: 39.100,58.631,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.561 | Acc: 38.662,58.117,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.590 | Acc: 38.012,58.184,67.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 2.803 | Acc: 60.156,78.125,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.183 | Acc: 52.232,71.763,89.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.295 | Acc: 51.239,70.655,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.309 | Acc: 50.858,70.633,88.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.292 | Acc: 51.157,70.814,88.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.291 | Acc: 51.021,70.668,88.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.308 | Acc: 50.639,70.312,88.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.301 | Acc: 50.709,70.329,88.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.334 | Acc: 50.456,70.089,88.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.338 | Acc: 50.401,69.976,88.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.338 | Acc: 50.455,70.048,88.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.356 | Acc: 50.258,69.913,88.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.368 | Acc: 50.269,69.710,88.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.376 | Acc: 50.204,69.660,88.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.394 | Acc: 50.064,69.481,87.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.397 | Acc: 50.184,69.503,87.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.403 | Acc: 50.141,69.461,87.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.408 | Acc: 50.105,69.440,87.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.413 | Acc: 50.154,69.317,87.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.416 | Acc: 50.207,69.277,87.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.770 | Acc: 35.938,57.812,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.640 | Acc: 37.723,57.589,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.698 | Acc: 38.243,57.165,65.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.709 | Acc: 37.846,57.236,65.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 3.417 | Acc: 54.688,69.531,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.290 | Acc: 50.372,70.908,88.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.314 | Acc: 50.381,70.389,88.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.307 | Acc: 50.269,70.133,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.288 | Acc: 50.502,70.419,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.305 | Acc: 50.371,70.065,88.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.325 | Acc: 50.452,70.003,88.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.316 | Acc: 50.754,70.119,88.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.328 | Acc: 50.752,70.070,88.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.335 | Acc: 50.652,70.054,88.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.350 | Acc: 50.575,69.912,88.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.368 | Acc: 50.438,69.651,88.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.379 | Acc: 50.250,69.518,88.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.381 | Acc: 50.308,69.543,88.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.380 | Acc: 50.323,69.629,88.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.390 | Acc: 50.296,69.599,87.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.401 | Acc: 50.236,69.417,87.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.405 | Acc: 50.270,69.325,87.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.409 | Acc: 50.238,69.291,87.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.420 | Acc: 50.148,69.211,87.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.532 | Acc: 35.156,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.029 | Acc: 33.668,56.585,64.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.017 | Acc: 33.041,55.755,65.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.045 | Acc: 32.659,55.610,65.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 3.196 | Acc: 54.688,66.406,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.181 | Acc: 51.786,72.135,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.229 | Acc: 51.848,71.189,89.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.211 | Acc: 52.280,71.363,89.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.252 | Acc: 51.881,71.055,89.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.270 | Acc: 51.671,70.815,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.296 | Acc: 51.388,70.267,88.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.286 | Acc: 51.502,70.462,88.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.289 | Acc: 51.461,70.332,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.304 | Acc: 51.334,70.261,88.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.316 | Acc: 51.252,70.130,88.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.327 | Acc: 51.025,70.079,88.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.335 | Acc: 50.992,70.014,88.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.340 | Acc: 50.958,69.998,88.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.348 | Acc: 50.867,69.909,88.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.357 | Acc: 50.745,69.812,88.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.370 | Acc: 50.633,69.685,87.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.382 | Acc: 50.600,69.545,87.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.391 | Acc: 50.578,69.460,87.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.394 | Acc: 50.652,69.423,87.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.066 | Acc: 43.750,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.510 | Acc: 38.951,59.375,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.517 | Acc: 39.768,58.651,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.514 | Acc: 40.113,58.696,65.612,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 3.299 | Acc: 47.656,70.312,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.146 | Acc: 52.083,71.912,89.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.122 | Acc: 52.001,72.447,89.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.162 | Acc: 51.985,71.875,89.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.181 | Acc: 51.958,71.441,89.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.202 | Acc: 51.864,71.132,89.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.220 | Acc: 51.776,70.848,89.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.242 | Acc: 51.646,70.506,89.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.260 | Acc: 51.533,70.279,89.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.278 | Acc: 51.304,70.092,88.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.285 | Acc: 51.104,70.068,88.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.302 | Acc: 51.018,69.899,88.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.312 | Acc: 50.859,69.778,88.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.323 | Acc: 50.766,69.720,88.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.330 | Acc: 50.692,69.676,88.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.342 | Acc: 50.690,69.648,88.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.354 | Acc: 50.555,69.563,88.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.356 | Acc: 50.568,69.582,88.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.368 | Acc: 50.565,69.492,87.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.374 | Acc: 50.521,69.433,87.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.827 | Acc: 32.812,55.469,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.660 | Acc: 37.426,55.618,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.670 | Acc: 37.195,55.926,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.731 | Acc: 36.732,56.096,66.060,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 3.345 | Acc: 42.969,67.188,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.338 | Acc: 50.707,69.680,88.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.262 | Acc: 51.067,70.655,88.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.271 | Acc: 51.089,70.492,88.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.275 | Acc: 51.206,70.496,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.286 | Acc: 51.230,70.282,89.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.297 | Acc: 51.311,70.384,88.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.311 | Acc: 51.125,70.191,88.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.312 | Acc: 51.097,70.167,88.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.323 | Acc: 51.135,69.976,88.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.327 | Acc: 51.042,69.990,88.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.333 | Acc: 51.015,69.966,88.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.349 | Acc: 50.956,69.797,88.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.353 | Acc: 50.967,69.795,88.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.363 | Acc: 50.826,69.693,88.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.371 | Acc: 50.758,69.539,87.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.378 | Acc: 50.672,69.500,87.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.381 | Acc: 50.644,69.524,87.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.395 | Acc: 50.517,69.410,87.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.397 | Acc: 50.455,69.404,87.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.280 | Acc: 36.719,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.246 | Acc: 33.110,55.766,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.262 | Acc: 32.889,54.668,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.268 | Acc: 32.748,54.598,65.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 2.762 | Acc: 53.906,78.125,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.254 | Acc: 51.451,72.135,89.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.254 | Acc: 51.315,71.951,89.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.267 | Acc: 51.191,71.388,88.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.272 | Acc: 50.907,71.026,89.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.281 | Acc: 50.859,70.815,89.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.293 | Acc: 50.949,70.577,88.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.308 | Acc: 50.853,70.229,88.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.305 | Acc: 50.873,70.230,88.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.313 | Acc: 50.846,70.269,88.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.320 | Acc: 50.750,70.130,88.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.332 | Acc: 50.626,69.917,88.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.342 | Acc: 50.558,69.868,88.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.352 | Acc: 50.506,69.810,88.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.368 | Acc: 50.370,69.651,88.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.379 | Acc: 50.298,69.560,88.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.388 | Acc: 50.190,69.468,88.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.397 | Acc: 50.121,69.357,87.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.407 | Acc: 50.026,69.215,87.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.409 | Acc: 50.053,69.220,87.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.912 | Acc: 40.625,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.748 | Acc: 36.384,57.329,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.804 | Acc: 36.109,56.593,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.827 | Acc: 35.925,56.250,66.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 2.805 | Acc: 53.906,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.253 | Acc: 50.670,71.280,89.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.263 | Acc: 50.572,71.056,88.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.226 | Acc: 51.025,71.260,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.239 | Acc: 51.331,71.248,89.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.227 | Acc: 51.416,71.256,89.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.241 | Acc: 51.362,71.087,88.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.254 | Acc: 51.335,70.944,88.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.262 | Acc: 51.470,70.875,88.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.279 | Acc: 51.429,70.701,88.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.296 | Acc: 51.287,70.363,88.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.309 | Acc: 51.188,70.160,88.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.315 | Acc: 51.122,70.121,88.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.330 | Acc: 51.093,69.974,88.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.342 | Acc: 51.023,69.854,87.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.355 | Acc: 50.911,69.708,87.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.362 | Acc: 50.898,69.609,87.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.366 | Acc: 50.898,69.600,87.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.372 | Acc: 50.881,69.559,87.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.384 | Acc: 50.763,69.439,87.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.440 | Acc: 39.844,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.485 | Acc: 40.699,60.007,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.432 | Acc: 41.273,59.299,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.461 | Acc: 41.009,58.786,66.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 3.853 | Acc: 42.188,62.500,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.186 | Acc: 52.083,71.763,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.170 | Acc: 51.848,72.389,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.208 | Acc: 51.153,71.696,89.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.227 | Acc: 51.071,71.296,89.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.235 | Acc: 51.269,71.101,89.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.248 | Acc: 51.065,70.900,89.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.260 | Acc: 50.936,70.739,89.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.249 | Acc: 51.286,71.011,89.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.277 | Acc: 50.915,70.615,89.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.280 | Acc: 51.018,70.585,89.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.291 | Acc: 50.884,70.330,88.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.297 | Acc: 50.917,70.261,88.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.302 | Acc: 50.961,70.271,88.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.322 | Acc: 50.848,70.059,88.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.334 | Acc: 50.750,70.040,88.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.343 | Acc: 50.681,69.950,88.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.352 | Acc: 50.669,69.834,88.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.361 | Acc: 50.571,69.733,88.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.373 | Acc: 50.527,69.546,87.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.540 | Acc: 41.406,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.514 | Acc: 39.658,58.743,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.544 | Acc: 39.101,58.327,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.575 | Acc: 38.691,58.543,66.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 3.336 | Acc: 47.656,68.750,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.259 | Acc: 50.707,70.610,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.263 | Acc: 50.934,70.408,88.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.256 | Acc: 51.178,70.492,88.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.259 | Acc: 50.974,70.544,89.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.270 | Acc: 50.928,70.575,88.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.262 | Acc: 50.994,70.616,89.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.268 | Acc: 50.942,70.578,88.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.278 | Acc: 50.849,70.536,88.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.279 | Acc: 50.794,70.623,88.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.292 | Acc: 50.676,70.515,88.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.311 | Acc: 50.520,70.341,88.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.323 | Acc: 50.438,70.186,88.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.332 | Acc: 50.485,70.085,88.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.337 | Acc: 50.487,70.007,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.339 | Acc: 50.555,70.032,88.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.350 | Acc: 50.565,69.862,88.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.354 | Acc: 50.616,69.854,88.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.361 | Acc: 50.593,69.817,87.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.367 | Acc: 50.509,69.763,87.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.006 | Acc: 45.312,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.560 | Acc: 41.592,59.859,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.502 | Acc: 41.806,59.413,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.491 | Acc: 41.983,59.119,65.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.439 | Acc: 47.656,69.531,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.183 | Acc: 52.083,71.168,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.229 | Acc: 51.200,70.865,89.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.247 | Acc: 51.358,71.043,88.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.271 | Acc: 50.974,70.747,88.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.273 | Acc: 51.122,70.854,88.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.282 | Acc: 51.123,70.674,88.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.294 | Acc: 50.809,70.584,88.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.304 | Acc: 50.762,70.453,88.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.311 | Acc: 50.803,70.304,88.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.315 | Acc: 50.824,70.289,88.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.321 | Acc: 50.742,70.277,88.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.331 | Acc: 50.668,70.147,88.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.333 | Acc: 50.712,70.154,88.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.337 | Acc: 50.709,70.101,88.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.345 | Acc: 50.548,69.962,88.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.356 | Acc: 50.450,69.850,88.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.361 | Acc: 50.449,69.786,87.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.368 | Acc: 50.435,69.689,87.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.370 | Acc: 50.439,69.724,87.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.349 | Acc: 42.969,61.719,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.899 | Acc: 37.835,55.171,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.912 | Acc: 38.243,55.469,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.934 | Acc: 38.025,55.161,65.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 3.539 | Acc: 50.781,70.312,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.259 | Acc: 51.562,71.689,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.214 | Acc: 51.753,71.913,89.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.212 | Acc: 51.691,71.542,89.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.223 | Acc: 51.794,71.441,89.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.229 | Acc: 51.810,71.372,89.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.238 | Acc: 51.627,71.287,89.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.247 | Acc: 51.441,71.254,89.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.249 | Acc: 51.436,71.147,89.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.254 | Acc: 51.446,71.016,89.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.260 | Acc: 51.329,71.020,89.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.278 | Acc: 51.205,70.885,88.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.288 | Acc: 51.183,70.799,88.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.295 | Acc: 51.170,70.639,88.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.303 | Acc: 51.134,70.538,88.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.315 | Acc: 50.997,70.442,88.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.326 | Acc: 51.020,70.220,88.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.335 | Acc: 50.987,70.150,88.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.345 | Acc: 50.993,70.042,88.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.348 | Acc: 50.999,70.007,87.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.608 | Acc: 42.969,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.678 | Acc: 39.397,58.557,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.693 | Acc: 39.291,58.175,65.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.741 | Acc: 38.166,58.171,65.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 3.309 | Acc: 46.875,72.656,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.203 | Acc: 51.823,71.875,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.172 | Acc: 52.401,71.837,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.162 | Acc: 52.702,72.093,89.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.187 | Acc: 52.373,71.962,89.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.229 | Acc: 52.050,71.218,88.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.244 | Acc: 51.931,70.894,88.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.256 | Acc: 51.723,70.783,88.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.271 | Acc: 51.567,70.647,88.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.272 | Acc: 51.416,70.688,88.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.281 | Acc: 51.353,70.569,88.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.282 | Acc: 51.421,70.634,88.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.286 | Acc: 51.387,70.620,88.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.299 | Acc: 51.239,70.387,88.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.308 | Acc: 51.298,70.388,88.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.321 | Acc: 51.129,70.248,88.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.319 | Acc: 51.081,70.254,88.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.323 | Acc: 51.026,70.164,88.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.323 | Acc: 51.004,70.198,88.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.329 | Acc: 50.908,70.130,88.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.254 | Acc: 40.625,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.656 | Acc: 38.579,58.445,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.710 | Acc: 38.472,57.812,66.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.725 | Acc: 38.332,57.748,66.534,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 3.188 | Acc: 55.469,76.562,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.344 | Acc: 50.000,71.057,88.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.310 | Acc: 50.857,70.846,89.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.282 | Acc: 51.396,70.927,89.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.249 | Acc: 51.418,71.209,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.263 | Acc: 51.098,70.970,89.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.281 | Acc: 50.904,70.706,89.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.278 | Acc: 50.992,70.706,89.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.285 | Acc: 51.106,70.604,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.275 | Acc: 51.304,70.684,89.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.289 | Acc: 51.201,70.414,88.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.301 | Acc: 51.022,70.344,88.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.310 | Acc: 50.943,70.193,88.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.323 | Acc: 50.901,70.103,88.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.328 | Acc: 50.859,70.021,88.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.334 | Acc: 50.875,69.998,88.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.332 | Acc: 50.893,70.030,88.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.342 | Acc: 50.825,69.923,88.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.345 | Acc: 50.844,69.908,88.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.347 | Acc: 50.789,69.948,88.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.065 | Acc: 44.531,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.706 | Acc: 38.467,56.324,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.787 | Acc: 37.348,56.174,66.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.795 | Acc: 37.577,56.045,66.598,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 3.375 | Acc: 49.219,64.062,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.059 | Acc: 53.125,71.801,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.153 | Acc: 52.420,71.075,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.184 | Acc: 52.177,71.119,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.161 | Acc: 52.566,71.402,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.178 | Acc: 52.290,71.380,89.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.193 | Acc: 52.324,71.107,89.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.219 | Acc: 52.100,70.883,89.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.234 | Acc: 51.718,70.803,89.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.244 | Acc: 51.670,70.610,89.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.255 | Acc: 51.702,70.472,89.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.264 | Acc: 51.612,70.472,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.278 | Acc: 51.550,70.358,88.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.291 | Acc: 51.518,70.292,88.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.303 | Acc: 51.476,70.204,88.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.312 | Acc: 51.399,70.105,88.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.323 | Acc: 51.334,70.062,88.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.335 | Acc: 51.168,69.962,88.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.341 | Acc: 51.121,69.843,88.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.349 | Acc: 51.111,69.767,88.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.820 | Acc: 48.438,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.710 | Acc: 39.918,56.510,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.755 | Acc: 39.768,56.193,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.773 | Acc: 39.562,56.160,66.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 3.123 | Acc: 53.125,67.969,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.158 | Acc: 52.344,70.945,89.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.195 | Acc: 51.925,71.265,89.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.217 | Acc: 51.793,71.030,89.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.237 | Acc: 51.572,71.074,89.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.236 | Acc: 51.516,71.187,89.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.261 | Acc: 51.369,70.835,89.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.257 | Acc: 51.341,70.994,89.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.253 | Acc: 51.465,70.997,89.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.259 | Acc: 51.420,71.012,89.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.267 | Acc: 51.426,70.864,88.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.278 | Acc: 51.290,70.754,88.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.290 | Acc: 51.148,70.611,88.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.299 | Acc: 51.093,70.519,88.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.302 | Acc: 51.132,70.418,88.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.316 | Acc: 51.132,70.250,88.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.325 | Acc: 51.161,70.152,88.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.331 | Acc: 51.075,70.106,88.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.338 | Acc: 50.993,70.014,88.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.342 | Acc: 50.917,70.011,88.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.425 | Acc: 37.500,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.547 | Acc: 39.918,58.929,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.547 | Acc: 40.339,59.127,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.564 | Acc: 39.921,58.722,65.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 3.487 | Acc: 48.438,66.406,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.189 | Acc: 52.418,71.726,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.178 | Acc: 52.611,71.856,89.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.173 | Acc: 52.523,71.965,89.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.196 | Acc: 52.209,71.547,89.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.188 | Acc: 52.390,71.759,89.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.213 | Acc: 51.892,71.449,89.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.220 | Acc: 51.995,71.254,89.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.237 | Acc: 51.878,70.977,89.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.251 | Acc: 51.796,70.714,89.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.262 | Acc: 51.800,70.534,88.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.267 | Acc: 51.669,70.602,88.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.281 | Acc: 51.498,70.426,88.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.298 | Acc: 51.401,70.253,88.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.310 | Acc: 51.284,70.171,88.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.318 | Acc: 51.199,70.107,88.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.331 | Acc: 51.154,69.984,88.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.331 | Acc: 51.125,69.996,88.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.340 | Acc: 51.021,69.910,88.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.343 | Acc: 50.999,69.956,88.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.086 | Acc: 44.531,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.314 | Acc: 41.704,59.152,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.352 | Acc: 41.311,58.994,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.411 | Acc: 41.240,58.619,66.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 3.072 | Acc: 52.344,73.438,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.198 | Acc: 51.190,71.466,89.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.219 | Acc: 51.886,72.027,89.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.229 | Acc: 51.601,71.516,89.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.234 | Acc: 51.678,71.325,89.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.244 | Acc: 51.323,71.156,89.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.252 | Acc: 51.446,71.042,88.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.248 | Acc: 51.574,70.916,88.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.265 | Acc: 51.485,70.696,88.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.276 | Acc: 51.368,70.425,88.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.279 | Acc: 51.302,70.511,88.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.284 | Acc: 51.308,70.468,88.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.291 | Acc: 51.248,70.403,88.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.298 | Acc: 51.209,70.277,88.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.299 | Acc: 51.284,70.276,88.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.305 | Acc: 51.311,70.162,88.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.306 | Acc: 51.307,70.244,88.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.323 | Acc: 51.150,70.072,88.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.334 | Acc: 51.119,70.055,88.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.340 | Acc: 51.126,69.960,88.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.240 | Acc: 37.500,54.688,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.074 | Acc: 36.905,53.943,63.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.045 | Acc: 36.986,53.563,64.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.050 | Acc: 36.898,53.279,64.127,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 3.018 | Acc: 53.906,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.112 | Acc: 52.790,73.028,89.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.175 | Acc: 51.753,71.913,89.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.191 | Acc: 51.972,71.696,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.188 | Acc: 52.141,71.721,89.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.225 | Acc: 51.501,71.364,89.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.225 | Acc: 51.453,71.307,89.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.251 | Acc: 51.208,71.088,89.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.254 | Acc: 51.242,71.055,89.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.261 | Acc: 51.127,70.960,89.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.279 | Acc: 50.968,70.814,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.278 | Acc: 51.124,70.804,89.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.287 | Acc: 51.034,70.682,89.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.303 | Acc: 50.994,70.495,88.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.305 | Acc: 50.951,70.543,88.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.315 | Acc: 50.937,70.344,88.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.319 | Acc: 50.998,70.271,88.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.323 | Acc: 51.001,70.228,88.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.328 | Acc: 51.019,70.191,88.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.335 | Acc: 50.927,70.112,88.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.670 | Acc: 34.375,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.980 | Acc: 32.999,56.250,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.045 | Acc: 33.441,55.736,65.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.061 | Acc: 33.043,55.507,65.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 3.514 | Acc: 48.438,70.312,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.306 | Acc: 51.525,70.945,88.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.265 | Acc: 52.001,71.246,88.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.259 | Acc: 52.203,71.593,88.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.251 | Acc: 52.103,71.383,89.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.246 | Acc: 51.880,71.094,89.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.242 | Acc: 51.963,71.081,89.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.244 | Acc: 51.884,71.144,89.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.248 | Acc: 51.684,71.026,89.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.263 | Acc: 51.640,70.770,89.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.262 | Acc: 51.780,70.806,89.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.265 | Acc: 51.778,70.765,89.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.273 | Acc: 51.702,70.666,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.284 | Acc: 51.586,70.534,88.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.286 | Acc: 51.574,70.513,88.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.283 | Acc: 51.679,70.497,88.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.287 | Acc: 51.631,70.403,88.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.296 | Acc: 51.590,70.274,88.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.305 | Acc: 51.418,70.139,88.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.312 | Acc: 51.376,70.042,88.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.015 | Acc: 47.656,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.570 | Acc: 39.807,58.222,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.559 | Acc: 39.748,58.727,66.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.607 | Acc: 39.882,58.478,66.060,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.806 | Acc: 59.375,76.562,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.160 | Acc: 52.158,72.991,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.094 | Acc: 53.716,72.790,89.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.159 | Acc: 52.907,72.003,89.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.167 | Acc: 53.260,71.653,89.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.194 | Acc: 52.769,71.465,89.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.192 | Acc: 52.822,71.501,89.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.195 | Acc: 52.654,71.376,89.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.204 | Acc: 52.548,71.302,89.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.214 | Acc: 52.383,71.348,89.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.230 | Acc: 52.247,71.160,89.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.248 | Acc: 52.093,70.924,88.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.265 | Acc: 51.887,70.640,88.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.275 | Acc: 51.775,70.471,88.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.287 | Acc: 51.643,70.357,88.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.287 | Acc: 51.752,70.429,88.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.287 | Acc: 51.713,70.446,88.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.297 | Acc: 51.562,70.377,88.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.302 | Acc: 51.543,70.325,88.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.309 | Acc: 51.464,70.298,88.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.266 | Acc: 39.844,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.695 | Acc: 38.839,58.594,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.701 | Acc: 39.348,58.384,65.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.749 | Acc: 39.165,57.800,65.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 3.328 | Acc: 50.781,70.312,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.222 | Acc: 51.674,69.866,88.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.193 | Acc: 52.649,70.846,88.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.199 | Acc: 52.766,71.107,88.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.227 | Acc: 52.160,70.843,88.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.248 | Acc: 52.166,70.862,88.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.241 | Acc: 52.169,71.036,88.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.249 | Acc: 52.078,70.988,88.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.238 | Acc: 52.106,71.162,89.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.247 | Acc: 52.024,71.180,88.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.250 | Acc: 51.901,71.160,88.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.251 | Acc: 51.888,71.157,88.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.259 | Acc: 51.747,70.909,88.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.270 | Acc: 51.649,70.881,88.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.268 | Acc: 51.682,70.841,88.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.280 | Acc: 51.456,70.676,88.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.282 | Acc: 51.482,70.590,88.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.286 | Acc: 51.459,70.539,88.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.293 | Acc: 51.450,70.399,88.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.297 | Acc: 51.425,70.390,88.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.124 | Acc: 42.188,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.455 | Acc: 41.667,58.110,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.471 | Acc: 41.768,57.222,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.448 | Acc: 41.829,57.300,67.367,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 3.134 | Acc: 54.688,75.000,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.245 | Acc: 51.972,70.759,89.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.202 | Acc: 51.963,71.265,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.211 | Acc: 51.819,71.606,89.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.223 | Acc: 51.804,71.518,89.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.236 | Acc: 51.470,71.334,89.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.237 | Acc: 51.375,71.216,89.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.250 | Acc: 51.114,70.977,89.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.243 | Acc: 51.446,71.021,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.263 | Acc: 51.200,70.779,89.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.275 | Acc: 51.081,70.686,89.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.279 | Acc: 51.039,70.627,88.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.278 | Acc: 51.054,70.633,88.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.282 | Acc: 51.024,70.528,88.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.291 | Acc: 51.048,70.488,88.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.301 | Acc: 51.088,70.422,88.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.303 | Acc: 51.073,70.390,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.311 | Acc: 50.983,70.356,88.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.311 | Acc: 51.054,70.347,88.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.315 | Acc: 50.956,70.278,88.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.006 | Acc: 33.594,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.483 | Acc: 32.292,52.902,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.549 | Acc: 31.898,52.401,66.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.562 | Acc: 31.340,52.062,65.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 3.129 | Acc: 52.344,77.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.243 | Acc: 50.670,72.173,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.209 | Acc: 51.334,71.970,89.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.180 | Acc: 51.716,71.798,89.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.142 | Acc: 52.247,72.145,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.159 | Acc: 51.856,71.945,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.171 | Acc: 51.879,71.720,89.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.186 | Acc: 51.795,71.570,89.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.190 | Acc: 51.849,71.487,89.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.209 | Acc: 51.765,71.297,89.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.219 | Acc: 51.753,71.311,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.237 | Acc: 51.573,71.154,89.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.242 | Acc: 51.624,71.071,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.250 | Acc: 51.539,70.956,89.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.266 | Acc: 51.493,70.857,88.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.275 | Acc: 51.409,70.751,88.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.280 | Acc: 51.421,70.768,88.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.289 | Acc: 51.329,70.656,88.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.301 | Acc: 51.281,70.501,88.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.313 | Acc: 51.152,70.341,88.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.206 | Acc: 39.062,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.831 | Acc: 35.751,57.254,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.862 | Acc: 35.976,56.155,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.864 | Acc: 36.066,55.994,65.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 3.437 | Acc: 49.219,64.844,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.218 | Acc: 51.190,71.987,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.223 | Acc: 51.448,71.608,89.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.228 | Acc: 51.614,71.568,89.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.238 | Acc: 51.427,71.277,89.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.242 | Acc: 51.330,71.194,89.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.233 | Acc: 51.659,71.339,89.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.226 | Acc: 51.718,71.315,89.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.220 | Acc: 51.897,71.346,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.222 | Acc: 51.865,71.292,89.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.232 | Acc: 51.870,71.308,89.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.244 | Acc: 51.743,71.115,88.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.255 | Acc: 51.559,70.971,88.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.271 | Acc: 51.296,70.815,88.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.283 | Acc: 51.201,70.646,88.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.284 | Acc: 51.274,70.582,88.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.284 | Acc: 51.353,70.590,88.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.286 | Acc: 51.391,70.590,88.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.295 | Acc: 51.333,70.568,88.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.296 | Acc: 51.345,70.499,88.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.049 | Acc: 33.594,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.722 | Acc: 29.464,52.455,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.658 | Acc: 30.945,52.058,64.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.671 | Acc: 30.622,51.998,63.614,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 3.083 | Acc: 55.469,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.184 | Acc: 51.711,71.243,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.173 | Acc: 51.429,71.665,89.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.158 | Acc: 51.562,72.093,89.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.177 | Acc: 51.350,71.595,89.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.182 | Acc: 51.346,71.697,89.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.194 | Acc: 51.337,71.617,89.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.202 | Acc: 51.186,71.443,89.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.202 | Acc: 51.271,71.467,89.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.208 | Acc: 51.489,71.392,89.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.211 | Acc: 51.520,71.292,89.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.225 | Acc: 51.488,71.143,89.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.242 | Acc: 51.468,70.909,89.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.256 | Acc: 51.338,70.675,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.252 | Acc: 51.429,70.710,89.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.269 | Acc: 51.295,70.533,88.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.271 | Acc: 51.378,70.512,88.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.277 | Acc: 51.414,70.409,88.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.281 | Acc: 51.454,70.401,88.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.282 | Acc: 51.470,70.423,88.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.282 | Acc: 44.531,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.583 | Acc: 39.360,58.519,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.569 | Acc: 39.329,58.270,65.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.634 | Acc: 38.794,57.851,65.215,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 3.030 | Acc: 52.344,71.094,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.124 | Acc: 51.711,71.949,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.145 | Acc: 51.848,71.151,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.187 | Acc: 51.498,71.004,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.186 | Acc: 51.833,70.968,89.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.187 | Acc: 52.019,71.040,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.197 | Acc: 51.885,71.178,89.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.227 | Acc: 51.607,70.988,89.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.231 | Acc: 51.698,70.875,89.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.232 | Acc: 51.727,70.921,89.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.239 | Acc: 51.702,70.958,89.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.240 | Acc: 51.722,70.995,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.245 | Acc: 51.653,70.951,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.246 | Acc: 51.682,70.962,88.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.265 | Acc: 51.588,70.746,88.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.276 | Acc: 51.508,70.634,88.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.282 | Acc: 51.521,70.544,88.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.293 | Acc: 51.395,70.427,88.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.301 | Acc: 51.322,70.332,88.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.308 | Acc: 51.224,70.259,88.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.733 | Acc: 42.969,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.638 | Acc: 39.435,57.701,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.606 | Acc: 39.787,57.984,66.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.647 | Acc: 39.549,57.979,65.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 3.144 | Acc: 53.906,76.562,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.163 | Acc: 51.079,72.210,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.167 | Acc: 52.039,72.237,88.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.163 | Acc: 51.895,72.349,89.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.175 | Acc: 51.881,72.020,89.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.173 | Acc: 52.034,71.790,89.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.189 | Acc: 51.918,71.817,89.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.212 | Acc: 51.751,71.598,89.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.215 | Acc: 51.645,71.618,89.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.219 | Acc: 51.670,71.448,89.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.229 | Acc: 51.485,71.385,89.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.239 | Acc: 51.329,71.274,89.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.250 | Acc: 51.232,71.304,89.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.254 | Acc: 51.272,71.169,88.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.266 | Acc: 51.298,71.019,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.272 | Acc: 51.389,70.972,88.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.283 | Acc: 51.331,70.897,88.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.289 | Acc: 51.310,70.878,88.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.296 | Acc: 51.409,70.821,88.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.301 | Acc: 51.378,70.704,88.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.908 | Acc: 30.469,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.919 | Acc: 35.417,57.664,65.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.873 | Acc: 35.938,57.641,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.896 | Acc: 35.861,57.441,65.484,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 3.382 | Acc: 47.656,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.063 | Acc: 53.088,73.438,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.136 | Acc: 52.477,72.809,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.126 | Acc: 52.766,72.695,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.161 | Acc: 52.276,72.213,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.177 | Acc: 52.034,71.952,90.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.172 | Acc: 52.240,71.959,90.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.167 | Acc: 52.355,71.875,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.175 | Acc: 52.305,71.817,90.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.193 | Acc: 52.162,71.586,89.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.187 | Acc: 52.177,71.634,89.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.196 | Acc: 52.061,71.567,89.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.204 | Acc: 51.971,71.418,89.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.219 | Acc: 51.850,71.309,89.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.225 | Acc: 51.849,71.138,89.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.232 | Acc: 51.851,71.115,89.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.240 | Acc: 51.801,71.055,89.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.247 | Acc: 51.679,70.984,89.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.256 | Acc: 51.660,70.901,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.267 | Acc: 51.562,70.774,88.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.344 | Acc: 36.719,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.990 | Acc: 35.231,55.692,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.941 | Acc: 36.090,56.231,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.944 | Acc: 36.245,55.776,66.086,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 3.091 | Acc: 52.344,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.148 | Acc: 51.674,71.280,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.129 | Acc: 51.944,72.485,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.132 | Acc: 52.241,72.157,89.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.147 | Acc: 52.093,71.923,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.143 | Acc: 51.918,71.921,90.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.144 | Acc: 52.247,71.830,89.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.156 | Acc: 52.172,71.720,89.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.173 | Acc: 51.839,71.429,89.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.186 | Acc: 51.804,71.275,89.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.197 | Acc: 51.734,71.113,89.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.205 | Acc: 51.760,71.094,89.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.218 | Acc: 51.624,70.977,89.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.222 | Acc: 51.754,70.917,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.240 | Acc: 51.557,70.755,89.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.252 | Acc: 51.412,70.728,88.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.273 | Acc: 51.309,70.566,88.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.281 | Acc: 51.306,70.526,88.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.289 | Acc: 51.277,70.479,88.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.296 | Acc: 51.253,70.405,88.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.171 | Acc: 42.188,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.362 | Acc: 40.774,58.333,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.356 | Acc: 41.444,58.841,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.380 | Acc: 41.560,58.645,66.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 3.053 | Acc: 50.781,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.064 | Acc: 53.534,72.247,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.088 | Acc: 52.630,72.066,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.132 | Acc: 52.126,72.131,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.128 | Acc: 52.267,72.039,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.152 | Acc: 52.073,71.720,89.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.180 | Acc: 51.860,71.358,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.190 | Acc: 51.729,71.254,89.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.213 | Acc: 51.499,71.128,89.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.221 | Acc: 51.416,71.150,89.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.226 | Acc: 51.613,71.140,89.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.230 | Acc: 51.616,71.161,89.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.236 | Acc: 51.543,71.081,89.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.233 | Acc: 51.661,71.142,89.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.244 | Acc: 51.596,70.971,89.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.249 | Acc: 51.516,70.878,89.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.253 | Acc: 51.485,70.790,88.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.253 | Acc: 51.519,70.798,88.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.261 | Acc: 51.469,70.624,88.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.265 | Acc: 51.474,70.552,88.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.750 | Acc: 39.062,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.115 | Acc: 32.775,54.353,66.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.089 | Acc: 33.479,55.335,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.099 | Acc: 33.811,55.264,65.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 3.617 | Acc: 51.562,70.312,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.090 | Acc: 53.683,73.549,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.101 | Acc: 53.258,73.552,89.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.097 | Acc: 52.946,73.117,89.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.080 | Acc: 53.713,73.052,90.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.096 | Acc: 53.504,72.834,89.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.108 | Acc: 53.661,72.792,89.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.122 | Acc: 53.441,72.673,89.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.133 | Acc: 53.275,72.462,89.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.149 | Acc: 53.121,72.238,89.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.169 | Acc: 52.880,72.054,89.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.179 | Acc: 52.771,71.857,89.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.190 | Acc: 52.704,71.872,89.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.199 | Acc: 52.589,71.737,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.215 | Acc: 52.505,71.516,88.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.217 | Acc: 52.416,71.569,88.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.228 | Acc: 52.332,71.478,88.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.239 | Acc: 52.193,71.362,88.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.249 | Acc: 52.134,71.174,88.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.260 | Acc: 52.067,70.950,88.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.304 | Acc: 44.531,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.682 | Acc: 38.765,58.371,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.702 | Acc: 37.805,57.698,65.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.728 | Acc: 37.692,57.723,65.330,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 3.176 | Acc: 56.250,75.781,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.184 | Acc: 51.897,71.391,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.168 | Acc: 52.306,72.008,90.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.187 | Acc: 51.947,71.644,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.187 | Acc: 52.045,71.576,89.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.183 | Acc: 51.996,71.852,89.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.180 | Acc: 51.924,71.823,89.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.194 | Acc: 51.817,71.604,89.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.199 | Acc: 51.800,71.555,89.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.215 | Acc: 51.649,71.461,89.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.218 | Acc: 51.702,71.381,89.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.232 | Acc: 51.587,71.217,89.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.242 | Acc: 51.546,71.181,89.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.248 | Acc: 51.557,71.070,88.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.260 | Acc: 51.415,70.960,88.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.266 | Acc: 51.435,70.871,88.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.278 | Acc: 51.370,70.736,88.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.281 | Acc: 51.434,70.711,88.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.282 | Acc: 51.493,70.752,88.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.286 | Acc: 51.517,70.747,88.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.215 | Acc: 43.750,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.603 | Acc: 40.253,57.366,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.581 | Acc: 40.511,57.698,65.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.582 | Acc: 40.484,57.480,65.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 3.128 | Acc: 51.562,69.531,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.068 | Acc: 52.939,73.251,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.107 | Acc: 52.172,72.790,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.091 | Acc: 52.549,72.797,90.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.103 | Acc: 52.296,72.830,90.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.107 | Acc: 52.313,72.679,90.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.114 | Acc: 52.279,72.469,90.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.133 | Acc: 52.161,72.302,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.145 | Acc: 52.242,72.152,89.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.165 | Acc: 52.085,72.017,89.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.171 | Acc: 52.056,71.875,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.181 | Acc: 52.061,71.769,89.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.200 | Acc: 51.922,71.528,89.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.211 | Acc: 51.811,71.342,89.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.221 | Acc: 51.718,71.141,89.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.227 | Acc: 51.742,71.140,88.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.236 | Acc: 51.718,71.018,88.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.247 | Acc: 51.650,70.881,88.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.254 | Acc: 51.593,70.825,88.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.262 | Acc: 51.534,70.682,88.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.569 | Acc: 37.500,57.031,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.687 | Acc: 37.835,58.296,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.696 | Acc: 37.500,57.355,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.706 | Acc: 37.321,57.364,65.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 3.127 | Acc: 53.125,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.039 | Acc: 53.646,74.070,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.117 | Acc: 52.896,72.580,89.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.103 | Acc: 53.189,72.605,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.139 | Acc: 52.633,72.309,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.132 | Acc: 52.491,72.184,89.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.144 | Acc: 52.253,71.920,89.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.166 | Acc: 51.934,71.581,89.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.178 | Acc: 51.892,71.472,89.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.200 | Acc: 51.770,71.258,89.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.202 | Acc: 51.780,71.381,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.216 | Acc: 51.658,71.228,88.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.227 | Acc: 51.582,71.032,88.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.240 | Acc: 51.488,70.866,88.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.239 | Acc: 51.504,70.913,88.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.246 | Acc: 51.474,70.842,88.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.256 | Acc: 51.424,70.763,88.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.261 | Acc: 51.384,70.709,88.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.268 | Acc: 51.400,70.587,88.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.277 | Acc: 51.405,70.487,88.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.666 | Acc: 40.625,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.677 | Acc: 39.025,56.101,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.632 | Acc: 39.310,56.517,67.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.666 | Acc: 38.922,56.135,67.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 3.096 | Acc: 55.469,72.656,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.091 | Acc: 51.600,71.019,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.128 | Acc: 52.420,70.922,89.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.141 | Acc: 52.164,71.145,89.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.139 | Acc: 52.286,71.740,89.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.134 | Acc: 52.529,71.906,89.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.129 | Acc: 52.596,72.114,89.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.131 | Acc: 52.732,72.025,89.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.157 | Acc: 52.518,71.720,89.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.164 | Acc: 52.478,71.603,89.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.172 | Acc: 52.429,71.591,89.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.188 | Acc: 52.156,71.433,89.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.198 | Acc: 52.020,71.304,89.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.204 | Acc: 52.080,71.291,89.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.220 | Acc: 51.993,71.169,89.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.228 | Acc: 51.944,71.133,89.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.231 | Acc: 51.967,71.096,89.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.235 | Acc: 51.970,71.107,88.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.240 | Acc: 51.900,71.001,88.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.245 | Acc: 51.882,70.924,88.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.698 | Acc: 39.844,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.135 | Acc: 35.603,55.246,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.059 | Acc: 35.747,55.373,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.081 | Acc: 35.540,55.443,65.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.646 | Acc: 56.250,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.198 | Acc: 52.009,71.652,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.179 | Acc: 51.810,71.837,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.184 | Acc: 51.447,71.644,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.174 | Acc: 51.495,71.971,90.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.169 | Acc: 51.617,71.929,90.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.174 | Acc: 51.743,71.836,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.178 | Acc: 51.917,71.720,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.189 | Acc: 51.810,71.618,89.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.196 | Acc: 51.744,71.504,89.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.195 | Acc: 51.870,71.482,89.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.197 | Acc: 51.877,71.461,89.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.204 | Acc: 51.815,71.334,89.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.215 | Acc: 51.730,71.184,89.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.224 | Acc: 51.790,71.083,89.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.231 | Acc: 51.739,71.008,89.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.236 | Acc: 51.682,70.931,89.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.238 | Acc: 51.750,70.965,89.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.251 | Acc: 51.775,70.752,88.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.264 | Acc: 51.702,70.630,88.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.207 | Acc: 46.094,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.520 | Acc: 40.253,58.668,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.490 | Acc: 40.682,59.146,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.525 | Acc: 40.740,58.965,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 2.952 | Acc: 50.781,71.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.048 | Acc: 53.311,73.140,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.047 | Acc: 53.296,73.056,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.025 | Acc: 53.560,73.373,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.043 | Acc: 53.607,73.110,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.079 | Acc: 53.249,72.726,90.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.086 | Acc: 53.106,72.618,90.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.095 | Acc: 52.998,72.484,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.120 | Acc: 52.713,72.220,89.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.137 | Acc: 52.430,71.953,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.151 | Acc: 52.476,71.801,89.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.174 | Acc: 52.245,71.440,89.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.189 | Acc: 52.198,71.266,89.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.191 | Acc: 52.206,71.291,89.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.203 | Acc: 52.105,71.180,89.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.208 | Acc: 52.050,71.174,89.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.215 | Acc: 52.081,71.096,89.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.217 | Acc: 52.163,70.979,89.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.222 | Acc: 52.117,70.877,89.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.235 | Acc: 51.989,70.741,88.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.125 | Acc: 46.875,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.679 | Acc: 38.765,58.557,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.684 | Acc: 38.834,57.984,66.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.731 | Acc: 38.525,57.992,66.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 3.071 | Acc: 53.906,71.094,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.185 | Acc: 52.902,70.461,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.168 | Acc: 53.296,71.589,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.146 | Acc: 53.368,72.016,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.147 | Acc: 53.048,72.029,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.177 | Acc: 52.785,71.813,89.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.190 | Acc: 52.731,71.481,89.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.203 | Acc: 52.527,71.448,89.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.188 | Acc: 52.892,71.555,89.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.182 | Acc: 52.862,71.586,89.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.194 | Acc: 52.736,71.486,89.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.211 | Acc: 52.538,71.239,89.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.218 | Acc: 52.503,71.201,89.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.218 | Acc: 52.484,71.225,88.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.217 | Acc: 52.541,71.194,88.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.222 | Acc: 52.507,71.203,88.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.226 | Acc: 52.378,71.198,88.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.239 | Acc: 52.266,71.066,88.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.241 | Acc: 52.242,71.044,88.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.246 | Acc: 52.213,70.973,88.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.458 | Acc: 37.500,56.250,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.922 | Acc: 31.957,50.707,62.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.963 | Acc: 31.784,50.305,61.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.052 | Acc: 31.160,49.424,61.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 3.031 | Acc: 53.125,70.312,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.131 | Acc: 53.348,71.577,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.110 | Acc: 53.277,72.104,89.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.129 | Acc: 53.048,72.323,89.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.147 | Acc: 52.623,71.827,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.142 | Acc: 52.591,72.061,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.144 | Acc: 52.589,72.049,89.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.147 | Acc: 52.565,72.008,89.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.151 | Acc: 52.514,71.865,89.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.165 | Acc: 52.525,71.668,89.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.172 | Acc: 52.421,71.428,89.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.177 | Acc: 52.404,71.408,89.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.180 | Acc: 52.464,71.460,89.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.187 | Acc: 52.499,71.378,89.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.203 | Acc: 52.397,71.227,89.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.211 | Acc: 52.377,71.195,88.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.213 | Acc: 52.361,71.140,88.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.225 | Acc: 52.243,70.931,88.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.233 | Acc: 52.117,70.856,88.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.245 | Acc: 51.966,70.725,88.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.135 | Acc: 46.875,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.466 | Acc: 42.188,58.482,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.533 | Acc: 42.607,58.270,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.561 | Acc: 42.277,58.120,66.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 3.011 | Acc: 53.906,77.344,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.078 | Acc: 52.902,72.954,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.124 | Acc: 53.201,72.485,89.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.096 | Acc: 53.112,72.426,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.107 | Acc: 52.739,72.367,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.107 | Acc: 52.630,72.254,90.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.137 | Acc: 52.505,71.823,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.152 | Acc: 52.438,71.725,89.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.175 | Acc: 52.373,71.613,89.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.192 | Acc: 52.314,71.413,89.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.208 | Acc: 52.095,71.284,89.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.222 | Acc: 51.962,71.182,89.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.220 | Acc: 51.971,71.227,89.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.226 | Acc: 51.898,71.106,89.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.228 | Acc: 51.874,71.094,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.232 | Acc: 51.801,71.042,89.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.233 | Acc: 51.901,71.013,88.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.237 | Acc: 51.931,70.901,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.237 | Acc: 51.976,70.875,88.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.241 | Acc: 51.960,70.901,88.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.955 | Acc: 36.719,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.072 | Acc: 35.900,55.841,66.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.111 | Acc: 35.537,55.050,65.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.097 | Acc: 35.720,55.123,65.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 3.109 | Acc: 51.562,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.225 | Acc: 51.860,70.833,88.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.222 | Acc: 51.562,70.522,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.158 | Acc: 52.011,71.619,89.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.116 | Acc: 52.672,72.261,89.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.138 | Acc: 52.638,71.921,89.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.125 | Acc: 52.699,72.185,90.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.123 | Acc: 52.599,72.257,90.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.141 | Acc: 52.606,72.055,89.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.146 | Acc: 52.655,71.901,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.157 | Acc: 52.600,71.824,89.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.170 | Acc: 52.524,71.592,89.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.181 | Acc: 52.399,71.428,89.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.195 | Acc: 52.179,71.294,89.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.207 | Acc: 52.102,71.113,89.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.216 | Acc: 51.991,71.034,89.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.225 | Acc: 51.984,70.931,89.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.229 | Acc: 51.936,70.938,89.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.234 | Acc: 51.972,70.942,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.242 | Acc: 51.903,70.880,88.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.721 | Acc: 37.500,62.500,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.755 | Acc: 39.397,59.040,65.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.845 | Acc: 38.377,57.812,64.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.866 | Acc: 38.025,57.812,64.831,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 3.163 | Acc: 52.344,70.312,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.220 | Acc: 53.646,71.280,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.112 | Acc: 53.582,72.752,89.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.136 | Acc: 53.227,72.528,89.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.153 | Acc: 53.019,72.135,89.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.162 | Acc: 52.808,72.022,89.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.139 | Acc: 53.222,72.308,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.144 | Acc: 52.998,72.202,89.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.156 | Acc: 52.800,72.224,89.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.175 | Acc: 52.659,72.013,89.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.195 | Acc: 52.561,71.778,89.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.207 | Acc: 52.407,71.486,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.212 | Acc: 52.308,71.444,89.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.215 | Acc: 52.251,71.387,89.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.218 | Acc: 52.205,71.244,89.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.223 | Acc: 52.232,71.211,89.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.230 | Acc: 52.178,71.123,89.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.236 | Acc: 52.142,71.025,88.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.240 | Acc: 52.134,70.957,88.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.247 | Acc: 52.096,70.899,88.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.121 | Acc: 48.438,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.462 | Acc: 43.192,57.775,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.366 | Acc: 44.036,58.708,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.405 | Acc: 43.558,59.068,66.022,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 3.299 | Acc: 48.438,71.875,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.941 | Acc: 55.915,74.628,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.985 | Acc: 54.421,74.104,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.019 | Acc: 54.009,73.642,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.049 | Acc: 53.347,73.177,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.071 | Acc: 53.079,72.857,90.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.097 | Acc: 52.854,72.469,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.118 | Acc: 52.743,72.207,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.141 | Acc: 52.363,71.987,89.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.150 | Acc: 52.383,71.922,89.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.168 | Acc: 52.285,71.704,89.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.187 | Acc: 52.160,71.603,89.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.196 | Acc: 52.208,71.489,89.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.201 | Acc: 52.086,71.456,89.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.198 | Acc: 52.132,71.477,89.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.214 | Acc: 51.947,71.330,89.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.219 | Acc: 51.940,71.206,89.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.219 | Acc: 51.899,71.181,89.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.224 | Acc: 51.865,71.174,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.230 | Acc: 51.833,71.071,89.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.061 | Acc: 46.094,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.343 | Acc: 41.778,60.193,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.326 | Acc: 41.730,60.652,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.378 | Acc: 41.675,60.489,67.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.904 | Acc: 57.031,82.031,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.065 | Acc: 52.493,73.735,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.111 | Acc: 51.925,72.409,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.129 | Acc: 52.075,72.041,90.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.130 | Acc: 52.402,72.126,89.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.138 | Acc: 52.297,72.030,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.146 | Acc: 52.376,71.894,89.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.147 | Acc: 52.416,71.997,89.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.153 | Acc: 52.543,71.933,89.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.167 | Acc: 52.534,71.789,89.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.185 | Acc: 52.367,71.661,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.196 | Acc: 52.333,71.507,89.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.197 | Acc: 52.480,71.499,89.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.201 | Acc: 52.410,71.405,89.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.204 | Acc: 52.424,71.369,89.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.203 | Acc: 52.507,71.371,89.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.213 | Acc: 52.414,71.240,88.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.221 | Acc: 52.380,71.135,88.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.222 | Acc: 52.437,71.157,88.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.229 | Acc: 52.409,71.170,88.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.358 | Acc: 43.750,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.587 | Acc: 39.509,57.329,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.525 | Acc: 40.034,58.308,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.551 | Acc: 39.869,57.992,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 3.095 | Acc: 46.875,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.127 | Acc: 52.455,72.433,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.102 | Acc: 52.344,73.095,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.115 | Acc: 52.228,73.028,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.086 | Acc: 52.865,73.042,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.092 | Acc: 52.939,72.973,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.107 | Acc: 52.841,72.708,90.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.120 | Acc: 52.759,72.424,90.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.120 | Acc: 52.839,72.297,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.132 | Acc: 52.793,72.199,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.144 | Acc: 52.659,72.093,89.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.143 | Acc: 52.697,72.112,89.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.153 | Acc: 52.603,72.031,89.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.163 | Acc: 52.565,71.950,89.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.170 | Acc: 52.611,71.758,89.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.178 | Acc: 52.601,71.714,89.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.191 | Acc: 52.468,71.629,89.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.198 | Acc: 52.330,71.529,89.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.205 | Acc: 52.303,71.466,89.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.220 | Acc: 52.188,71.280,88.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.468 | Acc: 42.969,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.889 | Acc: 39.323,57.403,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.805 | Acc: 39.768,57.660,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.815 | Acc: 39.395,57.608,66.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 2.869 | Acc: 52.344,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.061 | Acc: 54.018,72.991,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.052 | Acc: 54.192,72.923,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.070 | Acc: 53.484,72.964,90.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.094 | Acc: 52.865,72.598,90.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.098 | Acc: 52.924,72.540,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.136 | Acc: 52.441,72.133,89.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.130 | Acc: 52.610,72.219,89.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.125 | Acc: 52.844,72.312,89.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.142 | Acc: 52.715,72.143,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.156 | Acc: 52.523,72.077,89.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.162 | Acc: 52.489,71.932,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.178 | Acc: 52.298,71.629,89.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.185 | Acc: 52.215,71.603,89.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.193 | Acc: 52.138,71.497,89.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.195 | Acc: 52.157,71.468,89.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.201 | Acc: 52.120,71.413,89.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.209 | Acc: 52.053,71.398,88.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.214 | Acc: 52.047,71.325,88.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.226 | Acc: 51.958,71.174,88.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.838 | Acc: 50.781,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.444 | Acc: 42.894,59.226,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.564 | Acc: 42.931,58.308,65.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.594 | Acc: 42.495,57.864,65.471,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 3.260 | Acc: 53.906,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.091 | Acc: 53.757,73.735,89.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.091 | Acc: 53.258,73.190,89.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.127 | Acc: 53.010,72.772,89.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.129 | Acc: 52.816,72.502,89.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.127 | Acc: 52.761,72.409,89.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.147 | Acc: 52.634,71.914,89.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.138 | Acc: 52.776,71.964,89.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.152 | Acc: 52.552,71.763,89.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.154 | Acc: 52.499,71.741,89.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.163 | Acc: 52.375,71.467,89.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.167 | Acc: 52.323,71.405,89.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.176 | Acc: 52.217,71.266,89.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.179 | Acc: 52.302,71.234,89.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.180 | Acc: 52.433,71.288,89.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.191 | Acc: 52.333,71.182,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.193 | Acc: 52.251,71.206,89.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.190 | Acc: 52.261,71.220,89.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.197 | Acc: 52.168,71.178,89.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.210 | Acc: 52.094,71.026,89.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.828 | Acc: 43.750,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.696 | Acc: 38.058,58.259,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.689 | Acc: 38.986,58.460,66.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.711 | Acc: 39.101,57.953,65.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 3.092 | Acc: 50.000,76.562,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.082 | Acc: 53.237,73.065,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.069 | Acc: 53.011,73.247,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.069 | Acc: 53.074,72.964,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.065 | Acc: 53.366,72.946,90.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.091 | Acc: 53.071,72.710,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.114 | Acc: 52.634,72.404,89.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.126 | Acc: 52.371,72.257,90.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.131 | Acc: 52.518,72.137,89.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.132 | Acc: 52.564,72.065,89.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.143 | Acc: 52.635,71.999,89.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.161 | Acc: 52.475,71.730,89.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.160 | Acc: 52.464,71.697,89.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.166 | Acc: 52.544,71.624,89.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.171 | Acc: 52.516,71.555,89.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.185 | Acc: 52.474,71.397,89.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.196 | Acc: 52.407,71.332,89.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.199 | Acc: 52.458,71.295,89.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.201 | Acc: 52.389,71.276,89.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.209 | Acc: 52.292,71.217,88.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.340 | Acc: 38.281,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.765 | Acc: 38.021,57.440,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.731 | Acc: 37.595,57.317,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.731 | Acc: 37.641,57.147,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.786 | Acc: 62.500,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.075 | Acc: 53.795,72.917,89.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.066 | Acc: 53.449,72.980,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.081 | Acc: 52.997,72.989,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.080 | Acc: 53.096,73.042,90.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.100 | Acc: 52.785,72.749,90.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.104 | Acc: 52.725,72.611,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.124 | Acc: 52.660,72.207,90.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.129 | Acc: 52.577,72.220,90.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.131 | Acc: 52.711,72.190,90.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.144 | Acc: 52.697,72.069,90.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.149 | Acc: 52.662,72.098,89.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.148 | Acc: 52.746,72.118,89.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.158 | Acc: 52.694,71.992,89.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.160 | Acc: 52.727,71.978,89.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.170 | Acc: 52.725,71.745,89.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.181 | Acc: 52.653,71.578,89.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.191 | Acc: 52.481,71.444,89.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.199 | Acc: 52.493,71.325,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.206 | Acc: 52.493,71.190,89.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.136 | Acc: 42.969,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.638 | Acc: 40.699,56.510,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.638 | Acc: 40.644,57.050,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.639 | Acc: 40.369,57.313,65.612,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 2.966 | Acc: 53.906,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.123 | Acc: 52.344,73.251,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.062 | Acc: 53.811,72.885,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.091 | Acc: 53.304,72.695,89.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.130 | Acc: 53.077,72.261,89.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.137 | Acc: 53.017,72.099,89.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.143 | Acc: 52.834,72.146,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.153 | Acc: 52.959,71.919,89.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.157 | Acc: 52.970,71.875,89.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.152 | Acc: 53.013,71.953,89.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.161 | Acc: 52.950,71.894,89.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.168 | Acc: 52.909,71.882,89.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.170 | Acc: 52.950,71.856,89.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.182 | Acc: 52.850,71.758,89.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.186 | Acc: 52.727,71.761,89.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.187 | Acc: 52.730,71.782,89.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.191 | Acc: 52.684,71.758,89.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.199 | Acc: 52.587,71.625,89.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.208 | Acc: 52.508,71.511,89.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.212 | Acc: 52.483,71.432,88.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.362 | Acc: 45.312,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.088 | Acc: 37.946,54.874,65.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.091 | Acc: 37.462,54.802,64.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.106 | Acc: 37.077,54.969,64.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 2.930 | Acc: 61.719,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.107 | Acc: 53.088,72.321,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.098 | Acc: 53.296,72.275,89.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.133 | Acc: 52.677,72.067,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.123 | Acc: 52.778,72.338,89.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.092 | Acc: 53.009,72.602,89.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.105 | Acc: 52.854,72.366,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.109 | Acc: 52.909,72.379,89.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.111 | Acc: 52.945,72.336,89.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.118 | Acc: 52.806,72.251,89.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.135 | Acc: 52.697,71.992,89.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.148 | Acc: 52.591,71.932,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.169 | Acc: 52.451,71.710,89.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.182 | Acc: 52.293,71.564,89.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.190 | Acc: 52.199,71.514,89.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.201 | Acc: 52.214,71.403,89.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.211 | Acc: 52.130,71.237,89.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.217 | Acc: 52.122,71.213,88.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.224 | Acc: 52.032,71.161,88.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.230 | Acc: 52.063,71.073,88.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.736 | Acc: 42.188,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.771 | Acc: 38.170,57.403,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.760 | Acc: 38.967,57.470,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.805 | Acc: 39.050,57.121,65.266,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 3.144 | Acc: 51.562,74.219,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.118 | Acc: 53.051,72.917,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.095 | Acc: 52.896,73.171,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.103 | Acc: 52.843,72.618,89.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.096 | Acc: 52.884,72.444,89.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.106 | Acc: 52.754,72.362,90.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.105 | Acc: 53.035,72.308,90.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.121 | Acc: 52.992,72.108,89.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.129 | Acc: 52.955,72.050,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.132 | Acc: 52.741,72.000,89.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.140 | Acc: 52.620,71.891,89.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.158 | Acc: 52.407,71.645,89.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.167 | Acc: 52.370,71.561,89.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.183 | Acc: 52.335,71.459,89.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.182 | Acc: 52.388,71.483,89.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.192 | Acc: 52.287,71.371,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.205 | Acc: 52.232,71.201,89.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.215 | Acc: 52.108,71.153,88.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.217 | Acc: 52.080,71.180,88.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.220 | Acc: 52.067,71.149,88.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.470 | Acc: 39.844,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.723 | Acc: 39.100,58.036,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.681 | Acc: 40.168,58.136,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.715 | Acc: 39.652,57.851,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 3.346 | Acc: 47.656,70.312,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.030 | Acc: 53.832,73.549,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 54.459,74.066,90.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.015 | Acc: 53.893,74.001,90.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.034 | Acc: 53.713,73.939,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.069 | Acc: 53.458,73.414,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.095 | Acc: 53.190,72.973,90.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.111 | Acc: 52.854,72.695,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.125 | Acc: 52.669,72.414,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.127 | Acc: 52.620,72.402,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.139 | Acc: 52.542,72.248,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.151 | Acc: 52.457,72.108,89.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.163 | Acc: 52.298,71.920,89.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.164 | Acc: 52.368,71.896,89.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.167 | Acc: 52.397,71.883,89.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.170 | Acc: 52.372,71.852,89.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.173 | Acc: 52.431,71.821,89.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.175 | Acc: 52.465,71.731,89.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.177 | Acc: 52.428,71.637,89.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.183 | Acc: 52.401,71.590,89.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.497 | Acc: 39.844,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.787 | Acc: 38.393,56.696,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.816 | Acc: 38.643,56.402,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.861 | Acc: 38.012,56.032,65.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 3.368 | Acc: 52.344,69.531,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.178 | Acc: 52.604,73.028,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.159 | Acc: 52.515,72.351,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.115 | Acc: 53.023,72.772,89.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.108 | Acc: 53.009,72.724,89.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.116 | Acc: 53.017,72.571,89.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.135 | Acc: 52.776,72.211,89.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.143 | Acc: 52.721,72.180,89.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.140 | Acc: 52.727,72.205,89.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.144 | Acc: 52.762,72.173,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.143 | Acc: 52.791,72.190,89.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.155 | Acc: 52.736,72.062,89.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.160 | Acc: 52.778,71.959,89.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.164 | Acc: 52.727,71.872,89.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.170 | Acc: 52.597,71.761,89.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.179 | Acc: 52.448,71.579,89.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.187 | Acc: 52.441,71.459,89.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.199 | Acc: 52.371,71.291,88.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.201 | Acc: 52.372,71.304,88.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.205 | Acc: 52.346,71.211,88.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.746 | Acc: 43.750,59.375,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.006 | Acc: 39.993,54.836,64.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.012 | Acc: 39.768,54.992,63.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.029 | Acc: 39.331,55.059,64.229,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 3.072 | Acc: 56.250,75.781,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.020 | Acc: 52.641,73.661,89.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.092 | Acc: 52.439,73.228,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.081 | Acc: 52.574,73.284,90.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.070 | Acc: 53.221,73.177,89.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.084 | Acc: 53.256,72.857,89.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.095 | Acc: 53.099,72.798,89.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.091 | Acc: 53.175,72.767,89.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.099 | Acc: 52.955,72.753,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.110 | Acc: 52.745,72.678,89.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.112 | Acc: 52.810,72.633,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.133 | Acc: 52.743,72.363,89.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.136 | Acc: 52.817,72.245,89.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.147 | Acc: 52.766,72.135,89.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.163 | Acc: 52.613,71.956,89.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.163 | Acc: 52.583,71.891,89.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.174 | Acc: 52.441,71.717,89.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.178 | Acc: 52.383,71.731,89.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.186 | Acc: 52.335,71.555,89.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.196 | Acc: 52.260,71.416,88.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.613 | Acc: 33.594,53.125,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.316 | Acc: 34.189,55.580,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.281 | Acc: 34.451,55.354,66.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.342 | Acc: 33.991,55.123,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 3.229 | Acc: 51.562,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.978 | Acc: 55.171,73.586,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.963 | Acc: 54.973,74.028,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.020 | Acc: 54.034,73.373,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.036 | Acc: 53.733,73.302,90.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.053 | Acc: 53.519,72.958,90.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.079 | Acc: 53.499,72.624,90.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.096 | Acc: 53.180,72.401,90.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.108 | Acc: 53.130,72.200,89.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.118 | Acc: 53.246,72.061,89.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.128 | Acc: 53.257,71.995,89.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.146 | Acc: 52.927,71.744,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.146 | Acc: 52.947,71.719,89.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.152 | Acc: 52.921,71.639,89.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.160 | Acc: 52.864,71.689,89.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.171 | Acc: 52.814,71.512,89.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.169 | Acc: 52.833,71.583,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.188 | Acc: 52.660,71.380,89.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.189 | Acc: 52.707,71.438,89.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.197 | Acc: 52.731,71.371,89.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.514 | Acc: 42.188,62.500,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.479 | Acc: 41.778,58.891,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.510 | Acc: 42.016,58.270,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.575 | Acc: 41.931,58.235,66.124,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 3.114 | Acc: 49.219,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.010 | Acc: 55.357,74.405,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.043 | Acc: 54.459,73.380,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.080 | Acc: 53.471,72.797,90.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.082 | Acc: 53.540,72.589,90.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.083 | Acc: 53.334,72.633,90.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.108 | Acc: 53.274,72.366,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.119 | Acc: 53.053,72.152,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.119 | Acc: 52.926,72.176,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.133 | Acc: 52.844,72.056,89.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.152 | Acc: 52.662,71.817,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.147 | Acc: 52.803,71.861,89.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.151 | Acc: 52.707,71.856,89.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.170 | Acc: 52.592,71.639,89.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.177 | Acc: 52.508,71.544,89.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.177 | Acc: 52.520,71.462,89.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.185 | Acc: 52.366,71.371,89.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.194 | Acc: 52.275,71.238,89.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.200 | Acc: 52.264,71.217,89.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.206 | Acc: 52.241,71.145,89.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.248 | Acc: 42.188,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.975 | Acc: 38.021,56.473,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.973 | Acc: 38.396,56.193,65.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.000 | Acc: 38.102,55.712,64.921,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 3.113 | Acc: 51.562,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.041 | Acc: 53.869,74.182,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.029 | Acc: 53.601,74.123,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.041 | Acc: 53.663,73.617,90.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.065 | Acc: 53.607,73.428,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.072 | Acc: 53.465,73.198,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.080 | Acc: 53.467,72.947,90.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.093 | Acc: 53.158,72.800,90.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.099 | Acc: 53.057,72.705,90.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.112 | Acc: 52.922,72.596,89.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.120 | Acc: 52.826,72.466,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.120 | Acc: 52.789,72.451,89.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.128 | Acc: 52.830,72.329,89.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.138 | Acc: 52.787,72.192,89.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.145 | Acc: 52.747,72.100,89.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.156 | Acc: 52.634,71.989,89.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.161 | Acc: 52.563,71.941,89.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.170 | Acc: 52.486,71.809,89.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.175 | Acc: 52.478,71.715,89.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.179 | Acc: 52.436,71.666,89.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.720 | Acc: 39.844,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.736 | Acc: 37.649,57.403,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.725 | Acc: 38.662,57.546,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.736 | Acc: 38.922,57.697,66.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 3.438 | Acc: 41.406,67.188,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.032 | Acc: 52.530,72.693,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.022 | Acc: 53.296,73.095,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.044 | Acc: 53.573,72.938,90.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.056 | Acc: 53.337,72.840,90.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.069 | Acc: 53.218,72.687,90.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.075 | Acc: 53.119,72.469,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.070 | Acc: 53.203,72.584,90.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.080 | Acc: 53.033,72.501,90.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.089 | Acc: 52.905,72.397,90.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.111 | Acc: 52.705,72.198,90.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.113 | Acc: 52.793,72.197,89.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.126 | Acc: 52.785,71.972,89.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.143 | Acc: 52.700,71.779,89.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.157 | Acc: 52.580,71.658,89.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.171 | Acc: 52.536,71.493,89.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.182 | Acc: 52.551,71.473,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.189 | Acc: 52.465,71.497,89.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.194 | Acc: 52.450,71.429,88.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.203 | Acc: 52.393,71.338,88.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.778 | Acc: 31.250,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.194 | Acc: 33.296,55.618,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.189 | Acc: 33.803,55.907,66.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.145 | Acc: 33.914,56.173,66.419,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 3.016 | Acc: 57.812,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.212 | Acc: 51.600,72.656,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.213 | Acc: 51.582,71.837,89.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.169 | Acc: 52.497,71.913,89.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.145 | Acc: 52.710,72.251,89.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.146 | Acc: 52.723,72.277,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.137 | Acc: 52.686,72.198,90.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.131 | Acc: 52.737,72.307,90.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.115 | Acc: 52.829,72.399,90.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.110 | Acc: 52.853,72.427,90.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.112 | Acc: 52.915,72.365,90.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.131 | Acc: 52.680,72.158,90.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.129 | Acc: 52.726,72.027,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.134 | Acc: 52.715,71.956,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.145 | Acc: 52.683,71.878,89.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.153 | Acc: 52.723,71.771,89.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.166 | Acc: 52.616,71.675,89.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.171 | Acc: 52.628,71.639,89.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.179 | Acc: 52.577,71.630,89.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.185 | Acc: 52.465,71.588,89.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.241 | Acc: 42.188,62.500,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.412 | Acc: 40.067,58.371,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.461 | Acc: 39.920,58.289,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.464 | Acc: 39.985,58.594,66.227,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 2.977 | Acc: 52.344,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.053 | Acc: 54.241,73.065,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.048 | Acc: 54.325,72.656,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.075 | Acc: 53.586,72.362,90.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.077 | Acc: 53.424,72.386,90.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.076 | Acc: 53.597,72.548,90.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.073 | Acc: 53.441,72.650,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.081 | Acc: 53.330,72.501,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.086 | Acc: 53.271,72.574,90.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.100 | Acc: 53.116,72.427,89.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.105 | Acc: 53.117,72.310,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.122 | Acc: 52.874,72.172,89.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.135 | Acc: 52.827,72.053,89.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.137 | Acc: 52.871,72.120,89.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.144 | Acc: 52.847,72.058,89.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.155 | Acc: 52.728,71.896,89.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.168 | Acc: 52.631,71.712,89.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.172 | Acc: 52.600,71.676,89.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.182 | Acc: 52.601,71.622,89.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.184 | Acc: 52.569,71.613,89.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.590 | Acc: 42.969,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.229 | Acc: 33.631,54.948,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.141 | Acc: 34.718,54.840,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.158 | Acc: 34.606,54.547,65.817,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 3.105 | Acc: 53.125,71.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.015 | Acc: 54.613,74.182,90.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.069 | Acc: 53.620,73.133,89.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.098 | Acc: 52.984,72.246,90.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.110 | Acc: 52.990,72.213,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.097 | Acc: 53.164,72.478,89.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.088 | Acc: 53.370,72.437,89.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.095 | Acc: 53.363,72.307,89.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.105 | Acc: 53.280,72.152,89.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.121 | Acc: 53.151,72.164,89.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.131 | Acc: 53.043,71.961,89.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.140 | Acc: 53.132,71.928,89.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.147 | Acc: 53.122,71.852,89.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.154 | Acc: 53.065,71.755,89.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.164 | Acc: 53.003,71.753,89.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.176 | Acc: 52.863,71.553,89.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.180 | Acc: 52.838,71.515,89.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.190 | Acc: 52.681,71.431,88.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.198 | Acc: 52.627,71.392,88.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.202 | Acc: 52.598,71.369,88.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.066 | Acc: 39.844,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.818 | Acc: 38.021,56.510,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.815 | Acc: 38.796,56.536,65.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.823 | Acc: 38.640,56.263,65.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 3.167 | Acc: 44.531,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.030 | Acc: 53.311,74.107,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.084 | Acc: 52.915,73.152,90.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.062 | Acc: 52.997,73.169,90.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.080 | Acc: 53.048,73.196,90.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.075 | Acc: 53.241,73.190,90.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.079 | Acc: 53.164,73.024,90.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.095 | Acc: 52.953,72.983,90.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.102 | Acc: 53.120,72.870,90.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.114 | Acc: 52.922,72.661,90.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.110 | Acc: 52.985,72.641,89.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.112 | Acc: 52.945,72.628,89.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.132 | Acc: 52.733,72.465,89.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.142 | Acc: 52.742,72.309,89.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.143 | Acc: 52.722,72.270,89.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.140 | Acc: 52.710,72.285,89.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.149 | Acc: 52.607,72.196,89.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.160 | Acc: 52.490,72.067,89.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.173 | Acc: 52.419,71.912,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.177 | Acc: 52.407,71.896,89.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.424 | Acc: 44.531,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.492 | Acc: 41.927,57.515,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.558 | Acc: 41.978,57.336,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.603 | Acc: 41.662,57.147,66.201,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 3.599 | Acc: 46.875,64.844,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.165 | Acc: 52.307,71.503,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.084 | Acc: 53.354,72.542,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.077 | Acc: 53.381,72.387,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.088 | Acc: 53.125,72.676,90.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.097 | Acc: 52.939,72.602,90.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.116 | Acc: 52.880,72.392,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.129 | Acc: 52.842,72.185,90.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.124 | Acc: 52.902,72.268,90.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.119 | Acc: 52.896,72.220,90.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.127 | Acc: 52.775,72.054,89.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.135 | Acc: 52.704,71.946,89.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.145 | Acc: 52.762,71.794,89.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.150 | Acc: 52.700,71.701,89.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.158 | Acc: 52.630,71.700,89.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.172 | Acc: 52.520,71.558,89.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.183 | Acc: 52.434,71.430,89.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.191 | Acc: 52.390,71.311,89.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.198 | Acc: 52.352,71.269,89.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.205 | Acc: 52.424,71.211,89.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.323 | Acc: 42.188,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.864 | Acc: 38.281,56.659,66.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.904 | Acc: 38.510,57.127,65.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.924 | Acc: 38.128,56.762,65.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 2.970 | Acc: 56.250,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.128 | Acc: 52.158,71.801,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.138 | Acc: 52.477,71.894,90.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.134 | Acc: 52.574,72.029,90.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.127 | Acc: 52.643,72.020,90.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.141 | Acc: 52.738,71.914,90.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.160 | Acc: 52.499,71.881,89.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.154 | Acc: 52.637,71.969,89.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.148 | Acc: 52.635,72.040,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.146 | Acc: 52.745,72.216,89.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.151 | Acc: 52.760,72.178,89.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.158 | Acc: 52.715,72.045,89.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.167 | Acc: 52.619,72.027,89.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.169 | Acc: 52.700,72.019,89.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.173 | Acc: 52.769,71.970,89.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.183 | Acc: 52.658,71.880,89.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.193 | Acc: 52.655,71.690,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.194 | Acc: 52.667,71.669,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.200 | Acc: 52.619,71.598,88.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.205 | Acc: 52.571,71.535,88.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.313 | Acc: 39.844,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.630 | Acc: 39.658,58.445,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.715 | Acc: 38.605,57.679,67.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.742 | Acc: 38.768,57.531,66.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.645 | Acc: 53.906,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.047 | Acc: 51.860,73.661,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.985 | Acc: 53.049,74.295,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.985 | Acc: 53.740,73.745,91.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.008 | Acc: 53.810,73.331,91.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.016 | Acc: 53.813,73.190,91.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.040 | Acc: 53.629,72.998,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.070 | Acc: 53.385,72.484,90.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.071 | Acc: 53.402,72.637,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.079 | Acc: 53.393,72.566,90.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.084 | Acc: 53.191,72.493,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.086 | Acc: 53.125,72.614,90.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.091 | Acc: 53.161,72.640,90.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.106 | Acc: 53.098,72.569,90.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.108 | Acc: 53.136,72.556,90.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.121 | Acc: 53.013,72.373,90.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.136 | Acc: 52.918,72.223,89.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.144 | Acc: 52.823,72.088,89.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.152 | Acc: 52.893,71.988,89.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.154 | Acc: 52.934,71.949,89.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.948 | Acc: 44.531,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.474 | Acc: 40.439,60.119,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.459 | Acc: 40.072,59.813,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.496 | Acc: 39.460,59.631,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.718 | Acc: 60.156,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.985 | Acc: 54.985,72.917,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.101 | Acc: 53.582,72.027,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.114 | Acc: 53.368,72.374,89.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.086 | Acc: 53.752,72.541,89.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.160 | Acc: 52.468,72.223,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.207 | Acc: 51.666,71.572,89.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.222 | Acc: 51.529,71.554,89.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.224 | Acc: 51.504,71.589,89.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.209 | Acc: 51.606,71.694,89.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.226 | Acc: 51.426,71.533,89.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.240 | Acc: 51.294,71.302,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.246 | Acc: 51.277,71.233,88.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.245 | Acc: 51.377,71.213,88.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.246 | Acc: 51.376,71.194,88.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.249 | Acc: 51.472,71.153,88.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.252 | Acc: 51.426,71.208,88.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.253 | Acc: 51.514,71.130,88.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.259 | Acc: 51.511,71.083,88.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.264 | Acc: 51.487,70.967,88.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.163 | Acc: 49.219,64.062,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.416 | Acc: 41.555,59.226,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.374 | Acc: 42.207,60.061,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.416 | Acc: 41.931,59.772,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 3.080 | Acc: 59.375,74.219,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.094 | Acc: 53.125,71.912,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.115 | Acc: 53.049,72.313,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.095 | Acc: 53.125,72.477,90.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.078 | Acc: 53.270,72.753,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.086 | Acc: 52.970,72.679,90.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.076 | Acc: 53.048,72.785,90.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.074 | Acc: 53.197,72.806,90.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.086 | Acc: 53.144,72.545,90.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.106 | Acc: 53.000,72.436,90.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.122 | Acc: 52.977,72.170,89.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.130 | Acc: 52.987,72.133,89.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.141 | Acc: 52.836,72.082,89.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.156 | Acc: 52.754,71.905,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.165 | Acc: 52.719,71.836,89.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.181 | Acc: 52.624,71.714,89.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.182 | Acc: 52.590,71.734,89.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.186 | Acc: 52.559,71.712,89.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.186 | Acc: 52.556,71.752,89.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.191 | Acc: 52.522,71.684,89.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.962 | Acc: 46.875,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.643 | Acc: 38.281,59.301,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.602 | Acc: 38.281,59.889,66.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.661 | Acc: 38.256,59.785,66.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 3.263 | Acc: 44.531,69.531,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.965 | Acc: 55.208,73.847,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.999 | Acc: 54.821,73.342,90.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.985 | Acc: 54.777,73.591,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.018 | Acc: 53.964,73.196,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.026 | Acc: 53.752,73.175,90.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.052 | Acc: 53.435,73.050,90.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.062 | Acc: 53.286,72.955,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.070 | Acc: 53.436,72.802,90.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.076 | Acc: 53.406,72.721,90.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.084 | Acc: 53.370,72.625,90.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.099 | Acc: 53.125,72.458,90.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.111 | Acc: 53.128,72.352,90.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.127 | Acc: 52.978,72.061,89.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.145 | Acc: 52.925,71.958,89.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.153 | Acc: 52.842,71.888,89.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.164 | Acc: 52.689,71.838,89.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.179 | Acc: 52.541,71.655,89.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.184 | Acc: 52.567,71.591,89.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.189 | Acc: 52.450,71.547,89.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.433 | Acc: 46.094,60.156,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.858 | Acc: 38.951,58.073,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.828 | Acc: 38.891,57.870,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.878 | Acc: 38.870,57.339,65.164,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 3.149 | Acc: 53.125,71.094,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.101 | Acc: 53.460,72.656,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.091 | Acc: 53.277,72.656,89.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.053 | Acc: 53.842,73.284,90.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.063 | Acc: 53.540,73.148,90.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.071 | Acc: 53.496,72.896,90.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.094 | Acc: 53.170,72.753,90.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.104 | Acc: 53.097,72.684,90.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.123 | Acc: 52.989,72.370,90.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.124 | Acc: 53.134,72.341,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.117 | Acc: 53.265,72.442,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.119 | Acc: 53.288,72.533,89.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.138 | Acc: 53.031,72.254,89.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.148 | Acc: 52.918,72.171,89.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.165 | Acc: 52.733,71.931,89.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.173 | Acc: 52.741,71.857,89.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.179 | Acc: 52.743,71.741,89.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.187 | Acc: 52.706,71.646,89.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.190 | Acc: 52.742,71.604,89.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.190 | Acc: 52.746,71.613,89.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.457 | Acc: 42.188,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.707 | Acc: 41.220,57.887,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.662 | Acc: 41.044,58.155,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.697 | Acc: 40.638,58.210,66.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 3.019 | Acc: 56.250,77.344,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.999 | Acc: 53.497,74.777,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.969 | Acc: 54.230,74.676,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.997 | Acc: 53.957,74.180,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.030 | Acc: 53.578,73.900,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.035 | Acc: 53.558,73.739,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.052 | Acc: 53.357,73.347,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.046 | Acc: 53.535,73.227,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.048 | Acc: 53.387,73.205,90.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.054 | Acc: 53.254,73.269,90.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.062 | Acc: 53.245,73.099,90.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.074 | Acc: 53.228,72.957,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.091 | Acc: 53.080,72.705,90.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.098 | Acc: 53.035,72.578,90.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.115 | Acc: 52.911,72.342,89.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.118 | Acc: 52.881,72.368,89.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.125 | Acc: 52.869,72.238,89.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.133 | Acc: 52.871,72.097,89.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.145 | Acc: 52.785,72.003,89.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.150 | Acc: 52.838,71.959,89.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.233 | Acc: 41.406,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.736 | Acc: 36.161,58.854,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.726 | Acc: 37.214,59.032,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.751 | Acc: 37.001,58.760,66.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.955 | Acc: 52.344,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.013 | Acc: 54.167,73.772,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.001 | Acc: 54.002,73.418,90.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.030 | Acc: 53.855,72.989,90.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.043 | Acc: 53.868,72.724,90.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.054 | Acc: 54.015,72.672,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.079 | Acc: 53.551,72.540,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.086 | Acc: 53.280,72.346,89.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.100 | Acc: 52.902,72.176,89.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.112 | Acc: 52.737,72.091,89.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.116 | Acc: 52.686,72.054,89.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.123 | Acc: 52.584,71.949,89.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.130 | Acc: 52.610,71.894,89.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.131 | Acc: 52.646,71.884,89.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.135 | Acc: 52.711,71.836,89.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.142 | Acc: 52.658,71.797,89.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.148 | Acc: 52.636,71.722,89.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.156 | Acc: 52.623,71.648,89.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.156 | Acc: 52.619,71.602,89.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.159 | Acc: 52.657,71.584,89.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.762 | Acc: 46.094,61.719,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.728 | Acc: 40.439,58.222,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.694 | Acc: 40.625,58.136,66.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.762 | Acc: 40.202,57.633,65.945,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 2.703 | Acc: 57.812,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.814 | Acc: 55.766,75.260,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.749 | Acc: 56.155,76.277,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.732 | Acc: 55.968,76.652,92.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.698 | Acc: 56.163,77.064,93.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.678 | Acc: 56.498,77.042,93.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.651 | Acc: 56.411,77.505,93.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.638 | Acc: 56.377,77.848,93.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.616 | Acc: 56.551,78.217,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.604 | Acc: 56.768,78.293,94.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.594 | Acc: 56.736,78.343,94.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.585 | Acc: 56.773,78.496,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.572 | Acc: 56.723,78.676,94.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.560 | Acc: 56.888,78.870,94.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.545 | Acc: 57.028,79.045,94.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.532 | Acc: 57.151,79.218,95.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.527 | Acc: 57.136,79.266,95.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 57.166,79.387,95.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.512 | Acc: 57.278,79.473,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.500 | Acc: 57.454,79.601,95.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.937 | Acc: 56.250,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.109 | Acc: 53.199,69.494,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.114 | Acc: 53.411,68.941,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.157 | Acc: 53.215,68.558,74.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 2.549 | Acc: 53.906,78.906,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.283 | Acc: 59.115,82.440,97.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.248 | Acc: 59.756,83.136,97.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.265 | Acc: 59.093,83.017,97.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.258 | Acc: 59.491,82.967,97.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.279 | Acc: 59.011,82.696,97.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.278 | Acc: 59.117,82.729,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.278 | Acc: 59.076,82.807,97.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.274 | Acc: 59.239,82.803,97.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.275 | Acc: 59.280,82.787,97.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.277 | Acc: 59.188,82.758,97.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.277 | Acc: 59.120,82.749,97.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.275 | Acc: 59.054,82.838,97.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.273 | Acc: 58.947,82.881,97.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.268 | Acc: 59.078,82.924,97.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.267 | Acc: 59.108,82.903,97.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.267 | Acc: 58.986,82.910,97.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.261 | Acc: 59.047,82.975,97.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.258 | Acc: 59.137,82.947,97.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.255 | Acc: 59.156,82.921,97.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.911 | Acc: 55.469,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.094 | Acc: 53.460,69.568,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.099 | Acc: 53.982,68.864,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.141 | Acc: 53.689,68.827,74.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 2.113 | Acc: 58.594,87.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.115 | Acc: 60.900,85.007,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.174 | Acc: 59.394,84.070,97.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.182 | Acc: 59.170,84.068,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.164 | Acc: 59.307,84.201,98.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.175 | Acc: 59.244,84.135,98.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.162 | Acc: 59.562,84.246,98.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.164 | Acc: 59.447,84.309,98.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.168 | Acc: 59.419,84.234,98.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.157 | Acc: 59.681,84.397,98.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.157 | Acc: 59.701,84.375,98.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.158 | Acc: 59.683,84.340,98.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.162 | Acc: 59.673,84.271,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.171 | Acc: 59.528,84.168,98.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.172 | Acc: 59.400,84.208,98.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.172 | Acc: 59.406,84.199,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.170 | Acc: 59.433,84.180,98.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.169 | Acc: 59.377,84.164,98.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.167 | Acc: 59.470,84.128,98.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.165 | Acc: 59.527,84.193,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.912 | Acc: 56.250,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.076 | Acc: 53.646,70.164,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.074 | Acc: 53.925,69.322,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.113 | Acc: 53.612,69.198,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.928 | Acc: 60.938,88.281,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.032 | Acc: 61.570,86.086,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.101 | Acc: 60.118,85.290,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.106 | Acc: 59.810,85.489,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.109 | Acc: 59.828,85.272,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.114 | Acc: 59.839,85.056,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.116 | Acc: 59.904,85.053,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.118 | Acc: 59.946,84.940,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.115 | Acc: 59.977,84.952,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.116 | Acc: 60.005,84.893,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.111 | Acc: 60.106,84.806,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.109 | Acc: 60.064,84.856,98.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.110 | Acc: 60.036,84.787,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.113 | Acc: 60.001,84.722,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.112 | Acc: 59.956,84.792,98.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.112 | Acc: 59.943,84.829,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.113 | Acc: 59.871,84.789,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.116 | Acc: 59.836,84.748,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.114 | Acc: 59.905,84.726,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.115 | Acc: 59.896,84.699,98.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.801 | Acc: 56.250,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.062 | Acc: 53.088,70.238,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.085 | Acc: 53.544,69.493,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.115 | Acc: 53.445,69.326,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 2.080 | Acc: 61.719,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.070 | Acc: 61.161,85.789,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.087 | Acc: 61.033,84.985,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.095 | Acc: 60.733,84.708,98.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.088 | Acc: 60.745,84.770,98.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.085 | Acc: 60.675,85.009,98.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.085 | Acc: 60.595,84.969,98.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.084 | Acc: 60.300,85.145,98.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.079 | Acc: 60.428,85.239,98.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.078 | Acc: 60.368,85.290,98.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.074 | Acc: 60.463,85.397,98.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.076 | Acc: 60.365,85.467,98.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.078 | Acc: 60.211,85.477,98.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.077 | Acc: 60.189,85.480,98.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.080 | Acc: 60.206,85.415,98.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.081 | Acc: 60.224,85.374,98.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.089 | Acc: 60.076,85.183,98.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.090 | Acc: 60.131,85.131,98.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.089 | Acc: 60.098,85.124,98.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.084 | Acc: 60.160,85.220,98.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.800 | Acc: 54.688,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.077 | Acc: 53.795,70.647,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.099 | Acc: 54.402,69.665,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.144 | Acc: 54.214,69.467,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.910 | Acc: 60.938,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 62.128,87.612,98.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.971 | Acc: 62.214,87.214,98.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.001 | Acc: 61.911,86.565,98.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.021 | Acc: 61.545,86.092,98.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.024 | Acc: 61.239,86.146,98.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.025 | Acc: 61.138,86.118,98.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.023 | Acc: 61.181,86.021,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.029 | Acc: 61.136,85.952,98.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.035 | Acc: 61.045,85.907,98.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.039 | Acc: 60.887,85.825,98.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.042 | Acc: 60.839,85.810,98.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.045 | Acc: 60.827,85.879,98.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.050 | Acc: 60.683,85.845,98.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.050 | Acc: 60.693,85.890,98.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.048 | Acc: 60.699,85.901,98.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.049 | Acc: 60.716,85.882,98.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.046 | Acc: 60.782,85.944,98.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.051 | Acc: 60.693,85.896,98.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.053 | Acc: 60.589,85.890,98.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.701 | Acc: 53.906,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.091 | Acc: 54.167,69.754,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.110 | Acc: 53.849,69.474,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.147 | Acc: 53.791,69.237,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 2.035 | Acc: 60.938,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.991 | Acc: 61.310,86.496,99.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.021 | Acc: 61.033,86.433,99.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.025 | Acc: 61.014,86.232,99.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.026 | Acc: 61.198,86.217,98.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.028 | Acc: 61.170,86.131,98.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.023 | Acc: 61.021,86.286,98.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.025 | Acc: 60.766,86.364,98.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.014 | Acc: 60.981,86.369,98.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.011 | Acc: 61.119,86.360,98.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.009 | Acc: 61.245,86.338,98.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.003 | Acc: 61.330,86.351,98.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.003 | Acc: 61.307,86.414,98.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.002 | Acc: 61.192,86.381,98.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.005 | Acc: 61.149,86.432,98.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.009 | Acc: 61.119,86.405,98.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.010 | Acc: 61.074,86.412,98.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.007 | Acc: 61.089,86.425,98.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.009 | Acc: 61.057,86.398,98.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.010 | Acc: 60.985,86.403,98.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.820 | Acc: 54.688,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.091 | Acc: 53.757,70.126,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.109 | Acc: 54.078,69.569,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.152 | Acc: 54.290,69.314,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 2.128 | Acc: 52.344,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 60.640,87.500,98.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.990 | Acc: 60.976,87.119,98.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.009 | Acc: 60.745,86.834,98.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.002 | Acc: 60.696,86.989,98.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.013 | Acc: 60.582,86.804,98.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.015 | Acc: 60.679,86.777,98.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.017 | Acc: 60.677,86.774,98.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.016 | Acc: 60.714,86.826,98.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.020 | Acc: 60.631,86.663,98.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.016 | Acc: 60.658,86.746,98.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.018 | Acc: 60.683,86.705,98.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.015 | Acc: 60.801,86.709,98.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.016 | Acc: 60.803,86.659,98.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.014 | Acc: 60.824,86.666,98.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.014 | Acc: 60.836,86.714,98.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.014 | Acc: 60.886,86.709,98.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.011 | Acc: 60.935,86.746,98.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.007 | Acc: 60.948,86.786,98.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.006 | Acc: 60.987,86.795,98.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.767 | Acc: 56.250,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.081 | Acc: 54.539,70.275,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.122 | Acc: 54.649,69.169,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.158 | Acc: 54.201,69.019,74.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 2.071 | Acc: 57.812,89.844,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.927 | Acc: 62.277,87.760,99.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.972 | Acc: 61.357,87.024,99.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.950 | Acc: 61.732,87.321,99.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.953 | Acc: 61.719,87.288,99.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.957 | Acc: 61.518,87.338,99.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.946 | Acc: 61.738,87.326,99.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.952 | Acc: 61.325,87.356,99.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.950 | Acc: 61.306,87.398,99.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.957 | Acc: 61.231,87.401,99.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.955 | Acc: 61.248,87.391,99.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.960 | Acc: 61.196,87.327,99.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.964 | Acc: 61.148,87.270,99.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.966 | Acc: 61.189,87.234,99.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.967 | Acc: 61.174,87.172,99.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.965 | Acc: 61.335,87.116,99.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.968 | Acc: 61.322,87.072,99.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.970 | Acc: 61.318,87.062,99.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.973 | Acc: 61.217,87.052,99.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.973 | Acc: 61.227,87.049,99.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.741 | Acc: 57.812,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.153 | Acc: 54.018,70.126,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.152 | Acc: 54.440,69.112,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.187 | Acc: 54.239,69.070,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 1.894 | Acc: 62.500,86.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.904 | Acc: 61.905,87.649,99.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.914 | Acc: 61.414,87.881,99.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.923 | Acc: 61.450,87.987,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.913 | Acc: 61.834,87.944,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.913 | Acc: 61.873,87.840,99.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.897 | Acc: 62.255,87.984,99.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.901 | Acc: 62.123,87.910,99.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.909 | Acc: 61.913,87.806,99.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.915 | Acc: 61.727,87.621,99.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.916 | Acc: 61.703,87.589,99.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.919 | Acc: 61.574,87.698,99.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.928 | Acc: 61.498,87.594,99.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.933 | Acc: 61.392,87.512,99.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.935 | Acc: 61.510,87.447,99.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.939 | Acc: 61.457,87.407,99.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.944 | Acc: 61.324,87.339,99.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.947 | Acc: 61.256,87.337,99.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.948 | Acc: 61.238,87.318,99.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.951 | Acc: 61.153,87.260,99.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.658 | Acc: 57.812,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.128 | Acc: 54.613,70.350,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.159 | Acc: 54.135,69.703,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.194 | Acc: 53.983,69.403,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 2.187 | Acc: 54.688,85.156,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 59.152,87.277,99.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 60.442,87.348,99.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.931 | Acc: 60.361,87.718,99.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.921 | Acc: 60.889,87.799,99.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.913 | Acc: 61.146,87.972,99.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.918 | Acc: 61.144,87.791,99.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.917 | Acc: 61.359,87.677,99.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.928 | Acc: 61.141,87.636,99.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.932 | Acc: 61.339,87.560,99.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.938 | Acc: 61.221,87.453,99.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.948 | Acc: 61.160,87.288,99.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.947 | Acc: 61.132,87.289,99.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.944 | Acc: 61.138,87.407,99.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.944 | Acc: 61.146,87.442,99.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.939 | Acc: 61.265,87.510,99.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.941 | Acc: 61.198,87.510,99.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.938 | Acc: 61.228,87.571,99.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.938 | Acc: 61.262,87.576,99.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.941 | Acc: 61.245,87.500,99.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.850 | Acc: 56.250,74.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.183 | Acc: 53.720,69.792,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.189 | Acc: 54.211,69.036,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.227 | Acc: 53.932,69.032,74.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.445 | Acc: 72.656,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.882 | Acc: 61.012,88.690,99.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.883 | Acc: 61.242,88.777,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.886 | Acc: 61.603,88.384,99.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.889 | Acc: 61.613,88.262,99.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.878 | Acc: 62.067,88.428,99.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.881 | Acc: 61.809,88.494,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.889 | Acc: 61.636,88.398,99.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.892 | Acc: 61.500,88.373,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.888 | Acc: 61.641,88.406,99.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.894 | Acc: 61.641,88.254,99.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.895 | Acc: 61.722,88.267,99.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.901 | Acc: 61.709,88.109,99.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.904 | Acc: 61.674,88.132,99.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.907 | Acc: 61.633,88.073,99.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.907 | Acc: 61.631,88.040,99.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.909 | Acc: 61.595,88.067,99.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.914 | Acc: 61.471,87.981,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.917 | Acc: 61.474,87.939,99.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.919 | Acc: 61.475,87.871,99.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.726 | Acc: 56.250,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.176 | Acc: 54.539,69.829,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.186 | Acc: 54.268,69.150,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.229 | Acc: 53.945,69.121,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.657 | Acc: 67.188,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.815 | Acc: 63.690,89.174,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.846 | Acc: 62.786,89.177,99.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.867 | Acc: 62.564,88.845,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.873 | Acc: 62.307,88.899,99.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.893 | Acc: 62.121,88.560,99.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.883 | Acc: 62.293,88.585,99.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.895 | Acc: 62.084,88.342,99.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.888 | Acc: 62.204,88.306,99.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.888 | Acc: 62.194,88.337,99.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.890 | Acc: 62.115,88.320,99.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.890 | Acc: 62.023,88.345,99.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.894 | Acc: 61.975,88.294,99.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.889 | Acc: 62.156,88.347,99.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.889 | Acc: 62.114,88.379,99.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.892 | Acc: 62.113,88.331,99.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.894 | Acc: 62.067,88.276,99.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.897 | Acc: 61.996,88.185,99.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.897 | Acc: 61.981,88.180,99.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.904 | Acc: 61.907,88.066,99.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.853 | Acc: 57.031,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.168 | Acc: 53.943,70.052,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.196 | Acc: 54.383,69.055,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.223 | Acc: 54.214,68.993,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.825 | Acc: 60.938,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.921 | Acc: 60.417,88.616,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.862 | Acc: 61.452,88.700,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.863 | Acc: 61.744,88.883,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.865 | Acc: 61.632,88.715,99.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.856 | Acc: 61.889,88.683,99.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.858 | Acc: 61.745,88.804,99.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.859 | Acc: 61.746,88.774,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.869 | Acc: 61.772,88.665,99.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.870 | Acc: 61.809,88.635,99.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.873 | Acc: 61.820,88.511,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.875 | Acc: 61.864,88.515,99.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.878 | Acc: 61.829,88.498,99.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.878 | Acc: 61.824,88.509,99.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.881 | Acc: 61.810,88.462,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.881 | Acc: 61.830,88.491,99.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.884 | Acc: 61.792,88.410,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.887 | Acc: 61.755,88.325,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.891 | Acc: 61.647,88.314,99.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.892 | Acc: 61.674,88.275,99.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.779 | Acc: 53.906,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.209 | Acc: 52.790,69.643,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.218 | Acc: 53.906,68.845,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.253 | Acc: 53.932,68.750,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.806 | Acc: 63.281,87.500,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.848 | Acc: 63.281,88.914,99.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.872 | Acc: 62.348,88.739,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.862 | Acc: 62.013,88.896,99.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.857 | Acc: 61.960,89.053,99.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.856 | Acc: 61.974,89.039,99.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.856 | Acc: 61.861,88.953,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.857 | Acc: 61.963,88.891,99.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.862 | Acc: 62.020,88.771,99.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.866 | Acc: 61.900,88.778,99.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.879 | Acc: 61.688,88.616,99.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.882 | Acc: 61.556,88.557,99.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.886 | Acc: 61.479,88.518,99.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.888 | Acc: 61.473,88.521,99.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.887 | Acc: 61.432,88.512,99.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.884 | Acc: 61.537,88.525,99.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.883 | Acc: 61.582,88.498,99.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.884 | Acc: 61.604,88.444,99.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.884 | Acc: 61.630,88.411,99.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.885 | Acc: 61.739,88.386,99.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.969 | Acc: 57.031,75.000,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.214 | Acc: 54.018,70.052,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.232 | Acc: 54.592,69.398,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.257 | Acc: 54.457,69.083,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 2.076 | Acc: 63.281,85.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.789 | Acc: 63.356,90.067,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.802 | Acc: 63.034,89.425,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.800 | Acc: 62.666,89.319,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.820 | Acc: 62.558,89.062,99.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.827 | Acc: 62.678,88.946,99.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.817 | Acc: 62.829,89.140,99.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.823 | Acc: 62.855,89.068,99.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.827 | Acc: 62.767,88.985,99.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.827 | Acc: 62.867,89.002,99.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.830 | Acc: 62.803,89.000,99.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.825 | Acc: 62.864,89.034,99.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.828 | Acc: 62.824,89.043,99.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.832 | Acc: 62.760,88.946,99.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.836 | Acc: 62.725,88.851,99.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.842 | Acc: 62.583,88.800,99.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.846 | Acc: 62.493,88.763,99.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.851 | Acc: 62.342,88.735,99.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.852 | Acc: 62.273,88.736,99.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.855 | Acc: 62.233,88.695,99.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.806 | Acc: 55.469,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.247 | Acc: 53.981,69.085,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.267 | Acc: 53.925,68.712,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.287 | Acc: 53.753,68.712,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.744 | Acc: 57.812,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.824 | Acc: 61.682,89.955,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.827 | Acc: 61.261,90.034,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.822 | Acc: 61.603,89.857,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.838 | Acc: 61.709,89.574,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.827 | Acc: 62.136,89.542,99.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.833 | Acc: 62.319,89.534,99.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.833 | Acc: 62.306,89.417,99.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.832 | Acc: 62.291,89.266,99.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.829 | Acc: 62.371,89.218,99.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.833 | Acc: 62.247,89.164,99.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.837 | Acc: 62.182,89.154,99.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.834 | Acc: 62.260,89.186,99.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.840 | Acc: 62.141,89.098,99.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.838 | Acc: 62.211,89.079,99.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.841 | Acc: 62.225,89.005,99.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.841 | Acc: 62.274,88.934,99.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.841 | Acc: 62.253,88.927,99.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.842 | Acc: 62.273,88.935,99.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.849 | Acc: 62.127,88.843,99.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.814 | Acc: 56.250,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.210 | Acc: 54.576,69.792,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.239 | Acc: 54.287,69.245,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.275 | Acc: 54.252,68.916,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.892 | Acc: 66.406,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.858 | Acc: 61.310,88.728,99.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.873 | Acc: 61.852,88.510,99.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.859 | Acc: 62.077,88.563,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.855 | Acc: 62.172,88.436,99.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.848 | Acc: 62.369,88.397,99.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.852 | Acc: 62.293,88.333,99.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.848 | Acc: 62.350,88.470,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.847 | Acc: 62.350,88.529,99.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.844 | Acc: 62.388,88.575,99.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.845 | Acc: 62.333,88.666,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.847 | Acc: 62.242,88.642,99.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.849 | Acc: 62.166,88.664,99.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.851 | Acc: 62.030,88.712,99.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.848 | Acc: 62.147,88.751,99.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.853 | Acc: 61.947,88.658,99.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.849 | Acc: 62.064,88.644,99.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.849 | Acc: 62.099,88.662,99.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.849 | Acc: 62.095,88.645,99.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.851 | Acc: 62.055,88.613,99.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.797 | Acc: 57.031,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.239 | Acc: 55.097,70.015,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.244 | Acc: 55.030,69.055,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.276 | Acc: 54.649,68.968,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.766 | Acc: 60.938,91.406,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.794 | Acc: 63.542,90.402,99.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.810 | Acc: 62.710,89.691,99.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.817 | Acc: 62.500,89.306,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.814 | Acc: 62.606,89.419,99.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.816 | Acc: 62.407,89.496,99.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.816 | Acc: 62.545,89.514,99.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.822 | Acc: 62.572,89.389,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.822 | Acc: 62.422,89.422,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.817 | Acc: 62.526,89.429,99.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.815 | Acc: 62.558,89.517,99.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.819 | Acc: 62.472,89.469,99.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.823 | Acc: 62.409,89.419,99.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.825 | Acc: 62.338,89.359,99.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.827 | Acc: 62.247,89.263,99.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.828 | Acc: 62.147,89.286,99.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.828 | Acc: 62.167,89.318,99.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.827 | Acc: 62.225,89.294,99.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.830 | Acc: 62.072,89.264,99.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.832 | Acc: 62.057,89.253,99.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.900 | Acc: 58.594,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.282 | Acc: 53.757,69.792,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.292 | Acc: 53.925,68.998,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.330 | Acc: 53.855,68.724,74.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 2.030 | Acc: 58.594,84.375,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.769 | Acc: 62.574,89.955,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.812 | Acc: 61.966,89.348,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.804 | Acc: 62.564,89.511,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.805 | Acc: 62.625,89.516,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.808 | Acc: 62.887,89.519,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.816 | Acc: 62.797,89.411,99.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.815 | Acc: 62.799,89.417,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.824 | Acc: 62.767,89.286,99.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.820 | Acc: 62.819,89.252,99.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.822 | Acc: 62.729,89.171,99.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.823 | Acc: 62.624,89.161,99.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.824 | Acc: 62.545,89.186,99.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.822 | Acc: 62.554,89.164,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.822 | Acc: 62.572,89.132,99.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.822 | Acc: 62.523,89.120,99.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.823 | Acc: 62.595,89.036,99.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.825 | Acc: 62.532,89.014,99.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.832 | Acc: 62.422,88.924,99.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.832 | Acc: 62.400,88.929,99.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.834 | Acc: 56.250,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.295 | Acc: 54.055,69.457,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.342 | Acc: 54.154,68.788,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.374 | Acc: 53.893,68.417,74.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 1.765 | Acc: 60.156,90.625,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.768 | Acc: 62.686,89.769,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.767 | Acc: 62.348,90.149,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.784 | Acc: 62.590,89.780,99.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.787 | Acc: 62.548,89.824,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.788 | Acc: 62.508,89.821,99.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.797 | Acc: 62.339,89.695,99.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.796 | Acc: 62.461,89.694,99.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.798 | Acc: 62.335,89.674,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.804 | Acc: 62.228,89.697,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.800 | Acc: 62.329,89.684,99.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.804 | Acc: 62.387,89.639,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.807 | Acc: 62.328,89.675,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.806 | Acc: 62.356,89.655,99.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.805 | Acc: 62.408,89.635,99.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.809 | Acc: 62.339,89.537,99.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.811 | Acc: 62.349,89.488,99.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.812 | Acc: 62.406,89.484,99.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.813 | Acc: 62.426,89.437,99.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.814 | Acc: 62.369,89.395,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.972 | Acc: 55.469,74.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.275 | Acc: 54.129,69.568,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.292 | Acc: 54.078,69.036,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.317 | Acc: 53.855,68.904,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.556 | Acc: 68.750,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.736 | Acc: 62.463,91.109,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.727 | Acc: 63.034,91.292,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.719 | Acc: 63.409,90.856,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.730 | Acc: 63.715,90.731,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.750 | Acc: 63.444,90.501,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.756 | Acc: 63.443,90.380,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.766 | Acc: 63.226,90.221,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.774 | Acc: 63.082,90.033,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.785 | Acc: 62.888,89.930,99.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.790 | Acc: 62.865,89.902,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.794 | Acc: 62.779,89.784,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.795 | Acc: 62.814,89.734,99.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.796 | Acc: 62.793,89.646,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.799 | Acc: 62.728,89.563,99.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.801 | Acc: 62.767,89.514,99.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.804 | Acc: 62.685,89.449,99.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.806 | Acc: 62.633,89.447,99.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.807 | Acc: 62.604,89.467,99.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.808 | Acc: 62.623,89.421,99.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.668 | Acc: 57.812,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.256 | Acc: 54.539,69.271,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.283 | Acc: 54.707,68.845,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.307 | Acc: 54.649,68.609,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 1.713 | Acc: 61.719,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.791 | Acc: 62.277,90.774,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.779 | Acc: 62.062,90.796,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.764 | Acc: 62.269,90.817,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.772 | Acc: 62.510,90.557,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.759 | Acc: 62.887,90.640,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.764 | Acc: 62.920,90.489,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.771 | Acc: 62.672,90.453,99.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.774 | Acc: 62.631,90.397,99.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.778 | Acc: 62.586,90.344,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.775 | Acc: 62.772,90.326,99.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.773 | Acc: 62.825,90.325,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.774 | Acc: 62.811,90.314,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.776 | Acc: 62.763,90.308,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.775 | Acc: 62.803,90.244,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.777 | Acc: 62.796,90.186,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.779 | Acc: 62.751,90.153,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.780 | Acc: 62.743,90.123,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.783 | Acc: 62.684,90.069,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.783 | Acc: 62.668,90.071,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.887 | Acc: 57.031,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.349 | Acc: 54.167,69.680,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.339 | Acc: 54.478,69.398,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.366 | Acc: 54.393,69.006,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.795 | Acc: 66.406,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.747 | Acc: 62.946,89.769,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.772 | Acc: 62.843,89.748,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.753 | Acc: 62.884,90.087,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.766 | Acc: 62.799,90.075,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.778 | Acc: 62.902,89.913,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.776 | Acc: 62.816,90.018,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.774 | Acc: 62.877,90.088,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.772 | Acc: 62.849,89.994,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.776 | Acc: 62.906,89.896,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.777 | Acc: 62.916,89.774,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.781 | Acc: 62.733,89.706,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.781 | Acc: 62.808,89.669,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.781 | Acc: 62.772,89.688,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.782 | Acc: 62.784,89.708,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.785 | Acc: 62.713,89.683,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.784 | Acc: 62.687,89.647,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.786 | Acc: 62.610,89.617,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.789 | Acc: 62.578,89.541,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.789 | Acc: 62.588,89.522,99.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.800 | Acc: 55.469,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.330 | Acc: 54.204,68.490,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.359 | Acc: 54.421,68.007,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.384 | Acc: 54.316,67.982,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.770 | Acc: 59.375,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.778 | Acc: 62.872,89.844,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.782 | Acc: 62.576,89.825,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.787 | Acc: 62.564,89.933,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.773 | Acc: 63.040,89.940,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.771 | Acc: 62.879,90.192,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.770 | Acc: 62.855,90.283,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.772 | Acc: 62.871,90.276,99.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.773 | Acc: 62.830,90.213,99.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.771 | Acc: 62.884,90.228,99.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.773 | Acc: 62.830,90.178,99.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.774 | Acc: 62.825,90.169,99.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.774 | Acc: 62.863,90.155,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.772 | Acc: 62.904,90.146,99.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.774 | Acc: 62.823,90.102,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.769 | Acc: 63.037,90.121,99.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.768 | Acc: 63.043,90.126,99.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.768 | Acc: 63.027,90.132,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.774 | Acc: 62.946,90.077,99.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.776 | Acc: 62.830,90.057,99.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.907 | Acc: 57.812,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.374 | Acc: 53.646,69.382,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.379 | Acc: 54.002,68.579,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.415 | Acc: 53.893,68.122,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.354 | Acc: 72.656,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.751 | Acc: 63.802,90.141,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.768 | Acc: 62.919,89.844,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.781 | Acc: 62.577,89.639,99.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.778 | Acc: 62.799,89.689,99.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.776 | Acc: 62.631,89.720,99.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.774 | Acc: 62.577,89.715,99.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.769 | Acc: 62.810,89.705,99.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.768 | Acc: 62.966,89.703,99.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.776 | Acc: 62.755,89.611,99.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.773 | Acc: 62.795,89.614,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.776 | Acc: 62.769,89.575,99.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.775 | Acc: 62.701,89.672,99.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.775 | Acc: 62.656,89.736,99.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.779 | Acc: 62.558,89.735,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.782 | Acc: 62.495,89.696,99.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.782 | Acc: 62.529,89.703,99.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.782 | Acc: 62.502,89.766,99.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.782 | Acc: 62.483,89.746,99.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.780 | Acc: 62.566,89.792,99.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.865 | Acc: 57.812,75.000,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.338 | Acc: 53.869,69.680,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.380 | Acc: 53.792,68.216,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.403 | Acc: 53.650,68.084,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.884 | Acc: 58.594,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.753 | Acc: 62.574,90.365,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.726 | Acc: 63.739,90.682,99.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.736 | Acc: 63.256,90.663,99.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.736 | Acc: 63.108,90.760,99.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.749 | Acc: 62.601,90.679,99.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.744 | Acc: 62.655,90.715,99.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.752 | Acc: 62.600,90.642,99.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.750 | Acc: 62.733,90.562,99.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.755 | Acc: 62.677,90.331,99.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.759 | Acc: 62.582,90.287,99.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.761 | Acc: 62.599,90.215,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.763 | Acc: 62.565,90.184,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.764 | Acc: 62.500,90.176,99.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.767 | Acc: 62.408,90.122,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.765 | Acc: 62.500,90.129,99.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.767 | Acc: 62.524,90.082,99.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.770 | Acc: 62.564,90.011,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.770 | Acc: 62.541,90.021,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.769 | Acc: 62.584,90.026,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.029 | Acc: 55.469,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.375 | Acc: 54.315,69.085,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.404 | Acc: 54.192,68.540,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.441 | Acc: 54.252,68.251,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.737 | Acc: 67.188,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.775 | Acc: 62.202,91.481,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.738 | Acc: 62.938,91.159,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.733 | Acc: 63.332,91.060,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.731 | Acc: 63.252,90.847,99.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.734 | Acc: 63.320,90.640,99.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.731 | Acc: 63.326,90.670,99.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.731 | Acc: 63.464,90.597,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.738 | Acc: 63.354,90.581,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.740 | Acc: 63.225,90.543,99.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.739 | Acc: 63.246,90.536,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.744 | Acc: 63.327,90.420,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.746 | Acc: 63.366,90.372,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.750 | Acc: 63.284,90.302,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.748 | Acc: 63.259,90.277,99.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.751 | Acc: 63.222,90.210,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.757 | Acc: 63.133,90.160,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.759 | Acc: 63.096,90.059,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.760 | Acc: 63.091,90.039,99.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.760 | Acc: 63.107,90.041,99.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.996 | Acc: 56.250,74.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.403 | Acc: 54.762,68.378,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.408 | Acc: 54.707,67.759,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.443 | Acc: 54.406,67.495,74.155,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.403 | Acc: 68.750,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.673 | Acc: 63.988,90.737,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.700 | Acc: 63.224,90.720,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.718 | Acc: 63.179,90.779,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.721 | Acc: 63.436,90.712,99.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.730 | Acc: 63.057,90.671,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.739 | Acc: 62.855,90.599,99.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.741 | Acc: 62.932,90.486,99.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.747 | Acc: 62.854,90.411,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.752 | Acc: 62.832,90.357,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.754 | Acc: 62.679,90.372,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.752 | Acc: 62.581,90.441,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.754 | Acc: 62.610,90.362,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.754 | Acc: 62.623,90.359,99.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.755 | Acc: 62.614,90.311,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.757 | Acc: 62.586,90.251,99.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.755 | Acc: 62.668,90.289,99.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.753 | Acc: 62.734,90.284,99.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.754 | Acc: 62.747,90.242,99.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.754 | Acc: 62.789,90.223,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.846 | Acc: 60.938,75.000,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.354 | Acc: 54.762,68.973,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.377 | Acc: 54.897,68.521,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.412 | Acc: 54.662,68.379,74.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.822 | Acc: 64.062,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.758 | Acc: 63.058,90.067,99.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.762 | Acc: 62.405,90.473,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.733 | Acc: 63.307,90.523,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.732 | Acc: 63.098,90.461,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.729 | Acc: 63.034,90.610,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.727 | Acc: 63.081,90.631,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.731 | Acc: 62.932,90.625,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.733 | Acc: 63.000,90.513,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.738 | Acc: 62.962,90.500,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.735 | Acc: 63.079,90.512,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.734 | Acc: 63.020,90.480,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.735 | Acc: 62.973,90.479,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.741 | Acc: 62.853,90.398,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.743 | Acc: 62.742,90.391,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.741 | Acc: 62.900,90.420,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.743 | Acc: 62.880,90.365,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.747 | Acc: 62.770,90.320,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.748 | Acc: 62.799,90.255,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.752 | Acc: 62.693,90.227,99.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.115 | Acc: 54.688,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.471 | Acc: 54.278,68.973,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.497 | Acc: 54.649,68.407,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.527 | Acc: 54.124,67.841,73.937,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.965 | Acc: 59.375,89.062,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.682 | Acc: 64.137,91.555,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.673 | Acc: 64.444,91.311,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.701 | Acc: 63.704,91.496,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.709 | Acc: 63.812,91.339,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.707 | Acc: 63.699,91.290,99.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.702 | Acc: 63.675,91.213,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.704 | Acc: 63.625,91.312,99.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.710 | Acc: 63.412,91.232,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.717 | Acc: 63.303,91.139,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.715 | Acc: 63.301,91.142,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.712 | Acc: 63.423,91.074,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.713 | Acc: 63.411,91.037,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.712 | Acc: 63.395,90.987,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.714 | Acc: 63.437,90.909,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.718 | Acc: 63.318,90.895,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.720 | Acc: 63.259,90.868,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.721 | Acc: 63.240,90.783,99.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.725 | Acc: 63.151,90.748,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.730 | Acc: 63.050,90.666,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.113 | Acc: 58.594,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.378 | Acc: 54.762,69.643,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.399 | Acc: 54.592,68.598,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.436 | Acc: 54.367,68.161,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.399 | Acc: 65.625,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.677 | Acc: 63.132,91.406,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.710 | Acc: 63.319,90.816,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.702 | Acc: 63.525,91.099,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.690 | Acc: 63.706,91.194,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.701 | Acc: 63.444,91.027,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.712 | Acc: 63.210,90.883,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.715 | Acc: 63.176,90.841,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.713 | Acc: 63.286,90.872,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.715 | Acc: 63.363,90.789,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.711 | Acc: 63.417,90.792,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.713 | Acc: 63.341,90.791,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.717 | Acc: 63.184,90.807,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.720 | Acc: 63.132,90.855,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.721 | Acc: 63.070,90.870,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.719 | Acc: 63.118,90.890,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.722 | Acc: 63.125,90.812,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.724 | Acc: 63.070,90.833,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.727 | Acc: 63.024,90.751,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.728 | Acc: 63.004,90.723,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.762 | Acc: 55.469,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.411 | Acc: 54.427,68.638,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.448 | Acc: 54.707,68.274,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.468 | Acc: 54.290,68.135,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.019 | Acc: 54.688,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.693 | Acc: 64.025,90.885,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.675 | Acc: 64.005,91.444,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.699 | Acc: 63.576,91.214,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.703 | Acc: 63.368,91.127,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.707 | Acc: 63.181,91.143,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.708 | Acc: 63.294,91.167,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.705 | Acc: 63.475,91.262,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.710 | Acc: 63.233,91.091,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.716 | Acc: 63.052,90.992,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.718 | Acc: 63.036,90.975,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.724 | Acc: 62.981,90.872,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.729 | Acc: 62.863,90.807,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.730 | Acc: 62.994,90.757,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.730 | Acc: 63.031,90.717,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.729 | Acc: 62.980,90.721,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.726 | Acc: 63.067,90.798,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.725 | Acc: 63.114,90.779,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.722 | Acc: 63.177,90.792,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.724 | Acc: 63.166,90.754,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.976 | Acc: 53.125,75.781,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.421 | Acc: 53.906,69.159,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.446 | Acc: 54.249,68.388,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.490 | Acc: 54.137,68.186,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.696 | Acc: 55.469,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.700 | Acc: 63.951,91.592,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.689 | Acc: 64.425,91.349,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.707 | Acc: 64.037,91.112,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.699 | Acc: 64.130,91.020,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.695 | Acc: 64.240,91.066,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.692 | Acc: 64.108,91.122,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.694 | Acc: 64.018,91.162,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.702 | Acc: 63.898,91.033,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.707 | Acc: 63.769,90.919,99.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.707 | Acc: 63.794,90.924,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.708 | Acc: 63.702,90.869,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.708 | Acc: 63.667,90.868,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.710 | Acc: 63.506,90.838,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.711 | Acc: 63.426,90.795,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.717 | Acc: 63.362,90.755,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.717 | Acc: 63.379,90.769,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.716 | Acc: 63.373,90.792,99.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.716 | Acc: 63.312,90.776,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.718 | Acc: 63.234,90.732,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.929 | Acc: 50.000,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.472 | Acc: 53.274,68.452,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.487 | Acc: 53.868,67.931,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.515 | Acc: 53.881,67.841,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.614 | Acc: 65.625,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.656 | Acc: 63.170,91.332,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 63.472,91.521,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.672 | Acc: 63.601,91.586,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.666 | Acc: 63.686,91.416,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 63.699,91.259,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.677 | Acc: 63.656,91.361,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.678 | Acc: 63.819,91.307,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.690 | Acc: 63.500,91.183,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.698 | Acc: 63.290,91.186,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.702 | Acc: 63.165,91.150,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.701 | Acc: 63.214,91.081,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.703 | Acc: 63.255,91.033,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.702 | Acc: 63.335,91.035,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.701 | Acc: 63.429,91.009,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.703 | Acc: 63.357,91.025,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.702 | Acc: 63.486,91.024,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.703 | Acc: 63.467,91.010,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.708 | Acc: 63.400,90.947,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.708 | Acc: 63.412,90.914,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.983 | Acc: 53.125,75.000,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.445 | Acc: 54.129,69.048,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.485 | Acc: 54.154,68.274,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.504 | Acc: 54.290,68.174,74.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 1.718 | Acc: 64.062,92.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.705 | Acc: 62.984,91.629,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.683 | Acc: 63.853,91.845,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.689 | Acc: 63.537,91.701,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.697 | Acc: 63.407,91.580,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.701 | Acc: 63.436,91.391,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.697 | Acc: 63.694,91.309,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.694 | Acc: 63.708,91.340,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.686 | Acc: 63.718,91.367,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.684 | Acc: 63.773,91.311,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.685 | Acc: 63.748,91.274,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.685 | Acc: 63.812,91.215,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.685 | Acc: 63.904,91.176,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.692 | Acc: 63.826,91.107,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.695 | Acc: 63.721,91.131,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.695 | Acc: 63.655,91.144,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.703 | Acc: 63.532,91.053,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.710 | Acc: 63.410,90.978,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.710 | Acc: 63.344,90.980,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.715 | Acc: 63.279,90.900,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.023 | Acc: 57.031,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.469 | Acc: 54.055,69.048,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.494 | Acc: 54.383,68.407,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.525 | Acc: 54.214,68.494,74.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.892 | Acc: 56.250,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.687 | Acc: 63.021,92.076,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.680 | Acc: 63.415,91.921,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.669 | Acc: 63.614,91.714,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.668 | Acc: 63.407,91.889,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.663 | Acc: 63.575,91.870,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.675 | Acc: 63.623,91.555,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.685 | Acc: 63.348,91.578,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.688 | Acc: 63.335,91.498,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.697 | Acc: 63.147,91.380,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.691 | Acc: 63.437,91.406,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.698 | Acc: 63.409,91.265,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.701 | Acc: 63.333,91.257,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.696 | Acc: 63.464,91.263,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.697 | Acc: 63.476,91.198,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.699 | Acc: 63.401,91.206,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.695 | Acc: 63.388,91.226,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.697 | Acc: 63.311,91.198,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.699 | Acc: 63.294,91.151,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.702 | Acc: 63.212,91.111,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.934 | Acc: 57.812,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.460 | Acc: 54.092,67.671,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.504 | Acc: 54.192,67.359,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.524 | Acc: 54.239,67.252,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.545 | Acc: 65.625,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.703 | Acc: 64.732,91.034,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 64.444,91.349,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.681 | Acc: 64.165,91.201,99.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.679 | Acc: 63.947,91.300,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.687 | Acc: 63.738,91.228,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.681 | Acc: 63.727,91.245,99.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.685 | Acc: 63.630,91.284,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.681 | Acc: 63.684,91.261,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.679 | Acc: 63.726,91.311,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.681 | Acc: 63.650,91.321,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.684 | Acc: 63.550,91.328,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.686 | Acc: 63.541,91.306,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.685 | Acc: 63.640,91.284,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.690 | Acc: 63.609,91.214,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.692 | Acc: 63.572,91.178,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.695 | Acc: 63.527,91.148,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.693 | Acc: 63.547,91.127,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.694 | Acc: 63.508,91.123,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.693 | Acc: 63.482,91.105,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.293 | Acc: 57.031,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 54.278,69.048,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 53.982,67.931,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.545 | Acc: 53.970,67.815,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.694 | Acc: 67.188,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.665 | Acc: 64.100,92.188,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.658 | Acc: 64.120,91.921,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.679 | Acc: 63.768,91.650,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.672 | Acc: 63.947,91.638,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.701 | Acc: 63.498,91.313,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.709 | Acc: 63.352,91.309,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.702 | Acc: 63.226,91.456,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.695 | Acc: 63.412,91.421,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.696 | Acc: 63.532,91.372,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.696 | Acc: 63.514,91.383,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.690 | Acc: 63.599,91.435,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.695 | Acc: 63.466,91.267,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.694 | Acc: 63.482,91.263,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.691 | Acc: 63.607,91.273,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.696 | Acc: 63.499,91.139,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.696 | Acc: 63.583,91.100,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.698 | Acc: 63.501,91.031,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.700 | Acc: 63.489,90.984,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.701 | Acc: 63.503,90.990,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.097 | Acc: 51.562,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.471 | Acc: 53.460,68.564,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.499 | Acc: 53.792,67.835,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.539 | Acc: 53.740,67.559,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.880 | Acc: 58.594,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.666 | Acc: 63.839,91.704,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.668 | Acc: 63.853,91.883,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.665 | Acc: 64.229,91.752,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.675 | Acc: 64.246,91.435,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.669 | Acc: 64.086,91.623,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.680 | Acc: 63.740,91.458,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.678 | Acc: 63.758,91.500,99.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.674 | Acc: 63.708,91.576,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.682 | Acc: 63.566,91.501,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.684 | Acc: 63.433,91.523,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.691 | Acc: 63.345,91.406,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.692 | Acc: 63.330,91.406,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.692 | Acc: 63.317,91.319,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.696 | Acc: 63.259,91.309,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.695 | Acc: 63.279,91.305,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.695 | Acc: 63.257,91.231,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.693 | Acc: 63.274,91.262,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.693 | Acc: 63.281,91.246,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.695 | Acc: 63.220,91.207,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.082 | Acc: 54.688,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 53.869,68.713,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.526 | Acc: 53.525,67.854,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.550 | Acc: 53.586,67.892,74.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.662 | Acc: 64.844,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.698 | Acc: 63.579,90.699,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.667 | Acc: 63.777,91.273,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.667 | Acc: 63.883,91.342,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.666 | Acc: 64.034,91.271,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.668 | Acc: 64.117,91.120,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.677 | Acc: 63.875,91.012,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.675 | Acc: 63.808,91.090,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.678 | Acc: 63.733,91.091,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.674 | Acc: 63.769,91.186,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.671 | Acc: 63.814,91.220,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.673 | Acc: 63.758,91.212,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.680 | Acc: 63.557,91.189,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.683 | Acc: 63.530,91.125,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.685 | Acc: 63.604,91.081,99.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.686 | Acc: 63.684,91.069,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.682 | Acc: 63.744,91.095,99.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.685 | Acc: 63.627,91.088,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.688 | Acc: 63.578,91.036,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.686 | Acc: 63.599,91.025,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.137 | Acc: 58.594,76.562,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.527 | Acc: 53.683,68.713,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 53.849,68.312,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 53.842,67.687,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.715 | Acc: 66.406,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.657 | Acc: 63.579,92.076,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.649 | Acc: 64.024,91.502,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.653 | Acc: 63.870,91.457,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.655 | Acc: 63.870,91.503,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.662 | Acc: 63.823,91.290,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.666 | Acc: 64.121,91.225,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.662 | Acc: 64.129,91.334,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.671 | Acc: 63.839,91.173,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.668 | Acc: 63.946,91.234,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.670 | Acc: 63.911,91.196,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.671 | Acc: 63.857,91.222,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.673 | Acc: 63.858,91.238,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.674 | Acc: 63.814,91.272,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 63.751,91.198,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.676 | Acc: 63.759,91.238,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 63.649,91.229,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.680 | Acc: 63.666,91.214,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.684 | Acc: 63.632,91.151,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.685 | Acc: 63.665,91.156,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.207 | Acc: 57.812,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 53.646,68.564,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.541 | Acc: 53.944,68.083,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.587 | Acc: 53.740,67.956,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 1.665 | Acc: 68.750,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.638 | Acc: 64.249,91.369,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.663 | Acc: 63.758,91.120,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.673 | Acc: 64.114,91.112,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.681 | Acc: 63.764,91.020,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.680 | Acc: 63.691,91.159,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.671 | Acc: 63.862,91.193,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.674 | Acc: 63.785,91.196,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.668 | Acc: 63.912,91.135,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.671 | Acc: 63.769,91.152,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.671 | Acc: 63.923,91.161,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.675 | Acc: 63.790,91.166,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.678 | Acc: 63.686,91.153,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.677 | Acc: 63.766,91.155,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.682 | Acc: 63.743,91.100,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.682 | Acc: 63.806,91.092,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.682 | Acc: 63.719,91.075,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.681 | Acc: 63.710,91.115,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.687 | Acc: 63.556,91.108,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.687 | Acc: 63.542,91.078,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.234 | Acc: 56.250,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.588 | Acc: 53.051,68.527,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.596 | Acc: 53.316,68.083,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.614 | Acc: 53.330,67.994,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 1.774 | Acc: 58.594,89.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.642 | Acc: 64.881,92.039,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.653 | Acc: 64.386,91.825,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.633 | Acc: 65.126,91.893,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.654 | Acc: 64.660,91.840,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.658 | Acc: 64.465,91.747,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.660 | Acc: 64.276,91.677,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.666 | Acc: 64.090,91.628,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.663 | Acc: 64.135,91.610,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.665 | Acc: 64.067,91.592,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.660 | Acc: 64.136,91.647,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.667 | Acc: 63.932,91.530,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.671 | Acc: 63.839,91.461,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.674 | Acc: 63.823,91.460,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.676 | Acc: 63.851,91.412,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.675 | Acc: 63.748,91.427,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.676 | Acc: 63.770,91.445,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.677 | Acc: 63.774,91.427,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.680 | Acc: 63.770,91.372,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.681 | Acc: 63.712,91.332,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.723 | Acc: 56.250,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.617 | Acc: 53.088,67.560,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.652 | Acc: 53.468,67.607,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.679 | Acc: 53.176,67.482,74.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.992 | Acc: 58.594,87.500,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.690 | Acc: 62.946,91.406,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.651 | Acc: 63.796,91.711,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.660 | Acc: 64.139,91.662,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.655 | Acc: 64.198,91.725,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.660 | Acc: 64.264,91.638,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.665 | Acc: 64.192,91.677,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.678 | Acc: 63.797,91.567,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.678 | Acc: 63.689,91.518,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.678 | Acc: 63.747,91.510,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.667 | Acc: 64.016,91.589,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.671 | Acc: 63.903,91.576,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.673 | Acc: 63.845,91.539,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.674 | Acc: 63.832,91.502,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.674 | Acc: 63.804,91.448,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.671 | Acc: 63.829,91.471,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.672 | Acc: 63.732,91.472,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.674 | Acc: 63.703,91.466,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.678 | Acc: 63.617,91.428,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.676 | Acc: 63.673,91.433,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.240 | Acc: 54.688,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 53.311,68.601,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.590 | Acc: 53.525,68.026,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.623 | Acc: 53.407,67.777,74.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.597 | Acc: 61.719,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.675 | Acc: 62.760,91.741,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.654 | Acc: 62.862,91.635,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.652 | Acc: 63.281,91.931,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.635 | Acc: 64.082,92.033,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.639 | Acc: 64.039,91.986,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.638 | Acc: 64.146,92.000,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.641 | Acc: 64.057,91.982,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.647 | Acc: 63.791,91.984,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.650 | Acc: 63.773,91.967,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.653 | Acc: 63.934,91.884,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.656 | Acc: 64.027,91.891,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.656 | Acc: 64.017,91.818,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.654 | Acc: 64.095,91.798,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.655 | Acc: 64.101,91.768,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.657 | Acc: 63.992,91.762,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.655 | Acc: 64.026,91.725,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.657 | Acc: 63.946,91.665,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.659 | Acc: 63.939,91.610,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.665 | Acc: 63.868,91.550,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.147 | Acc: 53.906,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.539 | Acc: 53.981,68.527,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 54.078,67.683,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.598 | Acc: 53.778,67.700,74.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.582 | Acc: 66.406,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.681 | Acc: 63.951,91.146,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.670 | Acc: 63.681,91.559,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.661 | Acc: 63.870,91.739,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.651 | Acc: 63.850,92.014,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.661 | Acc: 63.683,91.870,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.663 | Acc: 63.772,91.703,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.670 | Acc: 63.580,91.683,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.673 | Acc: 63.475,91.610,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.678 | Acc: 63.428,91.501,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.677 | Acc: 63.464,91.457,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.677 | Acc: 63.377,91.470,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.677 | Acc: 63.414,91.474,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.680 | Acc: 63.344,91.424,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 63.398,91.479,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.679 | Acc: 63.432,91.432,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.680 | Acc: 63.396,91.367,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.683 | Acc: 63.403,91.383,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.681 | Acc: 63.521,91.350,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.681 | Acc: 63.581,91.326,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.296 | Acc: 53.125,75.000,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.525 | Acc: 54.129,68.862,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 54.230,68.083,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 54.162,67.636,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.521 | Acc: 64.062,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.629 | Acc: 63.690,92.336,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.639 | Acc: 64.425,92.188,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.640 | Acc: 64.395,92.136,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.642 | Acc: 64.082,92.178,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.645 | Acc: 64.217,91.963,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.646 | Acc: 64.159,91.910,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.649 | Acc: 64.140,91.811,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.645 | Acc: 64.140,91.751,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.645 | Acc: 64.097,91.743,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.641 | Acc: 64.086,91.795,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.642 | Acc: 64.112,91.753,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.650 | Acc: 63.998,91.692,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.651 | Acc: 63.913,91.673,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.655 | Acc: 63.818,91.637,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.654 | Acc: 63.894,91.585,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.660 | Acc: 63.817,91.508,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.662 | Acc: 63.808,91.468,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.661 | Acc: 63.792,91.517,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.660 | Acc: 63.812,91.527,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.248 | Acc: 56.250,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.647 | Acc: 53.348,67.708,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 53.811,67.797,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.622 | Acc: 53.509,67.520,74.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.635 | Acc: 64.062,91.406,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.684 | Acc: 63.318,91.853,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.669 | Acc: 63.929,91.616,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.689 | Acc: 63.678,91.432,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.673 | Acc: 63.580,91.541,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.655 | Acc: 64.055,91.723,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.667 | Acc: 63.798,91.619,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.670 | Acc: 63.835,91.584,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.670 | Acc: 63.786,91.659,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.668 | Acc: 63.838,91.678,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.663 | Acc: 63.923,91.671,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 64.017,91.678,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.659 | Acc: 63.978,91.701,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.659 | Acc: 63.940,91.667,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.659 | Acc: 63.904,91.640,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.656 | Acc: 63.873,91.687,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.659 | Acc: 63.778,91.630,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 63.767,91.576,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.664 | Acc: 63.658,91.508,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.664 | Acc: 63.642,91.449,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.232 | Acc: 55.469,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.531 | Acc: 54.204,68.527,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.540 | Acc: 54.516,67.931,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 54.265,67.674,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.848 | Acc: 57.031,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.679 | Acc: 62.649,91.964,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.695 | Acc: 62.538,91.616,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.687 | Acc: 63.204,91.778,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.676 | Acc: 63.513,91.811,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.665 | Acc: 63.753,91.886,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.666 | Acc: 63.527,91.845,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.666 | Acc: 63.630,91.927,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.659 | Acc: 63.771,91.882,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.661 | Acc: 63.760,91.769,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.659 | Acc: 63.787,91.752,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 63.861,91.785,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.657 | Acc: 63.855,91.730,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.654 | Acc: 63.874,91.765,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.657 | Acc: 63.837,91.729,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.659 | Acc: 63.746,91.702,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 63.829,91.640,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.659 | Acc: 63.783,91.622,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.659 | Acc: 63.837,91.586,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.657 | Acc: 63.870,91.646,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.159 | Acc: 56.250,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.541 | Acc: 54.092,68.899,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 54.002,67.721,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.615 | Acc: 54.086,67.674,74.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.610 | Acc: 69.531,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.653 | Acc: 63.914,91.890,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.629 | Acc: 64.558,91.482,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.647 | Acc: 63.998,91.304,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.647 | Acc: 64.120,91.551,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.641 | Acc: 64.055,91.847,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.640 | Acc: 64.004,91.800,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.644 | Acc: 63.874,91.772,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.641 | Acc: 63.878,91.833,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.643 | Acc: 63.911,91.834,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.645 | Acc: 63.969,91.779,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.649 | Acc: 63.903,91.756,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.654 | Acc: 63.755,91.649,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.656 | Acc: 63.757,91.577,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.657 | Acc: 63.715,91.534,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.657 | Acc: 63.746,91.466,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.661 | Acc: 63.668,91.435,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.663 | Acc: 63.687,91.477,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.663 | Acc: 63.736,91.441,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.662 | Acc: 63.792,91.472,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.255 | Acc: 52.344,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.589 | Acc: 53.237,67.560,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.622 | Acc: 53.354,67.454,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 53.368,67.431,74.296,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.641 | Acc: 65.625,92.969,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.638 | Acc: 64.025,92.262,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.616 | Acc: 64.710,92.283,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.622 | Acc: 64.754,92.098,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.637 | Acc: 64.400,92.014,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.638 | Acc: 64.318,91.917,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.640 | Acc: 64.301,91.813,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.647 | Acc: 64.112,91.678,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.644 | Acc: 64.169,91.697,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.643 | Acc: 64.179,91.799,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.649 | Acc: 63.961,91.721,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.650 | Acc: 63.946,91.678,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.652 | Acc: 63.978,91.623,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.656 | Acc: 63.946,91.547,99.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.656 | Acc: 63.901,91.581,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.657 | Acc: 63.850,91.552,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.655 | Acc: 63.824,91.586,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.653 | Acc: 63.886,91.576,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.655 | Acc: 63.848,91.536,99.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.657 | Acc: 63.841,91.488,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.316 | Acc: 58.594,74.219,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.669 | Acc: 53.385,68.713,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.672 | Acc: 53.601,67.816,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.700 | Acc: 53.317,67.661,74.078,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.700 | Acc: 64.062,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.635 | Acc: 64.397,91.220,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.627 | Acc: 64.062,91.787,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.602 | Acc: 64.383,91.867,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.620 | Acc: 64.545,91.802,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.629 | Acc: 64.403,91.646,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.632 | Acc: 64.579,91.542,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.641 | Acc: 64.345,91.534,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.631 | Acc: 64.519,91.581,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.638 | Acc: 64.416,91.527,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.643 | Acc: 64.303,91.492,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.646 | Acc: 64.200,91.537,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.646 | Acc: 64.085,91.542,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.648 | Acc: 64.060,91.550,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.650 | Acc: 63.960,91.554,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.656 | Acc: 63.842,91.482,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.654 | Acc: 63.851,91.452,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.656 | Acc: 63.884,91.425,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.657 | Acc: 63.857,91.443,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.658 | Acc: 63.870,91.382,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 53.125,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 54.688,67.969,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.577 | Acc: 54.688,67.759,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 54.457,67.520,74.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.672 | Acc: 63.281,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.641 | Acc: 64.025,92.336,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.637 | Acc: 63.986,92.245,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.632 | Acc: 64.267,92.149,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.640 | Acc: 63.937,92.236,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.630 | Acc: 64.256,92.195,99.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.642 | Acc: 64.108,92.039,99.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.639 | Acc: 64.129,92.055,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.638 | Acc: 64.135,91.896,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.639 | Acc: 64.136,91.907,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.637 | Acc: 64.191,91.923,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.636 | Acc: 64.250,91.869,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.634 | Acc: 64.273,91.880,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.634 | Acc: 64.227,91.813,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.635 | Acc: 64.132,91.812,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.636 | Acc: 64.109,91.822,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.641 | Acc: 63.975,91.742,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.643 | Acc: 63.978,91.706,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.645 | Acc: 63.972,91.668,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.648 | Acc: 63.921,91.611,99.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.215 | Acc: 53.125,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.676 | Acc: 52.604,66.890,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.677 | Acc: 53.430,66.864,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 53.074,67.098,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.581 | Acc: 65.625,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.553 | Acc: 65.811,92.299,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.604 | Acc: 64.291,92.283,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.616 | Acc: 63.909,92.239,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.607 | Acc: 64.342,92.390,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.597 | Acc: 64.271,92.497,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.601 | Acc: 64.360,92.459,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.608 | Acc: 64.423,92.237,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.606 | Acc: 64.572,92.212,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.612 | Acc: 64.481,92.140,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.610 | Acc: 64.552,92.094,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.606 | Acc: 64.699,92.085,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.613 | Acc: 64.682,92.029,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.619 | Acc: 64.529,91.993,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.621 | Acc: 64.413,91.976,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.621 | Acc: 64.366,91.982,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.629 | Acc: 64.320,91.905,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.632 | Acc: 64.321,91.828,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.637 | Acc: 64.225,91.737,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.642 | Acc: 64.177,91.671,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.370 | Acc: 57.031,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.656 | Acc: 53.237,67.857,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.700 | Acc: 53.468,67.340,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.733 | Acc: 53.202,67.021,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.695 | Acc: 62.500,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.656 | Acc: 63.207,92.225,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.640 | Acc: 63.510,92.378,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.637 | Acc: 63.845,92.098,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.644 | Acc: 63.976,91.831,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.639 | Acc: 64.078,91.855,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.630 | Acc: 64.334,91.871,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.632 | Acc: 64.389,91.833,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.629 | Acc: 64.407,91.858,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.625 | Acc: 64.421,91.959,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.629 | Acc: 64.327,91.912,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.634 | Acc: 64.229,91.841,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.636 | Acc: 64.189,91.834,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.642 | Acc: 64.060,91.768,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.642 | Acc: 64.004,91.807,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.643 | Acc: 63.930,91.767,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.642 | Acc: 64.014,91.752,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.642 | Acc: 64.035,91.750,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.644 | Acc: 64.021,91.701,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.642 | Acc: 64.040,91.740,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.348 | Acc: 55.469,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.582 | Acc: 54.613,67.597,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.645 | Acc: 54.402,66.902,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.685 | Acc: 54.098,66.995,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.464 | Acc: 67.188,94.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.573 | Acc: 64.621,93.601,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.610 | Acc: 63.853,92.740,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.614 | Acc: 63.947,92.456,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.613 | Acc: 64.101,92.448,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.617 | Acc: 64.209,92.288,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.621 | Acc: 64.224,92.207,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.624 | Acc: 64.262,92.160,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.623 | Acc: 64.276,92.110,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.635 | Acc: 63.998,92.019,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.637 | Acc: 63.872,91.974,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.637 | Acc: 63.840,91.979,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.640 | Acc: 63.823,91.889,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.639 | Acc: 63.880,91.855,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.644 | Acc: 63.865,91.834,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.645 | Acc: 63.982,91.796,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.645 | Acc: 63.968,91.776,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.647 | Acc: 63.991,91.706,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.648 | Acc: 64.095,91.657,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.649 | Acc: 64.171,91.589,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.287 | Acc: 59.375,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.632 | Acc: 53.720,67.671,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.656 | Acc: 54.154,67.149,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 53.650,66.829,74.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.573 | Acc: 66.406,93.750,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.630 | Acc: 63.876,92.374,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.605 | Acc: 64.120,92.473,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.601 | Acc: 64.498,92.456,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.609 | Acc: 64.612,92.390,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.624 | Acc: 64.465,92.249,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.636 | Acc: 64.224,92.097,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.634 | Acc: 64.212,92.127,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.644 | Acc: 64.203,91.896,99.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.646 | Acc: 64.123,91.920,99.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.641 | Acc: 64.218,91.873,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.642 | Acc: 64.158,91.869,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.643 | Acc: 64.124,91.828,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.643 | Acc: 64.083,91.834,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.641 | Acc: 64.074,91.896,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.642 | Acc: 64.086,91.793,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.643 | Acc: 64.121,91.766,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.644 | Acc: 64.161,91.716,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.647 | Acc: 64.078,91.672,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.647 | Acc: 64.056,91.683,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.547 | Acc: 56.250,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.705 | Acc: 52.493,66.667,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.735 | Acc: 52.820,66.311,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.755 | Acc: 52.600,66.329,73.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.630 | Acc: 63.281,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.615 | Acc: 64.211,93.192,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.594 | Acc: 64.863,93.083,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.618 | Acc: 64.549,92.585,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.617 | Acc: 64.448,92.602,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.612 | Acc: 64.643,92.543,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.617 | Acc: 64.327,92.510,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.623 | Acc: 64.157,92.409,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.631 | Acc: 64.077,92.280,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.639 | Acc: 64.058,92.166,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.639 | Acc: 64.105,92.160,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.633 | Acc: 64.264,92.134,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.632 | Acc: 64.215,92.129,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.632 | Acc: 64.278,92.101,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.635 | Acc: 64.271,91.982,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.638 | Acc: 64.265,91.863,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.639 | Acc: 64.257,91.815,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.639 | Acc: 64.216,91.800,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.639 | Acc: 64.290,91.783,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.640 | Acc: 64.290,91.734,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.413 | Acc: 54.688,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.646 | Acc: 54.018,67.522,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.679 | Acc: 53.963,66.806,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.697 | Acc: 53.817,66.650,73.553,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.753 | Acc: 57.812,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.620 | Acc: 64.472,92.262,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.605 | Acc: 64.634,92.130,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.616 | Acc: 64.472,92.200,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.613 | Acc: 64.545,92.303,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.617 | Acc: 64.534,92.304,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.608 | Acc: 64.611,92.297,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.615 | Acc: 64.578,92.193,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.616 | Acc: 64.383,92.226,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.615 | Acc: 64.481,92.088,99.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.619 | Acc: 64.346,92.063,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.621 | Acc: 64.402,92.007,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.621 | Acc: 64.468,91.957,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.625 | Acc: 64.377,91.909,99.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.626 | Acc: 64.388,91.907,99.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.632 | Acc: 64.317,91.814,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.633 | Acc: 64.284,91.803,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.635 | Acc: 64.255,91.789,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.641 | Acc: 64.153,91.740,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.646 | Acc: 64.013,91.722,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.256 | Acc: 56.250,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.699 | Acc: 53.013,68.266,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.735 | Acc: 52.992,67.721,73.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.751 | Acc: 52.984,67.508,73.463,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.723 | Acc: 62.500,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.653 | Acc: 64.658,92.113,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.613 | Acc: 65.111,92.759,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.617 | Acc: 64.857,92.661,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.610 | Acc: 64.863,92.641,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.605 | Acc: 64.898,92.574,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.607 | Acc: 64.811,92.530,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.612 | Acc: 64.705,92.376,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.623 | Acc: 64.611,92.319,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.625 | Acc: 64.645,92.282,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.622 | Acc: 64.630,92.292,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.623 | Acc: 64.610,92.315,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.621 | Acc: 64.685,92.320,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.623 | Acc: 64.601,92.289,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.626 | Acc: 64.502,92.240,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.629 | Acc: 64.483,92.162,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.630 | Acc: 64.459,92.175,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.633 | Acc: 64.376,92.158,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.634 | Acc: 64.357,92.133,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.632 | Acc: 64.327,92.122,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.166 | Acc: 57.031,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.629 | Acc: 54.688,67.820,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.636 | Acc: 54.745,67.530,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.662 | Acc: 54.521,67.328,73.796,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.711 | Acc: 58.594,92.969,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.630 | Acc: 64.583,92.485,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.628 | Acc: 64.482,92.473,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.638 | Acc: 64.011,92.277,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.642 | Acc: 64.149,92.178,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.642 | Acc: 64.217,92.002,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.630 | Acc: 64.379,92.104,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.637 | Acc: 64.090,92.060,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.632 | Acc: 64.174,92.105,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.635 | Acc: 64.054,92.084,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.628 | Acc: 64.222,92.141,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.631 | Acc: 64.140,92.046,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.634 | Acc: 64.105,92.048,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.630 | Acc: 64.134,92.026,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.632 | Acc: 64.140,91.957,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.633 | Acc: 64.135,91.899,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.631 | Acc: 64.255,91.917,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.633 | Acc: 64.216,91.844,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.635 | Acc: 64.147,91.848,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.634 | Acc: 64.130,91.866,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.371 | Acc: 50.781,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.653 | Acc: 53.534,68.155,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.675 | Acc: 53.430,67.569,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.700 | Acc: 53.381,67.239,73.783,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 1.381 | Acc: 69.531,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.560 | Acc: 64.360,92.857,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.559 | Acc: 64.463,92.702,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.566 | Acc: 64.383,92.751,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.568 | Acc: 64.477,92.785,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.568 | Acc: 64.751,92.567,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.577 | Acc: 64.682,92.459,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.590 | Acc: 64.600,92.320,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.597 | Acc: 64.562,92.265,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.600 | Acc: 64.563,92.257,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.604 | Acc: 64.424,92.242,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.602 | Acc: 64.504,92.265,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.602 | Acc: 64.542,92.252,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.605 | Acc: 64.520,92.214,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.607 | Acc: 64.507,92.224,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.609 | Acc: 64.447,92.154,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.613 | Acc: 64.352,92.100,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.616 | Acc: 64.260,92.103,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.620 | Acc: 64.244,92.045,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.624 | Acc: 64.202,92.019,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.274 | Acc: 51.562,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.626 | Acc: 53.125,68.341,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.659 | Acc: 53.220,67.797,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.685 | Acc: 53.087,67.520,74.129,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.583 | Acc: 65.625,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.599 | Acc: 64.323,92.894,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.578 | Acc: 65.015,92.492,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.595 | Acc: 64.652,92.431,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.608 | Acc: 64.333,92.226,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.602 | Acc: 64.596,92.265,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.597 | Acc: 64.695,92.413,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.610 | Acc: 64.561,92.265,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.616 | Acc: 64.528,92.183,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.619 | Acc: 64.494,92.075,99.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.620 | Acc: 64.463,92.083,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.624 | Acc: 64.469,92.011,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.620 | Acc: 64.552,92.016,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.620 | Acc: 64.613,92.011,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.625 | Acc: 64.471,91.962,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.623 | Acc: 64.491,91.962,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.625 | Acc: 64.393,91.990,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.627 | Acc: 64.353,91.954,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.628 | Acc: 64.281,91.934,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.632 | Acc: 64.274,91.872,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.541 | Acc: 50.781,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.637 | Acc: 53.237,67.708,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.691 | Acc: 53.525,67.416,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.727 | Acc: 53.689,67.072,73.899,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 1.351 | Acc: 71.875,96.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.603 | Acc: 64.360,92.597,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.597 | Acc: 64.501,92.321,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.608 | Acc: 64.216,92.380,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.616 | Acc: 64.169,92.236,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.612 | Acc: 64.202,92.265,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.604 | Acc: 64.334,92.336,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.613 | Acc: 64.129,92.232,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.613 | Acc: 64.077,92.328,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.613 | Acc: 64.071,92.300,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.615 | Acc: 64.144,92.269,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.619 | Acc: 64.062,92.184,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.623 | Acc: 64.040,92.116,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.619 | Acc: 64.176,92.122,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.622 | Acc: 64.224,92.057,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.624 | Acc: 64.273,91.990,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.627 | Acc: 64.121,91.947,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.628 | Acc: 64.115,91.931,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.630 | Acc: 64.071,91.878,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.631 | Acc: 64.099,91.884,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.594 | Acc: 49.219,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.685 | Acc: 52.307,68.341,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.701 | Acc: 52.630,68.216,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.733 | Acc: 52.959,67.725,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.417 | Acc: 69.531,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.571 | Acc: 63.914,93.155,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.581 | Acc: 64.653,92.530,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.593 | Acc: 64.524,92.380,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.604 | Acc: 64.236,92.313,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.601 | Acc: 64.248,92.404,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.606 | Acc: 64.198,92.239,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.613 | Acc: 64.090,92.149,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.626 | Acc: 63.621,92.124,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.621 | Acc: 63.760,92.140,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.626 | Acc: 63.779,92.090,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.626 | Acc: 63.801,92.074,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.622 | Acc: 63.965,92.119,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.624 | Acc: 63.982,92.041,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.627 | Acc: 63.985,92.035,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.627 | Acc: 64.031,92.001,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.625 | Acc: 64.116,92.027,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.626 | Acc: 64.095,92.016,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.627 | Acc: 64.082,92.010,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.628 | Acc: 64.093,91.970,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.503 | Acc: 55.469,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.637 | Acc: 54.167,67.783,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.670 | Acc: 54.249,67.397,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.708 | Acc: 53.996,66.906,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.000 | Acc: 59.375,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.587 | Acc: 65.179,92.225,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.609 | Acc: 64.748,92.321,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.583 | Acc: 65.177,92.316,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.585 | Acc: 64.757,92.622,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.582 | Acc: 64.929,92.567,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.590 | Acc: 64.721,92.407,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.600 | Acc: 64.550,92.226,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.599 | Acc: 64.674,92.081,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.604 | Acc: 64.425,92.075,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.605 | Acc: 64.408,92.044,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.612 | Acc: 64.257,92.081,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.613 | Acc: 64.280,92.035,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.618 | Acc: 64.209,91.978,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.619 | Acc: 64.282,91.948,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.621 | Acc: 64.226,91.923,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.622 | Acc: 64.213,91.891,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.622 | Acc: 64.248,91.839,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.624 | Acc: 64.184,91.830,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.630 | Acc: 64.093,91.786,99.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.277 | Acc: 50.781,72.656,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.755 | Acc: 51.823,67.001,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.827 | Acc: 52.725,66.178,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.835 | Acc: 52.523,66.048,73.438,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.769 | Acc: 60.156,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.582 | Acc: 64.137,92.932,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.567 | Acc: 65.168,92.988,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.591 | Acc: 64.741,92.905,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.587 | Acc: 64.882,92.901,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.577 | Acc: 64.983,92.961,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.591 | Acc: 64.676,92.904,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.600 | Acc: 64.528,92.886,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.603 | Acc: 64.441,92.673,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.608 | Acc: 64.296,92.580,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.612 | Acc: 64.206,92.533,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.608 | Acc: 64.359,92.569,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.608 | Acc: 64.357,92.492,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.612 | Acc: 64.395,92.457,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.615 | Acc: 64.310,92.438,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.619 | Acc: 64.205,92.348,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.623 | Acc: 64.123,92.275,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.624 | Acc: 64.209,92.226,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.623 | Acc: 64.218,92.242,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.626 | Acc: 64.151,92.190,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.325 | Acc: 52.344,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.641 | Acc: 54.650,68.118,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.686 | Acc: 54.649,67.226,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.722 | Acc: 54.367,66.842,74.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.424 | Acc: 67.969,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.568 | Acc: 64.918,92.485,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.574 | Acc: 65.530,92.492,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.579 | Acc: 64.933,92.405,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.589 | Acc: 64.593,92.622,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.598 | Acc: 64.488,92.590,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.594 | Acc: 64.637,92.581,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.588 | Acc: 64.744,92.586,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.586 | Acc: 64.698,92.648,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.592 | Acc: 64.675,92.563,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.593 | Acc: 64.611,92.565,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.596 | Acc: 64.575,92.495,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.601 | Acc: 64.552,92.414,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.606 | Acc: 64.485,92.409,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.612 | Acc: 64.441,92.265,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.614 | Acc: 64.397,92.234,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.617 | Acc: 64.364,92.161,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.619 | Acc: 64.370,92.103,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.622 | Acc: 64.292,92.107,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.622 | Acc: 64.284,92.116,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.201 | Acc: 53.906,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.747 | Acc: 52.158,68.229,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.778 | Acc: 52.706,67.492,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.806 | Acc: 52.766,67.008,74.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.915 | Acc: 59.375,88.281,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.551 | Acc: 65.141,93.006,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.555 | Acc: 65.206,93.350,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.581 | Acc: 64.728,92.969,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.586 | Acc: 65.037,92.699,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.590 | Acc: 64.906,92.520,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.597 | Acc: 64.708,92.375,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.595 | Acc: 64.982,92.309,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.596 | Acc: 65.111,92.241,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.599 | Acc: 65.129,92.200,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.602 | Acc: 65.065,92.125,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.609 | Acc: 64.967,92.021,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.614 | Acc: 64.873,91.925,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.619 | Acc: 64.655,91.930,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.619 | Acc: 64.644,91.904,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.621 | Acc: 64.543,91.897,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.625 | Acc: 64.440,91.844,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.625 | Acc: 64.445,91.807,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.629 | Acc: 64.288,91.820,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.631 | Acc: 64.231,91.794,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.663 | Acc: 46.875,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.711 | Acc: 53.460,67.485,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.770 | Acc: 53.735,66.292,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.805 | Acc: 53.356,66.227,73.412,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.712 | Acc: 53.906,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.625 | Acc: 65.476,92.001,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.622 | Acc: 64.825,91.997,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.598 | Acc: 64.882,92.341,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.602 | Acc: 64.747,92.390,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.618 | Acc: 64.148,92.296,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.612 | Acc: 64.198,92.259,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.614 | Acc: 64.184,92.237,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.613 | Acc: 64.169,92.236,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.618 | Acc: 64.283,92.131,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.618 | Acc: 64.389,92.114,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.621 | Acc: 64.501,92.043,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.619 | Acc: 64.477,92.074,99.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.621 | Acc: 64.422,92.080,99.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.620 | Acc: 64.421,92.104,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.620 | Acc: 64.426,92.104,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.625 | Acc: 64.359,92.015,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.624 | Acc: 64.358,92.016,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.623 | Acc: 64.372,92.014,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.622 | Acc: 64.345,92.021,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.400 | Acc: 56.250,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.793 | Acc: 52.679,67.634,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.778 | Acc: 53.468,67.207,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.827 | Acc: 53.304,66.534,73.911,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 1.580 | Acc: 64.062,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.635 | Acc: 63.876,92.560,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.624 | Acc: 63.167,92.835,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.604 | Acc: 63.934,92.700,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.589 | Acc: 64.390,92.814,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.595 | Acc: 64.356,92.605,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.594 | Acc: 64.353,92.627,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.598 | Acc: 64.251,92.498,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.601 | Acc: 64.179,92.435,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.604 | Acc: 64.192,92.369,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.608 | Acc: 64.140,92.300,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.608 | Acc: 64.140,92.230,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.610 | Acc: 64.062,92.246,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.616 | Acc: 63.976,92.196,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.617 | Acc: 64.071,92.115,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.618 | Acc: 64.073,92.120,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.620 | Acc: 63.929,92.117,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.621 | Acc: 63.957,92.094,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.620 | Acc: 63.985,92.090,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.616 | Acc: 64.071,92.112,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.408 | Acc: 54.688,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.744 | Acc: 53.423,67.299,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.761 | Acc: 53.525,67.207,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.794 | Acc: 53.522,66.765,73.668,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.719 | Acc: 57.812,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.534 | Acc: 65.030,92.560,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.559 | Acc: 65.206,93.197,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.567 | Acc: 64.869,93.097,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.574 | Acc: 64.554,93.133,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.574 | Acc: 64.596,93.015,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.587 | Acc: 64.534,92.639,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.587 | Acc: 64.561,92.586,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.587 | Acc: 64.451,92.610,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.595 | Acc: 64.468,92.438,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.604 | Acc: 64.385,92.285,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.605 | Acc: 64.289,92.269,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.607 | Acc: 64.406,92.217,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.603 | Acc: 64.467,92.247,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.608 | Acc: 64.299,92.182,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.610 | Acc: 64.348,92.177,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.611 | Acc: 64.347,92.149,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.617 | Acc: 64.250,92.057,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.619 | Acc: 64.266,92.019,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.619 | Acc: 64.327,92.001,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.094 | Acc: 53.906,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.747 | Acc: 54.055,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.749 | Acc: 53.887,67.245,73.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.790 | Acc: 53.727,66.944,73.694,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.516 | Acc: 67.969,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.544 | Acc: 65.439,93.341,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.547 | Acc: 65.168,93.140,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.568 | Acc: 64.818,92.764,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.577 | Acc: 65.143,92.535,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.575 | Acc: 65.300,92.512,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.572 | Acc: 65.354,92.433,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.593 | Acc: 64.921,92.315,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.591 | Acc: 64.873,92.367,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.586 | Acc: 64.978,92.472,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.585 | Acc: 64.879,92.409,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.584 | Acc: 64.840,92.435,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.587 | Acc: 64.652,92.466,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.591 | Acc: 64.583,92.385,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.592 | Acc: 64.621,92.388,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.595 | Acc: 64.649,92.341,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.598 | Acc: 64.617,92.280,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.603 | Acc: 64.578,92.206,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.610 | Acc: 64.480,92.162,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.613 | Acc: 64.450,92.093,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.867 | Acc: 50.000,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.816 | Acc: 52.716,66.815,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.812 | Acc: 52.496,66.768,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.862 | Acc: 52.677,66.317,73.553,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.528 | Acc: 69.531,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.553 | Acc: 66.295,92.969,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.566 | Acc: 64.806,93.064,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.546 | Acc: 64.908,93.110,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.577 | Acc: 64.641,92.699,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.584 | Acc: 64.442,92.474,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.596 | Acc: 64.282,92.446,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.599 | Acc: 64.262,92.476,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.599 | Acc: 64.189,92.445,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.596 | Acc: 64.403,92.477,99.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.601 | Acc: 64.370,92.374,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.602 | Acc: 64.409,92.272,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.598 | Acc: 64.474,92.337,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.603 | Acc: 64.446,92.256,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.605 | Acc: 64.452,92.179,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.611 | Acc: 64.330,92.107,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.612 | Acc: 64.352,92.068,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.613 | Acc: 64.358,92.064,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.614 | Acc: 64.439,92.036,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.617 | Acc: 64.407,91.999,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.725 | Acc: 57.812,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.724 | Acc: 53.609,67.411,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.771 | Acc: 53.011,67.111,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.816 | Acc: 53.240,66.598,73.924,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.695 | Acc: 58.594,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.591 | Acc: 64.695,92.671,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.561 | Acc: 65.072,92.873,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.533 | Acc: 65.484,93.263,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.528 | Acc: 65.557,93.383,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.527 | Acc: 65.602,93.394,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.521 | Acc: 65.644,93.485,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.522 | Acc: 65.370,93.584,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.521 | Acc: 65.232,93.638,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 65.344,93.841,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.507 | Acc: 65.372,93.836,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.505 | Acc: 65.420,93.853,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.505 | Acc: 65.469,93.886,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.500 | Acc: 65.676,93.927,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 65.736,93.947,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 65.661,93.986,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 65.562,93.998,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 65.579,94.055,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.501 | Acc: 65.525,94.075,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.499 | Acc: 65.617,94.101,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.226 | Acc: 55.469,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.477 | Acc: 56.250,69.420,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.519 | Acc: 56.021,69.036,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.552 | Acc: 55.891,68.801,74.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.429 | Acc: 66.406,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.478 | Acc: 65.625,95.350,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.459 | Acc: 65.930,95.217,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.451 | Acc: 66.470,95.146,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.451 | Acc: 66.532,95.081,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.437 | Acc: 66.801,95.189,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.444 | Acc: 66.503,95.177,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.441 | Acc: 66.406,95.229,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.441 | Acc: 66.222,95.201,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.444 | Acc: 66.225,95.153,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.447 | Acc: 66.185,95.072,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.448 | Acc: 66.194,95.047,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.448 | Acc: 66.147,95.040,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.450 | Acc: 66.104,95.019,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.451 | Acc: 66.100,95.032,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.452 | Acc: 66.097,95.076,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.451 | Acc: 66.190,95.081,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.455 | Acc: 66.115,95.058,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.455 | Acc: 66.123,95.090,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.454 | Acc: 66.187,95.118,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.265 | Acc: 54.688,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.468 | Acc: 56.027,69.531,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.505 | Acc: 55.888,69.169,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.544 | Acc: 55.763,68.916,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.433 | Acc: 64.062,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.463 | Acc: 65.960,94.829,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.456 | Acc: 66.101,94.646,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.441 | Acc: 66.445,94.915,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.434 | Acc: 66.416,95.110,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.428 | Acc: 66.754,95.166,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.433 | Acc: 66.697,95.183,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.429 | Acc: 66.772,95.180,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.436 | Acc: 66.620,95.172,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.438 | Acc: 66.600,95.200,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.435 | Acc: 66.531,95.266,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.438 | Acc: 66.445,95.284,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.441 | Acc: 66.384,95.270,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.444 | Acc: 66.275,95.244,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.446 | Acc: 66.292,95.240,99.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.445 | Acc: 66.391,95.206,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.446 | Acc: 66.399,95.198,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.445 | Acc: 66.431,95.198,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.444 | Acc: 66.413,95.248,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.442 | Acc: 66.470,95.278,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.249 | Acc: 55.469,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.470 | Acc: 55.878,69.457,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.515 | Acc: 55.678,69.207,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 55.584,69.134,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.111 | Acc: 74.219,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.412 | Acc: 66.778,95.647,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.430 | Acc: 66.597,95.484,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.430 | Acc: 66.432,95.479,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.433 | Acc: 66.474,95.534,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.426 | Acc: 66.708,95.560,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.424 | Acc: 66.748,95.616,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.430 | Acc: 66.561,95.590,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.423 | Acc: 66.756,95.662,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.427 | Acc: 66.730,95.641,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.424 | Acc: 66.733,95.686,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.427 | Acc: 66.654,95.609,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.428 | Acc: 66.610,95.598,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.430 | Acc: 66.559,95.591,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.432 | Acc: 66.501,95.557,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.432 | Acc: 66.487,95.549,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.432 | Acc: 66.470,95.551,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.433 | Acc: 66.489,95.555,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.433 | Acc: 66.456,95.581,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.432 | Acc: 66.556,95.581,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.317 | Acc: 53.906,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.483 | Acc: 55.990,69.159,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.511 | Acc: 55.812,69.226,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.544 | Acc: 55.584,69.185,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.600 | Acc: 61.719,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.475 | Acc: 65.179,95.089,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 64.596,95.312,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.473 | Acc: 65.394,95.287,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.461 | Acc: 65.567,95.476,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.446 | Acc: 65.756,95.545,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.449 | Acc: 65.961,95.513,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.439 | Acc: 66.295,95.573,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.439 | Acc: 66.324,95.492,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.435 | Acc: 66.389,95.472,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.436 | Acc: 66.391,95.546,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.433 | Acc: 66.516,95.592,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.434 | Acc: 66.442,95.582,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.432 | Acc: 66.472,95.570,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.431 | Acc: 66.459,95.568,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.428 | Acc: 66.552,95.567,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.427 | Acc: 66.623,95.590,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.430 | Acc: 66.557,95.581,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.426 | Acc: 66.670,95.605,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.426 | Acc: 66.681,95.612,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.270 | Acc: 54.688,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.479 | Acc: 55.692,69.457,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.522 | Acc: 55.697,69.322,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.545 | Acc: 55.751,69.070,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.362 | Acc: 75.000,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.401 | Acc: 68.341,95.871,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.404 | Acc: 67.683,95.884,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.416 | Acc: 67.085,96.017,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.434 | Acc: 66.136,96.074,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.424 | Acc: 66.584,96.024,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.420 | Acc: 66.748,96.010,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.419 | Acc: 66.645,95.988,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.420 | Acc: 66.571,95.987,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.420 | Acc: 66.449,95.986,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.423 | Acc: 66.465,95.919,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.424 | Acc: 66.516,95.814,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.422 | Acc: 66.533,95.779,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.422 | Acc: 66.568,95.785,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.425 | Acc: 66.495,95.757,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.421 | Acc: 66.635,95.824,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.422 | Acc: 66.628,95.836,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.421 | Acc: 66.683,95.835,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.420 | Acc: 66.688,95.854,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.420 | Acc: 66.603,95.862,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.338 | Acc: 53.125,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.472 | Acc: 56.324,69.754,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.528 | Acc: 56.040,69.417,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 55.827,69.224,74.296,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.569 | Acc: 66.406,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.408 | Acc: 67.485,96.354,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.411 | Acc: 66.711,96.437,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.409 | Acc: 66.816,96.196,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.412 | Acc: 66.503,96.123,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.419 | Acc: 66.399,95.970,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.418 | Acc: 66.464,95.900,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.425 | Acc: 66.334,95.894,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.426 | Acc: 66.304,95.900,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.426 | Acc: 66.376,95.904,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.422 | Acc: 66.511,95.958,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.417 | Acc: 66.686,96.037,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.418 | Acc: 66.682,95.990,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.420 | Acc: 66.604,95.986,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.420 | Acc: 66.601,95.932,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.420 | Acc: 66.544,95.881,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.422 | Acc: 66.484,95.872,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.421 | Acc: 66.493,95.901,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.420 | Acc: 66.508,95.912,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.422 | Acc: 66.451,95.895,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.210 | Acc: 56.250,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.461 | Acc: 56.362,69.457,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.505 | Acc: 56.059,69.322,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.536 | Acc: 55.943,69.173,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.171 | Acc: 70.312,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.417 | Acc: 66.109,96.317,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.428 | Acc: 66.444,95.827,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.424 | Acc: 66.329,95.914,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.429 | Acc: 66.483,95.775,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.418 | Acc: 66.607,95.823,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.421 | Acc: 66.561,95.835,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.419 | Acc: 66.572,95.939,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.422 | Acc: 66.426,95.982,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.424 | Acc: 66.514,95.930,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.421 | Acc: 66.593,95.954,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.419 | Acc: 66.643,95.956,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.418 | Acc: 66.675,95.935,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.419 | Acc: 66.595,95.944,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.417 | Acc: 66.601,95.985,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.421 | Acc: 66.474,95.935,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.417 | Acc: 66.569,95.965,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.414 | Acc: 66.564,95.998,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.415 | Acc: 66.536,95.960,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.416 | Acc: 66.511,95.938,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.166 | Acc: 56.250,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 56.510,69.531,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.514 | Acc: 56.117,69.455,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.540 | Acc: 56.148,69.249,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.310 | Acc: 71.094,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.372 | Acc: 67.150,96.652,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.406 | Acc: 66.635,96.437,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.396 | Acc: 66.995,96.401,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.381 | Acc: 67.409,96.518,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.387 | Acc: 67.489,96.380,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.387 | Acc: 67.497,96.339,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.395 | Acc: 67.243,96.133,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.393 | Acc: 67.319,96.137,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.396 | Acc: 67.278,96.107,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.394 | Acc: 67.312,96.129,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.401 | Acc: 67.205,96.034,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.399 | Acc: 67.217,96.061,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.403 | Acc: 67.113,95.986,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.403 | Acc: 67.087,95.966,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.406 | Acc: 67.019,95.972,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.408 | Acc: 66.971,95.999,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.408 | Acc: 66.974,95.968,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.410 | Acc: 66.993,95.962,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.407 | Acc: 66.993,96.014,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.226 | Acc: 55.469,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.483 | Acc: 56.138,69.643,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.518 | Acc: 55.907,69.284,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.543 | Acc: 55.712,69.224,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.366 | Acc: 64.844,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.411 | Acc: 66.890,95.573,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.409 | Acc: 66.749,95.732,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.397 | Acc: 67.303,95.876,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.390 | Acc: 67.670,95.959,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.382 | Acc: 67.582,96.109,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.385 | Acc: 67.317,96.036,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.391 | Acc: 67.127,96.088,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.397 | Acc: 67.124,96.031,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.402 | Acc: 67.054,96.064,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.401 | Acc: 67.013,96.028,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.405 | Acc: 66.792,96.041,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.407 | Acc: 66.786,96.000,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.407 | Acc: 66.756,95.977,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.410 | Acc: 66.726,95.963,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.408 | Acc: 66.780,95.946,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.409 | Acc: 66.774,95.916,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.408 | Acc: 66.851,95.894,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.409 | Acc: 66.785,95.884,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.410 | Acc: 66.751,95.860,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.256 | Acc: 55.469,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.480 | Acc: 55.878,69.457,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.530 | Acc: 55.869,69.303,75.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.564 | Acc: 55.622,68.981,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.306 | Acc: 70.312,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.435 | Acc: 66.927,95.499,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.397 | Acc: 67.435,96.037,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.394 | Acc: 67.405,95.927,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.388 | Acc: 67.294,95.978,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.395 | Acc: 66.870,95.846,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.392 | Acc: 66.929,95.887,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.396 | Acc: 66.827,95.855,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.396 | Acc: 66.838,95.890,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.401 | Acc: 66.864,95.908,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.397 | Acc: 66.904,95.965,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.397 | Acc: 66.876,96.012,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.398 | Acc: 66.811,96.035,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.401 | Acc: 66.724,96.073,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.400 | Acc: 66.757,96.077,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.401 | Acc: 66.725,96.086,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.402 | Acc: 66.732,96.057,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.402 | Acc: 66.780,96.091,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.403 | Acc: 66.761,96.089,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.403 | Acc: 66.708,96.118,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.171 | Acc: 57.031,75.000,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.479 | Acc: 55.729,69.420,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.534 | Acc: 55.964,69.112,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.562 | Acc: 55.853,69.045,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.527 | Acc: 64.844,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.383 | Acc: 66.555,96.354,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.392 | Acc: 66.635,96.418,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.395 | Acc: 66.406,96.542,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.390 | Acc: 66.696,96.316,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.386 | Acc: 66.963,96.241,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.384 | Acc: 67.020,96.313,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.383 | Acc: 67.027,96.304,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.390 | Acc: 66.877,96.317,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.390 | Acc: 66.937,96.310,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.390 | Acc: 66.842,96.327,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.395 | Acc: 66.703,96.207,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.397 | Acc: 66.649,96.181,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.399 | Acc: 66.589,96.199,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.398 | Acc: 66.565,96.177,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.401 | Acc: 66.539,96.127,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.404 | Acc: 66.496,96.094,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.402 | Acc: 66.454,96.126,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.402 | Acc: 66.480,96.124,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.404 | Acc: 66.431,96.108,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.251 | Acc: 55.469,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.517 | Acc: 56.027,69.531,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.553 | Acc: 55.907,69.150,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.584 | Acc: 55.751,68.942,74.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.146 | Acc: 71.094,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.381 | Acc: 67.485,96.280,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.381 | Acc: 67.416,96.132,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.381 | Acc: 67.418,96.055,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.379 | Acc: 67.101,95.997,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.384 | Acc: 66.901,96.132,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.382 | Acc: 67.039,96.184,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.381 | Acc: 66.999,96.149,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.389 | Acc: 66.896,96.055,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.392 | Acc: 66.924,96.085,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.391 | Acc: 66.981,96.090,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.392 | Acc: 66.982,96.104,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.399 | Acc: 66.714,96.091,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.401 | Acc: 66.655,96.088,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.399 | Acc: 66.754,96.088,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.399 | Acc: 66.733,96.094,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.398 | Acc: 66.779,96.072,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.396 | Acc: 66.823,96.114,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.399 | Acc: 66.787,96.102,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.398 | Acc: 66.843,96.149,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.215 | Acc: 55.469,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.500 | Acc: 56.399,69.680,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.546 | Acc: 55.888,69.379,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.572 | Acc: 55.661,69.134,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.272 | Acc: 67.969,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.400 | Acc: 66.406,96.689,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.382 | Acc: 66.654,96.456,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.387 | Acc: 66.714,96.388,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.395 | Acc: 66.753,96.229,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.397 | Acc: 66.847,96.117,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.399 | Acc: 66.781,96.158,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.397 | Acc: 66.816,96.149,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.398 | Acc: 66.785,96.152,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.398 | Acc: 66.747,96.210,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.396 | Acc: 66.822,96.276,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.395 | Acc: 66.908,96.232,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.398 | Acc: 66.834,96.269,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.399 | Acc: 66.909,96.210,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.398 | Acc: 66.923,96.205,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.396 | Acc: 66.964,96.205,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.395 | Acc: 66.978,96.201,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.398 | Acc: 66.871,96.181,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.399 | Acc: 66.956,96.139,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.402 | Acc: 66.943,96.163,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.146 | Acc: 56.250,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.478 | Acc: 55.766,69.606,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.517 | Acc: 56.079,69.284,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.552 | Acc: 55.930,69.006,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.254 | Acc: 65.625,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.365 | Acc: 66.295,96.466,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.375 | Acc: 66.711,96.551,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.390 | Acc: 66.470,96.427,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.395 | Acc: 66.580,96.296,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.394 | Acc: 66.646,96.295,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.391 | Acc: 66.884,96.216,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.391 | Acc: 66.872,96.277,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.392 | Acc: 66.896,96.215,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.395 | Acc: 66.665,96.202,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.395 | Acc: 66.752,96.183,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.397 | Acc: 66.714,96.172,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.401 | Acc: 66.520,96.204,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.400 | Acc: 66.478,96.249,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.397 | Acc: 66.570,96.230,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.395 | Acc: 66.689,96.249,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.398 | Acc: 66.669,96.220,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.398 | Acc: 66.665,96.238,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.398 | Acc: 66.666,96.202,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.398 | Acc: 66.685,96.221,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.220 | Acc: 55.469,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 56.324,69.940,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.534 | Acc: 56.079,69.341,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 55.686,69.070,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.541 | Acc: 61.719,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.408 | Acc: 66.481,95.871,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.410 | Acc: 66.406,95.979,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.393 | Acc: 67.021,96.068,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.393 | Acc: 67.226,96.094,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.391 | Acc: 67.188,96.148,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.391 | Acc: 67.246,96.197,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.395 | Acc: 67.215,96.144,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.396 | Acc: 67.173,96.079,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.396 | Acc: 67.153,96.120,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.397 | Acc: 67.114,96.148,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.393 | Acc: 67.191,96.172,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.397 | Acc: 67.051,96.152,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.397 | Acc: 66.966,96.157,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.394 | Acc: 67.043,96.211,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.398 | Acc: 66.920,96.185,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.399 | Acc: 66.869,96.186,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.399 | Acc: 66.826,96.179,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.397 | Acc: 66.872,96.172,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.396 | Acc: 66.929,96.182,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.189 | Acc: 55.469,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.495 | Acc: 56.473,69.717,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 55.926,69.245,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.580 | Acc: 55.674,69.045,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.583 | Acc: 62.500,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.420 | Acc: 66.927,96.205,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.397 | Acc: 67.130,96.303,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.399 | Acc: 66.970,96.465,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.405 | Acc: 66.657,96.489,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.394 | Acc: 66.824,96.589,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.395 | Acc: 66.865,96.507,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.390 | Acc: 66.883,96.504,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.393 | Acc: 66.853,96.419,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.387 | Acc: 66.976,96.469,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.389 | Acc: 66.873,96.432,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.392 | Acc: 66.820,96.444,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.390 | Acc: 66.974,96.408,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.389 | Acc: 66.999,96.396,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.390 | Acc: 67.035,96.386,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.394 | Acc: 66.879,96.390,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.392 | Acc: 66.910,96.359,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.392 | Acc: 66.903,96.376,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.390 | Acc: 66.898,96.392,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.392 | Acc: 66.921,96.385,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.319 | Acc: 52.344,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 55.729,69.382,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.556 | Acc: 55.755,69.055,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 55.725,69.057,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.472 | Acc: 62.500,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.434 | Acc: 65.960,96.503,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.405 | Acc: 66.711,96.456,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.400 | Acc: 66.714,96.414,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.395 | Acc: 66.705,96.373,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.402 | Acc: 66.692,96.326,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.401 | Acc: 66.826,96.281,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.400 | Acc: 66.838,96.199,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.404 | Acc: 66.639,96.220,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.399 | Acc: 67.006,96.236,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.400 | Acc: 66.954,96.226,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.397 | Acc: 67.071,96.210,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.395 | Acc: 67.058,96.194,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.393 | Acc: 67.092,96.148,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.395 | Acc: 66.993,96.163,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.397 | Acc: 66.946,96.203,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.394 | Acc: 66.990,96.232,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.393 | Acc: 66.988,96.252,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.393 | Acc: 67.008,96.239,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.396 | Acc: 66.884,96.198,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.189 | Acc: 56.250,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 56.176,69.382,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.553 | Acc: 56.021,69.036,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 55.815,68.750,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.456 | Acc: 64.062,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.401 | Acc: 66.927,96.726,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.378 | Acc: 66.806,96.837,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.384 | Acc: 66.598,96.811,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.373 | Acc: 66.898,96.750,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.379 | Acc: 66.723,96.620,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.383 | Acc: 66.755,96.591,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.387 | Acc: 66.822,96.559,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.390 | Acc: 66.867,96.463,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.392 | Acc: 66.872,96.452,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.394 | Acc: 66.807,96.447,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.395 | Acc: 66.724,96.444,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.394 | Acc: 66.688,96.441,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.393 | Acc: 66.628,96.504,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.394 | Acc: 66.631,96.527,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.393 | Acc: 66.687,96.480,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.397 | Acc: 66.603,96.449,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.400 | Acc: 66.516,96.394,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.399 | Acc: 66.599,96.377,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.396 | Acc: 66.634,96.407,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.166 | Acc: 55.469,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 56.064,69.420,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 55.869,68.883,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 55.674,68.788,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.250 | Acc: 71.094,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.406 | Acc: 67.001,96.057,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.399 | Acc: 66.444,96.170,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.395 | Acc: 66.470,96.145,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.390 | Acc: 66.753,96.161,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.398 | Acc: 66.584,96.156,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.396 | Acc: 66.561,96.191,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.390 | Acc: 66.700,96.238,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.395 | Acc: 66.595,96.157,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.397 | Acc: 66.570,96.180,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.394 | Acc: 66.612,96.226,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.394 | Acc: 66.746,96.242,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.393 | Acc: 66.753,96.256,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.393 | Acc: 66.882,96.228,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.393 | Acc: 66.884,96.219,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.395 | Acc: 66.889,96.213,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.393 | Acc: 66.951,96.230,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.395 | Acc: 66.929,96.188,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.396 | Acc: 66.867,96.180,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.397 | Acc: 66.921,96.178,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.254 | Acc: 56.250,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.541 | Acc: 56.213,69.345,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 55.926,68.712,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 55.763,68.391,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.540 | Acc: 61.719,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.406 | Acc: 66.927,96.168,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.396 | Acc: 66.883,96.227,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.398 | Acc: 66.816,96.337,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.398 | Acc: 66.609,96.277,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.391 | Acc: 66.901,96.357,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.390 | Acc: 66.942,96.333,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.392 | Acc: 66.927,96.343,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.390 | Acc: 66.959,96.361,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.396 | Acc: 66.812,96.344,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.395 | Acc: 66.768,96.393,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.391 | Acc: 66.785,96.412,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.391 | Acc: 66.834,96.389,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.393 | Acc: 66.864,96.369,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.396 | Acc: 66.793,96.347,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.394 | Acc: 66.907,96.371,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.394 | Acc: 66.859,96.357,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.390 | Acc: 66.961,96.366,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.386 | Acc: 67.062,96.399,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.388 | Acc: 67.001,96.360,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.206 | Acc: 56.250,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 55.915,69.159,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.576 | Acc: 55.983,68.693,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 55.840,68.481,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.492 | Acc: 63.281,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.370 | Acc: 68.080,96.801,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.378 | Acc: 67.530,96.608,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.374 | Acc: 67.623,96.529,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.371 | Acc: 67.882,96.528,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.377 | Acc: 67.597,96.465,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.377 | Acc: 67.543,96.513,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.374 | Acc: 67.586,96.559,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.374 | Acc: 67.517,96.589,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.377 | Acc: 67.300,96.560,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.376 | Acc: 67.409,96.552,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.386 | Acc: 67.142,96.483,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.387 | Acc: 67.178,96.489,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.390 | Acc: 67.038,96.540,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.390 | Acc: 67.026,96.544,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.389 | Acc: 67.029,96.540,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.387 | Acc: 67.059,96.527,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.388 | Acc: 67.082,96.492,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.385 | Acc: 67.138,96.492,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.384 | Acc: 67.173,96.479,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.226 | Acc: 54.688,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.540 | Acc: 55.915,69.345,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 55.678,68.921,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.598 | Acc: 55.507,68.584,74.936,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.244 | Acc: 70.312,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.388 | Acc: 67.336,96.689,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.393 | Acc: 67.130,96.646,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.396 | Acc: 66.816,96.516,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.389 | Acc: 67.409,96.528,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.391 | Acc: 67.226,96.504,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.386 | Acc: 67.310,96.455,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.390 | Acc: 67.093,96.426,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.389 | Acc: 67.144,96.477,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.393 | Acc: 67.071,96.405,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.389 | Acc: 67.020,96.444,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.384 | Acc: 67.170,96.479,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.385 | Acc: 67.194,96.470,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.385 | Acc: 67.110,96.423,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.387 | Acc: 67.071,96.405,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.387 | Acc: 67.011,96.418,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.386 | Acc: 67.066,96.403,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.387 | Acc: 67.020,96.378,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.385 | Acc: 67.010,96.395,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.386 | Acc: 67.015,96.379,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.348 | Acc: 56.250,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.531 | Acc: 55.878,69.382,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.576 | Acc: 55.659,68.807,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.596 | Acc: 55.507,68.635,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.605 | Acc: 60.938,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.366 | Acc: 67.113,96.391,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.369 | Acc: 66.692,96.437,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.363 | Acc: 66.983,96.491,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.362 | Acc: 66.917,96.451,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.373 | Acc: 66.886,96.419,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.374 | Acc: 66.955,96.404,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.368 | Acc: 67.149,96.487,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.364 | Acc: 67.255,96.482,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.360 | Acc: 67.434,96.569,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.364 | Acc: 67.347,96.599,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.366 | Acc: 67.308,96.610,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.365 | Acc: 67.285,96.609,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.366 | Acc: 67.250,96.567,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.371 | Acc: 67.204,96.550,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.375 | Acc: 67.149,96.506,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.376 | Acc: 67.119,96.500,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.379 | Acc: 67.050,96.467,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.381 | Acc: 66.991,96.477,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.383 | Acc: 66.960,96.467,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.291 | Acc: 53.125,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 55.655,69.792,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 55.736,69.303,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 55.597,68.801,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.404 | Acc: 67.188,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.369 | Acc: 67.522,97.061,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.358 | Acc: 68.140,96.932,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.374 | Acc: 67.828,96.619,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.378 | Acc: 67.303,96.586,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.377 | Acc: 67.280,96.581,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.377 | Acc: 67.381,96.584,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.370 | Acc: 67.437,96.670,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.370 | Acc: 67.493,96.564,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.371 | Acc: 67.438,96.564,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.375 | Acc: 67.351,96.514,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.381 | Acc: 67.276,96.433,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.382 | Acc: 67.152,96.431,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.385 | Acc: 67.053,96.462,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.386 | Acc: 66.973,96.522,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.384 | Acc: 67.032,96.504,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.382 | Acc: 67.056,96.512,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.384 | Acc: 67.009,96.508,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.384 | Acc: 67.010,96.477,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.384 | Acc: 67.015,96.496,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.286 | Acc: 54.688,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 56.213,69.159,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 56.021,68.960,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.614 | Acc: 55.968,68.648,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.196 | Acc: 74.219,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.368 | Acc: 67.150,96.540,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.386 | Acc: 66.502,96.437,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.385 | Acc: 66.624,96.504,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.384 | Acc: 66.821,96.402,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.392 | Acc: 66.723,96.357,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.390 | Acc: 66.826,96.475,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.387 | Acc: 66.966,96.554,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.383 | Acc: 67.105,96.516,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.378 | Acc: 67.149,96.521,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.385 | Acc: 67.071,96.447,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.386 | Acc: 67.021,96.426,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.389 | Acc: 66.893,96.398,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.389 | Acc: 66.921,96.405,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.389 | Acc: 66.859,96.400,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.389 | Acc: 66.803,96.397,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.390 | Acc: 66.818,96.396,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.389 | Acc: 66.828,96.421,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.386 | Acc: 66.926,96.434,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.386 | Acc: 66.948,96.432,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.248 | Acc: 55.469,72.656,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 56.138,68.899,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 56.059,68.769,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 55.879,68.916,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.396 | Acc: 65.625,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.355 | Acc: 68.304,96.689,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.382 | Acc: 67.397,96.418,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.370 | Acc: 67.277,96.606,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.370 | Acc: 67.265,96.653,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.371 | Acc: 67.242,96.682,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.373 | Acc: 67.188,96.617,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.376 | Acc: 66.966,96.637,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.373 | Acc: 67.056,96.642,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.372 | Acc: 67.166,96.586,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.371 | Acc: 67.188,96.591,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.375 | Acc: 67.124,96.546,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.374 | Acc: 67.213,96.551,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.376 | Acc: 67.185,96.516,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.373 | Acc: 67.215,96.536,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.373 | Acc: 67.198,96.530,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.372 | Acc: 67.207,96.537,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.371 | Acc: 67.261,96.547,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.374 | Acc: 67.196,96.505,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.371 | Acc: 67.253,96.500,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.225 | Acc: 54.688,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 56.213,69.568,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.584 | Acc: 56.098,69.055,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 56.032,68.788,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.541 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.334 | Acc: 67.894,96.949,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.366 | Acc: 66.673,96.704,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.365 | Acc: 66.790,96.709,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.357 | Acc: 66.946,96.798,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.369 | Acc: 66.863,96.597,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.375 | Acc: 66.865,96.513,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.371 | Acc: 66.955,96.509,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.372 | Acc: 66.891,96.511,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.374 | Acc: 66.937,96.512,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.371 | Acc: 67.075,96.490,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.377 | Acc: 66.855,96.504,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.378 | Acc: 66.915,96.457,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.373 | Acc: 67.044,96.471,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.373 | Acc: 67.004,96.516,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.371 | Acc: 67.042,96.551,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.374 | Acc: 66.900,96.549,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.374 | Acc: 66.956,96.573,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.373 | Acc: 67.001,96.594,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.375 | Acc: 66.993,96.559,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.154 | Acc: 57.812,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 56.027,69.196,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 55.888,68.941,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 55.686,68.686,74.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.388 | Acc: 71.094,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.404 | Acc: 66.555,96.838,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.395 | Acc: 66.635,96.513,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.391 | Acc: 66.765,96.504,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.402 | Acc: 66.725,96.200,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.398 | Acc: 66.677,96.132,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.386 | Acc: 66.923,96.320,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.379 | Acc: 67.060,96.465,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.377 | Acc: 67.217,96.506,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.383 | Acc: 67.118,96.456,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.382 | Acc: 67.067,96.451,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.377 | Acc: 67.085,96.479,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.377 | Acc: 67.106,96.486,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.374 | Acc: 67.179,96.480,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.373 | Acc: 67.185,96.458,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.377 | Acc: 67.110,96.465,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.377 | Acc: 67.132,96.452,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.378 | Acc: 67.116,96.469,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.379 | Acc: 67.114,96.447,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.379 | Acc: 67.138,96.453,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.313 | Acc: 53.125,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.569 | Acc: 56.213,69.308,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 56.040,68.960,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 55.751,68.673,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.305 | Acc: 69.531,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.354 | Acc: 67.634,96.615,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.363 | Acc: 67.340,96.532,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.376 | Acc: 67.021,96.363,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.388 | Acc: 66.599,96.451,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.384 | Acc: 66.863,96.395,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.379 | Acc: 67.026,96.410,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.377 | Acc: 67.104,96.520,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.376 | Acc: 67.217,96.555,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.377 | Acc: 67.188,96.603,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.376 | Acc: 67.327,96.529,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.381 | Acc: 67.230,96.504,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.379 | Acc: 67.152,96.515,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.377 | Acc: 67.062,96.543,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.376 | Acc: 67.135,96.516,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.378 | Acc: 67.107,96.491,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.378 | Acc: 67.095,96.456,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.380 | Acc: 67.023,96.433,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.382 | Acc: 66.926,96.403,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.382 | Acc: 66.970,96.416,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 58.594,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.551 | Acc: 55.990,69.606,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 55.793,69.284,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.609 | Acc: 55.597,68.916,74.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.386 | Acc: 66.406,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.350 | Acc: 66.741,96.540,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.383 | Acc: 65.968,96.627,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.366 | Acc: 66.522,96.619,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.363 | Acc: 66.802,96.701,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.364 | Acc: 66.731,96.651,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.371 | Acc: 66.639,96.759,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.370 | Acc: 66.694,96.725,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.375 | Acc: 66.625,96.647,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.379 | Acc: 66.613,96.538,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.382 | Acc: 66.604,96.533,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.379 | Acc: 66.823,96.525,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.377 | Acc: 66.844,96.557,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.376 | Acc: 66.885,96.552,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.376 | Acc: 66.865,96.544,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.378 | Acc: 66.819,96.543,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.376 | Acc: 66.910,96.568,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.376 | Acc: 66.887,96.563,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.375 | Acc: 66.947,96.581,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.376 | Acc: 66.948,96.555,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.333 | Acc: 55.469,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 55.543,69.494,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.596 | Acc: 55.564,69.017,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.627 | Acc: 55.866,68.737,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.701 | Acc: 59.375,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.328 | Acc: 68.229,97.098,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.338 | Acc: 68.121,96.989,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.384 | Acc: 67.495,96.657,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.378 | Acc: 67.438,96.566,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.379 | Acc: 67.249,96.627,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.381 | Acc: 67.220,96.610,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.385 | Acc: 67.027,96.476,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.389 | Acc: 66.935,96.492,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.389 | Acc: 66.937,96.482,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.386 | Acc: 67.121,96.463,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.378 | Acc: 67.265,96.511,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.377 | Acc: 67.171,96.570,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.381 | Acc: 66.987,96.543,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.381 | Acc: 67.021,96.527,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.378 | Acc: 67.076,96.551,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.380 | Acc: 66.939,96.534,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.378 | Acc: 66.938,96.566,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.378 | Acc: 66.965,96.566,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.379 | Acc: 66.974,96.574,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.270 | Acc: 56.250,72.656,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.582 | Acc: 55.878,69.568,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 55.926,69.074,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.635 | Acc: 55.712,68.609,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.304 | Acc: 70.312,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.365 | Acc: 66.109,97.061,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.343 | Acc: 66.540,97.104,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.357 | Acc: 66.406,97.067,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.358 | Acc: 66.917,97.087,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.370 | Acc: 66.623,97.092,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.381 | Acc: 66.393,96.927,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.376 | Acc: 66.728,96.969,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.373 | Acc: 66.955,96.914,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.370 | Acc: 67.062,96.957,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.373 | Acc: 67.067,96.836,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.373 | Acc: 67.039,96.818,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.368 | Acc: 67.207,96.810,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.372 | Acc: 67.167,96.800,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.370 | Acc: 67.151,96.786,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.368 | Acc: 67.200,96.761,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.368 | Acc: 67.175,96.763,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.371 | Acc: 67.126,96.760,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.369 | Acc: 67.177,96.728,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.368 | Acc: 67.235,96.705,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.282 | Acc: 54.688,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.593 | Acc: 56.250,69.829,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 56.136,69.379,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.637 | Acc: 55.955,68.942,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.196 | Acc: 66.406,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.356 | Acc: 66.778,97.135,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.361 | Acc: 67.168,97.123,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.358 | Acc: 67.341,97.182,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.357 | Acc: 67.265,96.991,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.369 | Acc: 67.056,96.852,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.359 | Acc: 67.355,96.965,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.361 | Acc: 67.276,96.886,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.364 | Acc: 67.377,96.802,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.368 | Acc: 67.291,96.776,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.370 | Acc: 67.106,96.805,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.371 | Acc: 67.163,96.794,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.370 | Acc: 67.158,96.794,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.372 | Acc: 67.131,96.782,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.373 | Acc: 67.079,96.772,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.374 | Acc: 67.042,96.766,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.374 | Acc: 66.990,96.778,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.373 | Acc: 66.979,96.779,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.372 | Acc: 67.045,96.799,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.372 | Acc: 67.062,96.772,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.214 | Acc: 56.250,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.597 | Acc: 56.027,69.792,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 55.983,69.169,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.640 | Acc: 55.866,68.622,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.443 | Acc: 58.594,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.394 | Acc: 65.923,96.466,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.383 | Acc: 66.406,96.608,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.356 | Acc: 67.252,96.491,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.361 | Acc: 67.390,96.489,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.360 | Acc: 67.365,96.542,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.357 | Acc: 67.323,96.643,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.354 | Acc: 67.448,96.670,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.355 | Acc: 67.513,96.666,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.355 | Acc: 67.537,96.672,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.358 | Acc: 67.483,96.618,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.361 | Acc: 67.438,96.571,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.359 | Acc: 67.457,96.619,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.362 | Acc: 67.388,96.600,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.365 | Acc: 67.315,96.561,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.371 | Acc: 67.193,96.522,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.372 | Acc: 67.151,96.522,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.374 | Acc: 67.064,96.518,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.374 | Acc: 67.088,96.529,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.371 | Acc: 67.171,96.561,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.269 | Acc: 57.031,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.584 | Acc: 55.990,69.903,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 55.869,69.341,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.618 | Acc: 55.686,68.955,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 1.135 | Acc: 72.656,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.395 | Acc: 68.006,96.391,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.377 | Acc: 67.321,96.475,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.386 | Acc: 67.149,96.094,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.393 | Acc: 66.744,96.132,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.390 | Acc: 66.677,96.163,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.390 | Acc: 66.839,96.229,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.383 | Acc: 67.043,96.354,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.385 | Acc: 67.110,96.356,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.381 | Acc: 67.304,96.405,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.380 | Acc: 67.331,96.416,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.378 | Acc: 67.347,96.451,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.377 | Acc: 67.324,96.515,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.377 | Acc: 67.301,96.504,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.376 | Acc: 67.251,96.533,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.376 | Acc: 67.268,96.561,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.376 | Acc: 67.256,96.556,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.379 | Acc: 67.176,96.550,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.379 | Acc: 67.166,96.540,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.379 | Acc: 67.126,96.541,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.133 | Acc: 56.250,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.611 | Acc: 55.878,69.717,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 55.869,69.150,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.643 | Acc: 55.635,68.904,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.303 | Acc: 67.188,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.349 | Acc: 67.634,97.359,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.351 | Acc: 67.854,97.085,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.367 | Acc: 67.200,96.952,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.364 | Acc: 67.139,96.865,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.364 | Acc: 67.157,96.759,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.359 | Acc: 67.362,96.765,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.359 | Acc: 67.287,96.820,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.366 | Acc: 67.061,96.817,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.364 | Acc: 67.196,96.815,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.364 | Acc: 67.168,96.848,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.365 | Acc: 67.163,96.794,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.365 | Acc: 67.162,96.797,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.366 | Acc: 67.101,96.788,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.368 | Acc: 67.068,96.794,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.368 | Acc: 67.047,96.820,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.368 | Acc: 67.117,96.836,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.370 | Acc: 67.048,96.831,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.368 | Acc: 67.110,96.810,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.366 | Acc: 67.140,96.813,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.223 | Acc: 54.688,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.603 | Acc: 55.469,69.382,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.614 | Acc: 55.526,69.093,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.642 | Acc: 55.405,68.840,74.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.212 | Acc: 73.438,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.329 | Acc: 67.522,96.726,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.354 | Acc: 67.378,96.589,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.345 | Acc: 67.572,96.709,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.355 | Acc: 67.052,96.711,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.354 | Acc: 67.033,96.759,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.358 | Acc: 66.974,96.720,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.359 | Acc: 66.899,96.753,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.364 | Acc: 66.814,96.749,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.359 | Acc: 67.088,96.832,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.358 | Acc: 67.195,96.848,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.358 | Acc: 67.237,96.772,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.361 | Acc: 67.158,96.745,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.362 | Acc: 67.089,96.770,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.364 | Acc: 67.051,96.755,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.364 | Acc: 67.014,96.740,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.367 | Acc: 66.954,96.678,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.368 | Acc: 66.949,96.657,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.367 | Acc: 67.038,96.674,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.364 | Acc: 67.132,96.707,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.215 | Acc: 57.031,73.438,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 56.101,69.940,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.614 | Acc: 55.812,69.322,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.642 | Acc: 55.776,68.904,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.298 | Acc: 71.875,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.315 | Acc: 68.378,97.321,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.327 | Acc: 68.331,97.046,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.330 | Acc: 68.186,97.131,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.329 | Acc: 68.017,97.116,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.329 | Acc: 68.108,97.061,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.334 | Acc: 67.962,97.049,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.335 | Acc: 67.963,97.041,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.340 | Acc: 67.915,97.016,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.342 | Acc: 67.869,97.052,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.338 | Acc: 68.070,97.003,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.339 | Acc: 67.993,96.953,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.341 | Acc: 67.816,96.937,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.344 | Acc: 67.801,96.923,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.351 | Acc: 67.666,96.875,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.350 | Acc: 67.644,96.898,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.352 | Acc: 67.560,96.902,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.352 | Acc: 67.559,96.909,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.353 | Acc: 67.545,96.890,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.354 | Acc: 67.464,96.896,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.227 | Acc: 55.469,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.576 | Acc: 56.101,69.531,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 56.288,68.979,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.637 | Acc: 55.917,68.609,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.342 | Acc: 67.969,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.349 | Acc: 68.787,96.466,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.351 | Acc: 68.121,97.085,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.370 | Acc: 67.277,96.977,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.363 | Acc: 67.216,96.943,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.358 | Acc: 67.466,96.983,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.358 | Acc: 67.284,96.978,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.355 | Acc: 67.453,96.997,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.355 | Acc: 67.435,96.996,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.355 | Acc: 67.403,96.996,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.363 | Acc: 67.273,96.941,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.359 | Acc: 67.311,96.949,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.357 | Acc: 67.395,96.998,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.359 | Acc: 67.358,96.974,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.359 | Acc: 67.285,96.970,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.359 | Acc: 67.291,96.981,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.358 | Acc: 67.341,96.977,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.355 | Acc: 67.410,97.001,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.355 | Acc: 67.361,96.998,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.354 | Acc: 67.343,97.006,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.145 | Acc: 57.031,75.000,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 56.064,69.829,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.590 | Acc: 55.964,69.284,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 55.853,68.968,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.224 | Acc: 67.969,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.330 | Acc: 66.704,96.912,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.361 | Acc: 66.311,96.894,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.364 | Acc: 66.419,96.798,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.358 | Acc: 66.551,96.933,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.360 | Acc: 66.739,96.929,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.355 | Acc: 67.039,96.894,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.354 | Acc: 67.115,96.892,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.356 | Acc: 67.158,96.856,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.356 | Acc: 67.200,96.931,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.358 | Acc: 67.102,96.887,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.354 | Acc: 67.142,96.960,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.359 | Acc: 67.106,96.901,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.360 | Acc: 67.122,96.866,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.359 | Acc: 67.143,96.856,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.363 | Acc: 66.990,96.836,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.365 | Acc: 67.029,96.856,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.361 | Acc: 67.149,96.857,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.358 | Acc: 67.224,96.864,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.359 | Acc: 67.239,96.889,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.267 | Acc: 57.031,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 56.436,69.792,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 56.002,69.284,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.627 | Acc: 55.815,68.942,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.615 | Acc: 64.844,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.372 | Acc: 67.708,97.098,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.349 | Acc: 68.502,96.761,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.356 | Acc: 68.174,96.619,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.358 | Acc: 67.795,96.701,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.358 | Acc: 67.760,96.767,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.361 | Acc: 67.717,96.798,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.356 | Acc: 67.697,96.869,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.350 | Acc: 67.828,96.875,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.348 | Acc: 67.757,96.875,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.347 | Acc: 67.802,96.941,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.348 | Acc: 67.721,96.960,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.351 | Acc: 67.661,96.950,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.348 | Acc: 67.726,96.980,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.347 | Acc: 67.782,97.028,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.347 | Acc: 67.730,97.033,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.347 | Acc: 67.755,96.992,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.348 | Acc: 67.740,96.999,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.349 | Acc: 67.648,97.001,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.349 | Acc: 67.632,97.012,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.223 | Acc: 57.031,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 56.622,69.792,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 56.345,69.188,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.615 | Acc: 55.994,68.904,74.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.636 | Acc: 67.188,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.368 | Acc: 67.262,96.912,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.347 | Acc: 67.397,96.818,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.357 | Acc: 67.277,96.709,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.357 | Acc: 66.985,96.730,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.367 | Acc: 66.963,96.805,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.361 | Acc: 67.271,96.843,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.362 | Acc: 67.232,96.847,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.360 | Acc: 67.260,96.856,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.354 | Acc: 67.364,96.892,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.357 | Acc: 67.409,96.856,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.360 | Acc: 67.354,96.847,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.358 | Acc: 67.463,96.859,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.358 | Acc: 67.460,96.824,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.356 | Acc: 67.474,96.797,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.356 | Acc: 67.431,96.828,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.354 | Acc: 67.438,96.838,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.354 | Acc: 67.458,96.831,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.352 | Acc: 67.558,96.830,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.356 | Acc: 67.485,96.816,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.236 | Acc: 55.469,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.598 | Acc: 56.138,69.680,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.617 | Acc: 55.983,69.150,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.645 | Acc: 55.789,68.852,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.385 | Acc: 70.312,98.438,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.265 | Acc: 69.940,97.619,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.300 | Acc: 68.807,97.542,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.316 | Acc: 68.558,97.426,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.338 | Acc: 67.853,97.261,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.342 | Acc: 68.077,97.177,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.341 | Acc: 67.936,97.095,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.342 | Acc: 67.863,97.080,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.339 | Acc: 67.813,97.040,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.338 | Acc: 67.852,97.048,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.334 | Acc: 68.004,97.015,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.334 | Acc: 67.933,97.002,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.337 | Acc: 67.907,96.950,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.339 | Acc: 67.882,96.920,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.343 | Acc: 67.730,96.889,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.345 | Acc: 67.717,96.919,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.345 | Acc: 67.733,96.890,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.345 | Acc: 67.719,96.880,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.345 | Acc: 67.668,96.866,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.346 | Acc: 67.710,96.854,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.218 | Acc: 57.031,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 55.766,69.978,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 55.755,69.493,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.618 | Acc: 55.635,69.045,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 1.178 | Acc: 70.312,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.337 | Acc: 68.229,97.098,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.349 | Acc: 67.759,96.989,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.342 | Acc: 67.610,96.990,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.345 | Acc: 67.843,96.856,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.348 | Acc: 67.814,96.890,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.354 | Acc: 67.620,96.869,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.357 | Acc: 67.603,96.853,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.355 | Acc: 67.551,96.826,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.359 | Acc: 67.434,96.927,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.359 | Acc: 67.347,96.902,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.362 | Acc: 67.276,96.889,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.363 | Acc: 67.129,96.875,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.363 | Acc: 67.155,96.866,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.362 | Acc: 67.188,96.889,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.358 | Acc: 67.247,96.932,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.360 | Acc: 67.209,96.924,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.357 | Acc: 67.295,96.932,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.357 | Acc: 67.311,96.955,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.358 | Acc: 67.304,96.947,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.325 | Acc: 57.031,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.587 | Acc: 55.878,69.792,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 55.964,69.284,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.628 | Acc: 55.827,69.096,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.431 | Acc: 64.062,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.365 | Acc: 67.299,96.689,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.365 | Acc: 67.530,96.665,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.343 | Acc: 67.713,96.901,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.340 | Acc: 67.660,96.894,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.337 | Acc: 68.031,96.929,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.350 | Acc: 67.556,96.862,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.349 | Acc: 67.426,96.886,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.356 | Acc: 67.304,96.788,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.352 | Acc: 67.390,96.853,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.350 | Acc: 67.452,96.817,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.348 | Acc: 67.424,96.843,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.347 | Acc: 67.431,96.907,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.346 | Acc: 67.508,96.914,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.347 | Acc: 67.543,96.928,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.352 | Acc: 67.468,96.909,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.350 | Acc: 67.497,96.938,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.350 | Acc: 67.501,96.939,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.354 | Acc: 67.426,96.864,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.354 | Acc: 67.434,96.859,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.262 | Acc: 54.688,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.569 | Acc: 55.915,69.531,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 55.793,69.303,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 55.789,68.968,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.412 | Acc: 67.188,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.356 | Acc: 66.518,97.098,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.340 | Acc: 67.397,96.837,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.324 | Acc: 67.713,96.862,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.332 | Acc: 67.631,96.807,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.346 | Acc: 67.110,96.774,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.348 | Acc: 67.065,96.759,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.344 | Acc: 67.071,96.814,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.347 | Acc: 67.037,96.870,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.346 | Acc: 67.084,96.897,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.350 | Acc: 67.141,96.836,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.353 | Acc: 67.219,96.840,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.350 | Acc: 67.278,96.911,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.356 | Acc: 67.158,96.917,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.354 | Acc: 67.290,96.869,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.357 | Acc: 67.219,96.839,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.357 | Acc: 67.214,96.858,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.356 | Acc: 67.259,96.877,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.358 | Acc: 67.235,96.866,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.358 | Acc: 67.243,96.861,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.209 | Acc: 55.469,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.570 | Acc: 56.250,69.717,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.596 | Acc: 55.888,69.398,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.615 | Acc: 55.751,69.032,74.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.455 | Acc: 65.625,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.376 | Acc: 67.560,96.689,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.363 | Acc: 67.435,96.856,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.363 | Acc: 67.764,96.709,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.369 | Acc: 67.332,96.672,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.363 | Acc: 67.234,96.883,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.366 | Acc: 67.045,96.881,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.363 | Acc: 67.182,96.869,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.361 | Acc: 67.294,96.894,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.365 | Acc: 67.157,96.910,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.358 | Acc: 67.343,96.957,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.358 | Acc: 67.325,96.942,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.357 | Acc: 67.369,96.982,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.357 | Acc: 67.355,97.007,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.358 | Acc: 67.268,97.006,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.356 | Acc: 67.307,96.989,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.357 | Acc: 67.346,96.965,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.354 | Acc: 67.426,96.978,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.353 | Acc: 67.421,97.009,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.354 | Acc: 67.376,97.000,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.285 | Acc: 54.688,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 55.878,70.015,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 55.983,69.550,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.618 | Acc: 55.751,69.147,74.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.323 | Acc: 71.094,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.391 | Acc: 66.853,96.391,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.374 | Acc: 67.492,96.303,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.363 | Acc: 67.367,96.529,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.361 | Acc: 67.554,96.605,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.356 | Acc: 67.652,96.689,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.357 | Acc: 67.601,96.720,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.359 | Acc: 67.442,96.720,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.362 | Acc: 67.328,96.637,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.357 | Acc: 67.511,96.672,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.359 | Acc: 67.506,96.653,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.359 | Acc: 67.467,96.663,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.360 | Acc: 67.431,96.648,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.361 | Acc: 67.487,96.668,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.361 | Acc: 67.438,96.694,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.360 | Acc: 67.530,96.709,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.364 | Acc: 67.438,96.688,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.361 | Acc: 67.531,96.680,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.360 | Acc: 67.506,96.685,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.361 | Acc: 67.509,96.668,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.167 | Acc: 55.469,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.596 | Acc: 55.618,69.680,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.602 | Acc: 55.678,69.303,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.637 | Acc: 55.571,68.852,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.337 | Acc: 64.844,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.344 | Acc: 68.824,96.763,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.352 | Acc: 67.588,96.818,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.335 | Acc: 67.815,96.926,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.337 | Acc: 67.872,96.894,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.348 | Acc: 67.597,96.898,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.350 | Acc: 67.426,96.888,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.350 | Acc: 67.465,96.897,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.352 | Acc: 67.396,96.909,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.354 | Acc: 67.330,96.866,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.359 | Acc: 67.226,96.824,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.359 | Acc: 67.226,96.833,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.357 | Acc: 67.301,96.807,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.359 | Acc: 67.208,96.803,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.358 | Acc: 67.290,96.839,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.357 | Acc: 67.291,96.846,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.358 | Acc: 67.214,96.819,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.359 | Acc: 67.183,96.827,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.360 | Acc: 67.168,96.825,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.360 | Acc: 67.224,96.828,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.135 | Acc: 54.688,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.592 | Acc: 56.324,69.606,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.602 | Acc: 56.059,69.322,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 55.930,68.981,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.438 | Acc: 67.188,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.326 | Acc: 68.713,97.507,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.340 | Acc: 67.912,97.275,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.352 | Acc: 67.802,97.131,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.360 | Acc: 67.496,96.991,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.359 | Acc: 67.257,97.037,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.358 | Acc: 67.175,96.985,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.363 | Acc: 67.115,96.908,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.364 | Acc: 67.197,96.919,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.366 | Acc: 67.287,96.927,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.363 | Acc: 67.347,96.933,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.361 | Acc: 67.255,96.935,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.357 | Acc: 67.288,96.979,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.354 | Acc: 67.361,96.983,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.352 | Acc: 67.393,97.017,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.353 | Acc: 67.390,97.015,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.353 | Acc: 67.392,97.026,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.355 | Acc: 67.419,96.971,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.356 | Acc: 67.387,96.959,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.354 | Acc: 67.423,96.953,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.234 | Acc: 53.906,75.781,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.601 | Acc: 55.766,69.792,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.617 | Acc: 55.678,69.379,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.646 | Acc: 55.558,69.083,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.210 | Acc: 67.969,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.368 | Acc: 66.220,97.582,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.353 | Acc: 66.959,97.351,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.350 | Acc: 67.418,97.093,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.357 | Acc: 67.419,96.991,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.354 | Acc: 67.675,96.937,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.358 | Acc: 67.607,96.940,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.357 | Acc: 67.525,96.958,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.356 | Acc: 67.547,96.972,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.354 | Acc: 67.554,96.957,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.354 | Acc: 67.413,96.964,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.352 | Acc: 67.552,96.995,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.351 | Acc: 67.641,96.969,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.352 | Acc: 67.628,96.980,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.353 | Acc: 67.568,96.975,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.355 | Acc: 67.502,96.971,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.355 | Acc: 67.492,96.965,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.356 | Acc: 67.465,96.971,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.353 | Acc: 67.499,96.988,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.354 | Acc: 67.475,96.975,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.385 | Acc: 56.250,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.636 | Acc: 55.729,69.457,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.650 | Acc: 55.602,69.188,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.667 | Acc: 55.546,68.878,74.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.381 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.314 | Acc: 67.783,97.210,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.338 | Acc: 67.188,96.932,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.348 | Acc: 67.123,96.977,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.353 | Acc: 67.265,96.827,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.353 | Acc: 67.249,96.860,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.356 | Acc: 67.271,96.914,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.357 | Acc: 67.132,96.930,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.356 | Acc: 67.212,96.928,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.354 | Acc: 67.218,96.922,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.357 | Acc: 67.149,96.902,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.357 | Acc: 67.145,96.879,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.360 | Acc: 67.132,96.826,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.357 | Acc: 67.244,96.860,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.356 | Acc: 67.377,96.839,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.360 | Acc: 67.273,96.839,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.358 | Acc: 67.265,96.887,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.358 | Acc: 67.304,96.875,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.357 | Acc: 67.348,96.899,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.355 | Acc: 67.393,96.916,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.230 | Acc: 56.250,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 55.952,69.903,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 55.869,69.436,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.620 | Acc: 55.853,69.109,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.268 | Acc: 71.094,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.391 | Acc: 66.741,96.577,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.400 | Acc: 66.387,96.437,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.384 | Acc: 66.803,96.644,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.372 | Acc: 67.216,96.740,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.361 | Acc: 67.489,96.720,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.363 | Acc: 67.330,96.649,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.369 | Acc: 67.016,96.581,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.362 | Acc: 67.008,96.608,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.359 | Acc: 67.036,96.676,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.361 | Acc: 67.051,96.704,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.359 | Acc: 67.138,96.677,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.360 | Acc: 67.113,96.642,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.360 | Acc: 67.202,96.651,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.357 | Acc: 67.285,96.661,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.354 | Acc: 67.302,96.678,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.355 | Acc: 67.222,96.702,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.356 | Acc: 67.208,96.708,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.358 | Acc: 67.198,96.713,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.357 | Acc: 67.292,96.713,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.373 | Acc: 55.469,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.601 | Acc: 56.176,69.457,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 55.888,68.941,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 55.840,68.648,74.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.406 | Acc: 68.750,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.360 | Acc: 67.299,97.135,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.352 | Acc: 67.740,97.046,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.357 | Acc: 67.456,97.016,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.350 | Acc: 67.178,97.010,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.349 | Acc: 67.149,97.061,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.343 | Acc: 67.336,97.095,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.342 | Acc: 67.393,96.980,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.348 | Acc: 67.197,97.011,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.343 | Acc: 67.438,97.035,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.347 | Acc: 67.498,97.019,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.346 | Acc: 67.527,96.992,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.344 | Acc: 67.671,96.956,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.344 | Acc: 67.702,96.932,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.349 | Acc: 67.552,96.947,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.349 | Acc: 67.489,96.968,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.348 | Acc: 67.540,96.948,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.350 | Acc: 67.481,96.923,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.347 | Acc: 67.534,96.946,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.350 | Acc: 67.499,96.904,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 54.688,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.607 | Acc: 56.176,69.829,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 55.812,69.322,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 55.802,68.916,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.221 | Acc: 65.625,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.302 | Acc: 67.857,97.619,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.343 | Acc: 67.188,97.237,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.339 | Acc: 67.559,97.234,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.340 | Acc: 67.689,97.087,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.340 | Acc: 67.775,97.107,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.341 | Acc: 67.911,97.030,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.344 | Acc: 67.714,97.019,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.342 | Acc: 67.746,97.001,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.352 | Acc: 67.494,96.987,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.353 | Acc: 67.378,97.038,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.354 | Acc: 67.389,97.016,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.353 | Acc: 67.401,97.060,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.353 | Acc: 67.418,97.049,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.354 | Acc: 67.276,97.047,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.356 | Acc: 67.188,97.057,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.354 | Acc: 67.234,97.070,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.352 | Acc: 67.304,97.051,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.354 | Acc: 67.291,97.018,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.354 | Acc: 67.331,97.006,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.290 | Acc: 53.125,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 56.176,69.792,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.596 | Acc: 56.269,69.264,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.623 | Acc: 56.212,68.865,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.326 | Acc: 67.188,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.339 | Acc: 68.266,97.284,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.350 | Acc: 68.045,96.780,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.361 | Acc: 67.482,97.003,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.352 | Acc: 67.429,96.923,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.356 | Acc: 67.234,96.952,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.360 | Acc: 67.252,96.869,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.361 | Acc: 67.304,96.919,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.359 | Acc: 67.513,96.933,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.357 | Acc: 67.503,96.922,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.358 | Acc: 67.549,96.898,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.356 | Acc: 67.555,96.932,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.354 | Acc: 67.538,96.943,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.355 | Acc: 67.472,96.965,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.354 | Acc: 67.482,96.983,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.351 | Acc: 67.525,96.961,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.349 | Acc: 67.543,96.972,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.351 | Acc: 67.499,96.983,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.352 | Acc: 67.439,96.959,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.354 | Acc: 67.403,96.928,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.356 | Acc: 53.125,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.598 | Acc: 55.952,69.457,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 55.716,68.998,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.643 | Acc: 55.674,68.750,74.718,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 1.329 | Acc: 66.406,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.393 | Acc: 66.295,97.173,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.354 | Acc: 67.092,96.913,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.356 | Acc: 67.264,96.977,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.356 | Acc: 67.351,96.923,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.354 | Acc: 67.435,96.952,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.352 | Acc: 67.620,96.946,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.351 | Acc: 67.658,96.947,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.344 | Acc: 67.702,97.074,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.340 | Acc: 67.753,97.043,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.336 | Acc: 67.844,97.062,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.341 | Acc: 67.739,97.052,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.343 | Acc: 67.648,97.063,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.346 | Acc: 67.583,97.070,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.344 | Acc: 67.624,97.075,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.346 | Acc: 67.546,97.026,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.350 | Acc: 67.470,96.963,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.350 | Acc: 67.462,96.962,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.350 | Acc: 67.542,96.944,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.350 | Acc: 67.571,96.930,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.181 | Acc: 57.031,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 56.362,69.754,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.596 | Acc: 56.079,69.207,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.627 | Acc: 56.019,68.801,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.132 | Acc: 75.781,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.400 | Acc: 66.183,96.615,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.377 | Acc: 66.578,96.646,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.370 | Acc: 66.701,96.862,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.354 | Acc: 67.525,96.914,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.357 | Acc: 67.450,96.860,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.357 | Acc: 67.459,96.856,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.356 | Acc: 67.426,96.919,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.358 | Acc: 67.255,96.919,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.361 | Acc: 67.261,96.858,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.359 | Acc: 67.339,96.887,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.358 | Acc: 67.336,96.864,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.354 | Acc: 67.482,96.878,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.352 | Acc: 67.463,96.887,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.351 | Acc: 67.521,96.878,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.354 | Acc: 67.512,96.823,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.356 | Acc: 67.475,96.829,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.357 | Acc: 67.375,96.838,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.355 | Acc: 67.408,96.856,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.354 | Acc: 67.423,96.859,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.273 | Acc: 56.250,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.585 | Acc: 56.138,69.940,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 55.850,69.322,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.634 | Acc: 55.699,68.993,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.221 | Acc: 71.094,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.367 | Acc: 66.332,96.689,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.368 | Acc: 66.978,96.684,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.360 | Acc: 67.572,96.747,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.365 | Acc: 67.535,96.663,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.365 | Acc: 67.450,96.744,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.360 | Acc: 67.426,96.804,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.363 | Acc: 67.060,96.809,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.366 | Acc: 67.076,96.807,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.361 | Acc: 67.149,96.828,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.360 | Acc: 67.125,96.852,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.355 | Acc: 67.340,96.826,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.353 | Acc: 67.288,96.878,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.354 | Acc: 67.298,96.866,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.351 | Acc: 67.368,96.889,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.349 | Acc: 67.367,96.914,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.351 | Acc: 67.368,96.873,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.354 | Acc: 67.336,96.884,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.353 | Acc: 67.365,96.901,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.350 | Acc: 67.462,96.898,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.228 | Acc: 55.469,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 56.176,69.494,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 56.002,69.207,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.628 | Acc: 55.776,68.865,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.325 | Acc: 66.406,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.331 | Acc: 68.229,96.875,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.345 | Acc: 67.397,96.894,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.350 | Acc: 67.303,96.824,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.358 | Acc: 67.062,96.914,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.363 | Acc: 66.940,96.790,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.368 | Acc: 66.781,96.785,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.368 | Acc: 66.977,96.764,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.362 | Acc: 67.183,96.802,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.371 | Acc: 66.941,96.784,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.366 | Acc: 67.098,96.840,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.363 | Acc: 67.096,96.864,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.361 | Acc: 67.165,96.813,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.360 | Acc: 67.229,96.803,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.357 | Acc: 67.260,96.833,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.358 | Acc: 67.154,96.831,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.356 | Acc: 67.185,96.814,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.357 | Acc: 67.176,96.815,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.358 | Acc: 67.118,96.812,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.358 | Acc: 67.146,96.811,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.349 | Acc: 54.688,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.596 | Acc: 56.473,69.494,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 56.269,69.055,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.636 | Acc: 56.058,68.788,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.494 | Acc: 64.062,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.388 | Acc: 66.890,96.354,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.374 | Acc: 67.645,96.418,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.373 | Acc: 67.431,96.632,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.371 | Acc: 67.274,96.682,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.365 | Acc: 67.404,96.682,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.356 | Acc: 67.426,96.681,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.355 | Acc: 67.453,96.687,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.355 | Acc: 67.420,96.666,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.356 | Acc: 67.295,96.733,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.359 | Acc: 67.230,96.696,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.357 | Acc: 67.237,96.737,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.354 | Acc: 67.204,96.800,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.354 | Acc: 67.217,96.812,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.351 | Acc: 67.299,96.811,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.349 | Acc: 67.302,96.826,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.349 | Acc: 67.280,96.851,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.349 | Acc: 67.297,96.852,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.349 | Acc: 67.281,96.856,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.351 | Acc: 67.237,96.865,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.169 | Acc: 58.594,75.000,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.597 | Acc: 56.250,69.308,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 56.193,69.017,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.639 | Acc: 56.058,68.660,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.279 | Acc: 69.531,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.356 | Acc: 67.374,96.503,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.330 | Acc: 68.159,96.989,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.356 | Acc: 67.367,96.773,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.357 | Acc: 67.226,96.798,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.348 | Acc: 67.536,96.875,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.331 | Acc: 67.814,96.991,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.333 | Acc: 67.719,97.036,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.334 | Acc: 67.760,97.079,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.337 | Acc: 67.705,97.082,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.342 | Acc: 67.611,97.104,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.342 | Acc: 67.516,97.066,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.346 | Acc: 67.369,97.034,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.346 | Acc: 67.346,97.013,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.348 | Acc: 67.304,97.014,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.346 | Acc: 67.419,96.992,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.344 | Acc: 67.494,96.997,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.345 | Acc: 67.449,97.001,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.348 | Acc: 67.358,96.981,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.348 | Acc: 67.308,96.961,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.238 | Acc: 55.469,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.575 | Acc: 56.585,69.829,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 56.098,69.322,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 56.019,68.891,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.207 | Acc: 71.875,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.327 | Acc: 67.262,96.615,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.353 | Acc: 67.149,96.704,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.349 | Acc: 67.533,96.773,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.353 | Acc: 67.525,96.865,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.350 | Acc: 67.396,96.921,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.356 | Acc: 67.104,96.894,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.356 | Acc: 66.949,96.930,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.353 | Acc: 67.042,96.938,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.352 | Acc: 67.183,96.918,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.348 | Acc: 67.277,96.879,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.351 | Acc: 67.255,96.882,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.351 | Acc: 67.353,96.846,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.352 | Acc: 67.361,96.878,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.353 | Acc: 67.443,96.867,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.349 | Acc: 67.538,96.854,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.351 | Acc: 67.438,96.838,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.353 | Acc: 67.355,96.848,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.355 | Acc: 67.337,96.862,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.355 | Acc: 67.311,96.885,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.241 | Acc: 57.031,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.579 | Acc: 55.878,69.643,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 55.602,69.322,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.631 | Acc: 55.584,68.904,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.508 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.358 | Acc: 68.452,96.801,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.343 | Acc: 68.521,97.085,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.352 | Acc: 67.994,97.067,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.353 | Acc: 67.602,97.174,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.356 | Acc: 67.280,97.146,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.364 | Acc: 66.987,97.082,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.355 | Acc: 67.271,97.113,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.351 | Acc: 67.459,97.093,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.351 | Acc: 67.446,97.061,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.351 | Acc: 67.320,96.988,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.348 | Acc: 67.407,97.031,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.345 | Acc: 67.473,97.034,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.349 | Acc: 67.424,96.998,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.350 | Acc: 67.404,96.989,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.354 | Acc: 67.291,96.948,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.351 | Acc: 67.336,96.970,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.351 | Acc: 67.373,96.955,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.351 | Acc: 67.402,96.970,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.350 | Acc: 67.436,96.980,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.179 | Acc: 55.469,73.438,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.593 | Acc: 55.543,69.792,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.616 | Acc: 55.812,69.322,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 55.648,68.852,74.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.115 | Acc: 72.656,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.340 | Acc: 67.857,97.321,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.337 | Acc: 67.378,97.180,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.344 | Acc: 67.021,97.041,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.356 | Acc: 66.667,97.058,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.362 | Acc: 66.600,96.960,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.361 | Acc: 66.665,96.914,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.362 | Acc: 66.750,96.908,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.363 | Acc: 66.799,96.880,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.362 | Acc: 66.881,96.862,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.361 | Acc: 66.958,96.844,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.355 | Acc: 67.142,96.875,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.356 | Acc: 67.116,96.914,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.355 | Acc: 67.262,96.893,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.356 | Acc: 67.260,96.875,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.355 | Acc: 67.221,96.893,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.357 | Acc: 67.141,96.892,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.356 | Acc: 67.158,96.884,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.358 | Acc: 67.125,96.873,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.356 | Acc: 67.226,96.850,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.296 | Acc: 55.469,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.586 | Acc: 55.841,70.052,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 55.755,69.322,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.639 | Acc: 55.776,69.134,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.254 | Acc: 68.750,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.351 | Acc: 68.043,96.875,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.348 | Acc: 67.740,96.875,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.345 | Acc: 67.520,96.875,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.362 | Acc: 67.265,96.682,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.361 | Acc: 67.450,96.620,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.351 | Acc: 67.581,96.733,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.351 | Acc: 67.647,96.803,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.349 | Acc: 67.595,96.846,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.349 | Acc: 67.619,96.910,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.349 | Acc: 67.545,96.902,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.352 | Acc: 67.410,96.896,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.354 | Acc: 67.314,96.933,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.349 | Acc: 67.424,96.950,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.352 | Acc: 67.379,96.945,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.352 | Acc: 67.390,96.937,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.349 | Acc: 67.441,96.953,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.350 | Acc: 67.403,96.985,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.351 | Acc: 67.367,96.975,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.353 | Acc: 67.304,96.971,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.215 | Acc: 53.906,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.595 | Acc: 56.436,69.792,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 55.926,69.379,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.651 | Acc: 55.789,69.019,74.718,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.138 | Acc: 75.781,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.327 | Acc: 68.043,96.652,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.348 | Acc: 67.759,96.513,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.350 | Acc: 67.572,96.555,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.356 | Acc: 67.477,96.730,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.350 | Acc: 67.613,96.860,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.341 | Acc: 67.736,96.901,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.339 | Acc: 67.880,96.997,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.346 | Acc: 67.653,96.996,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.347 | Acc: 67.619,96.953,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.345 | Acc: 67.600,96.945,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.347 | Acc: 67.559,96.903,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.346 | Acc: 67.628,96.917,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.350 | Acc: 67.541,96.893,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.352 | Acc: 67.432,96.897,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.356 | Acc: 67.250,96.896,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.357 | Acc: 67.212,96.887,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.358 | Acc: 67.160,96.857,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.356 | Acc: 67.276,96.866,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.355 | Acc: 67.280,96.861,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.260 | Acc: 57.031,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.579 | Acc: 56.771,69.792,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 56.345,69.284,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.642 | Acc: 56.096,68.942,74.475,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.425 | Acc: 59.375,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.335 | Acc: 68.341,97.693,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.337 | Acc: 67.931,97.256,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.342 | Acc: 67.572,97.221,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.353 | Acc: 67.467,97.000,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.346 | Acc: 67.644,97.022,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.348 | Acc: 67.568,97.011,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.344 | Acc: 67.769,97.036,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.353 | Acc: 67.537,97.084,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.350 | Acc: 67.632,97.108,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.345 | Acc: 67.736,97.081,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.346 | Acc: 67.774,97.108,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.347 | Acc: 67.826,97.057,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.347 | Acc: 67.825,97.079,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.349 | Acc: 67.752,97.072,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.347 | Acc: 67.886,97.051,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.350 | Acc: 67.733,97.026,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.349 | Acc: 67.687,97.049,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.348 | Acc: 67.666,97.048,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.349 | Acc: 67.673,97.027,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.322 | Acc: 56.250,72.656,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.579 | Acc: 55.952,69.792,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 55.736,69.436,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.632 | Acc: 55.763,69.032,74.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.272 | Acc: 69.531,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.336 | Acc: 67.857,96.801,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.362 | Acc: 66.730,96.894,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.369 | Acc: 66.752,96.965,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.366 | Acc: 66.869,96.933,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.367 | Acc: 66.754,96.976,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.371 | Acc: 66.800,96.927,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.371 | Acc: 66.933,96.919,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.364 | Acc: 67.197,96.933,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.364 | Acc: 67.170,96.940,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.360 | Acc: 67.257,96.937,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.361 | Acc: 67.184,96.914,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.358 | Acc: 67.324,96.943,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.359 | Acc: 67.217,96.980,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.358 | Acc: 67.260,96.967,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.356 | Acc: 67.271,96.961,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.356 | Acc: 67.314,96.965,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.356 | Acc: 67.265,96.969,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.357 | Acc: 67.183,96.966,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.357 | Acc: 67.112,96.955,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.256 | Acc: 54.688,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.617 | Acc: 55.655,69.978,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.630 | Acc: 55.602,69.455,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.651 | Acc: 55.584,69.032,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.169 | Acc: 71.094,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.358 | Acc: 68.006,97.024,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.373 | Acc: 67.035,97.066,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.359 | Acc: 67.316,97.029,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.360 | Acc: 67.226,97.010,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.367 | Acc: 67.118,96.968,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.363 | Acc: 67.284,96.959,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.361 | Acc: 67.204,96.980,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.353 | Acc: 67.416,97.001,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.353 | Acc: 67.360,97.004,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.349 | Acc: 67.545,97.023,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.348 | Acc: 67.534,97.045,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.348 | Acc: 67.512,97.034,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.347 | Acc: 67.517,97.034,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.350 | Acc: 67.404,97.020,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.350 | Acc: 67.416,96.981,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.349 | Acc: 67.538,96.953,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.351 | Acc: 67.465,96.937,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.349 | Acc: 67.519,96.946,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.351 | Acc: 67.432,96.937,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.230 | Acc: 55.469,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 56.027,70.089,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.612 | Acc: 55.850,69.398,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.639 | Acc: 55.686,69.057,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.161 | Acc: 75.000,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.366 | Acc: 67.746,96.577,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.351 | Acc: 67.035,96.970,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.351 | Acc: 67.533,96.811,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.353 | Acc: 67.390,96.971,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.342 | Acc: 67.845,97.107,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.340 | Acc: 67.969,97.056,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.338 | Acc: 68.080,97.074,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.343 | Acc: 68.066,97.084,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.345 | Acc: 67.766,97.086,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.341 | Acc: 67.755,97.089,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.344 | Acc: 67.728,97.091,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.347 | Acc: 67.674,97.053,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.341 | Acc: 67.927,97.049,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.347 | Acc: 67.760,97.042,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.349 | Acc: 67.771,97.026,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.346 | Acc: 67.769,97.075,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.347 | Acc: 67.737,97.090,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.348 | Acc: 67.711,97.120,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.350 | Acc: 67.635,97.090,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.233 | Acc: 53.906,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 56.771,70.052,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 56.441,69.531,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.627 | Acc: 56.122,69.147,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.572 | Acc: 61.719,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.401 | Acc: 65.885,96.726,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.382 | Acc: 66.349,96.684,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.366 | Acc: 66.957,96.811,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.359 | Acc: 67.303,96.827,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.353 | Acc: 67.365,96.968,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.352 | Acc: 67.394,96.907,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.351 | Acc: 67.448,96.914,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.354 | Acc: 67.362,97.021,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.351 | Acc: 67.455,97.017,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.351 | Acc: 67.421,96.953,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.351 | Acc: 67.424,96.960,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.355 | Acc: 67.363,96.924,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.356 | Acc: 67.346,96.932,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.352 | Acc: 67.402,96.958,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.353 | Acc: 67.403,96.961,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.350 | Acc: 67.465,97.016,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.350 | Acc: 67.417,97.040,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.349 | Acc: 67.432,97.065,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.347 | Acc: 67.470,97.074,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.248 | Acc: 55.469,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.579 | Acc: 56.176,69.680,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 56.040,69.112,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 55.891,68.699,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.172 | Acc: 75.781,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.360 | Acc: 66.927,97.359,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.342 | Acc: 68.102,97.161,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.333 | Acc: 67.956,97.374,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.340 | Acc: 67.728,97.319,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.345 | Acc: 67.474,97.177,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.342 | Acc: 67.485,97.140,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.342 | Acc: 67.409,97.219,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.343 | Acc: 67.382,97.190,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.345 | Acc: 67.421,97.190,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.343 | Acc: 67.436,97.201,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.347 | Acc: 67.361,97.214,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.344 | Acc: 67.453,97.215,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.346 | Acc: 67.439,97.198,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.344 | Acc: 67.454,97.172,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.345 | Acc: 67.483,97.168,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.349 | Acc: 67.428,97.106,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.353 | Acc: 67.323,97.097,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.353 | Acc: 67.320,97.130,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.353 | Acc: 67.335,97.119,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.167 | Acc: 55.469,71.875,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.570 | Acc: 56.027,69.308,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 55.869,68.941,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.617 | Acc: 55.699,68.814,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 1.346 | Acc: 63.281,99.219,100.000,% | Adaptive Acc: 94.531% | clf_exit: 0.492 0.508 0.000
Batch: 20 | Loss: 1.373 | Acc: 66.369,97.098,99.740,% | Adaptive Acc: 92.001% | clf_exit: 0.544 0.433 0.023
Batch: 40 | Loss: 1.369 | Acc: 66.845,97.161,99.771,% | Adaptive Acc: 92.340% | clf_exit: 0.536 0.442 0.022
Batch: 60 | Loss: 1.372 | Acc: 66.893,97.144,99.808,% | Adaptive Acc: 92.047% | clf_exit: 0.539 0.440 0.022
Batch: 80 | Loss: 1.370 | Acc: 67.043,97.058,99.826,% | Adaptive Acc: 91.985% | clf_exit: 0.539 0.439 0.022
Batch: 100 | Loss: 1.366 | Acc: 67.203,97.099,99.838,% | Adaptive Acc: 91.839% | clf_exit: 0.541 0.437 0.022
Batch: 120 | Loss: 1.365 | Acc: 67.233,97.043,99.832,% | Adaptive Acc: 91.871% | clf_exit: 0.543 0.435 0.022
Batch: 140 | Loss: 1.365 | Acc: 67.271,97.008,99.823,% | Adaptive Acc: 91.833% | clf_exit: 0.545 0.434 0.022
Batch: 160 | Loss: 1.360 | Acc: 67.328,97.030,99.820,% | Adaptive Acc: 91.828% | clf_exit: 0.546 0.432 0.022
Batch: 180 | Loss: 1.363 | Acc: 67.244,97.056,99.819,% | Adaptive Acc: 91.747% | clf_exit: 0.547 0.432 0.022
Batch: 200 | Loss: 1.364 | Acc: 67.261,96.988,99.825,% | Adaptive Acc: 91.659% | clf_exit: 0.547 0.432 0.021
Batch: 220 | Loss: 1.361 | Acc: 67.378,97.002,99.823,% | Adaptive Acc: 91.788% | clf_exit: 0.545 0.433 0.021
Batch: 240 | Loss: 1.359 | Acc: 67.453,96.946,99.812,% | Adaptive Acc: 91.750% | clf_exit: 0.547 0.432 0.021
Batch: 260 | Loss: 1.359 | Acc: 67.535,96.983,99.820,% | Adaptive Acc: 91.771% | clf_exit: 0.546 0.432 0.021
Batch: 280 | Loss: 1.358 | Acc: 67.577,97.011,99.819,% | Adaptive Acc: 91.732% | clf_exit: 0.548 0.431 0.021
Batch: 300 | Loss: 1.358 | Acc: 67.616,97.000,99.826,% | Adaptive Acc: 91.702% | clf_exit: 0.548 0.431 0.021
Batch: 320 | Loss: 1.357 | Acc: 67.577,97.016,99.825,% | Adaptive Acc: 91.696% | clf_exit: 0.548 0.431 0.021
Batch: 340 | Loss: 1.355 | Acc: 67.588,97.010,99.826,% | Adaptive Acc: 91.677% | clf_exit: 0.549 0.430 0.021
Batch: 360 | Loss: 1.353 | Acc: 67.653,97.024,99.829,% | Adaptive Acc: 91.720% | clf_exit: 0.550 0.430 0.021
Batch: 380 | Loss: 1.351 | Acc: 67.688,97.047,99.832,% | Adaptive Acc: 91.736% | clf_exit: 0.549 0.430 0.021
Batch: 0 | Loss: 4.299 | Acc: 55.469,71.875,78.906,% | Adaptive Acc: 71.875% | clf_exit: 0.562 0.344 0.094
Batch: 20 | Loss: 4.597 | Acc: 56.138,69.568,75.037,% | Adaptive Acc: 67.113% | clf_exit: 0.568 0.347 0.085
Batch: 40 | Loss: 4.620 | Acc: 55.755,69.322,74.848,% | Adaptive Acc: 66.711% | clf_exit: 0.571 0.344 0.085
Batch: 60 | Loss: 4.647 | Acc: 55.674,68.904,74.629,% | Adaptive Acc: 66.342% | clf_exit: 0.574 0.339 0.086
model is save as models/modelC_dp2_cifar100_adaptive0_circles10_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 35.132 | Acc: 2.344,3.125,4.688,% | Adaptive Acc: 2.344% | clf_exit: 0.984 0.000 0.016
Batch: 20 | Loss: 33.501 | Acc: 1.637,3.423,2.827,% | Adaptive Acc: 2.009% | clf_exit: 0.981 0.011 0.007
Batch: 40 | Loss: 33.361 | Acc: 1.601,3.239,2.820,% | Adaptive Acc: 1.810% | clf_exit: 0.984 0.008 0.008
Batch: 60 | Loss: 33.328 | Acc: 1.703,3.202,2.754,% | Adaptive Acc: 1.844% | clf_exit: 0.984 0.007 0.009
Batch: 0 | Loss: 33.725 | Acc: 3.125,5.469,10.938,% | Adaptive Acc: 3.125% | clf_exit: 0.992 0.008 0.000
Batch: 20 | Loss: 32.448 | Acc: 2.195,5.134,12.946,% | Adaptive Acc: 2.269% | clf_exit: 0.993 0.007 0.000
Batch: 40 | Loss: 32.319 | Acc: 2.229,4.764,13.072,% | Adaptive Acc: 2.306% | clf_exit: 0.992 0.007 0.000
Batch: 60 | Loss: 32.247 | Acc: 2.254,4.739,12.820,% | Adaptive Acc: 2.331% | clf_exit: 0.993 0.007 0.001
Batch: 0 | Loss: 26.869 | Acc: 4.688,6.250,30.469,% | Adaptive Acc: 4.688% | clf_exit: 0.992 0.000 0.008
Batch: 20 | Loss: 26.295 | Acc: 3.795,6.622,29.204,% | Adaptive Acc: 4.278% | clf_exit: 0.978 0.009 0.014
Batch: 40 | Loss: 26.163 | Acc: 3.678,6.441,29.116,% | Adaptive Acc: 4.306% | clf_exit: 0.976 0.010 0.014
Batch: 60 | Loss: 26.105 | Acc: 3.689,6.352,29.009,% | Adaptive Acc: 4.239% | clf_exit: 0.975 0.010 0.014
Batch: 0 | Loss: 21.416 | Acc: 5.469,8.594,44.531,% | Adaptive Acc: 10.938% | clf_exit: 0.891 0.039 0.070
Batch: 20 | Loss: 21.272 | Acc: 6.585,8.817,37.760,% | Adaptive Acc: 8.817% | clf_exit: 0.920 0.019 0.061
Batch: 40 | Loss: 21.161 | Acc: 6.040,8.537,37.748,% | Adaptive Acc: 8.784% | clf_exit: 0.917 0.021 0.062
Batch: 60 | Loss: 21.123 | Acc: 6.288,8.594,37.769,% | Adaptive Acc: 8.888% | clf_exit: 0.918 0.022 0.060
Batch: 0 | Loss: 16.753 | Acc: 14.062,16.406,53.906,% | Adaptive Acc: 20.312% | clf_exit: 0.836 0.031 0.133
Batch: 20 | Loss: 16.937 | Acc: 11.235,14.844,45.722,% | Adaptive Acc: 17.634% | clf_exit: 0.822 0.027 0.151
Batch: 40 | Loss: 16.835 | Acc: 10.499,14.386,46.227,% | Adaptive Acc: 18.007% | clf_exit: 0.814 0.028 0.158
Batch: 60 | Loss: 16.817 | Acc: 10.669,14.498,45.991,% | Adaptive Acc: 17.815% | clf_exit: 0.814 0.030 0.156
Batch: 0 | Loss: 12.984 | Acc: 19.531,29.688,56.250,% | Adaptive Acc: 34.375% | clf_exit: 0.688 0.031 0.281
Batch: 20 | Loss: 13.348 | Acc: 16.815,24.033,50.335,% | Adaptive Acc: 28.013% | clf_exit: 0.705 0.040 0.256
Batch: 40 | Loss: 13.258 | Acc: 16.597,24.333,50.972,% | Adaptive Acc: 28.544% | clf_exit: 0.701 0.040 0.259
Batch: 60 | Loss: 13.255 | Acc: 16.598,24.385,50.525,% | Adaptive Acc: 28.304% | clf_exit: 0.705 0.040 0.255
Batch: 0 | Loss: 9.789 | Acc: 28.906,40.625,67.188,% | Adaptive Acc: 46.094% | clf_exit: 0.602 0.078 0.320
Batch: 20 | Loss: 10.190 | Acc: 22.359,36.644,61.533,% | Adaptive Acc: 40.848% | clf_exit: 0.623 0.071 0.306
Batch: 40 | Loss: 10.105 | Acc: 22.694,37.176,61.814,% | Adaptive Acc: 40.816% | clf_exit: 0.620 0.076 0.304
Batch: 60 | Loss: 10.117 | Acc: 23.156,37.052,61.488,% | Adaptive Acc: 40.676% | clf_exit: 0.622 0.079 0.299
Batch: 0 | Loss: 7.137 | Acc: 32.812,59.375,77.344,% | Adaptive Acc: 59.375% | clf_exit: 0.586 0.125 0.289
Batch: 20 | Loss: 7.555 | Acc: 30.208,52.604,71.280,% | Adaptive Acc: 52.418% | clf_exit: 0.568 0.166 0.266
Batch: 40 | Loss: 7.484 | Acc: 30.640,52.630,70.598,% | Adaptive Acc: 52.134% | clf_exit: 0.560 0.179 0.262
Batch: 60 | Loss: 7.512 | Acc: 31.109,51.831,70.274,% | Adaptive Acc: 51.767% | clf_exit: 0.562 0.176 0.262
Batch: 0 | Loss: 5.302 | Acc: 43.750,68.750,79.688,% | Adaptive Acc: 65.625% | clf_exit: 0.539 0.273 0.188
Batch: 20 | Loss: 5.701 | Acc: 40.774,62.463,73.921,% | Adaptive Acc: 60.082% | clf_exit: 0.551 0.261 0.188
Batch: 40 | Loss: 5.668 | Acc: 41.311,62.176,73.666,% | Adaptive Acc: 60.385% | clf_exit: 0.551 0.263 0.186
Batch: 60 | Loss: 5.697 | Acc: 41.790,61.744,73.297,% | Adaptive Acc: 60.105% | clf_exit: 0.552 0.258 0.190
Batch: 0 | Loss: 4.377 | Acc: 50.000,75.000,79.688,% | Adaptive Acc: 68.750% | clf_exit: 0.609 0.242 0.148
Batch: 20 | Loss: 4.719 | Acc: 50.409,68.378,75.037,% | Adaptive Acc: 65.327% | clf_exit: 0.560 0.313 0.127
Batch: 40 | Loss: 4.712 | Acc: 51.067,67.950,74.905,% | Adaptive Acc: 65.492% | clf_exit: 0.566 0.310 0.124
Batch: 60 | Loss: 4.739 | Acc: 51.217,67.674,74.462,% | Adaptive Acc: 65.151% | clf_exit: 0.566 0.311 0.123
Batch: 0 | Loss: 4.299 | Acc: 55.469,71.875,78.906,% | Adaptive Acc: 71.875% | clf_exit: 0.562 0.344 0.094
Batch: 20 | Loss: 4.597 | Acc: 56.138,69.568,75.037,% | Adaptive Acc: 67.113% | clf_exit: 0.568 0.347 0.085
Batch: 40 | Loss: 4.620 | Acc: 55.755,69.322,74.848,% | Adaptive Acc: 66.711% | clf_exit: 0.571 0.344 0.085
Batch: 60 | Loss: 4.647 | Acc: 55.674,68.904,74.629,% | Adaptive Acc: 66.342% | clf_exit: 0.574 0.339 0.086







Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 12.039 |  Acc: 6.932,9.150,11.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 11.341 |  Acc: 8.280,12.150,15.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 10.495 |  Acc: 13.060,16.952,21.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 10.211 |  Acc: 13.130,16.960,24.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 9.513 |  Acc: 17.416,22.798,29.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 10.495 |  Acc: 11.390,16.510,29.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 8.804 |  Acc: 20.580,26.906,35.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 8.843 |  Acc: 17.200,25.320,37.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 8.212 |  Acc: 23.410,30.340,40.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 8.598 |  Acc: 18.120,27.650,41.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 7.780 |  Acc: 25.162,33.076,45.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 7.909 |  Acc: 22.090,33.340,44.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 7.371 |  Acc: 27.420,36.382,48.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 7.770 |  Acc: 24.070,33.910,47.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 7.000 |  Acc: 29.232,39.336,51.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 7.405 |  Acc: 22.600,38.200,51.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 6.719 |  Acc: 30.642,41.622,54.278,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 7.111 |  Acc: 27.360,39.190,52.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 6.443 |  Acc: 32.306,43.668,56.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 6.974 |  Acc: 25.870,40.740,55.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 6.193 |  Acc: 33.358,45.654,59.192,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 6.550 |  Acc: 28.460,45.390,58.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 5.969 |  Acc: 34.486,47.580,61.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 6.328 |  Acc: 30.760,46.040,59.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 5.775 |  Acc: 35.632,48.998,63.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 6.352 |  Acc: 31.910,46.630,58.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 5.593 |  Acc: 36.612,50.700,64.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 6.483 |  Acc: 28.880,45.550,59.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 5.452 |  Acc: 37.294,51.606,66.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 6.326 |  Acc: 29.230,46.990,62.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 5.319 |  Acc: 37.730,53.030,67.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 6.089 |  Acc: 32.160,48.660,62.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 5.164 |  Acc: 38.618,53.962,69.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 6.283 |  Acc: 30.710,48.020,61.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 5.046 |  Acc: 39.256,55.100,70.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 6.386 |  Acc: 30.640,47.780,62.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.949 |  Acc: 39.784,55.998,71.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 5.992 |  Acc: 34.710,50.010,63.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.864 |  Acc: 40.258,56.516,72.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 6.271 |  Acc: 29.960,48.040,62.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.765 |  Acc: 40.814,57.614,73.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 5.792 |  Acc: 35.760,51.090,63.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.700 |  Acc: 41.188,57.980,74.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 6.033 |  Acc: 31.660,52.470,64.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 4.610 |  Acc: 41.636,58.676,75.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 5.480 |  Acc: 38.040,55.770,65.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 4.538 |  Acc: 42.080,59.390,76.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 5.815 |  Acc: 35.890,52.850,64.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 4.476 |  Acc: 42.266,59.636,76.962,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 6.198 |  Acc: 30.780,51.220,63.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 4.410 |  Acc: 42.846,60.316,77.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 5.631 |  Acc: 36.560,54.600,65.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 4.374 |  Acc: 42.874,60.790,78.038,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 5.692 |  Acc: 36.490,53.440,65.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 4.308 |  Acc: 43.584,61.132,78.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 5.615 |  Acc: 37.110,55.100,65.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 4.254 |  Acc: 44.020,61.550,79.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 5.484 |  Acc: 38.260,56.110,65.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 4.215 |  Acc: 43.742,62.084,79.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 5.622 |  Acc: 36.220,54.670,65.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 4.187 |  Acc: 44.178,62.282,79.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 5.562 |  Acc: 37.630,55.040,65.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 4.154 |  Acc: 44.364,62.458,80.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 5.590 |  Acc: 37.820,54.650,66.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 4.084 |  Acc: 44.754,63.060,81.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 5.753 |  Acc: 33.510,55.660,65.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 4.073 |  Acc: 44.980,63.084,81.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 5.673 |  Acc: 37.340,54.770,65.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 4.035 |  Acc: 45.184,63.472,81.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 5.521 |  Acc: 37.550,55.550,65.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 4.004 |  Acc: 45.294,63.828,82.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 5.568 |  Acc: 36.570,55.730,66.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.983 |  Acc: 45.708,63.810,82.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 5.697 |  Acc: 36.390,56.020,65.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.944 |  Acc: 46.148,64.262,82.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 5.633 |  Acc: 37.610,55.340,65.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.925 |  Acc: 46.192,64.484,82.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 5.927 |  Acc: 33.870,55.170,66.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.891 |  Acc: 46.416,64.666,83.272,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 5.797 |  Acc: 35.360,54.360,65.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.857 |  Acc: 46.484,65.082,83.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 5.610 |  Acc: 36.540,56.250,67.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.864 |  Acc: 46.206,65.090,83.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 5.580 |  Acc: 38.810,55.410,66.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.823 |  Acc: 46.672,65.184,84.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 5.881 |  Acc: 36.670,54.440,65.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.812 |  Acc: 46.814,65.400,84.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 5.549 |  Acc: 38.170,57.020,65.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.764 |  Acc: 47.270,65.862,84.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 6.456 |  Acc: 32.210,51.460,64.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.792 |  Acc: 47.198,65.490,84.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 5.544 |  Acc: 39.220,55.570,65.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.763 |  Acc: 47.132,65.996,84.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 5.727 |  Acc: 36.860,55.120,65.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.758 |  Acc: 47.436,66.038,84.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 5.622 |  Acc: 36.550,56.050,66.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.711 |  Acc: 47.538,66.442,85.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 5.878 |  Acc: 33.970,55.510,66.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.700 |  Acc: 47.628,66.544,85.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 5.714 |  Acc: 36.840,56.730,65.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.685 |  Acc: 47.724,66.556,85.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 5.560 |  Acc: 39.080,57.520,66.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.689 |  Acc: 47.870,66.416,85.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 5.903 |  Acc: 37.210,54.300,65.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.689 |  Acc: 47.958,66.692,85.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 5.651 |  Acc: 36.820,57.350,65.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.665 |  Acc: 47.844,66.886,85.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 5.554 |  Acc: 39.530,56.840,65.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.632 |  Acc: 48.342,66.938,85.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 5.552 |  Acc: 36.990,58.180,65.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.636 |  Acc: 48.250,67.016,85.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 5.632 |  Acc: 38.200,56.020,65.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.628 |  Acc: 48.338,67.068,85.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 5.687 |  Acc: 38.880,55.460,65.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.604 |  Acc: 48.560,67.534,85.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 5.539 |  Acc: 38.380,57.190,67.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.580 |  Acc: 48.768,67.302,86.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 5.784 |  Acc: 39.080,55.480,64.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.579 |  Acc: 48.464,67.342,86.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 6.439 |  Acc: 31.490,51.300,63.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.577 |  Acc: 48.742,67.512,86.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 5.873 |  Acc: 32.420,56.040,66.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.565 |  Acc: 48.754,67.748,86.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 5.484 |  Acc: 40.300,56.680,66.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.541 |  Acc: 49.082,67.860,86.666,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 5.568 |  Acc: 38.460,56.940,66.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.562 |  Acc: 48.948,68.176,86.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 5.717 |  Acc: 37.150,56.250,65.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 3.507 |  Acc: 49.030,68.288,87.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 5.855 |  Acc: 36.710,54.620,65.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 3.522 |  Acc: 49.210,68.320,86.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 5.528 |  Acc: 38.520,58.250,66.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 3.510 |  Acc: 49.322,68.380,86.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 5.797 |  Acc: 37.660,55.730,66.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 3.503 |  Acc: 49.316,68.460,86.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 5.836 |  Acc: 35.560,54.610,66.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 3.497 |  Acc: 49.502,68.484,86.970,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 5.736 |  Acc: 37.930,55.190,65.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 3.497 |  Acc: 49.366,68.420,86.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 6.052 |  Acc: 33.940,55.220,66.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 3.463 |  Acc: 49.600,68.876,87.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 5.649 |  Acc: 39.120,57.220,65.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 3.469 |  Acc: 49.668,68.766,87.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 5.542 |  Acc: 40.190,57.330,66.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 3.471 |  Acc: 49.610,68.700,87.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 5.489 |  Acc: 41.840,56.290,65.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 3.433 |  Acc: 50.080,68.890,87.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 5.713 |  Acc: 37.630,56.460,65.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 3.446 |  Acc: 49.732,68.778,87.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 5.864 |  Acc: 38.810,55.260,65.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 3.448 |  Acc: 49.822,68.944,87.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 5.796 |  Acc: 39.160,54.970,64.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 3.459 |  Acc: 49.508,69.084,87.254,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 5.199 |  Acc: 42.980,58.430,67.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 3.411 |  Acc: 50.094,69.106,87.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 5.533 |  Acc: 38.170,58.460,67.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 3.420 |  Acc: 50.180,69.268,87.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 5.666 |  Acc: 37.890,57.390,65.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 3.425 |  Acc: 50.120,69.160,87.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 6.000 |  Acc: 32.880,55.680,65.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 3.398 |  Acc: 50.636,69.406,87.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 5.447 |  Acc: 40.700,58.680,65.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 3.382 |  Acc: 50.458,69.394,87.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 5.685 |  Acc: 37.210,56.460,66.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 3.398 |  Acc: 50.470,69.412,87.774,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 6.190 |  Acc: 32.970,55.140,66.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 3.408 |  Acc: 50.070,69.256,87.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 5.787 |  Acc: 36.060,56.480,66.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 3.385 |  Acc: 50.766,69.482,87.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 5.430 |  Acc: 41.220,58.600,66.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 3.381 |  Acc: 50.480,69.446,87.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 5.537 |  Acc: 38.820,58.580,66.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 3.373 |  Acc: 50.506,69.696,87.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 5.420 |  Acc: 42.680,59.270,66.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 3.376 |  Acc: 50.384,69.698,87.764,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 5.883 |  Acc: 38.090,55.190,65.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 3.351 |  Acc: 50.998,69.982,87.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 5.669 |  Acc: 38.310,58.560,66.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 3.332 |  Acc: 50.912,70.126,88.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 5.659 |  Acc: 38.700,57.990,66.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 3.352 |  Acc: 50.758,69.928,88.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 5.761 |  Acc: 37.730,55.990,66.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 3.351 |  Acc: 51.166,69.754,88.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 5.722 |  Acc: 39.550,56.370,66.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 3.348 |  Acc: 50.886,69.954,88.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 5.509 |  Acc: 40.220,58.960,66.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 3.347 |  Acc: 50.980,69.932,87.962,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 5.366 |  Acc: 41.630,58.850,66.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 3.344 |  Acc: 51.120,69.966,88.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 6.010 |  Acc: 37.210,53.390,64.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 3.343 |  Acc: 50.838,70.032,88.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 6.033 |  Acc: 33.120,55.540,65.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 3.318 |  Acc: 51.346,69.978,88.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 5.562 |  Acc: 39.820,58.730,66.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 3.314 |  Acc: 51.402,70.264,88.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 5.688 |  Acc: 39.300,57.870,65.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 3.305 |  Acc: 51.314,70.290,88.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 5.414 |  Acc: 41.870,57.570,67.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 3.319 |  Acc: 50.944,70.198,88.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 6.501 |  Acc: 31.690,52.250,66.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 3.315 |  Acc: 51.178,70.324,88.152,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 5.838 |  Acc: 35.740,56.270,66.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 3.298 |  Acc: 51.382,70.486,88.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 6.603 |  Acc: 31.180,52.280,63.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 3.289 |  Acc: 51.412,70.386,88.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 5.576 |  Acc: 38.920,58.100,65.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 3.312 |  Acc: 51.230,70.244,88.272,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 5.588 |  Acc: 40.110,58.370,66.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 3.307 |  Acc: 51.384,70.632,88.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 5.861 |  Acc: 36.250,57.570,65.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 3.274 |  Acc: 51.498,70.692,88.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 5.872 |  Acc: 36.530,56.270,66.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 3.300 |  Acc: 51.236,70.350,88.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 5.315 |  Acc: 42.100,58.990,66.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 3.271 |  Acc: 51.424,70.496,88.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 6.025 |  Acc: 34.190,55.830,66.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 3.266 |  Acc: 52.006,70.924,88.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 5.650 |  Acc: 37.860,58.050,65.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 3.288 |  Acc: 51.492,70.694,88.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 5.517 |  Acc: 40.840,57.530,66.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 3.263 |  Acc: 51.496,70.672,88.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 5.693 |  Acc: 37.590,57.730,65.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 3.280 |  Acc: 51.390,70.450,88.250,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 5.639 |  Acc: 39.040,56.230,67.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 3.252 |  Acc: 51.840,70.850,88.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 6.061 |  Acc: 35.280,55.670,65.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 3.268 |  Acc: 51.692,70.590,88.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 5.478 |  Acc: 40.880,59.200,66.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 3.239 |  Acc: 52.000,70.722,88.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 5.661 |  Acc: 38.710,58.630,66.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 3.256 |  Acc: 52.134,70.888,88.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.986 |  Acc: 31.570,49.700,61.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 3.250 |  Acc: 51.908,70.690,88.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 5.496 |  Acc: 42.330,58.490,67.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 3.247 |  Acc: 51.914,70.842,88.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 6.064 |  Acc: 36.000,55.510,65.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 3.246 |  Acc: 51.914,70.882,88.784,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 5.800 |  Acc: 38.370,57.850,65.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 3.246 |  Acc: 52.122,70.904,88.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 5.345 |  Acc: 43.860,59.280,66.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 3.229 |  Acc: 51.892,71.062,88.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 5.334 |  Acc: 42.130,60.520,67.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 3.234 |  Acc: 52.354,71.142,88.774,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 5.537 |  Acc: 40.220,58.260,66.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 3.222 |  Acc: 52.194,71.278,88.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 5.792 |  Acc: 39.800,57.920,66.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 3.234 |  Acc: 51.912,71.096,88.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 5.557 |  Acc: 42.530,58.050,65.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 3.215 |  Acc: 52.136,70.968,89.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 5.657 |  Acc: 39.480,58.260,66.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 3.209 |  Acc: 52.304,71.220,88.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 5.721 |  Acc: 37.410,57.270,66.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 3.216 |  Acc: 52.414,71.100,89.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 5.555 |  Acc: 40.920,57.780,65.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 3.217 |  Acc: 52.410,71.338,88.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 6.077 |  Acc: 36.820,55.110,64.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 3.234 |  Acc: 52.074,71.006,88.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 5.767 |  Acc: 39.000,57.270,65.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 3.224 |  Acc: 52.066,71.134,88.768,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 5.682 |  Acc: 39.560,58.100,66.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 3.188 |  Acc: 52.408,71.538,89.128,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 5.789 |  Acc: 38.290,56.300,66.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 3.212 |  Acc: 52.302,71.158,88.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 5.969 |  Acc: 39.770,55.380,64.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 3.202 |  Acc: 52.250,71.400,88.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 6.300 |  Acc: 33.990,55.260,66.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 3.203 |  Acc: 52.674,71.338,89.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 5.537 |  Acc: 41.680,58.150,66.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 3.210 |  Acc: 52.212,71.088,89.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 5.954 |  Acc: 38.180,55.880,65.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 3.183 |  Acc: 52.430,71.620,89.270,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 5.705 |  Acc: 39.290,57.810,66.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 3.207 |  Acc: 52.364,71.282,88.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 6.081 |  Acc: 34.030,56.510,66.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 3.189 |  Acc: 52.448,71.544,89.140,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 5.404 |  Acc: 40.760,58.660,66.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 3.191 |  Acc: 52.506,71.534,88.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 6.118 |  Acc: 34.720,54.530,65.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 3.202 |  Acc: 52.612,71.360,88.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 5.734 |  Acc: 38.790,56.820,66.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 3.181 |  Acc: 52.410,71.878,89.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 5.534 |  Acc: 42.100,57.490,66.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 3.206 |  Acc: 52.428,71.220,89.186,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 5.905 |  Acc: 38.340,56.750,65.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 3.205 |  Acc: 52.626,71.518,88.914,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 5.720 |  Acc: 38.960,57.540,67.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 3.158 |  Acc: 52.892,71.914,89.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 5.462 |  Acc: 39.730,59.960,67.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 3.266 |  Acc: 51.486,70.906,88.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 5.363 |  Acc: 42.150,60.200,67.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 3.194 |  Acc: 52.500,71.682,89.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 5.615 |  Acc: 38.290,59.960,66.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 3.192 |  Acc: 52.440,71.520,89.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 5.840 |  Acc: 38.880,57.200,65.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 3.192 |  Acc: 52.658,71.596,88.986,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 5.669 |  Acc: 40.610,58.260,66.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 3.155 |  Acc: 52.806,71.940,89.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 5.711 |  Acc: 37.150,58.830,66.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 3.161 |  Acc: 52.680,71.550,89.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 5.729 |  Acc: 40.450,58.050,66.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.496 |  Acc: 57.424,79.652,95.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.118 |  Acc: 53.300,68.800,74.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 2.255 |  Acc: 59.144,82.936,97.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.095 |  Acc: 53.920,69.040,74.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 2.166 |  Acc: 59.520,84.182,98.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.083 |  Acc: 53.940,69.190,74.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 2.115 |  Acc: 59.922,84.696,98.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.073 |  Acc: 53.780,69.400,75.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 2.086 |  Acc: 60.094,85.210,98.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.101 |  Acc: 54.350,69.520,74.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 2.056 |  Acc: 60.544,85.846,98.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.106 |  Acc: 54.160,69.160,74.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 2.010 |  Acc: 61.010,86.400,98.942,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.110 |  Acc: 54.500,69.300,74.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 2.003 |  Acc: 61.038,86.812,98.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.108 |  Acc: 54.590,69.190,75.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.975 |  Acc: 61.202,87.044,99.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.135 |  Acc: 54.660,69.240,74.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.954 |  Acc: 61.142,87.226,99.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.145 |  Acc: 54.370,69.610,75.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 1.939 |  Acc: 61.256,87.532,99.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.183 |  Acc: 54.340,69.260,74.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.922 |  Acc: 61.436,87.870,99.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.187 |  Acc: 54.400,69.280,75.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.906 |  Acc: 61.862,88.020,99.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.167 |  Acc: 54.660,69.310,74.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.896 |  Acc: 61.646,88.204,99.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.201 |  Acc: 54.550,69.040,74.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.886 |  Acc: 61.736,88.346,99.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.202 |  Acc: 54.970,69.240,75.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.857 |  Acc: 62.166,88.676,99.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.250 |  Acc: 54.230,68.910,74.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.850 |  Acc: 62.124,88.818,99.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.233 |  Acc: 54.640,69.070,74.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.851 |  Acc: 62.064,88.616,99.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.230 |  Acc: 55.030,69.120,75.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.833 |  Acc: 62.068,89.260,99.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.282 |  Acc: 54.410,68.930,74.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.830 |  Acc: 62.432,88.932,99.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.313 |  Acc: 54.410,68.660,74.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.815 |  Acc: 62.398,89.340,99.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.264 |  Acc: 54.350,69.170,75.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.809 |  Acc: 62.628,89.436,99.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.260 |  Acc: 54.970,68.840,75.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.782 |  Acc: 62.712,90.052,99.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.304 |  Acc: 54.850,69.220,75.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.790 |  Acc: 62.608,89.510,99.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.321 |  Acc: 54.680,68.390,74.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.776 |  Acc: 62.802,90.052,99.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.358 |  Acc: 54.170,68.440,75.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.784 |  Acc: 62.530,89.760,99.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.352 |  Acc: 54.100,68.420,74.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.770 |  Acc: 62.572,90.002,99.450,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.377 |  Acc: 54.740,68.660,74.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.759 |  Acc: 63.088,90.050,99.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.387 |  Acc: 54.710,67.730,74.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.754 |  Acc: 62.782,90.234,99.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.352 |  Acc: 54.990,68.720,74.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.750 |  Acc: 62.754,90.224,99.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.461 |  Acc: 54.340,68.070,74.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.731 |  Acc: 63.034,90.636,99.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.374 |  Acc: 54.690,68.540,74.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.728 |  Acc: 63.014,90.698,99.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.399 |  Acc: 54.800,68.460,74.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.725 |  Acc: 63.158,90.740,99.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.431 |  Acc: 54.520,68.330,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.716 |  Acc: 63.248,90.740,99.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.452 |  Acc: 54.220,68.380,74.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.711 |  Acc: 63.338,90.894,99.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.444 |  Acc: 54.780,68.400,74.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.718 |  Acc: 63.208,90.864,99.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.457 |  Acc: 54.630,68.640,74.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.703 |  Acc: 63.214,91.098,99.552,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.462 |  Acc: 54.750,67.580,74.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.695 |  Acc: 63.468,91.064,99.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.495 |  Acc: 54.240,68.080,74.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.703 |  Acc: 63.482,90.952,99.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.489 |  Acc: 54.210,67.990,74.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.697 |  Acc: 63.202,91.168,99.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.504 |  Acc: 53.930,68.150,74.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.688 |  Acc: 63.578,91.018,99.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.514 |  Acc: 54.280,68.110,74.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.687 |  Acc: 63.606,91.122,99.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.535 |  Acc: 54.100,68.310,74.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.687 |  Acc: 63.528,91.094,99.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.551 |  Acc: 53.790,68.290,74.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.682 |  Acc: 63.674,91.300,99.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.613 |  Acc: 53.510,67.800,74.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.678 |  Acc: 63.670,91.408,99.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.581 |  Acc: 53.610,68.020,74.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.665 |  Acc: 63.834,91.556,99.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.545 |  Acc: 54.310,67.780,74.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.680 |  Acc: 63.580,91.332,99.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.530 |  Acc: 54.530,68.040,74.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.662 |  Acc: 63.784,91.498,99.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.578 |  Acc: 53.980,67.830,74.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.664 |  Acc: 63.660,91.458,99.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.529 |  Acc: 54.510,67.990,74.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.658 |  Acc: 63.848,91.640,99.554,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.560 |  Acc: 54.520,68.060,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.661 |  Acc: 63.808,91.492,99.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.609 |  Acc: 53.730,67.670,74.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.657 |  Acc: 63.892,91.500,99.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.637 |  Acc: 53.770,68.080,74.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.660 |  Acc: 63.856,91.368,99.596,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.555 |  Acc: 54.880,67.920,74.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.651 |  Acc: 63.932,91.584,99.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.651 |  Acc: 53.440,67.350,74.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.644 |  Acc: 64.168,91.646,99.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.660 |  Acc: 53.700,67.420,74.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.642 |  Acc: 64.012,91.748,99.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.648 |  Acc: 54.460,67.510,74.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.648 |  Acc: 64.194,91.616,99.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.618 |  Acc: 53.970,67.270,74.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.649 |  Acc: 64.012,91.692,99.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.714 |  Acc: 53.080,66.670,73.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.641 |  Acc: 64.270,91.716,99.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.645 |  Acc: 54.150,67.020,73.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.647 |  Acc: 63.956,91.694,99.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.693 |  Acc: 53.500,67.620,73.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.632 |  Acc: 64.316,92.090,99.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.613 |  Acc: 54.710,67.570,73.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.636 |  Acc: 64.050,91.878,99.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.636 |  Acc: 53.770,67.580,74.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.625 |  Acc: 64.172,92.002,99.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.635 |  Acc: 53.370,67.830,74.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.631 |  Acc: 64.286,91.890,99.588,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.659 |  Acc: 53.840,67.260,74.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.631 |  Acc: 64.102,91.856,99.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.701 |  Acc: 53.170,67.750,74.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.628 |  Acc: 64.084,91.986,99.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.650 |  Acc: 54.380,67.200,74.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.631 |  Acc: 64.110,91.782,99.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.787 |  Acc: 52.940,66.310,73.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.628 |  Acc: 64.116,92.162,99.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.684 |  Acc: 54.530,67.300,74.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.625 |  Acc: 64.220,92.078,99.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.754 |  Acc: 52.950,67.100,74.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.633 |  Acc: 64.228,91.786,99.554,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.741 |  Acc: 53.910,66.500,73.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.621 |  Acc: 64.390,92.044,99.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.776 |  Acc: 53.690,66.730,74.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.615 |  Acc: 64.096,92.130,99.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.728 |  Acc: 53.850,67.130,73.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.618 |  Acc: 64.366,91.996,99.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.737 |  Acc: 53.990,67.190,73.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.613 |  Acc: 64.456,92.090,99.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.809 |  Acc: 53.040,66.430,73.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.617 |  Acc: 64.390,92.000,99.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.760 |  Acc: 53.510,66.730,74.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.500 |  Acc: 65.640,94.092,99.684,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.494 |  Acc: 56.270,69.020,74.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.453 |  Acc: 66.244,95.120,99.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.490 |  Acc: 56.200,69.020,74.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.443 |  Acc: 66.440,95.250,99.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.481 |  Acc: 55.890,69.220,74.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.433 |  Acc: 66.574,95.568,99.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.494 |  Acc: 56.020,69.210,74.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.426 |  Acc: 66.702,95.604,99.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.498 |  Acc: 56.120,69.160,75.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.421 |  Acc: 66.586,95.842,99.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.513 |  Acc: 56.200,69.410,74.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.422 |  Acc: 66.444,95.890,99.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.493 |  Acc: 56.340,69.250,74.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.417 |  Acc: 66.532,95.916,99.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.488 |  Acc: 56.360,69.310,74.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.407 |  Acc: 67.000,96.038,99.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.494 |  Acc: 56.150,69.270,74.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.410 |  Acc: 66.774,95.848,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.512 |  Acc: 55.980,68.940,74.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.404 |  Acc: 66.714,96.100,99.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.514 |  Acc: 56.370,69.120,75.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.404 |  Acc: 66.432,96.100,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.527 |  Acc: 56.220,69.140,74.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.400 |  Acc: 66.800,96.128,99.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.527 |  Acc: 56.060,69.240,75.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.403 |  Acc: 66.944,96.146,99.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.509 |  Acc: 56.240,69.130,75.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.401 |  Acc: 66.614,96.184,99.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.519 |  Acc: 56.150,69.190,74.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.399 |  Acc: 66.882,96.152,99.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.527 |  Acc: 56.080,69.100,75.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.393 |  Acc: 66.918,96.394,99.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.523 |  Acc: 56.080,69.120,74.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.396 |  Acc: 66.846,96.194,99.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.530 |  Acc: 56.190,68.900,74.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.396 |  Acc: 66.658,96.394,99.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.547 |  Acc: 56.080,69.080,74.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.398 |  Acc: 66.866,96.190,99.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.545 |  Acc: 56.020,68.690,74.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.390 |  Acc: 66.922,96.386,99.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.546 |  Acc: 56.350,68.740,75.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.384 |  Acc: 67.204,96.450,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.534 |  Acc: 55.880,68.830,75.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.388 |  Acc: 66.984,96.370,99.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.539 |  Acc: 55.850,68.770,74.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.384 |  Acc: 66.954,96.466,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.554 |  Acc: 55.980,68.960,74.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.384 |  Acc: 67.060,96.478,99.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.555 |  Acc: 56.370,68.830,74.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.386 |  Acc: 66.930,96.438,99.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.544 |  Acc: 56.210,69.020,74.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.372 |  Acc: 67.282,96.490,99.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.558 |  Acc: 56.390,68.920,74.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.375 |  Acc: 67.034,96.556,99.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.554 |  Acc: 56.150,68.760,74.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.379 |  Acc: 67.128,96.456,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.569 |  Acc: 56.170,68.910,75.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.383 |  Acc: 66.940,96.418,99.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.555 |  Acc: 56.020,69.100,75.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.376 |  Acc: 66.948,96.538,99.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.574 |  Acc: 56.240,68.940,74.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.380 |  Acc: 66.948,96.592,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.579 |  Acc: 56.130,68.760,74.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.367 |  Acc: 67.282,96.716,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.575 |  Acc: 56.400,69.030,74.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.371 |  Acc: 67.120,96.770,99.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.571 |  Acc: 56.350,68.840,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.371 |  Acc: 67.194,96.562,99.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.561 |  Acc: 56.200,69.110,74.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.380 |  Acc: 67.122,96.538,99.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.584 |  Acc: 56.020,69.040,74.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.366 |  Acc: 67.124,96.806,99.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.583 |  Acc: 55.920,68.950,74.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.363 |  Acc: 67.162,96.712,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.596 |  Acc: 55.990,68.950,74.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.354 |  Acc: 67.464,96.884,99.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.586 |  Acc: 56.340,68.730,74.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.354 |  Acc: 67.300,97.010,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.568 |  Acc: 56.120,68.970,74.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.359 |  Acc: 67.256,96.894,99.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.580 |  Acc: 56.220,69.030,74.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.351 |  Acc: 67.596,96.988,99.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.565 |  Acc: 56.420,68.950,74.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.356 |  Acc: 67.490,96.826,99.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.589 |  Acc: 56.240,68.980,74.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.348 |  Acc: 67.684,96.840,99.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.566 |  Acc: 56.060,69.130,75.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.356 |  Acc: 67.356,96.946,99.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.575 |  Acc: 56.300,69.290,75.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.354 |  Acc: 67.442,96.854,99.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.573 |  Acc: 56.250,69.050,75.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.358 |  Acc: 67.230,96.860,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.561 |  Acc: 56.190,69.130,75.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.355 |  Acc: 67.342,96.992,99.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.556 |  Acc: 56.250,69.240,74.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.362 |  Acc: 67.516,96.670,99.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.585 |  Acc: 56.030,69.040,75.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.360 |  Acc: 67.226,96.824,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.571 |  Acc: 56.300,69.070,74.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.355 |  Acc: 67.438,96.938,99.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.594 |  Acc: 56.130,69.110,74.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.356 |  Acc: 67.410,96.968,99.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.608 |  Acc: 56.080,68.950,74.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.355 |  Acc: 67.402,96.910,99.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.570 |  Acc: 56.260,69.140,75.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.357 |  Acc: 67.284,96.712,99.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.585 |  Acc: 56.270,68.780,74.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.350 |  Acc: 67.492,96.908,99.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.583 |  Acc: 56.130,69.010,74.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.354 |  Acc: 67.364,97.000,99.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.571 |  Acc: 56.490,68.960,74.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.354 |  Acc: 67.458,96.930,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.578 |  Acc: 56.120,68.830,74.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.353 |  Acc: 67.492,96.914,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.575 |  Acc: 56.380,68.930,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.355 |  Acc: 67.406,96.858,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.582 |  Acc: 56.160,68.990,74.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.351 |  Acc: 67.460,96.904,99.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.574 |  Acc: 56.220,68.970,74.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.356 |  Acc: 67.202,96.822,99.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.576 |  Acc: 56.530,68.900,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.352 |  Acc: 67.222,96.860,99.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.586 |  Acc: 56.520,68.890,75.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.350 |  Acc: 67.238,96.968,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.574 |  Acc: 56.470,69.040,74.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.356 |  Acc: 67.292,96.858,99.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.577 |  Acc: 56.050,68.950,74.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.350 |  Acc: 67.422,96.990,99.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.586 |  Acc: 56.060,69.000,74.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.356 |  Acc: 67.284,96.844,99.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.581 |  Acc: 56.220,69.170,74.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.354 |  Acc: 67.266,96.974,99.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.594 |  Acc: 56.290,69.080,74.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.356 |  Acc: 67.284,96.870,99.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.583 |  Acc: 56.560,69.000,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.349 |  Acc: 67.620,97.028,99.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.574 |  Acc: 56.250,69.120,74.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.356 |  Acc: 67.158,96.942,99.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.603 |  Acc: 56.040,69.090,75.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.352 |  Acc: 67.454,96.928,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.588 |  Acc: 56.030,69.100,74.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.350 |  Acc: 67.658,97.078,99.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.573 |  Acc: 56.520,69.170,74.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.348 |  Acc: 67.452,97.088,99.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.581 |  Acc: 56.370,68.790,74.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.355 |  Acc: 67.312,97.106,99.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.563 |  Acc: 56.040,68.900,74.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(adaptive=0, backend='modelC_dp2', batch_size=128, circles=10, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.351 |  Acc: 67.682,97.050,99.830,% | Adaptive Acc:91.748% | clf_exit: 0.549 0.430 0.020
Testing: Epoch=299 | Loss: 4.592 |  Acc: 56.100,69.000,74.750,% | Adaptive Acc:66.740% | clf_exit: 0.576 0.339 0.085

circles: 0
Testing: Epoch=299 | Loss: 33.206 |  Acc: 1.620,3.320,2.770,% | Adaptive Acc:1.770% | clf_exit: 0.985 0.006 0.009
circles: 1
Testing: Epoch=299 | Loss: 32.083 |  Acc: 2.190,4.830,12.720,% | Adaptive Acc:2.280% | clf_exit: 0.994 0.006 0.000
circles: 2
Testing: Epoch=299 | Loss: 25.962 |  Acc: 3.580,6.430,29.350,% | Adaptive Acc:4.160% | clf_exit: 0.976 0.010 0.014
circles: 3
Testing: Epoch=299 | Loss: 21.003 |  Acc: 6.270,8.700,38.060,% | Adaptive Acc:8.910% | clf_exit: 0.919 0.020 0.061
circles: 4
Testing: Epoch=299 | Loss: 16.707 |  Acc: 10.500,14.720,46.150,% | Adaptive Acc:17.620% | clf_exit: 0.816 0.029 0.154
circles: 5
Testing: Epoch=299 | Loss: 13.151 |  Acc: 16.470,24.710,50.740,% | Adaptive Acc:28.210% | clf_exit: 0.706 0.041 0.253
circles: 6
Testing: Epoch=299 | Loss: 10.018 |  Acc: 23.310,37.450,61.670,% | Adaptive Acc:40.810% | clf_exit: 0.623 0.081 0.296
circles: 7
Testing: Epoch=299 | Loss: 7.421 |  Acc: 31.280,52.350,70.560,% | Adaptive Acc:52.120% | clf_exit: 0.563 0.176 0.262
circles: 8
Testing: Epoch=299 | Loss: 5.622 |  Acc: 42.020,62.180,73.450,% | Adaptive Acc:60.640% | clf_exit: 0.548 0.263 0.189
circles: 9
Testing: Epoch=299 | Loss: 4.679 |  Acc: 51.670,67.850,74.630,% | Adaptive Acc:65.550% | clf_exit: 0.563 0.314 0.123
circles: 10
Testing: Epoch=299 | Loss: 4.592 |  Acc: 56.100,69.000,74.750,% | Adaptive Acc:66.740% | clf_exit: 0.576 0.339 0.085
