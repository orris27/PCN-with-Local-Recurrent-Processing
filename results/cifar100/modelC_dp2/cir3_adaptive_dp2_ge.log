==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=128, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=128, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=356, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=356, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=612, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=612, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 14.875 | Acc: 0.781,0.000,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.747 | Acc: 2.269,2.865,4.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.232 | Acc: 3.811,4.192,7.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.962 | Acc: 4.688,5.213,8.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.777 | Acc: 5.160,6.038,8.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.604 | Acc: 5.678,6.962,9.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.478 | Acc: 5.992,7.574,10.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.371 | Acc: 6.422,7.995,10.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.282 | Acc: 6.764,8.424,11.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.188 | Acc: 7.174,8.930,11.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.117 | Acc: 7.455,9.223,12.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.043 | Acc: 7.767,9.559,12.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.979 | Acc: 8.004,9.855,12.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.919 | Acc: 8.244,10.153,13.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.866 | Acc: 8.394,10.370,13.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.812 | Acc: 8.622,10.670,14.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.750 | Acc: 8.871,11.006,14.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.702 | Acc: 9.061,11.222,14.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.653 | Acc: 9.265,11.450,15.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.603 | Acc: 9.469,11.743,15.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.173 | Acc: 0.781,13.281,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.149 | Acc: 2.716,5.432,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.125 | Acc: 2.649,6.079,3.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.144 | Acc: 2.523,5.994,3.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 10.854 | Acc: 10.938,15.625,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.617 | Acc: 14.211,17.336,22.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.522 | Acc: 14.729,18.255,23.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.440 | Acc: 15.254,18.801,24.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.423 | Acc: 15.307,19.001,24.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.406 | Acc: 15.200,18.765,24.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.364 | Acc: 15.354,18.950,24.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.335 | Acc: 15.542,19.249,25.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.299 | Acc: 15.567,19.347,25.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.262 | Acc: 15.802,19.592,25.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.242 | Acc: 15.815,19.675,25.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.213 | Acc: 16.007,19.793,25.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.184 | Acc: 16.144,19.966,26.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.157 | Acc: 16.263,20.157,26.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.131 | Acc: 16.342,20.240,26.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.106 | Acc: 16.427,20.432,26.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.085 | Acc: 16.494,20.512,27.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.057 | Acc: 16.615,20.658,27.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.033 | Acc: 16.701,20.838,27.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.008 | Acc: 16.827,21.014,27.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.290 | Acc: 7.812,7.031,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.337 | Acc: 6.548,6.176,24.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.327 | Acc: 6.574,5.583,23.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.354 | Acc: 6.468,5.789,23.476,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 8.655 | Acc: 27.344,27.344,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.303 | Acc: 20.052,23.810,33.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.368 | Acc: 19.817,23.514,32.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.343 | Acc: 19.941,24.103,33.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.343 | Acc: 19.956,24.209,33.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.320 | Acc: 20.196,24.621,33.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.300 | Acc: 20.377,24.716,33.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.258 | Acc: 20.684,24.994,34.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.236 | Acc: 20.686,25.116,34.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.214 | Acc: 20.809,25.246,34.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.201 | Acc: 20.931,25.260,34.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.186 | Acc: 21.048,25.343,34.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.173 | Acc: 21.065,25.357,34.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.153 | Acc: 21.160,25.491,34.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.134 | Acc: 21.236,25.562,34.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.109 | Acc: 21.416,25.763,35.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.086 | Acc: 21.554,25.896,35.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.068 | Acc: 21.634,26.013,35.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.050 | Acc: 21.719,26.123,35.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.035 | Acc: 21.742,26.175,35.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.663 | Acc: 7.031,10.156,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.769 | Acc: 7.626,12.798,25.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.750 | Acc: 8.003,12.938,25.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.770 | Acc: 8.069,13.076,25.038,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 8.721 | Acc: 21.094,29.688,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.630 | Acc: 23.586,28.162,39.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.610 | Acc: 24.276,28.411,39.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.584 | Acc: 24.462,28.740,39.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.538 | Acc: 24.344,28.954,40.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.512 | Acc: 24.621,29.409,40.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.507 | Acc: 24.587,29.274,40.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.501 | Acc: 24.612,29.289,40.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.498 | Acc: 24.539,29.285,40.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.481 | Acc: 24.663,29.351,40.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.477 | Acc: 24.631,29.310,40.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.464 | Acc: 24.767,29.362,40.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.453 | Acc: 24.780,29.435,40.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.428 | Acc: 24.883,29.619,40.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.405 | Acc: 25.103,29.868,40.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.395 | Acc: 25.228,29.965,40.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.383 | Acc: 25.280,30.014,41.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.378 | Acc: 25.206,29.988,41.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.365 | Acc: 25.240,30.097,41.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.349 | Acc: 25.289,30.116,41.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.546 | Acc: 13.281,10.938,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.517 | Acc: 14.360,11.272,21.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.495 | Acc: 14.501,11.223,21.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.515 | Acc: 14.780,11.219,21.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 8.128 | Acc: 20.312,29.688,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.980 | Acc: 26.153,31.585,43.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.916 | Acc: 27.039,32.165,45.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.934 | Acc: 27.024,32.364,45.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.935 | Acc: 27.006,32.407,45.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.920 | Acc: 27.483,32.503,45.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.900 | Acc: 27.421,32.645,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.913 | Acc: 27.333,32.475,45.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.910 | Acc: 27.227,32.463,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.913 | Acc: 27.219,32.441,45.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.911 | Acc: 27.266,32.393,45.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.898 | Acc: 27.397,32.438,45.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.893 | Acc: 27.350,32.414,45.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.894 | Acc: 27.302,32.411,45.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.883 | Acc: 27.424,32.501,45.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.862 | Acc: 27.549,32.636,45.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.848 | Acc: 27.650,32.732,45.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.837 | Acc: 27.662,32.808,45.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.827 | Acc: 27.707,33.018,45.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.813 | Acc: 27.869,33.159,45.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.012 | Acc: 17.969,12.500,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.987 | Acc: 16.555,11.756,31.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.967 | Acc: 16.825,12.176,32.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.983 | Acc: 16.714,11.936,32.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 7.632 | Acc: 32.812,33.594,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.559 | Acc: 29.688,33.854,48.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.557 | Acc: 28.868,34.165,48.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.524 | Acc: 28.791,34.529,48.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.477 | Acc: 29.331,35.021,48.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.465 | Acc: 29.556,35.419,48.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.445 | Acc: 29.597,35.770,49.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.443 | Acc: 29.660,35.771,49.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.445 | Acc: 29.658,35.802,48.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.459 | Acc: 29.614,35.722,48.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.465 | Acc: 29.579,35.700,48.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.460 | Acc: 29.550,35.690,48.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.452 | Acc: 29.684,35.678,48.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.443 | Acc: 29.747,35.740,48.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.436 | Acc: 29.904,35.832,48.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.423 | Acc: 30.009,36.021,48.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.417 | Acc: 30.043,36.008,48.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.416 | Acc: 30.052,36.009,48.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.408 | Acc: 30.079,36.031,49.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.399 | Acc: 30.114,36.134,49.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.819 | Acc: 20.312,15.625,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.840 | Acc: 19.345,14.435,26.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.844 | Acc: 19.379,14.253,26.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.861 | Acc: 19.480,14.088,25.884,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 6.444 | Acc: 34.375,42.188,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.257 | Acc: 30.394,35.975,49.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.170 | Acc: 30.755,36.623,50.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.152 | Acc: 31.019,36.808,51.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.115 | Acc: 31.481,37.413,51.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.108 | Acc: 31.598,37.562,51.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.114 | Acc: 31.424,37.461,51.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.086 | Acc: 31.682,37.783,51.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.075 | Acc: 31.687,38.043,51.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.070 | Acc: 31.794,38.117,51.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.074 | Acc: 31.771,38.032,51.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.087 | Acc: 31.628,37.747,51.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.081 | Acc: 31.752,37.831,51.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.069 | Acc: 31.822,37.949,51.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.067 | Acc: 31.862,38.000,52.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.054 | Acc: 31.940,38.017,52.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.046 | Acc: 32.000,38.177,52.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.042 | Acc: 32.011,38.128,52.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.036 | Acc: 32.057,38.182,52.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.031 | Acc: 32.117,38.263,52.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.737 | Acc: 15.625,17.969,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.770 | Acc: 15.997,17.708,24.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.747 | Acc: 15.911,18.255,24.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.754 | Acc: 16.009,18.238,24.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 6.675 | Acc: 35.938,43.750,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.760 | Acc: 34.115,40.253,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.797 | Acc: 33.803,40.111,56.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.794 | Acc: 33.799,39.921,55.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.829 | Acc: 33.362,39.767,54.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.804 | Acc: 33.625,40.145,55.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.793 | Acc: 33.781,40.244,54.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.782 | Acc: 33.898,40.270,54.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.773 | Acc: 33.972,40.324,54.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.784 | Acc: 33.866,40.176,54.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.784 | Acc: 33.776,40.236,54.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.785 | Acc: 33.778,40.279,54.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.783 | Acc: 33.720,40.217,54.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.776 | Acc: 33.716,40.254,54.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.769 | Acc: 33.763,40.283,54.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.767 | Acc: 33.768,40.303,54.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.757 | Acc: 33.823,40.379,54.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.758 | Acc: 33.793,40.412,54.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.758 | Acc: 33.739,40.445,54.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.751 | Acc: 33.758,40.459,54.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.902 | Acc: 17.969,20.312,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.996 | Acc: 14.695,14.844,28.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.972 | Acc: 15.072,14.825,28.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.993 | Acc: 15.087,15.202,27.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 6.663 | Acc: 33.594,38.281,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.404 | Acc: 34.747,41.741,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.493 | Acc: 34.470,41.521,57.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.492 | Acc: 34.285,41.496,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.467 | Acc: 34.259,41.686,57.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.454 | Acc: 34.561,42.017,57.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.446 | Acc: 34.607,42.033,57.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.456 | Acc: 34.719,42.060,57.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.468 | Acc: 34.661,41.853,57.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.460 | Acc: 34.923,41.976,57.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.453 | Acc: 34.896,41.970,57.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.462 | Acc: 34.845,41.990,57.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.466 | Acc: 34.796,42.003,57.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.453 | Acc: 34.905,42.208,57.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.463 | Acc: 34.803,42.218,57.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.470 | Acc: 34.746,42.117,57.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.465 | Acc: 34.747,42.158,57.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.462 | Acc: 34.847,42.229,57.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.462 | Acc: 34.866,42.272,57.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.456 | Acc: 34.896,42.376,57.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.873 | Acc: 20.312,21.094,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.048 | Acc: 21.354,18.601,42.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.020 | Acc: 22.313,19.264,43.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.046 | Acc: 21.952,19.083,42.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 6.044 | Acc: 39.062,39.062,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.200 | Acc: 37.277,44.122,60.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.126 | Acc: 37.652,44.474,60.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.150 | Acc: 37.615,44.480,60.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.148 | Acc: 37.703,44.300,60.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.167 | Acc: 37.175,44.268,60.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.168 | Acc: 36.971,44.170,60.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.182 | Acc: 36.841,43.994,60.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.190 | Acc: 36.753,43.944,60.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.192 | Acc: 36.624,43.858,60.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.191 | Acc: 36.633,43.979,60.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.189 | Acc: 36.740,44.026,60.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.197 | Acc: 36.712,44.042,60.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.206 | Acc: 36.695,43.977,59.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.204 | Acc: 36.758,44.139,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.208 | Acc: 36.680,44.012,59.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.215 | Acc: 36.573,43.942,59.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.218 | Acc: 36.659,44.036,59.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.209 | Acc: 36.756,44.129,59.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.221 | Acc: 36.711,44.033,59.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.831 | Acc: 21.094,25.000,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.183 | Acc: 17.560,22.991,34.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.175 | Acc: 18.216,23.971,34.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.189 | Acc: 17.905,23.796,33.491,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 6.194 | Acc: 36.719,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.020 | Acc: 37.016,45.945,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.033 | Acc: 37.671,45.694,62.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.012 | Acc: 37.846,46.017,61.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.001 | Acc: 38.088,46.046,62.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.012 | Acc: 37.817,45.730,62.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.036 | Acc: 37.810,45.661,61.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.017 | Acc: 37.705,45.783,61.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.027 | Acc: 37.539,45.667,61.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.036 | Acc: 37.418,45.615,61.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.030 | Acc: 37.449,45.709,61.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.029 | Acc: 37.447,45.790,61.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.036 | Acc: 37.387,45.760,61.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.046 | Acc: 37.314,45.726,61.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.044 | Acc: 37.456,45.741,61.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.045 | Acc: 37.357,45.790,61.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.049 | Acc: 37.405,45.670,61.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.048 | Acc: 37.436,45.668,61.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.048 | Acc: 37.435,45.706,61.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.046 | Acc: 37.406,45.749,61.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.126 | Acc: 16.406,30.469,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.381 | Acc: 14.211,24.479,37.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.360 | Acc: 14.291,25.191,37.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.386 | Acc: 13.845,24.629,37.564,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 5.907 | Acc: 37.500,42.188,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.850 | Acc: 38.021,46.168,62.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.861 | Acc: 38.205,46.551,63.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.815 | Acc: 38.576,47.208,63.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.822 | Acc: 38.387,47.020,63.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.808 | Acc: 38.351,47.014,63.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.808 | Acc: 38.243,47.017,64.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.798 | Acc: 38.586,47.207,63.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.798 | Acc: 38.626,47.312,63.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.798 | Acc: 38.536,47.311,64.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.799 | Acc: 38.619,47.384,63.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.788 | Acc: 38.705,47.419,63.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.808 | Acc: 38.521,47.261,63.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.820 | Acc: 38.452,47.108,63.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.820 | Acc: 38.426,47.189,63.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.831 | Acc: 38.331,47.109,63.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.823 | Acc: 38.381,47.182,63.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.822 | Acc: 38.375,47.239,63.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.827 | Acc: 38.376,47.215,63.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.827 | Acc: 38.349,47.263,63.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.909 | Acc: 25.000,24.219,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.252 | Acc: 19.382,19.531,28.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.228 | Acc: 19.722,20.008,29.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.251 | Acc: 19.480,19.557,29.034,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 6.144 | Acc: 35.938,48.438,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.686 | Acc: 38.467,47.656,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.675 | Acc: 38.224,48.457,65.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.655 | Acc: 38.576,48.668,65.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.675 | Acc: 38.455,48.148,65.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.690 | Acc: 38.428,48.012,65.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.657 | Acc: 38.862,48.334,65.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.648 | Acc: 38.913,48.510,65.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.659 | Acc: 38.796,48.544,65.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.652 | Acc: 38.786,48.610,65.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.646 | Acc: 38.849,48.745,65.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.654 | Acc: 38.857,48.650,65.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.657 | Acc: 38.858,48.609,64.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.666 | Acc: 38.778,48.432,64.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.681 | Acc: 38.765,48.326,64.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.686 | Acc: 38.694,48.305,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.676 | Acc: 38.800,48.377,64.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.671 | Acc: 38.859,48.401,64.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.665 | Acc: 38.885,48.505,64.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.675 | Acc: 38.763,48.448,64.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.459 | Acc: 18.750,27.344,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.719 | Acc: 20.052,22.545,45.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.711 | Acc: 20.332,23.323,44.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.732 | Acc: 19.736,23.476,44.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 5.891 | Acc: 40.625,39.844,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.493 | Acc: 39.881,48.772,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.475 | Acc: 40.263,49.200,66.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.471 | Acc: 39.857,49.590,66.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.463 | Acc: 40.181,49.711,66.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.482 | Acc: 40.161,49.675,66.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.468 | Acc: 40.179,50.006,66.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.504 | Acc: 40.121,49.701,66.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.503 | Acc: 40.242,49.845,66.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.501 | Acc: 40.258,49.914,66.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.506 | Acc: 40.046,49.926,66.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.521 | Acc: 40.024,49.788,66.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.523 | Acc: 40.087,49.896,66.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.528 | Acc: 39.969,49.904,66.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.523 | Acc: 39.952,49.917,66.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.526 | Acc: 39.981,49.971,66.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.529 | Acc: 39.907,49.959,66.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.524 | Acc: 39.935,49.968,66.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.517 | Acc: 39.930,49.998,66.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.515 | Acc: 39.969,49.941,66.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.060 | Acc: 27.344,26.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.375 | Acc: 25.744,19.717,51.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.352 | Acc: 26.944,20.046,50.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.386 | Acc: 26.140,19.941,49.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 5.580 | Acc: 35.938,50.781,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.210 | Acc: 41.109,53.237,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.258 | Acc: 41.406,52.229,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.308 | Acc: 40.907,51.345,69.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.304 | Acc: 41.175,51.350,69.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.300 | Acc: 41.252,51.416,68.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.289 | Acc: 41.335,51.550,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.295 | Acc: 41.046,51.457,68.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.305 | Acc: 41.086,51.422,68.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.317 | Acc: 41.018,51.489,68.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.337 | Acc: 40.819,51.279,68.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.327 | Acc: 40.954,51.485,68.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.330 | Acc: 40.962,51.462,68.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.333 | Acc: 40.936,51.500,68.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.345 | Acc: 40.872,51.371,68.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.345 | Acc: 40.903,51.365,68.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.351 | Acc: 40.898,51.382,68.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.358 | Acc: 40.850,51.349,68.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.366 | Acc: 40.755,51.262,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.374 | Acc: 40.680,51.200,67.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.858 | Acc: 28.906,35.156,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.182 | Acc: 22.507,29.985,46.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.187 | Acc: 22.694,30.621,46.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.200 | Acc: 22.541,30.456,46.593,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 5.621 | Acc: 39.844,47.656,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.201 | Acc: 41.667,53.423,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.194 | Acc: 41.654,53.011,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.169 | Acc: 41.778,53.356,71.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.171 | Acc: 42.081,53.009,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.177 | Acc: 41.925,53.140,71.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.188 | Acc: 41.652,53.080,70.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.186 | Acc: 41.794,52.953,70.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.203 | Acc: 41.693,52.693,70.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.219 | Acc: 41.475,52.525,70.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.225 | Acc: 41.523,52.484,69.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.230 | Acc: 41.343,52.464,69.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.230 | Acc: 41.361,52.412,69.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.232 | Acc: 41.275,52.455,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.235 | Acc: 41.212,52.391,69.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.246 | Acc: 41.095,52.261,69.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.241 | Acc: 41.109,52.295,69.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.248 | Acc: 41.081,52.135,69.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.245 | Acc: 41.103,52.197,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.247 | Acc: 41.107,52.188,69.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.390 | Acc: 18.750,22.656,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.724 | Acc: 17.634,20.647,45.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.708 | Acc: 18.140,20.808,44.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.722 | Acc: 18.276,20.748,44.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 5.214 | Acc: 39.062,53.125,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.023 | Acc: 44.085,54.241,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.005 | Acc: 43.407,53.925,72.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.007 | Acc: 43.327,54.278,72.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.015 | Acc: 42.747,53.954,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.996 | Acc: 42.713,54.092,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.021 | Acc: 42.420,53.790,71.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.046 | Acc: 42.359,53.674,71.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.050 | Acc: 42.294,53.717,71.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.074 | Acc: 42.149,53.410,70.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.069 | Acc: 42.324,53.475,70.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.077 | Acc: 42.233,53.376,70.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.099 | Acc: 42.136,53.297,70.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.102 | Acc: 42.149,53.281,70.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.103 | Acc: 42.171,53.409,70.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.110 | Acc: 42.232,53.411,70.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.106 | Acc: 42.302,53.400,70.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.110 | Acc: 42.240,53.338,70.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.116 | Acc: 42.181,53.309,70.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.128 | Acc: 42.099,53.109,70.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.925 | Acc: 17.188,32.812,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.269 | Acc: 14.695,26.414,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.235 | Acc: 15.606,26.848,52.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.258 | Acc: 15.625,26.780,52.011,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 4.400 | Acc: 46.094,61.719,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.862 | Acc: 42.522,55.320,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.933 | Acc: 42.873,54.325,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.979 | Acc: 42.431,54.034,73.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.998 | Acc: 42.535,54.061,72.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.999 | Acc: 42.327,53.953,72.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.998 | Acc: 42.291,54.035,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.016 | Acc: 42.066,53.856,72.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.047 | Acc: 41.843,53.625,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.042 | Acc: 41.993,53.557,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.048 | Acc: 41.974,53.514,71.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.054 | Acc: 41.937,53.496,71.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.047 | Acc: 42.100,53.683,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.037 | Acc: 42.211,53.775,71.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.042 | Acc: 42.238,53.776,71.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.045 | Acc: 42.151,53.738,71.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.046 | Acc: 42.107,53.753,71.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.045 | Acc: 42.087,53.702,71.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.047 | Acc: 42.146,53.737,71.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.045 | Acc: 42.224,53.810,71.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.517 | Acc: 21.094,25.781,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.782 | Acc: 18.713,21.763,40.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.792 | Acc: 18.750,21.570,40.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.808 | Acc: 18.340,21.260,39.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 4.849 | Acc: 46.875,58.594,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.813 | Acc: 43.266,55.915,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.805 | Acc: 43.464,55.812,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.808 | Acc: 43.532,55.674,74.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.800 | Acc: 43.519,55.652,74.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.828 | Acc: 43.472,55.476,74.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.811 | Acc: 43.640,55.630,74.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.834 | Acc: 43.595,55.474,73.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.837 | Acc: 43.643,55.440,73.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.850 | Acc: 43.694,55.313,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.851 | Acc: 43.591,55.216,73.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.873 | Acc: 43.495,55.161,73.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.882 | Acc: 43.325,55.031,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.885 | Acc: 43.289,54.915,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.897 | Acc: 43.216,54.865,73.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.908 | Acc: 43.210,54.807,73.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.916 | Acc: 43.146,54.799,72.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.918 | Acc: 43.035,54.765,72.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.925 | Acc: 43.083,54.750,72.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.930 | Acc: 43.063,54.747,72.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.999 | Acc: 20.312,35.156,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.404 | Acc: 20.871,28.683,38.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.417 | Acc: 20.446,28.449,37.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.440 | Acc: 20.210,28.804,37.756,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 4.522 | Acc: 44.531,53.125,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.743 | Acc: 43.341,56.027,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.706 | Acc: 43.788,56.517,75.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.740 | Acc: 43.840,56.404,75.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.795 | Acc: 43.364,55.565,75.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.811 | Acc: 43.123,55.461,74.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.815 | Acc: 43.001,55.488,74.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.799 | Acc: 43.312,55.807,74.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.798 | Acc: 43.304,55.983,74.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.794 | Acc: 43.426,56.133,74.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.805 | Acc: 43.381,55.935,74.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.808 | Acc: 43.248,55.925,74.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.814 | Acc: 43.238,55.981,74.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.814 | Acc: 43.214,55.978,74.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.828 | Acc: 43.213,55.786,73.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.827 | Acc: 43.254,55.765,73.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.827 | Acc: 43.190,55.751,73.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.837 | Acc: 43.202,55.595,73.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.836 | Acc: 43.215,55.581,73.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.836 | Acc: 43.221,55.538,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.630 | Acc: 30.469,35.938,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.812 | Acc: 26.042,32.515,49.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.788 | Acc: 26.162,32.832,49.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.815 | Acc: 25.973,32.877,49.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 4.305 | Acc: 45.312,58.594,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.576 | Acc: 44.792,57.552,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.664 | Acc: 44.627,56.879,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 44.595,57.006,75.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.636 | Acc: 44.907,57.330,75.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.612 | Acc: 45.220,57.534,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.638 | Acc: 44.925,57.380,75.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.651 | Acc: 44.891,57.264,75.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.671 | Acc: 44.750,57.177,75.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.672 | Acc: 44.846,57.182,75.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.676 | Acc: 44.753,57.086,75.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.682 | Acc: 44.595,56.961,75.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.696 | Acc: 44.227,56.730,75.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.700 | Acc: 44.124,56.711,75.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.722 | Acc: 43.997,56.475,74.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.733 | Acc: 43.947,56.401,74.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.729 | Acc: 44.023,56.406,74.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.741 | Acc: 43.913,56.349,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.750 | Acc: 43.821,56.315,74.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.753 | Acc: 43.859,56.301,74.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.206 | Acc: 25.000,29.688,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.586 | Acc: 18.304,28.423,39.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.594 | Acc: 17.797,28.373,38.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.604 | Acc: 17.392,28.612,39.062,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 4.243 | Acc: 46.094,57.031,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 44.382,58.482,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 44.322,58.422,78.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 43.968,58.094,77.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.588 | Acc: 43.818,57.697,77.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.595 | Acc: 44.191,57.774,76.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.596 | Acc: 44.034,57.612,76.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.606 | Acc: 43.938,57.541,76.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.593 | Acc: 44.022,57.560,76.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.604 | Acc: 44.108,57.571,76.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.607 | Acc: 43.995,57.502,76.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.615 | Acc: 43.976,57.385,76.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.622 | Acc: 43.876,57.281,76.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.629 | Acc: 43.873,57.277,76.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.638 | Acc: 43.881,57.201,75.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.649 | Acc: 43.908,57.132,75.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.654 | Acc: 43.879,57.080,75.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.653 | Acc: 43.963,57.043,75.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.659 | Acc: 43.964,57.068,75.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.666 | Acc: 43.953,57.029,75.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.493 | Acc: 35.156,29.688,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.808 | Acc: 27.753,25.112,51.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.794 | Acc: 27.934,25.514,50.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.816 | Acc: 28.099,25.320,50.448,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 4.390 | Acc: 45.312,57.031,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.325 | Acc: 48.214,59.412,79.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.417 | Acc: 46.646,57.832,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.446 | Acc: 45.991,57.697,78.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.452 | Acc: 45.669,57.697,78.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.479 | Acc: 45.057,57.565,78.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.511 | Acc: 44.835,57.322,78.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.511 | Acc: 44.814,57.563,77.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.514 | Acc: 44.779,57.730,77.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.514 | Acc: 44.933,57.735,77.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.527 | Acc: 44.959,57.692,77.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.539 | Acc: 44.856,57.646,77.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.555 | Acc: 44.829,57.501,77.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.573 | Acc: 44.735,57.304,77.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.584 | Acc: 44.706,57.237,76.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.588 | Acc: 44.658,57.236,76.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.594 | Acc: 44.655,57.221,76.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.600 | Acc: 44.607,57.235,76.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.603 | Acc: 44.551,57.267,76.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.607 | Acc: 44.531,57.249,76.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.975 | Acc: 25.781,37.500,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.279 | Acc: 22.619,33.110,40.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.292 | Acc: 22.752,32.755,39.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.315 | Acc: 22.285,32.992,38.960,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 3.619 | Acc: 51.562,68.750,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.482 | Acc: 44.754,58.854,79.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.486 | Acc: 44.455,58.422,79.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.435 | Acc: 44.839,58.824,80.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.450 | Acc: 44.850,58.893,79.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.475 | Acc: 44.763,58.818,79.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.484 | Acc: 44.596,58.787,79.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.492 | Acc: 44.614,58.527,79.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.486 | Acc: 44.871,58.880,79.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.484 | Acc: 45.023,58.818,78.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.492 | Acc: 45.040,58.734,78.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.482 | Acc: 45.157,58.806,78.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.486 | Acc: 45.069,58.798,78.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.492 | Acc: 45.076,58.785,78.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.494 | Acc: 45.146,58.786,78.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.496 | Acc: 45.100,58.817,78.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.505 | Acc: 45.033,58.684,77.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.513 | Acc: 45.040,58.511,77.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.521 | Acc: 45.061,58.360,77.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.531 | Acc: 45.062,58.229,77.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.365 | Acc: 24.219,40.625,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.670 | Acc: 25.446,31.994,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.694 | Acc: 24.505,31.383,54.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.722 | Acc: 24.180,31.096,54.534,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 4.760 | Acc: 38.281,60.156,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.434 | Acc: 45.461,58.854,79.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.404 | Acc: 45.694,59.204,79.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.372 | Acc: 46.440,59.721,79.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.363 | Acc: 46.200,59.500,79.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.356 | Acc: 46.148,59.460,79.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.365 | Acc: 45.932,59.388,79.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.357 | Acc: 45.944,59.259,79.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.360 | Acc: 45.938,59.259,79.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.352 | Acc: 46.046,59.444,79.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.350 | Acc: 46.074,59.457,79.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.371 | Acc: 45.903,59.396,79.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.380 | Acc: 45.857,59.300,78.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.388 | Acc: 45.926,59.318,78.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.406 | Acc: 45.852,59.139,78.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.412 | Acc: 45.777,59.053,78.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.422 | Acc: 45.607,58.988,78.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.432 | Acc: 45.571,58.956,78.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.428 | Acc: 45.670,59.009,78.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.441 | Acc: 45.563,58.907,78.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.840 | Acc: 32.812,36.719,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.140 | Acc: 23.586,30.878,39.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.143 | Acc: 23.514,30.774,39.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.160 | Acc: 23.770,30.469,39.062,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 4.481 | Acc: 35.156,57.031,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.377 | Acc: 45.424,59.487,80.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.311 | Acc: 45.351,60.347,81.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.254 | Acc: 45.863,60.707,81.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.282 | Acc: 45.824,60.475,80.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.289 | Acc: 45.862,60.210,80.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.282 | Acc: 45.945,60.098,80.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.302 | Acc: 45.833,59.807,80.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.327 | Acc: 45.788,59.477,79.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.330 | Acc: 45.757,59.522,79.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.340 | Acc: 45.802,59.394,79.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.344 | Acc: 45.952,59.407,79.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.355 | Acc: 45.909,59.249,79.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.360 | Acc: 46.049,59.246,79.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.366 | Acc: 45.999,59.205,79.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.381 | Acc: 45.871,59.108,79.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.389 | Acc: 45.814,59.083,78.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.390 | Acc: 45.823,59.125,78.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.393 | Acc: 45.886,59.076,78.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.407 | Acc: 45.825,58.955,78.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.176 | Acc: 30.469,39.844,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.402 | Acc: 24.926,34.821,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.428 | Acc: 24.676,35.366,54.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.450 | Acc: 24.667,35.592,53.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 4.902 | Acc: 37.500,50.781,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.174 | Acc: 44.085,61.384,82.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.155 | Acc: 45.827,61.433,82.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.175 | Acc: 46.427,61.399,81.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.191 | Acc: 46.364,61.478,81.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.183 | Acc: 46.496,61.378,81.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.201 | Acc: 46.255,61.267,81.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.236 | Acc: 45.911,60.788,81.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.244 | Acc: 45.793,60.709,80.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.245 | Acc: 45.753,60.691,80.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.257 | Acc: 45.794,60.459,80.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.269 | Acc: 45.715,60.245,80.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.280 | Acc: 45.630,60.276,80.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.291 | Acc: 45.555,60.168,80.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.296 | Acc: 45.649,60.176,79.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.300 | Acc: 45.707,60.099,79.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.316 | Acc: 45.609,59.959,79.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.318 | Acc: 45.661,59.966,79.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.327 | Acc: 45.683,59.847,79.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.337 | Acc: 45.671,59.693,79.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.439 | Acc: 19.531,45.312,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.714 | Acc: 22.024,41.034,48.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.722 | Acc: 22.332,40.568,48.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.757 | Acc: 21.977,40.420,47.874,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 4.245 | Acc: 46.875,57.812,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.233 | Acc: 47.507,60.342,81.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.184 | Acc: 47.008,60.957,81.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.164 | Acc: 47.157,61.296,81.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.186 | Acc: 46.991,61.111,81.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.181 | Acc: 46.643,60.891,81.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.196 | Acc: 46.759,60.783,81.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.192 | Acc: 47.014,60.910,81.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.198 | Acc: 46.676,60.928,81.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.207 | Acc: 46.638,60.679,81.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.209 | Acc: 46.541,60.735,81.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.222 | Acc: 46.596,60.566,80.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.233 | Acc: 46.574,60.480,80.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.245 | Acc: 46.468,60.381,80.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.266 | Acc: 46.291,60.237,80.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.268 | Acc: 46.333,60.255,80.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.273 | Acc: 46.342,60.280,80.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.287 | Acc: 46.229,60.177,79.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.298 | Acc: 46.105,60.083,79.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.306 | Acc: 46.016,60.027,79.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.194 | Acc: 20.312,37.500,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.424 | Acc: 20.015,37.091,31.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.459 | Acc: 19.836,37.081,30.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.475 | Acc: 20.044,37.103,30.930,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 4.306 | Acc: 53.125,61.719,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.081 | Acc: 48.363,62.314,83.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.089 | Acc: 47.218,62.367,83.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.076 | Acc: 47.272,62.129,82.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.085 | Acc: 46.904,61.680,82.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.078 | Acc: 46.968,61.556,82.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.117 | Acc: 46.881,61.267,82.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.114 | Acc: 47.002,61.359,82.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.139 | Acc: 46.812,61.287,82.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.149 | Acc: 46.875,61.054,82.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.163 | Acc: 46.883,60.949,81.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.181 | Acc: 46.758,60.846,81.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.197 | Acc: 46.535,60.665,81.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.199 | Acc: 46.579,60.683,81.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.201 | Acc: 46.653,60.676,81.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.201 | Acc: 46.670,60.681,81.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.221 | Acc: 46.537,60.463,81.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.232 | Acc: 46.424,60.337,81.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.239 | Acc: 46.429,60.314,80.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.238 | Acc: 46.487,60.304,80.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.446 | Acc: 18.750,47.656,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.804 | Acc: 16.778,45.015,46.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.784 | Acc: 16.921,45.236,46.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.806 | Acc: 16.995,45.453,46.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 4.044 | Acc: 45.312,60.938,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.161 | Acc: 47.321,60.454,82.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.104 | Acc: 47.542,60.899,83.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.103 | Acc: 47.464,61.194,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.079 | Acc: 47.367,61.603,83.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.060 | Acc: 47.579,61.873,83.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.069 | Acc: 47.327,61.848,83.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.080 | Acc: 47.152,61.591,83.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.097 | Acc: 47.205,61.486,82.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.119 | Acc: 47.000,61.257,82.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.147 | Acc: 46.739,61.039,82.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.143 | Acc: 46.833,61.121,82.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.152 | Acc: 46.898,61.083,81.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.163 | Acc: 46.872,61.111,81.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.177 | Acc: 46.844,61.029,81.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.183 | Acc: 46.867,60.922,81.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.195 | Acc: 46.785,60.867,81.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.200 | Acc: 46.754,60.802,81.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.205 | Acc: 46.698,60.764,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.208 | Acc: 46.816,60.802,81.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.617 | Acc: 20.312,39.844,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.983 | Acc: 15.179,35.193,39.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.967 | Acc: 14.958,34.870,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.989 | Acc: 14.805,34.759,39.908,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 4.365 | Acc: 47.656,55.469,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.176 | Acc: 46.577,60.528,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.122 | Acc: 47.066,60.461,83.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.049 | Acc: 47.451,61.360,84.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.031 | Acc: 47.666,61.651,83.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.075 | Acc: 47.030,61.262,83.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.088 | Acc: 46.927,61.247,83.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.102 | Acc: 46.792,61.176,83.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.086 | Acc: 46.977,61.335,83.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.095 | Acc: 46.819,61.227,83.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.110 | Acc: 46.580,61.085,82.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.115 | Acc: 46.765,61.213,82.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.118 | Acc: 46.794,61.362,82.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.115 | Acc: 46.878,61.386,82.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.124 | Acc: 46.789,61.332,82.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.131 | Acc: 46.797,61.301,82.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.143 | Acc: 46.736,61.261,82.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.146 | Acc: 46.760,61.256,82.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.151 | Acc: 46.771,61.249,81.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.152 | Acc: 46.725,61.204,81.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.127 | Acc: 28.906,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.625 | Acc: 20.833,41.592,47.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.634 | Acc: 21.189,41.654,47.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.665 | Acc: 21.440,41.637,46.657,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 4.078 | Acc: 48.438,59.375,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.962 | Acc: 48.661,63.207,84.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.035 | Acc: 48.056,61.662,83.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.025 | Acc: 47.643,62.154,84.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.034 | Acc: 47.724,62.114,84.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.044 | Acc: 47.765,61.881,84.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.025 | Acc: 47.947,62.087,83.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.032 | Acc: 47.806,62.245,83.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.046 | Acc: 47.729,62.058,83.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.063 | Acc: 47.617,61.874,83.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.071 | Acc: 47.586,61.765,83.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.070 | Acc: 47.656,61.740,83.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.072 | Acc: 47.578,61.754,83.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.075 | Acc: 47.593,61.749,82.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.080 | Acc: 47.592,61.780,82.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.084 | Acc: 47.571,61.734,82.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.094 | Acc: 47.442,61.592,82.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.103 | Acc: 47.409,61.542,82.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.108 | Acc: 47.379,61.466,82.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.110 | Acc: 47.363,61.551,82.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.197 | Acc: 29.688,48.438,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.564 | Acc: 27.641,41.853,41.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.587 | Acc: 26.639,41.540,40.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.605 | Acc: 27.164,41.598,40.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 3.787 | Acc: 45.312,63.281,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.978 | Acc: 48.586,61.421,85.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.964 | Acc: 48.876,62.786,84.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.922 | Acc: 48.694,63.038,84.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.916 | Acc: 48.736,63.339,84.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.932 | Acc: 48.530,63.359,84.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.939 | Acc: 48.592,63.456,84.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.952 | Acc: 48.510,63.303,84.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.978 | Acc: 48.374,62.932,83.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.980 | Acc: 48.425,62.975,83.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.998 | Acc: 48.165,62.768,83.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.018 | Acc: 47.858,62.539,83.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.025 | Acc: 47.757,62.374,83.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.041 | Acc: 47.725,62.311,83.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.049 | Acc: 47.653,62.189,83.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.062 | Acc: 47.539,61.971,82.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.064 | Acc: 47.469,61.960,82.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.068 | Acc: 47.448,61.920,82.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.068 | Acc: 47.420,61.974,82.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.076 | Acc: 47.406,61.905,82.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.118 | Acc: 16.406,48.438,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.568 | Acc: 11.496,41.815,43.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.557 | Acc: 11.414,41.368,43.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.584 | Acc: 11.335,41.419,43.455,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 3.904 | Acc: 47.656,61.719,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.027 | Acc: 46.280,62.240,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.968 | Acc: 47.828,62.824,84.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.947 | Acc: 47.823,63.051,84.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.966 | Acc: 47.656,63.301,84.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.949 | Acc: 47.935,63.204,84.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.959 | Acc: 47.831,63.249,84.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.977 | Acc: 47.817,63.037,84.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.984 | Acc: 47.714,62.859,84.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.979 | Acc: 47.721,62.845,84.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.986 | Acc: 47.680,62.803,84.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.000 | Acc: 47.589,62.631,84.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.014 | Acc: 47.471,62.536,83.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.014 | Acc: 47.477,62.611,83.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.020 | Acc: 47.387,62.564,83.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.026 | Acc: 47.475,62.453,83.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.028 | Acc: 47.532,62.459,83.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.032 | Acc: 47.565,62.450,83.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.038 | Acc: 47.498,62.379,83.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.040 | Acc: 47.564,62.334,83.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.791 | Acc: 35.938,49.219,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.119 | Acc: 28.311,47.247,43.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.123 | Acc: 27.877,47.389,43.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.134 | Acc: 27.318,47.464,44.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 4.112 | Acc: 46.875,63.281,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.951 | Acc: 49.591,62.686,84.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.859 | Acc: 49.390,63.700,85.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.868 | Acc: 48.873,63.448,85.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.891 | Acc: 48.534,63.262,85.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.922 | Acc: 48.368,62.724,85.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.919 | Acc: 48.476,63.159,84.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.917 | Acc: 48.637,63.215,84.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.926 | Acc: 48.520,63.063,84.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.947 | Acc: 48.438,62.837,84.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.943 | Acc: 48.410,62.834,84.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.952 | Acc: 48.515,62.793,84.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.954 | Acc: 48.493,62.805,84.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.968 | Acc: 48.375,62.593,84.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.971 | Acc: 48.257,62.683,84.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.977 | Acc: 48.194,62.638,84.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.982 | Acc: 48.126,62.588,84.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.984 | Acc: 48.112,62.605,84.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.992 | Acc: 48.057,62.556,83.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.990 | Acc: 48.081,62.537,83.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.284 | Acc: 17.969,40.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.786 | Acc: 14.621,35.305,44.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.771 | Acc: 14.463,35.156,44.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.812 | Acc: 14.293,35.118,43.865,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 3.468 | Acc: 47.656,67.188,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.798 | Acc: 49.591,65.290,85.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.810 | Acc: 49.257,64.977,85.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.842 | Acc: 49.244,64.370,85.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.848 | Acc: 49.055,64.342,85.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.899 | Acc: 48.314,63.730,84.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.911 | Acc: 48.599,63.559,84.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.931 | Acc: 48.371,63.342,84.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.934 | Acc: 48.306,63.310,84.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.946 | Acc: 48.101,63.122,84.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.949 | Acc: 48.103,62.986,84.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.945 | Acc: 48.310,62.967,84.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.948 | Acc: 48.259,63.054,84.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.957 | Acc: 48.264,63.054,84.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.963 | Acc: 48.182,63.039,83.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.968 | Acc: 48.173,63.050,83.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.978 | Acc: 48.097,62.931,83.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.975 | Acc: 48.078,62.974,83.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.973 | Acc: 48.091,62.976,83.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.988 | Acc: 48.001,62.826,83.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.636 | Acc: 35.938,53.906,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.011 | Acc: 26.414,45.461,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.027 | Acc: 26.696,45.579,47.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.037 | Acc: 26.819,45.761,47.400,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 3.544 | Acc: 47.656,68.750,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.867 | Acc: 48.028,62.946,85.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.805 | Acc: 49.162,64.634,85.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.848 | Acc: 49.129,64.152,85.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.851 | Acc: 48.958,64.082,85.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.860 | Acc: 49.049,63.869,85.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.849 | Acc: 49.019,63.953,85.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.859 | Acc: 48.892,63.941,85.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.865 | Acc: 48.719,63.878,85.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.874 | Acc: 48.649,63.765,85.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.883 | Acc: 48.577,63.573,85.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.886 | Acc: 48.597,63.624,85.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.893 | Acc: 48.463,63.469,85.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.893 | Acc: 48.521,63.563,85.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.908 | Acc: 48.349,63.387,85.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.914 | Acc: 48.357,63.328,84.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.925 | Acc: 48.257,63.272,84.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.932 | Acc: 48.213,63.249,84.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.936 | Acc: 48.163,63.199,84.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.938 | Acc: 48.216,63.240,84.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.752 | Acc: 30.469,47.656,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.047 | Acc: 25.037,42.560,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.088 | Acc: 24.886,41.444,55.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.118 | Acc: 24.834,41.393,55.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 3.519 | Acc: 53.906,67.188,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.708 | Acc: 50.112,66.815,86.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.761 | Acc: 49.352,65.473,86.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.783 | Acc: 48.899,65.279,86.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.818 | Acc: 48.881,64.477,86.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.820 | Acc: 48.623,64.341,86.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.833 | Acc: 48.425,64.069,86.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.847 | Acc: 48.371,63.968,85.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.857 | Acc: 48.345,63.893,85.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.867 | Acc: 48.429,63.834,85.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.874 | Acc: 48.546,63.845,85.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.881 | Acc: 48.483,63.720,85.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.891 | Acc: 48.379,63.641,85.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.885 | Acc: 48.518,63.835,85.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.899 | Acc: 48.374,63.748,85.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.904 | Acc: 48.349,63.733,84.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.905 | Acc: 48.265,63.705,84.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.916 | Acc: 48.234,63.618,84.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.926 | Acc: 48.243,63.571,84.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.928 | Acc: 48.224,63.581,84.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.622 | Acc: 24.219,44.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.850 | Acc: 23.772,42.225,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.878 | Acc: 23.761,42.473,55.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.900 | Acc: 23.732,42.508,55.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.482 | Acc: 54.688,69.531,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.683 | Acc: 51.116,64.509,85.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.703 | Acc: 50.019,65.225,86.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.726 | Acc: 49.039,65.074,86.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.742 | Acc: 49.161,64.950,86.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.752 | Acc: 49.404,64.851,86.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.758 | Acc: 49.206,65.012,86.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.778 | Acc: 49.180,64.744,86.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.774 | Acc: 49.296,64.742,86.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.786 | Acc: 49.236,64.775,86.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.794 | Acc: 49.098,64.762,86.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.793 | Acc: 49.240,64.844,86.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.806 | Acc: 49.141,64.772,85.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.817 | Acc: 49.060,64.670,85.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.839 | Acc: 48.866,64.341,85.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.841 | Acc: 48.941,64.390,85.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.852 | Acc: 48.795,64.250,85.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.856 | Acc: 48.793,64.269,85.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.870 | Acc: 48.673,64.125,85.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.874 | Acc: 48.720,64.134,85.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.631 | Acc: 30.469,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.205 | Acc: 26.190,45.015,50.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.234 | Acc: 26.181,45.332,49.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.251 | Acc: 25.871,44.941,49.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 4.428 | Acc: 44.531,57.812,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.708 | Acc: 48.884,64.249,87.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.642 | Acc: 49.638,65.568,87.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.675 | Acc: 49.321,65.382,87.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.713 | Acc: 49.055,64.844,86.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.736 | Acc: 48.832,64.728,86.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.768 | Acc: 48.612,64.527,86.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.769 | Acc: 48.881,64.517,86.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.785 | Acc: 48.772,64.417,86.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.793 | Acc: 48.688,64.399,86.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.810 | Acc: 48.663,64.303,86.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.821 | Acc: 48.685,64.328,85.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.830 | Acc: 48.707,64.225,85.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.838 | Acc: 48.644,64.077,85.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.848 | Acc: 48.624,64.060,85.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.850 | Acc: 48.627,64.099,85.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.859 | Acc: 48.535,64.038,85.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.866 | Acc: 48.522,63.930,85.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.866 | Acc: 48.591,63.954,85.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.880 | Acc: 48.517,63.839,84.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.301 | Acc: 23.438,46.875,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.457 | Acc: 21.466,39.732,51.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.466 | Acc: 21.341,40.454,50.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.476 | Acc: 21.478,40.804,50.807,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.663 | Acc: 55.469,67.969,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.766 | Acc: 49.554,65.365,87.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.773 | Acc: 48.876,65.034,86.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.790 | Acc: 48.796,64.613,87.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.793 | Acc: 48.852,64.448,87.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.781 | Acc: 48.793,64.627,86.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.768 | Acc: 49.006,64.740,86.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.773 | Acc: 48.992,64.888,86.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.778 | Acc: 49.000,64.790,86.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.785 | Acc: 48.860,64.714,86.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.793 | Acc: 48.888,64.727,86.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.805 | Acc: 48.787,64.564,86.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.807 | Acc: 48.820,64.497,85.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.813 | Acc: 48.728,64.407,85.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.823 | Acc: 48.646,64.285,85.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.821 | Acc: 48.783,64.369,85.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.833 | Acc: 48.713,64.272,85.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.836 | Acc: 48.635,64.250,85.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.844 | Acc: 48.561,64.218,85.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.855 | Acc: 48.503,64.165,85.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.526 | Acc: 33.594,40.625,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.968 | Acc: 28.274,41.778,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.000 | Acc: 27.744,41.749,55.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.028 | Acc: 27.459,41.675,55.686,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 3.950 | Acc: 46.875,58.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.671 | Acc: 50.521,64.695,87.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.734 | Acc: 49.219,64.367,86.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.709 | Acc: 49.654,64.741,86.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.708 | Acc: 49.614,65.114,86.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.719 | Acc: 49.435,64.998,86.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.721 | Acc: 49.425,64.992,86.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.733 | Acc: 49.235,64.860,86.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.741 | Acc: 49.262,64.795,86.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.747 | Acc: 49.258,64.693,86.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.766 | Acc: 49.316,64.642,86.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.775 | Acc: 49.258,64.540,86.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.782 | Acc: 49.274,64.490,85.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.793 | Acc: 49.198,64.338,85.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.807 | Acc: 49.144,64.163,85.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.811 | Acc: 49.164,64.068,85.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.820 | Acc: 49.005,63.992,85.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.823 | Acc: 49.026,63.959,85.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.829 | Acc: 48.946,63.911,85.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.824 | Acc: 48.930,63.993,85.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.167 | Acc: 25.781,41.406,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.495 | Acc: 24.368,42.411,41.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.515 | Acc: 24.295,42.511,40.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.537 | Acc: 24.552,42.059,40.548,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.470 | Acc: 49.219,64.062,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.635 | Acc: 49.665,66.257,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.693 | Acc: 49.619,65.377,87.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.743 | Acc: 48.860,65.177,87.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.709 | Acc: 49.035,65.577,87.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.716 | Acc: 49.049,65.416,87.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.711 | Acc: 49.296,65.302,86.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.728 | Acc: 49.302,65.054,86.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.745 | Acc: 49.209,64.887,86.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.755 | Acc: 48.899,64.766,86.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.748 | Acc: 49.192,64.953,86.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.760 | Acc: 49.123,64.858,86.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.765 | Acc: 49.232,64.808,86.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.777 | Acc: 49.105,64.673,85.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.783 | Acc: 49.102,64.602,85.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.795 | Acc: 48.998,64.486,85.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.796 | Acc: 49.009,64.530,85.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.808 | Acc: 48.891,64.404,85.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.811 | Acc: 48.920,64.450,85.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.814 | Acc: 48.948,64.444,85.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.408 | Acc: 31.250,51.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.780 | Acc: 28.869,50.707,52.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.845 | Acc: 28.411,49.924,52.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.864 | Acc: 28.420,49.974,52.203,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 4.113 | Acc: 42.188,62.500,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.549 | Acc: 50.967,67.113,87.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.549 | Acc: 51.372,67.111,88.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.579 | Acc: 50.499,66.726,87.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.593 | Acc: 50.289,66.802,87.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.596 | Acc: 50.255,66.646,87.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.624 | Acc: 49.961,66.355,87.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.651 | Acc: 49.989,66.018,87.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.649 | Acc: 50.039,65.940,87.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.663 | Acc: 49.918,65.867,87.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.668 | Acc: 49.880,65.874,87.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.673 | Acc: 49.866,65.950,87.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.679 | Acc: 49.932,65.884,87.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.696 | Acc: 49.886,65.718,87.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.704 | Acc: 49.842,65.547,86.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.707 | Acc: 49.777,65.498,86.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.720 | Acc: 49.664,65.413,86.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.726 | Acc: 49.594,65.359,86.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.732 | Acc: 49.533,65.318,86.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.743 | Acc: 49.450,65.172,86.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.021 | Acc: 21.875,44.531,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.237 | Acc: 22.247,44.085,51.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.280 | Acc: 21.570,43.941,50.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.284 | Acc: 21.491,43.968,50.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 4.019 | Acc: 48.438,60.156,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.651 | Acc: 50.037,66.220,87.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.685 | Acc: 49.733,65.987,87.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.673 | Acc: 49.103,65.868,87.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.663 | Acc: 49.537,65.992,87.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.647 | Acc: 49.853,66.190,87.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.672 | Acc: 49.742,65.980,87.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.682 | Acc: 49.596,65.852,87.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.692 | Acc: 49.631,65.795,87.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.701 | Acc: 49.620,65.660,87.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.709 | Acc: 49.440,65.508,87.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.707 | Acc: 49.597,65.621,86.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.711 | Acc: 49.546,65.599,86.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.717 | Acc: 49.488,65.547,86.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.732 | Acc: 49.413,65.408,86.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.730 | Acc: 49.489,65.347,86.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.728 | Acc: 49.528,65.423,86.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.738 | Acc: 49.551,65.339,86.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.746 | Acc: 49.530,65.199,86.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.748 | Acc: 49.569,65.194,86.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.759 | Acc: 30.469,53.125,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.972 | Acc: 28.051,49.888,39.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.976 | Acc: 28.239,49.790,40.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.993 | Acc: 28.356,49.731,40.356,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 3.702 | Acc: 51.562,70.312,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.705 | Acc: 49.070,65.960,87.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.605 | Acc: 50.076,66.978,87.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.623 | Acc: 50.141,66.176,87.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.652 | Acc: 49.932,65.770,87.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.637 | Acc: 49.838,65.958,88.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.635 | Acc: 50.006,65.922,87.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.651 | Acc: 49.911,65.896,87.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.663 | Acc: 49.927,65.955,87.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.673 | Acc: 49.814,65.906,87.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.678 | Acc: 49.872,65.866,87.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.680 | Acc: 49.876,65.848,87.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.688 | Acc: 49.763,65.839,87.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.693 | Acc: 49.796,65.852,86.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.696 | Acc: 49.922,65.842,86.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.697 | Acc: 49.992,65.801,86.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.710 | Acc: 49.844,65.640,86.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.724 | Acc: 49.780,65.494,86.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.726 | Acc: 49.799,65.450,86.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.730 | Acc: 49.850,65.397,86.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.718 | Acc: 28.906,46.094,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.084 | Acc: 24.405,44.048,48.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.097 | Acc: 24.714,43.655,48.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.129 | Acc: 24.744,43.251,48.143,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 3.143 | Acc: 55.469,69.531,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.540 | Acc: 51.339,66.815,88.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.611 | Acc: 50.286,66.444,88.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.597 | Acc: 50.397,66.265,88.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.579 | Acc: 50.637,66.512,88.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.606 | Acc: 50.333,66.174,88.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.603 | Acc: 50.433,66.245,88.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.621 | Acc: 50.194,66.096,87.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.632 | Acc: 50.053,66.086,87.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.632 | Acc: 50.190,66.100,87.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.647 | Acc: 49.984,65.994,87.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.655 | Acc: 49.887,65.858,87.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.658 | Acc: 49.935,65.810,87.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.678 | Acc: 49.826,65.628,87.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.693 | Acc: 49.744,65.525,87.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.698 | Acc: 49.727,65.558,86.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.704 | Acc: 49.771,65.501,86.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.710 | Acc: 49.757,65.474,86.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.720 | Acc: 49.680,65.389,86.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.730 | Acc: 49.563,65.229,86.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.531 | Acc: 32.031,55.469,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.939 | Acc: 26.786,45.685,54.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.944 | Acc: 26.791,45.084,54.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.969 | Acc: 26.473,45.120,54.534,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 3.832 | Acc: 44.531,60.938,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.517 | Acc: 50.595,67.597,87.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.575 | Acc: 49.905,66.902,88.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.623 | Acc: 50.051,66.009,87.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.677 | Acc: 49.527,65.509,87.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.658 | Acc: 49.590,65.656,87.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.660 | Acc: 49.509,65.580,87.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.655 | Acc: 49.596,65.608,87.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.659 | Acc: 49.500,65.572,87.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.673 | Acc: 49.469,65.504,87.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.674 | Acc: 49.518,65.501,87.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.682 | Acc: 49.441,65.445,87.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.689 | Acc: 49.429,65.405,87.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.687 | Acc: 49.401,65.484,87.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.699 | Acc: 49.324,65.372,87.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.697 | Acc: 49.403,65.410,87.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.706 | Acc: 49.323,65.296,86.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.710 | Acc: 49.331,65.194,86.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.713 | Acc: 49.342,65.179,86.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.718 | Acc: 49.334,65.188,86.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.726 | Acc: 41.406,41.406,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.087 | Acc: 33.445,45.685,42.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.079 | Acc: 32.698,45.636,42.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.106 | Acc: 32.928,45.863,41.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.654 | Acc: 51.562,60.938,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.662 | Acc: 50.260,64.881,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.639 | Acc: 50.610,66.101,87.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.628 | Acc: 50.653,66.086,87.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.634 | Acc: 50.849,65.972,87.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.633 | Acc: 50.580,66.143,87.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.640 | Acc: 50.155,65.941,87.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.659 | Acc: 49.978,65.680,87.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.658 | Acc: 49.918,65.654,87.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.661 | Acc: 49.780,65.578,87.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.684 | Acc: 49.751,65.302,87.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.693 | Acc: 49.639,65.229,87.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.692 | Acc: 49.643,65.304,87.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.697 | Acc: 49.605,65.365,86.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.708 | Acc: 49.583,65.308,86.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.707 | Acc: 49.543,65.345,86.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.712 | Acc: 49.479,65.382,86.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.716 | Acc: 49.560,65.350,86.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.722 | Acc: 49.498,65.354,86.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.719 | Acc: 49.592,65.408,86.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.015 | Acc: 24.219,48.438,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.172 | Acc: 24.368,44.829,49.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.232 | Acc: 24.028,44.322,47.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.248 | Acc: 24.052,43.993,47.528,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 3.736 | Acc: 54.688,63.281,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.573 | Acc: 50.818,66.034,88.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.531 | Acc: 50.152,66.768,88.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.543 | Acc: 50.692,67.034,88.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.576 | Acc: 50.463,66.667,88.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.575 | Acc: 50.565,66.824,87.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.571 | Acc: 50.826,66.826,87.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.572 | Acc: 50.803,66.866,87.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.573 | Acc: 50.835,66.780,87.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.592 | Acc: 50.587,66.678,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.609 | Acc: 50.303,66.496,87.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.618 | Acc: 50.216,66.473,87.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.627 | Acc: 50.230,66.419,87.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.635 | Acc: 50.222,66.370,87.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.646 | Acc: 50.120,66.234,87.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.663 | Acc: 49.888,66.058,86.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.669 | Acc: 49.893,66.031,86.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.672 | Acc: 49.888,66.010,86.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.675 | Acc: 49.883,65.956,86.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.678 | Acc: 49.918,65.984,86.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.796 | Acc: 38.281,45.312,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.061 | Acc: 29.390,46.131,40.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.085 | Acc: 29.268,45.408,39.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.108 | Acc: 28.663,45.248,39.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 3.267 | Acc: 54.688,72.656,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.505 | Acc: 51.749,67.820,89.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.497 | Acc: 51.677,67.435,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.489 | Acc: 51.921,67.444,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.521 | Acc: 51.418,67.159,88.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.554 | Acc: 51.106,66.932,88.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.551 | Acc: 51.304,66.981,88.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.573 | Acc: 51.042,66.827,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.590 | Acc: 50.849,66.722,88.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.590 | Acc: 50.893,66.721,87.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.598 | Acc: 50.777,66.542,87.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.602 | Acc: 50.686,66.339,87.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.617 | Acc: 50.522,66.163,87.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.627 | Acc: 50.485,66.056,87.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.631 | Acc: 50.378,65.967,87.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.639 | Acc: 50.314,65.981,87.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.641 | Acc: 50.265,65.905,87.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.649 | Acc: 50.245,65.877,87.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.656 | Acc: 50.197,65.902,87.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.667 | Acc: 50.141,65.849,87.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.823 | Acc: 20.312,54.688,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.163 | Acc: 21.168,48.958,46.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.194 | Acc: 20.370,48.304,46.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.217 | Acc: 20.645,47.848,45.953,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 3.339 | Acc: 49.219,71.875,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.542 | Acc: 49.628,68.229,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.508 | Acc: 50.781,68.197,88.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.506 | Acc: 51.473,68.020,88.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.489 | Acc: 51.678,67.978,88.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.511 | Acc: 51.222,67.621,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.529 | Acc: 50.923,67.310,88.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.555 | Acc: 50.543,66.927,87.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.576 | Acc: 50.422,66.712,87.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.586 | Acc: 50.224,66.626,87.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.601 | Acc: 50.249,66.511,87.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.595 | Acc: 50.240,66.498,87.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.602 | Acc: 50.149,66.432,87.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.602 | Acc: 50.162,66.523,87.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.609 | Acc: 50.133,66.515,87.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.619 | Acc: 50.158,66.362,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.626 | Acc: 50.151,66.246,86.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.637 | Acc: 50.124,66.152,86.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.649 | Acc: 49.989,66.071,86.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.652 | Acc: 49.994,66.049,86.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.563 | Acc: 31.250,39.844,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.874 | Acc: 26.711,35.938,35.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.889 | Acc: 25.838,35.480,35.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.899 | Acc: 25.730,35.451,35.925,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.587 | Acc: 52.344,64.844,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.558 | Acc: 50.521,65.439,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.500 | Acc: 50.991,66.444,88.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.499 | Acc: 50.717,66.970,88.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.515 | Acc: 50.704,67.062,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.527 | Acc: 50.766,67.033,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.515 | Acc: 50.943,67.007,88.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.527 | Acc: 50.798,66.982,88.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.529 | Acc: 50.985,66.964,88.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.523 | Acc: 51.239,67.093,88.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.532 | Acc: 51.119,66.947,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.539 | Acc: 51.046,66.891,88.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.557 | Acc: 50.862,66.792,87.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.566 | Acc: 50.694,66.739,87.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.577 | Acc: 50.470,66.609,87.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.589 | Acc: 50.428,66.448,87.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.601 | Acc: 50.331,66.282,87.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.613 | Acc: 50.218,66.202,87.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.623 | Acc: 50.190,66.131,87.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.624 | Acc: 50.205,66.115,87.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.992 | Acc: 27.344,44.531,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.161 | Acc: 30.990,44.829,46.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.160 | Acc: 30.488,45.103,47.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.168 | Acc: 30.418,45.082,48.105,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 3.548 | Acc: 51.562,60.938,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.482 | Acc: 51.376,68.304,88.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.416 | Acc: 51.734,69.055,88.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.480 | Acc: 51.345,68.225,88.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.458 | Acc: 51.292,68.490,89.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.481 | Acc: 51.323,68.123,89.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.498 | Acc: 51.278,68.162,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.509 | Acc: 51.119,67.996,88.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.523 | Acc: 51.048,67.959,88.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.545 | Acc: 50.893,67.762,88.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.552 | Acc: 50.801,67.654,88.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.554 | Acc: 50.788,67.626,88.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.563 | Acc: 50.661,67.525,88.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.568 | Acc: 50.512,67.340,88.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.567 | Acc: 50.537,67.332,87.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.574 | Acc: 50.527,67.213,87.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.578 | Acc: 50.489,67.202,87.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.591 | Acc: 50.373,67.084,87.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.604 | Acc: 50.193,66.969,87.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.606 | Acc: 50.310,66.960,87.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.166 | Acc: 30.469,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.499 | Acc: 25.707,51.376,57.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.503 | Acc: 25.343,51.143,57.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.521 | Acc: 25.013,51.076,57.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 3.563 | Acc: 40.625,63.281,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.531 | Acc: 51.265,66.815,89.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.514 | Acc: 51.143,67.264,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.498 | Acc: 51.383,67.687,89.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.506 | Acc: 51.418,67.342,89.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.502 | Acc: 51.408,67.288,89.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.506 | Acc: 51.265,67.278,89.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.519 | Acc: 51.213,67.215,88.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.522 | Acc: 51.145,67.265,88.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.527 | Acc: 51.122,67.248,88.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.530 | Acc: 50.968,67.180,88.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.547 | Acc: 50.817,66.972,88.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.561 | Acc: 50.609,66.850,88.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.574 | Acc: 50.560,66.697,87.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.578 | Acc: 50.587,66.690,87.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.587 | Acc: 50.493,66.578,87.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.595 | Acc: 50.428,66.472,87.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.595 | Acc: 50.465,66.546,87.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.600 | Acc: 50.433,66.497,87.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.607 | Acc: 50.406,66.458,87.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.949 | Acc: 25.781,46.094,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.319 | Acc: 22.396,45.238,50.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.343 | Acc: 22.313,44.512,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.371 | Acc: 22.477,44.160,49.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 3.271 | Acc: 52.344,72.656,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.405 | Acc: 52.865,69.978,88.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.457 | Acc: 51.829,69.512,89.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.473 | Acc: 51.691,69.121,89.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.476 | Acc: 51.370,68.663,89.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.486 | Acc: 51.292,68.263,89.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.484 | Acc: 51.324,68.162,89.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.499 | Acc: 51.225,67.974,89.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.520 | Acc: 51.082,67.697,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.524 | Acc: 51.209,67.446,88.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.544 | Acc: 51.011,67.234,88.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.555 | Acc: 51.053,67.106,88.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.562 | Acc: 50.956,66.951,88.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.569 | Acc: 50.844,66.822,88.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.568 | Acc: 50.881,66.873,88.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.573 | Acc: 50.818,66.876,88.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.574 | Acc: 50.832,66.830,88.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.577 | Acc: 50.761,66.823,87.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.587 | Acc: 50.658,66.768,87.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.583 | Acc: 50.716,66.831,87.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.487 | Acc: 33.594,47.656,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.753 | Acc: 30.171,46.094,23.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.764 | Acc: 29.745,45.941,23.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.799 | Acc: 29.752,46.107,23.335,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 3.228 | Acc: 55.469,67.188,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.302 | Acc: 52.641,69.606,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.337 | Acc: 52.420,69.493,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.351 | Acc: 52.626,69.301,89.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.384 | Acc: 52.180,68.943,89.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.426 | Acc: 51.949,68.634,89.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.451 | Acc: 51.937,68.246,88.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.455 | Acc: 51.934,68.218,88.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.465 | Acc: 51.723,68.061,88.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.486 | Acc: 51.571,67.900,88.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.501 | Acc: 51.426,67.689,88.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.512 | Acc: 51.237,67.622,88.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.506 | Acc: 51.235,67.765,88.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.520 | Acc: 51.087,67.580,88.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.534 | Acc: 51.020,67.466,88.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.545 | Acc: 50.846,67.424,87.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.557 | Acc: 50.825,67.282,87.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.568 | Acc: 50.729,67.238,87.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.576 | Acc: 50.667,67.159,87.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.584 | Acc: 50.652,66.980,87.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.032 | Acc: 38.281,41.406,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.307 | Acc: 34.226,42.894,36.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.321 | Acc: 34.451,42.702,35.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.339 | Acc: 34.452,42.610,36.181,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 3.430 | Acc: 51.562,71.094,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.429 | Acc: 51.711,68.155,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.529 | Acc: 50.381,67.912,88.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.516 | Acc: 50.602,67.956,88.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.499 | Acc: 51.100,68.142,88.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.489 | Acc: 51.183,68.255,89.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.489 | Acc: 51.046,68.369,88.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.509 | Acc: 50.798,68.091,88.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.525 | Acc: 50.733,67.828,88.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.533 | Acc: 50.794,67.740,88.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.544 | Acc: 50.540,67.456,88.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.550 | Acc: 50.590,67.294,88.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.548 | Acc: 50.584,67.314,88.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.548 | Acc: 50.593,67.235,88.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.553 | Acc: 50.748,67.121,87.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.556 | Acc: 50.776,67.068,87.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.562 | Acc: 50.711,66.942,87.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.568 | Acc: 50.623,66.862,87.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.576 | Acc: 50.513,66.761,87.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.582 | Acc: 50.519,66.759,87.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.353 | Acc: 31.250,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.731 | Acc: 23.214,51.600,56.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.777 | Acc: 22.275,51.067,55.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.785 | Acc: 22.298,50.973,55.853,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.848 | Acc: 43.750,62.500,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.356 | Acc: 52.418,67.336,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.397 | Acc: 51.696,67.302,89.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.408 | Acc: 51.076,67.597,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.405 | Acc: 51.553,67.728,89.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.452 | Acc: 51.245,67.505,89.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.465 | Acc: 50.962,67.633,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.477 | Acc: 50.881,67.525,88.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.486 | Acc: 50.806,67.401,88.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.480 | Acc: 50.963,67.455,88.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.491 | Acc: 50.882,67.312,88.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.508 | Acc: 50.859,67.134,88.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.521 | Acc: 50.807,67.074,88.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.526 | Acc: 50.754,67.050,88.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.535 | Acc: 50.690,67.029,88.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.546 | Acc: 50.607,66.858,87.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.553 | Acc: 50.516,66.801,87.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.559 | Acc: 50.559,66.750,87.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.563 | Acc: 50.539,66.690,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.568 | Acc: 50.599,66.634,87.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.428 | Acc: 36.719,49.219,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.905 | Acc: 28.981,46.615,49.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.922 | Acc: 28.830,46.265,49.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.939 | Acc: 28.791,45.671,49.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 3.225 | Acc: 57.812,71.094,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.404 | Acc: 50.484,69.010,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.360 | Acc: 51.925,69.074,90.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.381 | Acc: 51.960,68.904,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.420 | Acc: 51.784,68.596,90.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.417 | Acc: 51.702,68.572,90.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.448 | Acc: 51.395,68.233,89.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.465 | Acc: 51.147,68.124,89.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.479 | Acc: 51.218,68.163,89.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.475 | Acc: 51.152,68.051,89.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.482 | Acc: 50.960,68.081,89.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.486 | Acc: 51.075,67.933,89.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.498 | Acc: 50.950,67.810,88.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.509 | Acc: 50.841,67.613,88.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.511 | Acc: 50.895,67.532,88.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.514 | Acc: 50.971,67.463,88.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.519 | Acc: 50.874,67.353,88.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.527 | Acc: 50.871,67.293,88.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.540 | Acc: 50.863,67.086,88.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.539 | Acc: 50.855,67.108,88.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.182 | Acc: 32.031,50.781,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.584 | Acc: 28.088,46.763,28.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.603 | Acc: 28.487,46.303,29.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.620 | Acc: 28.240,45.838,29.393,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 4.127 | Acc: 48.438,63.281,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.510 | Acc: 50.781,68.118,88.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.491 | Acc: 50.514,68.464,89.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.492 | Acc: 51.050,68.417,89.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.479 | Acc: 51.109,68.364,89.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.472 | Acc: 51.323,68.278,89.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.492 | Acc: 51.091,68.098,89.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.486 | Acc: 51.047,68.102,88.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.477 | Acc: 51.174,68.381,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.481 | Acc: 51.200,68.258,88.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.492 | Acc: 51.154,68.124,88.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.504 | Acc: 51.061,67.990,88.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.502 | Acc: 51.144,67.943,88.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.509 | Acc: 51.066,67.843,88.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.512 | Acc: 51.107,67.785,88.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.521 | Acc: 51.062,67.686,88.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.530 | Acc: 50.981,67.574,88.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.540 | Acc: 50.942,67.451,88.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.543 | Acc: 50.911,67.469,87.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.550 | Acc: 50.857,67.405,87.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.058 | Acc: 40.625,54.688,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.386 | Acc: 31.473,50.484,26.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.461 | Acc: 30.164,49.619,26.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.496 | Acc: 30.097,49.347,26.191,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 3.074 | Acc: 55.469,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.522 | Acc: 50.781,66.815,88.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.452 | Acc: 51.429,67.721,89.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.422 | Acc: 51.665,67.956,89.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.445 | Acc: 51.601,67.708,89.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.434 | Acc: 51.640,67.899,89.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.449 | Acc: 51.240,67.782,89.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.451 | Acc: 51.324,67.836,89.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.467 | Acc: 51.247,67.682,89.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.481 | Acc: 51.049,67.628,89.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.489 | Acc: 51.057,67.498,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.495 | Acc: 51.195,67.403,88.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.496 | Acc: 51.157,67.324,88.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.507 | Acc: 51.108,67.238,88.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.510 | Acc: 51.129,67.299,88.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.510 | Acc: 51.191,67.330,88.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.516 | Acc: 51.107,67.336,88.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.515 | Acc: 51.042,67.359,88.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.518 | Acc: 50.998,67.361,88.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.523 | Acc: 50.953,67.276,88.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.703 | Acc: 27.344,42.969,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.763 | Acc: 23.400,44.159,29.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.809 | Acc: 22.618,43.960,29.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.828 | Acc: 21.773,43.673,29.508,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 3.796 | Acc: 48.438,69.531,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.449 | Acc: 51.190,67.708,88.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.522 | Acc: 50.114,67.111,88.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.502 | Acc: 50.359,67.725,88.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.502 | Acc: 50.810,67.612,88.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.493 | Acc: 51.006,67.698,88.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.484 | Acc: 51.111,67.891,88.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.479 | Acc: 51.147,67.936,88.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.482 | Acc: 51.106,67.872,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.483 | Acc: 51.114,67.831,88.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.483 | Acc: 51.038,67.930,88.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.486 | Acc: 51.007,67.898,88.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.490 | Acc: 50.862,67.868,88.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.490 | Acc: 50.880,67.882,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.498 | Acc: 50.909,67.735,88.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.498 | Acc: 50.908,67.751,88.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.505 | Acc: 50.876,67.638,88.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.512 | Acc: 50.887,67.561,88.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.522 | Acc: 50.876,67.525,88.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.532 | Acc: 50.841,67.454,88.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.879 | Acc: 34.375,52.344,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.361 | Acc: 27.046,47.805,39.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.402 | Acc: 26.372,46.799,38.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.417 | Acc: 26.370,46.721,38.448,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.039 | Acc: 47.656,55.469,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.455 | Acc: 51.228,67.113,89.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.438 | Acc: 51.086,67.969,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.428 | Acc: 51.767,68.174,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.422 | Acc: 51.630,68.422,89.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.437 | Acc: 51.392,68.077,89.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.444 | Acc: 51.395,67.814,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.434 | Acc: 51.590,67.808,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.431 | Acc: 51.655,68.012,89.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.443 | Acc: 51.735,67.891,89.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.445 | Acc: 51.617,67.918,89.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.456 | Acc: 51.499,67.827,88.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.472 | Acc: 51.193,67.680,88.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.480 | Acc: 51.143,67.619,88.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.483 | Acc: 51.140,67.646,88.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.485 | Acc: 51.108,67.650,88.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.493 | Acc: 51.090,67.594,88.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.495 | Acc: 51.118,67.520,88.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.506 | Acc: 51.026,67.389,88.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.515 | Acc: 50.915,67.274,88.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.557 | Acc: 44.531,53.906,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.083 | Acc: 32.403,47.359,40.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.128 | Acc: 32.241,47.542,40.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.164 | Acc: 32.121,46.990,39.895,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 3.525 | Acc: 52.344,61.719,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.332 | Acc: 53.609,69.531,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.324 | Acc: 52.611,69.703,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.369 | Acc: 51.819,68.993,89.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.371 | Acc: 51.813,68.904,89.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.352 | Acc: 52.351,69.005,89.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.377 | Acc: 52.137,68.827,89.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.394 | Acc: 52.100,68.556,89.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.415 | Acc: 51.834,68.333,89.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.426 | Acc: 51.601,68.167,89.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.447 | Acc: 51.590,67.973,89.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.461 | Acc: 51.414,67.912,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.467 | Acc: 51.430,67.888,88.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.473 | Acc: 51.320,67.861,88.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.472 | Acc: 51.215,67.899,88.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.480 | Acc: 51.238,67.909,88.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.487 | Acc: 51.236,67.832,88.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.489 | Acc: 51.308,67.868,88.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.496 | Acc: 51.270,67.843,88.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.501 | Acc: 51.222,67.801,88.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.610 | Acc: 21.094,53.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.919 | Acc: 20.536,50.484,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.970 | Acc: 19.226,50.229,56.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.000 | Acc: 19.237,49.821,56.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 3.673 | Acc: 55.469,67.188,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.359 | Acc: 52.269,69.048,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.320 | Acc: 51.867,69.112,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.330 | Acc: 52.075,69.185,90.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.337 | Acc: 52.064,69.068,90.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.343 | Acc: 52.088,68.967,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.372 | Acc: 52.066,68.795,89.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.400 | Acc: 51.834,68.606,89.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.410 | Acc: 51.553,68.536,89.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.422 | Acc: 51.390,68.444,89.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.426 | Acc: 51.252,68.528,89.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.430 | Acc: 51.297,68.485,89.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.442 | Acc: 51.222,68.410,89.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.441 | Acc: 51.377,68.394,89.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.444 | Acc: 51.323,68.369,89.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.457 | Acc: 51.254,68.182,88.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.455 | Acc: 51.258,68.193,88.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.458 | Acc: 51.288,68.157,88.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.463 | Acc: 51.309,68.127,88.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.467 | Acc: 51.355,68.098,88.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.092 | Acc: 38.281,61.719,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.792 | Acc: 27.195,52.009,54.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.856 | Acc: 26.429,50.343,54.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.865 | Acc: 26.217,50.269,55.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 3.237 | Acc: 55.469,64.844,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.355 | Acc: 52.939,69.754,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.404 | Acc: 52.077,69.017,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.401 | Acc: 51.614,68.827,89.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.425 | Acc: 51.418,68.451,89.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.437 | Acc: 51.207,68.472,89.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.415 | Acc: 51.479,68.705,89.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.416 | Acc: 51.479,68.551,89.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.420 | Acc: 51.461,68.425,89.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.435 | Acc: 51.338,68.297,89.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.441 | Acc: 51.279,68.233,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.441 | Acc: 51.276,68.241,89.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.441 | Acc: 51.310,68.342,89.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.434 | Acc: 51.455,68.367,88.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.435 | Acc: 51.354,68.394,88.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.454 | Acc: 51.171,68.106,88.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.453 | Acc: 51.212,68.105,88.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.455 | Acc: 51.244,68.056,88.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.459 | Acc: 51.288,68.044,88.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.460 | Acc: 51.380,68.022,88.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.195 | Acc: 28.125,49.219,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.391 | Acc: 24.219,43.787,48.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.418 | Acc: 23.876,43.807,48.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.422 | Acc: 24.091,43.648,47.989,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 3.665 | Acc: 52.344,61.719,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.290 | Acc: 51.711,68.787,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.291 | Acc: 51.848,69.950,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.325 | Acc: 51.972,69.877,90.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.345 | Acc: 51.456,69.579,90.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.356 | Acc: 51.570,69.446,90.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.361 | Acc: 51.601,69.383,89.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.372 | Acc: 51.601,69.077,89.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.394 | Acc: 51.480,68.857,89.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.407 | Acc: 51.519,68.651,89.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.413 | Acc: 51.551,68.427,89.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.415 | Acc: 51.573,68.368,89.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.419 | Acc: 51.566,68.312,89.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.420 | Acc: 51.491,68.286,89.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.427 | Acc: 51.479,68.258,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.435 | Acc: 51.417,68.272,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.445 | Acc: 51.399,68.202,88.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.450 | Acc: 51.361,68.186,88.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.461 | Acc: 51.357,68.092,88.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.464 | Acc: 51.345,68.157,88.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.115 | Acc: 39.844,51.562,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.626 | Acc: 31.548,49.926,53.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.646 | Acc: 31.421,50.057,52.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.671 | Acc: 31.698,49.718,52.228,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 2.953 | Acc: 54.688,75.000,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.365 | Acc: 52.418,69.122,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.309 | Acc: 53.049,69.360,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.272 | Acc: 53.125,69.326,90.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.311 | Acc: 52.595,69.136,90.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.315 | Acc: 52.700,69.067,90.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.322 | Acc: 52.576,68.892,90.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.340 | Acc: 52.482,68.828,90.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.363 | Acc: 52.218,68.687,89.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.368 | Acc: 52.197,68.707,89.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.388 | Acc: 51.986,68.517,89.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.387 | Acc: 51.965,68.488,89.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.395 | Acc: 51.971,68.432,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.404 | Acc: 51.901,68.316,89.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.416 | Acc: 51.807,68.216,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.426 | Acc: 51.651,68.143,89.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.437 | Acc: 51.638,68.039,88.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.443 | Acc: 51.631,68.042,88.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.447 | Acc: 51.534,68.025,88.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.453 | Acc: 51.503,67.965,88.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.286 | Acc: 29.688,46.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.634 | Acc: 27.083,47.396,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.703 | Acc: 26.601,47.485,55.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.705 | Acc: 26.857,47.157,55.815,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 3.376 | Acc: 55.469,70.312,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.289 | Acc: 53.125,70.610,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.291 | Acc: 52.992,70.141,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.329 | Acc: 52.164,69.454,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.332 | Acc: 52.276,69.300,90.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.341 | Acc: 52.174,69.253,90.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.336 | Acc: 52.189,69.318,90.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.346 | Acc: 52.388,69.227,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.349 | Acc: 52.353,69.206,90.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.362 | Acc: 52.106,69.095,89.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.380 | Acc: 51.975,68.902,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.386 | Acc: 52.001,68.838,89.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.391 | Acc: 52.033,68.769,89.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.396 | Acc: 52.006,68.750,89.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.402 | Acc: 51.996,68.639,89.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.406 | Acc: 51.960,68.555,89.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.417 | Acc: 51.881,68.482,89.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.429 | Acc: 51.785,68.411,89.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.431 | Acc: 51.686,68.365,89.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.441 | Acc: 51.714,68.291,88.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.091 | Acc: 42.188,53.906,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.544 | Acc: 35.528,52.269,47.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.567 | Acc: 35.004,52.649,47.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.588 | Acc: 35.297,52.075,47.003,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 3.580 | Acc: 43.750,67.188,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.288 | Acc: 53.571,69.829,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.286 | Acc: 52.973,70.217,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.275 | Acc: 53.624,70.581,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.319 | Acc: 52.807,70.071,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.324 | Acc: 52.692,69.972,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.328 | Acc: 52.499,69.544,90.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.334 | Acc: 52.377,69.609,90.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.341 | Acc: 52.324,69.536,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.351 | Acc: 52.292,69.423,90.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.348 | Acc: 52.313,69.457,90.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.349 | Acc: 52.323,69.397,90.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.363 | Acc: 52.149,69.201,89.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.376 | Acc: 52.041,69.031,89.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.389 | Acc: 51.874,69.009,89.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.399 | Acc: 51.749,68.882,89.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.413 | Acc: 51.711,68.728,89.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.417 | Acc: 51.723,68.736,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.430 | Acc: 51.718,68.670,89.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.434 | Acc: 51.766,68.611,89.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.894 | Acc: 30.469,53.125,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.231 | Acc: 26.525,46.652,42.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.240 | Acc: 26.105,45.960,42.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.259 | Acc: 25.986,46.491,42.021,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 3.079 | Acc: 51.562,69.531,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.300 | Acc: 52.530,69.457,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.298 | Acc: 52.572,69.588,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.322 | Acc: 52.638,70.005,89.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.319 | Acc: 52.498,70.004,89.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.341 | Acc: 52.406,69.624,89.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.359 | Acc: 52.324,69.338,89.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.376 | Acc: 52.432,68.961,89.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.383 | Acc: 52.310,68.886,89.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.398 | Acc: 52.068,68.802,89.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.391 | Acc: 52.270,68.804,89.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.400 | Acc: 52.178,68.715,89.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.406 | Acc: 52.201,68.662,89.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.424 | Acc: 52.056,68.508,89.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.427 | Acc: 51.879,68.486,88.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.439 | Acc: 51.832,68.332,88.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.448 | Acc: 51.728,68.268,88.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.451 | Acc: 51.679,68.310,88.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.458 | Acc: 51.699,68.213,88.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.466 | Acc: 51.606,68.135,88.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.469 | Acc: 33.594,53.125,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.051 | Acc: 28.646,48.028,51.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.089 | Acc: 27.973,47.713,50.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.119 | Acc: 27.984,47.464,49.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 3.406 | Acc: 57.031,67.188,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.431 | Acc: 50.967,69.010,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.325 | Acc: 51.353,69.893,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.320 | Acc: 51.755,69.467,89.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.337 | Acc: 51.968,69.541,89.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.354 | Acc: 51.740,69.353,89.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.359 | Acc: 51.614,69.525,89.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.367 | Acc: 51.596,69.448,89.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.374 | Acc: 51.825,69.260,89.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.378 | Acc: 51.847,69.255,89.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.389 | Acc: 51.866,69.154,89.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.397 | Acc: 51.813,69.072,89.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.404 | Acc: 51.770,68.983,89.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.409 | Acc: 51.709,68.974,89.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.408 | Acc: 51.685,69.028,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.413 | Acc: 51.659,69.020,88.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.423 | Acc: 51.618,68.860,88.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.429 | Acc: 51.606,68.761,88.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.435 | Acc: 51.597,68.685,88.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.443 | Acc: 51.604,68.645,88.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.312 | Acc: 32.812,53.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.975 | Acc: 27.716,49.554,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.010 | Acc: 26.391,48.742,51.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.045 | Acc: 26.524,48.630,50.640,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 3.073 | Acc: 57.812,66.406,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.234 | Acc: 54.501,69.494,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.210 | Acc: 53.830,70.274,91.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.271 | Acc: 52.997,69.903,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.271 | Acc: 52.961,69.869,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.297 | Acc: 52.870,69.701,90.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.309 | Acc: 52.692,69.383,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.323 | Acc: 52.632,69.415,90.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.342 | Acc: 52.281,69.104,90.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.352 | Acc: 52.232,69.052,90.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.375 | Acc: 51.990,68.777,89.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.385 | Acc: 51.951,68.778,89.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.384 | Acc: 52.107,68.753,89.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.394 | Acc: 52.095,68.705,89.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.402 | Acc: 52.046,68.611,89.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.407 | Acc: 52.025,68.532,89.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.421 | Acc: 51.969,68.368,89.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.423 | Acc: 51.895,68.315,89.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.429 | Acc: 51.865,68.274,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.435 | Acc: 51.807,68.280,88.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.231 | Acc: 32.812,60.938,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.050 | Acc: 26.786,51.228,40.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.102 | Acc: 26.391,50.248,39.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.115 | Acc: 26.588,50.231,39.511,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 3.181 | Acc: 46.875,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.333 | Acc: 52.641,70.052,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.279 | Acc: 52.858,70.636,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.307 | Acc: 53.061,69.903,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.289 | Acc: 53.173,70.081,89.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.302 | Acc: 52.963,69.980,89.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.316 | Acc: 52.634,69.867,89.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.331 | Acc: 52.504,69.598,89.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.340 | Acc: 52.436,69.507,89.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.360 | Acc: 52.339,69.277,89.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.368 | Acc: 52.231,69.201,89.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.365 | Acc: 52.319,69.132,89.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.374 | Acc: 52.117,69.022,89.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.381 | Acc: 52.059,68.948,89.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.397 | Acc: 51.932,68.831,89.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.402 | Acc: 51.931,68.817,89.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.404 | Acc: 51.884,68.806,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.402 | Acc: 51.860,68.844,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.415 | Acc: 51.755,68.592,89.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.421 | Acc: 51.710,68.533,88.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.890 | Acc: 32.031,55.469,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.459 | Acc: 26.897,47.135,26.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.451 | Acc: 26.620,47.504,27.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.467 | Acc: 26.947,46.965,26.972,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 3.088 | Acc: 53.125,68.750,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.280 | Acc: 53.348,69.643,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.222 | Acc: 54.345,70.351,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.250 | Acc: 54.278,70.197,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.253 | Acc: 53.983,70.149,90.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.304 | Acc: 53.388,69.748,89.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.305 | Acc: 53.403,69.802,89.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.318 | Acc: 53.092,69.686,89.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.325 | Acc: 52.975,69.657,89.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.329 | Acc: 53.026,69.544,89.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.345 | Acc: 52.709,69.387,89.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.352 | Acc: 52.715,69.340,89.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.360 | Acc: 52.590,69.246,89.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.368 | Acc: 52.604,69.193,89.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.383 | Acc: 52.441,68.947,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.384 | Acc: 52.414,68.976,89.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.395 | Acc: 52.239,68.813,89.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.400 | Acc: 52.188,68.750,89.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.407 | Acc: 52.065,68.709,88.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.408 | Acc: 52.012,68.701,88.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.328 | Acc: 45.312,53.906,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.007 | Acc: 32.440,46.205,43.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.015 | Acc: 31.822,45.827,43.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.043 | Acc: 31.404,45.402,43.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 2.953 | Acc: 61.719,71.875,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.159 | Acc: 54.390,71.577,90.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.172 | Acc: 53.659,71.399,90.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.243 | Acc: 53.087,70.389,89.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.284 | Acc: 52.865,69.840,89.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.295 | Acc: 52.645,69.771,89.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.319 | Acc: 52.531,69.415,89.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.329 | Acc: 52.405,69.204,89.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.329 | Acc: 52.353,69.284,89.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.335 | Acc: 52.443,69.182,89.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.341 | Acc: 52.453,69.127,89.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.346 | Acc: 52.425,69.149,89.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.351 | Acc: 52.379,69.048,89.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.356 | Acc: 52.523,69.109,89.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.363 | Acc: 52.408,69.086,89.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.370 | Acc: 52.313,69.007,89.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.379 | Acc: 52.203,68.974,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.390 | Acc: 52.103,68.924,88.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.391 | Acc: 52.106,68.895,88.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.399 | Acc: 52.014,68.902,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.510 | Acc: 35.156,48.438,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.889 | Acc: 28.460,49.628,43.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.925 | Acc: 28.849,49.752,43.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.935 | Acc: 29.009,49.872,43.302,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 3.300 | Acc: 50.781,66.406,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.167 | Acc: 52.790,72.842,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.269 | Acc: 52.325,71.227,90.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.310 | Acc: 52.664,70.402,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.296 | Acc: 52.942,70.033,90.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.285 | Acc: 52.939,70.220,90.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.296 | Acc: 52.931,70.035,89.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.321 | Acc: 52.560,69.686,89.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.323 | Acc: 52.683,69.657,89.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.336 | Acc: 52.590,69.462,89.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.342 | Acc: 52.390,69.329,89.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.353 | Acc: 52.312,69.181,89.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.361 | Acc: 52.204,69.149,89.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.360 | Acc: 52.227,69.100,89.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.372 | Acc: 52.119,68.933,89.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.384 | Acc: 51.965,68.789,89.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.390 | Acc: 51.925,68.784,89.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.396 | Acc: 51.853,68.764,89.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.393 | Acc: 51.969,68.778,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.400 | Acc: 51.932,68.707,88.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.276 | Acc: 29.688,57.031,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.604 | Acc: 27.567,50.781,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.642 | Acc: 27.172,50.553,55.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.660 | Acc: 27.280,50.231,55.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 2.985 | Acc: 57.812,75.781,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.294 | Acc: 53.906,69.940,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.260 | Acc: 54.554,70.503,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.308 | Acc: 53.650,69.736,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.265 | Acc: 53.897,70.245,90.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.298 | Acc: 53.280,69.701,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.295 | Acc: 53.506,69.809,90.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.303 | Acc: 53.153,69.470,90.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.297 | Acc: 53.241,69.570,90.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.311 | Acc: 53.116,69.423,89.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.323 | Acc: 52.973,69.356,89.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.337 | Acc: 52.718,69.164,89.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.353 | Acc: 52.535,69.120,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.359 | Acc: 52.472,68.980,89.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.369 | Acc: 52.313,68.967,89.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.372 | Acc: 52.248,68.986,89.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.381 | Acc: 52.200,68.889,89.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.391 | Acc: 52.174,68.741,89.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.390 | Acc: 52.184,68.819,89.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.392 | Acc: 52.155,68.826,89.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.507 | Acc: 28.125,53.906,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.030 | Acc: 22.693,50.818,50.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.044 | Acc: 22.713,50.286,49.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.066 | Acc: 22.246,50.013,49.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 2.985 | Acc: 57.031,73.438,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.211 | Acc: 53.497,71.652,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.257 | Acc: 52.363,69.931,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.282 | Acc: 52.754,70.159,90.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.293 | Acc: 52.517,70.091,90.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.296 | Acc: 52.460,69.825,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.302 | Acc: 52.596,69.783,90.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.322 | Acc: 52.416,69.648,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.337 | Acc: 52.315,69.526,89.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.343 | Acc: 52.309,69.454,89.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.341 | Acc: 52.441,69.434,89.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.348 | Acc: 52.390,69.439,89.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.356 | Acc: 52.399,69.392,89.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.363 | Acc: 52.350,69.331,89.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.368 | Acc: 52.405,69.395,89.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.377 | Acc: 52.346,69.326,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.390 | Acc: 52.234,69.198,89.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.394 | Acc: 52.193,69.172,89.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.401 | Acc: 52.134,69.055,89.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.403 | Acc: 52.133,69.047,88.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.749 | Acc: 29.688,50.781,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.375 | Acc: 23.772,44.754,40.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.381 | Acc: 23.361,44.588,40.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.384 | Acc: 23.258,44.813,40.138,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 3.250 | Acc: 53.906,75.781,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.226 | Acc: 53.757,71.354,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.352 | Acc: 51.963,69.303,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.361 | Acc: 52.139,69.390,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.358 | Acc: 51.823,69.117,90.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.377 | Acc: 51.733,69.206,90.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.375 | Acc: 51.724,69.183,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.364 | Acc: 51.873,69.332,90.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.362 | Acc: 51.912,69.187,89.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.365 | Acc: 51.947,69.143,89.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.356 | Acc: 52.041,69.259,89.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.349 | Acc: 52.153,69.372,89.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.350 | Acc: 52.143,69.372,89.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.359 | Acc: 51.991,69.331,89.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.367 | Acc: 51.868,69.281,89.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.370 | Acc: 51.941,69.251,89.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.378 | Acc: 51.803,69.161,89.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.378 | Acc: 51.853,69.142,89.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.381 | Acc: 51.861,69.090,89.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.388 | Acc: 51.751,68.974,89.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.787 | Acc: 32.812,50.000,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.160 | Acc: 29.241,46.429,43.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.191 | Acc: 29.211,45.903,42.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.207 | Acc: 29.419,45.684,42.892,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 2.917 | Acc: 60.938,70.312,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.257 | Acc: 53.497,69.978,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.251 | Acc: 53.163,70.046,90.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.231 | Acc: 53.061,70.312,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.247 | Acc: 52.913,69.956,90.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.274 | Acc: 52.599,69.701,90.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.294 | Acc: 52.531,69.609,90.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.290 | Acc: 52.748,69.620,90.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.302 | Acc: 52.664,69.575,90.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.315 | Acc: 52.827,69.475,90.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.311 | Acc: 52.787,69.562,90.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.315 | Acc: 52.761,69.567,90.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.323 | Acc: 52.567,69.496,90.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.330 | Acc: 52.452,69.441,89.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.337 | Acc: 52.360,69.423,89.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.339 | Acc: 52.403,69.443,89.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.338 | Acc: 52.463,69.444,89.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.346 | Acc: 52.431,69.394,89.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.357 | Acc: 52.452,69.265,89.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.362 | Acc: 52.366,69.205,89.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.434 | Acc: 33.594,60.156,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.867 | Acc: 31.957,55.208,42.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.885 | Acc: 32.107,55.011,41.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.902 | Acc: 31.903,54.956,41.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 3.403 | Acc: 51.562,66.406,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.258 | Acc: 53.274,70.089,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.252 | Acc: 52.954,69.646,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.239 | Acc: 53.176,69.954,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.238 | Acc: 53.009,70.129,90.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.254 | Acc: 52.916,69.972,90.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.257 | Acc: 52.686,70.074,90.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.266 | Acc: 52.809,69.908,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.276 | Acc: 52.717,69.924,90.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.286 | Acc: 52.672,69.920,90.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.295 | Acc: 52.596,69.854,90.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.295 | Acc: 52.676,69.906,90.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.303 | Acc: 52.661,69.829,90.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.317 | Acc: 52.598,69.708,89.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.326 | Acc: 52.511,69.604,89.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.324 | Acc: 52.466,69.643,89.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.328 | Acc: 52.470,69.551,89.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.336 | Acc: 52.419,69.483,89.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.341 | Acc: 52.322,69.451,89.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.357 | Acc: 52.235,69.273,89.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.776 | Acc: 35.938,52.344,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.121 | Acc: 28.943,49.330,42.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.160 | Acc: 28.087,49.447,40.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.173 | Acc: 28.138,49.603,40.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 3.407 | Acc: 54.688,64.062,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.277 | Acc: 53.348,71.243,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.257 | Acc: 53.811,70.846,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.233 | Acc: 53.612,70.799,90.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.237 | Acc: 53.530,70.910,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.220 | Acc: 53.442,71.163,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.234 | Acc: 53.351,70.687,90.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.248 | Acc: 53.203,70.623,90.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.264 | Acc: 53.091,70.507,90.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.275 | Acc: 53.043,70.330,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.289 | Acc: 52.861,70.184,90.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.296 | Acc: 52.828,70.122,90.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.302 | Acc: 52.798,70.060,89.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.316 | Acc: 52.613,69.878,89.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.324 | Acc: 52.480,69.798,89.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.331 | Acc: 52.518,69.736,89.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.336 | Acc: 52.351,69.609,89.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.342 | Acc: 52.337,69.540,89.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.357 | Acc: 52.311,69.369,89.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.359 | Acc: 52.360,69.416,89.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.046 | Acc: 47.656,58.594,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.574 | Acc: 37.500,54.241,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.591 | Acc: 36.909,54.230,48.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.619 | Acc: 36.872,53.689,47.759,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 3.189 | Acc: 52.344,66.406,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.140 | Acc: 54.129,72.693,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.130 | Acc: 54.135,72.218,91.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.164 | Acc: 53.356,71.683,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.177 | Acc: 53.482,71.537,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.194 | Acc: 53.048,71.295,90.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.212 | Acc: 52.996,70.997,90.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.223 | Acc: 52.914,70.950,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.243 | Acc: 52.645,70.841,90.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.253 | Acc: 52.616,70.641,89.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.259 | Acc: 52.604,70.608,89.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.276 | Acc: 52.517,70.415,89.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.283 | Acc: 52.525,70.316,89.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.297 | Acc: 52.455,70.139,89.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.304 | Acc: 52.438,70.037,89.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.322 | Acc: 52.357,69.856,89.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.328 | Acc: 52.346,69.770,89.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.338 | Acc: 52.314,69.644,89.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.346 | Acc: 52.223,69.585,89.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.355 | Acc: 52.081,69.523,89.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.485 | Acc: 28.906,50.000,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.925 | Acc: 25.037,45.610,56.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.952 | Acc: 24.790,45.332,55.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.968 | Acc: 25.013,45.056,55.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 3.212 | Acc: 53.125,71.875,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.196 | Acc: 53.348,71.019,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.172 | Acc: 53.735,71.704,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.220 | Acc: 53.304,70.876,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.243 | Acc: 53.077,70.602,91.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.246 | Acc: 52.785,70.707,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.253 | Acc: 52.712,70.590,90.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.269 | Acc: 52.504,70.213,90.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.269 | Acc: 52.654,70.395,90.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.282 | Acc: 52.525,70.243,90.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.286 | Acc: 52.635,70.165,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.302 | Acc: 52.577,70.037,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.305 | Acc: 52.577,69.995,90.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.315 | Acc: 52.517,69.866,89.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.319 | Acc: 52.447,69.815,89.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.331 | Acc: 52.349,69.614,89.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.346 | Acc: 52.246,69.378,89.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.353 | Acc: 52.211,69.291,89.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.358 | Acc: 52.207,69.265,89.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.359 | Acc: 52.251,69.300,89.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.806 | Acc: 27.344,52.344,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.191 | Acc: 27.865,48.475,48.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.223 | Acc: 26.772,48.495,48.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.263 | Acc: 26.562,48.489,48.207,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 3.505 | Acc: 56.250,71.094,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.159 | Acc: 54.018,72.135,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.178 | Acc: 52.954,71.818,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.222 | Acc: 52.830,70.927,90.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.215 | Acc: 52.961,70.862,91.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.202 | Acc: 53.079,70.869,90.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.229 | Acc: 53.048,70.706,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.230 | Acc: 53.042,70.678,90.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.239 | Acc: 53.004,70.594,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.253 | Acc: 52.952,70.511,90.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.269 | Acc: 52.900,70.379,90.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.272 | Acc: 52.874,70.358,90.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.289 | Acc: 52.736,70.115,90.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.283 | Acc: 52.880,70.238,90.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.296 | Acc: 52.847,70.115,90.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.300 | Acc: 52.803,70.011,89.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.310 | Acc: 52.697,69.933,89.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.318 | Acc: 52.669,69.831,89.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.327 | Acc: 52.569,69.724,89.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.328 | Acc: 52.580,69.720,89.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.034 | Acc: 32.812,61.719,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.443 | Acc: 32.031,55.655,52.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.476 | Acc: 31.002,55.240,52.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.497 | Acc: 30.430,55.020,52.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.064 | Acc: 53.906,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.203 | Acc: 54.167,70.982,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.154 | Acc: 54.021,71.456,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.162 | Acc: 54.188,71.388,90.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.190 | Acc: 53.675,70.910,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.193 | Acc: 53.782,70.885,90.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.212 | Acc: 53.616,70.745,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.202 | Acc: 53.768,70.867,90.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.228 | Acc: 53.440,70.487,90.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.244 | Acc: 53.246,70.312,90.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.263 | Acc: 53.043,70.215,90.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.269 | Acc: 53.008,70.115,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.269 | Acc: 53.119,70.144,90.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.275 | Acc: 53.161,70.094,90.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.293 | Acc: 52.928,69.895,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.295 | Acc: 52.858,69.863,90.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.298 | Acc: 52.913,69.801,90.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.306 | Acc: 52.800,69.799,89.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.307 | Acc: 52.872,69.730,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.317 | Acc: 52.735,69.628,89.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.712 | Acc: 35.156,49.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.208 | Acc: 28.460,43.638,62.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.255 | Acc: 27.992,43.598,62.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.249 | Acc: 27.946,43.673,62.884,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 3.424 | Acc: 50.781,65.625,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.205 | Acc: 53.571,70.499,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.204 | Acc: 53.449,70.179,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.203 | Acc: 53.240,70.953,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.221 | Acc: 52.951,70.727,91.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.261 | Acc: 53.055,70.312,90.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.275 | Acc: 52.809,70.345,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.282 | Acc: 52.859,70.229,90.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.287 | Acc: 53.033,70.201,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.290 | Acc: 53.013,70.187,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.290 | Acc: 52.993,70.110,90.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.288 | Acc: 53.044,70.037,90.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.292 | Acc: 53.037,70.102,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.299 | Acc: 52.969,70.043,89.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.307 | Acc: 52.939,69.987,89.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.318 | Acc: 52.852,69.817,89.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.332 | Acc: 52.770,69.687,89.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.342 | Acc: 52.729,69.586,89.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.344 | Acc: 52.770,69.525,89.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.348 | Acc: 52.701,69.505,89.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.785 | Acc: 39.062,56.250,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.239 | Acc: 34.152,51.972,34.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.311 | Acc: 32.965,50.724,34.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.331 | Acc: 32.915,50.371,33.811,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 2.967 | Acc: 58.594,70.312,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.169 | Acc: 54.353,71.689,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.174 | Acc: 54.021,71.799,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.173 | Acc: 54.034,71.990,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.187 | Acc: 53.665,71.817,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.210 | Acc: 53.326,71.612,90.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.206 | Acc: 53.596,71.559,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.232 | Acc: 53.275,71.299,90.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.249 | Acc: 53.169,70.997,90.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.250 | Acc: 53.185,70.917,90.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.268 | Acc: 53.028,70.573,90.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.273 | Acc: 53.022,70.521,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.280 | Acc: 52.973,70.355,90.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.288 | Acc: 52.829,70.292,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.288 | Acc: 52.961,70.232,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.290 | Acc: 52.949,70.139,90.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.291 | Acc: 52.916,70.142,89.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.304 | Acc: 52.768,69.980,89.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.310 | Acc: 52.725,70.005,89.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.318 | Acc: 52.649,69.917,89.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.213 | Acc: 32.031,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.526 | Acc: 29.501,49.814,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.569 | Acc: 28.144,49.276,54.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.607 | Acc: 28.074,49.360,54.342,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 3.115 | Acc: 53.125,73.438,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.179 | Acc: 53.125,70.982,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.185 | Acc: 52.896,71.189,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.182 | Acc: 52.894,71.568,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.205 | Acc: 53.038,71.200,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.209 | Acc: 53.156,71.125,91.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.226 | Acc: 53.086,70.926,91.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.230 | Acc: 53.131,70.861,90.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.230 | Acc: 53.232,70.837,90.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.225 | Acc: 53.388,70.887,90.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.243 | Acc: 53.238,70.705,90.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.249 | Acc: 53.206,70.726,90.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.254 | Acc: 53.089,70.595,90.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.261 | Acc: 53.107,70.528,90.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.270 | Acc: 52.986,70.424,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.280 | Acc: 52.860,70.312,90.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.288 | Acc: 52.835,70.257,90.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.294 | Acc: 52.772,70.161,90.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.300 | Acc: 52.790,70.144,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.301 | Acc: 52.832,70.167,89.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.718 | Acc: 34.375,50.000,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.303 | Acc: 27.455,46.838,40.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.338 | Acc: 27.077,46.456,39.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.353 | Acc: 27.190,46.235,38.883,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 3.545 | Acc: 50.000,71.875,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.256 | Acc: 54.464,71.429,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.236 | Acc: 53.963,71.589,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.214 | Acc: 53.637,71.580,90.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.223 | Acc: 53.434,71.345,90.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.239 | Acc: 53.110,70.931,90.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.243 | Acc: 53.009,70.881,90.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.254 | Acc: 52.831,70.684,90.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.267 | Acc: 52.844,70.482,90.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.274 | Acc: 52.866,70.248,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.273 | Acc: 52.900,70.250,90.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.282 | Acc: 52.902,70.107,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.286 | Acc: 52.768,70.018,90.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.292 | Acc: 52.802,69.965,90.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.296 | Acc: 52.794,69.918,90.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.303 | Acc: 52.736,69.843,90.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.312 | Acc: 52.672,69.733,89.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.318 | Acc: 52.575,69.664,89.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.322 | Acc: 52.595,69.575,89.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.320 | Acc: 52.627,69.574,89.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.236 | Acc: 28.125,59.375,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.699 | Acc: 27.530,52.493,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.751 | Acc: 26.791,51.429,54.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.793 | Acc: 26.883,50.948,54.611,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 3.307 | Acc: 50.000,70.312,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.195 | Acc: 53.051,72.359,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.184 | Acc: 53.506,71.837,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.163 | Acc: 53.227,71.888,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.158 | Acc: 53.328,71.846,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.180 | Acc: 53.450,71.527,90.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.195 | Acc: 53.493,71.391,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.208 | Acc: 53.430,71.188,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.229 | Acc: 53.144,70.963,90.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.243 | Acc: 53.116,70.813,90.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.242 | Acc: 53.222,70.794,90.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.262 | Acc: 53.058,70.546,89.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.265 | Acc: 52.963,70.526,89.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.270 | Acc: 52.969,70.408,89.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.269 | Acc: 53.061,70.440,89.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.274 | Acc: 52.951,70.292,89.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.288 | Acc: 52.818,70.132,89.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.292 | Acc: 52.738,70.157,89.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.305 | Acc: 52.662,70.029,89.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.313 | Acc: 52.610,69.964,89.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.734 | Acc: 40.625,47.656,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.044 | Acc: 32.552,49.256,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.073 | Acc: 31.822,48.876,31.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.095 | Acc: 31.660,48.412,30.353,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 3.115 | Acc: 52.344,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.289 | Acc: 52.716,70.126,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.237 | Acc: 53.182,70.389,90.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.252 | Acc: 53.074,70.441,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.242 | Acc: 53.308,70.631,90.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.241 | Acc: 53.396,70.730,90.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.246 | Acc: 53.403,70.506,90.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.239 | Acc: 53.175,70.639,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.252 | Acc: 52.950,70.642,90.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.255 | Acc: 52.853,70.623,90.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.263 | Acc: 52.767,70.530,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.273 | Acc: 52.803,70.408,90.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.282 | Acc: 52.836,70.186,89.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.294 | Acc: 52.805,70.043,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.301 | Acc: 52.814,69.976,89.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.304 | Acc: 52.793,69.967,89.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.301 | Acc: 52.840,70.033,89.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.310 | Acc: 52.726,69.978,89.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.317 | Acc: 52.755,69.927,89.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.325 | Acc: 52.811,69.909,89.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.351 | Acc: 42.188,50.781,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.770 | Acc: 32.738,48.363,50.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.806 | Acc: 32.012,47.637,50.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.828 | Acc: 32.159,47.772,49.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 3.162 | Acc: 55.469,72.656,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.210 | Acc: 54.576,70.945,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.134 | Acc: 54.249,71.608,90.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.133 | Acc: 54.047,71.491,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.144 | Acc: 53.781,71.480,91.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.193 | Acc: 53.458,71.264,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.198 | Acc: 53.422,71.042,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.205 | Acc: 53.380,70.916,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.213 | Acc: 53.314,70.895,90.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.221 | Acc: 53.233,70.740,90.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.230 | Acc: 53.179,70.643,90.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.226 | Acc: 53.312,70.673,90.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.227 | Acc: 53.394,70.591,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.238 | Acc: 53.361,70.471,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.239 | Acc: 53.381,70.566,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.251 | Acc: 53.252,70.434,90.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.263 | Acc: 53.118,70.359,90.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.278 | Acc: 53.031,70.230,90.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.282 | Acc: 52.967,70.148,89.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.293 | Acc: 52.926,70.103,89.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.612 | Acc: 27.344,49.219,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.767 | Acc: 25.186,49.144,48.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.774 | Acc: 24.962,49.295,48.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.786 | Acc: 24.962,49.539,48.566,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 3.028 | Acc: 59.375,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.301 | Acc: 52.865,70.126,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.221 | Acc: 54.002,70.903,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.242 | Acc: 53.471,70.415,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.240 | Acc: 53.636,70.197,90.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.254 | Acc: 53.419,70.065,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.267 | Acc: 53.338,69.912,90.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.258 | Acc: 53.164,70.058,90.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.264 | Acc: 53.149,70.002,90.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.263 | Acc: 53.233,70.097,90.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.273 | Acc: 53.082,70.099,89.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.286 | Acc: 52.853,69.973,89.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.282 | Acc: 52.905,69.927,89.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.286 | Acc: 53.005,69.950,89.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.283 | Acc: 52.994,70.034,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.289 | Acc: 53.073,70.017,89.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.298 | Acc: 52.916,69.955,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.303 | Acc: 52.802,69.928,89.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.309 | Acc: 52.783,69.854,89.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.310 | Acc: 52.787,69.868,89.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.670 | Acc: 24.219,46.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.919 | Acc: 21.243,39.621,46.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.947 | Acc: 20.427,39.139,45.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.992 | Acc: 19.954,38.653,44.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 3.263 | Acc: 51.562,69.531,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.279 | Acc: 52.790,71.391,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.287 | Acc: 52.992,70.998,90.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.259 | Acc: 53.496,70.914,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.239 | Acc: 53.810,71.065,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.215 | Acc: 53.682,71.156,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.221 | Acc: 53.157,71.055,90.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.233 | Acc: 53.147,70.894,90.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.231 | Acc: 53.091,71.016,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.249 | Acc: 52.905,70.761,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.263 | Acc: 52.845,70.507,90.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.264 | Acc: 52.825,70.500,90.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.255 | Acc: 52.918,70.552,90.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.260 | Acc: 52.963,70.552,90.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.269 | Acc: 52.819,70.490,90.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.269 | Acc: 52.884,70.471,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.272 | Acc: 52.896,70.454,89.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.288 | Acc: 52.774,70.246,89.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.292 | Acc: 52.712,70.206,89.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.299 | Acc: 52.791,70.177,89.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.097 | Acc: 31.250,57.812,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.588 | Acc: 27.269,53.088,49.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.624 | Acc: 26.848,53.182,48.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.653 | Acc: 26.332,53.176,48.361,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.781 | Acc: 61.719,77.344,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.264 | Acc: 54.464,71.689,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.207 | Acc: 53.830,72.104,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.185 | Acc: 53.983,71.977,90.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.213 | Acc: 53.366,71.836,90.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.223 | Acc: 53.419,71.627,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.220 | Acc: 53.674,71.591,90.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.224 | Acc: 53.751,71.382,90.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.231 | Acc: 53.659,71.220,90.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.243 | Acc: 53.630,71.003,90.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.253 | Acc: 53.580,70.942,90.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.265 | Acc: 53.341,70.747,89.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.261 | Acc: 53.258,70.724,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.258 | Acc: 53.287,70.761,89.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.265 | Acc: 53.136,70.699,89.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.271 | Acc: 53.026,70.655,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.273 | Acc: 53.045,70.597,89.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.275 | Acc: 53.049,70.558,89.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.282 | Acc: 53.086,70.473,89.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.295 | Acc: 53.033,70.327,89.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.223 | Acc: 35.938,56.250,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.534 | Acc: 29.055,51.079,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.583 | Acc: 28.411,50.534,56.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.613 | Acc: 28.087,50.487,56.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 3.156 | Acc: 57.031,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.131 | Acc: 53.460,71.168,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.157 | Acc: 53.182,71.151,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.157 | Acc: 53.189,71.196,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.148 | Acc: 53.819,71.528,91.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.130 | Acc: 54.007,71.968,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.145 | Acc: 54.048,71.649,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.180 | Acc: 53.646,71.304,91.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.192 | Acc: 53.402,71.283,90.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.208 | Acc: 53.142,71.215,90.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.209 | Acc: 53.203,71.245,90.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.220 | Acc: 53.139,71.143,90.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.236 | Acc: 53.018,70.964,90.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.248 | Acc: 52.880,70.788,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.258 | Acc: 52.875,70.618,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.266 | Acc: 52.827,70.484,90.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.265 | Acc: 52.925,70.493,90.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.261 | Acc: 52.928,70.514,89.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.275 | Acc: 52.768,70.377,89.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.281 | Acc: 52.778,70.333,89.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.026 | Acc: 35.938,58.594,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.381 | Acc: 29.985,53.162,52.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.408 | Acc: 29.783,53.182,52.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.449 | Acc: 29.700,52.997,51.665,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 3.687 | Acc: 50.781,71.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.135 | Acc: 54.315,72.284,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.141 | Acc: 54.078,71.513,91.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.162 | Acc: 53.842,71.465,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.167 | Acc: 53.598,71.383,91.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.179 | Acc: 53.605,71.403,91.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.191 | Acc: 53.435,71.132,90.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.200 | Acc: 53.590,71.049,90.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.195 | Acc: 53.814,71.162,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.207 | Acc: 53.729,71.176,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.221 | Acc: 53.766,70.950,90.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.226 | Acc: 53.684,70.885,90.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.235 | Acc: 53.579,70.766,90.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.243 | Acc: 53.568,70.741,90.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.244 | Acc: 53.556,70.724,90.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.253 | Acc: 53.462,70.601,90.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.253 | Acc: 53.514,70.600,90.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.264 | Acc: 53.462,70.420,89.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.276 | Acc: 53.333,70.282,89.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.280 | Acc: 53.328,70.288,89.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.143 | Acc: 25.781,60.156,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.531 | Acc: 25.186,55.357,55.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.597 | Acc: 23.952,53.982,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.623 | Acc: 24.039,53.932,54.316,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 3.219 | Acc: 53.906,68.750,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.150 | Acc: 54.129,72.173,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.114 | Acc: 54.173,72.485,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.120 | Acc: 53.919,72.541,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.125 | Acc: 53.935,72.357,91.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.147 | Acc: 53.860,71.952,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.166 | Acc: 53.687,71.849,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.182 | Acc: 53.507,71.615,91.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.178 | Acc: 53.673,71.628,91.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.183 | Acc: 53.803,71.616,90.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.184 | Acc: 53.891,71.545,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.212 | Acc: 53.765,71.292,90.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.220 | Acc: 53.627,71.279,90.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.236 | Acc: 53.520,71.106,90.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.237 | Acc: 53.561,71.116,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.241 | Acc: 53.509,71.044,90.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.245 | Acc: 53.497,71.050,90.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.253 | Acc: 53.464,70.901,90.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.257 | Acc: 53.467,70.836,89.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.267 | Acc: 53.412,70.671,89.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.331 | Acc: 40.625,54.688,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.778 | Acc: 33.854,46.429,50.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.814 | Acc: 32.679,45.560,50.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.832 | Acc: 32.684,45.479,50.487,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.828 | Acc: 53.906,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.104 | Acc: 54.613,72.879,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.120 | Acc: 54.611,72.732,91.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.167 | Acc: 54.649,71.542,91.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.161 | Acc: 54.244,71.807,91.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.184 | Acc: 54.185,71.581,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.202 | Acc: 54.048,71.417,90.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.216 | Acc: 53.917,71.121,90.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.217 | Acc: 53.673,71.133,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.228 | Acc: 53.578,71.038,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.218 | Acc: 53.595,71.199,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.229 | Acc: 53.556,71.104,90.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.240 | Acc: 53.414,70.919,90.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.248 | Acc: 53.391,70.830,90.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.264 | Acc: 53.261,70.599,90.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.268 | Acc: 53.226,70.580,89.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.268 | Acc: 53.232,70.558,89.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.269 | Acc: 53.246,70.562,89.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.276 | Acc: 53.270,70.520,89.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.280 | Acc: 53.213,70.464,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.493 | Acc: 39.844,57.812,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.952 | Acc: 32.031,47.731,43.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.991 | Acc: 31.460,47.428,43.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.017 | Acc: 31.301,47.503,42.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 3.292 | Acc: 45.312,67.969,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.197 | Acc: 53.981,70.685,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.142 | Acc: 54.306,71.532,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.117 | Acc: 54.124,72.118,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.147 | Acc: 53.752,71.740,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.164 | Acc: 53.589,71.682,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.161 | Acc: 53.796,71.617,91.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.161 | Acc: 53.995,71.554,90.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.175 | Acc: 54.110,71.404,90.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.170 | Acc: 54.053,71.374,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.190 | Acc: 53.848,71.117,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.194 | Acc: 53.747,71.143,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.207 | Acc: 53.566,70.870,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.217 | Acc: 53.565,70.794,90.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.208 | Acc: 53.734,70.980,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.214 | Acc: 53.686,70.808,90.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.226 | Acc: 53.702,70.678,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.238 | Acc: 53.533,70.615,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.244 | Acc: 53.493,70.602,89.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.251 | Acc: 53.353,70.548,89.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.318 | Acc: 26.562,46.094,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.665 | Acc: 25.558,44.308,42.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.701 | Acc: 24.600,43.159,41.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.718 | Acc: 24.693,43.199,41.675,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 3.327 | Acc: 51.562,74.219,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.153 | Acc: 53.088,72.247,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.163 | Acc: 52.934,71.989,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.165 | Acc: 53.279,72.029,91.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.184 | Acc: 53.520,71.576,91.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.168 | Acc: 53.674,71.736,91.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.181 | Acc: 53.461,71.546,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.174 | Acc: 53.607,71.714,91.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.180 | Acc: 53.649,71.720,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.186 | Acc: 53.751,71.603,90.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.187 | Acc: 53.646,71.580,90.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.193 | Acc: 53.655,71.451,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.201 | Acc: 53.582,71.340,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.214 | Acc: 53.403,71.148,90.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.227 | Acc: 53.245,71.038,90.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.232 | Acc: 53.242,70.959,90.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.241 | Acc: 53.239,70.855,90.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.242 | Acc: 53.260,70.835,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.253 | Acc: 53.175,70.704,89.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.261 | Acc: 53.164,70.651,89.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.306 | Acc: 39.844,53.906,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.856 | Acc: 32.068,47.582,48.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.866 | Acc: 31.993,47.275,49.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.883 | Acc: 32.262,46.952,48.386,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 3.309 | Acc: 50.000,71.094,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.144 | Acc: 54.725,72.619,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.115 | Acc: 54.478,72.389,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.144 | Acc: 54.137,72.195,91.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.125 | Acc: 54.331,72.463,91.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.141 | Acc: 54.247,72.138,90.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.153 | Acc: 54.126,72.043,90.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.175 | Acc: 54.084,71.698,90.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.181 | Acc: 54.086,71.564,90.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.202 | Acc: 53.872,71.219,90.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.204 | Acc: 53.848,71.210,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.209 | Acc: 53.754,71.154,90.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.213 | Acc: 53.683,71.097,90.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.222 | Acc: 53.616,70.965,90.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.225 | Acc: 53.531,70.960,90.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.234 | Acc: 53.400,70.847,90.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.235 | Acc: 53.344,70.782,90.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.235 | Acc: 53.363,70.899,90.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.240 | Acc: 53.370,70.849,89.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.254 | Acc: 53.252,70.675,89.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.694 | Acc: 37.500,57.812,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.182 | Acc: 30.246,48.438,38.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.192 | Acc: 29.287,48.418,39.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.210 | Acc: 29.316,48.399,38.678,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 3.341 | Acc: 54.688,69.531,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.064 | Acc: 54.911,72.805,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.106 | Acc: 54.554,72.313,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.126 | Acc: 54.662,71.837,91.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.115 | Acc: 54.504,71.807,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.102 | Acc: 54.270,72.215,91.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.096 | Acc: 54.481,72.269,91.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.103 | Acc: 54.344,72.191,91.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.112 | Acc: 54.328,72.016,91.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.113 | Acc: 54.338,72.030,91.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.131 | Acc: 54.233,71.797,90.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.141 | Acc: 54.164,71.592,90.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.160 | Acc: 54.013,71.382,90.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.181 | Acc: 53.801,71.169,90.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.195 | Acc: 53.631,71.044,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.214 | Acc: 53.405,70.819,90.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.223 | Acc: 53.344,70.692,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.236 | Acc: 53.212,70.615,90.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.242 | Acc: 53.179,70.488,89.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.244 | Acc: 53.228,70.554,89.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.340 | Acc: 39.844,55.469,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.828 | Acc: 30.841,50.260,48.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.865 | Acc: 30.373,49.714,48.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.870 | Acc: 30.610,49.565,48.233,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 3.016 | Acc: 52.344,66.406,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.023 | Acc: 53.274,72.619,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.067 | Acc: 54.897,72.332,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.091 | Acc: 54.649,72.272,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.147 | Acc: 54.176,72.213,91.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.130 | Acc: 54.223,72.486,90.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.145 | Acc: 53.732,72.353,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.170 | Acc: 53.391,71.997,91.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.185 | Acc: 53.246,71.661,90.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.190 | Acc: 53.315,71.573,90.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.197 | Acc: 53.347,71.475,90.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.192 | Acc: 53.471,71.521,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.194 | Acc: 53.627,71.431,90.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.202 | Acc: 53.568,71.375,90.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.204 | Acc: 53.592,71.361,90.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.216 | Acc: 53.530,71.252,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.219 | Acc: 53.561,71.259,90.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.224 | Acc: 53.588,71.201,90.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.235 | Acc: 53.452,71.057,90.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.246 | Acc: 53.357,70.932,89.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.468 | Acc: 32.031,52.344,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.082 | Acc: 26.935,46.057,47.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.122 | Acc: 26.867,45.675,47.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.147 | Acc: 27.113,45.517,47.182,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.669 | Acc: 56.250,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.034 | Acc: 56.771,73.661,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.054 | Acc: 55.926,72.885,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.106 | Acc: 55.238,72.208,91.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.088 | Acc: 55.073,72.492,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.089 | Acc: 54.935,72.478,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.116 | Acc: 54.965,72.230,91.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.131 | Acc: 54.765,71.803,91.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.143 | Acc: 54.683,71.661,91.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.165 | Acc: 54.567,71.517,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.173 | Acc: 54.481,71.471,90.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.185 | Acc: 54.338,71.278,90.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.191 | Acc: 54.273,71.126,90.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.193 | Acc: 54.268,71.157,90.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.217 | Acc: 53.984,70.977,90.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.228 | Acc: 53.828,70.884,90.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.234 | Acc: 53.702,70.833,90.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.234 | Acc: 53.762,70.789,90.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.239 | Acc: 53.696,70.758,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.244 | Acc: 53.681,70.673,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.181 | Acc: 28.125,60.156,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.717 | Acc: 24.479,50.744,55.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.734 | Acc: 24.104,49.733,55.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.728 | Acc: 24.475,50.115,55.699,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 2.710 | Acc: 53.906,75.781,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.059 | Acc: 56.027,73.698,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.103 | Acc: 54.954,72.771,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.058 | Acc: 55.123,73.066,91.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.077 | Acc: 55.093,73.100,91.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.077 | Acc: 55.229,72.919,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.088 | Acc: 55.204,72.637,91.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.100 | Acc: 54.920,72.490,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.128 | Acc: 54.639,72.249,91.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.145 | Acc: 54.502,71.996,90.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.156 | Acc: 54.252,71.824,90.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.168 | Acc: 54.097,71.723,90.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.181 | Acc: 53.945,71.577,90.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.186 | Acc: 53.894,71.480,90.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.187 | Acc: 53.815,71.444,90.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.209 | Acc: 53.610,71.182,90.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.218 | Acc: 53.505,71.089,90.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.225 | Acc: 53.425,70.917,90.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.236 | Acc: 53.268,70.776,89.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.240 | Acc: 53.258,70.721,89.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.194 | Acc: 31.250,55.469,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.593 | Acc: 28.646,51.488,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.669 | Acc: 28.125,49.886,56.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.685 | Acc: 28.035,50.154,55.686,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 3.366 | Acc: 53.906,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.020 | Acc: 53.943,73.177,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.066 | Acc: 54.325,72.008,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.127 | Acc: 54.060,71.721,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.141 | Acc: 53.906,71.335,90.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.152 | Acc: 53.875,71.496,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.137 | Acc: 54.100,71.649,91.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.160 | Acc: 53.834,71.454,90.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.167 | Acc: 53.872,71.380,90.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.172 | Acc: 54.014,71.310,90.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.199 | Acc: 53.770,70.915,90.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.203 | Acc: 53.687,70.800,90.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.200 | Acc: 53.666,70.922,90.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.201 | Acc: 53.840,70.989,90.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.203 | Acc: 53.878,70.946,90.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.214 | Acc: 53.701,70.886,90.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.218 | Acc: 53.712,70.906,90.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.226 | Acc: 53.657,70.830,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.231 | Acc: 53.644,70.817,90.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.239 | Acc: 53.574,70.706,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.436 | Acc: 27.344,51.562,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.981 | Acc: 23.661,47.656,47.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.991 | Acc: 23.228,47.370,47.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.993 | Acc: 23.578,47.157,47.298,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 2.962 | Acc: 54.688,73.438,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.038 | Acc: 55.915,73.065,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.057 | Acc: 55.774,72.904,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.077 | Acc: 55.546,72.669,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.077 | Acc: 55.257,72.647,91.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.114 | Acc: 54.633,72.285,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.132 | Acc: 54.223,72.185,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.139 | Acc: 53.901,72.119,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.143 | Acc: 53.969,71.967,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.159 | Acc: 53.889,71.698,90.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.160 | Acc: 53.953,71.720,90.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.170 | Acc: 53.949,71.564,90.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.186 | Acc: 53.874,71.366,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.196 | Acc: 53.733,71.252,90.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.194 | Acc: 53.659,71.238,90.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.206 | Acc: 53.600,71.216,90.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.221 | Acc: 53.468,71.111,90.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.229 | Acc: 53.466,71.025,90.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.233 | Acc: 53.495,71.007,90.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.243 | Acc: 53.410,70.825,90.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.805 | Acc: 31.250,50.000,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.058 | Acc: 26.935,46.987,42.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.104 | Acc: 25.953,47.523,42.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.098 | Acc: 25.717,47.759,42.802,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 2.946 | Acc: 56.250,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.154 | Acc: 53.274,72.098,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.110 | Acc: 53.868,72.351,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.119 | Acc: 54.009,72.272,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.113 | Acc: 53.868,72.425,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.112 | Acc: 53.806,72.099,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.127 | Acc: 53.764,71.823,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.129 | Acc: 53.928,71.858,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.136 | Acc: 53.979,71.802,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.152 | Acc: 53.919,71.780,90.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.151 | Acc: 53.984,71.731,90.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.157 | Acc: 54.034,71.666,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.160 | Acc: 54.013,71.599,90.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.177 | Acc: 53.942,71.402,90.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.182 | Acc: 53.934,71.316,90.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.185 | Acc: 53.828,71.226,90.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.198 | Acc: 53.743,71.084,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.212 | Acc: 53.574,71.007,90.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.218 | Acc: 53.512,70.925,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.232 | Acc: 53.441,70.770,90.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.451 | Acc: 31.250,47.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.812 | Acc: 28.906,46.168,55.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.855 | Acc: 28.716,46.341,54.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.891 | Acc: 28.727,45.722,54.367,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 2.643 | Acc: 57.031,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.087 | Acc: 55.208,73.214,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.043 | Acc: 55.221,73.018,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.065 | Acc: 55.225,73.053,90.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.048 | Acc: 55.083,73.177,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.069 | Acc: 54.881,72.881,90.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.095 | Acc: 54.655,72.624,90.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.099 | Acc: 54.444,72.545,90.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.110 | Acc: 54.328,72.491,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.120 | Acc: 54.152,72.488,90.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.118 | Acc: 54.136,72.435,90.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.134 | Acc: 54.069,72.296,90.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.147 | Acc: 53.874,72.196,90.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.157 | Acc: 53.760,72.091,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.168 | Acc: 53.614,71.956,90.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.187 | Acc: 53.418,71.686,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.198 | Acc: 53.500,71.551,90.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.199 | Acc: 53.469,71.531,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.215 | Acc: 53.391,71.345,90.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.226 | Acc: 53.334,71.182,89.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.236 | Acc: 36.719,50.781,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.404 | Acc: 30.766,50.446,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.404 | Acc: 30.640,51.277,51.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.438 | Acc: 30.686,51.037,51.268,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.478 | Acc: 63.281,77.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.120 | Acc: 54.204,72.470,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.069 | Acc: 54.325,72.732,91.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.127 | Acc: 53.727,71.888,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.106 | Acc: 53.800,72.309,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.106 | Acc: 53.906,72.401,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.116 | Acc: 54.139,72.359,91.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.132 | Acc: 53.834,72.257,91.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.146 | Acc: 53.562,72.055,91.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.161 | Acc: 53.764,71.728,90.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.165 | Acc: 53.673,71.646,90.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.183 | Acc: 53.429,71.415,90.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.178 | Acc: 53.449,71.512,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.177 | Acc: 53.466,71.540,90.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.187 | Acc: 53.375,71.383,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.195 | Acc: 53.320,71.281,90.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.194 | Acc: 53.500,71.286,90.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.208 | Acc: 53.382,71.153,90.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.217 | Acc: 53.365,71.059,90.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.226 | Acc: 53.361,70.960,90.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.120 | Acc: 36.719,48.438,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.470 | Acc: 31.548,44.940,26.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.512 | Acc: 30.602,44.512,27.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.529 | Acc: 30.353,44.582,26.550,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 2.960 | Acc: 58.594,71.094,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.162 | Acc: 54.427,72.470,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.138 | Acc: 53.906,72.542,91.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.164 | Acc: 53.945,72.195,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.159 | Acc: 53.935,71.914,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.131 | Acc: 53.953,72.123,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.122 | Acc: 54.010,72.191,91.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.146 | Acc: 53.895,71.803,91.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.138 | Acc: 53.838,71.870,91.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.142 | Acc: 53.958,71.828,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.161 | Acc: 53.766,71.646,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.172 | Acc: 53.507,71.585,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.177 | Acc: 53.475,71.570,90.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.183 | Acc: 53.415,71.483,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.196 | Acc: 53.278,71.336,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.207 | Acc: 53.231,71.213,90.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.209 | Acc: 53.281,71.228,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.211 | Acc: 53.345,71.204,90.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.219 | Acc: 53.261,71.128,90.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.226 | Acc: 53.191,71.077,90.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.357 | Acc: 32.812,53.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.118 | Acc: 27.679,44.754,51.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.139 | Acc: 27.134,44.398,51.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.172 | Acc: 27.139,44.198,51.409,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 3.026 | Acc: 57.812,72.656,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.092 | Acc: 54.539,72.991,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.090 | Acc: 55.373,73.056,90.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.075 | Acc: 55.187,73.066,90.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.080 | Acc: 55.112,72.878,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.111 | Acc: 54.633,72.409,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.125 | Acc: 54.526,72.282,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.134 | Acc: 54.555,72.252,90.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.144 | Acc: 54.314,71.919,90.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.167 | Acc: 54.105,71.616,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.168 | Acc: 54.000,71.681,90.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.169 | Acc: 54.104,71.681,90.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.173 | Acc: 54.068,71.499,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.181 | Acc: 53.978,71.363,90.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.188 | Acc: 53.979,71.305,90.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.191 | Acc: 53.930,71.327,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.200 | Acc: 53.853,71.271,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.209 | Acc: 53.794,71.121,90.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.225 | Acc: 53.621,70.895,90.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.231 | Acc: 53.709,70.864,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.755 | Acc: 30.469,42.969,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.068 | Acc: 30.580,36.607,45.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.090 | Acc: 30.602,36.871,46.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.107 | Acc: 30.648,36.757,46.183,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 2.853 | Acc: 56.250,72.656,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.153 | Acc: 53.571,71.429,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.054 | Acc: 54.668,72.256,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.078 | Acc: 54.444,72.528,91.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.082 | Acc: 54.408,72.492,91.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.098 | Acc: 54.015,72.455,91.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.104 | Acc: 53.771,72.592,91.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.113 | Acc: 53.840,72.363,91.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.126 | Acc: 53.940,72.166,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.121 | Acc: 54.075,72.086,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.125 | Acc: 53.930,72.011,90.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.135 | Acc: 53.846,71.854,90.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.140 | Acc: 53.871,71.846,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.150 | Acc: 53.885,71.770,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.167 | Acc: 53.681,71.539,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.172 | Acc: 53.639,71.447,90.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.182 | Acc: 53.546,71.340,90.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.186 | Acc: 53.567,71.288,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.188 | Acc: 53.543,71.291,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.196 | Acc: 53.519,71.192,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.229 | Acc: 41.406,53.906,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.949 | Acc: 33.966,48.400,42.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.946 | Acc: 33.670,47.866,41.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.977 | Acc: 33.350,47.874,41.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 2.863 | Acc: 53.906,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.191 | Acc: 52.530,71.949,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.142 | Acc: 53.544,72.599,91.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.116 | Acc: 53.740,72.733,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.119 | Acc: 53.733,72.357,91.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.139 | Acc: 54.015,72.153,91.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.121 | Acc: 54.152,72.191,91.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.133 | Acc: 54.095,72.219,91.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.129 | Acc: 54.246,72.190,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.140 | Acc: 54.170,72.030,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.141 | Acc: 54.178,71.999,90.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.146 | Acc: 54.083,71.946,90.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.166 | Acc: 53.987,71.713,90.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.171 | Acc: 53.984,71.642,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.185 | Acc: 53.856,71.514,90.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.197 | Acc: 53.813,71.395,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.201 | Acc: 53.836,71.327,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.212 | Acc: 53.718,71.247,90.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.212 | Acc: 53.698,71.256,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.212 | Acc: 53.677,71.248,90.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.242 | Acc: 32.812,54.688,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.729 | Acc: 28.348,50.074,45.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.718 | Acc: 28.601,49.428,46.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.747 | Acc: 28.637,49.180,46.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.911 | Acc: 59.375,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.139 | Acc: 53.274,72.061,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.082 | Acc: 53.944,72.409,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.103 | Acc: 54.009,72.157,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.099 | Acc: 54.128,72.261,91.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.056 | Acc: 54.332,72.749,91.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.070 | Acc: 54.190,72.734,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.088 | Acc: 54.200,72.407,91.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.104 | Acc: 54.047,72.103,91.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.119 | Acc: 53.729,71.832,90.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.120 | Acc: 53.953,71.797,90.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.130 | Acc: 53.963,71.702,90.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.141 | Acc: 53.913,71.586,90.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.157 | Acc: 53.733,71.453,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.167 | Acc: 53.614,71.394,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.175 | Acc: 53.616,71.325,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.185 | Acc: 53.544,71.172,90.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.195 | Acc: 53.517,71.030,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.204 | Acc: 53.478,70.975,90.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.211 | Acc: 53.412,70.897,89.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.914 | Acc: 28.906,61.719,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.225 | Acc: 27.232,52.344,44.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.256 | Acc: 25.915,52.115,43.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.270 | Acc: 26.012,51.895,43.391,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 3.108 | Acc: 61.719,68.750,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.118 | Acc: 53.720,72.507,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.104 | Acc: 54.230,72.523,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.092 | Acc: 54.944,72.925,91.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.110 | Acc: 54.572,72.733,91.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.113 | Acc: 54.502,72.788,91.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.111 | Acc: 54.403,72.734,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.125 | Acc: 54.388,72.490,91.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.121 | Acc: 54.552,72.375,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.119 | Acc: 54.463,72.259,91.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.130 | Acc: 54.338,72.062,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.135 | Acc: 54.267,71.978,90.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.145 | Acc: 54.146,71.911,90.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.156 | Acc: 54.152,71.803,90.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.160 | Acc: 54.070,71.769,90.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.171 | Acc: 54.015,71.574,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.173 | Acc: 54.050,71.539,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.177 | Acc: 54.060,71.536,90.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.188 | Acc: 53.859,71.388,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.194 | Acc: 53.839,71.332,90.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.177 | Acc: 33.594,53.125,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.672 | Acc: 26.153,46.726,20.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.687 | Acc: 26.391,46.818,19.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.697 | Acc: 26.883,46.952,19.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 3.321 | Acc: 52.344,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.132 | Acc: 54.539,72.731,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.126 | Acc: 53.925,72.847,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.123 | Acc: 53.855,72.797,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.144 | Acc: 53.752,72.531,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.123 | Acc: 54.007,72.571,90.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.117 | Acc: 54.152,72.566,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.136 | Acc: 54.106,72.158,90.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.137 | Acc: 54.091,72.273,91.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.141 | Acc: 54.126,72.078,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.157 | Acc: 54.035,71.824,90.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.171 | Acc: 53.832,71.539,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.177 | Acc: 53.841,71.421,90.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.182 | Acc: 53.775,71.378,90.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.190 | Acc: 53.731,71.263,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.192 | Acc: 53.730,71.237,90.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.193 | Acc: 53.719,71.208,90.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.201 | Acc: 53.728,71.151,90.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.205 | Acc: 53.789,71.105,90.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.215 | Acc: 53.675,71.016,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.739 | Acc: 37.500,62.500,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.358 | Acc: 31.845,53.088,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.384 | Acc: 31.517,53.030,52.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.385 | Acc: 31.545,53.048,52.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.938 | Acc: 60.156,74.219,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.171 | Acc: 54.948,73.214,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.174 | Acc: 54.745,72.618,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.131 | Acc: 55.264,73.258,91.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.116 | Acc: 55.257,73.486,91.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.088 | Acc: 55.229,73.453,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.092 | Acc: 54.797,73.186,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.109 | Acc: 54.660,72.944,91.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.116 | Acc: 54.527,72.690,91.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.122 | Acc: 54.398,72.544,91.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.142 | Acc: 54.244,72.256,90.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.150 | Acc: 53.998,72.147,90.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.167 | Acc: 53.803,71.946,90.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.174 | Acc: 53.793,71.860,90.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.175 | Acc: 53.815,71.789,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.173 | Acc: 53.917,71.823,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.182 | Acc: 53.845,71.729,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.186 | Acc: 53.769,71.708,90.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.191 | Acc: 53.757,71.665,90.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.196 | Acc: 53.701,71.549,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.987 | Acc: 32.812,57.812,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.526 | Acc: 29.501,51.376,51.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.519 | Acc: 28.639,51.200,51.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.538 | Acc: 28.727,50.807,51.345,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 3.135 | Acc: 53.125,71.875,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.948 | Acc: 55.804,74.516,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.947 | Acc: 55.850,74.771,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.961 | Acc: 55.661,74.424,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.999 | Acc: 55.083,73.814,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.033 | Acc: 54.641,73.484,91.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.055 | Acc: 54.339,73.244,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.070 | Acc: 54.178,72.889,91.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.080 | Acc: 54.231,72.836,91.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.092 | Acc: 54.195,72.626,91.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.104 | Acc: 54.120,72.512,90.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.121 | Acc: 53.931,72.476,90.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.133 | Acc: 53.854,72.319,90.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.151 | Acc: 53.667,72.186,90.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.161 | Acc: 53.706,72.078,90.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.170 | Acc: 53.675,72.033,90.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.176 | Acc: 53.656,71.926,90.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.182 | Acc: 53.613,71.870,90.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.188 | Acc: 53.577,71.747,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.198 | Acc: 53.582,71.643,90.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.920 | Acc: 31.250,63.281,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.447 | Acc: 29.799,55.506,50.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.461 | Acc: 29.021,56.021,50.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.484 | Acc: 29.329,56.468,50.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 2.741 | Acc: 57.031,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.982 | Acc: 55.097,73.698,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.090 | Acc: 54.211,72.694,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.117 | Acc: 54.508,72.374,90.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.106 | Acc: 54.427,72.550,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.128 | Acc: 54.247,72.308,90.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.116 | Acc: 54.552,72.495,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.128 | Acc: 54.322,72.396,90.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.137 | Acc: 54.324,72.229,90.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.147 | Acc: 54.247,72.151,90.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.156 | Acc: 54.182,72.023,90.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.167 | Acc: 53.889,71.879,90.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.165 | Acc: 53.796,71.917,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.168 | Acc: 53.763,71.824,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.176 | Acc: 53.723,71.650,90.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.185 | Acc: 53.605,71.548,90.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.188 | Acc: 53.566,71.542,90.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.188 | Acc: 53.553,71.550,90.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.193 | Acc: 53.610,71.488,90.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.198 | Acc: 53.566,71.371,90.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.998 | Acc: 30.469,53.906,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.595 | Acc: 28.348,51.637,36.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.588 | Acc: 27.934,51.543,35.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.595 | Acc: 28.522,51.627,35.259,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 2.793 | Acc: 53.125,76.562,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.010 | Acc: 55.804,73.958,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.013 | Acc: 55.126,73.514,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.022 | Acc: 55.238,73.399,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.046 | Acc: 55.006,73.013,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.072 | Acc: 54.811,72.579,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.092 | Acc: 54.571,72.411,91.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.107 | Acc: 54.327,72.279,90.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.118 | Acc: 54.309,72.142,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.133 | Acc: 54.187,72.000,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.142 | Acc: 54.089,71.894,90.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.144 | Acc: 54.140,71.861,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.152 | Acc: 54.101,71.856,90.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.151 | Acc: 54.179,71.857,90.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.161 | Acc: 54.123,71.742,90.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.172 | Acc: 54.065,71.584,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.175 | Acc: 54.096,71.624,90.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.189 | Acc: 54.021,71.428,90.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.197 | Acc: 53.887,71.332,90.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.210 | Acc: 53.855,71.182,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.518 | Acc: 39.844,57.812,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.800 | Acc: 35.156,53.757,41.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.850 | Acc: 34.623,53.468,42.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.863 | Acc: 34.465,53.599,42.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 3.103 | Acc: 53.906,75.000,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.047 | Acc: 56.324,73.996,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.095 | Acc: 55.164,73.114,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.038 | Acc: 55.482,73.412,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.020 | Acc: 55.411,73.438,91.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.018 | Acc: 55.252,73.360,91.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.034 | Acc: 55.120,73.186,91.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.043 | Acc: 55.098,73.105,91.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.065 | Acc: 54.794,72.933,91.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.075 | Acc: 54.705,72.674,91.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.078 | Acc: 54.645,72.575,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.092 | Acc: 54.606,72.455,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.104 | Acc: 54.503,72.241,91.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.112 | Acc: 54.514,72.135,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.124 | Acc: 54.337,71.975,90.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.131 | Acc: 54.272,71.937,90.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.139 | Acc: 54.252,71.836,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.142 | Acc: 54.188,71.818,90.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.153 | Acc: 54.116,71.741,90.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.158 | Acc: 54.156,71.660,90.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.193 | Acc: 26.562,65.625,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.638 | Acc: 24.888,53.237,47.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.685 | Acc: 24.638,52.706,47.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.683 | Acc: 24.782,52.626,47.157,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.527 | Acc: 60.156,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.127 | Acc: 53.051,71.354,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.062 | Acc: 53.849,72.771,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.087 | Acc: 54.086,72.195,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.100 | Acc: 53.848,71.894,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.093 | Acc: 54.061,72.200,91.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.108 | Acc: 53.945,72.107,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.113 | Acc: 54.034,72.036,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.128 | Acc: 53.940,72.001,91.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.129 | Acc: 53.954,72.030,91.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.131 | Acc: 53.856,71.898,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.136 | Acc: 53.832,71.868,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.144 | Acc: 53.841,71.791,90.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.151 | Acc: 53.793,71.758,90.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.160 | Acc: 53.723,71.661,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.172 | Acc: 53.714,71.561,90.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.177 | Acc: 53.709,71.544,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.189 | Acc: 53.723,71.435,90.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.190 | Acc: 53.783,71.494,90.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.192 | Acc: 53.806,71.475,90.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.753 | Acc: 37.500,50.781,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.040 | Acc: 31.585,46.168,45.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.033 | Acc: 31.383,46.570,45.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.050 | Acc: 31.276,47.195,45.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 2.959 | Acc: 53.906,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.000 | Acc: 54.725,73.363,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.004 | Acc: 54.821,73.476,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.072 | Acc: 54.457,72.976,92.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.058 | Acc: 54.562,73.090,91.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.066 | Acc: 54.463,72.981,91.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.062 | Acc: 54.558,72.889,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.077 | Acc: 54.494,72.867,91.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.109 | Acc: 54.115,72.467,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.133 | Acc: 53.837,72.117,91.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.140 | Acc: 53.817,72.007,90.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.142 | Acc: 53.973,71.949,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.145 | Acc: 53.845,71.927,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.150 | Acc: 53.840,71.854,90.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.156 | Acc: 53.856,71.775,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.163 | Acc: 53.792,71.602,90.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.163 | Acc: 53.845,71.583,90.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.172 | Acc: 53.773,71.502,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.177 | Acc: 53.683,71.511,90.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.190 | Acc: 53.597,71.280,90.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.872 | Acc: 37.500,55.469,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.180 | Acc: 28.460,49.479,48.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.175 | Acc: 27.420,49.104,48.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.207 | Acc: 27.728,48.809,47.951,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 2.704 | Acc: 63.281,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.035 | Acc: 54.836,73.735,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.065 | Acc: 54.573,73.495,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.029 | Acc: 54.713,73.566,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.013 | Acc: 54.813,73.679,91.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.033 | Acc: 54.734,73.236,91.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.038 | Acc: 54.797,73.140,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.059 | Acc: 54.615,72.900,91.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.064 | Acc: 54.542,72.923,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.084 | Acc: 54.506,72.682,91.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.093 | Acc: 54.505,72.641,91.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.106 | Acc: 54.532,72.494,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.109 | Acc: 54.441,72.536,91.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.120 | Acc: 54.367,72.336,91.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.134 | Acc: 54.170,72.253,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.138 | Acc: 54.207,72.085,90.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.142 | Acc: 54.169,71.985,90.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.150 | Acc: 54.167,71.884,90.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.156 | Acc: 54.086,71.825,90.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.164 | Acc: 54.011,71.658,90.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.486 | Acc: 35.938,59.375,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.002 | Acc: 35.677,52.716,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.013 | Acc: 35.099,52.325,56.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.033 | Acc: 35.169,52.472,56.276,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 2.849 | Acc: 56.250,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.899 | Acc: 56.510,75.000,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.007 | Acc: 55.202,73.895,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.027 | Acc: 55.289,73.553,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.048 | Acc: 55.141,73.235,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.040 | Acc: 55.252,73.345,91.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.063 | Acc: 55.139,73.160,91.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.057 | Acc: 55.319,73.216,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.063 | Acc: 55.037,73.166,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.081 | Acc: 54.955,73.058,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.089 | Acc: 54.862,72.858,90.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.105 | Acc: 54.663,72.670,90.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.109 | Acc: 54.587,72.595,90.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.117 | Acc: 54.514,72.432,90.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.126 | Acc: 54.446,72.362,90.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.139 | Acc: 54.270,72.212,90.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.150 | Acc: 54.137,72.172,90.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.157 | Acc: 54.126,72.031,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.169 | Acc: 54.038,71.916,90.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.172 | Acc: 54.029,71.828,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.789 | Acc: 30.469,51.562,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.966 | Acc: 32.626,50.223,43.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.023 | Acc: 32.527,49.543,42.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.045 | Acc: 32.736,50.038,42.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 3.141 | Acc: 52.344,68.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.977 | Acc: 56.436,74.777,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.989 | Acc: 55.850,74.390,91.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.040 | Acc: 55.405,73.899,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.061 | Acc: 54.823,73.563,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.075 | Acc: 54.804,73.368,91.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.086 | Acc: 54.533,72.979,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.092 | Acc: 54.399,72.967,91.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.102 | Acc: 54.202,72.807,90.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.121 | Acc: 53.962,72.674,90.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.119 | Acc: 53.996,72.699,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.121 | Acc: 54.005,72.692,90.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.129 | Acc: 53.978,72.510,90.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.139 | Acc: 53.748,72.351,90.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.143 | Acc: 53.742,72.275,90.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.148 | Acc: 53.730,72.186,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.152 | Acc: 53.743,72.082,90.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.151 | Acc: 53.764,72.038,90.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.159 | Acc: 53.703,71.990,90.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.162 | Acc: 53.697,71.928,90.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.799 | Acc: 44.531,50.000,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.140 | Acc: 34.152,45.536,43.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.184 | Acc: 33.098,45.655,42.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.199 | Acc: 33.210,45.850,42.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 3.345 | Acc: 56.250,63.281,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.174 | Acc: 54.501,71.503,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.120 | Acc: 54.821,71.932,90.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.099 | Acc: 54.534,72.118,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.098 | Acc: 54.716,72.039,91.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.104 | Acc: 54.873,72.076,91.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.099 | Acc: 54.842,71.991,91.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.100 | Acc: 54.710,72.047,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.114 | Acc: 54.552,71.933,91.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.131 | Acc: 54.454,71.771,91.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.132 | Acc: 54.485,71.673,90.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.142 | Acc: 54.231,71.536,90.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.151 | Acc: 54.123,71.450,90.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.154 | Acc: 53.948,71.447,90.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.162 | Acc: 53.859,71.377,90.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.167 | Acc: 53.808,71.351,90.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.174 | Acc: 53.750,71.374,90.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.175 | Acc: 53.778,71.371,90.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.180 | Acc: 53.792,71.308,90.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.186 | Acc: 53.783,71.284,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.439 | Acc: 37.500,58.594,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.638 | Acc: 32.292,54.241,40.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.653 | Acc: 31.993,53.601,39.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.675 | Acc: 31.903,54.226,39.498,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 3.122 | Acc: 58.594,75.000,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.050 | Acc: 55.246,72.656,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.018 | Acc: 55.755,73.266,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.076 | Acc: 54.713,72.772,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.078 | Acc: 54.485,72.569,91.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.078 | Acc: 54.363,72.556,91.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.071 | Acc: 54.526,72.682,91.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.079 | Acc: 54.438,72.496,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.078 | Acc: 54.736,72.583,90.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.108 | Acc: 54.351,72.112,90.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.122 | Acc: 54.112,72.065,90.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.127 | Acc: 54.118,71.917,90.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.145 | Acc: 54.033,71.732,90.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.160 | Acc: 54.098,71.615,90.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.162 | Acc: 54.168,71.655,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.164 | Acc: 54.104,71.675,90.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.166 | Acc: 54.052,71.610,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.170 | Acc: 54.067,71.614,90.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.178 | Acc: 54.021,71.470,90.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.185 | Acc: 53.982,71.432,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.020 | Acc: 28.906,57.031,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.506 | Acc: 24.591,49.442,38.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.541 | Acc: 23.800,49.295,37.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.583 | Acc: 24.193,49.155,37.359,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 3.166 | Acc: 51.562,69.531,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.066 | Acc: 54.799,72.917,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.044 | Acc: 54.764,73.056,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.045 | Acc: 55.046,73.028,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.076 | Acc: 54.919,72.676,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.087 | Acc: 54.525,72.772,91.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.097 | Acc: 54.287,72.598,91.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.096 | Acc: 54.460,72.435,91.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.106 | Acc: 54.498,72.278,91.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.119 | Acc: 54.338,72.143,91.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.134 | Acc: 54.248,71.789,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.136 | Acc: 54.412,71.751,90.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.137 | Acc: 54.418,71.710,90.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.134 | Acc: 54.424,71.758,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.142 | Acc: 54.382,71.742,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.150 | Acc: 54.327,71.678,90.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.154 | Acc: 54.254,71.675,90.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.159 | Acc: 54.151,71.648,90.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.168 | Acc: 54.025,71.492,90.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.173 | Acc: 54.037,71.459,90.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.370 | Acc: 32.812,57.031,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.803 | Acc: 30.729,51.004,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.832 | Acc: 30.373,50.857,51.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.853 | Acc: 30.353,50.640,50.525,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 2.859 | Acc: 58.594,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.113 | Acc: 54.688,72.693,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.045 | Acc: 55.393,73.819,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.051 | Acc: 54.764,73.463,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.043 | Acc: 54.774,73.322,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.041 | Acc: 54.935,73.244,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.060 | Acc: 54.700,72.902,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.075 | Acc: 54.538,72.667,91.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.082 | Acc: 54.455,72.588,91.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.086 | Acc: 54.679,72.514,91.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.095 | Acc: 54.548,72.388,91.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.113 | Acc: 54.295,72.193,91.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.126 | Acc: 54.253,72.076,90.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.129 | Acc: 54.301,72.117,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.133 | Acc: 54.315,72.033,90.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.141 | Acc: 54.285,71.932,90.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.148 | Acc: 54.335,71.831,90.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.150 | Acc: 54.339,71.802,90.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.156 | Acc: 54.283,71.760,90.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.163 | Acc: 54.179,71.717,90.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.566 | Acc: 38.281,61.719,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.127 | Acc: 31.436,54.501,27.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.167 | Acc: 31.250,53.754,26.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.189 | Acc: 31.199,53.535,26.691,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 3.402 | Acc: 50.000,64.844,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.117 | Acc: 53.832,72.582,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.082 | Acc: 54.040,73.075,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.114 | Acc: 53.650,72.848,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.109 | Acc: 53.598,72.888,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.123 | Acc: 53.489,72.293,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.138 | Acc: 53.338,72.198,90.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.126 | Acc: 53.640,72.246,90.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.132 | Acc: 53.596,72.205,90.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.138 | Acc: 53.621,71.996,90.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.145 | Acc: 53.821,71.910,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.144 | Acc: 53.818,71.889,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.138 | Acc: 53.958,71.856,90.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.145 | Acc: 53.909,71.695,90.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.153 | Acc: 53.890,71.544,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.159 | Acc: 53.813,71.475,90.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.155 | Acc: 53.809,71.539,90.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.167 | Acc: 53.750,71.378,90.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.168 | Acc: 53.789,71.397,90.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.174 | Acc: 53.818,71.338,90.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.034 | Acc: 33.594,57.031,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.673 | Acc: 25.967,54.204,41.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.720 | Acc: 26.029,53.468,41.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.723 | Acc: 25.909,53.151,41.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 2.818 | Acc: 57.031,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.049 | Acc: 53.609,73.028,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.027 | Acc: 54.097,73.361,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.023 | Acc: 54.252,73.284,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.034 | Acc: 54.533,73.167,91.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.058 | Acc: 54.479,72.904,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.067 | Acc: 54.533,72.921,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.076 | Acc: 54.532,72.695,91.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.093 | Acc: 54.387,72.574,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.089 | Acc: 54.463,72.665,91.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.096 | Acc: 54.423,72.477,91.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.113 | Acc: 54.161,72.299,91.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.116 | Acc: 54.140,72.228,91.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.117 | Acc: 54.224,72.183,90.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.118 | Acc: 54.187,72.175,90.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.130 | Acc: 54.057,72.119,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.126 | Acc: 54.167,72.131,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.132 | Acc: 54.177,72.111,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.142 | Acc: 54.129,72.022,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.146 | Acc: 54.134,71.945,90.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.224 | Acc: 33.594,50.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.800 | Acc: 30.543,44.829,48.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.826 | Acc: 30.393,44.779,48.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.843 | Acc: 30.418,44.403,48.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 2.527 | Acc: 61.719,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.992 | Acc: 55.804,74.442,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.959 | Acc: 56.021,73.761,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.979 | Acc: 55.840,73.668,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.023 | Acc: 55.170,73.235,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.041 | Acc: 54.734,72.966,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.047 | Acc: 54.584,72.902,92.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.057 | Acc: 54.422,72.789,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.058 | Acc: 54.489,72.826,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.076 | Acc: 54.472,72.639,91.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.077 | Acc: 54.625,72.687,91.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.086 | Acc: 54.415,72.607,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.096 | Acc: 54.347,72.459,91.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.102 | Acc: 54.280,72.432,91.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.111 | Acc: 54.270,72.359,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.122 | Acc: 54.220,72.241,90.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.132 | Acc: 54.184,72.160,90.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.140 | Acc: 54.039,72.072,90.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.147 | Acc: 53.971,72.011,90.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.161 | Acc: 53.818,71.848,90.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.080 | Acc: 34.375,57.031,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.493 | Acc: 31.362,51.823,51.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.509 | Acc: 30.640,51.601,50.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.518 | Acc: 30.289,51.460,51.332,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 3.285 | Acc: 49.219,65.625,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.047 | Acc: 55.543,73.549,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.067 | Acc: 54.516,73.075,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.032 | Acc: 55.097,72.989,91.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.053 | Acc: 55.122,72.840,91.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.059 | Acc: 55.198,72.749,91.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.057 | Acc: 55.139,72.785,91.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.060 | Acc: 55.064,72.850,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.053 | Acc: 55.081,72.928,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.073 | Acc: 54.994,72.855,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.074 | Acc: 55.010,72.827,91.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.082 | Acc: 54.963,72.656,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.096 | Acc: 54.882,72.491,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.101 | Acc: 54.789,72.333,90.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.115 | Acc: 54.604,72.228,90.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.127 | Acc: 54.568,72.070,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.136 | Acc: 54.597,72.006,90.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.142 | Acc: 54.555,71.928,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.151 | Acc: 54.421,71.799,90.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.162 | Acc: 54.290,71.666,90.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.404 | Acc: 30.469,64.062,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.769 | Acc: 27.604,53.348,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.792 | Acc: 26.734,53.335,53.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.821 | Acc: 26.460,53.304,53.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 2.765 | Acc: 60.156,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.005 | Acc: 55.208,73.400,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.051 | Acc: 55.221,73.018,91.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.019 | Acc: 55.289,73.502,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.040 | Acc: 55.228,72.946,91.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.043 | Acc: 55.360,72.989,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.038 | Acc: 55.385,73.050,91.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.058 | Acc: 55.164,72.878,91.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.065 | Acc: 55.042,72.744,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.076 | Acc: 55.167,72.674,91.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.090 | Acc: 55.065,72.676,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.100 | Acc: 55.037,72.536,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.108 | Acc: 54.976,72.475,90.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.122 | Acc: 54.825,72.333,90.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.130 | Acc: 54.701,72.195,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.135 | Acc: 54.547,72.179,90.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.136 | Acc: 54.520,72.128,90.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.147 | Acc: 54.383,72.022,90.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.157 | Acc: 54.289,71.914,90.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.162 | Acc: 54.281,71.857,90.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.060 | Acc: 28.125,56.250,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.693 | Acc: 25.484,50.558,52.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.726 | Acc: 25.171,51.124,52.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.742 | Acc: 25.512,51.127,52.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 2.838 | Acc: 62.500,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.967 | Acc: 56.808,73.549,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.996 | Acc: 55.488,73.438,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.010 | Acc: 55.802,73.540,91.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.010 | Acc: 55.285,73.360,91.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.997 | Acc: 55.345,73.515,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.005 | Acc: 55.365,73.386,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.017 | Acc: 55.253,73.083,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.033 | Acc: 55.022,72.768,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.036 | Acc: 55.003,72.790,91.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.056 | Acc: 54.812,72.528,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.070 | Acc: 54.642,72.366,91.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.084 | Acc: 54.506,72.209,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.092 | Acc: 54.472,72.120,90.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.095 | Acc: 54.437,72.198,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.094 | Acc: 54.553,72.303,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.102 | Acc: 54.439,72.201,90.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.118 | Acc: 54.337,72.054,90.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.123 | Acc: 54.378,71.985,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.127 | Acc: 54.380,72.019,90.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.660 | Acc: 33.594,53.125,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.997 | Acc: 27.195,48.140,47.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.046 | Acc: 25.819,48.171,46.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.057 | Acc: 25.832,48.117,46.875,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 2.592 | Acc: 56.250,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.029 | Acc: 54.948,73.996,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.012 | Acc: 54.707,74.409,91.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.041 | Acc: 54.649,74.103,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.083 | Acc: 54.167,73.274,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.083 | Acc: 54.270,73.175,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.098 | Acc: 54.100,72.998,90.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.099 | Acc: 54.333,72.800,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.101 | Acc: 54.120,72.676,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.106 | Acc: 54.062,72.557,90.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.111 | Acc: 54.015,72.555,90.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.133 | Acc: 53.942,72.243,90.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.134 | Acc: 53.893,72.164,90.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.139 | Acc: 53.930,72.135,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.150 | Acc: 53.873,72.042,90.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.149 | Acc: 53.924,71.976,90.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.145 | Acc: 54.028,71.953,90.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.151 | Acc: 53.993,71.877,90.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.158 | Acc: 53.965,71.814,90.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.162 | Acc: 53.970,71.793,90.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.935 | Acc: 28.125,59.375,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.551 | Acc: 27.716,48.363,38.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.569 | Acc: 27.210,48.457,38.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.606 | Acc: 26.985,48.028,38.486,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 3.143 | Acc: 44.531,70.312,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.867 | Acc: 56.027,75.781,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.943 | Acc: 55.297,74.962,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.978 | Acc: 55.033,74.641,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.997 | Acc: 54.900,74.171,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.982 | Acc: 55.237,74.219,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.002 | Acc: 55.191,73.857,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.024 | Acc: 54.998,73.598,91.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.047 | Acc: 54.877,73.311,91.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.050 | Acc: 54.890,73.291,91.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.062 | Acc: 54.820,73.220,91.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.075 | Acc: 54.758,73.066,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.088 | Acc: 54.636,72.899,90.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.096 | Acc: 54.562,72.818,90.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.104 | Acc: 54.476,72.670,90.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.116 | Acc: 54.335,72.532,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.125 | Acc: 54.308,72.362,90.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.135 | Acc: 54.158,72.253,90.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.142 | Acc: 54.120,72.159,90.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.148 | Acc: 54.033,72.133,90.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.246 | Acc: 40.625,52.344,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.586 | Acc: 36.347,46.875,51.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.617 | Acc: 35.842,46.856,50.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.649 | Acc: 36.181,46.798,49.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.507 | Acc: 68.750,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.988 | Acc: 55.060,73.251,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.048 | Acc: 54.173,73.304,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.045 | Acc: 54.803,73.233,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.030 | Acc: 54.909,73.553,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.049 | Acc: 54.819,73.151,91.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.069 | Acc: 54.778,72.831,91.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.091 | Acc: 54.688,72.662,91.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.105 | Acc: 54.586,72.554,91.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.126 | Acc: 54.381,72.173,91.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.134 | Acc: 54.171,72.167,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.133 | Acc: 54.281,72.112,91.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.126 | Acc: 54.321,72.232,91.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.125 | Acc: 54.367,72.222,91.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.127 | Acc: 54.390,72.178,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.131 | Acc: 54.384,72.186,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.145 | Acc: 54.225,72.009,90.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.151 | Acc: 54.149,71.919,90.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.159 | Acc: 54.097,71.860,90.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.156 | Acc: 54.189,71.805,90.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.712 | Acc: 32.031,54.688,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.134 | Acc: 28.162,49.033,43.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.177 | Acc: 28.220,48.323,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.201 | Acc: 28.125,48.527,42.969,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.858 | Acc: 58.594,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.108 | Acc: 53.385,73.847,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.066 | Acc: 54.116,73.552,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.053 | Acc: 54.278,73.514,91.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.052 | Acc: 54.263,73.505,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.057 | Acc: 53.984,73.260,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.053 | Acc: 54.190,73.102,91.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.050 | Acc: 54.322,73.116,91.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.056 | Acc: 54.246,72.986,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.057 | Acc: 54.312,72.984,91.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.054 | Acc: 54.443,73.053,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.057 | Acc: 54.401,73.045,91.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.082 | Acc: 54.263,72.760,91.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.087 | Acc: 54.349,72.686,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.089 | Acc: 54.423,72.634,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.100 | Acc: 54.428,72.462,90.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.114 | Acc: 54.249,72.337,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.130 | Acc: 54.110,72.180,90.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.128 | Acc: 54.136,72.124,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.136 | Acc: 54.136,72.035,90.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.646 | Acc: 43.750,52.344,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.138 | Acc: 33.743,46.057,32.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.173 | Acc: 33.403,45.979,32.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.188 | Acc: 33.081,46.055,31.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 2.704 | Acc: 61.719,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.952 | Acc: 57.106,74.442,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.004 | Acc: 56.040,74.314,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 55.418,73.770,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.033 | Acc: 55.150,73.322,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.039 | Acc: 55.105,73.252,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.048 | Acc: 55.107,73.153,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.058 | Acc: 54.965,72.911,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.059 | Acc: 55.051,73.010,91.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.075 | Acc: 54.813,72.764,91.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.091 | Acc: 54.598,72.664,91.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.091 | Acc: 54.631,72.639,91.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.107 | Acc: 54.496,72.488,91.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.108 | Acc: 54.493,72.495,91.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.121 | Acc: 54.390,72.353,90.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.128 | Acc: 54.480,72.264,90.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.130 | Acc: 54.488,72.150,90.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.141 | Acc: 54.431,72.010,90.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.145 | Acc: 54.313,71.886,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.156 | Acc: 54.257,71.799,90.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.796 | Acc: 37.500,60.156,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.395 | Acc: 30.469,50.372,39.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.417 | Acc: 29.440,50.495,39.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.442 | Acc: 29.649,50.320,38.909,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 3.380 | Acc: 50.000,67.969,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.010 | Acc: 55.841,72.284,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.950 | Acc: 56.784,73.590,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.964 | Acc: 56.109,73.630,91.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.971 | Acc: 55.951,73.640,91.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.990 | Acc: 56.041,73.399,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.002 | Acc: 55.798,73.102,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.020 | Acc: 55.668,72.883,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.034 | Acc: 55.561,72.729,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.059 | Acc: 55.240,72.514,91.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.070 | Acc: 55.127,72.439,91.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.074 | Acc: 55.112,72.426,91.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.073 | Acc: 55.093,72.523,90.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.088 | Acc: 54.879,72.342,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.105 | Acc: 54.612,72.184,90.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.117 | Acc: 54.560,72.090,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.119 | Acc: 54.573,72.058,90.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.123 | Acc: 54.495,72.049,90.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.137 | Acc: 54.426,71.843,90.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.146 | Acc: 54.409,71.811,90.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.420 | Acc: 32.031,64.062,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.095 | Acc: 26.302,55.432,36.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.111 | Acc: 26.372,55.469,36.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.134 | Acc: 26.383,55.456,36.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 2.360 | Acc: 60.938,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.977 | Acc: 56.064,74.144,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.010 | Acc: 55.640,73.819,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.060 | Acc: 55.008,73.233,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.077 | Acc: 54.919,72.946,91.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.082 | Acc: 54.765,72.904,91.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.082 | Acc: 54.965,72.676,91.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.088 | Acc: 54.820,72.601,91.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.094 | Acc: 54.678,72.613,91.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.089 | Acc: 54.679,72.686,91.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.082 | Acc: 54.839,72.781,91.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.085 | Acc: 54.702,72.702,91.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.096 | Acc: 54.597,72.653,90.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.107 | Acc: 54.511,72.435,90.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.105 | Acc: 54.551,72.414,90.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.115 | Acc: 54.456,72.192,90.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.124 | Acc: 54.376,72.123,90.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.131 | Acc: 54.351,72.097,90.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.140 | Acc: 54.272,71.968,90.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.143 | Acc: 54.304,71.916,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.117 | Acc: 30.469,56.250,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.562 | Acc: 23.289,50.037,38.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.605 | Acc: 22.866,48.495,38.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.622 | Acc: 22.746,48.642,38.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 2.817 | Acc: 58.594,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.937 | Acc: 56.473,74.293,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.906 | Acc: 56.822,74.829,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.938 | Acc: 56.634,74.577,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.960 | Acc: 56.134,74.190,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.983 | Acc: 55.600,73.600,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.015 | Acc: 55.236,73.425,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.029 | Acc: 55.120,73.160,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.048 | Acc: 54.872,72.991,91.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.052 | Acc: 54.998,72.941,91.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.061 | Acc: 55.026,72.932,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.066 | Acc: 54.914,72.833,91.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.076 | Acc: 54.733,72.689,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.081 | Acc: 54.673,72.635,91.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.089 | Acc: 54.601,72.562,91.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.096 | Acc: 54.620,72.524,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.099 | Acc: 54.675,72.471,90.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.109 | Acc: 54.550,72.358,90.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.115 | Acc: 54.462,72.338,90.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.117 | Acc: 54.489,72.365,90.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.353 | Acc: 32.031,60.156,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.000 | Acc: 29.204,49.814,46.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.008 | Acc: 27.934,49.790,46.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.016 | Acc: 28.445,49.872,46.222,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 3.220 | Acc: 46.094,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.022 | Acc: 55.543,74.405,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.993 | Acc: 55.412,74.752,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.979 | Acc: 55.046,74.590,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.970 | Acc: 54.986,74.489,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.972 | Acc: 55.314,74.234,92.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.996 | Acc: 55.094,73.773,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.007 | Acc: 55.037,73.665,91.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.018 | Acc: 55.008,73.462,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.021 | Acc: 55.046,73.394,91.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.031 | Acc: 54.944,73.197,91.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.050 | Acc: 54.762,72.936,91.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.066 | Acc: 54.597,72.744,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.069 | Acc: 54.619,72.740,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.069 | Acc: 54.685,72.712,91.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.078 | Acc: 54.643,72.550,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.086 | Acc: 54.666,72.496,90.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.094 | Acc: 54.594,72.420,90.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.098 | Acc: 54.588,72.427,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.105 | Acc: 54.571,72.353,90.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.798 | Acc: 21.875,53.906,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.397 | Acc: 22.545,45.871,20.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.419 | Acc: 22.104,44.970,20.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.453 | Acc: 22.221,44.582,19.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 3.202 | Acc: 53.906,70.312,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.806 | Acc: 56.957,76.525,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.852 | Acc: 56.174,75.495,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.805 | Acc: 56.929,75.269,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.784 | Acc: 57.118,75.627,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.743 | Acc: 57.387,76.354,94.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.704 | Acc: 57.658,76.943,94.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.682 | Acc: 57.624,77.333,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.651 | Acc: 58.016,77.567,94.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.638 | Acc: 57.964,77.823,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.610 | Acc: 58.279,78.106,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.595 | Acc: 58.435,78.189,95.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.584 | Acc: 58.496,78.371,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.570 | Acc: 58.567,78.637,95.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.562 | Acc: 58.496,78.692,95.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.552 | Acc: 58.620,78.766,95.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.547 | Acc: 58.606,78.855,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.540 | Acc: 58.662,78.954,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.535 | Acc: 58.702,79.047,95.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.528 | Acc: 58.717,79.156,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.374 | Acc: 41.406,68.750,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.870 | Acc: 38.430,61.868,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.903 | Acc: 37.748,62.900,54.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.924 | Acc: 37.961,62.987,53.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 2.424 | Acc: 63.281,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.265 | Acc: 60.863,81.771,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.269 | Acc: 61.395,82.050,97.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.282 | Acc: 61.027,81.788,97.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.314 | Acc: 60.436,81.501,97.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.318 | Acc: 60.149,81.629,97.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.326 | Acc: 60.059,81.541,97.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.328 | Acc: 60.045,81.710,97.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.325 | Acc: 60.011,81.891,97.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.324 | Acc: 60.074,81.824,97.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.319 | Acc: 60.094,81.930,97.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.319 | Acc: 60.050,81.918,97.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.320 | Acc: 60.069,81.840,97.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.329 | Acc: 59.947,81.813,97.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.329 | Acc: 59.939,81.878,97.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.325 | Acc: 60.050,81.896,97.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.327 | Acc: 60.091,81.815,97.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.324 | Acc: 60.110,81.953,97.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.322 | Acc: 60.156,81.973,97.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.322 | Acc: 60.130,81.996,97.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.801 | Acc: 43.750,69.531,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.332 | Acc: 38.839,61.682,45.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.364 | Acc: 37.614,61.890,45.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.395 | Acc: 37.590,61.975,44.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 2.191 | Acc: 65.625,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.353 | Acc: 59.598,82.254,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.305 | Acc: 60.175,82.431,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.295 | Acc: 60.182,82.825,98.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.284 | Acc: 60.224,82.841,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.265 | Acc: 60.288,82.696,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.265 | Acc: 60.253,82.748,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.262 | Acc: 60.306,82.840,98.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.256 | Acc: 60.433,82.817,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.252 | Acc: 60.627,82.895,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.247 | Acc: 60.790,82.984,98.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.243 | Acc: 60.899,83.081,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.240 | Acc: 60.934,83.218,98.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.238 | Acc: 60.946,83.333,98.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.239 | Acc: 60.999,83.332,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.237 | Acc: 61.023,83.298,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.236 | Acc: 61.013,83.338,98.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.240 | Acc: 60.990,83.321,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.239 | Acc: 60.963,83.302,98.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.239 | Acc: 60.974,83.309,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.593 | Acc: 39.062,70.312,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.082 | Acc: 37.240,61.049,56.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.109 | Acc: 36.547,61.528,55.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.140 | Acc: 36.437,61.693,55.213,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 2.314 | Acc: 60.156,82.031,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.065 | Acc: 63.132,84.859,98.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.116 | Acc: 62.538,85.080,98.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.145 | Acc: 62.180,84.644,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.164 | Acc: 61.844,84.356,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.175 | Acc: 61.897,84.352,98.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.178 | Acc: 61.777,84.278,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.174 | Acc: 61.846,84.253,98.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.174 | Acc: 61.767,84.254,98.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.170 | Acc: 61.840,84.284,98.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.171 | Acc: 61.909,84.200,98.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.166 | Acc: 61.828,84.244,98.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.161 | Acc: 61.946,84.287,98.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.163 | Acc: 61.862,84.294,98.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.169 | Acc: 61.730,84.147,98.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.178 | Acc: 61.690,84.045,98.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.181 | Acc: 61.680,84.029,98.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.179 | Acc: 61.730,84.045,98.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.184 | Acc: 61.649,84.027,98.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.186 | Acc: 61.575,84.012,98.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.577 | Acc: 43.750,70.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.122 | Acc: 40.997,60.938,49.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.143 | Acc: 40.111,61.376,49.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.177 | Acc: 40.010,61.437,49.052,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 2.217 | Acc: 59.375,88.281,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.073 | Acc: 61.607,86.272,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.113 | Acc: 61.986,85.556,98.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.128 | Acc: 61.360,85.054,98.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.133 | Acc: 61.294,84.934,98.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.154 | Acc: 61.425,84.731,98.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.152 | Acc: 61.661,84.795,98.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.150 | Acc: 61.569,84.696,98.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.160 | Acc: 61.515,84.661,98.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.164 | Acc: 61.313,84.513,98.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.163 | Acc: 61.311,84.585,98.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.169 | Acc: 61.287,84.527,98.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.169 | Acc: 61.330,84.443,98.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.171 | Acc: 61.189,84.429,98.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.169 | Acc: 61.229,84.414,98.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.174 | Acc: 61.176,84.398,98.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.171 | Acc: 61.200,84.412,98.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.168 | Acc: 61.313,84.439,98.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.163 | Acc: 61.368,84.514,98.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.161 | Acc: 61.354,84.516,98.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.379 | Acc: 42.188,70.312,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.895 | Acc: 42.001,61.235,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.921 | Acc: 41.063,61.566,57.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.953 | Acc: 41.048,61.603,56.481,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 2.031 | Acc: 64.844,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.101 | Acc: 61.347,85.231,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.103 | Acc: 61.776,84.794,99.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.092 | Acc: 61.962,85.054,99.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.091 | Acc: 61.613,85.041,99.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.119 | Acc: 61.587,84.932,98.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.120 | Acc: 61.583,85.021,99.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.127 | Acc: 61.553,84.896,98.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.132 | Acc: 61.544,84.860,98.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.123 | Acc: 61.637,84.906,98.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.121 | Acc: 61.692,84.838,99.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.123 | Acc: 61.694,84.838,98.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.121 | Acc: 61.690,84.903,98.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.127 | Acc: 61.623,84.809,98.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.124 | Acc: 61.596,84.887,98.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.127 | Acc: 61.527,84.886,98.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.131 | Acc: 61.405,84.862,98.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.136 | Acc: 61.265,84.819,98.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.135 | Acc: 61.251,84.834,98.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.135 | Acc: 61.194,84.865,98.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.913 | Acc: 44.531,70.312,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.414 | Acc: 43.192,63.132,62.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.441 | Acc: 42.454,63.072,62.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.467 | Acc: 42.687,63.307,61.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.854 | Acc: 60.938,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.012 | Acc: 62.723,86.198,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.019 | Acc: 63.072,86.204,99.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.062 | Acc: 62.141,85.733,99.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.058 | Acc: 62.326,85.716,99.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.064 | Acc: 62.160,85.620,99.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.066 | Acc: 62.145,85.841,99.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.075 | Acc: 62.156,85.865,99.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.082 | Acc: 61.976,85.840,99.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.093 | Acc: 61.904,85.666,99.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.099 | Acc: 61.839,85.665,99.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.098 | Acc: 61.860,85.747,99.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.105 | Acc: 61.780,85.630,99.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.104 | Acc: 61.809,85.545,99.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.104 | Acc: 61.780,85.576,99.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.107 | Acc: 61.651,85.525,99.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.105 | Acc: 61.697,85.502,99.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.110 | Acc: 61.625,85.459,99.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.112 | Acc: 61.637,85.392,99.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.113 | Acc: 61.659,85.345,99.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.398 | Acc: 42.188,69.531,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.960 | Acc: 38.690,60.231,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.979 | Acc: 38.014,60.385,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.012 | Acc: 38.064,60.425,57.864,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.816 | Acc: 63.281,89.062,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.113 | Acc: 61.458,84.859,99.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.072 | Acc: 61.928,85.347,99.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.062 | Acc: 62.295,85.669,99.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.048 | Acc: 62.355,85.754,99.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.057 | Acc: 62.399,85.744,99.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.059 | Acc: 62.235,85.524,99.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.072 | Acc: 62.145,85.467,99.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.076 | Acc: 62.180,85.379,99.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.064 | Acc: 62.422,85.558,99.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.068 | Acc: 62.216,85.564,99.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.068 | Acc: 62.161,85.609,99.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.063 | Acc: 62.273,85.668,99.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.071 | Acc: 62.147,85.620,99.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.072 | Acc: 62.125,85.623,99.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.075 | Acc: 62.118,85.569,99.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.079 | Acc: 62.098,85.460,99.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.077 | Acc: 62.092,85.507,99.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.075 | Acc: 62.063,85.533,99.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.077 | Acc: 62.051,85.493,99.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.569 | Acc: 43.750,70.312,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.094 | Acc: 43.304,59.673,56.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.107 | Acc: 41.997,59.661,56.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.143 | Acc: 42.123,59.964,56.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.505 | Acc: 71.094,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.024 | Acc: 63.988,86.235,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.005 | Acc: 62.805,86.814,99.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 62.474,86.796,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.026 | Acc: 62.683,86.642,99.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.029 | Acc: 62.515,86.618,99.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.033 | Acc: 62.410,86.480,99.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.035 | Acc: 62.461,86.553,99.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.043 | Acc: 62.384,86.321,99.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.045 | Acc: 62.276,86.343,99.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.045 | Acc: 62.337,86.462,99.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.045 | Acc: 62.323,86.422,99.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.056 | Acc: 62.046,86.372,99.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.059 | Acc: 61.865,86.378,99.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.057 | Acc: 61.888,86.407,99.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.063 | Acc: 61.877,86.296,99.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.061 | Acc: 61.984,86.307,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.061 | Acc: 61.941,86.293,99.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.063 | Acc: 61.942,86.240,99.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.061 | Acc: 62.022,86.184,99.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.634 | Acc: 43.750,70.312,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.193 | Acc: 41.964,57.701,57.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.217 | Acc: 40.930,57.622,57.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.243 | Acc: 40.804,57.877,56.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 2.020 | Acc: 67.969,88.281,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.002 | Acc: 63.318,86.347,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.995 | Acc: 62.729,86.566,99.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.985 | Acc: 63.025,86.732,99.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.987 | Acc: 63.088,86.757,99.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.988 | Acc: 63.057,86.781,99.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.005 | Acc: 62.874,86.615,99.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.008 | Acc: 62.965,86.569,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.017 | Acc: 62.786,86.369,99.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.030 | Acc: 62.755,86.309,99.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.039 | Acc: 62.531,86.252,99.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.045 | Acc: 62.281,86.206,99.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.043 | Acc: 62.341,86.242,99.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.050 | Acc: 62.255,86.213,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.050 | Acc: 62.317,86.241,99.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.050 | Acc: 62.386,86.197,99.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.051 | Acc: 62.322,86.142,99.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.053 | Acc: 62.310,86.132,99.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.056 | Acc: 62.251,86.113,99.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.056 | Acc: 62.209,86.141,99.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.879 | Acc: 39.844,69.531,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.348 | Acc: 38.318,59.970,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.375 | Acc: 37.252,59.394,55.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.408 | Acc: 37.359,59.554,54.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.625 | Acc: 67.188,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.953 | Acc: 62.909,87.240,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.949 | Acc: 62.557,87.176,99.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.987 | Acc: 62.423,86.783,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.014 | Acc: 62.211,86.593,99.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.994 | Acc: 62.469,86.734,99.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.001 | Acc: 62.481,86.680,99.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.005 | Acc: 62.639,86.602,99.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.012 | Acc: 62.665,86.714,99.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.011 | Acc: 62.694,86.650,99.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.012 | Acc: 62.729,86.575,99.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.015 | Acc: 62.687,86.567,99.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.013 | Acc: 62.646,86.498,99.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.018 | Acc: 62.479,86.494,99.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.016 | Acc: 62.439,86.549,99.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.021 | Acc: 62.394,86.524,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.020 | Acc: 62.376,86.534,99.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.026 | Acc: 62.287,86.460,99.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.028 | Acc: 62.258,86.461,99.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.032 | Acc: 62.149,86.452,99.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.616 | Acc: 41.406,70.312,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.156 | Acc: 42.001,59.933,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.176 | Acc: 41.387,60.137,55.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.210 | Acc: 41.842,60.207,54.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.799 | Acc: 61.719,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.943 | Acc: 64.062,87.537,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.928 | Acc: 64.405,87.843,99.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.948 | Acc: 63.730,87.577,99.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.951 | Acc: 63.436,87.645,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.969 | Acc: 63.467,87.167,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.988 | Acc: 63.017,86.835,99.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.991 | Acc: 62.949,86.896,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.992 | Acc: 62.878,86.806,99.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.995 | Acc: 62.906,86.740,99.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.997 | Acc: 62.811,86.719,99.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.009 | Acc: 62.595,86.482,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.017 | Acc: 62.588,86.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.019 | Acc: 62.578,86.345,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.026 | Acc: 62.458,86.279,99.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.023 | Acc: 62.453,86.332,99.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.017 | Acc: 62.554,86.363,99.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.017 | Acc: 62.539,86.403,99.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.017 | Acc: 62.506,86.396,99.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.016 | Acc: 62.547,86.401,99.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.584 | Acc: 36.719,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.076 | Acc: 33.557,59.263,62.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.105 | Acc: 32.736,59.585,62.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.134 | Acc: 32.723,59.964,61.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.804 | Acc: 67.969,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.980 | Acc: 63.504,87.612,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.931 | Acc: 63.929,87.691,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 63.883,87.449,99.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.984 | Acc: 63.484,87.249,99.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.986 | Acc: 63.304,87.191,99.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.995 | Acc: 63.004,87.093,99.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.000 | Acc: 62.982,86.996,99.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.003 | Acc: 62.893,86.889,99.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.006 | Acc: 62.686,86.809,99.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.010 | Acc: 62.764,86.777,99.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.005 | Acc: 62.744,86.899,99.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.002 | Acc: 62.850,86.975,99.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.011 | Acc: 62.638,86.886,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.011 | Acc: 62.686,86.877,99.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.008 | Acc: 62.648,86.849,99.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.011 | Acc: 62.546,86.811,99.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.012 | Acc: 62.539,86.806,99.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.012 | Acc: 62.550,86.790,99.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.013 | Acc: 62.514,86.747,99.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.657 | Acc: 41.406,67.188,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.227 | Acc: 39.211,58.296,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.247 | Acc: 38.377,58.003,60.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.278 | Acc: 38.601,58.325,59.324,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 2.234 | Acc: 60.156,84.375,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.033 | Acc: 61.235,87.165,99.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.021 | Acc: 62.271,87.138,99.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.036 | Acc: 62.308,87.116,99.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.035 | Acc: 62.481,87.047,99.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.008 | Acc: 62.670,87.353,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.995 | Acc: 62.803,87.506,99.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.998 | Acc: 62.844,87.195,99.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.000 | Acc: 62.830,87.083,99.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.991 | Acc: 62.867,87.133,99.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.991 | Acc: 62.834,87.111,99.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.985 | Acc: 62.846,87.111,99.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.989 | Acc: 62.759,87.101,99.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.987 | Acc: 62.659,87.090,99.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.984 | Acc: 62.675,87.097,99.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.990 | Acc: 62.599,87.056,99.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.989 | Acc: 62.597,87.042,99.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.989 | Acc: 62.582,86.968,99.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.991 | Acc: 62.552,86.981,99.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.989 | Acc: 62.568,87.035,99.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.236 | Acc: 45.312,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.759 | Acc: 42.746,60.156,63.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.784 | Acc: 42.264,60.156,63.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.817 | Acc: 42.175,60.195,62.999,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.959 | Acc: 64.844,90.625,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.967 | Acc: 63.951,89.323,99.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.966 | Acc: 63.662,88.338,99.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.943 | Acc: 63.832,88.230,99.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.974 | Acc: 63.397,87.712,99.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.976 | Acc: 63.096,87.778,99.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.986 | Acc: 63.029,87.500,99.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.986 | Acc: 62.988,87.478,99.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.986 | Acc: 63.034,87.393,99.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.987 | Acc: 63.027,87.371,99.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.991 | Acc: 62.815,87.317,99.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.992 | Acc: 62.670,87.238,99.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.988 | Acc: 62.857,87.257,99.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.994 | Acc: 62.730,87.270,99.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.997 | Acc: 62.697,87.186,99.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.998 | Acc: 62.658,87.230,99.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.996 | Acc: 62.678,87.230,99.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.995 | Acc: 62.741,87.193,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.999 | Acc: 62.699,87.104,99.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.996 | Acc: 62.736,87.098,99.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.390 | Acc: 35.938,67.188,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.063 | Acc: 33.929,57.106,65.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.087 | Acc: 33.022,57.050,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.117 | Acc: 32.864,57.262,65.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.942 | Acc: 63.281,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.950 | Acc: 64.062,88.504,99.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.960 | Acc: 62.748,87.938,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.984 | Acc: 62.602,87.538,99.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.989 | Acc: 62.519,87.683,99.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.993 | Acc: 62.523,87.485,99.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.978 | Acc: 62.629,87.584,99.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.977 | Acc: 62.716,87.722,99.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.974 | Acc: 62.840,87.738,99.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.964 | Acc: 63.139,87.733,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.965 | Acc: 63.071,87.667,99.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.967 | Acc: 62.977,87.634,99.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.973 | Acc: 62.934,87.451,99.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.975 | Acc: 62.802,87.437,99.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.976 | Acc: 62.795,87.430,99.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.977 | Acc: 62.778,87.375,99.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.978 | Acc: 62.846,87.347,99.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.986 | Acc: 62.786,87.239,99.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.988 | Acc: 62.829,87.206,99.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.987 | Acc: 62.797,87.225,99.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.435 | Acc: 39.062,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.993 | Acc: 38.802,57.254,62.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.029 | Acc: 38.072,57.088,62.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.062 | Acc: 38.179,56.980,62.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.817 | Acc: 61.719,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.851 | Acc: 65.402,88.132,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.893 | Acc: 64.291,87.691,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.932 | Acc: 63.409,87.423,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.931 | Acc: 63.522,87.461,99.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.939 | Acc: 63.181,87.461,99.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.937 | Acc: 63.152,87.590,99.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.941 | Acc: 63.237,87.616,99.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.944 | Acc: 63.184,87.485,99.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.950 | Acc: 63.147,87.375,99.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.944 | Acc: 63.297,87.383,99.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.947 | Acc: 63.200,87.369,99.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.955 | Acc: 62.999,87.348,99.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.957 | Acc: 62.949,87.335,99.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.954 | Acc: 63.025,87.417,99.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.952 | Acc: 63.092,87.430,99.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.964 | Acc: 62.965,87.303,99.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.966 | Acc: 62.967,87.204,99.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.969 | Acc: 62.970,87.143,99.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.968 | Acc: 62.965,87.153,99.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.433 | Acc: 36.719,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.961 | Acc: 34.449,58.259,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.998 | Acc: 33.689,57.698,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.025 | Acc: 33.876,57.787,64.908,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.760 | Acc: 58.594,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.834 | Acc: 63.728,89.137,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.863 | Acc: 63.891,88.891,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.871 | Acc: 64.357,88.704,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.892 | Acc: 63.870,88.474,99.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.890 | Acc: 64.032,88.459,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.896 | Acc: 63.953,88.481,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.906 | Acc: 63.586,88.337,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.911 | Acc: 63.509,88.306,99.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.912 | Acc: 63.588,88.294,99.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.922 | Acc: 63.468,88.165,99.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.919 | Acc: 63.571,88.193,99.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.931 | Acc: 63.511,88.041,99.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.928 | Acc: 63.506,88.024,99.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.931 | Acc: 63.429,87.995,99.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.933 | Acc: 63.312,87.980,99.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.935 | Acc: 63.284,87.923,99.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.936 | Acc: 63.240,87.903,99.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.934 | Acc: 63.238,87.920,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.938 | Acc: 63.171,87.855,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.040 | Acc: 46.094,72.656,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.677 | Acc: 44.122,62.165,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.704 | Acc: 43.312,61.471,61.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.737 | Acc: 43.276,61.501,61.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.968 | Acc: 54.688,87.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.848 | Acc: 63.951,89.583,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.877 | Acc: 63.624,89.043,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.919 | Acc: 63.397,88.742,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.904 | Acc: 63.503,88.937,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.904 | Acc: 63.537,88.800,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.899 | Acc: 63.817,88.791,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.901 | Acc: 63.708,88.691,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.912 | Acc: 63.519,88.519,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.918 | Acc: 63.342,88.255,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.923 | Acc: 63.375,88.114,99.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.927 | Acc: 63.373,88.059,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.931 | Acc: 63.330,87.973,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.933 | Acc: 63.281,87.949,99.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.933 | Acc: 63.228,87.917,99.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.930 | Acc: 63.276,87.910,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.934 | Acc: 63.189,87.860,99.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.937 | Acc: 63.141,87.830,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.941 | Acc: 63.097,87.747,99.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.944 | Acc: 63.021,87.728,99.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.955 | Acc: 43.750,64.062,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.474 | Acc: 40.141,56.920,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.492 | Acc: 39.272,56.784,55.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.520 | Acc: 39.575,56.583,55.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.623 | Acc: 64.062,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.930 | Acc: 62.314,88.914,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 62.614,88.262,99.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.933 | Acc: 63.230,87.999,99.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.921 | Acc: 63.194,88.233,99.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.924 | Acc: 63.359,87.956,99.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.933 | Acc: 63.423,87.991,99.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.944 | Acc: 63.398,87.916,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.948 | Acc: 63.441,87.932,99.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.950 | Acc: 63.294,87.776,99.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.949 | Acc: 63.277,87.834,99.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.959 | Acc: 63.165,87.624,99.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.964 | Acc: 63.129,87.636,99.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.960 | Acc: 63.263,87.665,99.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.960 | Acc: 63.212,87.650,99.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.953 | Acc: 63.331,87.721,99.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.955 | Acc: 63.235,87.673,99.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.955 | Acc: 63.151,87.644,99.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.953 | Acc: 63.229,87.710,99.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.954 | Acc: 63.209,87.672,99.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.616 | Acc: 36.719,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.073 | Acc: 35.528,59.933,62.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.100 | Acc: 34.737,59.661,62.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.123 | Acc: 35.143,59.849,62.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 2.057 | Acc: 61.719,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.942 | Acc: 62.388,89.323,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.926 | Acc: 63.091,88.967,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.946 | Acc: 63.012,88.627,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.918 | Acc: 63.513,88.850,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.910 | Acc: 63.668,88.769,99.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.925 | Acc: 63.184,88.733,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.927 | Acc: 63.071,88.520,99.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.926 | Acc: 63.257,88.461,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.924 | Acc: 63.268,88.402,99.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.922 | Acc: 63.149,88.518,99.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.930 | Acc: 63.041,88.398,99.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.933 | Acc: 63.084,88.304,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.935 | Acc: 63.084,88.123,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.937 | Acc: 63.131,88.092,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.941 | Acc: 63.087,88.035,99.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.940 | Acc: 63.062,88.057,99.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.945 | Acc: 63.041,87.979,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.944 | Acc: 63.052,87.950,99.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.943 | Acc: 63.052,87.972,99.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.869 | Acc: 37.500,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.325 | Acc: 34.598,56.622,61.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.353 | Acc: 34.013,56.136,61.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.385 | Acc: 34.311,55.622,61.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 2.173 | Acc: 60.156,86.719,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.914 | Acc: 63.170,89.360,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.898 | Acc: 63.948,88.720,99.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.914 | Acc: 63.384,88.461,99.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.905 | Acc: 63.638,88.754,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.888 | Acc: 63.846,88.977,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.890 | Acc: 64.017,88.862,99.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.886 | Acc: 63.935,88.835,99.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.893 | Acc: 63.766,88.626,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.895 | Acc: 63.778,88.631,99.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.901 | Acc: 63.689,88.619,99.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.905 | Acc: 63.638,88.486,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.912 | Acc: 63.557,88.489,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.915 | Acc: 63.542,88.536,99.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.911 | Acc: 63.629,88.484,99.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.911 | Acc: 63.613,88.476,99.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.918 | Acc: 63.481,88.386,99.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.920 | Acc: 63.352,88.332,99.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.926 | Acc: 63.305,88.234,99.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.931 | Acc: 63.238,88.142,99.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.282 | Acc: 42.188,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.788 | Acc: 40.588,60.938,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.816 | Acc: 39.653,60.938,62.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.841 | Acc: 40.113,60.925,61.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 2.109 | Acc: 57.031,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.857 | Acc: 64.025,88.802,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.872 | Acc: 63.758,88.605,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.900 | Acc: 63.550,88.461,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.888 | Acc: 63.889,88.677,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.891 | Acc: 64.001,88.552,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.884 | Acc: 63.998,88.540,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.887 | Acc: 63.974,88.603,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.885 | Acc: 64.101,88.548,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.886 | Acc: 64.062,88.545,99.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.890 | Acc: 63.907,88.437,99.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.893 | Acc: 63.896,88.387,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.896 | Acc: 63.806,88.275,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.901 | Acc: 63.733,88.215,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.910 | Acc: 63.537,88.120,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.907 | Acc: 63.575,88.159,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.913 | Acc: 63.459,88.108,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.913 | Acc: 63.446,88.087,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.915 | Acc: 63.372,88.041,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.913 | Acc: 63.412,88.058,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.781 | Acc: 38.281,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.310 | Acc: 37.946,56.287,60.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.328 | Acc: 37.100,56.383,60.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.350 | Acc: 37.282,55.968,60.015,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 2.001 | Acc: 64.062,84.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.924 | Acc: 62.463,88.467,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.869 | Acc: 63.853,88.910,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.885 | Acc: 63.768,88.704,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.894 | Acc: 63.947,88.831,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.901 | Acc: 63.606,88.885,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.890 | Acc: 63.888,89.017,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.891 | Acc: 63.830,89.035,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.885 | Acc: 64.121,88.941,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.888 | Acc: 63.920,88.963,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.887 | Acc: 63.977,88.930,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.892 | Acc: 63.886,88.783,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.899 | Acc: 63.871,88.599,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.896 | Acc: 63.922,88.578,99.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.891 | Acc: 64.001,88.587,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.889 | Acc: 63.992,88.595,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.887 | Acc: 63.938,88.627,99.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.885 | Acc: 63.971,88.632,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.888 | Acc: 63.937,88.640,99.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.893 | Acc: 63.890,88.538,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.257 | Acc: 41.406,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.742 | Acc: 39.360,59.784,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.785 | Acc: 38.186,59.432,64.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.811 | Acc: 38.473,59.465,64.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.608 | Acc: 66.406,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.839 | Acc: 63.802,90.141,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.850 | Acc: 64.253,89.558,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.869 | Acc: 63.730,89.613,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.874 | Acc: 63.744,89.217,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.857 | Acc: 63.815,89.395,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.859 | Acc: 63.875,89.295,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.865 | Acc: 63.924,89.212,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.873 | Acc: 63.800,89.135,99.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.876 | Acc: 63.696,89.123,99.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.876 | Acc: 63.732,89.074,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.873 | Acc: 63.766,89.091,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.871 | Acc: 63.774,89.030,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.877 | Acc: 63.736,88.916,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.884 | Acc: 63.626,88.837,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.885 | Acc: 63.580,88.772,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.885 | Acc: 63.568,88.710,99.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.889 | Acc: 63.503,88.668,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.890 | Acc: 63.502,88.638,99.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.890 | Acc: 63.529,88.566,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.730 | Acc: 33.594,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.208 | Acc: 32.701,56.436,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.243 | Acc: 31.669,55.678,64.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.270 | Acc: 31.698,55.507,64.767,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.784 | Acc: 67.188,91.406,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.810 | Acc: 64.769,89.769,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.857 | Acc: 64.005,88.948,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.865 | Acc: 63.947,89.127,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.851 | Acc: 64.525,89.178,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.850 | Acc: 64.442,89.202,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.865 | Acc: 64.134,89.043,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.870 | Acc: 63.808,89.146,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.860 | Acc: 63.951,89.145,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.870 | Acc: 63.747,89.140,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.875 | Acc: 63.697,88.961,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.878 | Acc: 63.585,88.988,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.881 | Acc: 63.576,88.926,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.882 | Acc: 63.590,88.862,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.881 | Acc: 63.659,88.871,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.881 | Acc: 63.678,88.829,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.879 | Acc: 63.817,88.785,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.882 | Acc: 63.762,88.721,99.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.881 | Acc: 63.721,88.747,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.882 | Acc: 63.757,88.683,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.540 | Acc: 45.312,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.009 | Acc: 43.118,57.999,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.035 | Acc: 42.111,57.603,61.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.054 | Acc: 42.264,57.441,61.373,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.522 | Acc: 75.781,89.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.841 | Acc: 63.690,89.807,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.859 | Acc: 63.548,89.653,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.853 | Acc: 63.794,89.626,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.843 | Acc: 63.927,89.641,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.866 | Acc: 63.529,89.264,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.858 | Acc: 63.636,89.237,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.859 | Acc: 63.813,89.162,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.862 | Acc: 63.844,89.101,99.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.868 | Acc: 63.808,89.015,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.873 | Acc: 63.783,88.880,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.875 | Acc: 63.748,88.854,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.875 | Acc: 63.852,88.813,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.872 | Acc: 63.754,88.904,99.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.877 | Acc: 63.768,88.823,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.876 | Acc: 63.824,88.793,99.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.880 | Acc: 63.732,88.756,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.881 | Acc: 63.815,88.758,99.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.889 | Acc: 63.705,88.656,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.888 | Acc: 63.745,88.656,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.546 | Acc: 41.406,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.067 | Acc: 39.993,58.780,62.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.088 | Acc: 38.796,58.384,62.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.119 | Acc: 38.486,57.800,62.487,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.924 | Acc: 64.844,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.850 | Acc: 64.732,89.695,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.858 | Acc: 64.463,88.967,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.855 | Acc: 64.293,89.011,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.856 | Acc: 64.091,88.956,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.871 | Acc: 63.784,88.776,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.873 | Acc: 63.707,88.862,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.865 | Acc: 63.824,89.024,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.868 | Acc: 63.888,89.004,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.867 | Acc: 63.829,89.071,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.868 | Acc: 63.872,88.930,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.864 | Acc: 63.840,88.889,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.864 | Acc: 63.768,88.855,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.871 | Acc: 63.685,88.838,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.872 | Acc: 63.704,88.840,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.870 | Acc: 63.722,88.857,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.872 | Acc: 63.729,88.846,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.875 | Acc: 63.639,88.806,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.875 | Acc: 63.695,88.727,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.878 | Acc: 63.626,88.603,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.247 | Acc: 41.406,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.757 | Acc: 39.695,60.528,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.783 | Acc: 38.548,60.366,62.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.812 | Acc: 38.845,60.387,62.679,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.731 | Acc: 65.625,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.796 | Acc: 65.179,89.695,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.842 | Acc: 64.158,89.024,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.863 | Acc: 64.075,88.576,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.849 | Acc: 64.516,88.792,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.859 | Acc: 64.248,88.730,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.849 | Acc: 64.585,88.953,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.852 | Acc: 64.356,89.040,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.856 | Acc: 64.339,88.961,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.859 | Acc: 64.339,88.924,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.864 | Acc: 64.327,88.849,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.868 | Acc: 64.193,88.857,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.875 | Acc: 64.046,88.845,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.872 | Acc: 64.068,88.874,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.874 | Acc: 64.079,88.823,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.875 | Acc: 64.037,88.761,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.874 | Acc: 64.058,88.727,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.872 | Acc: 64.095,88.684,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.876 | Acc: 64.006,88.608,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.876 | Acc: 63.966,88.638,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.678 | Acc: 39.844,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.187 | Acc: 38.318,56.510,63.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.212 | Acc: 37.671,55.888,62.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.245 | Acc: 37.666,55.520,62.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.902 | Acc: 64.844,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.839 | Acc: 63.802,89.062,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.827 | Acc: 64.939,89.101,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.834 | Acc: 64.306,89.255,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.832 | Acc: 64.448,89.111,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.843 | Acc: 64.101,88.954,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.847 | Acc: 64.121,89.192,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.846 | Acc: 64.085,89.251,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.849 | Acc: 63.985,89.223,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.856 | Acc: 63.864,89.106,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.863 | Acc: 63.717,88.973,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.856 | Acc: 63.840,89.038,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.862 | Acc: 63.670,88.988,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.864 | Acc: 63.649,88.976,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.867 | Acc: 63.548,88.943,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.865 | Acc: 63.567,88.961,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.863 | Acc: 63.666,88.929,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.868 | Acc: 63.627,88.936,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.871 | Acc: 63.545,88.876,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.871 | Acc: 63.601,88.849,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.004 | Acc: 37.500,65.625,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.476 | Acc: 38.318,56.845,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.496 | Acc: 36.814,56.707,57.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.528 | Acc: 36.885,56.698,57.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 2.043 | Acc: 60.938,89.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.830 | Acc: 64.211,89.100,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.837 | Acc: 64.272,89.005,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.856 | Acc: 64.357,89.127,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.849 | Acc: 64.255,89.072,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.837 | Acc: 64.295,89.256,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.836 | Acc: 64.276,89.211,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.844 | Acc: 64.240,89.062,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.836 | Acc: 64.407,89.111,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.837 | Acc: 64.334,89.071,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.835 | Acc: 64.350,89.035,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.833 | Acc: 64.363,89.013,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.839 | Acc: 64.351,88.962,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.841 | Acc: 64.296,88.973,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.847 | Acc: 64.218,89.004,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.854 | Acc: 64.099,88.948,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.858 | Acc: 63.989,88.994,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.858 | Acc: 63.953,88.985,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.861 | Acc: 63.881,88.965,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.865 | Acc: 63.823,88.919,99.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.400 | Acc: 42.969,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.899 | Acc: 39.918,58.557,63.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.927 | Acc: 38.720,59.127,62.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.954 | Acc: 38.537,59.157,62.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.720 | Acc: 61.719,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.855 | Acc: 64.509,89.100,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.850 | Acc: 64.672,89.005,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.853 | Acc: 64.895,89.075,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.835 | Acc: 64.882,89.390,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.837 | Acc: 64.581,89.372,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.841 | Acc: 64.631,89.327,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.855 | Acc: 64.550,89.256,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.852 | Acc: 64.577,89.242,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.857 | Acc: 64.395,89.278,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.854 | Acc: 64.342,89.241,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.856 | Acc: 64.211,89.169,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.857 | Acc: 64.221,89.179,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.860 | Acc: 64.140,89.119,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.864 | Acc: 64.049,89.101,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.864 | Acc: 64.037,89.052,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.857 | Acc: 64.138,89.062,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.858 | Acc: 64.117,89.037,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.857 | Acc: 64.121,89.047,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.859 | Acc: 64.060,89.005,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.403 | Acc: 38.281,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.921 | Acc: 36.793,60.565,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.947 | Acc: 35.556,60.385,61.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.983 | Acc: 35.528,60.284,61.399,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 1.635 | Acc: 64.844,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.757 | Acc: 65.179,90.699,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.801 | Acc: 65.072,90.339,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.808 | Acc: 65.164,90.074,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.796 | Acc: 65.230,90.143,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.812 | Acc: 64.712,89.968,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.816 | Acc: 64.540,90.147,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.821 | Acc: 64.633,89.988,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.829 | Acc: 64.606,89.771,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.838 | Acc: 64.321,89.658,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.844 | Acc: 64.202,89.533,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.842 | Acc: 64.144,89.451,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.846 | Acc: 64.014,89.374,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.857 | Acc: 63.805,89.275,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.858 | Acc: 63.718,89.265,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.859 | Acc: 63.826,89.223,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.862 | Acc: 63.824,89.162,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.862 | Acc: 63.865,89.092,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.861 | Acc: 63.935,89.041,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.861 | Acc: 63.978,88.991,99.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.441 | Acc: 36.719,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.851 | Acc: 34.784,61.235,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.890 | Acc: 33.861,60.690,64.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.919 | Acc: 33.850,60.720,64.229,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.915 | Acc: 61.719,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.924 | Acc: 62.016,88.393,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.856 | Acc: 63.834,89.196,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.893 | Acc: 63.192,88.973,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.875 | Acc: 63.445,88.937,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.862 | Acc: 63.738,89.032,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.860 | Acc: 63.895,88.940,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.854 | Acc: 64.002,88.974,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.849 | Acc: 64.024,88.985,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.848 | Acc: 64.006,89.024,99.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.842 | Acc: 64.051,89.086,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.835 | Acc: 64.147,89.101,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.831 | Acc: 64.157,89.088,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.831 | Acc: 64.128,89.086,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.833 | Acc: 64.065,89.088,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.841 | Acc: 64.024,88.935,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.841 | Acc: 64.043,88.912,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.839 | Acc: 64.097,88.886,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.842 | Acc: 64.041,88.853,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.846 | Acc: 63.993,88.833,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.144 | Acc: 42.969,64.844,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.677 | Acc: 39.695,53.460,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.701 | Acc: 38.281,53.125,56.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.736 | Acc: 37.935,52.638,56.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.737 | Acc: 65.625,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.703 | Acc: 64.993,90.737,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.770 | Acc: 64.787,90.111,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.788 | Acc: 64.921,89.959,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.774 | Acc: 64.824,90.133,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.792 | Acc: 64.650,90.084,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.803 | Acc: 64.508,89.986,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.802 | Acc: 64.417,90.099,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.814 | Acc: 64.184,89.902,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.808 | Acc: 64.490,89.965,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.811 | Acc: 64.459,89.863,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.819 | Acc: 64.349,89.741,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.826 | Acc: 64.137,89.669,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.824 | Acc: 64.152,89.697,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.826 | Acc: 64.149,89.652,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.830 | Acc: 64.127,89.563,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.831 | Acc: 64.089,89.564,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.834 | Acc: 64.046,89.601,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.838 | Acc: 63.965,89.541,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.841 | Acc: 63.933,89.507,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.030 | Acc: 39.062,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.584 | Acc: 34.635,52.939,61.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.607 | Acc: 33.498,52.382,60.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.639 | Acc: 33.248,52.203,60.451,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 1.691 | Acc: 60.938,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.723 | Acc: 65.960,91.109,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.735 | Acc: 65.949,90.930,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.734 | Acc: 65.676,90.804,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.754 | Acc: 65.297,90.220,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.771 | Acc: 64.766,90.169,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.777 | Acc: 64.715,90.154,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.792 | Acc: 64.594,90.032,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.790 | Acc: 64.436,89.931,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.798 | Acc: 64.347,89.740,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.803 | Acc: 64.358,89.607,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.810 | Acc: 64.243,89.504,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.811 | Acc: 64.221,89.507,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.823 | Acc: 64.003,89.392,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.822 | Acc: 64.029,89.427,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.826 | Acc: 63.961,89.423,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.831 | Acc: 64.021,89.364,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.834 | Acc: 64.012,89.221,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.832 | Acc: 64.095,89.236,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.834 | Acc: 64.075,89.222,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.385 | Acc: 46.094,67.969,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.893 | Acc: 43.899,60.045,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.917 | Acc: 42.816,59.413,60.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.948 | Acc: 42.892,59.401,59.887,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.880 | Acc: 64.062,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.742 | Acc: 64.435,90.997,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.795 | Acc: 63.967,90.396,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.799 | Acc: 63.986,90.292,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.809 | Acc: 64.034,90.017,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.808 | Acc: 64.256,89.983,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.808 | Acc: 64.237,89.934,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.814 | Acc: 64.245,89.794,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.815 | Acc: 64.179,89.703,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.817 | Acc: 64.041,89.598,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.823 | Acc: 63.923,89.564,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.831 | Acc: 63.833,89.547,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.836 | Acc: 63.849,89.432,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.840 | Acc: 63.850,89.320,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.837 | Acc: 63.915,89.374,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.836 | Acc: 63.990,89.382,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.835 | Acc: 64.014,89.372,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.834 | Acc: 64.072,89.363,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.835 | Acc: 64.071,89.348,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.839 | Acc: 64.019,89.311,99.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.312 | Acc: 37.500,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.736 | Acc: 38.170,61.161,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.779 | Acc: 36.776,61.166,64.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.804 | Acc: 36.693,61.245,64.319,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.651 | Acc: 61.719,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.771 | Acc: 65.513,90.513,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.777 | Acc: 65.130,90.091,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.761 | Acc: 65.330,90.228,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.758 | Acc: 65.278,90.123,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.765 | Acc: 65.223,90.060,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.776 | Acc: 64.941,90.179,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.785 | Acc: 65.010,90.137,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.795 | Acc: 64.824,90.023,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.792 | Acc: 64.826,90.021,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.791 | Acc: 64.844,89.929,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.790 | Acc: 64.777,89.939,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.796 | Acc: 64.649,89.896,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.797 | Acc: 64.742,89.832,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.796 | Acc: 64.735,89.883,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.798 | Acc: 64.618,89.901,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.804 | Acc: 64.535,89.807,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.805 | Acc: 64.509,89.752,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.805 | Acc: 64.569,89.671,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.815 | Acc: 64.458,89.540,99.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.517 | Acc: 39.062,67.969,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.048 | Acc: 38.728,60.305,61.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.070 | Acc: 37.614,60.404,61.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.097 | Acc: 37.654,60.438,61.142,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.668 | Acc: 70.312,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.792 | Acc: 64.062,89.397,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.764 | Acc: 65.091,90.225,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.804 | Acc: 64.857,89.588,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.803 | Acc: 64.535,89.506,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.811 | Acc: 64.356,89.604,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.803 | Acc: 64.372,89.585,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.799 | Acc: 64.323,89.672,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.800 | Acc: 64.407,89.650,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.803 | Acc: 64.265,89.602,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.806 | Acc: 64.241,89.607,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.817 | Acc: 64.236,89.430,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.812 | Acc: 64.370,89.503,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.814 | Acc: 64.368,89.464,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.811 | Acc: 64.341,89.441,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.813 | Acc: 64.397,89.364,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.816 | Acc: 64.379,89.311,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.818 | Acc: 64.303,89.308,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.819 | Acc: 64.309,89.350,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.820 | Acc: 64.241,89.321,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.234 | Acc: 42.188,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.717 | Acc: 40.104,61.793,64.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.749 | Acc: 38.834,61.547,64.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.774 | Acc: 38.678,61.603,64.139,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.639 | Acc: 68.750,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.775 | Acc: 64.472,90.885,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.748 | Acc: 64.882,91.197,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.767 | Acc: 64.588,90.932,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.789 | Acc: 64.400,90.586,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.782 | Acc: 64.565,90.494,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.783 | Acc: 64.495,90.360,99.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.795 | Acc: 64.356,90.354,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.807 | Acc: 64.194,90.271,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.796 | Acc: 64.309,90.379,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.800 | Acc: 64.280,90.252,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.805 | Acc: 64.275,90.183,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.801 | Acc: 64.328,90.194,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.801 | Acc: 64.287,90.140,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.807 | Acc: 64.140,90.058,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.809 | Acc: 64.109,90.025,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.807 | Acc: 64.101,90.046,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.812 | Acc: 64.122,89.972,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.816 | Acc: 64.110,89.878,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.821 | Acc: 64.120,89.852,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.994 | Acc: 39.062,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.460 | Acc: 37.091,59.375,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.501 | Acc: 35.537,59.261,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.530 | Acc: 35.617,59.234,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.766 | Acc: 61.719,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.765 | Acc: 65.885,90.811,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.797 | Acc: 64.882,90.111,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.808 | Acc: 64.677,89.869,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.804 | Acc: 64.776,90.037,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.803 | Acc: 64.797,90.029,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.804 | Acc: 64.728,89.882,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.799 | Acc: 64.700,89.949,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.800 | Acc: 64.674,89.936,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.804 | Acc: 64.568,89.891,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.801 | Acc: 64.677,89.883,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.804 | Acc: 64.678,89.890,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.803 | Acc: 64.675,89.850,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.804 | Acc: 64.628,89.844,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.806 | Acc: 64.632,89.769,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.809 | Acc: 64.579,89.709,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.806 | Acc: 64.613,89.707,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.810 | Acc: 64.587,89.656,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.812 | Acc: 64.556,89.653,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.817 | Acc: 64.489,89.657,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.478 | Acc: 31.250,70.312,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.894 | Acc: 29.315,62.277,64.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.932 | Acc: 28.354,62.043,64.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.959 | Acc: 28.445,62.820,64.165,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.652 | Acc: 60.156,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.702 | Acc: 64.732,90.365,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.748 | Acc: 64.768,90.568,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.745 | Acc: 65.126,90.394,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.758 | Acc: 64.998,90.230,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.769 | Acc: 64.821,90.122,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.772 | Acc: 64.986,90.231,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.785 | Acc: 64.722,90.148,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.790 | Acc: 64.494,90.115,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.792 | Acc: 64.524,90.133,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.802 | Acc: 64.451,89.995,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.811 | Acc: 64.215,89.929,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.814 | Acc: 64.267,89.918,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.814 | Acc: 64.212,89.829,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.820 | Acc: 64.099,89.819,99.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.816 | Acc: 64.148,89.805,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.821 | Acc: 64.097,89.695,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.817 | Acc: 64.193,89.681,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.815 | Acc: 64.169,89.692,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.815 | Acc: 64.151,89.676,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.449 | Acc: 40.625,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.931 | Acc: 36.682,57.106,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.975 | Acc: 35.061,56.745,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.007 | Acc: 35.079,56.301,67.533,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 1.380 | Acc: 80.469,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.718 | Acc: 65.960,90.067,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.757 | Acc: 66.159,90.225,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.751 | Acc: 65.881,90.446,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.759 | Acc: 65.654,90.336,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.771 | Acc: 65.161,90.455,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.780 | Acc: 65.044,90.347,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.772 | Acc: 65.032,90.281,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.767 | Acc: 65.038,90.363,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.774 | Acc: 65.060,90.271,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.773 | Acc: 64.937,90.384,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.775 | Acc: 65.010,90.363,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.776 | Acc: 64.983,90.285,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.773 | Acc: 65.038,90.242,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.777 | Acc: 64.958,90.144,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.787 | Acc: 64.781,90.028,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.790 | Acc: 64.703,89.975,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.796 | Acc: 64.656,89.933,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.798 | Acc: 64.619,89.876,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.799 | Acc: 64.567,89.875,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.929 | Acc: 39.844,57.812,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.406 | Acc: 38.318,53.571,63.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.442 | Acc: 37.138,53.125,63.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.472 | Acc: 37.295,52.830,63.589,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 1.750 | Acc: 59.375,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.803 | Acc: 63.467,90.811,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.786 | Acc: 64.386,90.720,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.787 | Acc: 64.716,90.523,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.786 | Acc: 64.747,90.432,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.790 | Acc: 64.674,90.277,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.788 | Acc: 64.605,90.283,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.783 | Acc: 64.628,90.381,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.782 | Acc: 64.795,90.397,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.782 | Acc: 64.848,90.319,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.789 | Acc: 64.797,90.217,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.787 | Acc: 64.808,90.215,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.785 | Acc: 64.844,90.207,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.790 | Acc: 64.748,90.074,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.795 | Acc: 64.724,89.958,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.790 | Acc: 64.722,90.015,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.794 | Acc: 64.622,89.985,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.796 | Acc: 64.615,89.935,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.804 | Acc: 64.500,89.844,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.806 | Acc: 64.493,89.797,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.783 | Acc: 39.062,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.213 | Acc: 32.775,57.329,64.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.253 | Acc: 31.917,57.298,63.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.282 | Acc: 31.890,56.967,63.614,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.305 | Acc: 74.219,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.772 | Acc: 64.323,91.220,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.777 | Acc: 64.291,90.930,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.803 | Acc: 64.267,90.561,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.777 | Acc: 65.114,90.596,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.785 | Acc: 65.006,90.586,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.787 | Acc: 64.966,90.541,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.781 | Acc: 64.960,90.481,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.780 | Acc: 64.883,90.465,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.779 | Acc: 64.839,90.457,99.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.782 | Acc: 64.727,90.392,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.781 | Acc: 64.720,90.321,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.778 | Acc: 64.802,90.301,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.777 | Acc: 64.895,90.227,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.780 | Acc: 64.891,90.197,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.781 | Acc: 64.867,90.230,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.788 | Acc: 64.732,90.150,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.788 | Acc: 64.745,90.167,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.788 | Acc: 64.729,90.084,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.791 | Acc: 64.659,90.034,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.349 | Acc: 37.500,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.866 | Acc: 34.635,59.412,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.902 | Acc: 33.232,59.356,65.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.928 | Acc: 33.312,59.234,65.215,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 2.015 | Acc: 58.594,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.809 | Acc: 63.170,90.737,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.808 | Acc: 63.739,90.377,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.798 | Acc: 64.088,90.113,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.796 | Acc: 64.159,90.307,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.803 | Acc: 64.217,90.254,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.810 | Acc: 64.172,90.257,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.808 | Acc: 64.301,90.342,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.799 | Acc: 64.407,90.314,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.793 | Acc: 64.416,90.327,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.800 | Acc: 64.455,90.252,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.797 | Acc: 64.543,90.254,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.796 | Acc: 64.455,90.239,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.801 | Acc: 64.422,90.077,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.806 | Acc: 64.329,90.055,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.806 | Acc: 64.338,90.070,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.804 | Acc: 64.352,90.051,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.808 | Acc: 64.285,90.020,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.811 | Acc: 64.283,89.987,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.811 | Acc: 64.354,89.961,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.631 | Acc: 39.062,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.093 | Acc: 39.286,52.902,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.122 | Acc: 38.129,52.630,65.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.150 | Acc: 37.987,52.446,65.049,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.623 | Acc: 63.281,94.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.715 | Acc: 64.807,91.071,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.744 | Acc: 64.425,90.739,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.743 | Acc: 64.780,90.804,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.731 | Acc: 65.123,90.644,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.736 | Acc: 64.998,90.548,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.737 | Acc: 64.999,90.554,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.753 | Acc: 64.816,90.509,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.756 | Acc: 64.834,90.576,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.759 | Acc: 64.688,90.534,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.762 | Acc: 64.735,90.462,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.763 | Acc: 64.688,90.508,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.768 | Acc: 64.568,90.466,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.771 | Acc: 64.550,90.457,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.776 | Acc: 64.449,90.416,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.780 | Acc: 64.509,90.381,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.783 | Acc: 64.430,90.265,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.789 | Acc: 64.303,90.185,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.790 | Acc: 64.318,90.168,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.793 | Acc: 64.251,90.172,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.937 | Acc: 35.156,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.406 | Acc: 32.999,49.256,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.435 | Acc: 31.745,48.971,63.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.458 | Acc: 31.596,48.630,63.730,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.103 | Acc: 56.250,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.786 | Acc: 64.955,90.662,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.753 | Acc: 65.530,90.835,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.766 | Acc: 65.190,90.651,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.779 | Acc: 64.882,90.480,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.780 | Acc: 64.774,90.323,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.777 | Acc: 64.966,90.225,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.774 | Acc: 64.888,90.281,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.785 | Acc: 64.553,90.261,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.796 | Acc: 64.356,90.060,99.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.799 | Acc: 64.280,90.112,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.800 | Acc: 64.313,89.982,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.796 | Acc: 64.332,89.957,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.798 | Acc: 64.284,89.940,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.796 | Acc: 64.329,89.988,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.801 | Acc: 64.325,89.961,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.797 | Acc: 64.435,89.973,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.798 | Acc: 64.443,89.974,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.798 | Acc: 64.441,89.963,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.799 | Acc: 64.411,89.961,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.298 | Acc: 33.594,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.766 | Acc: 32.961,49.814,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.783 | Acc: 31.460,49.981,59.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.809 | Acc: 31.621,50.154,59.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.540 | Acc: 68.750,89.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.754 | Acc: 65.216,90.625,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.749 | Acc: 64.806,90.454,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.762 | Acc: 64.549,90.471,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.759 | Acc: 64.660,90.664,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.769 | Acc: 64.372,90.555,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.770 | Acc: 64.476,90.444,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.776 | Acc: 64.556,90.409,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.770 | Acc: 64.722,90.387,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.765 | Acc: 64.874,90.405,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.768 | Acc: 64.890,90.337,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.772 | Acc: 64.957,90.300,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.777 | Acc: 64.935,90.259,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.783 | Acc: 64.724,90.197,99.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.784 | Acc: 64.702,90.191,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.784 | Acc: 64.732,90.116,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.787 | Acc: 64.666,90.092,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.787 | Acc: 64.706,90.128,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.792 | Acc: 64.681,90.084,99.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.793 | Acc: 64.618,90.053,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.099 | Acc: 42.188,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.524 | Acc: 37.835,59.933,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.553 | Acc: 36.719,60.080,66.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.566 | Acc: 36.988,60.195,66.598,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.795 | Acc: 65.625,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.726 | Acc: 65.960,90.439,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.735 | Acc: 65.568,90.911,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.752 | Acc: 65.318,90.984,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.742 | Acc: 65.461,90.972,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.739 | Acc: 65.509,90.958,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.752 | Acc: 65.212,90.748,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.742 | Acc: 65.320,90.714,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.742 | Acc: 65.358,90.649,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.752 | Acc: 65.241,90.573,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.762 | Acc: 65.166,90.365,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.769 | Acc: 64.996,90.356,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.771 | Acc: 64.964,90.298,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.768 | Acc: 64.922,90.254,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.767 | Acc: 64.863,90.258,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.770 | Acc: 64.826,90.233,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.774 | Acc: 64.732,90.182,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.774 | Acc: 64.720,90.201,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.776 | Acc: 64.642,90.186,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.780 | Acc: 64.678,90.102,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.766 | Acc: 35.156,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.278 | Acc: 32.999,58.557,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.316 | Acc: 32.279,58.175,60.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.344 | Acc: 32.377,58.274,59.823,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.751 | Acc: 55.469,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.704 | Acc: 64.472,91.629,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.699 | Acc: 65.739,91.540,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.717 | Acc: 65.177,91.137,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.723 | Acc: 65.162,90.934,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.724 | Acc: 65.254,90.826,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.733 | Acc: 65.212,90.670,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.741 | Acc: 65.054,90.575,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.752 | Acc: 64.868,90.411,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.754 | Acc: 64.917,90.396,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.758 | Acc: 64.712,90.256,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.755 | Acc: 64.770,90.236,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.757 | Acc: 64.614,90.242,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.755 | Acc: 64.688,90.221,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.756 | Acc: 64.719,90.166,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.758 | Acc: 64.743,90.212,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.763 | Acc: 64.754,90.163,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.768 | Acc: 64.706,90.169,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.776 | Acc: 64.673,90.090,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.776 | Acc: 64.641,90.071,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.668 | Acc: 36.719,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.182 | Acc: 36.124,57.478,61.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.213 | Acc: 35.271,57.088,61.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.234 | Acc: 35.425,56.737,61.258,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.592 | Acc: 64.062,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.713 | Acc: 65.699,90.923,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.697 | Acc: 66.463,90.987,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.731 | Acc: 65.753,90.702,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.753 | Acc: 65.239,90.384,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.759 | Acc: 65.153,90.316,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.756 | Acc: 65.192,90.302,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.759 | Acc: 65.082,90.309,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.754 | Acc: 65.169,90.353,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.764 | Acc: 65.094,90.349,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.774 | Acc: 64.972,90.205,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.772 | Acc: 64.865,90.243,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.772 | Acc: 64.860,90.213,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.772 | Acc: 64.832,90.074,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.775 | Acc: 64.796,89.988,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.776 | Acc: 64.813,89.997,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.775 | Acc: 64.815,89.948,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.778 | Acc: 64.748,89.915,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.777 | Acc: 64.703,89.919,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.779 | Acc: 64.696,89.938,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.612 | Acc: 41.406,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.110 | Acc: 38.579,55.469,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.134 | Acc: 36.833,55.621,61.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.156 | Acc: 37.154,55.469,60.861,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.486 | Acc: 67.188,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.810 | Acc: 63.356,90.253,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.825 | Acc: 63.243,89.996,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.823 | Acc: 63.742,89.741,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.829 | Acc: 63.908,89.506,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.812 | Acc: 64.287,89.720,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.792 | Acc: 64.676,89.979,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.794 | Acc: 64.727,90.021,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.791 | Acc: 64.659,90.048,99.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.792 | Acc: 64.701,89.978,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.784 | Acc: 64.945,90.026,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.788 | Acc: 64.893,89.929,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.795 | Acc: 64.837,89.915,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.790 | Acc: 64.913,89.898,99.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.788 | Acc: 64.872,89.916,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.790 | Acc: 64.766,89.865,99.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.795 | Acc: 64.627,89.841,99.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.801 | Acc: 64.585,89.791,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.797 | Acc: 64.608,89.798,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.797 | Acc: 64.608,89.831,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.171 | Acc: 42.969,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.728 | Acc: 40.848,57.924,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.741 | Acc: 40.454,57.470,65.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.775 | Acc: 40.215,56.954,65.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.425 | Acc: 73.438,92.969,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.783 | Acc: 66.667,90.551,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.778 | Acc: 65.739,90.701,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.766 | Acc: 65.254,90.663,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.773 | Acc: 65.278,90.557,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.780 | Acc: 65.200,90.470,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.773 | Acc: 65.031,90.496,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.779 | Acc: 64.883,90.426,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.770 | Acc: 65.159,90.547,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.769 | Acc: 65.137,90.599,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.771 | Acc: 65.065,90.512,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.769 | Acc: 65.074,90.494,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.769 | Acc: 65.145,90.440,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.772 | Acc: 65.044,90.451,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.771 | Acc: 65.041,90.408,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.773 | Acc: 65.018,90.347,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.775 | Acc: 64.953,90.345,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.774 | Acc: 64.951,90.348,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.775 | Acc: 64.967,90.307,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.775 | Acc: 64.938,90.303,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.738 | Acc: 40.625,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.202 | Acc: 39.062,54.725,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.230 | Acc: 38.453,54.059,61.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.255 | Acc: 38.256,53.829,61.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 2.102 | Acc: 60.156,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.730 | Acc: 64.844,91.592,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.746 | Acc: 65.663,91.139,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.723 | Acc: 65.689,91.534,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.723 | Acc: 65.799,91.078,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.729 | Acc: 65.540,91.205,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.720 | Acc: 65.845,91.129,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.735 | Acc: 65.625,90.924,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.738 | Acc: 65.606,90.751,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.746 | Acc: 65.569,90.595,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.753 | Acc: 65.380,90.501,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.754 | Acc: 65.279,90.487,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.763 | Acc: 65.006,90.486,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.762 | Acc: 65.059,90.448,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.759 | Acc: 65.088,90.472,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.758 | Acc: 65.070,90.459,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.760 | Acc: 65.051,90.408,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.762 | Acc: 64.977,90.405,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.762 | Acc: 64.961,90.348,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.767 | Acc: 64.924,90.274,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.054 | Acc: 41.406,57.031,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.518 | Acc: 40.737,50.186,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.562 | Acc: 39.024,49.352,59.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.597 | Acc: 39.203,48.988,59.657,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.723 | Acc: 63.281,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.720 | Acc: 64.286,91.332,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.742 | Acc: 65.091,90.987,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.718 | Acc: 65.407,91.022,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.726 | Acc: 65.085,90.876,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.720 | Acc: 65.184,90.981,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.735 | Acc: 65.160,90.870,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.746 | Acc: 65.021,90.736,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.754 | Acc: 64.766,90.664,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.746 | Acc: 64.857,90.681,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.750 | Acc: 64.836,90.707,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.757 | Acc: 64.784,90.537,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.757 | Acc: 64.860,90.541,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.753 | Acc: 64.895,90.598,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.750 | Acc: 64.955,90.606,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.751 | Acc: 64.968,90.558,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.755 | Acc: 64.905,90.506,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.753 | Acc: 65.000,90.499,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.749 | Acc: 65.049,90.525,99.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.750 | Acc: 64.991,90.496,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.651 | Acc: 38.281,62.500,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.134 | Acc: 37.054,55.952,63.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.176 | Acc: 35.423,55.621,63.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.199 | Acc: 35.566,55.482,63.076,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.989 | Acc: 62.500,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.739 | Acc: 66.034,90.997,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.720 | Acc: 65.663,91.540,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.740 | Acc: 65.113,91.265,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.744 | Acc: 65.056,91.136,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.752 | Acc: 65.130,90.965,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.752 | Acc: 65.141,91.006,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.754 | Acc: 65.154,90.941,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.753 | Acc: 65.213,90.892,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.752 | Acc: 65.107,90.949,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.749 | Acc: 65.085,90.990,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.754 | Acc: 65.028,90.918,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.755 | Acc: 65.035,90.875,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.759 | Acc: 64.987,90.760,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.759 | Acc: 65.002,90.647,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.762 | Acc: 64.945,90.578,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.761 | Acc: 64.987,90.552,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.764 | Acc: 64.908,90.476,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.763 | Acc: 64.896,90.474,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.766 | Acc: 64.911,90.432,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.689 | Acc: 34.375,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.166 | Acc: 31.548,56.473,63.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.195 | Acc: 30.373,56.688,63.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.211 | Acc: 30.430,56.327,63.461,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.505 | Acc: 67.188,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.702 | Acc: 65.811,91.704,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.702 | Acc: 66.216,91.387,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.715 | Acc: 65.638,91.189,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.729 | Acc: 65.201,91.069,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.727 | Acc: 65.300,91.027,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.734 | Acc: 65.483,90.851,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.737 | Acc: 65.542,90.686,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.733 | Acc: 65.712,90.756,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.743 | Acc: 65.349,90.664,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.754 | Acc: 65.299,90.508,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.757 | Acc: 65.388,90.526,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.755 | Acc: 65.346,90.518,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.761 | Acc: 65.245,90.478,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.767 | Acc: 65.175,90.430,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.767 | Acc: 65.215,90.451,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.776 | Acc: 65.063,90.343,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.775 | Acc: 65.045,90.334,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.775 | Acc: 65.017,90.283,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.774 | Acc: 65.022,90.293,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.113 | Acc: 35.938,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.574 | Acc: 36.979,48.661,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.596 | Acc: 35.976,48.666,59.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.624 | Acc: 35.848,48.271,59.490,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.677 | Acc: 61.719,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.698 | Acc: 66.443,90.923,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.732 | Acc: 65.339,90.854,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.734 | Acc: 65.446,90.638,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.744 | Acc: 64.882,90.808,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.742 | Acc: 64.975,90.695,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.747 | Acc: 64.973,90.560,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.753 | Acc: 64.844,90.575,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.760 | Acc: 64.771,90.411,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.757 | Acc: 64.792,90.487,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.758 | Acc: 64.797,90.361,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.761 | Acc: 64.716,90.367,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.765 | Acc: 64.623,90.333,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.767 | Acc: 64.673,90.314,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.766 | Acc: 64.646,90.330,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.769 | Acc: 64.652,90.293,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.768 | Acc: 64.693,90.309,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.769 | Acc: 64.679,90.231,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.771 | Acc: 64.668,90.184,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.775 | Acc: 64.616,90.123,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.685 | Acc: 39.844,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.116 | Acc: 36.198,54.576,63.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.166 | Acc: 35.156,54.440,63.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.195 | Acc: 35.207,54.214,63.358,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.716 | Acc: 67.188,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.739 | Acc: 65.327,91.295,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.734 | Acc: 64.729,91.044,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.734 | Acc: 65.254,90.984,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.741 | Acc: 64.892,90.895,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.733 | Acc: 65.068,90.811,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.734 | Acc: 64.986,90.825,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.742 | Acc: 64.855,90.836,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.728 | Acc: 65.242,90.741,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.740 | Acc: 65.073,90.720,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.743 | Acc: 65.061,90.714,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.745 | Acc: 65.013,90.671,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.746 | Acc: 65.054,90.709,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.748 | Acc: 65.071,90.700,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.749 | Acc: 65.075,90.672,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.745 | Acc: 65.106,90.713,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.751 | Acc: 64.990,90.632,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.750 | Acc: 65.004,90.655,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.751 | Acc: 65.026,90.558,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.757 | Acc: 64.877,90.514,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.118 | Acc: 33.594,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.579 | Acc: 34.561,51.600,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.603 | Acc: 33.251,51.829,60.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.632 | Acc: 33.133,51.178,60.182,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.713 | Acc: 68.750,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.740 | Acc: 64.844,89.955,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.728 | Acc: 64.634,90.873,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.725 | Acc: 64.921,90.907,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.729 | Acc: 64.670,90.963,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.716 | Acc: 65.130,90.927,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.717 | Acc: 65.089,91.038,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.727 | Acc: 65.204,90.791,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.737 | Acc: 65.120,90.805,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.741 | Acc: 65.163,90.716,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.744 | Acc: 65.170,90.644,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.746 | Acc: 65.240,90.636,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.747 | Acc: 65.197,90.563,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.749 | Acc: 65.263,90.520,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.747 | Acc: 65.255,90.555,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.750 | Acc: 65.075,90.578,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.751 | Acc: 65.014,90.530,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.752 | Acc: 65.041,90.504,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.756 | Acc: 64.930,90.458,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.754 | Acc: 64.957,90.510,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.043 | Acc: 36.719,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.513 | Acc: 37.165,48.847,60.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.553 | Acc: 36.147,48.723,59.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.586 | Acc: 36.130,47.912,59.874,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.701 | Acc: 62.500,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.749 | Acc: 64.323,91.592,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.761 | Acc: 64.196,91.216,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.744 | Acc: 64.242,91.265,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.762 | Acc: 64.439,90.818,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.762 | Acc: 64.550,90.648,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.761 | Acc: 64.553,90.806,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.749 | Acc: 64.949,90.908,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.747 | Acc: 65.048,90.863,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.754 | Acc: 64.865,90.780,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.758 | Acc: 64.902,90.683,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.752 | Acc: 65.038,90.773,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.752 | Acc: 65.003,90.764,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.753 | Acc: 65.044,90.670,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.752 | Acc: 65.083,90.650,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.757 | Acc: 64.963,90.583,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.761 | Acc: 64.873,90.540,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.763 | Acc: 64.883,90.490,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.765 | Acc: 64.855,90.463,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.763 | Acc: 64.879,90.473,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.855 | Acc: 39.844,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.277 | Acc: 36.458,50.967,62.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.310 | Acc: 35.061,50.896,62.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.336 | Acc: 35.105,50.551,62.718,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 1.832 | Acc: 58.594,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.775 | Acc: 63.839,90.960,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.751 | Acc: 65.053,91.159,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.757 | Acc: 65.049,90.766,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.745 | Acc: 65.297,90.741,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.748 | Acc: 65.215,90.679,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.737 | Acc: 65.444,90.799,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.757 | Acc: 65.132,90.575,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.752 | Acc: 65.057,90.606,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.756 | Acc: 65.077,90.517,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.761 | Acc: 64.976,90.411,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.764 | Acc: 64.985,90.416,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.761 | Acc: 65.080,90.392,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.758 | Acc: 65.014,90.439,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.758 | Acc: 65.091,90.383,99.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.765 | Acc: 64.994,90.365,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.764 | Acc: 64.897,90.379,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.763 | Acc: 64.871,90.403,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.768 | Acc: 64.766,90.333,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.772 | Acc: 64.690,90.260,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.790 | Acc: 24.219,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.153 | Acc: 29.464,55.097,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.207 | Acc: 28.430,54.554,65.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.239 | Acc: 28.471,53.970,65.394,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.548 | Acc: 71.094,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.706 | Acc: 65.588,91.146,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.716 | Acc: 65.149,91.254,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.736 | Acc: 64.946,90.932,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.745 | Acc: 64.805,90.934,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.754 | Acc: 64.658,90.803,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.757 | Acc: 64.921,90.683,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.748 | Acc: 65.160,90.703,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.747 | Acc: 65.232,90.640,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.751 | Acc: 65.189,90.737,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.757 | Acc: 65.026,90.676,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.756 | Acc: 65.056,90.674,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.753 | Acc: 65.093,90.648,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.749 | Acc: 65.113,90.595,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.750 | Acc: 65.111,90.592,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.753 | Acc: 65.018,90.573,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.754 | Acc: 65.007,90.547,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.758 | Acc: 64.965,90.485,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.756 | Acc: 64.987,90.439,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.760 | Acc: 65.006,90.389,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.453 | Acc: 39.844,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.956 | Acc: 36.793,57.254,62.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.978 | Acc: 35.728,57.279,62.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.013 | Acc: 35.822,57.044,62.679,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 1.548 | Acc: 69.531,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.758 | Acc: 65.923,90.960,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.743 | Acc: 64.939,91.292,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.740 | Acc: 65.305,91.253,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.745 | Acc: 65.027,91.204,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.750 | Acc: 64.998,91.043,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.751 | Acc: 65.005,91.051,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.757 | Acc: 64.883,90.874,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.757 | Acc: 64.834,90.916,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.749 | Acc: 64.947,90.975,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.754 | Acc: 64.937,90.854,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.757 | Acc: 64.872,90.784,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.758 | Acc: 64.899,90.680,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.758 | Acc: 64.847,90.649,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.758 | Acc: 64.849,90.617,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.759 | Acc: 64.885,90.594,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.759 | Acc: 64.858,90.606,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.758 | Acc: 64.910,90.607,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.758 | Acc: 64.926,90.614,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.759 | Acc: 64.899,90.568,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.423 | Acc: 42.969,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.967 | Acc: 38.430,52.009,64.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.016 | Acc: 36.757,51.582,63.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.044 | Acc: 36.911,50.884,63.576,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.963 | Acc: 60.938,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.718 | Acc: 65.327,91.592,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.719 | Acc: 65.701,91.311,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.725 | Acc: 65.766,91.329,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 65.683,91.291,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.714 | Acc: 65.756,91.182,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.708 | Acc: 65.709,91.213,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.717 | Acc: 65.486,91.185,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.719 | Acc: 65.547,91.047,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.725 | Acc: 65.414,90.944,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.721 | Acc: 65.411,90.913,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.726 | Acc: 65.279,90.837,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.732 | Acc: 65.314,90.800,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.734 | Acc: 65.257,90.763,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.740 | Acc: 65.197,90.708,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.740 | Acc: 65.205,90.708,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.744 | Acc: 65.167,90.657,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.742 | Acc: 65.236,90.664,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.744 | Acc: 65.274,90.647,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.745 | Acc: 65.276,90.668,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.440 | Acc: 46.094,67.188,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.938 | Acc: 43.862,57.701,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.981 | Acc: 42.569,57.298,58.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.005 | Acc: 42.853,57.339,58.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 1.637 | Acc: 66.406,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.689 | Acc: 65.625,91.629,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.708 | Acc: 65.816,91.330,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.720 | Acc: 65.932,91.124,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.741 | Acc: 65.644,91.020,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.742 | Acc: 65.486,91.004,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.741 | Acc: 65.347,91.090,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.731 | Acc: 65.342,91.124,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.729 | Acc: 65.489,91.120,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.734 | Acc: 65.426,91.022,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.737 | Acc: 65.349,90.862,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.735 | Acc: 65.346,90.798,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.739 | Acc: 65.204,90.748,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.740 | Acc: 65.230,90.700,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.735 | Acc: 65.286,90.728,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.735 | Acc: 65.186,90.729,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.735 | Acc: 65.257,90.764,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.734 | Acc: 65.270,90.760,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.737 | Acc: 65.220,90.673,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.743 | Acc: 65.151,90.596,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.361 | Acc: 30.469,51.562,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.923 | Acc: 29.353,44.792,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.964 | Acc: 28.392,45.103,61.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.987 | Acc: 28.535,44.915,61.206,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.432 | Acc: 67.188,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.763 | Acc: 65.179,91.034,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.720 | Acc: 66.235,91.044,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.716 | Acc: 66.214,91.112,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 65.924,90.847,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.729 | Acc: 66.019,90.834,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.727 | Acc: 65.877,90.903,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.717 | Acc: 65.941,90.963,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.710 | Acc: 66.096,90.984,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.710 | Acc: 66.070,90.957,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.715 | Acc: 65.944,90.979,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.719 | Acc: 65.798,90.950,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.720 | Acc: 65.813,90.894,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.727 | Acc: 65.619,90.832,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.728 | Acc: 65.686,90.856,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.731 | Acc: 65.643,90.799,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.733 | Acc: 65.586,90.749,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.731 | Acc: 65.593,90.714,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.734 | Acc: 65.560,90.683,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.736 | Acc: 65.520,90.646,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.669 | Acc: 35.156,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.171 | Acc: 32.664,49.665,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.211 | Acc: 31.593,49.524,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.237 | Acc: 31.621,49.385,66.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.567 | Acc: 66.406,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.716 | Acc: 65.885,91.183,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.724 | Acc: 65.949,90.854,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.747 | Acc: 65.023,90.753,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.747 | Acc: 64.988,90.635,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.739 | Acc: 64.983,90.741,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.745 | Acc: 64.889,90.670,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.732 | Acc: 64.993,90.752,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.745 | Acc: 64.771,90.712,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.745 | Acc: 64.921,90.746,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.744 | Acc: 65.050,90.765,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.744 | Acc: 65.070,90.791,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.746 | Acc: 65.223,90.657,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.745 | Acc: 65.212,90.589,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.750 | Acc: 65.116,90.569,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.754 | Acc: 65.044,90.534,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.752 | Acc: 65.007,90.576,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.752 | Acc: 65.018,90.538,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.756 | Acc: 64.941,90.530,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.755 | Acc: 64.932,90.508,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.142 | Acc: 39.062,59.375,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.593 | Acc: 36.533,50.186,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.635 | Acc: 35.271,50.457,59.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.665 | Acc: 35.207,50.090,59.670,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.604 | Acc: 69.531,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.655 | Acc: 65.737,91.927,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.649 | Acc: 66.254,92.168,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.660 | Acc: 66.342,92.008,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.675 | Acc: 66.252,91.590,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.685 | Acc: 65.857,91.360,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.703 | Acc: 65.496,91.258,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.709 | Acc: 65.658,91.102,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.718 | Acc: 65.392,91.071,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.723 | Acc: 65.405,90.893,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.726 | Acc: 65.419,90.847,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.729 | Acc: 65.317,90.837,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.733 | Acc: 65.307,90.777,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.733 | Acc: 65.365,90.685,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.733 | Acc: 65.383,90.703,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.735 | Acc: 65.345,90.674,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.738 | Acc: 65.287,90.635,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.738 | Acc: 65.270,90.618,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.738 | Acc: 65.307,90.616,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.739 | Acc: 65.264,90.609,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.646 | Acc: 32.812,49.219,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.143 | Acc: 33.371,41.443,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.192 | Acc: 31.841,40.835,57.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.217 | Acc: 31.878,40.484,57.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.848 | Acc: 67.969,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.769 | Acc: 64.621,91.853,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.766 | Acc: 65.149,91.597,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.756 | Acc: 65.292,91.227,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.745 | Acc: 65.471,91.262,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.749 | Acc: 65.153,91.213,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.748 | Acc: 65.309,91.187,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.738 | Acc: 65.414,91.312,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.735 | Acc: 65.465,91.333,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.732 | Acc: 65.409,91.268,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.738 | Acc: 65.205,91.224,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.744 | Acc: 65.197,91.134,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.738 | Acc: 65.291,91.134,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.743 | Acc: 65.122,91.041,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.737 | Acc: 65.197,91.070,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.742 | Acc: 65.103,90.934,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.739 | Acc: 65.182,90.883,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.743 | Acc: 65.199,90.694,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.745 | Acc: 65.084,90.666,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.743 | Acc: 65.160,90.730,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.790 | Acc: 34.375,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.301 | Acc: 32.292,58.371,62.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.333 | Acc: 30.907,58.155,62.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.360 | Acc: 30.802,57.505,61.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 1.943 | Acc: 61.719,89.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.737 | Acc: 64.844,90.960,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.731 | Acc: 64.768,90.987,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.741 | Acc: 64.344,90.907,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.738 | Acc: 64.535,90.837,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.712 | Acc: 65.200,91.019,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.723 | Acc: 65.102,90.935,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.718 | Acc: 65.160,91.074,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.712 | Acc: 65.261,90.916,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.710 | Acc: 65.319,90.953,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.715 | Acc: 65.357,90.928,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.716 | Acc: 65.247,91.028,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.718 | Acc: 65.194,91.004,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.715 | Acc: 65.254,91.020,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.714 | Acc: 65.272,90.998,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.721 | Acc: 65.145,90.916,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.725 | Acc: 65.133,90.851,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.729 | Acc: 65.100,90.829,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.729 | Acc: 65.142,90.768,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.731 | Acc: 65.104,90.738,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.960 | Acc: 39.844,69.531,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.417 | Acc: 36.756,57.217,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.460 | Acc: 35.347,56.574,55.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.491 | Acc: 35.489,56.391,54.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.859 | Acc: 64.844,83.594,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.688 | Acc: 65.141,90.960,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.717 | Acc: 65.187,91.235,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.690 | Acc: 65.689,91.432,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.702 | Acc: 65.538,91.426,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.710 | Acc: 65.756,91.391,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.714 | Acc: 65.696,91.284,99.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.719 | Acc: 65.326,91.229,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.718 | Acc: 65.329,91.149,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.719 | Acc: 65.349,91.087,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.720 | Acc: 65.252,91.095,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.722 | Acc: 65.257,90.887,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.723 | Acc: 65.288,90.813,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.726 | Acc: 65.206,90.784,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.730 | Acc: 65.161,90.642,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.731 | Acc: 65.158,90.586,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.738 | Acc: 65.007,90.562,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.740 | Acc: 64.967,90.499,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.739 | Acc: 64.928,90.521,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.739 | Acc: 65.018,90.486,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.456 | Acc: 47.656,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.032 | Acc: 43.899,51.823,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.068 | Acc: 43.883,51.944,57.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.101 | Acc: 43.801,51.831,57.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.973 | Acc: 60.156,89.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.666 | Acc: 66.629,92.262,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.680 | Acc: 66.730,91.444,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.689 | Acc: 66.163,91.137,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.702 | Acc: 65.490,91.020,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.717 | Acc: 65.091,90.989,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.715 | Acc: 65.380,91.058,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.707 | Acc: 65.486,91.096,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.707 | Acc: 65.518,91.096,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.702 | Acc: 65.586,91.065,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.711 | Acc: 65.508,91.002,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.719 | Acc: 65.416,90.961,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.720 | Acc: 65.401,90.975,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.718 | Acc: 65.329,91.005,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.724 | Acc: 65.314,90.942,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.725 | Acc: 65.282,90.942,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.728 | Acc: 65.284,90.929,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.728 | Acc: 65.323,90.856,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.733 | Acc: 65.290,90.751,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.731 | Acc: 65.365,90.687,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.928 | Acc: 38.281,57.812,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.391 | Acc: 34.375,49.628,63.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.425 | Acc: 33.003,49.524,62.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.449 | Acc: 32.774,49.103,62.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.837 | Acc: 63.281,85.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.638 | Acc: 67.522,91.592,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.690 | Acc: 66.387,90.854,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.685 | Acc: 66.752,91.112,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.693 | Acc: 66.503,91.011,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.703 | Acc: 66.136,91.004,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.701 | Acc: 65.948,91.006,99.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.708 | Acc: 65.908,90.991,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.706 | Acc: 65.863,91.033,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.716 | Acc: 65.672,90.983,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.726 | Acc: 65.644,90.823,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.737 | Acc: 65.505,90.657,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.739 | Acc: 65.401,90.670,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.739 | Acc: 65.362,90.592,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.744 | Acc: 65.339,90.455,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.747 | Acc: 65.407,90.381,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.746 | Acc: 65.498,90.360,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.743 | Acc: 65.531,90.400,99.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.740 | Acc: 65.556,90.452,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.739 | Acc: 65.549,90.520,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.880 | Acc: 39.062,60.156,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.351 | Acc: 38.542,53.051,59.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.391 | Acc: 37.557,52.096,59.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.409 | Acc: 38.038,51.972,59.029,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.798 | Acc: 65.625,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.632 | Acc: 66.369,93.006,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.623 | Acc: 66.711,92.835,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.634 | Acc: 66.560,92.610,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.647 | Acc: 66.300,92.506,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.640 | Acc: 66.360,92.597,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.638 | Acc: 66.600,92.698,99.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.632 | Acc: 66.550,92.736,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.634 | Acc: 66.460,92.775,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.632 | Acc: 66.449,92.775,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.634 | Acc: 66.515,92.712,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.636 | Acc: 66.484,92.735,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.633 | Acc: 66.536,92.664,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.627 | Acc: 66.580,92.675,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.631 | Acc: 66.442,92.674,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.632 | Acc: 66.479,92.670,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.627 | Acc: 66.579,92.708,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.623 | Acc: 66.674,92.740,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.621 | Acc: 66.737,92.785,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.619 | Acc: 66.825,92.797,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.830 | Acc: 39.844,55.469,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.255 | Acc: 37.574,49.851,64.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.292 | Acc: 35.861,49.600,63.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.317 | Acc: 35.950,49.411,64.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.511 | Acc: 67.969,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.589 | Acc: 66.741,93.973,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.582 | Acc: 67.092,93.941,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.579 | Acc: 66.855,93.981,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.571 | Acc: 67.255,94.184,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.576 | Acc: 67.126,94.083,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.577 | Acc: 67.097,93.982,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.576 | Acc: 67.121,93.900,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.581 | Acc: 67.076,93.779,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.581 | Acc: 67.183,93.759,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.585 | Acc: 67.156,93.664,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.588 | Acc: 67.127,93.736,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.584 | Acc: 67.142,93.773,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.584 | Acc: 67.190,93.723,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.581 | Acc: 67.246,93.764,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.580 | Acc: 67.185,93.779,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.580 | Acc: 67.173,93.735,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.585 | Acc: 67.105,93.718,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.584 | Acc: 67.101,93.733,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.579 | Acc: 67.204,93.719,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.636 | Acc: 30.469,57.812,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.074 | Acc: 28.869,49.740,53.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.110 | Acc: 28.258,49.752,53.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.138 | Acc: 28.445,49.680,53.356,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.647 | Acc: 63.281,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.539 | Acc: 68.118,93.638,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.555 | Acc: 67.264,93.845,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.568 | Acc: 66.957,93.686,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.568 | Acc: 66.580,93.654,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.561 | Acc: 66.747,93.820,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.557 | Acc: 67.116,93.795,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.562 | Acc: 67.093,93.811,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.568 | Acc: 67.052,93.765,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.576 | Acc: 66.933,93.763,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.576 | Acc: 66.989,93.804,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.581 | Acc: 66.880,93.838,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.578 | Acc: 66.928,93.834,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.583 | Acc: 66.715,93.792,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.582 | Acc: 66.784,93.797,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.582 | Acc: 66.759,93.805,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.583 | Acc: 66.732,93.825,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.579 | Acc: 66.883,93.816,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.580 | Acc: 66.941,93.813,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.576 | Acc: 67.009,93.853,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.784 | Acc: 42.188,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.201 | Acc: 38.542,53.534,62.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.244 | Acc: 36.986,53.373,62.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.270 | Acc: 37.116,53.035,61.988,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.504 | Acc: 69.531,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.524 | Acc: 65.923,94.382,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.529 | Acc: 67.226,94.341,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.537 | Acc: 67.508,94.352,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.561 | Acc: 67.737,94.001,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.560 | Acc: 67.675,93.943,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.544 | Acc: 67.846,94.086,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.551 | Acc: 67.708,94.010,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.554 | Acc: 67.566,93.988,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.557 | Acc: 67.472,93.940,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.559 | Acc: 67.355,93.983,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.562 | Acc: 67.350,94.019,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.562 | Acc: 67.282,93.987,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.562 | Acc: 67.292,93.966,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.565 | Acc: 67.282,93.936,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.571 | Acc: 67.252,93.955,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.572 | Acc: 67.224,93.986,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.572 | Acc: 67.188,93.984,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.578 | Acc: 67.103,93.966,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.578 | Acc: 67.132,93.953,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.924 | Acc: 37.500,58.594,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.357 | Acc: 36.198,51.897,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.396 | Acc: 34.928,51.734,61.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.420 | Acc: 34.990,51.345,61.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.822 | Acc: 58.594,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.566 | Acc: 66.778,94.010,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.570 | Acc: 66.806,93.921,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.570 | Acc: 67.072,93.865,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.572 | Acc: 67.313,94.088,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.570 | Acc: 67.242,94.083,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.557 | Acc: 67.452,94.086,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.554 | Acc: 67.326,94.005,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.555 | Acc: 67.343,93.910,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.559 | Acc: 67.231,93.927,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.561 | Acc: 67.094,93.890,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.554 | Acc: 67.283,94.012,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.555 | Acc: 67.285,94.084,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.562 | Acc: 67.167,93.969,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.561 | Acc: 67.235,93.978,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.563 | Acc: 67.211,93.997,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.567 | Acc: 67.180,93.989,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.565 | Acc: 67.183,93.979,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.565 | Acc: 67.209,93.966,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.566 | Acc: 67.179,93.961,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.708 | Acc: 46.094,59.375,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.150 | Acc: 44.568,52.009,58.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.189 | Acc: 43.331,51.677,58.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.217 | Acc: 43.340,51.383,58.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.514 | Acc: 67.188,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.622 | Acc: 65.885,94.382,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.573 | Acc: 66.997,94.569,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.573 | Acc: 67.136,94.480,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.568 | Acc: 67.255,94.358,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.572 | Acc: 67.280,94.137,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.570 | Acc: 67.278,94.118,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.571 | Acc: 67.032,94.077,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.563 | Acc: 67.061,94.061,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.556 | Acc: 67.231,94.151,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.552 | Acc: 67.277,94.146,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.555 | Acc: 67.233,94.104,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.557 | Acc: 67.233,94.129,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.560 | Acc: 67.193,94.046,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.555 | Acc: 67.246,94.081,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.558 | Acc: 67.180,94.046,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.558 | Acc: 67.153,94.074,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.560 | Acc: 67.181,94.110,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.565 | Acc: 67.246,94.085,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.569 | Acc: 67.183,94.000,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.156 | Acc: 34.375,54.688,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.622 | Acc: 31.622,49.963,60.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.665 | Acc: 30.697,49.905,60.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.694 | Acc: 30.712,49.577,60.528,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.754 | Acc: 64.062,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.584 | Acc: 66.667,93.824,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.573 | Acc: 66.978,94.341,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.559 | Acc: 67.162,94.365,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.566 | Acc: 67.004,94.261,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.550 | Acc: 67.273,94.377,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.564 | Acc: 67.375,94.157,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.560 | Acc: 67.420,94.210,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.566 | Acc: 67.406,94.114,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.568 | Acc: 67.386,94.000,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.563 | Acc: 67.382,94.030,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.560 | Acc: 67.449,94.029,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.557 | Acc: 67.369,94.068,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.557 | Acc: 67.304,94.082,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.551 | Acc: 67.418,94.134,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.549 | Acc: 67.483,94.196,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.548 | Acc: 67.463,94.227,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.549 | Acc: 67.456,94.231,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.549 | Acc: 67.410,94.226,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.549 | Acc: 67.470,94.209,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.701 | Acc: 36.719,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.162 | Acc: 36.830,55.580,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.199 | Acc: 35.556,55.602,60.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.224 | Acc: 35.630,54.982,60.131,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.678 | Acc: 62.500,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.568 | Acc: 67.336,94.568,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.564 | Acc: 67.245,94.150,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.574 | Acc: 66.919,94.147,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.570 | Acc: 66.869,94.020,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.562 | Acc: 67.064,94.013,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.557 | Acc: 67.317,94.041,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.555 | Acc: 67.276,94.160,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.554 | Acc: 67.270,94.201,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.550 | Acc: 67.403,94.225,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.550 | Acc: 67.417,94.174,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.547 | Acc: 67.477,94.213,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.548 | Acc: 67.434,94.158,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.552 | Acc: 67.460,94.088,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.553 | Acc: 67.457,94.095,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.556 | Acc: 67.406,94.051,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.556 | Acc: 67.351,94.064,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.555 | Acc: 67.382,94.041,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.555 | Acc: 67.354,94.036,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.555 | Acc: 67.274,94.025,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.017 | Acc: 39.062,59.375,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.476 | Acc: 35.193,53.609,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.510 | Acc: 33.803,53.525,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.540 | Acc: 33.850,52.805,57.108,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.600 | Acc: 65.625,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.498 | Acc: 70.015,94.420,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.531 | Acc: 68.750,94.284,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.521 | Acc: 68.865,94.429,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.531 | Acc: 68.306,94.184,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.527 | Acc: 68.340,94.299,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.545 | Acc: 68.098,94.163,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.543 | Acc: 67.952,94.044,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.541 | Acc: 67.852,94.007,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.541 | Acc: 67.822,94.005,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.539 | Acc: 67.852,94.057,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.541 | Acc: 67.834,94.061,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.539 | Acc: 67.949,94.071,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.537 | Acc: 68.056,94.022,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.542 | Acc: 67.888,94.047,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.546 | Acc: 67.777,93.986,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.547 | Acc: 67.718,93.979,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.547 | Acc: 67.708,93.977,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.548 | Acc: 67.692,93.986,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.549 | Acc: 67.669,94.004,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.384 | Acc: 39.844,57.031,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.874 | Acc: 37.277,51.749,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.909 | Acc: 35.995,52.058,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.936 | Acc: 36.168,51.639,66.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.416 | Acc: 71.094,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.544 | Acc: 67.671,94.978,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.524 | Acc: 67.588,94.970,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.509 | Acc: 67.853,94.915,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.513 | Acc: 68.017,94.956,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.517 | Acc: 67.698,94.872,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.529 | Acc: 67.491,94.854,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.526 | Acc: 67.487,94.836,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.530 | Acc: 67.372,94.861,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.531 | Acc: 67.326,94.738,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.536 | Acc: 67.444,94.656,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.536 | Acc: 67.414,94.662,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.532 | Acc: 67.376,94.690,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.532 | Acc: 67.349,94.636,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.534 | Acc: 67.343,94.623,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.530 | Acc: 67.421,94.643,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.530 | Acc: 67.433,94.597,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.533 | Acc: 67.417,94.492,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.535 | Acc: 67.458,94.462,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.536 | Acc: 67.462,94.449,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.480 | Acc: 29.688,44.531,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.946 | Acc: 29.874,40.179,62.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.978 | Acc: 28.887,39.615,62.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.003 | Acc: 28.753,39.306,62.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.332 | Acc: 73.438,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.529 | Acc: 67.485,94.606,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.522 | Acc: 67.569,94.512,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.534 | Acc: 67.380,94.198,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.536 | Acc: 67.130,94.261,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.553 | Acc: 66.917,93.959,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.553 | Acc: 67.104,93.950,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.543 | Acc: 67.370,94.121,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.544 | Acc: 67.464,94.177,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.540 | Acc: 67.494,94.182,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.542 | Acc: 67.561,94.154,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.540 | Acc: 67.545,94.181,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.543 | Acc: 67.531,94.158,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.544 | Acc: 67.577,94.181,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.539 | Acc: 67.621,94.245,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.540 | Acc: 67.647,94.241,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.540 | Acc: 67.638,94.259,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.543 | Acc: 67.568,94.238,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.543 | Acc: 67.575,94.217,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.542 | Acc: 67.600,94.183,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.917 | Acc: 39.062,57.031,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.337 | Acc: 37.202,49.926,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.374 | Acc: 35.633,50.019,61.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.405 | Acc: 35.528,49.757,61.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.420 | Acc: 69.531,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.509 | Acc: 67.634,95.238,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.556 | Acc: 66.806,94.303,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.553 | Acc: 66.842,94.429,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.537 | Acc: 66.956,94.579,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.539 | Acc: 66.963,94.578,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.536 | Acc: 67.013,94.667,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.535 | Acc: 67.110,94.625,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.537 | Acc: 67.207,94.541,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.544 | Acc: 67.144,94.432,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.544 | Acc: 67.199,94.387,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.545 | Acc: 67.233,94.330,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.537 | Acc: 67.353,94.369,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.540 | Acc: 67.268,94.301,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.539 | Acc: 67.318,94.298,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.543 | Acc: 67.242,94.308,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.542 | Acc: 67.222,94.315,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.545 | Acc: 67.194,94.270,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.542 | Acc: 67.237,94.304,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.543 | Acc: 67.220,94.279,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.720 | Acc: 41.406,56.250,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.203 | Acc: 41.555,48.624,61.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.242 | Acc: 40.206,48.399,61.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.268 | Acc: 40.266,48.220,61.309,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.382 | Acc: 73.438,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.578 | Acc: 67.001,94.345,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.557 | Acc: 67.340,94.360,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.567 | Acc: 67.533,94.288,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.554 | Acc: 67.650,94.242,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.540 | Acc: 67.768,94.493,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.543 | Acc: 67.782,94.460,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.537 | Acc: 68.063,94.537,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.542 | Acc: 67.901,94.565,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.533 | Acc: 68.008,94.510,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.534 | Acc: 67.957,94.457,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.536 | Acc: 67.923,94.425,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.536 | Acc: 67.836,94.466,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.534 | Acc: 67.819,94.459,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.535 | Acc: 67.810,94.445,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.542 | Acc: 67.727,94.412,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.541 | Acc: 67.716,94.393,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.541 | Acc: 67.749,94.385,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.546 | Acc: 67.625,94.367,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.543 | Acc: 67.624,94.371,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.876 | Acc: 39.062,57.812,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.318 | Acc: 37.314,50.856,61.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.352 | Acc: 36.414,50.953,61.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.384 | Acc: 36.194,50.435,61.117,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.678 | Acc: 64.844,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.538 | Acc: 68.601,95.015,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.582 | Acc: 67.492,94.436,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.569 | Acc: 67.751,94.224,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.550 | Acc: 67.921,94.252,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.544 | Acc: 67.868,94.400,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.544 | Acc: 67.530,94.428,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.552 | Acc: 67.481,94.371,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.546 | Acc: 67.517,94.478,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.548 | Acc: 67.235,94.445,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.547 | Acc: 67.335,94.442,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.544 | Acc: 67.520,94.475,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.544 | Acc: 67.525,94.418,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.543 | Acc: 67.583,94.388,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.541 | Acc: 67.585,94.378,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.545 | Acc: 67.577,94.360,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.545 | Acc: 67.521,94.363,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.546 | Acc: 67.531,94.375,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.546 | Acc: 67.512,94.386,99.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.547 | Acc: 67.518,94.339,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.033 | Acc: 34.375,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.489 | Acc: 32.664,51.600,61.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.522 | Acc: 31.631,51.963,61.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.550 | Acc: 31.506,51.332,61.117,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.606 | Acc: 60.938,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.536 | Acc: 67.225,94.271,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.578 | Acc: 67.302,94.322,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.573 | Acc: 67.226,94.288,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.541 | Acc: 67.882,94.618,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.542 | Acc: 67.721,94.593,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.540 | Acc: 67.807,94.409,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.539 | Acc: 67.753,94.465,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.543 | Acc: 67.741,94.483,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.536 | Acc: 67.848,94.531,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.537 | Acc: 67.708,94.539,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.532 | Acc: 67.774,94.478,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.533 | Acc: 67.683,94.444,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.532 | Acc: 67.693,94.441,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.534 | Acc: 67.630,94.426,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.532 | Acc: 67.512,94.482,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.529 | Acc: 67.555,94.531,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.536 | Acc: 67.499,94.458,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.539 | Acc: 67.512,94.397,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.541 | Acc: 67.487,94.408,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.261 | Acc: 35.938,51.562,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.760 | Acc: 31.994,43.564,62.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.790 | Acc: 31.212,43.426,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.822 | Acc: 31.250,43.186,62.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.389 | Acc: 71.875,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.516 | Acc: 68.192,94.420,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.530 | Acc: 68.255,94.226,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.567 | Acc: 67.994,94.173,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.561 | Acc: 67.882,94.358,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.557 | Acc: 67.574,94.423,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.560 | Acc: 67.491,94.338,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.555 | Acc: 67.481,94.343,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.548 | Acc: 67.595,94.381,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.543 | Acc: 67.783,94.436,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.550 | Acc: 67.592,94.380,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.549 | Acc: 67.506,94.397,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.550 | Acc: 67.538,94.418,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.552 | Acc: 67.439,94.385,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.551 | Acc: 67.438,94.323,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.546 | Acc: 67.460,94.326,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.543 | Acc: 67.518,94.361,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.543 | Acc: 67.604,94.371,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.543 | Acc: 67.586,94.399,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.546 | Acc: 67.665,94.363,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.901 | Acc: 38.281,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.399 | Acc: 38.207,49.665,60.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.429 | Acc: 36.852,49.905,60.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.458 | Acc: 36.898,49.360,60.425,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.599 | Acc: 63.281,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.478 | Acc: 67.857,94.531,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.473 | Acc: 69.017,94.360,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.495 | Acc: 68.263,94.454,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.501 | Acc: 68.171,94.483,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.508 | Acc: 67.876,94.554,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.510 | Acc: 68.072,94.589,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.510 | Acc: 68.118,94.592,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.526 | Acc: 67.818,94.526,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.527 | Acc: 67.869,94.454,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.532 | Acc: 67.736,94.446,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.534 | Acc: 67.735,94.496,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.536 | Acc: 67.700,94.492,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.539 | Acc: 67.586,94.510,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.539 | Acc: 67.588,94.540,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.538 | Acc: 67.642,94.461,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.543 | Acc: 67.611,94.422,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.545 | Acc: 67.501,94.430,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.547 | Acc: 67.434,94.451,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.546 | Acc: 67.446,94.439,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.308 | Acc: 28.125,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.732 | Acc: 26.823,48.177,63.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.767 | Acc: 25.724,48.552,62.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.795 | Acc: 25.884,48.156,62.551,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.830 | Acc: 68.750,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.595 | Acc: 66.815,94.159,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.550 | Acc: 67.359,94.188,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.541 | Acc: 67.367,94.390,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.535 | Acc: 67.371,94.416,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.525 | Acc: 67.474,94.524,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.526 | Acc: 67.510,94.518,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.527 | Acc: 67.525,94.459,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.525 | Acc: 67.576,94.400,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.522 | Acc: 67.705,94.436,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.531 | Acc: 67.460,94.352,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.534 | Acc: 67.460,94.390,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.535 | Acc: 67.395,94.389,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.535 | Acc: 67.499,94.423,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.531 | Acc: 67.557,94.437,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.532 | Acc: 67.574,94.479,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.531 | Acc: 67.574,94.475,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.529 | Acc: 67.582,94.481,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.531 | Acc: 67.499,94.499,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.532 | Acc: 67.442,94.509,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.286 | Acc: 32.812,61.719,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.706 | Acc: 31.696,55.692,53.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.743 | Acc: 30.469,55.888,54.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.768 | Acc: 30.392,55.571,54.342,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.485 | Acc: 67.969,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.580 | Acc: 67.039,93.824,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.549 | Acc: 67.435,94.150,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.526 | Acc: 67.866,94.544,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.533 | Acc: 67.650,94.608,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.518 | Acc: 67.976,94.624,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.522 | Acc: 67.969,94.564,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.530 | Acc: 67.786,94.564,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.530 | Acc: 67.867,94.522,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.534 | Acc: 67.865,94.557,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.535 | Acc: 67.856,94.469,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.536 | Acc: 67.820,94.464,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.530 | Acc: 67.917,94.499,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.533 | Acc: 67.876,94.510,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.536 | Acc: 67.824,94.478,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.540 | Acc: 67.701,94.427,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.541 | Acc: 67.630,94.451,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.537 | Acc: 67.611,94.451,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.536 | Acc: 67.614,94.468,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.539 | Acc: 67.571,94.466,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.363 | Acc: 38.281,65.625,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.821 | Acc: 35.751,58.222,61.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.862 | Acc: 34.432,58.498,61.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.885 | Acc: 34.375,58.607,61.437,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.465 | Acc: 75.000,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.508 | Acc: 67.820,94.494,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.511 | Acc: 68.197,95.027,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.496 | Acc: 68.430,95.108,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.523 | Acc: 67.863,95.149,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.535 | Acc: 67.559,94.980,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.536 | Acc: 67.265,94.964,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.534 | Acc: 67.553,94.808,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.543 | Acc: 67.319,94.653,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.544 | Acc: 67.270,94.583,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.547 | Acc: 67.269,94.605,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.541 | Acc: 67.375,94.644,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.540 | Acc: 67.379,94.619,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.537 | Acc: 67.472,94.600,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.532 | Acc: 67.474,94.565,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.530 | Acc: 67.509,94.599,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.534 | Acc: 67.450,94.509,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.530 | Acc: 67.570,94.508,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 67.545,94.447,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.531 | Acc: 67.563,94.466,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.273 | Acc: 34.375,53.125,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.707 | Acc: 32.068,46.615,60.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.747 | Acc: 31.059,46.284,60.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.773 | Acc: 31.071,45.927,60.015,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.377 | Acc: 71.875,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.521 | Acc: 68.713,95.312,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.530 | Acc: 68.579,95.027,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.528 | Acc: 68.276,95.095,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.526 | Acc: 67.930,94.888,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.534 | Acc: 68.015,94.701,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.537 | Acc: 68.027,94.635,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.532 | Acc: 68.041,94.648,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.534 | Acc: 68.017,94.512,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.538 | Acc: 67.973,94.492,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.546 | Acc: 67.751,94.461,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.552 | Acc: 67.640,94.443,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.551 | Acc: 67.661,94.479,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.552 | Acc: 67.681,94.462,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.548 | Acc: 67.788,94.492,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.545 | Acc: 67.826,94.523,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.546 | Acc: 67.779,94.509,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.546 | Acc: 67.689,94.524,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.545 | Acc: 67.666,94.549,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.546 | Acc: 67.639,94.542,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.160 | Acc: 37.500,53.125,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.593 | Acc: 36.310,48.512,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.626 | Acc: 34.585,48.590,59.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.655 | Acc: 34.465,48.258,59.375,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.564 | Acc: 64.844,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.492 | Acc: 67.225,94.940,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.494 | Acc: 67.893,95.332,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.502 | Acc: 68.148,95.197,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.506 | Acc: 68.171,94.927,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.514 | Acc: 68.239,94.771,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.518 | Acc: 68.195,94.706,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.525 | Acc: 67.891,94.725,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.522 | Acc: 67.930,94.740,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.522 | Acc: 67.809,94.725,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.523 | Acc: 67.875,94.733,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.521 | Acc: 67.813,94.747,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.521 | Acc: 67.823,94.677,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.525 | Acc: 67.729,94.654,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.523 | Acc: 67.766,94.637,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.522 | Acc: 67.704,94.632,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.523 | Acc: 67.635,94.621,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.521 | Acc: 67.625,94.621,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.522 | Acc: 67.664,94.609,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.527 | Acc: 67.612,94.556,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.005 | Acc: 32.812,64.844,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.453 | Acc: 30.878,55.804,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.491 | Acc: 30.107,55.831,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.519 | Acc: 29.982,55.353,57.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.350 | Acc: 71.094,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.481 | Acc: 69.271,94.940,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.517 | Acc: 68.083,94.703,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.536 | Acc: 67.341,94.647,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.508 | Acc: 67.795,94.715,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.511 | Acc: 67.628,94.794,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.512 | Acc: 67.601,94.764,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.512 | Acc: 67.725,94.747,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.517 | Acc: 67.585,94.750,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.523 | Acc: 67.520,94.656,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.521 | Acc: 67.669,94.663,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.525 | Acc: 67.605,94.648,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.521 | Acc: 67.606,94.671,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.522 | Acc: 67.598,94.672,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.528 | Acc: 67.491,94.631,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.528 | Acc: 67.507,94.648,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.530 | Acc: 67.499,94.621,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.528 | Acc: 67.547,94.630,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.527 | Acc: 67.508,94.618,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.527 | Acc: 67.448,94.576,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.631 | Acc: 28.906,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.003 | Acc: 26.637,47.135,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.036 | Acc: 25.800,46.818,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.063 | Acc: 25.909,46.529,57.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.467 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.580 | Acc: 68.192,94.271,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.565 | Acc: 68.064,94.493,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.531 | Acc: 67.930,94.711,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.529 | Acc: 67.872,94.676,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.533 | Acc: 67.930,94.678,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.530 | Acc: 67.911,94.718,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.530 | Acc: 67.658,94.686,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.525 | Acc: 67.765,94.788,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.529 | Acc: 67.766,94.713,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.528 | Acc: 67.697,94.753,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.535 | Acc: 67.622,94.701,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.534 | Acc: 67.531,94.774,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.532 | Acc: 67.538,94.786,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.531 | Acc: 67.563,94.762,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.529 | Acc: 67.629,94.710,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.529 | Acc: 67.618,94.689,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.529 | Acc: 67.625,94.689,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 67.495,94.629,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.533 | Acc: 67.495,94.603,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.162 | Acc: 38.281,62.500,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.592 | Acc: 32.812,54.129,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.633 | Acc: 31.593,54.364,57.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.661 | Acc: 31.660,53.893,57.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.430 | Acc: 75.000,94.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 68.824,94.754,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.491 | Acc: 68.216,94.989,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.504 | Acc: 67.777,95.120,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.495 | Acc: 68.113,95.120,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.511 | Acc: 67.853,94.903,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.513 | Acc: 67.769,94.932,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.508 | Acc: 67.775,94.908,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.513 | Acc: 67.755,94.740,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.520 | Acc: 67.740,94.751,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.519 | Acc: 67.852,94.788,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.518 | Acc: 68.004,94.821,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.522 | Acc: 67.878,94.742,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.521 | Acc: 67.903,94.771,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.523 | Acc: 67.780,94.768,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.525 | Acc: 67.790,94.762,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.529 | Acc: 67.738,94.682,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.531 | Acc: 67.714,94.671,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 67.646,94.668,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.533 | Acc: 67.569,94.615,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.569 | Acc: 36.719,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.964 | Acc: 34.784,53.869,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.013 | Acc: 33.651,53.887,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.036 | Acc: 33.543,53.291,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.438 | Acc: 68.750,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.512 | Acc: 67.411,95.424,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.482 | Acc: 68.178,95.312,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.511 | Acc: 67.789,95.044,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.518 | Acc: 67.622,94.927,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.517 | Acc: 67.768,94.763,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 67.943,94.790,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 68.024,94.742,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.509 | Acc: 67.872,94.701,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.516 | Acc: 67.710,94.661,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.514 | Acc: 67.887,94.636,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.518 | Acc: 67.817,94.694,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.519 | Acc: 67.777,94.648,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.518 | Acc: 67.825,94.648,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.523 | Acc: 67.727,94.615,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.526 | Acc: 67.639,94.594,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.529 | Acc: 67.533,94.599,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.529 | Acc: 67.506,94.570,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.530 | Acc: 67.462,94.544,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.530 | Acc: 67.468,94.562,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.172 | Acc: 45.312,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.643 | Acc: 43.787,55.469,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.684 | Acc: 42.721,55.335,64.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.711 | Acc: 42.508,55.033,64.524,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.478 | Acc: 71.875,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.536 | Acc: 67.188,94.308,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.493 | Acc: 68.731,94.627,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.501 | Acc: 67.713,94.544,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.501 | Acc: 67.757,94.570,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.500 | Acc: 67.814,94.593,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.498 | Acc: 68.085,94.673,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 68.035,94.576,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.510 | Acc: 67.964,94.619,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.513 | Acc: 68.008,94.570,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.514 | Acc: 67.988,94.613,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.521 | Acc: 67.831,94.584,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.523 | Acc: 67.836,94.557,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.520 | Acc: 67.900,94.567,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.521 | Acc: 67.908,94.503,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.516 | Acc: 67.927,94.544,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.523 | Acc: 67.781,94.522,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.524 | Acc: 67.783,94.515,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.520 | Acc: 67.835,94.531,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.520 | Acc: 67.782,94.562,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.585 | Acc: 40.625,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.055 | Acc: 37.277,53.832,62.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.094 | Acc: 35.785,53.754,62.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.120 | Acc: 35.809,53.356,62.244,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.147 | Acc: 73.438,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.545 | Acc: 67.225,94.680,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.559 | Acc: 67.283,95.046,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.556 | Acc: 67.226,94.685,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.553 | Acc: 67.255,94.715,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.549 | Acc: 67.342,94.647,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.552 | Acc: 67.271,94.731,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.555 | Acc: 67.182,94.692,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.547 | Acc: 67.357,94.725,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.546 | Acc: 67.395,94.596,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.543 | Acc: 67.335,94.644,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.543 | Acc: 67.400,94.634,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.541 | Acc: 67.431,94.616,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.539 | Acc: 67.484,94.609,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.542 | Acc: 67.466,94.615,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.535 | Acc: 67.569,94.645,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.535 | Acc: 67.560,94.660,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.535 | Acc: 67.529,94.627,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 67.599,94.639,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.533 | Acc: 67.573,94.605,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.356 | Acc: 39.062,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.761 | Acc: 37.351,56.473,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.799 | Acc: 35.785,56.250,64.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.820 | Acc: 35.861,55.891,64.331,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.467 | Acc: 68.750,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.593 | Acc: 65.960,94.420,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.580 | Acc: 66.444,94.531,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.554 | Acc: 67.123,94.826,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.556 | Acc: 66.937,94.763,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.555 | Acc: 67.048,94.670,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.561 | Acc: 66.710,94.583,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.547 | Acc: 67.104,94.542,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.533 | Acc: 67.391,94.580,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.536 | Acc: 67.304,94.518,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.546 | Acc: 67.141,94.465,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.544 | Acc: 67.142,94.464,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.543 | Acc: 67.178,94.486,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.544 | Acc: 67.238,94.486,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.543 | Acc: 67.168,94.506,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.541 | Acc: 67.213,94.498,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.541 | Acc: 67.217,94.526,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.538 | Acc: 67.316,94.598,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.537 | Acc: 67.311,94.566,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.538 | Acc: 67.253,94.550,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.973 | Acc: 31.250,53.906,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.379 | Acc: 29.576,49.888,64.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.422 | Acc: 28.544,50.038,64.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.446 | Acc: 28.586,49.501,64.306,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.480 | Acc: 71.094,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.486 | Acc: 68.118,94.568,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.509 | Acc: 67.797,94.284,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.533 | Acc: 67.444,94.237,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.524 | Acc: 67.631,94.338,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.525 | Acc: 67.652,94.261,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.527 | Acc: 67.633,94.292,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.522 | Acc: 67.686,94.376,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.522 | Acc: 67.615,94.323,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.523 | Acc: 67.731,94.298,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.521 | Acc: 67.759,94.294,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.524 | Acc: 67.672,94.316,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.529 | Acc: 67.521,94.350,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.526 | Acc: 67.583,94.352,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.528 | Acc: 67.630,94.337,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.530 | Acc: 67.639,94.360,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.530 | Acc: 67.650,94.361,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.530 | Acc: 67.680,94.385,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.530 | Acc: 67.694,94.356,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.527 | Acc: 67.758,94.382,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.134 | Acc: 32.031,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.575 | Acc: 30.432,50.186,61.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.610 | Acc: 29.421,50.114,61.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.637 | Acc: 29.470,49.590,61.066,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.472 | Acc: 69.531,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.526 | Acc: 67.374,95.350,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.519 | Acc: 67.264,94.855,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.514 | Acc: 67.149,94.800,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.519 | Acc: 67.139,95.004,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.518 | Acc: 67.249,94.957,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.532 | Acc: 66.962,94.873,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.524 | Acc: 67.188,94.936,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.521 | Acc: 67.231,94.890,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.522 | Acc: 67.196,94.898,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.519 | Acc: 67.277,94.877,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.524 | Acc: 67.212,94.828,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.531 | Acc: 67.097,94.791,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.532 | Acc: 67.059,94.804,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.528 | Acc: 67.096,94.804,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.528 | Acc: 67.099,94.780,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.529 | Acc: 67.078,94.750,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.527 | Acc: 67.226,94.696,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.529 | Acc: 67.192,94.702,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.526 | Acc: 67.304,94.706,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.254 | Acc: 31.250,60.156,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.673 | Acc: 31.101,52.493,57.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.705 | Acc: 29.973,52.744,58.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.728 | Acc: 29.905,52.382,58.056,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.417 | Acc: 73.438,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.527 | Acc: 68.229,94.010,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.536 | Acc: 67.626,94.417,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.549 | Acc: 67.469,94.390,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.543 | Acc: 67.708,94.454,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.546 | Acc: 67.536,94.446,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.548 | Acc: 67.394,94.402,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.546 | Acc: 67.376,94.398,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.542 | Acc: 67.435,94.386,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.539 | Acc: 67.490,94.315,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.534 | Acc: 67.611,94.376,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.529 | Acc: 67.693,94.482,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.529 | Acc: 67.706,94.483,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.527 | Acc: 67.663,94.510,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.527 | Acc: 67.727,94.487,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.525 | Acc: 67.712,94.472,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.522 | Acc: 67.759,94.495,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.523 | Acc: 67.802,94.476,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.529 | Acc: 67.681,94.451,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.528 | Acc: 67.688,94.421,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.223 | Acc: 34.375,50.781,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.675 | Acc: 33.371,45.312,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.713 | Acc: 32.393,45.122,60.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.740 | Acc: 32.364,44.890,60.579,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.363 | Acc: 67.188,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.505 | Acc: 67.374,94.978,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.554 | Acc: 66.235,94.855,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.558 | Acc: 66.291,94.749,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.549 | Acc: 66.580,94.772,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.549 | Acc: 66.592,94.717,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.538 | Acc: 67.065,94.725,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.536 | Acc: 67.271,94.792,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.531 | Acc: 67.285,94.808,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.528 | Acc: 67.442,94.877,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.529 | Acc: 67.452,94.842,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.529 | Acc: 67.371,94.842,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.531 | Acc: 67.359,94.791,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.528 | Acc: 67.448,94.831,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.526 | Acc: 67.496,94.806,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.523 | Acc: 67.605,94.806,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.528 | Acc: 67.514,94.738,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.527 | Acc: 67.575,94.701,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.526 | Acc: 67.696,94.745,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.530 | Acc: 67.678,94.671,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.337 | Acc: 26.562,63.281,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.771 | Acc: 27.455,53.832,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.807 | Acc: 26.753,53.925,57.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.833 | Acc: 26.883,53.586,56.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.660 | Acc: 63.281,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.518 | Acc: 67.076,94.680,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.492 | Acc: 67.492,94.627,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 67.572,94.429,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.521 | Acc: 67.660,94.551,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.515 | Acc: 67.814,94.701,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.519 | Acc: 67.517,94.660,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.527 | Acc: 67.426,94.614,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.523 | Acc: 67.493,94.580,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.527 | Acc: 67.416,94.561,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.533 | Acc: 67.401,94.520,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.534 | Acc: 67.255,94.531,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.530 | Acc: 67.327,94.570,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.529 | Acc: 67.328,94.549,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.526 | Acc: 67.371,94.540,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.526 | Acc: 67.424,94.555,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.526 | Acc: 67.475,94.556,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.525 | Acc: 67.506,94.529,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.525 | Acc: 67.469,94.464,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.527 | Acc: 67.473,94.429,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.733 | Acc: 39.844,62.500,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.229 | Acc: 36.644,53.571,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.264 | Acc: 35.061,53.735,61.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.290 | Acc: 34.810,53.407,61.642,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.849 | Acc: 61.719,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.524 | Acc: 68.192,94.122,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.491 | Acc: 68.521,94.627,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 68.315,94.813,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.502 | Acc: 67.747,94.695,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.515 | Acc: 67.481,94.817,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.521 | Acc: 67.246,94.764,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.529 | Acc: 67.149,94.792,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.539 | Acc: 67.037,94.672,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.534 | Acc: 67.140,94.730,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.528 | Acc: 67.261,94.768,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.530 | Acc: 67.276,94.683,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.526 | Acc: 67.395,94.693,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.526 | Acc: 67.412,94.741,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.528 | Acc: 67.463,94.640,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.528 | Acc: 67.481,94.573,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.530 | Acc: 67.465,94.570,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.532 | Acc: 67.403,94.570,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 67.404,94.596,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.532 | Acc: 67.388,94.591,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.872 | Acc: 42.188,54.688,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.347 | Acc: 40.067,46.912,60.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.377 | Acc: 38.700,47.389,60.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.404 | Acc: 39.024,47.195,60.041,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 1.265 | Acc: 69.531,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.468 | Acc: 68.787,94.680,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.503 | Acc: 68.178,94.646,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.517 | Acc: 67.738,94.851,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.530 | Acc: 67.197,94.657,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.536 | Acc: 67.095,94.740,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.541 | Acc: 67.291,94.660,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.534 | Acc: 67.320,94.686,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.531 | Acc: 67.241,94.725,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.530 | Acc: 67.235,94.674,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.522 | Acc: 67.324,94.691,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.527 | Acc: 67.290,94.687,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.528 | Acc: 67.282,94.684,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.528 | Acc: 67.286,94.693,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.527 | Acc: 67.288,94.695,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.530 | Acc: 67.271,94.700,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.527 | Acc: 67.370,94.711,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.527 | Acc: 67.380,94.712,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.527 | Acc: 67.428,94.691,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.532 | Acc: 67.360,94.656,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.162 | Acc: 30.469,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.650 | Acc: 30.134,51.935,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.686 | Acc: 28.925,52.248,59.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.711 | Acc: 29.111,51.742,59.196,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.361 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.458 | Acc: 69.010,94.568,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.485 | Acc: 68.864,94.950,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.483 | Acc: 69.096,94.890,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.487 | Acc: 68.904,94.763,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.498 | Acc: 68.742,94.756,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.508 | Acc: 68.692,94.609,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.518 | Acc: 68.279,94.603,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.517 | Acc: 68.250,94.589,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.513 | Acc: 68.116,94.674,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.509 | Acc: 68.183,94.702,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.501 | Acc: 68.283,94.715,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 68.196,94.739,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.500 | Acc: 68.241,94.783,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.504 | Acc: 68.211,94.820,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.508 | Acc: 68.002,94.773,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.509 | Acc: 68.066,94.738,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.510 | Acc: 68.070,94.698,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.511 | Acc: 68.062,94.696,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.514 | Acc: 68.041,94.662,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.451 | Acc: 41.406,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.915 | Acc: 37.686,54.464,64.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.952 | Acc: 36.357,54.573,64.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.974 | Acc: 36.603,54.367,64.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.566 | Acc: 65.625,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.474 | Acc: 68.415,94.754,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.516 | Acc: 67.835,94.950,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.529 | Acc: 67.328,94.851,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.518 | Acc: 67.612,94.869,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.528 | Acc: 67.435,94.670,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.530 | Acc: 67.536,94.686,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.525 | Acc: 67.531,94.781,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.523 | Acc: 67.600,94.803,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.517 | Acc: 67.723,94.820,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.521 | Acc: 67.584,94.823,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.525 | Acc: 67.502,94.796,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.518 | Acc: 67.690,94.797,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.517 | Acc: 67.807,94.840,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.518 | Acc: 67.769,94.857,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.514 | Acc: 67.857,94.832,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.519 | Acc: 67.735,94.765,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.517 | Acc: 67.797,94.747,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.519 | Acc: 67.819,94.709,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.519 | Acc: 67.780,94.681,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.813 | Acc: 42.188,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.293 | Acc: 40.551,46.801,61.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.330 | Acc: 39.215,46.780,61.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.353 | Acc: 39.447,46.401,60.976,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.720 | Acc: 65.625,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.531 | Acc: 67.299,95.275,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.491 | Acc: 67.893,95.370,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.529 | Acc: 67.111,94.903,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.526 | Acc: 67.361,95.023,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.522 | Acc: 67.528,94.895,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.530 | Acc: 67.362,94.912,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.538 | Acc: 67.210,94.875,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.540 | Acc: 67.124,94.856,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.530 | Acc: 67.438,94.907,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.527 | Acc: 67.510,94.866,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.522 | Acc: 67.665,94.864,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.516 | Acc: 67.836,94.901,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.513 | Acc: 67.894,94.923,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.511 | Acc: 68.044,94.937,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.509 | Acc: 68.031,94.960,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.510 | Acc: 68.022,94.952,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.512 | Acc: 68.001,94.971,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.511 | Acc: 68.008,94.977,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.510 | Acc: 67.997,94.991,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.738 | Acc: 39.062,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.172 | Acc: 35.119,55.841,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.207 | Acc: 33.861,56.136,61.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.231 | Acc: 34.016,55.763,61.463,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.553 | Acc: 71.875,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.540 | Acc: 68.080,95.201,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.507 | Acc: 68.579,95.084,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.519 | Acc: 67.687,95.082,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.514 | Acc: 67.901,94.927,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.499 | Acc: 68.263,95.073,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.497 | Acc: 68.279,95.022,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.503 | Acc: 68.146,95.019,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.499 | Acc: 68.187,95.026,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.496 | Acc: 68.167,95.127,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.502 | Acc: 68.058,95.099,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.503 | Acc: 68.092,95.033,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 68.121,95.056,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.503 | Acc: 68.187,95.142,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.502 | Acc: 68.122,95.140,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.503 | Acc: 68.008,95.133,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 67.993,95.086,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 67.939,95.074,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.501 | Acc: 68.016,95.064,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.504 | Acc: 67.977,95.071,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.451 | Acc: 38.281,60.156,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.884 | Acc: 35.231,53.013,50.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.914 | Acc: 33.632,52.877,50.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.942 | Acc: 33.824,52.587,50.307,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.312 | Acc: 72.656,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.481 | Acc: 69.308,94.903,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.489 | Acc: 69.550,95.198,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.498 | Acc: 69.006,95.261,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.497 | Acc: 68.760,95.312,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 68.866,95.312,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.492 | Acc: 68.750,95.280,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.500 | Acc: 68.501,95.274,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.503 | Acc: 68.469,95.162,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.499 | Acc: 68.474,95.161,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.498 | Acc: 68.591,95.126,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.508 | Acc: 68.474,95.058,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.510 | Acc: 68.410,95.037,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.510 | Acc: 68.379,95.004,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.513 | Acc: 68.277,94.926,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.512 | Acc: 68.358,94.952,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.514 | Acc: 68.254,94.947,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.512 | Acc: 68.276,94.999,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.511 | Acc: 68.244,94.973,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.509 | Acc: 68.211,94.999,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.253 | Acc: 35.156,55.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.675 | Acc: 32.812,47.396,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.707 | Acc: 31.822,47.675,60.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.735 | Acc: 31.839,47.400,60.528,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.932 | Acc: 58.594,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.474 | Acc: 69.085,95.015,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 69.207,95.027,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.470 | Acc: 69.275,95.018,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.487 | Acc: 68.538,94.927,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.497 | Acc: 68.472,95.042,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.498 | Acc: 68.175,94.977,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.496 | Acc: 68.174,94.930,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.498 | Acc: 68.187,94.939,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.502 | Acc: 68.137,94.846,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.506 | Acc: 68.132,94.873,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.514 | Acc: 67.986,94.821,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.510 | Acc: 68.014,94.859,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.508 | Acc: 68.121,94.890,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.506 | Acc: 68.138,94.937,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.507 | Acc: 68.179,94.947,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 68.151,95.006,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 68.246,95.015,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 68.164,95.033,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.500 | Acc: 68.188,95.077,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.674 | Acc: 39.062,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.154 | Acc: 36.719,53.051,63.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.191 | Acc: 35.175,53.258,63.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.215 | Acc: 35.310,52.792,63.755,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.401 | Acc: 64.844,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.536 | Acc: 68.304,94.940,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.484 | Acc: 68.216,95.122,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.476 | Acc: 68.353,95.031,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.505 | Acc: 68.162,94.821,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.497 | Acc: 68.085,94.833,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.492 | Acc: 68.143,94.925,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.483 | Acc: 68.262,94.997,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.482 | Acc: 68.507,95.016,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.485 | Acc: 68.513,95.032,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.491 | Acc: 68.381,94.998,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.489 | Acc: 68.506,95.054,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.487 | Acc: 68.591,95.105,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.485 | Acc: 68.460,95.076,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 68.494,95.007,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.489 | Acc: 68.439,94.960,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.494 | Acc: 68.344,94.908,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.493 | Acc: 68.331,94.992,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.496 | Acc: 68.177,94.979,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.496 | Acc: 68.137,94.937,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.820 | Acc: 39.844,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.300 | Acc: 36.496,53.720,60.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.339 | Acc: 35.080,53.678,60.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.365 | Acc: 35.207,53.420,59.964,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.385 | Acc: 73.438,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.507 | Acc: 67.411,95.499,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.510 | Acc: 67.893,95.065,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.525 | Acc: 67.751,94.928,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.510 | Acc: 67.824,95.004,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.505 | Acc: 67.613,94.933,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 67.710,94.944,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 67.814,94.908,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.499 | Acc: 67.809,94.973,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.498 | Acc: 67.762,94.902,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.497 | Acc: 67.778,94.955,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.502 | Acc: 67.806,94.885,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.505 | Acc: 67.790,94.949,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.500 | Acc: 67.897,94.932,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.500 | Acc: 67.874,94.990,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 67.805,94.988,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 67.828,94.960,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.504 | Acc: 67.783,94.905,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.501 | Acc: 67.867,94.914,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.501 | Acc: 67.854,94.937,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.686 | Acc: 30.469,55.469,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.141 | Acc: 27.046,47.991,53.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.172 | Acc: 26.543,47.999,53.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.197 | Acc: 26.486,47.387,53.112,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 1.611 | Acc: 66.406,89.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.491 | Acc: 68.155,94.717,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.511 | Acc: 68.445,95.103,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.522 | Acc: 67.994,95.044,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.516 | Acc: 68.007,95.110,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.516 | Acc: 68.154,95.065,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.513 | Acc: 67.956,95.132,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.500 | Acc: 68.107,95.135,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.506 | Acc: 68.202,95.016,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.503 | Acc: 68.198,94.993,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.507 | Acc: 68.027,95.040,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 68.085,95.033,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.508 | Acc: 67.949,95.056,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 67.981,95.025,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.507 | Acc: 67.974,95.059,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.507 | Acc: 67.956,95.102,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.507 | Acc: 67.974,95.086,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.510 | Acc: 67.962,95.074,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.510 | Acc: 67.938,95.085,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.508 | Acc: 67.944,95.126,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.959 | Acc: 36.719,61.719,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.418 | Acc: 33.185,52.865,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.452 | Acc: 32.165,52.973,58.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.476 | Acc: 32.121,52.754,58.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.269 | Acc: 71.094,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.457 | Acc: 67.634,94.940,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.453 | Acc: 68.255,95.065,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.453 | Acc: 68.558,95.108,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.467 | Acc: 68.258,95.158,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.468 | Acc: 68.270,95.258,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.478 | Acc: 68.027,95.248,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.495 | Acc: 67.908,95.207,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.494 | Acc: 67.838,95.235,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.501 | Acc: 67.805,95.118,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.511 | Acc: 67.607,95.064,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.510 | Acc: 67.590,94.998,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.506 | Acc: 67.765,94.985,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.500 | Acc: 67.930,94.974,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.500 | Acc: 67.944,94.954,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.505 | Acc: 67.878,94.975,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.506 | Acc: 67.896,94.986,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.508 | Acc: 67.930,94.953,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.507 | Acc: 67.984,94.953,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 67.997,94.974,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.209 | Acc: 35.938,61.719,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.633 | Acc: 33.817,53.981,53.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.669 | Acc: 32.431,53.773,53.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.697 | Acc: 32.441,53.458,53.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.710 | Acc: 64.062,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.480 | Acc: 69.345,95.238,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 68.902,95.027,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.487 | Acc: 68.468,95.005,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.492 | Acc: 68.422,94.965,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.481 | Acc: 68.773,94.988,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.476 | Acc: 68.763,94.944,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 68.329,94.975,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.488 | Acc: 68.289,94.973,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.491 | Acc: 68.141,94.993,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 68.284,94.998,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.493 | Acc: 68.252,94.973,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.494 | Acc: 68.257,94.953,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.499 | Acc: 68.226,94.920,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 68.202,94.862,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.494 | Acc: 68.241,94.871,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.493 | Acc: 68.254,94.848,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.493 | Acc: 68.207,94.923,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.497 | Acc: 68.073,94.893,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.496 | Acc: 68.096,94.919,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.171 | Acc: 31.250,59.375,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.617 | Acc: 29.167,52.381,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.653 | Acc: 28.106,52.439,59.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.679 | Acc: 28.330,52.075,59.541,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.484 | Acc: 67.969,98.438,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.457 | Acc: 68.601,95.387,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.505 | Acc: 68.464,94.741,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.477 | Acc: 68.929,94.877,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.499 | Acc: 68.490,95.042,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.501 | Acc: 68.363,95.096,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.494 | Acc: 68.447,95.035,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.494 | Acc: 68.445,95.107,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.502 | Acc: 68.231,95.104,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.501 | Acc: 68.249,95.075,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.504 | Acc: 68.132,95.033,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.503 | Acc: 68.237,95.069,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.505 | Acc: 68.215,95.079,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.504 | Acc: 68.178,95.091,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.506 | Acc: 68.105,95.093,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.503 | Acc: 68.093,95.136,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 68.005,95.130,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.505 | Acc: 68.028,95.122,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.506 | Acc: 67.971,95.072,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 67.965,95.027,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.436 | Acc: 40.625,53.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.899 | Acc: 35.863,45.126,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.930 | Acc: 34.489,44.931,53.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.964 | Acc: 34.554,44.582,53.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.295 | Acc: 71.875,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.524 | Acc: 67.969,95.275,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.479 | Acc: 68.102,95.217,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.481 | Acc: 68.122,95.415,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.494 | Acc: 67.969,95.081,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 68.038,95.011,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.478 | Acc: 68.175,94.977,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.485 | Acc: 68.080,95.047,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.488 | Acc: 68.197,95.055,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.490 | Acc: 68.154,95.066,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.495 | Acc: 68.116,95.017,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.488 | Acc: 68.259,95.016,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.492 | Acc: 68.241,95.001,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.500 | Acc: 68.160,94.932,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.493 | Acc: 68.247,94.998,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.497 | Acc: 68.223,94.998,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.497 | Acc: 68.193,94.967,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 68.173,94.932,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.499 | Acc: 68.185,94.910,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 68.198,94.888,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.285 | Acc: 29.688,57.812,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.770 | Acc: 28.646,49.070,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.804 | Acc: 27.649,49.066,59.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.828 | Acc: 27.561,48.566,59.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.729 | Acc: 64.062,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.540 | Acc: 67.522,94.792,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.515 | Acc: 67.607,94.798,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.511 | Acc: 67.815,94.647,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.528 | Acc: 67.294,94.695,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.531 | Acc: 67.288,94.663,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.523 | Acc: 67.439,94.757,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.511 | Acc: 67.775,94.736,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.513 | Acc: 67.794,94.725,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.516 | Acc: 67.757,94.687,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 67.693,94.710,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.514 | Acc: 67.732,94.750,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.513 | Acc: 67.777,94.719,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.515 | Acc: 67.765,94.732,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.512 | Acc: 67.863,94.768,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.510 | Acc: 67.922,94.796,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.511 | Acc: 67.840,94.818,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.510 | Acc: 67.907,94.857,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.510 | Acc: 67.993,94.875,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 67.967,94.909,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.653 | Acc: 42.969,54.688,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.154 | Acc: 38.467,49.516,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.194 | Acc: 37.271,49.295,63.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.222 | Acc: 37.346,49.155,63.909,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.222 | Acc: 75.000,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.527 | Acc: 67.894,95.499,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.551 | Acc: 67.092,95.389,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.544 | Acc: 67.098,95.287,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.538 | Acc: 67.274,95.168,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.527 | Acc: 67.698,95.135,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.521 | Acc: 67.833,95.054,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.513 | Acc: 67.847,94.963,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.509 | Acc: 67.872,95.026,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.499 | Acc: 67.986,95.015,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.495 | Acc: 68.023,95.075,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 68.047,95.058,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.500 | Acc: 67.946,95.047,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.506 | Acc: 67.903,94.989,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.511 | Acc: 67.805,94.915,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.511 | Acc: 67.813,94.957,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 68.022,95.025,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 68.143,95.003,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 68.070,95.046,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 68.028,95.013,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.319 | Acc: 26.562,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.763 | Acc: 25.744,55.171,57.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.793 | Acc: 25.057,55.373,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.821 | Acc: 24.949,54.905,57.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.512 | Acc: 69.531,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.512 | Acc: 68.750,94.457,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.512 | Acc: 67.988,94.684,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.495 | Acc: 67.969,95.005,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.490 | Acc: 67.785,95.014,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.502 | Acc: 67.420,94.964,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 67.323,94.983,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 67.542,94.963,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.498 | Acc: 67.556,94.958,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.502 | Acc: 67.550,94.980,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.501 | Acc: 67.611,95.002,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.501 | Acc: 67.615,95.040,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.501 | Acc: 67.700,95.018,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 67.684,95.007,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 67.771,95.029,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.506 | Acc: 67.800,95.014,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.512 | Acc: 67.721,94.964,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.513 | Acc: 67.678,94.955,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.510 | Acc: 67.763,94.979,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.508 | Acc: 67.758,94.970,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.500 | Acc: 32.031,56.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.931 | Acc: 28.757,49.777,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.963 | Acc: 27.992,49.809,55.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.991 | Acc: 28.087,49.462,54.854,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.357 | Acc: 74.219,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.479 | Acc: 68.713,94.122,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.489 | Acc: 68.121,94.627,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.484 | Acc: 68.430,94.903,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.486 | Acc: 68.740,95.004,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.502 | Acc: 68.178,95.204,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 67.917,95.254,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 67.902,95.224,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.493 | Acc: 68.153,95.269,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 68.111,95.200,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.487 | Acc: 68.202,95.254,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.490 | Acc: 68.138,95.270,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.493 | Acc: 68.157,95.280,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.495 | Acc: 68.071,95.274,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 67.980,95.212,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.498 | Acc: 68.026,95.219,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.500 | Acc: 67.991,95.174,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 67.976,95.166,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.502 | Acc: 68.001,95.196,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 67.928,95.161,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.405 | Acc: 35.938,53.125,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.782 | Acc: 32.106,46.466,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.816 | Acc: 31.040,46.608,59.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.842 | Acc: 30.891,46.055,59.042,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.309 | Acc: 75.781,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.475 | Acc: 69.420,94.754,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.474 | Acc: 68.598,95.084,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.477 | Acc: 68.251,95.159,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.466 | Acc: 68.798,95.129,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.478 | Acc: 68.619,95.096,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 68.388,94.964,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.477 | Acc: 68.617,94.975,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.489 | Acc: 68.197,94.983,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.494 | Acc: 68.198,94.972,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.491 | Acc: 68.136,95.029,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.494 | Acc: 68.075,95.012,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.498 | Acc: 67.982,95.040,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.500 | Acc: 67.963,94.995,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 68.052,95.026,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.504 | Acc: 68.057,94.962,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.506 | Acc: 67.920,94.938,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.505 | Acc: 67.900,94.976,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.507 | Acc: 67.832,94.942,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.511 | Acc: 67.745,94.950,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.875 | Acc: 43.750,58.594,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.301 | Acc: 42.969,52.046,54.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.327 | Acc: 41.940,52.058,55.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.356 | Acc: 41.957,51.883,55.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.817 | Acc: 60.156,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.516 | Acc: 67.188,94.717,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.516 | Acc: 67.188,94.817,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.519 | Acc: 67.111,94.877,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.513 | Acc: 66.956,95.158,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.500 | Acc: 67.412,95.374,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.499 | Acc: 67.394,95.248,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 67.520,95.191,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.504 | Acc: 67.551,95.162,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.500 | Acc: 67.567,95.166,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.503 | Acc: 67.444,95.165,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.505 | Acc: 67.477,95.104,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.507 | Acc: 67.437,95.115,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.506 | Acc: 67.436,95.109,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 67.474,95.107,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.507 | Acc: 67.478,95.115,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.508 | Acc: 67.526,95.084,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.501 | Acc: 67.630,95.125,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.497 | Acc: 67.707,95.178,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.496 | Acc: 67.776,95.208,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.475 | Acc: 42.188,65.625,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.930 | Acc: 40.402,58.073,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.967 | Acc: 38.758,57.565,59.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.993 | Acc: 38.781,57.275,59.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.764 | Acc: 60.938,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.524 | Acc: 67.188,94.866,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.531 | Acc: 67.207,94.569,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.518 | Acc: 67.636,94.928,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.503 | Acc: 68.210,94.869,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.498 | Acc: 68.093,94.856,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.496 | Acc: 68.111,94.899,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 68.268,95.063,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 68.173,95.099,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.490 | Acc: 68.176,94.980,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.488 | Acc: 68.311,95.021,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.485 | Acc: 68.372,95.012,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.491 | Acc: 68.286,94.936,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.490 | Acc: 68.283,94.986,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.491 | Acc: 68.188,94.959,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.494 | Acc: 68.109,94.910,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.492 | Acc: 68.098,94.926,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.495 | Acc: 68.040,94.898,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.496 | Acc: 67.977,94.923,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.495 | Acc: 67.969,94.964,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.924 | Acc: 39.062,61.719,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.393 | Acc: 36.049,54.650,56.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.429 | Acc: 34.737,54.688,56.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.457 | Acc: 34.746,54.124,56.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.552 | Acc: 66.406,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.477 | Acc: 69.457,94.420,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.478 | Acc: 68.369,94.665,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.484 | Acc: 68.494,94.851,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.466 | Acc: 68.644,95.149,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.482 | Acc: 68.255,95.111,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.487 | Acc: 68.169,95.119,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.486 | Acc: 68.224,95.202,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.489 | Acc: 67.974,95.288,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 67.939,95.312,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.489 | Acc: 67.996,95.289,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.491 | Acc: 68.050,95.309,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.497 | Acc: 67.972,95.235,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 67.948,95.163,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.501 | Acc: 67.960,95.165,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 67.925,95.178,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.499 | Acc: 67.998,95.222,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 67.914,95.248,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.510 | Acc: 67.744,95.148,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.508 | Acc: 67.782,95.130,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.836 | Acc: 38.281,63.281,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.274 | Acc: 33.371,53.423,62.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.316 | Acc: 32.031,53.563,61.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.342 | Acc: 32.006,53.061,61.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 1.776 | Acc: 59.375,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.537 | Acc: 67.188,95.201,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.516 | Acc: 67.454,95.370,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.525 | Acc: 67.354,95.479,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.514 | Acc: 67.429,95.611,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.514 | Acc: 67.536,95.421,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.514 | Acc: 67.407,95.312,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.514 | Acc: 67.431,95.235,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.518 | Acc: 67.425,95.196,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 67.714,95.235,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.507 | Acc: 67.685,95.211,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.505 | Acc: 67.686,95.228,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.506 | Acc: 67.622,95.218,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.504 | Acc: 67.553,95.214,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 67.568,95.196,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.503 | Acc: 67.637,95.203,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.506 | Acc: 67.572,95.191,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 67.584,95.230,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.504 | Acc: 67.605,95.170,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.505 | Acc: 67.641,95.157,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.842 | Acc: 37.500,59.375,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.283 | Acc: 34.263,51.711,61.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.323 | Acc: 32.832,52.115,61.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.348 | Acc: 32.928,51.575,60.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.390 | Acc: 71.094,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.581 | Acc: 67.039,94.159,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.554 | Acc: 66.864,94.360,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.541 | Acc: 67.175,94.429,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.517 | Acc: 67.747,94.483,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.518 | Acc: 67.667,94.578,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.529 | Acc: 67.433,94.557,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.521 | Acc: 67.487,94.603,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.519 | Acc: 67.551,94.745,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.522 | Acc: 67.546,94.691,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.517 | Acc: 67.654,94.722,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.521 | Acc: 67.477,94.719,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.515 | Acc: 67.573,94.771,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.515 | Acc: 67.574,94.768,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.517 | Acc: 67.557,94.765,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.517 | Acc: 67.608,94.786,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.516 | Acc: 67.674,94.821,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.516 | Acc: 67.657,94.886,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.511 | Acc: 67.755,94.951,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.508 | Acc: 67.858,94.950,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.045 | Acc: 32.812,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.506 | Acc: 31.138,53.348,58.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.541 | Acc: 30.393,53.373,58.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.568 | Acc: 30.533,52.894,58.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.567 | Acc: 64.844,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.499 | Acc: 67.597,95.461,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.501 | Acc: 67.511,95.408,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.502 | Acc: 67.892,95.236,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.498 | Acc: 68.287,94.946,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.499 | Acc: 68.325,95.003,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.509 | Acc: 68.020,95.003,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.514 | Acc: 67.974,95.035,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.514 | Acc: 67.930,95.070,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 68.029,95.036,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.505 | Acc: 68.113,95.040,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 68.050,95.044,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.507 | Acc: 67.972,95.043,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 67.927,95.037,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 67.844,95.018,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.504 | Acc: 67.990,95.035,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.507 | Acc: 67.942,95.042,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.505 | Acc: 67.973,95.040,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.506 | Acc: 67.977,95.066,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.505 | Acc: 67.946,95.073,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.031 | Acc: 31.250,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.500 | Acc: 29.464,51.153,61.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.536 | Acc: 28.697,51.124,61.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.565 | Acc: 28.663,50.717,61.245,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.493 | Acc: 64.062,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.505 | Acc: 66.592,95.164,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.500 | Acc: 67.111,95.103,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.521 | Acc: 67.047,94.787,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.517 | Acc: 67.245,94.782,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.521 | Acc: 67.242,94.663,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.518 | Acc: 67.556,94.725,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.507 | Acc: 67.764,94.830,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.510 | Acc: 67.789,94.915,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.503 | Acc: 67.887,94.928,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.509 | Acc: 67.778,94.924,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.504 | Acc: 67.902,94.941,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.504 | Acc: 67.842,94.930,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.508 | Acc: 67.711,94.926,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.510 | Acc: 67.771,94.901,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.507 | Acc: 67.787,94.908,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.507 | Acc: 67.794,94.916,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.507 | Acc: 67.781,94.962,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.499 | Acc: 67.912,95.007,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.500 | Acc: 67.911,94.993,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.722 | Acc: 42.969,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.170 | Acc: 40.997,52.121,60.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.204 | Acc: 39.615,52.191,60.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.232 | Acc: 39.831,51.742,60.246,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.738 | Acc: 66.406,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.461 | Acc: 67.485,95.536,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.485 | Acc: 67.645,95.389,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.502 | Acc: 67.649,94.954,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.490 | Acc: 68.017,94.985,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.491 | Acc: 67.752,95.142,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 67.794,95.099,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.503 | Acc: 67.780,95.107,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.500 | Acc: 67.911,95.075,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.503 | Acc: 67.809,95.097,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.499 | Acc: 67.860,95.184,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 67.923,95.206,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.495 | Acc: 67.920,95.209,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.499 | Acc: 67.957,95.106,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.497 | Acc: 67.991,95.071,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 67.909,95.053,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 67.969,94.979,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 68.035,94.989,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.498 | Acc: 68.112,94.997,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.498 | Acc: 68.084,94.989,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.002 | Acc: 32.031,60.938,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.444 | Acc: 31.064,53.162,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.481 | Acc: 30.202,53.277,59.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.505 | Acc: 30.174,52.843,59.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.497 | Acc: 64.062,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.484 | Acc: 69.271,95.052,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.510 | Acc: 68.197,95.217,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.518 | Acc: 67.982,94.903,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.526 | Acc: 67.853,94.927,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.530 | Acc: 67.907,94.864,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.520 | Acc: 68.072,94.873,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 68.384,94.969,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 68.226,94.905,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.509 | Acc: 68.258,94.881,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.518 | Acc: 68.046,94.866,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.518 | Acc: 67.926,94.917,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.516 | Acc: 67.978,94.982,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.514 | Acc: 68.071,95.007,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.517 | Acc: 68.080,95.009,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.516 | Acc: 68.057,95.006,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.517 | Acc: 67.986,95.013,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.513 | Acc: 68.083,94.989,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.514 | Acc: 68.086,94.979,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.509 | Acc: 68.207,95.017,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.469 | Acc: 34.375,57.812,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.903 | Acc: 33.147,47.470,54.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.928 | Acc: 32.317,47.504,55.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.954 | Acc: 32.441,47.093,54.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.648 | Acc: 61.719,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.540 | Acc: 66.704,95.238,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.540 | Acc: 67.797,95.217,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.530 | Acc: 67.572,95.312,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.529 | Acc: 67.699,95.206,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.520 | Acc: 67.845,95.336,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.512 | Acc: 68.079,95.261,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 68.118,95.202,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 68.148,95.220,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.509 | Acc: 68.262,95.170,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.511 | Acc: 68.334,95.126,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.514 | Acc: 68.174,95.139,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.515 | Acc: 68.147,95.124,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.512 | Acc: 68.142,95.130,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.515 | Acc: 68.010,95.073,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.519 | Acc: 67.906,95.084,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.517 | Acc: 67.937,95.108,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.518 | Acc: 67.891,95.118,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.520 | Acc: 67.783,95.109,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.521 | Acc: 67.723,95.046,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.187 | Acc: 39.844,48.438,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.650 | Acc: 36.458,41.592,61.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.684 | Acc: 34.947,41.292,61.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.711 | Acc: 34.990,41.022,61.309,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.610 | Acc: 64.844,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.489 | Acc: 69.420,94.940,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.508 | Acc: 68.617,94.855,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.534 | Acc: 67.495,94.826,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.528 | Acc: 67.670,94.821,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.532 | Acc: 67.443,94.740,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.523 | Acc: 67.691,94.783,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.511 | Acc: 67.725,94.853,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.500 | Acc: 67.891,94.915,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.506 | Acc: 67.874,94.950,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.507 | Acc: 67.833,94.990,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 67.979,94.973,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 67.969,95.034,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 67.858,95.052,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.504 | Acc: 67.863,95.079,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.504 | Acc: 67.865,95.030,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 67.864,95.033,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 67.850,95.122,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.500 | Acc: 67.850,95.157,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 67.805,95.173,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.705 | Acc: 42.969,65.625,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.129 | Acc: 38.765,57.924,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.164 | Acc: 37.290,57.889,57.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.193 | Acc: 37.436,57.544,57.223,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.747 | Acc: 62.500,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.521 | Acc: 67.448,95.015,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.507 | Acc: 67.397,94.970,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.496 | Acc: 67.495,95.082,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.482 | Acc: 68.027,95.071,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 67.984,95.150,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.490 | Acc: 67.769,95.035,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.490 | Acc: 67.919,95.052,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.491 | Acc: 67.818,95.080,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.493 | Acc: 67.800,95.032,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.495 | Acc: 67.704,95.169,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.494 | Acc: 67.746,95.150,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.497 | Acc: 67.693,95.053,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.491 | Acc: 67.666,95.139,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.493 | Acc: 67.682,95.135,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.491 | Acc: 67.712,95.152,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.492 | Acc: 67.781,95.149,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.492 | Acc: 67.827,95.157,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.499 | Acc: 67.731,95.165,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.500 | Acc: 67.776,95.194,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.965 | Acc: 41.406,53.906,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.399 | Acc: 38.207,47.359,60.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.433 | Acc: 36.909,47.752,59.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.460 | Acc: 37.013,47.374,59.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.425 | Acc: 68.750,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.497 | Acc: 68.713,94.903,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.541 | Acc: 67.740,94.931,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.537 | Acc: 67.367,95.082,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.531 | Acc: 67.419,95.187,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.522 | Acc: 67.729,95.258,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.520 | Acc: 67.710,95.312,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.507 | Acc: 67.891,95.301,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.504 | Acc: 68.012,95.245,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.505 | Acc: 68.033,95.170,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.505 | Acc: 67.980,95.231,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 67.983,95.203,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.502 | Acc: 68.056,95.257,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.504 | Acc: 67.978,95.271,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.501 | Acc: 67.997,95.282,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.498 | Acc: 68.049,95.287,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.500 | Acc: 67.998,95.205,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.498 | Acc: 68.049,95.191,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.501 | Acc: 68.014,95.144,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 68.057,95.118,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.331 | Acc: 35.938,59.375,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.784 | Acc: 32.403,52.381,52.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.821 | Acc: 31.364,52.630,52.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.851 | Acc: 31.378,51.985,52.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.602 | Acc: 66.406,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.540 | Acc: 68.118,94.866,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.565 | Acc: 66.387,94.588,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.540 | Acc: 67.597,94.557,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.532 | Acc: 67.708,94.763,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.526 | Acc: 67.907,94.817,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.518 | Acc: 68.130,94.841,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 68.163,94.880,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.513 | Acc: 67.911,94.818,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.512 | Acc: 67.874,94.920,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.505 | Acc: 68.039,94.951,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 67.993,95.016,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.498 | Acc: 68.102,95.053,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.501 | Acc: 68.080,95.037,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 68.027,95.059,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 68.034,95.063,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 67.957,95.035,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 68.047,95.067,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 68.034,95.085,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.503 | Acc: 67.985,95.064,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.840 | Acc: 42.188,57.812,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.295 | Acc: 41.034,51.674,56.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.325 | Acc: 39.444,51.867,57.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.350 | Acc: 39.588,51.665,57.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.567 | Acc: 67.188,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.499 | Acc: 68.490,94.978,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.518 | Acc: 67.797,94.798,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.519 | Acc: 67.725,95.005,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.507 | Acc: 67.795,95.177,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.521 | Acc: 67.659,94.964,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.515 | Acc: 67.807,95.009,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.515 | Acc: 67.764,94.897,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.515 | Acc: 67.794,94.919,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 67.887,94.928,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 67.755,94.935,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.516 | Acc: 67.735,94.941,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.517 | Acc: 67.755,94.936,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.512 | Acc: 67.831,94.950,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.510 | Acc: 67.807,94.959,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.510 | Acc: 67.857,94.926,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.507 | Acc: 67.874,94.972,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 67.941,95.003,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.507 | Acc: 67.867,94.958,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 67.782,94.962,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.822 | Acc: 35.938,54.688,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.254 | Acc: 34.003,47.098,65.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.298 | Acc: 32.660,47.218,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.322 | Acc: 32.748,46.798,65.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.403 | Acc: 68.750,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.514 | Acc: 67.299,95.499,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.518 | Acc: 67.092,95.179,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 67.047,94.915,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.514 | Acc: 67.197,94.907,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.513 | Acc: 67.033,94.833,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.510 | Acc: 67.188,95.009,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.509 | Acc: 67.171,95.024,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.506 | Acc: 67.362,94.934,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.506 | Acc: 67.339,95.010,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.506 | Acc: 67.257,95.021,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.503 | Acc: 67.453,95.023,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.499 | Acc: 67.606,95.105,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.499 | Acc: 67.660,95.094,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.501 | Acc: 67.735,95.079,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.504 | Acc: 67.810,95.089,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.509 | Acc: 67.725,95.040,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.506 | Acc: 67.728,95.026,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.508 | Acc: 67.731,95.048,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.509 | Acc: 67.723,94.999,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.170 | Acc: 35.156,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.623 | Acc: 31.734,50.707,59.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.656 | Acc: 30.774,50.896,59.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.684 | Acc: 30.891,50.192,59.657,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.288 | Acc: 75.781,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.551 | Acc: 67.932,95.089,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.521 | Acc: 68.197,95.236,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.518 | Acc: 67.879,95.172,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.507 | Acc: 68.355,95.120,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.510 | Acc: 68.185,95.227,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.525 | Acc: 68.091,95.196,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.525 | Acc: 68.013,95.213,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.523 | Acc: 67.847,95.254,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.516 | Acc: 67.939,95.196,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.510 | Acc: 68.078,95.130,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.503 | Acc: 68.199,95.129,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.501 | Acc: 68.189,95.154,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.503 | Acc: 68.124,95.121,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.502 | Acc: 68.113,95.104,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.506 | Acc: 68.119,95.092,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 68.185,95.079,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 68.154,95.113,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.505 | Acc: 68.099,95.137,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.506 | Acc: 68.082,95.140,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.685 | Acc: 39.062,64.062,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.108 | Acc: 37.612,56.585,58.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.147 | Acc: 35.709,56.688,58.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.172 | Acc: 35.873,56.442,58.863,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.488 | Acc: 73.438,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.501 | Acc: 67.374,95.908,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.522 | Acc: 67.454,95.370,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.508 | Acc: 67.354,95.338,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.483 | Acc: 67.921,95.467,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 68.317,95.436,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.484 | Acc: 68.414,95.332,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.486 | Acc: 68.445,95.301,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.494 | Acc: 68.318,95.225,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.494 | Acc: 68.439,95.187,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.498 | Acc: 68.342,95.157,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.494 | Acc: 68.259,95.153,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.495 | Acc: 68.199,95.167,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.496 | Acc: 68.241,95.124,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.497 | Acc: 68.230,95.096,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.497 | Acc: 68.221,95.118,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.500 | Acc: 68.176,95.142,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.499 | Acc: 68.175,95.170,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.498 | Acc: 68.224,95.200,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 68.161,95.144,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.149 | Acc: 42.188,54.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.603 | Acc: 38.616,48.549,55.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.631 | Acc: 37.100,48.438,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.658 | Acc: 37.436,48.194,55.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.665 | Acc: 64.844,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.527 | Acc: 66.964,95.573,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.526 | Acc: 67.111,95.236,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.529 | Acc: 67.239,95.044,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.533 | Acc: 67.274,95.033,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.517 | Acc: 67.597,94.972,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.516 | Acc: 67.891,95.041,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.509 | Acc: 68.024,95.224,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.511 | Acc: 68.027,95.249,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.509 | Acc: 68.003,95.248,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.511 | Acc: 67.977,95.215,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.507 | Acc: 67.905,95.238,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 67.904,95.241,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 67.894,95.256,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.506 | Acc: 67.930,95.162,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.505 | Acc: 67.982,95.141,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.503 | Acc: 67.971,95.174,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 68.033,95.150,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.496 | Acc: 68.168,95.209,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.492 | Acc: 68.256,95.200,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.371 | Acc: 32.812,60.156,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.808 | Acc: 30.766,53.981,52.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.831 | Acc: 29.840,54.249,52.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.857 | Acc: 29.752,53.983,52.805,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.620 | Acc: 64.062,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.495 | Acc: 67.969,94.457,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 67.988,95.084,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.470 | Acc: 68.417,95.338,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.484 | Acc: 68.441,95.303,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 68.317,95.227,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.491 | Acc: 68.175,95.119,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 68.301,95.202,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.492 | Acc: 68.313,95.186,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.497 | Acc: 68.163,95.144,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.504 | Acc: 68.039,95.122,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.509 | Acc: 67.997,95.086,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.504 | Acc: 68.037,95.124,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.503 | Acc: 68.005,95.124,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 67.910,95.157,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.498 | Acc: 68.062,95.235,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 67.996,95.198,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 68.040,95.175,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.505 | Acc: 67.973,95.148,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 67.915,95.130,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.245 | Acc: 37.500,52.344,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.678 | Acc: 34.933,45.647,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.710 | Acc: 33.689,45.541,58.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.739 | Acc: 33.568,45.402,58.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 1.378 | Acc: 67.188,94.531,100.000,% | Adaptive Acc: 93.750% | clf_exit: 0.516 0.430 0.055
Batch: 20 | Loss: 1.483 | Acc: 68.824,95.015,99.777,% | Adaptive Acc: 93.155% | clf_exit: 0.521 0.401 0.078
Batch: 40 | Loss: 1.493 | Acc: 68.121,95.293,99.790,% | Adaptive Acc: 92.873% | clf_exit: 0.519 0.411 0.070
Batch: 60 | Loss: 1.489 | Acc: 68.315,95.005,99.769,% | Adaptive Acc: 92.687% | clf_exit: 0.526 0.401 0.074
Batch: 80 | Loss: 1.488 | Acc: 68.519,95.139,99.797,% | Adaptive Acc: 92.795% | clf_exit: 0.525 0.402 0.072
Batch: 100 | Loss: 1.476 | Acc: 68.541,95.398,99.822,% | Adaptive Acc: 92.713% | clf_exit: 0.529 0.401 0.070
Batch: 120 | Loss: 1.485 | Acc: 68.304,95.164,99.813,% | Adaptive Acc: 92.601% | clf_exit: 0.527 0.401 0.071
Batch: 140 | Loss: 1.484 | Acc: 68.401,95.213,99.795,% | Adaptive Acc: 92.686% | clf_exit: 0.528 0.401 0.071
Batch: 160 | Loss: 1.492 | Acc: 68.357,95.143,99.801,% | Adaptive Acc: 92.576% | clf_exit: 0.527 0.401 0.072
Batch: 180 | Loss: 1.496 | Acc: 68.267,95.179,99.801,% | Adaptive Acc: 92.615% | clf_exit: 0.525 0.404 0.072
Batch: 200 | Loss: 1.501 | Acc: 68.186,95.087,99.810,% | Adaptive Acc: 92.576% | clf_exit: 0.526 0.401 0.073
Batch: 220 | Loss: 1.501 | Acc: 68.241,95.065,99.823,% | Adaptive Acc: 92.633% | clf_exit: 0.524 0.403 0.073
Batch: 240 | Loss: 1.501 | Acc: 68.257,95.040,99.815,% | Adaptive Acc: 92.696% | clf_exit: 0.524 0.402 0.075
Batch: 260 | Loss: 1.503 | Acc: 68.214,95.040,99.811,% | Adaptive Acc: 92.681% | clf_exit: 0.523 0.402 0.075
Batch: 280 | Loss: 1.506 | Acc: 68.052,95.015,99.808,% | Adaptive Acc: 92.668% | clf_exit: 0.522 0.403 0.075
Batch: 300 | Loss: 1.508 | Acc: 68.036,95.019,99.813,% | Adaptive Acc: 92.725% | clf_exit: 0.520 0.405 0.075
Batch: 320 | Loss: 1.506 | Acc: 68.039,95.062,99.815,% | Adaptive Acc: 92.769% | clf_exit: 0.519 0.406 0.075
Batch: 340 | Loss: 1.507 | Acc: 68.060,95.035,99.810,% | Adaptive Acc: 92.811% | clf_exit: 0.518 0.407 0.075
Batch: 360 | Loss: 1.508 | Acc: 67.975,95.020,99.797,% | Adaptive Acc: 92.755% | clf_exit: 0.517 0.408 0.075
Batch: 380 | Loss: 1.506 | Acc: 68.082,94.974,99.799,% | Adaptive Acc: 92.764% | clf_exit: 0.517 0.408 0.074
Batch: 0 | Loss: 7.462 | Acc: 34.375,53.125,60.938,% | Adaptive Acc: 64.844% | clf_exit: 0.109 0.094 0.797
Batch: 20 | Loss: 7.906 | Acc: 32.068,47.768,54.836,% | Adaptive Acc: 55.952% | clf_exit: 0.102 0.081 0.817
Batch: 40 | Loss: 7.945 | Acc: 30.888,47.142,55.488,% | Adaptive Acc: 56.536% | clf_exit: 0.093 0.084 0.823
Batch: 60 | Loss: 7.975 | Acc: 30.891,46.657,55.328,% | Adaptive Acc: 56.429% | clf_exit: 0.092 0.084 0.824
Evaluate with different circles:
circles: 0
Batch: 0 | Loss: 7.462 | Acc: 34.375,53.125,60.938,% | Adaptive Acc: 64.844% | clf_exit: 0.109 0.094 0.797
Batch: 20 | Loss: 7.906 | Acc: 32.068,47.768,54.836,% | Adaptive Acc: 55.952% | clf_exit: 0.102 0.081 0.817
Batch: 40 | Loss: 7.945 | Acc: 30.888,47.142,55.488,% | Adaptive Acc: 56.536% | clf_exit: 0.093 0.084 0.823
Batch: 60 | Loss: 7.975 | Acc: 30.891,46.657,55.328,% | Adaptive Acc: 56.429% | clf_exit: 0.092 0.084 0.824
circles: 1
Batch: 0 | Loss: 4.072 | Acc: 59.375,67.969,76.562,% | Adaptive Acc: 74.219% | clf_exit: 0.414 0.258 0.328
Batch: 20 | Loss: 4.544 | Acc: 54.613,66.927,73.698,% | Adaptive Acc: 69.866% | clf_exit: 0.401 0.276 0.323
Batch: 40 | Loss: 4.593 | Acc: 54.116,66.711,72.752,% | Adaptive Acc: 69.226% | clf_exit: 0.388 0.279 0.333
Batch: 60 | Loss: 4.600 | Acc: 54.162,66.893,72.451,% | Adaptive Acc: 69.365% | clf_exit: 0.388 0.275 0.336
circles: 2
Batch: 0 | Loss: 3.799 | Acc: 62.500,71.094,77.344,% | Adaptive Acc: 71.094% | clf_exit: 0.641 0.219 0.141
Batch: 20 | Loss: 4.380 | Acc: 56.845,68.006,74.219,% | Adaptive Acc: 66.704% | clf_exit: 0.634 0.247 0.119
Batch: 40 | Loss: 4.432 | Acc: 56.612,67.721,73.380,% | Adaptive Acc: 66.139% | clf_exit: 0.627 0.252 0.120
Batch: 60 | Loss: 4.425 | Acc: 56.698,67.994,73.373,% | Adaptive Acc: 66.381% | clf_exit: 0.629 0.251 0.120
circles: 3
Batch: 0 | Loss: 4.666 | Acc: 62.500,67.969,75.781,% | Adaptive Acc: 67.969% | clf_exit: 0.742 0.188 0.070
Batch: 20 | Loss: 5.320 | Acc: 55.878,65.848,73.400,% | Adaptive Acc: 61.161% | clf_exit: 0.767 0.174 0.059
Batch: 40 | Loss: 5.385 | Acc: 55.259,66.082,72.694,% | Adaptive Acc: 61.014% | clf_exit: 0.764 0.174 0.062
Batch: 60 | Loss: 5.368 | Acc: 55.187,66.368,73.028,% | Adaptive Acc: 61.066% | clf_exit: 0.766 0.174 0.060

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 11.578 |  Acc: 9.616,11.876,15.642,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=0 | Loss: 13.134 |  Acc: 2.540,6.020,3.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 9.996 |  Acc: 16.840,21.046,27.808,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=1 | Loss: 12.342 |  Acc: 6.570,5.830,23.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 9.028 |  Acc: 21.752,26.176,35.810,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=2 | Loss: 11.750 |  Acc: 7.990,13.110,25.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 8.342 |  Acc: 25.368,30.164,41.336,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=3 | Loss: 11.486 |  Acc: 15.190,11.410,21.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 7.809 |  Acc: 27.864,33.194,45.542,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=4 | Loss: 10.960 |  Acc: 16.750,12.200,32.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 7.396 |  Acc: 30.108,36.182,49.160,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=5 | Loss: 10.833 |  Acc: 19.670,13.900,26.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 7.030 |  Acc: 32.134,38.276,52.372,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=6 | Loss: 10.722 |  Acc: 16.480,18.400,24.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 6.753 |  Acc: 33.706,40.418,54.664,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=7 | Loss: 10.970 |  Acc: 15.120,15.390,28.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 6.455 |  Acc: 34.894,42.422,57.102,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=8 | Loss: 10.013 |  Acc: 22.050,19.100,42.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 6.223 |  Acc: 36.706,44.016,59.434,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=9 | Loss: 10.155 |  Acc: 17.680,24.100,33.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 6.044 |  Acc: 37.436,45.772,61.184,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=10 | Loss: 10.353 |  Acc: 13.760,24.720,37.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 5.834 |  Acc: 38.256,47.214,63.250,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=11 | Loss: 10.213 |  Acc: 19.620,19.840,29.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 5.669 |  Acc: 38.792,48.502,64.684,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=12 | Loss: 9.697 |  Acc: 20.190,23.870,44.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 5.512 |  Acc: 39.968,49.970,66.242,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=13 | Loss: 9.342 |  Acc: 26.430,20.260,50.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 5.376 |  Acc: 40.710,51.168,67.826,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=14 | Loss: 9.172 |  Acc: 22.770,30.940,46.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 5.252 |  Acc: 41.032,52.174,69.248,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=15 | Loss: 9.687 |  Acc: 18.470,20.870,44.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 5.133 |  Acc: 42.076,53.018,70.008,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=16 | Loss: 9.229 |  Acc: 16.040,26.810,52.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 5.044 |  Acc: 42.220,53.838,71.404,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=17 | Loss: 9.783 |  Acc: 18.270,21.540,39.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.932 |  Acc: 43.032,54.748,72.608,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=18 | Loss: 9.406 |  Acc: 20.350,29.200,38.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.836 |  Acc: 43.270,55.518,73.704,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=19 | Loss: 8.788 |  Acc: 26.210,33.170,49.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.750 |  Acc: 43.904,56.316,74.454,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=20 | Loss: 9.578 |  Acc: 17.790,28.620,39.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.667 |  Acc: 43.990,57.028,75.398,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=21 | Loss: 8.784 |  Acc: 28.460,25.750,50.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 4.608 |  Acc: 44.556,57.298,76.510,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=22 | Loss: 9.282 |  Acc: 22.540,33.390,39.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 4.535 |  Acc: 45.076,58.154,77.414,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=23 | Loss: 8.683 |  Acc: 24.450,31.780,54.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 4.443 |  Acc: 45.544,58.920,78.196,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=24 | Loss: 9.121 |  Acc: 24.210,31.060,39.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 4.406 |  Acc: 45.876,58.956,78.624,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=25 | Loss: 8.423 |  Acc: 24.860,35.910,54.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 4.341 |  Acc: 45.636,59.628,79.376,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=26 | Loss: 8.716 |  Acc: 22.380,40.670,48.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 4.314 |  Acc: 45.932,59.978,79.618,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=27 | Loss: 9.455 |  Acc: 20.290,37.250,31.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 4.241 |  Acc: 46.492,60.260,80.742,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=28 | Loss: 8.784 |  Acc: 17.050,45.640,47.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 4.209 |  Acc: 46.828,60.802,81.028,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=29 | Loss: 8.970 |  Acc: 14.780,35.350,40.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 4.156 |  Acc: 46.698,61.168,81.800,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=30 | Loss: 8.630 |  Acc: 21.290,41.830,47.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 4.114 |  Acc: 47.306,61.528,82.354,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=31 | Loss: 8.582 |  Acc: 27.200,41.860,41.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 4.085 |  Acc: 47.374,61.796,82.592,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=32 | Loss: 8.546 |  Acc: 11.370,41.770,43.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 4.048 |  Acc: 47.478,62.246,83.032,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=33 | Loss: 8.102 |  Acc: 27.310,47.740,44.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 3.998 |  Acc: 48.082,62.534,83.730,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=34 | Loss: 8.782 |  Acc: 14.440,35.340,44.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 3.999 |  Acc: 47.940,62.682,83.384,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=35 | Loss: 8.000 |  Acc: 26.930,46.010,48.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.943 |  Acc: 48.166,63.192,84.404,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=36 | Loss: 8.078 |  Acc: 25.170,41.760,56.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.932 |  Acc: 48.192,63.516,84.458,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=37 | Loss: 7.862 |  Acc: 23.840,43.000,55.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.878 |  Acc: 48.738,64.078,85.054,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=38 | Loss: 8.223 |  Acc: 25.830,45.060,49.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.884 |  Acc: 48.494,63.800,84.804,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=39 | Loss: 8.438 |  Acc: 21.720,40.790,50.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.859 |  Acc: 48.492,64.150,85.170,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=40 | Loss: 7.998 |  Acc: 27.760,42.240,55.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.826 |  Acc: 48.944,63.992,85.398,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=41 | Loss: 8.487 |  Acc: 25.030,42.730,41.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.820 |  Acc: 48.906,64.418,85.330,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=42 | Loss: 7.822 |  Acc: 28.960,50.160,52.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.746 |  Acc: 49.398,65.158,86.288,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=43 | Loss: 8.243 |  Acc: 21.700,44.150,50.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.754 |  Acc: 49.556,65.126,86.156,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=44 | Loss: 7.960 |  Acc: 28.180,49.820,40.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.735 |  Acc: 49.808,65.384,86.306,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=45 | Loss: 8.088 |  Acc: 25.140,43.340,48.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.735 |  Acc: 49.554,65.176,86.308,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=46 | Loss: 7.943 |  Acc: 26.700,45.660,54.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.723 |  Acc: 49.326,65.184,86.584,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=47 | Loss: 8.048 |  Acc: 32.930,45.940,42.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.719 |  Acc: 49.618,65.414,86.546,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=48 | Loss: 8.210 |  Acc: 24.140,44.040,48.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.680 |  Acc: 49.916,65.940,86.484,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=49 | Loss: 8.069 |  Acc: 28.770,45.700,40.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.669 |  Acc: 50.122,65.852,86.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=50 | Loss: 8.192 |  Acc: 20.850,48.000,46.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.655 |  Acc: 50.002,65.982,86.620,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=51 | Loss: 8.850 |  Acc: 26.010,35.650,36.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.628 |  Acc: 50.192,66.074,87.058,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=52 | Loss: 8.132 |  Acc: 30.540,45.180,48.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.613 |  Acc: 50.284,66.912,87.248,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=53 | Loss: 7.489 |  Acc: 24.870,51.070,57.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.610 |  Acc: 50.410,66.428,87.338,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=54 | Loss: 8.309 |  Acc: 22.550,44.730,50.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.587 |  Acc: 50.666,66.806,87.714,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=55 | Loss: 8.750 |  Acc: 30.090,46.680,23.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.589 |  Acc: 50.620,66.932,87.386,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=56 | Loss: 8.305 |  Acc: 35.000,42.650,36.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.586 |  Acc: 50.570,66.738,87.444,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=57 | Loss: 7.751 |  Acc: 22.260,51.180,56.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.571 |  Acc: 50.598,66.612,87.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=58 | Loss: 7.905 |  Acc: 28.990,45.720,50.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.542 |  Acc: 50.882,67.058,88.250,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=59 | Loss: 8.577 |  Acc: 28.310,45.850,29.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.549 |  Acc: 50.876,67.368,87.794,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=60 | Loss: 8.460 |  Acc: 29.910,49.390,26.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.528 |  Acc: 50.952,67.224,88.024,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=61 | Loss: 8.794 |  Acc: 22.020,43.700,29.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.537 |  Acc: 50.804,67.378,87.918,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=62 | Loss: 8.389 |  Acc: 26.530,47.030,38.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.520 |  Acc: 50.884,67.226,88.168,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=63 | Loss: 8.118 |  Acc: 32.590,47.470,40.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 3.505 |  Acc: 51.260,67.742,88.100,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=64 | Loss: 7.966 |  Acc: 19.310,49.930,56.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 3.469 |  Acc: 51.300,68.098,88.488,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=65 | Loss: 7.847 |  Acc: 26.100,50.390,55.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 3.459 |  Acc: 51.384,68.038,88.588,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=66 | Loss: 8.390 |  Acc: 24.160,44.100,48.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 3.470 |  Acc: 51.296,68.090,88.594,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=67 | Loss: 7.629 |  Acc: 31.950,50.010,52.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 3.459 |  Acc: 51.522,67.934,88.668,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=68 | Loss: 7.670 |  Acc: 27.250,47.430,56.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 3.437 |  Acc: 51.774,68.386,88.918,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=69 | Loss: 7.549 |  Acc: 35.270,52.310,47.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 3.438 |  Acc: 51.724,68.574,88.998,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=70 | Loss: 8.220 |  Acc: 26.010,46.730,42.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 3.466 |  Acc: 51.650,68.152,88.470,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=71 | Loss: 8.076 |  Acc: 28.090,47.940,50.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 3.444 |  Acc: 51.622,68.608,88.458,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=72 | Loss: 8.009 |  Acc: 26.930,48.870,51.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 3.435 |  Acc: 51.840,68.270,88.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=73 | Loss: 8.076 |  Acc: 26.890,50.560,40.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 3.425 |  Acc: 51.678,68.520,88.896,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=74 | Loss: 8.414 |  Acc: 27.400,47.710,27.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 3.414 |  Acc: 51.984,68.608,88.924,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=75 | Loss: 8.001 |  Acc: 31.730,45.860,43.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 3.406 |  Acc: 51.970,68.854,88.768,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=76 | Loss: 7.878 |  Acc: 29.520,50.160,43.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 3.408 |  Acc: 51.872,68.638,88.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=77 | Loss: 7.627 |  Acc: 27.440,50.540,55.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 3.393 |  Acc: 52.174,68.862,89.264,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=78 | Loss: 8.034 |  Acc: 22.540,50.150,50.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 3.403 |  Acc: 52.094,69.058,88.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=79 | Loss: 8.347 |  Acc: 23.540,45.360,40.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 3.390 |  Acc: 51.734,68.980,88.986,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=80 | Loss: 8.160 |  Acc: 29.380,45.900,43.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 3.361 |  Acc: 52.410,69.198,89.222,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=81 | Loss: 7.862 |  Acc: 32.180,55.210,41.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 3.359 |  Acc: 52.216,69.266,89.460,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=82 | Loss: 8.129 |  Acc: 28.250,49.800,41.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 3.368 |  Acc: 52.322,69.334,89.184,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=83 | Loss: 7.574 |  Acc: 37.280,53.870,48.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 3.356 |  Acc: 52.132,69.494,89.028,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=84 | Loss: 7.921 |  Acc: 24.990,45.190,56.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 3.364 |  Acc: 52.218,69.264,89.404,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=85 | Loss: 8.229 |  Acc: 26.430,48.790,48.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 3.333 |  Acc: 52.570,69.658,89.602,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=86 | Loss: 7.444 |  Acc: 30.510,55.020,53.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 3.320 |  Acc: 52.714,69.622,89.614,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=87 | Loss: 7.226 |  Acc: 28.210,43.810,63.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 3.348 |  Acc: 52.730,69.486,89.270,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=88 | Loss: 8.283 |  Acc: 33.030,50.700,34.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 3.324 |  Acc: 52.628,69.876,89.564,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=89 | Loss: 7.568 |  Acc: 28.260,49.710,54.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 3.303 |  Acc: 52.826,70.170,89.740,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=90 | Loss: 8.310 |  Acc: 27.320,46.480,39.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 3.327 |  Acc: 52.578,69.532,89.682,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=91 | Loss: 7.755 |  Acc: 27.090,50.960,54.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 3.318 |  Acc: 52.578,69.924,89.414,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=92 | Loss: 8.050 |  Acc: 31.740,48.410,30.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 3.329 |  Acc: 52.746,69.854,89.344,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=93 | Loss: 7.804 |  Acc: 32.280,47.790,50.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 3.294 |  Acc: 52.938,70.068,89.666,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=94 | Loss: 7.733 |  Acc: 25.170,50.060,49.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 3.313 |  Acc: 52.788,69.848,89.410,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=95 | Loss: 8.947 |  Acc: 20.010,39.200,45.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 3.307 |  Acc: 52.712,70.096,89.416,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=96 | Loss: 7.615 |  Acc: 26.290,53.440,48.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 3.298 |  Acc: 52.966,70.272,89.512,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=97 | Loss: 7.583 |  Acc: 28.090,50.770,56.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 3.281 |  Acc: 52.848,70.348,89.732,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=98 | Loss: 7.418 |  Acc: 29.850,53.450,52.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 3.286 |  Acc: 53.266,70.186,89.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=99 | Loss: 7.583 |  Acc: 24.410,54.170,54.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 3.268 |  Acc: 53.372,70.652,89.824,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=100 | Loss: 7.798 |  Acc: 33.060,45.500,50.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 3.281 |  Acc: 53.232,70.486,89.560,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=101 | Loss: 7.968 |  Acc: 31.710,47.950,43.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 3.250 |  Acc: 53.396,70.546,89.894,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=102 | Loss: 8.671 |  Acc: 25.100,43.460,42.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 3.261 |  Acc: 53.130,70.684,89.790,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=103 | Loss: 7.843 |  Acc: 32.670,47.230,49.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 3.258 |  Acc: 53.236,70.678,89.716,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=104 | Loss: 8.166 |  Acc: 29.430,48.640,39.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 3.247 |  Acc: 53.214,70.580,89.898,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=105 | Loss: 7.840 |  Acc: 30.960,49.880,48.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 3.244 |  Acc: 53.448,70.940,89.854,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=106 | Loss: 8.095 |  Acc: 27.330,45.930,47.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 3.249 |  Acc: 53.646,70.608,90.016,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=107 | Loss: 7.691 |  Acc: 24.700,50.260,56.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 3.243 |  Acc: 53.266,70.712,89.798,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=108 | Loss: 7.648 |  Acc: 28.300,50.490,56.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 3.244 |  Acc: 53.592,70.668,90.064,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=109 | Loss: 7.960 |  Acc: 23.770,47.410,47.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 3.246 |  Acc: 53.370,70.804,90.054,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=110 | Loss: 8.072 |  Acc: 25.740,47.670,43.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 3.232 |  Acc: 53.424,70.776,90.148,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=111 | Loss: 7.840 |  Acc: 29.140,46.450,55.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 3.226 |  Acc: 53.426,71.168,89.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=112 | Loss: 7.415 |  Acc: 30.910,51.330,51.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 3.228 |  Acc: 53.340,70.910,90.042,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=113 | Loss: 8.476 |  Acc: 30.810,45.020,26.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 3.234 |  Acc: 53.084,71.046,90.024,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=114 | Loss: 8.132 |  Acc: 27.300,44.620,51.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 3.235 |  Acc: 53.666,70.856,89.926,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=115 | Loss: 8.065 |  Acc: 30.780,37.290,46.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 3.205 |  Acc: 53.442,71.108,90.164,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=116 | Loss: 7.926 |  Acc: 33.780,48.120,41.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 3.218 |  Acc: 53.634,71.160,90.240,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=117 | Loss: 7.696 |  Acc: 28.970,50.120,46.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 3.213 |  Acc: 53.422,70.886,89.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=118 | Loss: 8.236 |  Acc: 26.080,51.860,43.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 3.195 |  Acc: 53.864,71.360,90.160,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=119 | Loss: 8.652 |  Acc: 27.170,47.690,19.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 3.216 |  Acc: 53.684,71.014,90.044,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=120 | Loss: 7.343 |  Acc: 32.010,53.800,52.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 3.200 |  Acc: 53.726,71.514,90.358,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=121 | Loss: 7.497 |  Acc: 28.990,51.140,52.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 3.202 |  Acc: 53.588,71.618,90.130,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=122 | Loss: 7.460 |  Acc: 29.260,56.820,50.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 3.200 |  Acc: 53.566,71.280,90.148,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=123 | Loss: 8.557 |  Acc: 28.520,51.990,35.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 3.213 |  Acc: 53.858,71.148,89.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=124 | Loss: 7.809 |  Acc: 34.520,54.190,43.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 3.165 |  Acc: 54.126,71.592,90.374,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=125 | Loss: 7.630 |  Acc: 25.090,52.750,47.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 3.196 |  Acc: 53.808,71.416,90.264,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=126 | Loss: 7.998 |  Acc: 31.800,47.490,46.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 3.193 |  Acc: 53.594,71.232,90.232,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=127 | Loss: 8.162 |  Acc: 27.900,49.690,48.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 3.170 |  Acc: 53.950,71.644,90.452,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=128 | Loss: 6.987 |  Acc: 35.020,52.900,57.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 3.179 |  Acc: 53.992,71.774,90.074,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=129 | Loss: 7.998 |  Acc: 32.850,50.370,42.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 3.167 |  Acc: 53.670,71.852,90.128,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=130 | Loss: 8.154 |  Acc: 33.500,46.160,42.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 3.188 |  Acc: 53.796,71.278,90.418,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=131 | Loss: 7.634 |  Acc: 32.300,54.360,39.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 3.183 |  Acc: 53.980,71.466,90.112,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=132 | Loss: 8.550 |  Acc: 24.160,49.720,37.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 3.179 |  Acc: 54.024,71.402,90.192,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=133 | Loss: 7.806 |  Acc: 30.520,50.660,51.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 3.169 |  Acc: 54.118,71.632,90.304,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=134 | Loss: 8.149 |  Acc: 31.330,53.680,26.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 3.178 |  Acc: 53.814,71.302,90.360,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=135 | Loss: 7.688 |  Acc: 25.780,53.380,42.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 3.145 |  Acc: 54.194,71.946,90.478,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=136 | Loss: 7.794 |  Acc: 30.900,44.870,49.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 3.168 |  Acc: 53.816,71.782,90.246,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=137 | Loss: 7.468 |  Acc: 30.490,51.850,52.130,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 3.162 |  Acc: 54.296,71.640,90.312,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=138 | Loss: 7.775 |  Acc: 26.790,53.730,53.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 3.167 |  Acc: 54.248,71.772,90.222,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=139 | Loss: 7.696 |  Acc: 25.590,51.530,53.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 3.133 |  Acc: 54.292,71.940,90.650,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=140 | Loss: 8.020 |  Acc: 26.030,48.470,47.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 3.165 |  Acc: 53.986,71.772,90.138,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=141 | Loss: 8.566 |  Acc: 26.870,48.410,38.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 3.150 |  Acc: 54.034,72.152,90.218,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=142 | Loss: 7.609 |  Acc: 36.310,46.920,50.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 3.161 |  Acc: 54.098,71.736,90.532,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=143 | Loss: 8.173 |  Acc: 28.080,48.710,43.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 3.138 |  Acc: 54.126,72.086,90.572,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=144 | Loss: 8.128 |  Acc: 33.760,46.490,32.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 3.159 |  Acc: 54.192,71.808,90.492,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=145 | Loss: 8.408 |  Acc: 29.780,50.780,39.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 3.152 |  Acc: 54.414,71.746,90.160,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=146 | Loss: 8.089 |  Acc: 26.280,55.380,36.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 3.148 |  Acc: 54.294,71.834,90.350,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=147 | Loss: 8.580 |  Acc: 22.830,48.680,38.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 3.117 |  Acc: 54.482,72.372,90.874,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=148 | Loss: 7.959 |  Acc: 28.580,50.210,46.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 3.105 |  Acc: 54.568,72.326,90.796,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=149 | Loss: 9.389 |  Acc: 22.210,45.210,19.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.523 |  Acc: 58.744,79.220,95.914,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=150 | Loss: 6.871 |  Acc: 38.100,62.920,54.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 2.321 |  Acc: 60.190,82.016,97.758,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=151 | Loss: 7.340 |  Acc: 37.930,62.080,45.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 2.237 |  Acc: 60.960,83.330,98.348,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=152 | Loss: 7.088 |  Acc: 36.530,61.740,55.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 2.187 |  Acc: 61.490,83.994,98.576,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=153 | Loss: 7.127 |  Acc: 40.380,61.500,49.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 2.167 |  Acc: 61.276,84.398,98.732,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=154 | Loss: 6.905 |  Acc: 41.360,61.620,57.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 2.137 |  Acc: 61.178,84.838,98.892,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=155 | Loss: 6.415 |  Acc: 42.960,63.460,62.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 2.114 |  Acc: 61.678,85.326,99.038,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=156 | Loss: 6.957 |  Acc: 38.200,60.770,58.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 2.079 |  Acc: 62.022,85.482,99.088,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=157 | Loss: 7.089 |  Acc: 42.380,60.160,56.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 2.063 |  Acc: 61.986,86.176,99.200,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=158 | Loss: 7.190 |  Acc: 41.120,58.010,57.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 2.056 |  Acc: 62.262,86.130,99.266,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=159 | Loss: 7.353 |  Acc: 37.560,59.730,55.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 2.034 |  Acc: 62.078,86.394,99.242,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=160 | Loss: 7.153 |  Acc: 42.230,60.390,55.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 2.018 |  Acc: 62.504,86.384,99.252,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=161 | Loss: 7.085 |  Acc: 33.080,60.330,61.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 2.014 |  Acc: 62.490,86.708,99.302,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=162 | Loss: 7.227 |  Acc: 38.950,58.620,60.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.989 |  Acc: 62.582,87.072,99.368,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=163 | Loss: 6.765 |  Acc: 42.730,60.430,63.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.995 |  Acc: 62.748,87.108,99.352,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=164 | Loss: 7.067 |  Acc: 33.120,57.700,66.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.984 |  Acc: 62.846,87.230,99.310,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=165 | Loss: 7.010 |  Acc: 38.620,57.410,62.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.969 |  Acc: 62.972,87.110,99.388,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=166 | Loss: 6.972 |  Acc: 34.130,58.100,65.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.942 |  Acc: 63.116,87.840,99.416,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=167 | Loss: 6.690 |  Acc: 43.600,61.840,61.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.944 |  Acc: 63.062,87.712,99.464,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=168 | Loss: 7.471 |  Acc: 39.900,56.920,55.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.953 |  Acc: 63.250,87.674,99.386,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=169 | Loss: 7.077 |  Acc: 35.480,60.010,62.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.939 |  Acc: 63.136,88.002,99.450,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=170 | Loss: 7.333 |  Acc: 34.780,56.110,61.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.930 |  Acc: 63.284,88.162,99.432,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=171 | Loss: 6.791 |  Acc: 40.470,61.170,62.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.912 |  Acc: 63.416,88.070,99.500,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=172 | Loss: 7.301 |  Acc: 37.530,56.250,60.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.895 |  Acc: 63.852,88.514,99.454,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=173 | Loss: 6.764 |  Acc: 38.870,59.830,65.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.889 |  Acc: 63.554,88.586,99.464,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=174 | Loss: 7.224 |  Acc: 31.860,55.900,65.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.886 |  Acc: 63.676,88.636,99.512,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=175 | Loss: 7.006 |  Acc: 42.640,57.630,62.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.889 |  Acc: 63.682,88.682,99.492,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=176 | Loss: 7.073 |  Acc: 38.640,58.050,63.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.879 |  Acc: 63.614,88.570,99.554,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=177 | Loss: 6.759 |  Acc: 39.200,60.850,63.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.875 |  Acc: 63.988,88.630,99.558,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=178 | Loss: 7.193 |  Acc: 37.710,55.950,63.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.872 |  Acc: 63.562,88.832,99.542,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=179 | Loss: 7.475 |  Acc: 37.070,56.960,58.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.864 |  Acc: 63.798,88.950,99.542,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=180 | Loss: 6.904 |  Acc: 38.850,59.530,62.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.863 |  Acc: 64.052,88.980,99.538,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=181 | Loss: 6.937 |  Acc: 35.680,60.720,62.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.863 |  Acc: 63.978,88.950,99.566,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=182 | Loss: 6.874 |  Acc: 34.220,60.980,64.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.846 |  Acc: 63.994,88.818,99.568,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=183 | Loss: 7.689 |  Acc: 38.070,52.800,56.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.840 |  Acc: 63.950,89.488,99.524,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=184 | Loss: 7.592 |  Acc: 33.550,52.560,61.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.836 |  Acc: 64.050,89.206,99.546,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=185 | Loss: 6.895 |  Acc: 43.350,60.030,60.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.842 |  Acc: 64.020,89.284,99.606,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=186 | Loss: 6.751 |  Acc: 36.990,61.580,64.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.817 |  Acc: 64.392,89.564,99.608,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=187 | Loss: 7.044 |  Acc: 37.990,60.610,61.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.823 |  Acc: 64.174,89.266,99.546,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=188 | Loss: 6.727 |  Acc: 38.710,61.800,64.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.824 |  Acc: 64.090,89.810,99.546,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=189 | Loss: 6.491 |  Acc: 36.000,59.670,68.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.820 |  Acc: 64.464,89.602,99.572,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=190 | Loss: 6.912 |  Acc: 28.920,62.980,64.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.816 |  Acc: 64.160,89.668,99.580,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=191 | Loss: 6.973 |  Acc: 35.230,56.620,67.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.799 |  Acc: 64.542,89.888,99.602,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=192 | Loss: 7.430 |  Acc: 37.510,53.160,64.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.805 |  Acc: 64.532,89.758,99.556,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=193 | Loss: 7.242 |  Acc: 32.160,57.180,64.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.793 |  Acc: 64.632,89.964,99.580,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=194 | Loss: 6.886 |  Acc: 33.540,59.490,65.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.812 |  Acc: 64.324,89.936,99.560,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=195 | Loss: 7.104 |  Acc: 38.330,52.820,65.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.789 |  Acc: 64.314,90.200,99.624,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=196 | Loss: 7.415 |  Acc: 31.870,48.930,64.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.797 |  Acc: 64.398,89.980,99.554,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=197 | Loss: 7.766 |  Acc: 31.950,50.450,60.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.796 |  Acc: 64.562,90.004,99.596,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=198 | Loss: 6.524 |  Acc: 37.250,60.430,67.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.783 |  Acc: 64.682,90.060,99.588,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=199 | Loss: 7.296 |  Acc: 32.680,58.710,60.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.778 |  Acc: 64.610,90.058,99.578,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=200 | Loss: 7.188 |  Acc: 35.880,57.270,62.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.783 |  Acc: 64.670,89.908,99.538,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=201 | Loss: 7.114 |  Acc: 37.280,56.050,61.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.798 |  Acc: 64.568,89.824,99.536,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=202 | Loss: 6.724 |  Acc: 40.620,57.530,65.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.774 |  Acc: 64.934,90.336,99.606,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=203 | Loss: 7.207 |  Acc: 38.850,54.300,62.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.766 |  Acc: 64.918,90.280,99.572,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=204 | Loss: 7.553 |  Acc: 39.480,49.640,60.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.753 |  Acc: 64.950,90.460,99.586,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=205 | Loss: 7.158 |  Acc: 35.790,55.940,63.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.767 |  Acc: 64.898,90.402,99.670,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=206 | Loss: 7.170 |  Acc: 30.440,56.620,64.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.773 |  Acc: 65.014,90.284,99.638,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=207 | Loss: 7.581 |  Acc: 35.990,48.620,60.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.775 |  Acc: 64.602,90.132,99.588,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=208 | Loss: 7.153 |  Acc: 35.450,54.680,63.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.757 |  Acc: 64.916,90.540,99.610,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=209 | Loss: 7.584 |  Acc: 33.410,51.490,60.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.754 |  Acc: 64.976,90.508,99.528,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=210 | Loss: 7.543 |  Acc: 36.580,48.310,60.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.765 |  Acc: 64.864,90.438,99.626,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=211 | Loss: 7.285 |  Acc: 35.250,51.000,63.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.771 |  Acc: 64.708,90.256,99.578,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=212 | Loss: 7.197 |  Acc: 28.900,54.150,66.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.759 |  Acc: 65.008,90.392,99.584,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=213 | Loss: 6.967 |  Acc: 36.210,57.540,63.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.761 |  Acc: 64.916,90.546,99.562,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=214 | Loss: 6.996 |  Acc: 37.370,51.470,64.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.747 |  Acc: 65.304,90.686,99.580,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=215 | Loss: 6.964 |  Acc: 43.360,57.670,58.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.742 |  Acc: 65.184,90.594,99.602,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=216 | Loss: 7.944 |  Acc: 28.860,45.250,61.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.737 |  Acc: 65.490,90.634,99.580,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=217 | Loss: 7.203 |  Acc: 32.020,49.750,66.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.753 |  Acc: 64.966,90.546,99.612,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=218 | Loss: 7.621 |  Acc: 35.420,50.550,60.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.739 |  Acc: 65.266,90.598,99.586,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=219 | Loss: 8.176 |  Acc: 32.140,40.820,58.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.745 |  Acc: 65.122,90.720,99.592,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=220 | Loss: 7.315 |  Acc: 31.170,57.870,62.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.733 |  Acc: 65.116,90.738,99.630,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=221 | Loss: 7.441 |  Acc: 35.840,56.820,55.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.742 |  Acc: 64.988,90.468,99.590,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=222 | Loss: 7.058 |  Acc: 44.030,52.320,57.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.731 |  Acc: 65.408,90.670,99.534,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=223 | Loss: 7.405 |  Acc: 33.060,49.410,63.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.740 |  Acc: 65.598,90.498,99.530,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=224 | Loss: 7.355 |  Acc: 38.270,52.660,59.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.618 |  Acc: 66.844,92.816,99.678,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=225 | Loss: 7.270 |  Acc: 36.300,50.030,64.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.581 |  Acc: 67.172,93.680,99.756,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=226 | Loss: 8.090 |  Acc: 28.860,50.190,54.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.576 |  Acc: 67.004,93.860,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=227 | Loss: 7.222 |  Acc: 37.400,53.460,62.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.577 |  Acc: 67.178,93.946,99.802,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=228 | Loss: 7.373 |  Acc: 35.310,51.720,62.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.569 |  Acc: 67.144,93.932,99.794,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=229 | Loss: 7.169 |  Acc: 43.600,51.920,59.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.569 |  Acc: 67.214,93.976,99.770,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=230 | Loss: 7.649 |  Acc: 31.080,49.960,61.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.548 |  Acc: 67.494,94.208,99.808,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=231 | Loss: 7.178 |  Acc: 35.880,55.600,60.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.555 |  Acc: 67.346,94.018,99.802,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=232 | Loss: 7.490 |  Acc: 34.080,53.190,57.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.551 |  Acc: 67.638,94.004,99.750,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=233 | Loss: 6.892 |  Acc: 36.450,52.080,67.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.537 |  Acc: 67.402,94.384,99.774,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=234 | Loss: 7.956 |  Acc: 28.960,39.690,63.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.541 |  Acc: 67.588,94.216,99.772,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=235 | Loss: 7.359 |  Acc: 35.680,50.220,62.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.545 |  Acc: 67.198,94.238,99.800,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=236 | Loss: 7.221 |  Acc: 40.650,48.670,62.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.543 |  Acc: 67.602,94.394,99.814,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=237 | Loss: 7.341 |  Acc: 36.420,50.700,61.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.547 |  Acc: 67.542,94.328,99.736,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=238 | Loss: 7.505 |  Acc: 31.510,51.850,61.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.542 |  Acc: 67.464,94.398,99.810,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=239 | Loss: 7.774 |  Acc: 31.480,43.610,63.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.545 |  Acc: 67.644,94.344,99.778,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=240 | Loss: 7.411 |  Acc: 37.100,49.860,61.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.543 |  Acc: 67.478,94.462,99.786,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=241 | Loss: 7.751 |  Acc: 26.120,48.520,63.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.532 |  Acc: 67.480,94.506,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=242 | Loss: 7.722 |  Acc: 30.660,55.880,55.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.540 |  Acc: 67.568,94.448,99.784,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=243 | Loss: 6.841 |  Acc: 34.630,58.750,62.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.532 |  Acc: 67.588,94.464,99.816,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=244 | Loss: 7.726 |  Acc: 31.420,46.120,60.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.547 |  Acc: 67.610,94.532,99.800,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=245 | Loss: 7.610 |  Acc: 34.600,48.750,60.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.528 |  Acc: 67.594,94.536,99.822,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=246 | Loss: 7.474 |  Acc: 30.320,55.710,57.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.527 |  Acc: 67.450,94.586,99.824,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=247 | Loss: 8.019 |  Acc: 26.070,46.900,58.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.533 |  Acc: 67.472,94.578,99.782,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=248 | Loss: 7.614 |  Acc: 31.860,54.290,57.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.537 |  Acc: 67.508,94.584,99.814,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=249 | Loss: 6.992 |  Acc: 33.870,53.670,67.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.533 |  Acc: 67.482,94.580,99.796,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=250 | Loss: 6.664 |  Acc: 42.830,55.530,65.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.524 |  Acc: 67.712,94.558,99.786,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=251 | Loss: 7.076 |  Acc: 36.070,53.790,62.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.534 |  Acc: 67.588,94.616,99.812,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=252 | Loss: 6.774 |  Acc: 35.850,56.300,64.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.538 |  Acc: 67.306,94.552,99.804,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=253 | Loss: 7.401 |  Acc: 28.890,49.880,65.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.528 |  Acc: 67.750,94.376,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=254 | Loss: 7.591 |  Acc: 29.640,49.930,61.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.526 |  Acc: 67.356,94.676,99.806,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=255 | Loss: 7.682 |  Acc: 30.020,52.740,58.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.525 |  Acc: 67.744,94.426,99.830,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=256 | Loss: 7.696 |  Acc: 32.770,45.330,61.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.530 |  Acc: 67.668,94.670,99.776,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=257 | Loss: 7.790 |  Acc: 27.110,54.040,57.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.526 |  Acc: 67.488,94.456,99.788,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=258 | Loss: 7.244 |  Acc: 34.860,53.740,62.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.532 |  Acc: 67.396,94.584,99.766,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=259 | Loss: 7.354 |  Acc: 39.240,47.610,60.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.530 |  Acc: 67.390,94.660,99.802,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=260 | Loss: 7.668 |  Acc: 29.200,52.040,60.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.516 |  Acc: 68.006,94.658,99.804,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=261 | Loss: 6.930 |  Acc: 36.810,54.780,64.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.519 |  Acc: 67.768,94.686,99.808,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=262 | Loss: 7.306 |  Acc: 39.640,46.820,61.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.511 |  Acc: 68.004,94.966,99.794,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=263 | Loss: 7.183 |  Acc: 34.120,56.000,62.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.507 |  Acc: 67.912,95.042,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=264 | Loss: 7.892 |  Acc: 33.960,52.910,51.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.510 |  Acc: 68.138,94.996,99.808,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=265 | Loss: 7.689 |  Acc: 31.940,47.930,61.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.502 |  Acc: 68.176,95.056,99.824,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=266 | Loss: 7.170 |  Acc: 35.470,53.150,64.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.498 |  Acc: 68.136,94.948,99.802,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=267 | Loss: 7.319 |  Acc: 35.410,53.770,60.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.498 |  Acc: 67.934,94.966,99.834,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=268 | Loss: 8.149 |  Acc: 26.750,47.700,53.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.508 |  Acc: 67.944,95.130,99.808,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=269 | Loss: 7.430 |  Acc: 32.320,53.180,59.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.509 |  Acc: 67.958,94.938,99.826,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=270 | Loss: 7.650 |  Acc: 32.690,53.690,54.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.497 |  Acc: 68.072,94.908,99.814,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=271 | Loss: 7.632 |  Acc: 28.590,52.470,60.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.507 |  Acc: 67.968,95.016,99.794,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=272 | Loss: 7.916 |  Acc: 34.770,44.820,54.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.501 |  Acc: 68.212,94.868,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=273 | Loss: 7.783 |  Acc: 27.830,48.870,60.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.509 |  Acc: 67.962,94.888,99.820,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=274 | Loss: 7.177 |  Acc: 37.620,49.510,64.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.507 |  Acc: 68.032,95.008,99.804,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=275 | Loss: 7.776 |  Acc: 25.270,55.270,58.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.508 |  Acc: 67.826,94.958,99.812,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=276 | Loss: 7.944 |  Acc: 28.360,49.790,55.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.505 |  Acc: 67.992,95.178,99.790,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=277 | Loss: 7.795 |  Acc: 31.070,46.500,59.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.511 |  Acc: 67.738,94.950,99.844,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=278 | Loss: 7.306 |  Acc: 42.420,52.370,55.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.500 |  Acc: 67.746,95.204,99.828,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=279 | Loss: 6.942 |  Acc: 39.060,57.750,60.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.496 |  Acc: 67.970,94.956,99.838,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=280 | Loss: 7.411 |  Acc: 34.920,54.540,57.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.507 |  Acc: 67.788,95.138,99.772,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=281 | Loss: 7.294 |  Acc: 32.120,53.520,62.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.505 |  Acc: 67.630,95.154,99.828,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=282 | Loss: 7.304 |  Acc: 33.200,51.870,61.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.508 |  Acc: 67.862,94.962,99.864,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=283 | Loss: 7.522 |  Acc: 30.620,53.230,59.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.503 |  Acc: 67.970,95.068,99.822,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=284 | Loss: 7.519 |  Acc: 28.830,50.960,61.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.503 |  Acc: 67.854,95.004,99.834,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=285 | Loss: 7.185 |  Acc: 40.080,52.110,61.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.498 |  Acc: 68.060,94.980,99.834,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=286 | Loss: 7.460 |  Acc: 30.330,53.140,60.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.509 |  Acc: 68.176,95.022,99.838,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=287 | Loss: 7.903 |  Acc: 32.580,47.550,55.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.520 |  Acc: 67.730,95.058,99.818,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=288 | Loss: 7.667 |  Acc: 35.170,41.360,62.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.503 |  Acc: 67.844,95.168,99.824,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=289 | Loss: 7.143 |  Acc: 37.660,58.020,58.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.502 |  Acc: 67.716,95.198,99.816,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=290 | Loss: 7.414 |  Acc: 37.250,47.700,60.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.504 |  Acc: 68.048,95.120,99.820,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=291 | Loss: 7.801 |  Acc: 31.610,52.310,53.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.506 |  Acc: 67.948,95.050,99.796,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=292 | Loss: 7.302 |  Acc: 39.860,51.930,58.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.506 |  Acc: 67.846,94.966,99.832,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=293 | Loss: 7.276 |  Acc: 32.950,47.130,66.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.507 |  Acc: 67.742,94.998,99.796,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=294 | Loss: 7.639 |  Acc: 31.040,50.560,60.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.508 |  Acc: 68.032,95.138,99.832,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=295 | Loss: 7.125 |  Acc: 36.050,56.910,59.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.504 |  Acc: 68.122,95.120,99.796,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=296 | Loss: 7.609 |  Acc: 37.630,48.570,56.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.493 |  Acc: 68.222,95.184,99.840,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=297 | Loss: 7.807 |  Acc: 29.930,54.390,53.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.506 |  Acc: 67.902,95.136,99.834,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=298 | Loss: 7.688 |  Acc: 33.740,45.720,59.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=3, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.505 |  Acc: 68.098,94.986,99.798,% | Adaptive Acc:92.762% | clf_exit: 0.517 0.408 0.074 
Testing: Epoch=299 | Loss: 7.930 |  Acc: 30.930,47.010,56.150,% | Adaptive Acc:57.110% | clf_exit: 0.093 0.082 0.824 
Testing: Epoch=299 | Loss: 7.930 |  Acc: 30.930,47.010,56.150,% | Adaptive Acc:57.110% | clf_exit: 0.093 0.082 0.824 
Testing: Epoch=299 | Loss: 4.557 |  Acc: 54.740,67.290,72.990,% | Adaptive Acc:69.920% | clf_exit: 0.389 0.279 0.332 
Testing: Epoch=299 | Loss: 4.383 |  Acc: 57.220,68.360,73.760,% | Adaptive Acc:66.870% | clf_exit: 0.630 0.253 0.117 
Testing: Epoch=299 | Loss: 5.319 |  Acc: 55.590,66.830,73.390,% | Adaptive Acc:61.640% | clf_exit: 0.767 0.174 0.059 
