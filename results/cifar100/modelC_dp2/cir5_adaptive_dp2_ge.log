==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=128, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=128, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=356, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=356, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=612, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=612, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 15.116 | Acc: 1.562,0.781,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.750 | Acc: 2.753,3.348,5.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.293 | Acc: 4.116,4.421,6.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.044 | Acc: 4.623,4.995,7.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.835 | Acc: 5.073,5.999,8.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.673 | Acc: 5.546,6.838,9.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.545 | Acc: 6.160,7.419,9.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.439 | Acc: 6.505,7.779,10.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.348 | Acc: 6.721,8.113,10.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.259 | Acc: 6.867,8.507,11.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.172 | Acc: 7.222,8.951,11.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.100 | Acc: 7.417,9.276,11.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.034 | Acc: 7.599,9.641,12.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.971 | Acc: 7.860,9.980,12.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.912 | Acc: 8.110,10.276,13.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.851 | Acc: 8.368,10.535,13.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.793 | Acc: 8.633,10.869,13.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.739 | Acc: 8.866,11.222,14.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.689 | Acc: 9.050,11.466,14.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.640 | Acc: 9.264,11.747,15.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.567 | Acc: 1.562,0.781,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.534 | Acc: 2.790,1.153,5.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.531 | Acc: 2.668,1.048,5.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.556 | Acc: 2.651,1.012,4.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 10.166 | Acc: 15.625,21.875,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.668 | Acc: 12.798,17.039,21.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.596 | Acc: 13.186,17.569,22.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.606 | Acc: 13.281,17.252,22.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.544 | Acc: 13.407,17.255,23.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.506 | Acc: 13.560,17.652,23.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.464 | Acc: 13.920,17.943,23.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.419 | Acc: 14.135,18.179,24.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.394 | Acc: 14.213,18.299,24.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.362 | Acc: 14.304,18.582,24.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.340 | Acc: 14.443,18.668,24.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.313 | Acc: 14.586,18.743,25.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.287 | Acc: 14.652,18.935,25.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.253 | Acc: 14.778,19.094,25.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.215 | Acc: 14.969,19.287,25.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.183 | Acc: 15.199,19.547,26.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.152 | Acc: 15.369,19.721,26.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.115 | Acc: 15.522,19.962,26.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.086 | Acc: 15.649,20.077,26.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.055 | Acc: 15.822,20.253,27.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.121 | Acc: 3.125,2.344,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.115 | Acc: 3.534,1.897,8.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.106 | Acc: 3.678,1.734,8.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.131 | Acc: 3.727,1.716,8.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 9.629 | Acc: 18.750,28.906,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.438 | Acc: 19.717,23.810,31.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.441 | Acc: 18.864,22.904,31.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.379 | Acc: 18.904,23.245,32.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.354 | Acc: 19.290,23.698,33.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.334 | Acc: 19.400,23.940,33.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.340 | Acc: 19.215,23.767,33.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.319 | Acc: 19.426,23.980,33.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.291 | Acc: 19.594,24.175,33.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.269 | Acc: 19.885,24.374,33.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.254 | Acc: 19.932,24.464,33.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.224 | Acc: 20.065,24.682,33.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.216 | Acc: 20.099,24.780,33.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.203 | Acc: 20.106,24.805,34.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.193 | Acc: 20.090,24.789,34.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.175 | Acc: 20.201,24.974,34.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.157 | Acc: 20.381,25.148,34.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.140 | Acc: 20.418,25.270,34.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.129 | Acc: 20.520,25.284,34.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.112 | Acc: 20.544,25.322,34.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.698 | Acc: 7.812,1.562,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.728 | Acc: 7.031,1.339,9.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.731 | Acc: 6.993,1.162,9.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.758 | Acc: 7.006,1.114,9.670,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 7.885 | Acc: 27.344,31.250,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.660 | Acc: 22.173,27.455,38.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.626 | Acc: 22.675,27.954,39.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.585 | Acc: 23.220,28.445,40.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.581 | Acc: 23.302,28.655,40.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.555 | Acc: 23.298,28.775,40.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.542 | Acc: 23.541,28.977,40.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.529 | Acc: 23.498,29.000,40.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.524 | Acc: 23.471,29.013,40.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.505 | Acc: 23.528,29.126,40.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.494 | Acc: 23.589,29.248,40.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.474 | Acc: 23.674,29.341,40.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.466 | Acc: 23.739,29.337,40.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.450 | Acc: 23.806,29.382,40.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.436 | Acc: 23.888,29.507,40.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.426 | Acc: 23.897,29.558,40.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.426 | Acc: 23.893,29.507,40.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.414 | Acc: 23.923,29.541,40.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.403 | Acc: 23.966,29.707,40.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.392 | Acc: 23.997,29.765,40.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.324 | Acc: 7.812,3.125,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.373 | Acc: 7.217,2.679,12.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.364 | Acc: 7.088,2.534,11.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.384 | Acc: 7.159,2.459,11.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 7.284 | Acc: 26.562,32.031,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.848 | Acc: 27.195,33.929,45.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.961 | Acc: 25.553,32.088,44.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.919 | Acc: 25.897,32.275,45.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.926 | Acc: 25.868,32.340,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.959 | Acc: 25.727,32.093,44.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.954 | Acc: 25.826,32.206,44.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.945 | Acc: 25.615,32.186,44.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.941 | Acc: 25.582,32.085,44.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.943 | Acc: 25.578,32.187,44.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.943 | Acc: 25.583,32.319,44.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.938 | Acc: 25.604,32.286,44.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.930 | Acc: 25.781,32.414,44.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.924 | Acc: 25.724,32.498,44.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.910 | Acc: 25.809,32.551,44.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.912 | Acc: 25.771,32.607,44.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.901 | Acc: 25.767,32.718,44.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.891 | Acc: 25.887,32.808,44.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.891 | Acc: 25.926,32.804,44.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.879 | Acc: 25.990,32.878,45.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.165 | Acc: 8.594,10.938,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.101 | Acc: 7.180,9.821,8.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.103 | Acc: 7.260,9.832,8.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.119 | Acc: 6.839,9.734,8.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 7.576 | Acc: 35.156,40.625,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.556 | Acc: 26.711,35.231,49.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.606 | Acc: 26.867,35.080,48.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.671 | Acc: 26.588,34.631,47.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.651 | Acc: 26.640,34.578,47.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.626 | Acc: 26.996,34.947,47.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.599 | Acc: 27.234,35.008,48.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.605 | Acc: 27.028,34.735,47.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.602 | Acc: 27.106,34.943,47.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.577 | Acc: 27.314,35.230,48.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.573 | Acc: 27.418,35.199,47.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.557 | Acc: 27.489,35.216,48.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.540 | Acc: 27.629,35.322,48.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.533 | Acc: 27.766,35.444,48.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.526 | Acc: 27.811,35.490,48.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.523 | Acc: 27.816,35.494,48.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.517 | Acc: 27.784,35.456,48.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.510 | Acc: 27.843,35.557,48.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.490 | Acc: 27.999,35.643,48.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.471 | Acc: 28.082,35.771,48.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.111 | Acc: 7.812,9.375,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.058 | Acc: 6.771,8.333,11.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.044 | Acc: 7.317,8.460,11.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.069 | Acc: 7.185,8.466,10.873,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 7.473 | Acc: 28.906,33.594,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.220 | Acc: 30.097,37.463,50.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.225 | Acc: 30.164,36.300,51.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.193 | Acc: 29.700,36.501,51.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.185 | Acc: 29.620,36.709,51.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.181 | Acc: 29.649,37.106,51.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.185 | Acc: 29.778,37.306,51.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.188 | Acc: 29.787,37.206,51.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.186 | Acc: 29.620,37.068,51.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.185 | Acc: 29.713,37.051,51.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.185 | Acc: 29.785,37.123,51.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.177 | Acc: 29.868,37.207,51.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.156 | Acc: 30.025,37.403,51.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.152 | Acc: 30.113,37.440,51.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.143 | Acc: 30.188,37.586,51.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.138 | Acc: 30.178,37.676,51.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.148 | Acc: 30.128,37.573,51.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.138 | Acc: 30.159,37.644,51.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.126 | Acc: 30.222,37.855,51.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.114 | Acc: 30.305,37.996,51.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.696 | Acc: 19.531,10.938,7.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.725 | Acc: 13.914,11.421,10.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.726 | Acc: 13.796,11.185,10.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.749 | Acc: 13.512,11.014,10.374,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 7.493 | Acc: 27.344,31.250,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.752 | Acc: 31.659,40.067,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.805 | Acc: 31.269,39.977,55.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.809 | Acc: 31.647,40.523,55.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.804 | Acc: 31.829,40.702,55.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.808 | Acc: 31.598,40.555,54.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.810 | Acc: 31.741,40.541,54.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.795 | Acc: 31.704,40.680,54.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.791 | Acc: 31.798,40.576,54.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.786 | Acc: 31.897,40.651,54.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.810 | Acc: 31.748,40.485,54.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.801 | Acc: 31.706,40.459,54.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.808 | Acc: 31.678,40.421,54.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.804 | Acc: 31.714,40.332,54.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.811 | Acc: 31.661,40.269,54.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.803 | Acc: 31.683,40.311,54.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.798 | Acc: 31.749,40.394,54.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.791 | Acc: 31.825,40.430,54.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.782 | Acc: 31.895,40.491,54.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.783 | Acc: 31.882,40.537,54.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.639 | Acc: 11.719,7.031,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.552 | Acc: 9.487,10.342,16.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.557 | Acc: 9.566,10.709,16.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.570 | Acc: 9.452,10.784,16.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 6.652 | Acc: 36.719,47.656,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.518 | Acc: 31.845,42.336,57.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.522 | Acc: 32.851,42.702,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.519 | Acc: 33.094,43.007,57.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.517 | Acc: 33.256,42.921,57.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.541 | Acc: 33.099,42.342,57.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.533 | Acc: 33.129,42.607,57.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.525 | Acc: 33.173,42.548,57.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.516 | Acc: 33.438,42.678,57.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.521 | Acc: 33.348,42.593,57.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.527 | Acc: 33.287,42.514,57.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.531 | Acc: 33.336,42.396,57.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.543 | Acc: 33.318,42.350,57.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.537 | Acc: 33.348,42.415,57.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.527 | Acc: 33.499,42.521,57.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.528 | Acc: 33.459,42.486,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.526 | Acc: 33.540,42.523,57.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.526 | Acc: 33.532,42.540,57.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.520 | Acc: 33.542,42.590,57.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.513 | Acc: 33.625,42.626,57.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.120 | Acc: 13.281,14.062,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.279 | Acc: 10.193,13.542,17.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.276 | Acc: 10.480,13.834,17.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.299 | Acc: 10.156,13.473,17.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 6.141 | Acc: 35.156,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.308 | Acc: 34.487,45.164,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.251 | Acc: 34.851,45.312,59.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.276 | Acc: 34.477,44.826,59.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.254 | Acc: 34.529,44.454,59.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.238 | Acc: 34.739,44.694,59.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.238 | Acc: 34.717,44.589,59.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.239 | Acc: 34.824,44.476,59.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.259 | Acc: 34.724,44.454,59.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.290 | Acc: 34.565,44.264,59.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.286 | Acc: 34.468,44.240,59.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.293 | Acc: 34.375,44.111,59.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.272 | Acc: 34.540,44.275,59.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.275 | Acc: 34.498,44.247,59.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.279 | Acc: 34.453,44.253,59.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.288 | Acc: 34.466,44.106,59.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.286 | Acc: 34.472,44.096,59.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.287 | Acc: 34.506,44.078,59.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.291 | Acc: 34.511,44.122,59.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.281 | Acc: 34.603,44.259,59.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.516 | Acc: 7.031,14.062,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.496 | Acc: 6.138,15.588,18.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.494 | Acc: 6.117,16.120,18.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.519 | Acc: 5.968,15.971,18.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 5.865 | Acc: 36.719,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.250 | Acc: 34.226,44.382,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.151 | Acc: 35.366,45.008,61.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.100 | Acc: 35.502,45.581,61.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.093 | Acc: 35.532,45.544,61.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.057 | Acc: 35.860,45.947,61.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.085 | Acc: 35.524,45.635,61.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.080 | Acc: 35.705,45.678,61.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.066 | Acc: 35.797,45.783,61.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.060 | Acc: 35.877,45.938,61.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.051 | Acc: 35.980,46.257,61.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.045 | Acc: 35.906,46.331,61.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.045 | Acc: 35.993,46.282,61.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.045 | Acc: 36.033,46.219,61.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.055 | Acc: 36.004,46.258,61.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.059 | Acc: 35.984,46.229,61.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.064 | Acc: 35.940,46.162,61.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.056 | Acc: 35.956,46.176,61.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.061 | Acc: 35.968,46.159,60.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.062 | Acc: 35.954,46.118,60.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.778 | Acc: 14.062,18.750,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.035 | Acc: 8.668,17.634,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.037 | Acc: 9.299,17.378,23.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.067 | Acc: 9.285,17.200,23.745,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 4.990 | Acc: 44.531,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.741 | Acc: 38.616,49.144,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.841 | Acc: 37.176,47.447,63.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.822 | Acc: 37.513,47.746,63.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.855 | Acc: 37.635,47.724,63.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.896 | Acc: 37.392,47.246,62.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.895 | Acc: 37.274,47.249,62.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.907 | Acc: 37.129,47.008,62.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.915 | Acc: 37.044,46.860,62.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.896 | Acc: 37.025,46.944,62.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.882 | Acc: 37.057,47.093,62.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.889 | Acc: 37.016,47.154,62.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.898 | Acc: 36.913,47.147,62.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.886 | Acc: 37.060,47.222,62.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.867 | Acc: 37.336,47.462,62.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.860 | Acc: 37.440,47.537,63.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.854 | Acc: 37.483,47.569,63.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.858 | Acc: 37.498,47.478,63.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.857 | Acc: 37.498,47.472,63.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.853 | Acc: 37.537,47.492,63.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.253 | Acc: 6.250,13.281,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.477 | Acc: 4.427,13.430,18.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.482 | Acc: 4.516,13.891,17.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.527 | Acc: 4.572,13.601,17.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 5.937 | Acc: 33.594,50.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.582 | Acc: 39.732,49.888,65.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.665 | Acc: 38.872,49.543,65.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.639 | Acc: 39.114,50.013,65.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.646 | Acc: 38.812,49.682,65.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.648 | Acc: 38.722,49.451,65.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.652 | Acc: 38.533,49.225,65.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.652 | Acc: 38.431,49.058,65.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.653 | Acc: 38.437,49.199,65.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.658 | Acc: 38.450,49.197,65.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.662 | Acc: 38.479,49.087,65.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.655 | Acc: 38.550,49.201,65.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.660 | Acc: 38.508,49.079,64.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.664 | Acc: 38.461,49.066,64.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.667 | Acc: 38.426,48.985,64.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.671 | Acc: 38.364,48.902,64.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.673 | Acc: 38.254,48.932,64.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.681 | Acc: 38.192,48.850,64.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.682 | Acc: 38.203,48.849,64.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.688 | Acc: 38.164,48.829,64.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.286 | Acc: 7.031,13.281,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.484 | Acc: 5.878,14.658,23.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.482 | Acc: 6.174,14.672,23.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.542 | Acc: 5.968,14.383,23.220,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 5.163 | Acc: 48.438,56.250,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.371 | Acc: 39.174,50.558,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.383 | Acc: 39.463,50.514,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.406 | Acc: 39.370,50.448,67.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.465 | Acc: 38.918,49.923,67.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.476 | Acc: 38.846,50.070,66.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.482 | Acc: 38.830,50.026,66.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.472 | Acc: 39.002,50.183,66.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.487 | Acc: 39.164,50.019,66.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.497 | Acc: 39.149,49.875,66.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.497 | Acc: 39.210,49.930,66.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.500 | Acc: 39.105,49.830,66.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.486 | Acc: 39.338,50.052,66.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.494 | Acc: 39.239,50.000,66.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.495 | Acc: 39.249,49.967,66.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.498 | Acc: 39.159,49.930,66.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.505 | Acc: 39.160,49.915,66.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.506 | Acc: 39.172,49.879,66.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.507 | Acc: 39.214,50.000,66.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.507 | Acc: 39.181,50.016,66.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.655 | Acc: 8.594,24.219,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.668 | Acc: 6.101,19.345,26.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.665 | Acc: 6.021,19.188,25.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.709 | Acc: 6.007,19.147,25.525,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 6.006 | Acc: 42.188,48.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.190 | Acc: 41.443,53.274,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.220 | Acc: 39.863,52.401,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.291 | Acc: 39.524,51.524,69.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.238 | Acc: 40.037,51.987,69.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.286 | Acc: 39.735,51.416,69.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.284 | Acc: 39.734,51.408,69.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.271 | Acc: 40.027,51.507,69.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.289 | Acc: 40.091,51.456,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.284 | Acc: 40.094,51.584,68.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.280 | Acc: 40.151,51.671,68.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.295 | Acc: 40.141,51.598,68.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.310 | Acc: 40.084,51.465,68.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.325 | Acc: 39.946,51.341,68.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.335 | Acc: 39.910,51.298,68.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.337 | Acc: 39.885,51.300,68.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.347 | Acc: 39.890,51.341,68.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.345 | Acc: 39.892,51.345,68.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.350 | Acc: 39.922,51.273,68.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.353 | Acc: 39.893,51.321,67.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.654 | Acc: 10.156,14.844,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.726 | Acc: 5.952,14.695,29.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.732 | Acc: 6.326,14.158,29.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.768 | Acc: 6.096,13.896,29.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 5.279 | Acc: 42.188,53.125,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.113 | Acc: 42.336,53.051,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.163 | Acc: 41.387,52.687,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.172 | Acc: 41.304,52.971,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.159 | Acc: 41.570,53.086,70.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.165 | Acc: 41.422,53.117,70.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.152 | Acc: 41.368,53.390,70.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.170 | Acc: 41.096,53.219,70.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.152 | Acc: 41.149,53.450,70.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.158 | Acc: 40.936,53.263,70.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.183 | Acc: 40.780,53.055,69.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.197 | Acc: 40.713,52.825,69.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.207 | Acc: 40.550,52.798,69.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.216 | Acc: 40.493,52.718,69.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.222 | Acc: 40.586,52.622,69.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.223 | Acc: 40.576,52.585,69.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.223 | Acc: 40.637,52.697,69.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.226 | Acc: 40.595,52.646,69.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.232 | Acc: 40.636,52.608,69.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.233 | Acc: 40.687,52.578,69.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.860 | Acc: 3.125,17.969,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.393 | Acc: 1.711,13.653,37.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.366 | Acc: 1.791,13.281,37.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.417 | Acc: 1.908,13.307,37.551,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 4.454 | Acc: 42.969,64.062,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.948 | Acc: 42.076,53.943,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.991 | Acc: 42.226,53.430,72.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.987 | Acc: 42.533,54.060,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.001 | Acc: 42.371,53.694,71.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.052 | Acc: 41.832,53.164,71.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.027 | Acc: 42.233,53.796,71.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.049 | Acc: 42.038,53.529,71.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.069 | Acc: 41.916,53.358,71.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.065 | Acc: 41.916,53.539,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.070 | Acc: 41.849,53.459,70.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.085 | Acc: 41.763,53.337,70.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.090 | Acc: 41.798,53.303,70.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.089 | Acc: 41.873,53.349,70.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.088 | Acc: 41.876,53.428,70.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.086 | Acc: 41.754,53.340,70.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.090 | Acc: 41.781,53.329,70.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.092 | Acc: 41.743,53.405,70.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.090 | Acc: 41.759,53.445,70.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.100 | Acc: 41.706,53.357,70.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.821 | Acc: 5.469,17.188,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.188 | Acc: 3.720,12.835,36.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.182 | Acc: 3.544,12.729,35.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.250 | Acc: 3.676,12.551,35.822,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 4.978 | Acc: 39.844,52.344,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.889 | Acc: 43.676,54.390,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.924 | Acc: 42.626,54.135,73.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.975 | Acc: 42.213,54.483,72.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.981 | Acc: 42.072,54.176,72.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.940 | Acc: 42.396,54.680,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.942 | Acc: 41.929,54.397,72.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.942 | Acc: 42.077,54.427,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.923 | Acc: 42.566,54.527,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.920 | Acc: 42.451,54.605,72.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.941 | Acc: 42.312,54.447,72.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.935 | Acc: 42.361,54.680,72.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.949 | Acc: 42.178,54.561,72.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.966 | Acc: 41.993,54.385,72.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.973 | Acc: 42.004,54.440,71.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.976 | Acc: 41.993,54.482,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.984 | Acc: 41.983,54.427,71.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.999 | Acc: 41.929,54.293,71.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.007 | Acc: 41.943,54.235,71.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.010 | Acc: 41.882,54.269,71.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.598 | Acc: 4.688,17.969,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.768 | Acc: 2.567,14.993,26.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.763 | Acc: 2.420,14.520,25.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.813 | Acc: 2.433,14.319,26.050,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 4.654 | Acc: 46.875,61.719,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.795 | Acc: 42.411,55.022,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.877 | Acc: 41.787,54.573,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.923 | Acc: 41.496,54.559,73.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.926 | Acc: 41.705,54.591,73.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.908 | Acc: 41.963,54.742,73.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.886 | Acc: 42.181,55.133,73.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.890 | Acc: 42.093,55.186,73.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.903 | Acc: 42.081,55.100,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.898 | Acc: 42.041,55.115,73.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.907 | Acc: 42.024,54.940,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.914 | Acc: 42.057,54.875,72.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.920 | Acc: 42.103,54.850,72.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.929 | Acc: 42.092,54.822,72.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.937 | Acc: 42.037,54.782,72.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.926 | Acc: 42.232,54.919,72.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.928 | Acc: 42.180,54.911,72.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.931 | Acc: 42.171,54.859,72.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.929 | Acc: 42.216,54.897,72.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.927 | Acc: 42.274,54.944,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.664 | Acc: 3.125,17.188,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.951 | Acc: 1.935,15.104,39.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.927 | Acc: 1.848,14.920,39.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.986 | Acc: 1.934,14.933,39.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 3.752 | Acc: 46.875,64.062,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.632 | Acc: 42.969,56.399,76.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 43.636,57.165,76.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.719 | Acc: 43.199,56.378,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.739 | Acc: 43.191,56.231,75.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.751 | Acc: 43.116,56.095,75.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.749 | Acc: 43.001,55.998,75.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.752 | Acc: 43.168,55.906,75.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.768 | Acc: 43.226,55.847,74.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.771 | Acc: 43.098,55.715,74.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.783 | Acc: 43.093,55.581,74.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.793 | Acc: 43.160,55.525,74.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.805 | Acc: 43.066,55.430,74.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.819 | Acc: 42.999,55.370,74.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.825 | Acc: 42.941,55.271,74.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.824 | Acc: 42.925,55.440,74.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.842 | Acc: 42.818,55.291,73.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.838 | Acc: 42.877,55.434,73.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.836 | Acc: 42.941,55.501,73.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.839 | Acc: 42.926,55.458,73.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.985 | Acc: 12.500,16.406,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.112 | Acc: 6.920,14.249,28.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.089 | Acc: 7.203,14.005,29.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.137 | Acc: 7.031,13.576,28.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 4.462 | Acc: 42.969,57.812,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.671 | Acc: 44.196,56.696,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 44.112,57.527,77.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.602 | Acc: 44.006,57.044,76.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.594 | Acc: 44.174,57.166,76.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.592 | Acc: 44.230,57.372,76.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.644 | Acc: 43.660,56.779,76.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.645 | Acc: 43.761,56.893,76.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.653 | Acc: 43.706,56.769,76.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.658 | Acc: 43.621,56.820,75.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.683 | Acc: 43.486,56.623,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.693 | Acc: 43.534,56.621,75.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.699 | Acc: 43.555,56.645,75.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.705 | Acc: 43.490,56.636,75.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.711 | Acc: 43.522,56.703,75.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.720 | Acc: 43.452,56.632,75.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.722 | Acc: 43.470,56.644,75.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.726 | Acc: 43.512,56.644,74.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.736 | Acc: 43.445,56.605,74.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.740 | Acc: 43.477,56.594,74.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.444 | Acc: 10.156,25.000,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.767 | Acc: 6.882,20.796,32.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.746 | Acc: 6.707,20.751,31.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.801 | Acc: 6.545,20.159,31.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 4.750 | Acc: 41.406,61.719,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.576 | Acc: 44.382,58.222,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.589 | Acc: 45.198,58.079,77.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.558 | Acc: 44.954,58.274,77.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.574 | Acc: 44.811,57.600,77.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.594 | Acc: 44.802,57.403,76.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.620 | Acc: 44.622,57.076,76.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.600 | Acc: 44.697,57.358,76.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.610 | Acc: 44.667,57.483,76.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.630 | Acc: 44.397,57.364,76.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.619 | Acc: 44.341,57.587,76.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.628 | Acc: 44.227,57.455,76.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.635 | Acc: 44.168,57.427,76.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.646 | Acc: 44.046,57.313,76.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.653 | Acc: 44.014,57.306,75.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.658 | Acc: 44.025,57.293,75.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.665 | Acc: 43.979,57.197,75.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.674 | Acc: 43.890,57.171,75.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.679 | Acc: 43.860,57.139,75.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.685 | Acc: 43.734,57.093,75.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.541 | Acc: 4.688,17.969,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.182 | Acc: 2.381,16.109,37.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.159 | Acc: 2.229,15.320,37.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.226 | Acc: 2.344,14.908,36.936,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 5.145 | Acc: 35.156,49.219,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.391 | Acc: 42.336,59.152,80.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.420 | Acc: 43.426,59.146,80.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.405 | Acc: 44.147,59.119,79.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.420 | Acc: 44.387,59.182,78.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.451 | Acc: 44.531,58.718,78.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.454 | Acc: 44.564,58.529,78.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.491 | Acc: 44.221,58.195,77.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.492 | Acc: 44.264,58.147,77.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.523 | Acc: 44.052,58.063,77.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.541 | Acc: 43.979,58.003,77.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.549 | Acc: 44.050,57.972,77.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.560 | Acc: 44.097,57.803,77.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.558 | Acc: 44.172,57.818,76.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.567 | Acc: 44.089,57.699,76.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.580 | Acc: 44.036,57.631,76.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.585 | Acc: 44.013,57.574,76.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.586 | Acc: 44.064,57.615,76.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.586 | Acc: 44.116,57.631,76.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.586 | Acc: 44.131,57.605,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.959 | Acc: 1.562,10.938,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.055 | Acc: 1.339,12.612,25.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.050 | Acc: 1.258,12.519,25.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.096 | Acc: 1.345,12.167,25.487,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 4.625 | Acc: 47.656,57.031,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.272 | Acc: 45.350,60.491,79.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.355 | Acc: 45.655,60.156,79.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.368 | Acc: 45.620,60.336,78.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.381 | Acc: 45.631,60.012,78.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.393 | Acc: 45.475,59.816,78.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.395 | Acc: 45.435,59.756,78.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.425 | Acc: 45.274,59.397,78.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.446 | Acc: 45.021,59.152,77.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.449 | Acc: 45.015,59.112,77.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.463 | Acc: 45.037,58.928,77.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.453 | Acc: 45.136,58.976,77.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.460 | Acc: 45.095,58.905,77.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.467 | Acc: 44.926,58.815,77.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.475 | Acc: 44.857,58.716,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.487 | Acc: 44.747,58.576,77.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.499 | Acc: 44.762,58.596,77.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.508 | Acc: 44.772,58.566,77.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.511 | Acc: 44.728,58.542,77.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.526 | Acc: 44.646,58.378,77.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.138 | Acc: 3.906,25.000,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.597 | Acc: 3.051,24.330,38.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.571 | Acc: 2.896,23.171,38.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.659 | Acc: 2.920,23.040,38.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 4.180 | Acc: 50.000,59.375,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.214 | Acc: 46.503,61.124,80.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.248 | Acc: 45.827,60.861,80.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.317 | Acc: 45.351,60.067,80.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.373 | Acc: 44.917,59.896,80.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.390 | Acc: 44.670,59.483,79.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.378 | Acc: 44.712,59.614,79.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.385 | Acc: 44.886,59.497,79.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.401 | Acc: 44.958,59.399,79.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.398 | Acc: 45.153,59.397,79.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.407 | Acc: 45.099,59.356,79.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.411 | Acc: 45.178,59.174,78.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.408 | Acc: 45.124,59.226,78.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.428 | Acc: 44.965,59.028,78.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.424 | Acc: 45.037,59.022,78.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.437 | Acc: 45.001,58.882,78.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.433 | Acc: 45.047,58.944,78.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.446 | Acc: 44.937,58.825,77.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.447 | Acc: 44.936,58.821,77.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.456 | Acc: 44.925,58.733,77.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.848 | Acc: 4.688,17.969,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.994 | Acc: 3.013,17.708,50.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.990 | Acc: 2.725,16.768,49.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.054 | Acc: 2.779,16.675,49.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 4.199 | Acc: 46.875,61.719,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.331 | Acc: 45.461,58.705,79.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.328 | Acc: 45.941,59.032,79.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.335 | Acc: 46.017,59.132,79.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.331 | Acc: 45.930,59.645,79.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.340 | Acc: 46.009,59.259,79.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.356 | Acc: 45.945,59.162,79.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.360 | Acc: 46.133,59.236,79.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.351 | Acc: 46.089,59.336,79.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.368 | Acc: 45.848,59.293,79.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.363 | Acc: 45.748,59.340,79.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.367 | Acc: 45.652,59.453,79.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.376 | Acc: 45.588,59.336,79.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.383 | Acc: 45.525,59.207,78.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.390 | Acc: 45.499,59.150,78.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.398 | Acc: 45.494,59.043,78.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.399 | Acc: 45.490,59.022,78.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.402 | Acc: 45.498,59.024,78.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.402 | Acc: 45.503,59.094,78.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.409 | Acc: 45.528,58.994,78.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.290 | Acc: 4.688,31.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.877 | Acc: 2.976,23.512,47.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.856 | Acc: 2.896,23.266,46.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.918 | Acc: 2.997,23.463,46.875,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 4.528 | Acc: 41.406,54.688,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.244 | Acc: 47.545,60.603,80.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.261 | Acc: 46.418,60.842,80.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.286 | Acc: 45.774,60.297,81.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.270 | Acc: 45.853,60.465,81.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.277 | Acc: 45.498,60.412,81.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.273 | Acc: 45.739,60.466,80.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.274 | Acc: 45.723,60.616,80.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.284 | Acc: 45.570,60.326,80.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.299 | Acc: 45.338,60.143,80.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.303 | Acc: 45.487,60.172,80.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.319 | Acc: 45.411,60.047,80.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.325 | Acc: 45.394,60.046,80.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.333 | Acc: 45.423,59.878,79.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.342 | Acc: 45.429,59.770,79.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.349 | Acc: 45.292,59.655,79.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.352 | Acc: 45.271,59.596,79.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.346 | Acc: 45.367,59.689,79.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.347 | Acc: 45.388,59.697,79.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.353 | Acc: 45.331,59.697,79.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.041 | Acc: 3.125,35.156,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.311 | Acc: 2.604,26.042,41.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.310 | Acc: 2.344,25.267,41.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.385 | Acc: 2.357,24.808,40.138,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 4.181 | Acc: 45.312,66.406,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.257 | Acc: 44.903,61.198,81.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.163 | Acc: 46.532,61.261,81.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.133 | Acc: 46.939,61.232,82.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.115 | Acc: 47.203,61.478,82.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.136 | Acc: 47.045,61.231,81.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.146 | Acc: 46.914,61.228,81.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.156 | Acc: 46.820,61.032,81.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.187 | Acc: 46.671,60.777,81.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.199 | Acc: 46.465,60.765,81.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.208 | Acc: 46.323,60.506,81.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.210 | Acc: 46.355,60.489,81.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.222 | Acc: 46.272,60.467,81.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.217 | Acc: 46.261,60.605,80.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.226 | Acc: 46.274,60.534,80.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.236 | Acc: 46.159,60.499,80.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.238 | Acc: 46.186,60.368,80.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.249 | Acc: 46.158,60.289,80.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.261 | Acc: 46.100,60.193,80.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.263 | Acc: 46.153,60.226,80.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.942 | Acc: 2.344,42.969,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.648 | Acc: 1.339,30.320,43.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.670 | Acc: 1.353,30.126,42.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.722 | Acc: 1.422,30.251,42.252,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 4.389 | Acc: 50.000,63.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.121 | Acc: 46.689,62.016,82.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.141 | Acc: 46.913,61.376,81.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.096 | Acc: 46.990,61.232,82.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.102 | Acc: 46.904,61.381,82.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.118 | Acc: 46.999,61.394,82.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.129 | Acc: 47.024,61.357,82.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.133 | Acc: 47.058,61.370,81.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.173 | Acc: 46.759,61.005,81.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.175 | Acc: 47.030,61.149,81.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.182 | Acc: 47.027,61.019,81.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.193 | Acc: 46.960,61.008,80.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.199 | Acc: 46.745,60.928,80.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.204 | Acc: 46.633,60.836,80.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.205 | Acc: 46.616,60.818,80.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.212 | Acc: 46.517,60.841,80.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.211 | Acc: 46.595,60.889,80.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.223 | Acc: 46.437,60.773,80.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.236 | Acc: 46.345,60.671,80.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.240 | Acc: 46.328,60.669,80.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.978 | Acc: 2.344,35.156,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.551 | Acc: 1.562,26.935,44.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.559 | Acc: 1.524,26.963,44.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.617 | Acc: 1.627,26.665,44.429,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 3.685 | Acc: 46.875,61.719,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.037 | Acc: 48.103,62.500,82.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.061 | Acc: 47.656,61.909,82.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.055 | Acc: 47.118,62.052,82.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.056 | Acc: 46.991,62.346,83.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.060 | Acc: 47.068,62.183,82.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.073 | Acc: 47.011,61.938,82.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.109 | Acc: 46.809,61.564,82.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.135 | Acc: 46.608,61.486,82.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.122 | Acc: 46.784,61.637,82.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.125 | Acc: 46.801,61.505,82.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.124 | Acc: 46.857,61.599,82.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.130 | Acc: 46.758,61.505,82.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.152 | Acc: 46.698,61.276,81.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.159 | Acc: 46.733,61.279,81.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.170 | Acc: 46.686,61.135,81.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.181 | Acc: 46.566,61.011,81.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.188 | Acc: 46.469,60.921,81.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.195 | Acc: 46.395,60.816,81.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.203 | Acc: 46.455,60.759,81.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.146 | Acc: 10.156,31.250,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.448 | Acc: 5.618,28.981,33.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.449 | Acc: 5.469,28.468,33.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.506 | Acc: 5.315,28.906,33.017,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 3.821 | Acc: 52.344,65.625,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.072 | Acc: 47.396,61.310,82.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.116 | Acc: 46.989,61.166,82.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.099 | Acc: 46.913,61.296,82.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.082 | Acc: 47.184,61.709,82.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.080 | Acc: 46.929,61.726,82.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.090 | Acc: 46.649,61.532,82.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.095 | Acc: 46.554,61.464,82.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.108 | Acc: 46.506,61.272,82.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.106 | Acc: 46.538,61.408,82.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.113 | Acc: 46.463,61.396,82.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.102 | Acc: 46.649,61.528,82.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.108 | Acc: 46.690,61.433,82.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.122 | Acc: 46.743,61.401,81.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.124 | Acc: 46.666,61.357,81.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.128 | Acc: 46.654,61.376,81.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.132 | Acc: 46.688,61.363,81.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.140 | Acc: 46.731,61.274,81.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.144 | Acc: 46.732,61.236,81.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.153 | Acc: 46.598,61.182,81.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.175 | Acc: 1.562,20.312,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.555 | Acc: 0.967,15.141,52.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.544 | Acc: 1.010,14.920,52.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.618 | Acc: 1.076,14.664,52.113,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 3.848 | Acc: 52.344,67.969,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.896 | Acc: 50.260,63.802,84.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.875 | Acc: 49.486,63.434,84.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.946 | Acc: 48.604,62.551,84.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.961 | Acc: 48.216,62.731,83.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.971 | Acc: 47.826,62.631,83.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.000 | Acc: 47.605,62.468,83.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.010 | Acc: 47.501,62.517,83.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.028 | Acc: 47.312,62.384,83.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.042 | Acc: 47.164,62.284,83.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.056 | Acc: 47.135,62.146,82.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.056 | Acc: 47.207,62.189,83.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.068 | Acc: 47.112,62.033,82.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.072 | Acc: 47.153,62.048,82.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.074 | Acc: 47.211,62.108,82.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.079 | Acc: 47.140,62.041,82.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.079 | Acc: 47.230,62.079,82.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.095 | Acc: 47.093,61.943,82.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.107 | Acc: 47.005,61.859,82.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.117 | Acc: 47.006,61.758,81.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.713 | Acc: 3.125,27.344,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.163 | Acc: 1.972,22.842,38.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.148 | Acc: 1.963,22.466,38.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.239 | Acc: 2.126,22.259,38.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 4.083 | Acc: 44.531,60.938,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.077 | Acc: 47.842,61.793,84.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.992 | Acc: 48.095,62.805,84.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.956 | Acc: 48.617,63.243,84.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.939 | Acc: 48.476,63.301,84.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.936 | Acc: 48.693,63.041,84.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.961 | Acc: 48.315,62.791,83.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.976 | Acc: 48.216,62.655,83.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.978 | Acc: 48.025,62.728,83.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.979 | Acc: 48.036,62.707,83.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.991 | Acc: 48.041,62.690,83.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.993 | Acc: 48.027,62.712,83.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.001 | Acc: 47.951,62.630,83.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.019 | Acc: 47.938,62.512,83.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.028 | Acc: 47.809,62.353,83.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.041 | Acc: 47.744,62.266,82.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.052 | Acc: 47.717,62.152,82.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.054 | Acc: 47.629,62.131,82.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.060 | Acc: 47.624,62.074,82.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.067 | Acc: 47.513,62.057,82.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.181 | Acc: 2.344,22.656,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.735 | Acc: 1.749,19.159,31.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.720 | Acc: 1.734,18.483,31.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.804 | Acc: 1.883,18.238,31.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 4.061 | Acc: 44.531,64.844,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.819 | Acc: 49.554,65.551,83.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.825 | Acc: 48.495,64.958,84.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.882 | Acc: 48.220,63.755,84.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.881 | Acc: 48.052,63.783,84.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.877 | Acc: 48.205,63.730,84.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.918 | Acc: 47.843,63.217,84.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.936 | Acc: 47.806,63.043,83.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.934 | Acc: 47.899,62.980,83.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.930 | Acc: 48.053,63.178,83.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.953 | Acc: 47.792,62.963,83.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.962 | Acc: 47.858,62.942,83.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.962 | Acc: 47.967,62.918,83.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.984 | Acc: 47.752,62.722,83.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.991 | Acc: 47.731,62.664,83.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.002 | Acc: 47.719,62.591,83.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.014 | Acc: 47.605,62.534,82.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.021 | Acc: 47.649,62.440,82.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.019 | Acc: 47.687,62.457,82.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.029 | Acc: 47.671,62.404,82.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.457 | Acc: 2.344,12.500,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.850 | Acc: 1.600,10.379,38.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.843 | Acc: 1.658,10.061,38.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.889 | Acc: 1.767,9.926,38.550,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 4.046 | Acc: 50.781,67.188,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.953 | Acc: 49.777,62.946,84.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.924 | Acc: 48.628,62.938,84.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.869 | Acc: 48.975,63.384,84.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.880 | Acc: 48.669,63.571,84.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.859 | Acc: 48.940,63.722,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.885 | Acc: 48.612,63.365,84.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.887 | Acc: 48.715,63.436,84.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.890 | Acc: 48.593,63.495,84.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.893 | Acc: 48.645,63.484,84.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.909 | Acc: 48.375,63.312,84.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.931 | Acc: 48.176,63.066,84.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.936 | Acc: 48.185,63.122,84.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.943 | Acc: 48.204,63.144,84.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.953 | Acc: 48.104,63.012,84.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.963 | Acc: 47.999,62.907,83.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.968 | Acc: 48.016,62.843,83.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.977 | Acc: 47.897,62.782,83.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.991 | Acc: 47.806,62.677,83.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.003 | Acc: 47.726,62.625,83.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.672 | Acc: 3.125,35.156,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.098 | Acc: 2.418,28.162,47.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.097 | Acc: 2.325,27.458,46.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.180 | Acc: 2.318,27.754,46.593,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 4.008 | Acc: 42.969,61.719,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.839 | Acc: 48.214,64.844,84.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.816 | Acc: 49.314,64.444,85.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.839 | Acc: 48.937,64.139,85.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.843 | Acc: 48.852,64.178,85.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.853 | Acc: 48.685,64.194,85.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.866 | Acc: 48.676,64.114,84.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.889 | Acc: 48.637,64.179,84.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.901 | Acc: 48.486,63.902,84.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.914 | Acc: 48.252,63.825,84.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.910 | Acc: 48.472,63.926,84.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.926 | Acc: 48.416,63.642,83.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.937 | Acc: 48.392,63.563,83.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.943 | Acc: 48.345,63.434,83.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.953 | Acc: 48.387,63.392,83.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.957 | Acc: 48.235,63.362,83.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.973 | Acc: 48.119,63.123,83.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.983 | Acc: 48.071,63.013,83.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.985 | Acc: 48.126,62.952,83.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.986 | Acc: 48.058,62.929,83.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.847 | Acc: 3.125,17.969,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.621 | Acc: 2.195,12.760,52.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.638 | Acc: 2.191,12.195,51.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.736 | Acc: 2.267,12.013,51.332,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 4.091 | Acc: 44.531,60.938,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.691 | Acc: 50.335,66.890,85.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.671 | Acc: 50.152,66.997,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.752 | Acc: 49.091,65.843,85.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.797 | Acc: 48.640,65.297,85.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.838 | Acc: 48.523,64.921,85.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.852 | Acc: 48.366,64.469,85.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.854 | Acc: 48.521,64.340,85.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.869 | Acc: 48.476,64.062,85.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.872 | Acc: 48.425,64.106,85.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.871 | Acc: 48.644,64.230,84.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.874 | Acc: 48.635,64.218,84.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.886 | Acc: 48.564,64.098,84.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.886 | Acc: 48.656,64.042,84.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.886 | Acc: 48.674,63.999,84.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.890 | Acc: 48.632,64.003,84.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.897 | Acc: 48.598,63.972,84.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.907 | Acc: 48.618,63.847,84.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.916 | Acc: 48.539,63.649,83.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.927 | Acc: 48.446,63.544,83.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.843 | Acc: 2.344,25.000,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.492 | Acc: 1.153,18.192,35.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.470 | Acc: 1.239,18.788,34.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.542 | Acc: 1.319,18.532,33.965,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 3.936 | Acc: 46.875,64.062,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.787 | Acc: 49.554,64.546,86.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.806 | Acc: 49.143,64.158,85.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.817 | Acc: 49.360,64.434,86.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.798 | Acc: 49.547,64.545,86.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.820 | Acc: 49.296,64.194,86.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.847 | Acc: 49.103,63.927,85.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.849 | Acc: 48.969,63.913,85.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.855 | Acc: 48.976,63.912,85.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.872 | Acc: 48.753,63.795,85.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.879 | Acc: 48.647,63.639,85.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.874 | Acc: 48.713,63.667,85.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.875 | Acc: 48.694,63.823,84.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.882 | Acc: 48.590,63.781,84.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.886 | Acc: 48.660,63.729,84.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.892 | Acc: 48.710,63.665,84.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.897 | Acc: 48.661,63.622,84.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.896 | Acc: 48.712,63.673,84.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.899 | Acc: 48.712,63.612,84.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.904 | Acc: 48.714,63.558,84.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.047 | Acc: 2.344,14.062,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.525 | Acc: 1.414,11.830,33.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.484 | Acc: 1.410,11.433,33.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.560 | Acc: 1.524,11.360,33.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.793 | Acc: 55.469,64.062,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.754 | Acc: 50.707,65.030,86.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.720 | Acc: 50.343,65.835,86.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.722 | Acc: 49.731,65.894,86.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.763 | Acc: 49.470,65.075,86.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.759 | Acc: 49.489,65.161,85.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.785 | Acc: 49.722,64.818,85.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.777 | Acc: 49.579,64.844,85.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.795 | Acc: 49.452,64.645,85.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.800 | Acc: 49.361,64.395,85.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.814 | Acc: 49.351,64.226,85.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.828 | Acc: 49.215,64.055,85.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.833 | Acc: 49.235,64.101,85.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.847 | Acc: 49.042,64.000,84.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.861 | Acc: 48.905,63.910,84.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.869 | Acc: 49.006,63.889,84.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.877 | Acc: 48.905,63.841,84.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.884 | Acc: 48.834,63.794,84.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.890 | Acc: 48.795,63.684,84.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.901 | Acc: 48.651,63.546,84.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.727 | Acc: 1.562,21.875,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.004 | Acc: 1.488,18.676,32.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.980 | Acc: 1.543,18.655,33.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.069 | Acc: 1.703,18.942,32.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 3.002 | Acc: 59.375,71.094,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.787 | Acc: 49.851,63.876,86.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.697 | Acc: 49.638,64.958,86.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.717 | Acc: 49.539,64.690,86.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.715 | Acc: 49.470,65.017,86.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.720 | Acc: 49.443,64.743,86.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.737 | Acc: 49.251,64.734,86.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.727 | Acc: 49.535,64.905,86.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.738 | Acc: 49.515,64.917,86.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.739 | Acc: 49.586,64.874,85.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.759 | Acc: 49.468,64.739,85.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.772 | Acc: 49.438,64.533,85.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.791 | Acc: 49.225,64.345,85.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.802 | Acc: 49.192,64.278,85.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.819 | Acc: 49.010,64.207,85.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.840 | Acc: 48.975,63.959,85.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.837 | Acc: 49.061,64.024,85.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.842 | Acc: 49.024,63.971,85.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.844 | Acc: 49.020,63.913,84.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.852 | Acc: 48.960,63.798,84.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.472 | Acc: 2.344,15.625,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.017 | Acc: 1.786,14.286,44.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.974 | Acc: 1.696,13.624,44.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.074 | Acc: 1.780,13.345,44.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.639 | Acc: 50.000,66.406,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.853 | Acc: 48.475,64.695,86.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.733 | Acc: 49.447,65.968,86.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.718 | Acc: 49.244,65.663,87.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.727 | Acc: 49.026,65.355,87.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.727 | Acc: 49.188,65.238,86.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.728 | Acc: 49.270,65.070,86.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.726 | Acc: 49.535,65.365,86.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.754 | Acc: 49.374,64.941,86.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.768 | Acc: 49.378,64.913,85.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.768 | Acc: 49.456,64.949,85.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.773 | Acc: 49.544,64.953,85.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.785 | Acc: 49.381,64.756,85.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.788 | Acc: 49.410,64.778,85.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.801 | Acc: 49.244,64.638,85.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.804 | Acc: 49.234,64.615,85.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.810 | Acc: 49.226,64.642,85.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.817 | Acc: 49.205,64.605,84.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.821 | Acc: 49.152,64.619,84.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.826 | Acc: 49.094,64.565,84.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.453 | Acc: 4.688,21.094,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.886 | Acc: 2.121,17.188,48.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.859 | Acc: 2.172,17.492,47.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.963 | Acc: 2.280,17.175,47.195,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 3.604 | Acc: 50.000,67.188,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.579 | Acc: 50.260,66.927,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.606 | Acc: 50.724,66.368,88.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.580 | Acc: 50.333,66.637,87.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.616 | Acc: 49.682,66.155,87.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.679 | Acc: 49.567,65.432,87.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.690 | Acc: 49.522,65.328,87.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.722 | Acc: 49.330,64.955,87.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.747 | Acc: 49.146,64.771,86.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.768 | Acc: 49.029,64.546,86.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.779 | Acc: 48.997,64.319,86.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.789 | Acc: 48.993,64.384,86.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.802 | Acc: 48.927,64.244,86.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.806 | Acc: 49.024,64.233,85.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.804 | Acc: 49.080,64.171,85.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.797 | Acc: 49.092,64.205,85.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.806 | Acc: 49.117,64.182,85.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.813 | Acc: 49.040,64.136,85.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.815 | Acc: 49.030,64.097,85.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.823 | Acc: 49.008,64.106,85.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.218 | Acc: 2.344,31.250,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.873 | Acc: 1.525,19.457,37.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.852 | Acc: 1.524,18.731,37.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.964 | Acc: 1.703,18.852,37.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.739 | Acc: 50.000,63.281,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.445 | Acc: 51.414,67.820,88.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.490 | Acc: 50.381,66.730,88.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.567 | Acc: 49.718,65.907,88.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.607 | Acc: 49.691,65.712,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.662 | Acc: 49.343,65.161,87.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.678 | Acc: 49.374,65.031,87.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.696 | Acc: 49.418,64.977,86.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.709 | Acc: 49.534,64.805,86.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.713 | Acc: 49.538,64.865,86.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.716 | Acc: 49.557,64.890,86.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.712 | Acc: 49.685,64.911,86.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.727 | Acc: 49.556,64.643,86.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.730 | Acc: 49.575,64.667,86.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.739 | Acc: 49.519,64.543,85.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.745 | Acc: 49.543,64.514,86.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.758 | Acc: 49.540,64.384,85.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.760 | Acc: 49.507,64.431,85.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.772 | Acc: 49.442,64.365,85.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.783 | Acc: 49.313,64.255,85.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.973 | Acc: 7.031,30.469,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.373 | Acc: 4.129,20.536,38.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.377 | Acc: 4.211,19.493,38.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.494 | Acc: 4.086,19.070,37.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 3.757 | Acc: 44.531,66.406,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.610 | Acc: 51.228,66.257,87.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.640 | Acc: 51.524,66.311,87.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.640 | Acc: 51.089,66.227,86.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.681 | Acc: 50.357,65.818,86.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.697 | Acc: 50.224,65.633,86.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.707 | Acc: 50.019,65.489,86.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.721 | Acc: 49.994,65.265,86.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.727 | Acc: 49.714,65.334,86.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.730 | Acc: 49.719,65.379,86.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.743 | Acc: 49.615,65.096,86.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.739 | Acc: 49.643,65.137,86.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.739 | Acc: 49.643,65.106,86.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.747 | Acc: 49.566,64.960,86.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.755 | Acc: 49.491,64.874,86.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.760 | Acc: 49.442,64.833,85.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.768 | Acc: 49.353,64.788,85.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.768 | Acc: 49.381,64.812,85.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.776 | Acc: 49.364,64.699,85.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.784 | Acc: 49.381,64.604,85.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.209 | Acc: 5.469,23.438,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.642 | Acc: 2.418,20.685,49.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.654 | Acc: 2.439,20.484,48.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.735 | Acc: 2.626,20.261,48.053,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 3.760 | Acc: 49.219,59.375,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.788 | Acc: 49.777,64.174,86.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.711 | Acc: 49.981,65.053,87.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.711 | Acc: 49.705,64.946,87.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.688 | Acc: 50.222,65.046,87.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.667 | Acc: 50.704,65.362,87.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.690 | Acc: 50.278,65.354,87.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.692 | Acc: 50.255,65.265,87.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.695 | Acc: 50.214,65.213,87.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.704 | Acc: 50.233,65.185,86.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.706 | Acc: 50.225,65.135,86.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.720 | Acc: 50.180,64.982,86.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.723 | Acc: 50.253,65.100,86.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.724 | Acc: 50.269,65.065,86.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.724 | Acc: 50.242,65.155,86.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.746 | Acc: 50.169,64.888,86.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.751 | Acc: 49.985,64.832,85.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.754 | Acc: 49.936,64.775,85.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.754 | Acc: 49.994,64.794,85.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.763 | Acc: 49.863,64.684,85.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.609 | Acc: 6.250,25.000,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.226 | Acc: 3.199,21.540,48.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.218 | Acc: 3.316,21.494,48.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.303 | Acc: 3.356,21.030,47.746,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 4.330 | Acc: 43.750,53.906,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.688 | Acc: 50.521,66.220,87.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.662 | Acc: 49.867,65.796,87.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.686 | Acc: 50.051,65.446,87.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.623 | Acc: 50.598,65.905,87.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.643 | Acc: 50.309,65.787,87.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.644 | Acc: 50.194,65.883,87.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.643 | Acc: 50.271,65.830,87.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.638 | Acc: 50.330,65.931,87.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.651 | Acc: 50.211,65.811,87.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.657 | Acc: 50.117,65.804,87.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.673 | Acc: 49.908,65.491,87.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.682 | Acc: 49.929,65.434,87.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.688 | Acc: 49.943,65.493,86.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.700 | Acc: 49.875,65.314,86.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.707 | Acc: 49.844,65.236,86.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.713 | Acc: 49.832,65.150,86.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.707 | Acc: 49.908,65.160,86.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.714 | Acc: 49.864,65.147,86.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.719 | Acc: 49.838,65.119,86.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.210 | Acc: 2.344,22.656,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.608 | Acc: 1.414,24.219,46.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.592 | Acc: 1.524,23.514,46.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.649 | Acc: 1.755,23.604,46.657,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 3.900 | Acc: 52.344,62.500,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.603 | Acc: 51.190,67.783,87.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.614 | Acc: 50.343,66.806,87.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.619 | Acc: 50.397,66.675,87.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.616 | Acc: 50.530,66.522,87.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.621 | Acc: 50.603,66.112,87.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.628 | Acc: 50.549,66.161,87.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.666 | Acc: 50.427,65.625,87.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.679 | Acc: 50.146,65.499,87.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.681 | Acc: 50.056,65.474,86.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.685 | Acc: 50.031,65.489,86.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.689 | Acc: 50.000,65.519,86.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.691 | Acc: 49.951,65.599,86.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.703 | Acc: 49.877,65.380,86.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.706 | Acc: 49.894,65.258,86.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.707 | Acc: 49.940,65.262,86.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.718 | Acc: 49.883,65.121,86.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.718 | Acc: 49.947,65.112,86.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.717 | Acc: 49.983,65.142,86.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.725 | Acc: 49.943,65.045,85.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.094 | Acc: 3.125,21.875,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.594 | Acc: 2.232,18.452,31.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.568 | Acc: 2.287,18.083,31.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.649 | Acc: 2.459,18.276,30.815,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 3.648 | Acc: 54.688,63.281,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.668 | Acc: 49.963,64.918,87.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.617 | Acc: 51.010,65.434,87.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.610 | Acc: 51.050,65.420,88.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.566 | Acc: 51.119,65.828,88.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.579 | Acc: 50.804,66.050,88.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.582 | Acc: 50.723,66.071,87.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.596 | Acc: 50.709,66.041,87.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.603 | Acc: 50.791,65.945,87.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.619 | Acc: 50.639,65.750,87.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.625 | Acc: 50.692,65.703,87.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.631 | Acc: 50.693,65.643,87.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.634 | Acc: 50.648,65.703,87.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.647 | Acc: 50.473,65.541,87.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.654 | Acc: 50.367,65.497,86.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.660 | Acc: 50.249,65.381,86.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.669 | Acc: 50.307,65.316,86.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.674 | Acc: 50.291,65.217,86.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.675 | Acc: 50.309,65.285,86.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.688 | Acc: 50.217,65.283,86.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.735 | Acc: 3.906,24.219,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.318 | Acc: 2.009,19.345,42.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.291 | Acc: 2.229,18.331,41.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.377 | Acc: 2.280,18.071,41.611,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.576 | Acc: 51.562,62.500,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.567 | Acc: 50.930,65.960,88.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.584 | Acc: 51.258,66.330,87.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.567 | Acc: 51.511,66.637,87.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.561 | Acc: 51.292,66.493,87.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.565 | Acc: 51.214,66.445,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.563 | Acc: 51.065,66.290,87.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.575 | Acc: 50.964,66.207,87.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.599 | Acc: 50.762,66.047,87.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.614 | Acc: 50.647,65.983,87.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.624 | Acc: 50.692,65.889,87.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.640 | Acc: 50.516,65.770,87.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.659 | Acc: 50.272,65.602,86.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.667 | Acc: 50.213,65.535,86.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.663 | Acc: 50.323,65.647,86.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.669 | Acc: 50.356,65.565,86.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.678 | Acc: 50.326,65.503,86.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.685 | Acc: 50.259,65.426,86.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.699 | Acc: 50.132,65.307,86.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.704 | Acc: 50.141,65.270,86.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.704 | Acc: 8.594,39.062,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.287 | Acc: 4.836,31.808,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.277 | Acc: 5.202,31.021,44.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.347 | Acc: 5.200,31.327,44.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 3.912 | Acc: 49.219,57.812,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.534 | Acc: 51.004,67.150,88.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.546 | Acc: 50.934,67.111,88.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.559 | Acc: 50.538,66.778,88.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.556 | Acc: 50.482,66.840,88.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.558 | Acc: 50.665,66.592,88.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.546 | Acc: 50.962,66.652,87.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.562 | Acc: 50.837,66.295,87.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.572 | Acc: 50.728,66.309,87.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.567 | Acc: 50.863,66.415,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.578 | Acc: 50.750,66.294,87.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.581 | Acc: 50.749,66.300,87.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.594 | Acc: 50.681,66.170,87.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.593 | Acc: 50.712,66.161,87.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.602 | Acc: 50.734,66.067,87.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.613 | Acc: 50.690,66.017,86.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.620 | Acc: 50.623,65.944,86.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.628 | Acc: 50.598,65.850,86.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.642 | Acc: 50.511,65.701,86.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.647 | Acc: 50.490,65.689,86.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.353 | Acc: 4.688,28.906,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.039 | Acc: 3.162,22.210,44.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.001 | Acc: 3.239,22.085,43.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.129 | Acc: 3.202,21.376,43.404,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 3.347 | Acc: 56.250,66.406,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.438 | Acc: 52.790,67.336,88.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.469 | Acc: 52.591,67.359,88.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.530 | Acc: 51.486,67.341,88.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.527 | Acc: 51.042,66.927,88.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.523 | Acc: 51.044,66.839,88.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.529 | Acc: 50.762,66.652,88.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.547 | Acc: 50.482,66.362,88.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.563 | Acc: 50.524,66.266,88.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.570 | Acc: 50.518,66.324,88.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.585 | Acc: 50.466,66.091,88.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.585 | Acc: 50.470,66.198,87.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.595 | Acc: 50.399,66.089,87.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.603 | Acc: 50.383,66.023,87.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.609 | Acc: 50.384,66.003,87.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.618 | Acc: 50.374,65.978,87.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.615 | Acc: 50.460,66.024,87.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.625 | Acc: 50.403,66.044,87.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.627 | Acc: 50.435,65.993,87.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.637 | Acc: 50.351,65.959,87.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.967 | Acc: 4.688,33.594,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.322 | Acc: 1.786,28.348,33.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.331 | Acc: 1.791,27.572,33.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.443 | Acc: 1.908,27.369,33.133,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 3.462 | Acc: 53.125,71.875,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.486 | Acc: 51.339,67.820,89.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.418 | Acc: 51.848,67.645,89.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.405 | Acc: 51.780,67.700,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.457 | Acc: 51.235,67.110,89.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.500 | Acc: 50.951,66.770,88.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.507 | Acc: 50.956,66.710,88.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.531 | Acc: 50.731,66.622,88.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.522 | Acc: 50.660,66.819,88.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.530 | Acc: 50.855,66.795,88.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.551 | Acc: 50.746,66.663,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.557 | Acc: 50.788,66.555,88.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.579 | Acc: 50.733,66.328,87.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.589 | Acc: 50.757,66.245,87.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.590 | Acc: 50.829,66.192,87.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.595 | Acc: 50.857,66.144,87.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.600 | Acc: 50.825,66.126,87.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.613 | Acc: 50.671,66.028,87.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.616 | Acc: 50.723,65.984,87.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.623 | Acc: 50.744,65.920,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.663 | Acc: 2.344,23.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.248 | Acc: 1.600,19.234,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.209 | Acc: 1.601,18.769,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.310 | Acc: 1.691,19.032,56.148,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.920 | Acc: 49.219,60.156,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.497 | Acc: 50.112,68.490,89.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.505 | Acc: 51.220,68.407,88.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.522 | Acc: 51.204,67.546,88.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.514 | Acc: 51.514,67.525,88.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.519 | Acc: 51.245,67.211,88.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.537 | Acc: 51.169,67.084,88.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.561 | Acc: 51.175,66.822,87.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.555 | Acc: 51.344,66.707,87.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.569 | Acc: 51.105,66.566,87.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.586 | Acc: 50.871,66.418,87.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.586 | Acc: 50.979,66.572,87.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.590 | Acc: 50.940,66.484,87.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.601 | Acc: 50.892,66.331,87.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.610 | Acc: 50.840,66.289,87.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.617 | Acc: 50.784,66.269,87.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.613 | Acc: 50.779,66.321,87.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.615 | Acc: 50.836,66.287,87.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.624 | Acc: 50.697,66.173,86.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.627 | Acc: 50.779,66.193,86.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.952 | Acc: 5.469,26.562,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.142 | Acc: 3.051,26.042,38.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.103 | Acc: 3.049,25.495,38.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.228 | Acc: 3.099,25.371,37.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 3.298 | Acc: 53.906,64.844,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.531 | Acc: 50.558,66.257,88.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.515 | Acc: 51.353,66.578,88.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.514 | Acc: 51.486,67.111,88.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.485 | Acc: 51.591,67.101,88.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.476 | Acc: 51.694,67.528,88.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.470 | Acc: 51.672,67.704,88.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.470 | Acc: 51.723,67.675,88.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.497 | Acc: 51.480,67.469,88.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.511 | Acc: 51.355,67.257,88.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.519 | Acc: 51.236,67.219,87.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.538 | Acc: 51.099,67.028,87.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.549 | Acc: 51.047,66.821,87.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.549 | Acc: 51.018,66.822,87.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.563 | Acc: 50.979,66.618,87.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.577 | Acc: 50.869,66.450,87.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.588 | Acc: 50.854,66.297,87.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.596 | Acc: 50.891,66.228,87.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.598 | Acc: 50.851,66.162,87.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.605 | Acc: 50.728,66.105,87.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.948 | Acc: 6.250,26.562,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.190 | Acc: 5.097,24.814,32.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.170 | Acc: 5.488,24.238,32.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.278 | Acc: 5.405,23.450,32.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 3.866 | Acc: 45.312,73.438,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.434 | Acc: 50.037,69.420,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.450 | Acc: 51.582,69.055,88.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.429 | Acc: 51.998,69.096,88.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.447 | Acc: 51.688,68.432,88.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.488 | Acc: 51.037,67.845,88.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.462 | Acc: 51.046,68.066,88.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.489 | Acc: 51.042,67.742,88.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.508 | Acc: 50.844,67.542,88.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.523 | Acc: 50.859,67.364,87.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.539 | Acc: 50.836,67.141,87.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.549 | Acc: 50.894,66.845,87.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.554 | Acc: 51.050,66.782,87.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.560 | Acc: 50.982,66.739,87.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.558 | Acc: 51.068,66.751,87.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.561 | Acc: 51.095,66.637,87.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.565 | Acc: 51.090,66.594,87.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.570 | Acc: 51.031,66.562,87.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.577 | Acc: 51.063,66.482,87.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.588 | Acc: 51.074,66.412,86.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.225 | Acc: 5.469,17.188,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.770 | Acc: 3.162,11.719,43.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.789 | Acc: 3.354,10.918,43.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.897 | Acc: 3.304,11.027,42.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 3.611 | Acc: 48.438,65.625,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.515 | Acc: 51.339,66.815,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.456 | Acc: 52.058,67.626,89.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.490 | Acc: 51.742,67.162,89.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.492 | Acc: 51.524,67.255,89.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.498 | Acc: 51.648,67.133,88.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.504 | Acc: 51.207,66.910,88.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.506 | Acc: 51.280,66.982,88.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.517 | Acc: 51.286,66.882,88.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.545 | Acc: 51.105,66.773,88.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.549 | Acc: 51.084,66.682,88.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.557 | Acc: 51.071,66.615,87.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.550 | Acc: 51.180,66.659,87.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.549 | Acc: 51.084,66.730,87.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.552 | Acc: 51.090,66.676,87.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.559 | Acc: 51.077,66.705,87.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.562 | Acc: 51.051,66.766,87.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.572 | Acc: 51.020,66.622,87.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.576 | Acc: 50.978,66.586,87.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.577 | Acc: 51.072,66.605,87.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.050 | Acc: 6.250,22.656,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.551 | Acc: 2.827,15.365,44.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.514 | Acc: 2.992,14.996,44.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.605 | Acc: 3.035,14.716,44.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 3.670 | Acc: 55.469,61.719,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.436 | Acc: 52.455,68.118,88.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.511 | Acc: 51.353,66.883,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.478 | Acc: 51.793,67.162,88.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.481 | Acc: 51.370,67.159,88.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.487 | Acc: 51.300,67.242,88.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.493 | Acc: 51.375,67.220,88.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.502 | Acc: 51.186,67.315,88.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.494 | Acc: 51.398,67.454,88.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.510 | Acc: 51.101,67.326,88.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.510 | Acc: 51.170,67.355,88.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.514 | Acc: 51.064,67.272,88.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.525 | Acc: 51.037,67.142,88.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.523 | Acc: 51.054,67.143,88.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.528 | Acc: 51.093,67.104,88.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.525 | Acc: 51.168,67.154,88.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.535 | Acc: 51.088,67.054,88.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.547 | Acc: 51.031,66.970,87.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.557 | Acc: 50.915,66.865,87.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.565 | Acc: 50.931,66.835,87.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.911 | Acc: 8.594,19.531,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.833 | Acc: 6.287,17.299,36.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.825 | Acc: 6.421,17.111,36.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.922 | Acc: 6.378,17.162,36.706,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 3.226 | Acc: 51.562,68.750,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.570 | Acc: 50.744,67.820,87.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.541 | Acc: 51.620,67.854,88.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.551 | Acc: 50.845,67.380,88.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.541 | Acc: 50.916,67.226,88.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.523 | Acc: 51.245,67.319,88.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.500 | Acc: 51.395,67.291,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.513 | Acc: 51.324,67.043,88.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.521 | Acc: 51.135,66.819,88.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.531 | Acc: 51.122,66.674,88.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.547 | Acc: 50.999,66.686,88.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.546 | Acc: 51.025,66.749,88.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.552 | Acc: 51.008,66.672,88.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.542 | Acc: 51.146,66.789,88.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.547 | Acc: 51.229,66.795,87.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.548 | Acc: 51.246,66.835,87.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.562 | Acc: 51.085,66.740,87.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.573 | Acc: 51.013,66.557,87.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.581 | Acc: 50.967,66.486,87.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.589 | Acc: 50.890,66.378,87.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.458 | Acc: 3.125,12.500,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.362 | Acc: 1.153,10.268,38.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.324 | Acc: 1.353,9.870,37.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.425 | Acc: 1.306,10.067,37.756,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.830 | Acc: 40.625,67.969,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.347 | Acc: 52.827,68.862,88.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.315 | Acc: 52.915,68.636,89.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.350 | Acc: 52.843,68.263,89.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.384 | Acc: 52.469,68.046,88.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.409 | Acc: 52.313,67.961,88.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.412 | Acc: 52.085,68.027,88.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.443 | Acc: 51.840,67.758,88.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.441 | Acc: 51.951,67.794,88.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.445 | Acc: 52.016,67.602,88.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.460 | Acc: 51.796,67.611,88.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.478 | Acc: 51.605,67.325,88.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.491 | Acc: 51.426,67.191,88.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.496 | Acc: 51.509,67.214,88.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.493 | Acc: 51.560,67.238,87.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.504 | Acc: 51.534,67.066,87.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.516 | Acc: 51.485,67.012,87.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.528 | Acc: 51.407,66.874,87.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.538 | Acc: 51.273,66.755,87.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.548 | Acc: 51.169,66.617,87.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.967 | Acc: 3.906,16.406,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.498 | Acc: 1.637,14.881,46.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.465 | Acc: 1.715,14.120,46.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.568 | Acc: 1.691,14.152,45.914,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 3.695 | Acc: 50.000,65.625,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.394 | Acc: 52.902,68.304,88.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.386 | Acc: 52.248,68.598,89.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.388 | Acc: 52.228,68.648,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.394 | Acc: 52.305,68.519,89.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.416 | Acc: 52.243,68.178,88.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.431 | Acc: 52.092,68.053,88.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.430 | Acc: 52.128,68.129,88.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.437 | Acc: 52.218,68.008,88.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.453 | Acc: 52.145,67.766,88.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.468 | Acc: 51.975,67.650,88.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.476 | Acc: 51.838,67.562,88.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.483 | Acc: 51.744,67.418,88.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.487 | Acc: 51.658,67.355,88.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.490 | Acc: 51.676,67.329,88.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.499 | Acc: 51.612,67.200,88.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.509 | Acc: 51.601,67.068,87.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.518 | Acc: 51.581,67.034,87.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.522 | Acc: 51.591,67.027,87.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.531 | Acc: 51.585,66.919,87.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.156 | Acc: 3.906,28.906,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.697 | Acc: 3.237,25.893,45.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.654 | Acc: 3.316,25.343,44.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.755 | Acc: 3.356,25.166,44.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 3.585 | Acc: 39.844,71.875,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.510 | Acc: 50.744,68.527,89.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.454 | Acc: 51.277,68.579,89.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.402 | Acc: 52.139,69.019,89.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.393 | Acc: 52.324,68.904,89.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.392 | Acc: 52.135,68.897,89.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.391 | Acc: 52.202,68.905,89.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.430 | Acc: 51.629,68.434,89.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.431 | Acc: 51.781,68.454,89.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.447 | Acc: 51.519,68.159,89.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.455 | Acc: 51.325,68.113,89.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.466 | Acc: 51.308,68.001,88.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.468 | Acc: 51.323,68.066,88.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.471 | Acc: 51.443,68.035,88.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.475 | Acc: 51.398,67.896,88.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.477 | Acc: 51.456,67.823,88.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.488 | Acc: 51.402,67.713,88.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.495 | Acc: 51.354,67.579,88.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.503 | Acc: 51.257,67.436,88.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.509 | Acc: 51.277,67.391,88.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.522 | Acc: 4.688,29.688,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.344 | Acc: 1.972,19.382,49.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.314 | Acc: 2.153,18.693,49.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.426 | Acc: 2.254,18.814,48.386,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 3.772 | Acc: 52.344,63.281,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.491 | Acc: 52.567,67.113,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.443 | Acc: 52.515,68.064,88.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.422 | Acc: 52.459,68.110,89.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.471 | Acc: 51.669,67.747,89.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.444 | Acc: 51.942,68.147,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.456 | Acc: 51.724,67.794,89.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.459 | Acc: 51.679,67.620,89.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.465 | Acc: 51.868,67.435,89.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.465 | Acc: 51.951,67.464,89.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.466 | Acc: 51.811,67.343,89.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.479 | Acc: 51.739,67.205,88.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.495 | Acc: 51.592,67.032,88.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.486 | Acc: 51.697,67.062,88.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.500 | Acc: 51.624,66.979,88.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.505 | Acc: 51.596,66.998,88.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.515 | Acc: 51.519,66.922,88.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.518 | Acc: 51.560,66.897,88.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.515 | Acc: 51.649,66.945,88.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.524 | Acc: 51.599,66.857,88.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.737 | Acc: 6.250,22.656,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.182 | Acc: 3.832,19.680,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.194 | Acc: 4.097,18.826,53.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.279 | Acc: 4.060,18.532,53.548,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 3.893 | Acc: 47.656,71.094,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.397 | Acc: 52.827,68.564,88.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.371 | Acc: 53.258,69.074,89.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.371 | Acc: 53.279,68.609,89.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.380 | Acc: 52.990,68.499,89.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.391 | Acc: 52.947,68.340,89.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.400 | Acc: 52.841,68.447,89.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.397 | Acc: 52.793,68.495,88.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.425 | Acc: 52.421,68.216,88.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.439 | Acc: 52.270,67.973,88.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.442 | Acc: 52.157,67.945,88.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.450 | Acc: 52.255,67.866,88.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.455 | Acc: 52.253,67.810,88.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.462 | Acc: 52.191,67.753,88.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.460 | Acc: 52.238,67.813,88.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.465 | Acc: 52.211,67.800,88.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.469 | Acc: 52.198,67.679,88.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.479 | Acc: 52.025,67.600,88.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.490 | Acc: 51.978,67.480,87.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.495 | Acc: 51.983,67.429,87.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.402 | Acc: 4.688,35.156,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.048 | Acc: 2.121,28.013,42.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.069 | Acc: 2.420,27.401,42.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.141 | Acc: 2.459,27.421,42.585,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 3.980 | Acc: 43.750,67.969,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.335 | Acc: 52.493,70.164,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.365 | Acc: 52.363,69.074,89.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.372 | Acc: 52.280,69.057,89.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.394 | Acc: 52.132,68.924,89.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.381 | Acc: 52.189,68.735,89.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.404 | Acc: 52.105,68.266,89.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.395 | Acc: 52.299,68.357,89.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.390 | Acc: 52.295,68.362,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.400 | Acc: 52.396,68.370,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.412 | Acc: 52.258,68.264,88.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.426 | Acc: 52.029,68.262,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.427 | Acc: 51.939,68.270,88.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.440 | Acc: 51.919,68.106,88.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.449 | Acc: 51.916,67.972,88.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.457 | Acc: 51.952,67.917,88.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.456 | Acc: 52.001,67.862,88.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.466 | Acc: 51.924,67.808,88.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.478 | Acc: 51.930,67.635,88.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.480 | Acc: 51.917,67.620,88.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.759 | Acc: 4.688,39.844,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.613 | Acc: 2.455,33.371,44.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.609 | Acc: 2.325,32.431,43.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.686 | Acc: 2.203,32.364,43.558,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 3.334 | Acc: 50.000,67.188,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.403 | Acc: 52.381,69.010,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.421 | Acc: 52.744,69.226,88.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.395 | Acc: 52.677,69.045,88.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.423 | Acc: 52.025,68.644,88.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.436 | Acc: 52.135,68.518,88.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.424 | Acc: 52.266,68.705,88.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.399 | Acc: 52.438,68.744,89.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.406 | Acc: 52.198,68.532,88.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.413 | Acc: 52.262,68.344,88.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.419 | Acc: 52.060,68.319,88.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.415 | Acc: 52.181,68.372,88.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.421 | Acc: 52.078,68.218,88.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.431 | Acc: 52.035,68.109,88.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.448 | Acc: 51.868,67.835,88.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.462 | Acc: 51.742,67.733,88.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.479 | Acc: 51.575,67.601,88.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.483 | Acc: 51.617,67.529,88.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.491 | Acc: 51.584,67.454,88.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.491 | Acc: 51.575,67.417,88.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.499 | Acc: 4.688,32.812,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.933 | Acc: 3.088,25.260,29.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.874 | Acc: 3.087,25.343,29.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.938 | Acc: 3.151,25.423,29.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 3.339 | Acc: 46.094,66.406,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.403 | Acc: 52.753,68.490,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.423 | Acc: 52.229,68.064,89.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.422 | Acc: 52.075,68.302,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.373 | Acc: 52.768,69.136,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.373 | Acc: 52.746,69.353,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.391 | Acc: 52.608,68.853,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.391 | Acc: 52.344,68.672,89.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.405 | Acc: 52.232,68.512,89.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.401 | Acc: 52.098,68.590,89.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.420 | Acc: 52.037,68.287,89.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.415 | Acc: 52.026,68.347,88.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.421 | Acc: 51.955,68.267,88.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.436 | Acc: 51.958,68.041,88.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.440 | Acc: 52.096,68.002,88.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.453 | Acc: 52.079,67.774,88.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.463 | Acc: 52.044,67.745,88.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.472 | Acc: 51.986,67.749,88.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.478 | Acc: 51.891,67.703,88.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.482 | Acc: 51.901,67.684,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.141 | Acc: 3.906,26.562,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.583 | Acc: 1.786,22.582,28.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.541 | Acc: 2.001,22.675,28.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.619 | Acc: 2.100,22.861,28.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 3.210 | Acc: 60.156,75.000,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.332 | Acc: 52.158,70.685,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.356 | Acc: 52.534,69.760,89.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.346 | Acc: 52.369,70.031,89.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.347 | Acc: 52.373,69.782,89.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.359 | Acc: 52.290,69.508,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.360 | Acc: 52.150,69.460,89.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.366 | Acc: 52.194,69.254,89.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.372 | Acc: 52.193,69.143,89.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.386 | Acc: 51.973,69.095,89.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.391 | Acc: 52.064,68.960,89.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.409 | Acc: 51.973,68.729,89.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.415 | Acc: 52.046,68.724,88.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.419 | Acc: 52.086,68.675,88.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.422 | Acc: 52.010,68.717,88.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.431 | Acc: 51.944,68.589,88.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.437 | Acc: 51.850,68.465,88.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.441 | Acc: 51.897,68.349,88.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.453 | Acc: 51.794,68.172,88.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.459 | Acc: 51.757,68.180,88.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.458 | Acc: 6.250,31.250,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.891 | Acc: 3.832,23.772,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.825 | Acc: 3.906,22.980,33.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.918 | Acc: 3.765,23.066,33.145,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 3.016 | Acc: 58.594,72.656,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.336 | Acc: 53.720,66.778,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.349 | Acc: 53.316,67.893,89.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.334 | Acc: 53.394,68.609,89.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.353 | Acc: 53.279,68.779,88.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.346 | Acc: 53.156,69.083,89.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.358 | Acc: 52.976,69.028,89.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.385 | Acc: 52.687,68.639,89.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.395 | Acc: 52.499,68.386,88.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.409 | Acc: 52.266,68.146,88.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.417 | Acc: 52.219,68.054,88.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.418 | Acc: 52.220,68.092,88.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.431 | Acc: 52.110,68.066,88.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.439 | Acc: 52.116,67.960,88.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.454 | Acc: 51.921,67.766,88.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.459 | Acc: 51.897,67.652,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.465 | Acc: 51.867,67.599,88.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.476 | Acc: 51.805,67.465,88.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.484 | Acc: 51.755,67.328,87.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.485 | Acc: 51.743,67.263,87.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.430 | Acc: 7.031,15.625,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.201 | Acc: 3.832,11.198,29.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.184 | Acc: 3.792,10.957,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.266 | Acc: 3.881,11.194,30.097,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 3.077 | Acc: 60.156,69.531,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.399 | Acc: 51.935,69.829,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.315 | Acc: 52.687,69.950,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.359 | Acc: 52.741,69.262,89.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.377 | Acc: 52.431,69.126,89.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.383 | Acc: 52.297,68.998,89.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.387 | Acc: 52.163,68.815,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.382 | Acc: 52.183,68.722,89.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.404 | Acc: 52.140,68.420,89.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.413 | Acc: 52.158,68.469,89.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.398 | Acc: 52.348,68.571,89.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.403 | Acc: 52.478,68.538,89.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.418 | Acc: 52.392,68.426,88.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.418 | Acc: 52.457,68.448,88.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.414 | Acc: 52.452,68.480,88.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.417 | Acc: 52.380,68.503,88.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.427 | Acc: 52.305,68.348,88.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.435 | Acc: 52.250,68.230,88.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.445 | Acc: 52.106,68.109,88.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.451 | Acc: 52.100,68.018,88.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.883 | Acc: 4.688,38.281,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.576 | Acc: 3.720,30.692,44.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.572 | Acc: 4.154,30.373,44.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.666 | Acc: 4.098,29.700,43.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 4.206 | Acc: 44.531,67.188,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.373 | Acc: 51.562,69.717,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.384 | Acc: 52.153,69.379,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.356 | Acc: 52.600,69.967,90.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.376 | Acc: 52.267,69.194,90.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.374 | Acc: 52.390,68.990,90.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.383 | Acc: 52.389,68.924,89.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.387 | Acc: 52.410,68.711,89.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.387 | Acc: 52.528,68.629,89.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.387 | Acc: 52.650,68.625,89.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.384 | Acc: 52.709,68.567,89.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.391 | Acc: 52.722,68.623,89.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.405 | Acc: 52.477,68.510,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.412 | Acc: 52.499,68.358,88.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.412 | Acc: 52.486,68.439,88.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.411 | Acc: 52.474,68.452,88.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.428 | Acc: 52.232,68.302,88.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.437 | Acc: 52.188,68.175,88.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.446 | Acc: 52.145,68.049,88.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.453 | Acc: 52.059,67.973,88.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.099 | Acc: 3.125,35.156,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.784 | Acc: 1.525,23.958,47.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.798 | Acc: 1.829,22.809,47.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.888 | Acc: 1.755,22.797,47.170,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 3.317 | Acc: 43.750,71.875,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.264 | Acc: 52.567,70.461,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.331 | Acc: 52.325,69.607,89.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.340 | Acc: 52.766,69.723,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.342 | Acc: 52.575,69.049,89.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.363 | Acc: 52.421,68.827,89.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.357 | Acc: 52.589,68.815,88.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.355 | Acc: 52.499,68.722,88.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.375 | Acc: 52.256,68.338,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.380 | Acc: 52.262,68.280,88.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.384 | Acc: 52.204,68.252,89.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.388 | Acc: 52.347,68.234,89.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.389 | Acc: 52.337,68.303,88.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.393 | Acc: 52.389,68.199,88.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.399 | Acc: 52.299,68.238,88.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.406 | Acc: 52.185,68.153,88.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.416 | Acc: 52.139,68.059,88.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.425 | Acc: 52.085,67.918,88.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.442 | Acc: 51.972,67.845,88.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.447 | Acc: 52.046,67.799,88.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.192 | Acc: 6.250,28.125,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.947 | Acc: 2.827,19.606,34.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.941 | Acc: 2.877,18.998,34.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.012 | Acc: 2.830,19.275,34.708,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 3.325 | Acc: 53.125,70.312,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.251 | Acc: 52.716,70.610,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.279 | Acc: 53.030,70.351,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.302 | Acc: 53.074,70.172,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.303 | Acc: 53.463,69.695,90.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.285 | Acc: 53.597,69.740,90.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.296 | Acc: 53.577,69.764,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.309 | Acc: 53.474,69.587,89.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.323 | Acc: 53.183,69.497,89.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.344 | Acc: 52.970,69.264,89.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.355 | Acc: 52.880,69.220,89.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.359 | Acc: 52.863,69.157,89.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.365 | Acc: 52.862,69.081,89.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.371 | Acc: 52.769,69.016,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.375 | Acc: 52.658,69.053,89.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.379 | Acc: 52.707,68.968,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.388 | Acc: 52.560,68.857,88.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.388 | Acc: 52.580,68.892,88.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.398 | Acc: 52.476,68.689,88.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.404 | Acc: 52.381,68.684,88.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.733 | Acc: 3.906,27.344,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.793 | Acc: 1.451,23.438,34.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.792 | Acc: 1.791,22.523,33.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.877 | Acc: 1.755,22.733,33.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 3.001 | Acc: 47.656,72.656,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.196 | Acc: 54.353,71.615,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.185 | Acc: 54.802,71.341,90.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.245 | Acc: 54.559,70.159,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.268 | Acc: 54.244,70.042,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.287 | Acc: 53.899,69.578,90.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.313 | Acc: 53.577,69.596,89.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.314 | Acc: 53.513,69.515,89.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.327 | Acc: 53.353,69.211,89.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.335 | Acc: 53.211,69.022,89.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.342 | Acc: 52.985,68.859,89.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.349 | Acc: 52.909,68.704,89.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.363 | Acc: 52.811,68.423,89.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.365 | Acc: 52.826,68.376,89.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.375 | Acc: 52.686,68.369,89.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.380 | Acc: 52.694,68.345,89.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.389 | Acc: 52.689,68.273,89.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.400 | Acc: 52.559,68.196,88.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.408 | Acc: 52.400,68.086,88.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.409 | Acc: 52.393,68.084,88.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.515 | Acc: 3.125,33.594,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.480 | Acc: 1.079,21.912,38.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.458 | Acc: 1.239,21.265,37.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.560 | Acc: 1.153,21.209,37.615,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 3.359 | Acc: 55.469,68.750,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.369 | Acc: 51.972,68.713,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.342 | Acc: 52.401,69.303,88.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.345 | Acc: 52.626,69.109,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.335 | Acc: 52.672,69.309,89.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.350 | Acc: 52.622,69.152,89.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.358 | Acc: 52.473,68.976,89.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.370 | Acc: 52.383,68.850,89.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.365 | Acc: 52.615,68.915,89.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.347 | Acc: 52.922,69.156,89.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.367 | Acc: 52.779,68.925,89.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.368 | Acc: 52.870,68.835,89.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.374 | Acc: 52.798,68.815,89.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.391 | Acc: 52.670,68.618,89.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.394 | Acc: 52.683,68.619,89.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.395 | Acc: 52.627,68.659,89.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.407 | Acc: 52.529,68.526,88.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.415 | Acc: 52.396,68.425,88.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.423 | Acc: 52.344,68.382,88.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.421 | Acc: 52.346,68.373,88.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.216 | Acc: 7.031,21.094,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.947 | Acc: 2.753,15.848,35.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.918 | Acc: 2.725,15.339,35.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.044 | Acc: 2.497,15.113,34.810,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 3.152 | Acc: 55.469,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.254 | Acc: 53.571,70.759,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.238 | Acc: 53.544,70.960,90.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.230 | Acc: 53.535,70.697,90.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.226 | Acc: 53.540,70.833,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.269 | Acc: 53.512,70.235,90.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.274 | Acc: 53.512,70.170,90.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.285 | Acc: 53.369,70.047,90.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.300 | Acc: 53.110,69.813,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.321 | Acc: 53.056,69.479,89.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.323 | Acc: 53.051,69.419,89.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.337 | Acc: 52.966,69.312,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.346 | Acc: 52.791,69.239,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.349 | Acc: 52.724,69.229,89.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.357 | Acc: 52.655,69.086,89.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.369 | Acc: 52.572,68.986,89.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.379 | Acc: 52.482,68.906,88.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.383 | Acc: 52.467,68.865,88.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.392 | Acc: 52.432,68.752,88.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.396 | Acc: 52.440,68.738,88.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.611 | Acc: 3.906,15.625,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.419 | Acc: 1.600,10.826,31.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.410 | Acc: 1.696,10.232,31.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.486 | Acc: 1.524,10.579,31.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 3.555 | Acc: 49.219,67.969,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.355 | Acc: 52.046,69.680,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.320 | Acc: 52.458,69.684,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.289 | Acc: 52.959,69.429,90.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.255 | Acc: 53.578,70.216,90.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.281 | Acc: 53.473,69.926,90.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.292 | Acc: 53.035,69.635,90.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.321 | Acc: 52.809,69.204,89.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.323 | Acc: 53.009,69.172,89.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.333 | Acc: 52.857,69.078,89.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.350 | Acc: 52.631,68.913,89.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.367 | Acc: 52.637,68.633,89.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.374 | Acc: 52.603,68.607,89.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.381 | Acc: 52.664,68.487,89.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.381 | Acc: 52.733,68.489,88.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.393 | Acc: 52.593,68.358,88.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.399 | Acc: 52.543,68.387,88.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.402 | Acc: 52.561,68.466,88.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.412 | Acc: 52.482,68.389,88.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.414 | Acc: 52.493,68.352,88.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.014 | Acc: 5.469,17.969,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.674 | Acc: 3.162,15.662,41.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.665 | Acc: 2.954,15.434,41.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.716 | Acc: 3.099,15.407,40.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 4.156 | Acc: 49.219,60.938,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.304 | Acc: 54.315,70.275,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.268 | Acc: 54.421,70.655,90.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.265 | Acc: 54.009,70.863,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.263 | Acc: 53.964,70.775,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.261 | Acc: 53.782,70.877,90.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.266 | Acc: 53.700,70.855,90.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.271 | Acc: 53.469,70.645,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.258 | Acc: 53.567,70.604,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.268 | Acc: 53.570,70.481,89.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.286 | Acc: 53.319,70.235,89.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.287 | Acc: 53.369,70.245,89.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.299 | Acc: 53.242,69.940,89.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.312 | Acc: 53.233,69.786,89.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.326 | Acc: 53.136,69.615,89.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.336 | Acc: 53.050,69.531,89.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.353 | Acc: 52.879,69.332,88.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.363 | Acc: 52.777,69.249,88.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.371 | Acc: 52.718,69.079,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.373 | Acc: 52.614,69.064,88.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.391 | Acc: 4.688,25.000,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.101 | Acc: 1.600,18.676,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.118 | Acc: 1.905,18.407,49.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.198 | Acc: 1.742,18.212,49.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 3.147 | Acc: 51.562,70.312,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.144 | Acc: 54.799,71.912,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.237 | Acc: 53.525,70.065,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.250 | Acc: 53.317,69.839,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.238 | Acc: 53.684,69.985,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.218 | Acc: 53.697,70.166,90.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.249 | Acc: 53.467,69.944,90.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.278 | Acc: 53.180,69.664,90.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.288 | Acc: 52.965,69.415,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.307 | Acc: 52.624,69.134,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.315 | Acc: 52.627,69.115,89.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.322 | Acc: 52.623,69.047,89.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.331 | Acc: 52.490,69.061,89.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.332 | Acc: 52.628,69.067,89.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.333 | Acc: 52.711,69.111,89.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.344 | Acc: 52.606,68.950,89.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.356 | Acc: 52.558,68.735,89.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.364 | Acc: 52.509,68.716,88.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.374 | Acc: 52.428,68.611,88.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.377 | Acc: 52.403,68.625,88.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.592 | Acc: 3.125,18.750,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.257 | Acc: 1.265,14.695,39.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.215 | Acc: 1.410,14.367,38.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.272 | Acc: 1.306,14.370,39.242,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 3.211 | Acc: 51.562,71.875,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.263 | Acc: 52.195,70.238,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.352 | Acc: 52.077,69.017,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.329 | Acc: 52.754,68.981,89.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.294 | Acc: 53.434,69.416,89.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.306 | Acc: 53.388,69.214,89.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.303 | Acc: 53.215,69.221,89.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.312 | Acc: 52.992,69.071,89.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.323 | Acc: 52.941,68.871,89.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.320 | Acc: 52.961,68.810,89.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.347 | Acc: 52.701,68.711,89.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.351 | Acc: 52.800,68.754,89.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.361 | Acc: 52.804,68.718,88.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.371 | Acc: 52.730,68.672,88.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.381 | Acc: 52.750,68.605,88.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.391 | Acc: 52.666,68.511,88.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.394 | Acc: 52.667,68.521,88.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.401 | Acc: 52.550,68.399,88.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.402 | Acc: 52.595,68.415,88.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.404 | Acc: 52.604,68.369,88.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.537 | Acc: 3.125,27.344,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.374 | Acc: 1.042,18.155,33.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.365 | Acc: 1.239,17.359,32.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.458 | Acc: 1.178,17.188,32.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 3.226 | Acc: 55.469,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.155 | Acc: 54.762,71.131,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.201 | Acc: 53.678,70.922,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.223 | Acc: 53.509,70.197,90.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.217 | Acc: 53.742,70.110,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.220 | Acc: 53.829,70.189,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.239 | Acc: 53.629,70.241,90.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.230 | Acc: 53.895,70.263,90.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.253 | Acc: 53.766,70.002,90.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.261 | Acc: 53.699,69.885,90.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.279 | Acc: 53.494,69.691,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.284 | Acc: 53.319,69.690,89.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.301 | Acc: 53.180,69.486,89.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.314 | Acc: 53.065,69.376,89.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.315 | Acc: 52.939,69.376,89.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.325 | Acc: 52.969,69.256,89.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.339 | Acc: 52.855,69.120,89.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.349 | Acc: 52.786,69.034,89.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.356 | Acc: 52.768,68.945,89.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.366 | Acc: 52.664,68.850,89.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.121 | Acc: 4.688,18.750,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.814 | Acc: 1.600,13.765,40.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.818 | Acc: 1.715,13.281,39.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.903 | Acc: 1.652,13.435,39.383,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 3.163 | Acc: 58.594,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.198 | Acc: 54.836,71.763,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.213 | Acc: 53.754,71.094,90.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.234 | Acc: 53.689,70.825,90.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.225 | Acc: 53.916,70.968,90.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.232 | Acc: 53.844,70.390,90.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.249 | Acc: 53.868,70.138,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.262 | Acc: 53.751,70.035,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.274 | Acc: 53.567,69.987,89.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.287 | Acc: 53.475,69.807,89.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.295 | Acc: 53.339,69.718,89.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.292 | Acc: 53.288,69.680,89.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.301 | Acc: 53.138,69.502,89.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.311 | Acc: 53.164,69.429,89.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.321 | Acc: 53.017,69.298,89.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.328 | Acc: 53.016,69.248,89.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.337 | Acc: 52.977,69.105,89.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.346 | Acc: 52.868,69.020,89.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.347 | Acc: 52.939,68.977,89.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.357 | Acc: 52.813,68.859,88.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.485 | Acc: 4.688,24.219,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.352 | Acc: 2.307,19.680,49.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.390 | Acc: 2.268,19.131,47.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.489 | Acc: 2.203,19.006,47.080,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 3.446 | Acc: 53.906,70.312,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.130 | Acc: 55.804,72.545,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.182 | Acc: 54.516,71.227,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.192 | Acc: 53.970,70.927,90.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.225 | Acc: 54.118,70.303,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.232 | Acc: 54.239,70.096,90.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.253 | Acc: 53.822,69.919,90.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.267 | Acc: 53.491,70.052,89.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.261 | Acc: 53.702,69.905,89.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.263 | Acc: 53.829,69.967,89.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.274 | Acc: 53.825,69.819,89.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.288 | Acc: 53.712,69.687,89.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.299 | Acc: 53.530,69.509,89.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.310 | Acc: 53.361,69.361,89.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.310 | Acc: 53.409,69.334,89.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.321 | Acc: 53.289,69.256,89.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.329 | Acc: 53.327,69.259,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.342 | Acc: 53.219,69.174,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.341 | Acc: 53.153,69.185,89.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.346 | Acc: 53.158,69.068,88.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.281 | Acc: 2.344,14.844,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.069 | Acc: 1.004,11.644,34.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.025 | Acc: 1.181,11.395,33.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.147 | Acc: 1.114,11.488,33.017,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 3.300 | Acc: 46.094,71.094,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.266 | Acc: 53.832,70.015,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.287 | Acc: 54.249,69.684,89.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.243 | Acc: 54.226,70.005,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.239 | Acc: 54.176,70.081,90.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.254 | Acc: 53.922,69.988,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.268 | Acc: 54.029,69.751,90.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.256 | Acc: 53.801,69.997,90.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.249 | Acc: 53.892,70.012,90.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.247 | Acc: 53.837,70.062,90.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.256 | Acc: 53.809,69.970,90.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.270 | Acc: 53.599,69.789,89.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.277 | Acc: 53.508,69.654,89.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.278 | Acc: 53.517,69.636,89.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.294 | Acc: 53.425,69.428,89.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.300 | Acc: 53.395,69.373,89.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.304 | Acc: 53.278,69.222,89.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.319 | Acc: 53.217,69.107,89.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.322 | Acc: 53.170,69.109,89.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.325 | Acc: 53.131,69.144,89.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.906 | Acc: 3.125,16.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.018 | Acc: 1.079,11.124,50.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.973 | Acc: 1.239,11.585,50.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.075 | Acc: 1.165,11.270,50.717,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 3.074 | Acc: 56.250,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.167 | Acc: 55.320,71.019,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.219 | Acc: 54.268,70.903,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.233 | Acc: 54.585,70.543,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.242 | Acc: 53.954,70.139,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.254 | Acc: 53.581,69.887,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.270 | Acc: 53.622,69.699,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.276 | Acc: 53.624,69.775,90.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.265 | Acc: 53.761,69.919,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.274 | Acc: 53.626,69.799,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.287 | Acc: 53.471,69.621,89.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.294 | Acc: 53.397,69.690,89.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.304 | Acc: 53.264,69.641,89.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.307 | Acc: 53.341,69.606,89.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.311 | Acc: 53.242,69.540,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.312 | Acc: 53.109,69.510,89.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.324 | Acc: 53.025,69.344,89.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.328 | Acc: 53.086,69.304,89.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.340 | Acc: 52.974,69.202,89.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.351 | Acc: 52.975,69.101,89.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.066 | Acc: 3.906,18.750,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.135 | Acc: 1.488,14.100,53.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.106 | Acc: 1.829,13.548,53.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.198 | Acc: 1.678,13.550,53.829,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 3.095 | Acc: 51.562,69.531,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.206 | Acc: 54.278,70.536,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.247 | Acc: 53.887,70.446,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.238 | Acc: 53.791,70.351,90.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.234 | Acc: 53.897,70.804,90.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.253 | Acc: 53.628,70.382,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.254 | Acc: 53.571,70.325,90.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.273 | Acc: 53.374,69.941,89.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.280 | Acc: 53.198,69.973,89.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.281 | Acc: 53.073,69.976,89.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.296 | Acc: 52.946,69.897,89.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.298 | Acc: 53.047,69.931,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.312 | Acc: 52.921,69.641,89.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.317 | Acc: 52.966,69.474,89.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.326 | Acc: 52.853,69.401,89.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.335 | Acc: 52.775,69.339,89.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.340 | Acc: 52.731,69.288,89.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.341 | Acc: 52.768,69.300,89.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.344 | Acc: 52.811,69.278,89.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.348 | Acc: 52.744,69.254,89.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.891 | Acc: 6.250,25.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.711 | Acc: 2.567,21.540,52.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.718 | Acc: 2.782,21.075,52.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.837 | Acc: 2.472,20.863,52.280,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 3.485 | Acc: 46.094,67.969,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.181 | Acc: 54.762,71.429,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.191 | Acc: 54.325,71.037,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.186 | Acc: 54.098,70.774,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.191 | Acc: 54.041,71.113,91.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.201 | Acc: 53.984,71.009,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.237 | Acc: 53.351,70.429,90.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.240 | Acc: 53.419,70.351,90.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.252 | Acc: 53.222,70.245,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.262 | Acc: 53.078,70.105,90.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.274 | Acc: 53.082,69.889,90.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.287 | Acc: 52.839,69.630,90.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.300 | Acc: 52.720,69.515,89.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.306 | Acc: 52.742,69.522,89.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.312 | Acc: 52.789,69.520,89.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.320 | Acc: 52.814,69.459,89.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.325 | Acc: 52.787,69.368,89.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.329 | Acc: 52.784,69.343,89.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.333 | Acc: 52.759,69.243,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.332 | Acc: 52.803,69.271,89.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.023 | Acc: 3.906,17.188,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.378 | Acc: 1.414,12.946,39.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.345 | Acc: 1.696,12.900,39.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.424 | Acc: 1.614,12.999,39.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 2.984 | Acc: 56.250,68.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.132 | Acc: 54.278,71.689,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.156 | Acc: 54.707,71.189,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.178 | Acc: 54.572,70.914,91.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.198 | Acc: 54.514,70.602,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.199 | Acc: 54.278,70.746,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.209 | Acc: 54.203,70.700,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.213 | Acc: 54.050,70.501,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.227 | Acc: 53.911,70.366,90.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.229 | Acc: 53.928,70.369,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.242 | Acc: 53.840,70.141,90.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.246 | Acc: 53.726,70.093,90.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.254 | Acc: 53.637,70.060,90.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.261 | Acc: 53.493,69.983,90.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.275 | Acc: 53.392,69.812,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.289 | Acc: 53.307,69.697,89.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.296 | Acc: 53.269,69.660,89.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.315 | Acc: 53.098,69.440,89.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.321 | Acc: 53.080,69.371,89.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.331 | Acc: 52.973,69.308,89.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.635 | Acc: 4.688,21.094,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.473 | Acc: 2.158,18.713,44.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.468 | Acc: 2.306,18.559,45.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.567 | Acc: 2.126,18.366,45.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.547 | Acc: 51.562,71.875,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.239 | Acc: 56.027,70.536,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.264 | Acc: 54.402,69.684,89.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.277 | Acc: 53.701,69.762,89.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.258 | Acc: 53.926,70.129,89.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.232 | Acc: 54.401,70.173,90.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.247 | Acc: 54.035,69.996,90.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.255 | Acc: 53.807,69.914,90.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.254 | Acc: 53.761,69.803,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.269 | Acc: 53.513,69.842,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.281 | Acc: 53.490,69.675,89.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.292 | Acc: 53.415,69.517,89.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.298 | Acc: 53.368,69.466,89.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.299 | Acc: 53.421,69.444,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.311 | Acc: 53.445,69.248,89.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.316 | Acc: 53.392,69.173,89.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.329 | Acc: 53.315,69.069,89.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.339 | Acc: 53.262,68.988,88.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.341 | Acc: 53.216,69.064,88.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.350 | Acc: 53.119,69.031,88.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.916 | Acc: 5.469,23.438,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.583 | Acc: 2.232,16.295,45.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.516 | Acc: 2.401,16.425,45.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.609 | Acc: 2.228,16.163,45.697,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 3.089 | Acc: 52.344,68.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.106 | Acc: 56.138,70.759,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.131 | Acc: 55.240,70.998,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.170 | Acc: 55.494,70.710,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.194 | Acc: 54.823,70.573,90.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.193 | Acc: 54.695,70.699,90.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.217 | Acc: 54.429,70.345,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.229 | Acc: 54.272,70.274,89.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.235 | Acc: 54.197,70.215,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.239 | Acc: 54.174,70.101,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.253 | Acc: 53.996,70.099,89.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.256 | Acc: 53.874,70.086,89.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.281 | Acc: 53.627,69.778,89.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.285 | Acc: 53.661,69.759,89.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.294 | Acc: 53.637,69.651,89.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.300 | Acc: 53.579,69.632,89.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.299 | Acc: 53.643,69.716,89.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.307 | Acc: 53.579,69.483,89.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.313 | Acc: 53.484,69.460,89.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.319 | Acc: 53.424,69.359,89.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.053 | Acc: 9.375,27.344,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.901 | Acc: 5.060,19.866,40.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.882 | Acc: 4.859,19.722,40.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.954 | Acc: 4.752,19.839,40.548,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 3.710 | Acc: 55.469,67.188,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.264 | Acc: 53.646,70.499,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.244 | Acc: 54.192,70.084,90.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.192 | Acc: 54.483,71.132,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.175 | Acc: 54.861,71.084,90.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.188 | Acc: 54.757,71.024,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.223 | Acc: 54.287,70.616,90.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.213 | Acc: 54.316,70.606,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.212 | Acc: 54.260,70.730,90.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.221 | Acc: 54.204,70.628,90.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.228 | Acc: 54.163,70.487,90.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.228 | Acc: 54.253,70.450,89.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.255 | Acc: 53.978,70.115,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.262 | Acc: 53.837,70.085,89.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.268 | Acc: 53.865,70.001,89.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.272 | Acc: 53.818,69.944,89.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.286 | Acc: 53.731,69.772,89.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.284 | Acc: 53.744,69.731,89.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.297 | Acc: 53.586,69.613,89.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.305 | Acc: 53.554,69.556,89.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.610 | Acc: 3.125,21.875,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.785 | Acc: 1.376,17.299,37.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.752 | Acc: 1.524,16.940,38.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.838 | Acc: 1.409,16.829,38.153,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 3.033 | Acc: 52.344,73.438,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.163 | Acc: 54.464,71.577,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.152 | Acc: 54.611,70.998,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.138 | Acc: 54.470,70.927,90.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.147 | Acc: 54.273,70.978,90.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.171 | Acc: 53.914,70.730,90.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.179 | Acc: 53.977,70.590,90.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.194 | Acc: 53.995,70.512,90.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.191 | Acc: 54.100,70.609,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.191 | Acc: 54.096,70.580,90.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.209 | Acc: 53.988,70.309,90.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.213 | Acc: 53.966,70.312,90.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.224 | Acc: 53.815,70.209,90.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.235 | Acc: 53.625,70.169,90.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.249 | Acc: 53.595,69.959,89.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.253 | Acc: 53.571,69.983,89.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.260 | Acc: 53.551,69.891,89.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.266 | Acc: 53.469,69.802,89.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.273 | Acc: 53.458,69.815,89.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.280 | Acc: 53.424,69.773,89.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.267 | Acc: 7.031,21.094,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.581 | Acc: 4.576,16.815,48.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.576 | Acc: 4.516,15.968,48.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.662 | Acc: 4.367,15.599,48.450,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 3.254 | Acc: 53.906,68.750,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.168 | Acc: 53.943,71.168,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.195 | Acc: 52.954,70.636,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.220 | Acc: 52.946,70.108,90.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.237 | Acc: 53.241,70.023,90.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.229 | Acc: 53.380,70.181,90.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.249 | Acc: 53.241,70.054,90.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.259 | Acc: 53.153,70.041,90.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.270 | Acc: 53.164,69.861,89.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.261 | Acc: 53.319,69.924,89.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.276 | Acc: 53.156,69.838,89.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.278 | Acc: 53.220,69.800,89.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.287 | Acc: 53.235,69.732,89.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.290 | Acc: 53.089,69.753,89.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.298 | Acc: 53.067,69.654,89.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.303 | Acc: 53.122,69.583,89.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.313 | Acc: 52.989,69.531,89.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.316 | Acc: 52.997,69.550,89.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.320 | Acc: 53.049,69.555,89.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.322 | Acc: 53.094,69.511,89.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.036 | Acc: 3.125,21.094,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.950 | Acc: 1.339,11.421,34.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.897 | Acc: 1.658,11.376,34.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.987 | Acc: 1.511,11.270,34.349,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 3.310 | Acc: 48.438,71.094,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.175 | Acc: 53.274,71.577,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.131 | Acc: 54.592,71.761,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.159 | Acc: 54.636,71.491,90.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.147 | Acc: 54.659,71.431,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.158 | Acc: 54.610,71.171,90.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.171 | Acc: 54.345,71.313,90.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.188 | Acc: 54.200,71.088,90.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.190 | Acc: 54.178,71.031,90.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.202 | Acc: 53.911,70.977,90.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.216 | Acc: 53.871,70.783,90.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.228 | Acc: 53.737,70.634,90.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.238 | Acc: 53.624,70.601,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.242 | Acc: 53.520,70.561,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.248 | Acc: 53.511,70.415,89.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.250 | Acc: 53.579,70.440,89.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.258 | Acc: 53.587,70.354,89.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.265 | Acc: 53.583,70.237,89.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.274 | Acc: 53.482,70.185,89.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.274 | Acc: 53.588,70.243,89.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.051 | Acc: 6.250,30.469,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.947 | Acc: 3.795,21.875,44.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.941 | Acc: 3.639,21.018,44.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.037 | Acc: 3.368,20.902,43.840,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 3.147 | Acc: 54.688,73.438,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.188 | Acc: 55.246,70.982,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.133 | Acc: 55.583,71.475,90.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.167 | Acc: 54.892,70.761,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.158 | Acc: 54.524,70.496,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.190 | Acc: 54.409,70.073,90.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.194 | Acc: 54.365,69.867,90.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.205 | Acc: 54.311,69.697,90.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.215 | Acc: 54.173,69.735,90.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.224 | Acc: 54.131,69.708,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.232 | Acc: 54.050,69.694,90.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.232 | Acc: 54.203,69.835,90.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.240 | Acc: 54.120,69.804,90.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.250 | Acc: 53.933,69.717,90.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.260 | Acc: 53.876,69.615,89.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.260 | Acc: 53.893,69.588,89.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.266 | Acc: 53.889,69.512,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.272 | Acc: 53.840,69.453,89.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.286 | Acc: 53.692,69.330,89.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.295 | Acc: 53.660,69.261,89.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.863 | Acc: 5.469,34.375,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.470 | Acc: 3.906,30.432,46.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.544 | Acc: 4.097,30.164,45.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.659 | Acc: 3.791,30.200,45.697,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 3.500 | Acc: 51.562,60.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.169 | Acc: 53.460,70.424,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.157 | Acc: 54.021,71.037,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.179 | Acc: 54.278,70.786,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.210 | Acc: 53.945,70.583,90.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.204 | Acc: 54.092,70.668,90.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.199 | Acc: 54.022,70.590,90.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.211 | Acc: 53.768,70.512,90.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.223 | Acc: 53.727,70.269,90.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.238 | Acc: 53.790,70.088,90.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.237 | Acc: 53.770,70.114,90.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.253 | Acc: 53.684,69.970,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.240 | Acc: 53.922,70.115,89.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.253 | Acc: 53.888,70.061,89.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.264 | Acc: 53.837,69.979,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.276 | Acc: 53.784,69.944,89.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.294 | Acc: 53.643,69.814,89.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.302 | Acc: 53.579,69.772,89.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.304 | Acc: 53.530,69.795,89.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.309 | Acc: 53.543,69.781,88.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.468 | Acc: 3.906,13.281,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.069 | Acc: 1.525,11.570,43.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.094 | Acc: 1.829,11.261,42.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.144 | Acc: 1.793,11.347,42.405,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 3.103 | Acc: 53.906,68.750,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.174 | Acc: 54.688,70.201,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.222 | Acc: 54.135,70.370,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.158 | Acc: 54.483,71.311,90.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.169 | Acc: 54.176,71.480,90.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.176 | Acc: 54.053,71.419,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.172 | Acc: 53.887,71.475,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.160 | Acc: 54.023,71.531,90.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.174 | Acc: 54.110,71.225,90.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.183 | Acc: 53.919,70.982,90.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.198 | Acc: 53.766,70.927,90.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.205 | Acc: 53.744,70.758,90.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.215 | Acc: 53.741,70.676,90.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.229 | Acc: 53.694,70.522,89.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.247 | Acc: 53.670,70.293,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.259 | Acc: 53.564,70.219,89.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.268 | Acc: 53.536,70.103,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.275 | Acc: 53.494,70.102,89.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.285 | Acc: 53.413,69.927,89.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.291 | Acc: 53.416,69.806,89.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.238 | Acc: 3.125,23.438,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.121 | Acc: 1.823,18.080,47.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.152 | Acc: 1.905,17.416,47.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.239 | Acc: 1.729,17.059,47.118,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 2.855 | Acc: 59.375,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.169 | Acc: 53.943,70.685,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.200 | Acc: 53.506,71.132,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.216 | Acc: 53.932,70.978,90.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.193 | Acc: 54.012,70.910,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.205 | Acc: 53.960,70.761,90.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.201 | Acc: 54.113,70.739,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.207 | Acc: 54.289,70.695,90.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.220 | Acc: 54.139,70.405,90.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.230 | Acc: 54.018,70.403,90.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.242 | Acc: 53.891,70.402,90.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.248 | Acc: 53.836,70.238,90.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.253 | Acc: 53.858,70.150,90.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.251 | Acc: 53.813,70.199,89.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.259 | Acc: 53.664,70.026,89.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.258 | Acc: 53.631,70.084,89.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.265 | Acc: 53.597,70.086,89.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.263 | Acc: 53.563,70.113,89.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.267 | Acc: 53.530,70.094,89.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.272 | Acc: 53.486,70.023,89.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.673 | Acc: 3.906,34.375,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.211 | Acc: 2.269,25.000,33.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.205 | Acc: 2.534,24.486,33.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.267 | Acc: 2.408,24.296,33.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.746 | Acc: 57.812,76.562,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.089 | Acc: 53.609,71.912,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.144 | Acc: 53.582,71.246,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.133 | Acc: 53.586,71.158,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.155 | Acc: 53.472,70.804,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.170 | Acc: 53.473,70.715,91.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.191 | Acc: 53.680,70.377,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.211 | Acc: 53.629,70.063,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.218 | Acc: 53.610,70.036,90.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.215 | Acc: 53.738,70.110,90.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.226 | Acc: 53.611,70.064,90.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.236 | Acc: 53.496,70.030,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.244 | Acc: 53.508,70.018,90.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.251 | Acc: 53.457,69.980,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.257 | Acc: 53.556,69.904,90.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.258 | Acc: 53.530,69.939,90.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.264 | Acc: 53.439,69.889,89.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.269 | Acc: 53.437,69.893,89.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.270 | Acc: 53.506,69.947,89.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.281 | Acc: 53.441,69.796,89.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.993 | Acc: 11.719,28.125,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.454 | Acc: 9.263,21.019,42.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.459 | Acc: 9.184,20.960,42.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.508 | Acc: 8.824,20.838,41.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 2.835 | Acc: 60.938,75.000,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.084 | Acc: 55.990,72.135,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.085 | Acc: 56.059,71.284,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.099 | Acc: 55.430,71.337,90.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.135 | Acc: 54.948,71.161,90.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.118 | Acc: 54.958,71.364,90.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.130 | Acc: 54.784,71.152,90.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.160 | Acc: 54.582,70.900,90.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.175 | Acc: 54.556,70.817,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.191 | Acc: 54.364,70.554,90.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.196 | Acc: 54.225,70.503,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.202 | Acc: 54.196,70.443,90.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.214 | Acc: 54.068,70.277,90.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.222 | Acc: 53.957,70.124,90.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.232 | Acc: 53.856,70.057,90.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.236 | Acc: 53.917,70.037,89.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.240 | Acc: 53.836,69.996,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.251 | Acc: 53.718,69.873,89.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.253 | Acc: 53.714,69.940,89.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.260 | Acc: 53.644,69.874,89.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.717 | Acc: 6.250,18.750,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.024 | Acc: 4.241,18.304,35.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.074 | Acc: 4.097,18.102,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.140 | Acc: 3.817,17.815,34.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 2.969 | Acc: 59.375,71.875,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.209 | Acc: 53.720,71.019,89.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.100 | Acc: 54.973,71.913,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.120 | Acc: 54.342,71.644,90.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.135 | Acc: 53.906,71.605,90.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.130 | Acc: 54.285,71.511,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.132 | Acc: 54.287,71.436,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.141 | Acc: 54.266,71.398,90.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.154 | Acc: 54.333,71.239,90.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.174 | Acc: 54.152,70.904,90.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.185 | Acc: 54.178,70.794,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.191 | Acc: 54.129,70.765,90.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.200 | Acc: 54.081,70.601,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.211 | Acc: 53.987,70.390,90.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.223 | Acc: 53.901,70.299,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.226 | Acc: 53.950,70.261,90.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.227 | Acc: 53.952,70.261,89.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.243 | Acc: 53.938,70.143,89.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.252 | Acc: 53.941,70.038,89.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.256 | Acc: 53.882,69.978,89.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.384 | Acc: 3.125,26.562,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.164 | Acc: 2.344,22.135,44.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.215 | Acc: 2.534,21.113,43.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.291 | Acc: 2.280,20.825,43.455,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.665 | Acc: 63.281,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.148 | Acc: 53.906,72.061,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.172 | Acc: 54.211,71.608,90.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.152 | Acc: 54.367,71.606,91.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.162 | Acc: 54.331,71.238,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.171 | Acc: 54.316,71.140,91.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.186 | Acc: 54.352,70.829,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.201 | Acc: 54.034,70.861,90.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.195 | Acc: 54.290,70.807,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.208 | Acc: 54.303,70.632,90.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.216 | Acc: 54.209,70.596,90.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.234 | Acc: 53.984,70.334,90.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.239 | Acc: 53.874,70.283,90.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.242 | Acc: 53.852,70.229,90.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.244 | Acc: 53.753,70.218,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.251 | Acc: 53.678,70.203,89.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.254 | Acc: 53.697,70.145,89.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.258 | Acc: 53.714,70.136,89.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.263 | Acc: 53.651,70.074,89.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.270 | Acc: 53.658,69.964,89.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.489 | Acc: 8.594,32.812,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.915 | Acc: 5.432,26.153,42.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.951 | Acc: 5.412,25.057,42.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.037 | Acc: 5.085,24.641,42.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 3.483 | Acc: 50.781,64.844,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.131 | Acc: 55.692,72.768,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.115 | Acc: 55.107,72.294,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.128 | Acc: 54.982,71.811,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.153 | Acc: 54.543,71.508,90.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.168 | Acc: 54.324,71.465,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.199 | Acc: 54.055,71.210,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.203 | Acc: 54.056,71.088,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.201 | Acc: 54.066,71.002,90.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.197 | Acc: 54.161,70.986,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.201 | Acc: 54.062,70.892,90.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.211 | Acc: 53.942,70.776,90.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.223 | Acc: 53.819,70.685,90.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.219 | Acc: 53.790,70.657,90.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.222 | Acc: 53.778,70.660,90.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.227 | Acc: 53.797,70.663,89.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.236 | Acc: 53.721,70.570,89.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.237 | Acc: 53.659,70.530,89.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.235 | Acc: 53.683,70.527,89.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.239 | Acc: 53.695,70.481,89.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.119 | Acc: 4.688,16.406,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.973 | Acc: 3.013,11.533,31.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.957 | Acc: 3.239,11.662,31.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.062 | Acc: 2.946,11.335,31.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 3.260 | Acc: 55.469,69.531,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.262 | Acc: 55.841,70.201,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.170 | Acc: 54.973,71.075,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.147 | Acc: 54.969,71.568,90.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.147 | Acc: 54.524,71.412,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.158 | Acc: 54.278,71.511,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.169 | Acc: 54.190,71.294,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.180 | Acc: 54.150,71.066,90.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.192 | Acc: 53.979,70.783,90.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.193 | Acc: 53.971,70.727,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.194 | Acc: 53.922,70.705,90.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.207 | Acc: 53.811,70.553,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.213 | Acc: 53.861,70.595,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.222 | Acc: 53.858,70.576,89.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.229 | Acc: 53.792,70.507,89.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.237 | Acc: 53.730,70.450,89.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.230 | Acc: 53.794,70.483,89.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.237 | Acc: 53.787,70.452,89.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.241 | Acc: 53.755,70.401,89.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.247 | Acc: 53.765,70.302,89.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.158 | Acc: 2.344,11.719,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.677 | Acc: 0.930,8.631,51.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.628 | Acc: 1.162,8.632,50.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.750 | Acc: 1.114,8.453,50.448,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 3.294 | Acc: 53.906,67.969,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.014 | Acc: 55.283,73.028,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.071 | Acc: 54.878,72.370,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.112 | Acc: 54.585,71.696,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.097 | Acc: 54.726,71.971,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.084 | Acc: 54.943,72.138,91.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.102 | Acc: 54.784,71.888,90.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.106 | Acc: 54.627,71.869,90.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.132 | Acc: 54.440,71.613,90.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.158 | Acc: 54.334,71.150,90.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.165 | Acc: 54.338,71.055,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.177 | Acc: 54.249,70.945,90.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.182 | Acc: 54.302,70.906,90.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.196 | Acc: 54.158,70.759,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.199 | Acc: 54.207,70.688,90.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.202 | Acc: 54.228,70.660,90.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.210 | Acc: 54.086,70.549,90.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.220 | Acc: 53.934,70.473,89.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.232 | Acc: 53.856,70.390,89.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.244 | Acc: 53.765,70.239,89.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.492 | Acc: 10.938,14.062,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.892 | Acc: 6.473,11.272,41.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.897 | Acc: 6.402,10.290,40.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.964 | Acc: 5.981,10.400,40.663,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 3.131 | Acc: 60.938,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.144 | Acc: 54.948,71.019,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.103 | Acc: 55.202,71.399,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.121 | Acc: 54.816,71.119,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.170 | Acc: 54.340,70.862,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.158 | Acc: 54.425,70.815,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.163 | Acc: 54.397,70.797,90.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.181 | Acc: 54.333,70.484,90.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.193 | Acc: 54.168,70.332,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.204 | Acc: 53.975,70.153,90.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.204 | Acc: 53.972,70.215,90.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.218 | Acc: 53.927,70.164,90.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.209 | Acc: 53.991,70.361,90.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.215 | Acc: 53.891,70.342,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.231 | Acc: 53.798,70.199,89.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.234 | Acc: 53.776,70.126,89.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.237 | Acc: 53.828,70.125,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.240 | Acc: 53.755,70.198,89.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.247 | Acc: 53.727,70.113,89.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.258 | Acc: 53.683,69.999,89.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.861 | Acc: 2.344,21.094,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.369 | Acc: 1.302,18.155,44.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.376 | Acc: 1.562,17.378,42.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.465 | Acc: 1.511,17.405,42.789,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 3.195 | Acc: 49.219,67.969,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.100 | Acc: 54.055,71.912,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.041 | Acc: 54.630,72.656,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.070 | Acc: 54.726,72.643,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.089 | Acc: 54.639,72.174,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.129 | Acc: 54.494,71.937,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.117 | Acc: 54.384,72.004,90.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.115 | Acc: 54.516,72.019,90.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.124 | Acc: 54.581,71.754,90.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.141 | Acc: 54.295,71.625,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.158 | Acc: 54.167,71.381,90.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.172 | Acc: 54.019,71.150,90.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.172 | Acc: 54.094,71.097,90.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.181 | Acc: 54.050,70.974,90.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.199 | Acc: 53.909,70.777,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.206 | Acc: 53.940,70.782,89.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.215 | Acc: 53.904,70.699,89.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.214 | Acc: 53.943,70.723,89.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.218 | Acc: 53.895,70.663,89.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.218 | Acc: 53.988,70.614,89.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.412 | Acc: 2.344,19.531,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.784 | Acc: 2.344,13.690,48.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.757 | Acc: 2.668,13.586,47.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.844 | Acc: 2.485,13.589,47.426,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 3.076 | Acc: 53.125,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.157 | Acc: 54.055,72.210,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.116 | Acc: 55.069,71.989,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.179 | Acc: 54.470,71.401,90.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.188 | Acc: 54.437,71.615,90.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.184 | Acc: 54.254,71.434,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.169 | Acc: 54.255,71.597,90.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.159 | Acc: 54.510,71.620,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.171 | Acc: 54.445,71.395,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.176 | Acc: 54.420,71.310,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.175 | Acc: 54.555,71.168,90.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.184 | Acc: 54.373,71.030,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.184 | Acc: 54.532,70.945,90.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.196 | Acc: 54.400,70.845,90.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.203 | Acc: 54.357,70.705,90.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.209 | Acc: 54.410,70.686,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.211 | Acc: 54.395,70.697,89.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.220 | Acc: 54.351,70.636,89.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.233 | Acc: 54.261,70.421,89.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.241 | Acc: 54.206,70.331,89.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.181 | Acc: 3.906,28.906,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.813 | Acc: 2.455,19.048,51.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.854 | Acc: 2.591,18.274,50.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.938 | Acc: 2.497,17.866,49.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.829 | Acc: 60.938,73.438,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.026 | Acc: 56.510,72.731,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.109 | Acc: 55.507,72.752,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.136 | Acc: 54.623,72.246,90.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.139 | Acc: 54.398,72.039,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.133 | Acc: 54.556,71.983,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.153 | Acc: 54.533,71.849,90.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.156 | Acc: 54.593,71.604,90.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.160 | Acc: 54.489,71.545,90.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.163 | Acc: 54.454,71.564,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.179 | Acc: 54.384,71.517,90.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.186 | Acc: 54.369,71.458,90.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.194 | Acc: 54.201,71.337,90.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.190 | Acc: 54.262,71.420,90.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.200 | Acc: 54.159,71.311,90.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.200 | Acc: 54.168,71.270,90.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.203 | Acc: 54.086,71.218,90.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.207 | Acc: 54.037,71.151,90.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.211 | Acc: 54.001,71.089,90.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.218 | Acc: 53.962,70.999,90.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.842 | Acc: 7.812,27.344,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.425 | Acc: 6.027,22.656,46.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.402 | Acc: 6.040,22.713,46.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.486 | Acc: 5.533,22.374,45.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 3.155 | Acc: 52.344,71.094,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.106 | Acc: 55.990,71.391,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.141 | Acc: 55.507,71.437,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.103 | Acc: 55.392,71.811,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.096 | Acc: 55.314,72.029,90.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.097 | Acc: 55.337,71.883,90.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.099 | Acc: 55.172,71.817,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.123 | Acc: 54.981,71.537,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.128 | Acc: 54.974,71.288,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.141 | Acc: 54.834,71.111,90.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.156 | Acc: 54.862,71.008,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.169 | Acc: 54.712,70.931,90.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.175 | Acc: 54.704,70.844,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.176 | Acc: 54.664,70.845,90.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.185 | Acc: 54.554,70.763,90.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.192 | Acc: 54.501,70.694,89.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.196 | Acc: 54.471,70.697,89.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.200 | Acc: 54.474,70.711,89.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.204 | Acc: 54.471,70.670,89.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.216 | Acc: 54.314,70.595,89.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.113 | Acc: 2.344,21.875,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.233 | Acc: 1.042,13.988,47.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.278 | Acc: 1.391,13.548,47.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.373 | Acc: 1.345,13.345,47.182,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 3.784 | Acc: 46.875,67.969,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.097 | Acc: 55.208,72.693,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.129 | Acc: 54.364,71.761,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.102 | Acc: 54.457,71.734,90.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.081 | Acc: 55.025,72.068,90.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.074 | Acc: 55.113,72.215,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.081 | Acc: 54.836,72.301,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.087 | Acc: 54.832,72.246,90.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.109 | Acc: 54.610,71.890,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.120 | Acc: 54.614,71.720,90.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.135 | Acc: 54.361,71.537,90.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.144 | Acc: 54.405,71.451,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.152 | Acc: 54.415,71.405,90.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.167 | Acc: 54.346,71.187,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.178 | Acc: 54.321,71.077,90.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.188 | Acc: 54.301,70.938,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.190 | Acc: 54.308,70.901,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.203 | Acc: 54.145,70.723,89.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.206 | Acc: 54.136,70.683,89.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.212 | Acc: 54.083,70.634,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.912 | Acc: 3.125,24.219,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.677 | Acc: 1.228,17.969,42.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.732 | Acc: 1.391,17.454,41.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.838 | Acc: 1.294,17.367,41.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 3.005 | Acc: 53.125,77.344,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.078 | Acc: 54.241,71.689,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.153 | Acc: 54.230,71.208,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.085 | Acc: 55.213,72.029,90.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.072 | Acc: 55.035,71.952,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.099 | Acc: 54.819,71.782,90.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.095 | Acc: 55.004,71.810,90.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.114 | Acc: 54.942,71.604,90.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.124 | Acc: 54.867,71.700,90.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.136 | Acc: 54.718,71.499,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.148 | Acc: 54.513,71.459,90.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.150 | Acc: 54.599,71.476,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.150 | Acc: 54.568,71.496,90.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.164 | Acc: 54.412,71.381,90.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.167 | Acc: 54.373,71.238,90.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.169 | Acc: 54.371,71.203,90.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.184 | Acc: 54.288,70.979,90.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.188 | Acc: 54.238,70.885,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.197 | Acc: 54.144,70.810,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.203 | Acc: 54.214,70.786,89.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.427 | Acc: 7.812,29.688,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.269 | Acc: 5.022,21.354,50.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.289 | Acc: 4.992,20.960,49.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.410 | Acc: 4.508,20.786,49.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 2.624 | Acc: 57.812,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.034 | Acc: 56.362,72.917,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.063 | Acc: 56.021,72.542,91.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.065 | Acc: 55.917,72.323,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.078 | Acc: 55.613,72.309,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.101 | Acc: 55.291,72.061,91.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.105 | Acc: 55.288,71.946,91.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.107 | Acc: 55.098,71.919,90.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.142 | Acc: 54.852,71.516,90.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.161 | Acc: 54.549,71.357,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.165 | Acc: 54.703,71.265,90.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.170 | Acc: 54.656,71.274,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.178 | Acc: 54.522,71.123,90.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.182 | Acc: 54.532,71.028,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.187 | Acc: 54.576,70.960,90.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.191 | Acc: 54.503,70.920,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.187 | Acc: 54.546,70.909,90.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.197 | Acc: 54.513,70.787,89.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.207 | Acc: 54.439,70.635,89.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.217 | Acc: 54.292,70.567,89.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.715 | Acc: 8.594,30.469,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.592 | Acc: 4.353,24.479,48.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.543 | Acc: 4.383,25.915,48.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.624 | Acc: 4.111,25.602,48.092,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 3.016 | Acc: 54.688,74.219,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.110 | Acc: 56.436,72.805,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.121 | Acc: 55.545,72.085,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.120 | Acc: 55.456,72.285,90.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.131 | Acc: 55.083,71.711,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.152 | Acc: 54.896,71.256,90.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.144 | Acc: 54.920,71.249,91.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.157 | Acc: 54.765,71.210,90.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.158 | Acc: 54.736,71.332,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.166 | Acc: 54.713,71.275,90.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.161 | Acc: 54.722,71.300,90.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.159 | Acc: 54.755,71.263,90.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.173 | Acc: 54.581,71.078,90.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.177 | Acc: 54.523,71.088,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.186 | Acc: 54.498,70.966,90.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.196 | Acc: 54.482,70.852,89.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.200 | Acc: 54.425,70.807,89.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.207 | Acc: 54.454,70.681,89.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.213 | Acc: 54.454,70.577,89.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.221 | Acc: 54.370,70.493,89.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.486 | Acc: 2.344,25.000,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.028 | Acc: 1.860,13.765,29.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.944 | Acc: 2.115,13.510,29.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.071 | Acc: 2.075,13.307,29.150,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.823 | Acc: 60.156,75.781,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.172 | Acc: 54.204,71.429,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.120 | Acc: 54.554,71.932,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.127 | Acc: 54.316,71.555,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.133 | Acc: 54.234,71.566,90.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.123 | Acc: 54.417,71.581,90.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.114 | Acc: 54.642,71.694,90.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.115 | Acc: 54.732,71.609,90.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.127 | Acc: 54.537,71.550,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.138 | Acc: 54.653,71.474,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.141 | Acc: 54.485,71.447,90.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.144 | Acc: 54.493,71.415,90.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.148 | Acc: 54.493,71.363,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.157 | Acc: 54.544,71.219,90.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.176 | Acc: 54.426,70.999,90.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.182 | Acc: 54.267,70.959,90.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.183 | Acc: 54.288,70.919,90.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.194 | Acc: 54.225,70.817,89.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.202 | Acc: 54.224,70.706,89.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.200 | Acc: 54.281,70.673,89.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.890 | Acc: 3.906,28.906,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.875 | Acc: 2.269,19.531,44.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.896 | Acc: 2.458,19.131,43.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.987 | Acc: 2.395,18.622,42.853,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 3.508 | Acc: 52.344,67.188,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.230 | Acc: 53.125,71.094,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.206 | Acc: 53.982,71.361,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.168 | Acc: 54.636,71.619,90.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.174 | Acc: 54.668,71.779,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.164 | Acc: 54.834,71.860,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.148 | Acc: 54.997,71.881,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.146 | Acc: 55.048,71.831,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.132 | Acc: 55.182,71.938,90.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.142 | Acc: 55.085,71.689,90.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.161 | Acc: 54.804,71.603,90.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.168 | Acc: 54.695,71.451,90.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.183 | Acc: 54.542,71.207,90.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.189 | Acc: 54.493,71.139,89.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.186 | Acc: 54.537,71.211,89.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.195 | Acc: 54.431,71.073,89.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.204 | Acc: 54.386,71.013,89.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.211 | Acc: 54.277,70.933,89.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.211 | Acc: 54.298,71.005,89.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.218 | Acc: 54.294,70.911,89.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.918 | Acc: 3.125,27.344,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.694 | Acc: 1.897,23.810,36.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.711 | Acc: 2.172,23.533,36.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.822 | Acc: 1.985,23.130,36.104,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 3.964 | Acc: 43.750,60.156,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.268 | Acc: 53.348,70.685,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.148 | Acc: 54.021,71.056,90.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.118 | Acc: 54.265,71.440,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.104 | Acc: 54.813,71.875,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.095 | Acc: 54.602,72.107,91.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.081 | Acc: 54.855,72.178,91.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.099 | Acc: 54.715,72.180,91.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.105 | Acc: 54.576,72.040,91.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.110 | Acc: 54.558,72.065,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.122 | Acc: 54.629,71.832,90.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.127 | Acc: 54.560,71.748,90.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.136 | Acc: 54.438,71.593,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.149 | Acc: 54.358,71.396,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.157 | Acc: 54.198,71.358,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.162 | Acc: 54.142,71.255,90.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.172 | Acc: 54.198,71.157,90.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.181 | Acc: 54.186,71.050,90.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.185 | Acc: 54.227,71.033,90.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.197 | Acc: 54.183,71.024,90.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.323 | Acc: 9.375,30.469,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.608 | Acc: 6.845,26.228,51.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.632 | Acc: 6.574,25.591,51.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.723 | Acc: 6.250,25.435,50.986,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 3.326 | Acc: 53.125,62.500,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.116 | Acc: 54.576,71.243,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.117 | Acc: 54.764,71.456,91.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.092 | Acc: 55.085,71.990,91.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.102 | Acc: 54.958,72.174,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.105 | Acc: 55.082,72.084,91.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.106 | Acc: 55.017,71.978,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.119 | Acc: 55.053,71.836,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.140 | Acc: 54.692,71.463,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.141 | Acc: 54.692,71.456,90.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.140 | Acc: 54.699,71.545,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.144 | Acc: 54.772,71.461,90.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.152 | Acc: 54.788,71.418,90.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.166 | Acc: 54.610,71.318,90.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.174 | Acc: 54.585,71.308,90.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.186 | Acc: 54.576,71.200,90.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.187 | Acc: 54.585,71.174,90.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.188 | Acc: 54.598,71.165,90.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.192 | Acc: 54.543,71.169,90.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.197 | Acc: 54.515,71.151,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.178 | Acc: 4.688,30.469,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.712 | Acc: 2.790,23.438,39.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.721 | Acc: 3.144,23.380,38.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.802 | Acc: 2.946,23.297,39.562,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 3.057 | Acc: 55.469,74.219,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.190 | Acc: 54.911,71.540,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.123 | Acc: 54.821,72.085,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.136 | Acc: 54.726,71.824,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.124 | Acc: 55.199,71.740,90.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.084 | Acc: 55.275,72.061,90.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.093 | Acc: 55.081,71.765,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.107 | Acc: 54.965,71.653,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.108 | Acc: 54.998,71.720,90.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.124 | Acc: 54.765,71.534,90.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.146 | Acc: 54.641,71.370,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.148 | Acc: 54.709,71.278,90.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.151 | Acc: 54.772,71.340,90.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.158 | Acc: 54.586,71.321,90.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.167 | Acc: 54.404,71.097,90.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.171 | Acc: 54.402,71.096,90.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.177 | Acc: 54.417,71.069,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.184 | Acc: 54.426,70.961,89.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.187 | Acc: 54.441,70.914,89.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.192 | Acc: 54.435,70.794,89.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.851 | Acc: 2.344,25.000,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.735 | Acc: 1.302,17.485,36.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.707 | Acc: 1.543,18.274,35.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.806 | Acc: 1.498,17.930,35.669,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.920 | Acc: 60.938,74.219,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.071 | Acc: 55.952,72.173,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.047 | Acc: 55.602,72.046,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.007 | Acc: 56.224,72.669,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.069 | Acc: 55.729,72.193,91.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.087 | Acc: 55.608,71.945,91.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.086 | Acc: 55.540,72.082,91.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.098 | Acc: 55.330,71.809,91.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.104 | Acc: 55.182,71.851,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.112 | Acc: 55.223,71.797,90.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.123 | Acc: 55.131,71.642,90.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.140 | Acc: 54.956,71.394,90.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.147 | Acc: 54.807,71.269,90.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.152 | Acc: 54.741,71.276,90.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.157 | Acc: 54.685,71.249,90.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.165 | Acc: 54.713,71.140,90.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.176 | Acc: 54.632,71.001,90.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.185 | Acc: 54.557,70.826,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.193 | Acc: 54.504,70.745,89.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.197 | Acc: 54.454,70.665,89.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.165 | Acc: 5.469,27.344,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.990 | Acc: 4.129,18.676,39.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.021 | Acc: 4.135,18.788,38.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.106 | Acc: 3.932,18.327,38.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 3.183 | Acc: 59.375,74.219,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.031 | Acc: 56.362,72.396,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.113 | Acc: 55.278,72.199,91.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.090 | Acc: 55.571,72.503,91.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.079 | Acc: 55.478,72.685,91.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.077 | Acc: 55.190,72.780,91.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.083 | Acc: 55.210,72.740,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.090 | Acc: 55.037,72.689,90.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.120 | Acc: 54.770,72.278,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.124 | Acc: 54.718,72.082,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.119 | Acc: 54.773,72.042,90.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.141 | Acc: 54.521,71.794,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.148 | Acc: 54.428,71.726,90.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.154 | Acc: 54.379,71.612,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.161 | Acc: 54.315,71.500,90.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.175 | Acc: 54.251,71.429,90.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.174 | Acc: 54.332,71.376,90.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.185 | Acc: 54.305,71.181,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.181 | Acc: 54.343,71.237,90.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.188 | Acc: 54.339,71.149,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.281 | Acc: 5.469,26.562,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.903 | Acc: 4.911,22.656,45.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.928 | Acc: 4.935,21.970,45.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.021 | Acc: 4.521,21.888,45.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 2.822 | Acc: 53.125,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.982 | Acc: 57.812,73.251,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.035 | Acc: 57.336,72.561,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.040 | Acc: 56.250,72.259,90.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.060 | Acc: 56.154,72.222,91.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.053 | Acc: 55.941,72.587,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.065 | Acc: 55.475,72.411,91.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.052 | Acc: 55.397,72.551,91.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.076 | Acc: 55.236,72.186,91.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.080 | Acc: 55.253,72.069,90.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.095 | Acc: 55.313,71.894,90.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.112 | Acc: 55.264,71.702,90.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.127 | Acc: 55.190,71.492,90.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.135 | Acc: 55.023,71.387,90.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.142 | Acc: 54.960,71.297,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.150 | Acc: 54.786,71.247,90.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.158 | Acc: 54.765,71.201,90.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.170 | Acc: 54.699,71.050,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.174 | Acc: 54.718,70.970,89.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.175 | Acc: 54.677,70.942,89.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.750 | Acc: 2.344,25.000,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.433 | Acc: 1.190,21.391,40.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.429 | Acc: 1.372,21.075,40.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.548 | Acc: 1.306,20.940,39.946,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 3.416 | Acc: 52.344,66.406,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.083 | Acc: 54.688,72.173,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.094 | Acc: 54.935,71.970,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.064 | Acc: 55.264,72.503,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.041 | Acc: 55.093,72.743,91.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.055 | Acc: 55.221,72.447,91.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.068 | Acc: 55.120,72.282,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.092 | Acc: 54.992,72.080,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.096 | Acc: 54.969,72.050,91.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.107 | Acc: 55.016,72.026,91.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.122 | Acc: 54.804,71.883,90.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.131 | Acc: 54.631,71.723,90.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.139 | Acc: 54.571,71.622,90.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.146 | Acc: 54.547,71.597,90.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.147 | Acc: 54.565,71.672,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.164 | Acc: 54.446,71.480,90.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.166 | Acc: 54.410,71.471,90.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.175 | Acc: 54.362,71.362,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.184 | Acc: 54.300,71.228,90.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.184 | Acc: 54.353,71.252,90.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.982 | Acc: 7.031,14.844,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.957 | Acc: 3.088,11.793,45.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.973 | Acc: 3.296,11.643,44.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.049 | Acc: 3.163,11.872,44.544,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 2.710 | Acc: 62.500,75.000,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.087 | Acc: 55.022,71.949,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.104 | Acc: 54.840,72.123,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.077 | Acc: 55.097,72.221,91.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.088 | Acc: 55.218,72.367,91.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.103 | Acc: 55.043,72.169,91.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.122 | Acc: 54.894,71.772,90.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.127 | Acc: 54.898,71.604,90.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.135 | Acc: 54.930,71.535,90.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.130 | Acc: 54.908,71.655,90.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.126 | Acc: 54.890,71.782,90.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.136 | Acc: 54.878,71.652,90.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.146 | Acc: 54.759,71.557,90.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.138 | Acc: 54.738,71.639,90.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.144 | Acc: 54.668,71.508,90.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.149 | Acc: 54.651,71.504,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.153 | Acc: 54.554,71.400,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.157 | Acc: 54.587,71.350,90.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.161 | Acc: 54.629,71.317,90.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.161 | Acc: 54.628,71.325,90.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.191 | Acc: 5.469,23.438,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.965 | Acc: 3.162,17.708,46.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.969 | Acc: 3.258,17.435,46.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.061 | Acc: 3.048,17.341,46.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 2.731 | Acc: 56.250,76.562,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.090 | Acc: 54.911,73.698,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.072 | Acc: 54.897,73.476,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.068 | Acc: 55.020,73.412,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.069 | Acc: 54.823,72.965,91.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.060 | Acc: 54.989,72.710,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.064 | Acc: 55.359,72.630,91.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.070 | Acc: 55.269,72.473,91.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.082 | Acc: 55.202,72.385,91.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.085 | Acc: 55.141,72.242,91.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.116 | Acc: 54.792,71.961,90.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.118 | Acc: 54.755,71.963,90.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.117 | Acc: 54.811,71.950,90.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.118 | Acc: 54.936,71.980,90.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.124 | Acc: 54.843,71.833,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.129 | Acc: 54.781,71.784,90.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.137 | Acc: 54.739,71.692,90.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.142 | Acc: 54.726,71.628,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.144 | Acc: 54.726,71.628,90.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.157 | Acc: 54.646,71.494,90.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.659 | Acc: 8.594,18.750,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.119 | Acc: 5.543,14.249,47.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.141 | Acc: 5.335,14.634,47.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.215 | Acc: 5.161,14.485,46.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 3.148 | Acc: 57.812,66.406,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.008 | Acc: 55.841,72.024,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.996 | Acc: 55.793,72.713,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.025 | Acc: 55.379,72.567,91.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.021 | Acc: 55.372,72.791,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.026 | Acc: 55.384,72.873,91.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.044 | Acc: 55.210,72.488,91.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.038 | Acc: 55.436,72.518,91.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.024 | Acc: 55.619,72.598,91.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.041 | Acc: 55.546,72.376,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.055 | Acc: 55.387,72.373,91.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.068 | Acc: 55.232,72.285,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.088 | Acc: 55.093,72.108,90.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.104 | Acc: 54.930,71.977,90.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.117 | Acc: 54.749,71.758,90.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.127 | Acc: 54.745,71.683,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.132 | Acc: 54.675,71.651,90.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.141 | Acc: 54.610,71.653,90.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.140 | Acc: 54.670,71.622,90.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.147 | Acc: 54.626,71.559,89.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.721 | Acc: 2.344,28.125,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.299 | Acc: 1.711,18.713,36.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.350 | Acc: 1.925,18.026,36.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.441 | Acc: 1.844,17.994,36.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 3.227 | Acc: 46.875,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.103 | Acc: 56.399,72.470,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.010 | Acc: 56.631,73.152,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.053 | Acc: 56.084,72.503,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.040 | Acc: 56.067,72.676,91.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.080 | Acc: 55.384,71.999,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.088 | Acc: 55.210,72.036,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.095 | Acc: 55.214,72.091,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.102 | Acc: 55.056,71.991,90.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.117 | Acc: 54.929,71.741,90.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.121 | Acc: 55.033,71.646,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.125 | Acc: 55.020,71.702,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.135 | Acc: 54.814,71.745,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.136 | Acc: 54.882,71.773,90.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.136 | Acc: 54.821,71.800,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.145 | Acc: 54.802,71.678,90.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.148 | Acc: 54.717,71.678,90.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.159 | Acc: 54.639,71.561,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.164 | Acc: 54.573,71.550,90.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.176 | Acc: 54.478,71.375,89.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.297 | Acc: 4.688,28.906,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.574 | Acc: 4.018,23.028,44.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.600 | Acc: 4.040,22.504,42.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.691 | Acc: 3.881,22.656,42.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 3.611 | Acc: 54.688,67.969,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.029 | Acc: 57.180,74.554,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.055 | Acc: 56.079,73.666,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.059 | Acc: 55.277,73.361,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.083 | Acc: 55.208,72.820,91.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.079 | Acc: 55.012,72.834,91.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.072 | Acc: 55.204,72.818,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.080 | Acc: 55.192,72.678,91.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.090 | Acc: 55.095,72.482,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.089 | Acc: 55.102,72.445,90.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.094 | Acc: 55.204,72.435,90.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.104 | Acc: 54.963,72.221,90.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.105 | Acc: 54.970,72.225,90.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.104 | Acc: 55.071,72.285,90.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.106 | Acc: 55.007,72.248,90.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.118 | Acc: 54.957,72.124,90.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.128 | Acc: 54.872,71.975,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.137 | Acc: 54.809,71.838,90.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.146 | Acc: 54.770,71.661,90.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.151 | Acc: 54.780,71.590,90.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.028 | Acc: 3.125,21.875,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.500 | Acc: 1.562,15.402,43.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.489 | Acc: 1.791,14.691,44.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.664 | Acc: 1.665,14.267,43.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 2.976 | Acc: 53.906,76.562,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.067 | Acc: 55.134,72.507,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.056 | Acc: 54.954,72.980,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.053 | Acc: 54.777,72.605,91.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.071 | Acc: 54.678,72.184,91.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.082 | Acc: 55.036,72.153,91.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.083 | Acc: 55.043,72.120,90.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.083 | Acc: 54.920,72.113,90.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.080 | Acc: 55.056,72.210,90.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.083 | Acc: 54.929,72.177,90.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.096 | Acc: 54.835,72.019,90.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.103 | Acc: 54.832,71.907,90.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.116 | Acc: 54.733,71.726,90.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.129 | Acc: 54.661,71.624,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.135 | Acc: 54.674,71.644,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.142 | Acc: 54.693,71.626,90.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.150 | Acc: 54.600,71.488,90.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.156 | Acc: 54.610,71.396,90.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.162 | Acc: 54.566,71.297,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.167 | Acc: 54.521,71.268,89.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.477 | Acc: 2.344,10.938,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.139 | Acc: 1.562,9.487,34.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.162 | Acc: 1.791,9.489,33.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.272 | Acc: 1.767,9.529,33.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 2.627 | Acc: 57.031,72.656,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.953 | Acc: 56.436,73.475,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.998 | Acc: 55.793,73.666,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.007 | Acc: 55.533,73.668,91.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.021 | Acc: 55.556,73.438,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.033 | Acc: 55.206,73.236,91.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.032 | Acc: 55.198,73.108,91.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.038 | Acc: 55.175,73.194,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.052 | Acc: 55.115,72.957,91.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.066 | Acc: 54.985,72.777,90.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.073 | Acc: 54.991,72.683,90.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.089 | Acc: 54.893,72.469,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.098 | Acc: 54.859,72.384,90.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.105 | Acc: 54.652,72.300,90.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.118 | Acc: 54.732,72.145,90.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.120 | Acc: 54.742,72.070,90.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.119 | Acc: 54.807,72.087,90.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.122 | Acc: 54.775,71.999,90.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.127 | Acc: 54.781,71.838,90.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.141 | Acc: 54.708,71.656,90.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.076 | Acc: 4.688,28.906,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.473 | Acc: 1.674,27.083,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.518 | Acc: 1.734,26.524,48.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.623 | Acc: 1.601,26.191,47.400,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 3.130 | Acc: 58.594,74.219,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.025 | Acc: 56.362,73.177,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.018 | Acc: 56.212,73.171,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.972 | Acc: 56.621,73.963,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.996 | Acc: 55.845,73.823,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.046 | Acc: 55.175,73.159,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.073 | Acc: 54.985,72.760,90.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.086 | Acc: 54.931,72.634,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.088 | Acc: 54.974,72.559,90.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.089 | Acc: 54.968,72.518,90.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.105 | Acc: 54.831,72.283,90.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.116 | Acc: 54.758,72.115,90.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.120 | Acc: 54.710,72.024,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.130 | Acc: 54.705,71.833,90.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.140 | Acc: 54.640,71.725,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.138 | Acc: 54.726,71.774,90.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.146 | Acc: 54.685,71.658,90.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.148 | Acc: 54.699,71.630,90.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.149 | Acc: 54.646,71.624,90.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.150 | Acc: 54.706,71.586,90.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.592 | Acc: 5.469,32.812,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.062 | Acc: 4.018,25.186,47.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.100 | Acc: 4.021,24.047,46.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.163 | Acc: 3.791,24.168,46.990,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 3.088 | Acc: 46.875,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.932 | Acc: 57.478,73.884,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.951 | Acc: 56.822,73.971,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.990 | Acc: 55.763,73.770,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.033 | Acc: 54.861,72.897,91.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.055 | Acc: 55.113,72.556,91.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.070 | Acc: 54.616,72.398,91.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.083 | Acc: 54.782,72.302,90.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.105 | Acc: 54.440,71.972,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.105 | Acc: 54.390,71.970,90.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.111 | Acc: 54.322,71.914,90.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.120 | Acc: 54.313,71.857,90.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.119 | Acc: 54.477,71.823,90.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.117 | Acc: 54.565,71.779,90.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.124 | Acc: 54.468,71.725,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.126 | Acc: 54.475,71.774,90.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.133 | Acc: 54.415,71.722,90.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.135 | Acc: 54.452,71.628,90.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.144 | Acc: 54.460,71.522,90.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.142 | Acc: 54.560,71.543,90.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.018 | Acc: 5.469,30.469,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.770 | Acc: 3.832,23.103,50.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.827 | Acc: 4.021,22.123,50.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.908 | Acc: 3.893,22.041,50.295,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 2.611 | Acc: 56.250,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.985 | Acc: 55.766,74.330,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.018 | Acc: 54.973,73.228,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.983 | Acc: 55.443,73.630,91.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.040 | Acc: 55.440,73.061,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.043 | Acc: 55.229,72.896,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.044 | Acc: 55.127,72.986,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.063 | Acc: 55.181,72.773,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.071 | Acc: 55.008,72.797,91.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.067 | Acc: 54.990,72.799,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.082 | Acc: 54.917,72.656,91.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.072 | Acc: 54.981,72.730,90.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.081 | Acc: 55.060,72.556,90.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.087 | Acc: 54.972,72.495,90.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.089 | Acc: 54.865,72.378,90.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.108 | Acc: 54.638,72.116,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.112 | Acc: 54.651,72.004,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.111 | Acc: 54.706,71.969,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.112 | Acc: 54.744,71.955,90.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.117 | Acc: 54.716,71.932,90.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.496 | Acc: 7.031,21.094,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.444 | Acc: 3.348,16.592,50.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.516 | Acc: 3.449,16.025,49.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.601 | Acc: 3.317,15.727,49.898,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 3.092 | Acc: 57.812,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.870 | Acc: 56.622,74.330,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.944 | Acc: 55.736,73.114,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.000 | Acc: 54.944,73.105,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.000 | Acc: 55.064,73.013,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.017 | Acc: 55.012,72.942,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.040 | Acc: 54.875,72.669,91.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.039 | Acc: 55.175,72.689,91.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.049 | Acc: 55.182,72.666,91.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.062 | Acc: 55.020,72.535,91.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.069 | Acc: 55.084,72.334,91.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.076 | Acc: 55.115,72.225,90.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.088 | Acc: 54.999,72.180,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.089 | Acc: 54.993,72.201,90.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.098 | Acc: 54.957,72.092,90.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.109 | Acc: 54.867,71.974,90.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.119 | Acc: 54.765,71.848,90.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.125 | Acc: 54.736,71.797,90.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.126 | Acc: 54.757,71.788,90.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.125 | Acc: 54.798,71.772,90.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.485 | Acc: 3.125,20.312,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.163 | Acc: 1.823,14.732,39.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.130 | Acc: 1.925,14.405,39.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.222 | Acc: 1.844,14.229,39.511,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 3.223 | Acc: 59.375,67.969,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.074 | Acc: 54.278,73.177,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.992 | Acc: 55.373,73.418,91.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.036 | Acc: 54.969,73.181,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.070 | Acc: 54.649,72.897,91.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.059 | Acc: 54.703,72.649,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.065 | Acc: 54.888,72.727,91.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.076 | Acc: 54.887,72.579,91.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.072 | Acc: 54.998,72.520,91.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.067 | Acc: 55.072,72.544,91.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.060 | Acc: 55.247,72.613,90.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.057 | Acc: 55.334,72.660,90.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.065 | Acc: 55.423,72.585,90.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.068 | Acc: 55.367,72.614,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.074 | Acc: 55.338,72.603,90.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.084 | Acc: 55.264,72.430,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.093 | Acc: 55.269,72.320,90.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.098 | Acc: 55.198,72.232,90.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.108 | Acc: 55.205,72.174,90.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.111 | Acc: 55.124,72.113,90.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.474 | Acc: 7.031,32.031,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.261 | Acc: 4.204,29.464,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.257 | Acc: 4.383,29.726,56.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.355 | Acc: 4.175,29.483,56.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 2.805 | Acc: 53.906,72.656,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.109 | Acc: 54.390,71.615,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.113 | Acc: 54.268,71.704,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.025 | Acc: 55.238,72.887,91.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.016 | Acc: 55.440,72.704,91.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.023 | Acc: 55.051,72.757,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.030 | Acc: 55.081,72.514,91.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.041 | Acc: 55.009,72.446,91.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.054 | Acc: 54.974,72.467,90.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.067 | Acc: 54.985,72.255,90.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.080 | Acc: 54.979,72.178,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.083 | Acc: 54.907,72.214,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.087 | Acc: 54.850,72.102,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.090 | Acc: 54.705,72.094,90.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.094 | Acc: 54.660,72.109,90.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.098 | Acc: 54.604,72.046,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.101 | Acc: 54.600,71.977,90.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.109 | Acc: 54.545,71.900,90.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.112 | Acc: 54.629,71.892,90.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.119 | Acc: 54.653,71.842,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.224 | Acc: 4.688,26.562,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.971 | Acc: 3.274,20.052,46.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.004 | Acc: 3.411,19.798,45.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.096 | Acc: 3.138,19.647,46.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 3.493 | Acc: 42.188,65.625,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.135 | Acc: 54.799,71.354,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.116 | Acc: 54.249,71.589,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.075 | Acc: 54.572,72.067,90.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.047 | Acc: 54.967,72.454,91.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.055 | Acc: 54.920,72.239,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.045 | Acc: 54.997,72.211,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.053 | Acc: 54.887,72.396,90.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.058 | Acc: 55.090,72.355,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.061 | Acc: 54.959,72.367,90.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.075 | Acc: 54.859,72.357,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.074 | Acc: 54.970,72.345,90.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.082 | Acc: 54.973,72.280,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.089 | Acc: 54.969,72.162,90.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.093 | Acc: 54.882,72.156,90.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.104 | Acc: 54.895,72.013,90.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.114 | Acc: 54.807,71.877,90.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.120 | Acc: 54.724,71.850,90.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.126 | Acc: 54.664,71.793,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.136 | Acc: 54.628,71.649,89.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.114 | Acc: 7.031,38.281,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.069 | Acc: 3.981,29.353,44.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.051 | Acc: 3.906,28.944,44.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.148 | Acc: 3.701,28.983,43.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 3.492 | Acc: 41.406,70.312,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.085 | Acc: 55.060,72.917,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.024 | Acc: 55.640,72.828,91.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 55.482,72.643,91.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.013 | Acc: 55.401,72.434,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.028 | Acc: 55.322,72.362,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.030 | Acc: 55.101,72.140,91.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.040 | Acc: 55.109,72.119,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.052 | Acc: 55.081,71.972,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.064 | Acc: 54.934,71.871,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.078 | Acc: 54.886,71.809,91.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.079 | Acc: 55.045,71.801,90.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.089 | Acc: 54.830,71.697,90.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.102 | Acc: 54.670,71.639,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.106 | Acc: 54.671,71.622,90.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.118 | Acc: 54.610,71.556,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.119 | Acc: 54.583,71.583,90.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.130 | Acc: 54.413,71.465,90.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.133 | Acc: 54.445,71.442,90.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.138 | Acc: 54.405,71.428,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.994 | Acc: 13.281,30.469,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.307 | Acc: 11.049,26.042,35.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.382 | Acc: 10.995,25.877,33.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.462 | Acc: 10.656,25.564,33.927,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 2.399 | Acc: 60.938,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.014 | Acc: 56.064,73.028,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.958 | Acc: 56.879,74.181,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.991 | Acc: 56.288,73.860,91.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.010 | Acc: 56.173,73.360,91.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.020 | Acc: 56.080,73.205,91.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.022 | Acc: 55.953,73.069,90.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.038 | Acc: 55.663,72.878,90.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.031 | Acc: 55.566,73.010,90.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.056 | Acc: 55.305,72.812,90.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.065 | Acc: 55.162,72.753,90.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.076 | Acc: 55.126,72.571,90.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.088 | Acc: 55.057,72.501,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.085 | Acc: 55.092,72.474,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.097 | Acc: 55.063,72.300,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.105 | Acc: 55.002,72.192,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.109 | Acc: 55.048,72.152,90.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.116 | Acc: 55.088,72.024,90.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.125 | Acc: 54.887,71.940,90.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.129 | Acc: 54.868,71.904,89.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.823 | Acc: 4.688,26.562,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.538 | Acc: 3.013,19.531,32.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.512 | Acc: 3.049,19.798,32.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.583 | Acc: 2.830,19.967,32.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 2.884 | Acc: 57.812,72.656,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.952 | Acc: 56.585,73.810,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.017 | Acc: 55.888,72.351,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.041 | Acc: 55.187,72.528,90.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.084 | Acc: 54.986,72.193,90.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.079 | Acc: 55.213,72.200,90.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.069 | Acc: 55.598,72.262,90.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.061 | Acc: 55.618,72.440,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.074 | Acc: 55.377,72.283,90.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.088 | Acc: 55.270,72.207,90.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.086 | Acc: 55.403,72.240,90.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.087 | Acc: 55.426,72.151,90.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.099 | Acc: 55.281,71.953,90.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.109 | Acc: 55.223,71.827,90.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.104 | Acc: 55.288,71.908,90.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.108 | Acc: 55.175,71.942,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.110 | Acc: 55.196,71.982,90.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.115 | Acc: 55.205,71.951,90.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.121 | Acc: 55.101,71.918,90.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.123 | Acc: 55.089,71.830,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.466 | Acc: 7.031,19.531,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.656 | Acc: 4.799,15.625,49.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.729 | Acc: 4.954,15.358,48.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.840 | Acc: 4.867,15.113,48.899,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 3.103 | Acc: 55.469,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.959 | Acc: 56.101,74.368,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.959 | Acc: 55.545,73.476,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.987 | Acc: 55.738,72.964,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.002 | Acc: 55.652,72.618,91.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.008 | Acc: 55.569,72.850,91.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.017 | Acc: 55.314,72.850,91.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.016 | Acc: 55.303,72.883,91.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.032 | Acc: 55.333,72.632,91.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.036 | Acc: 55.391,72.535,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.042 | Acc: 55.298,72.442,90.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.047 | Acc: 55.232,72.303,90.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.060 | Acc: 55.252,72.128,90.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.072 | Acc: 55.113,71.908,90.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.071 | Acc: 55.132,71.961,90.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.086 | Acc: 55.038,71.815,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.086 | Acc: 55.089,71.834,90.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.091 | Acc: 55.006,71.845,90.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.091 | Acc: 55.084,71.860,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.102 | Acc: 55.016,71.785,90.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.787 | Acc: 7.812,23.438,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.389 | Acc: 5.246,20.126,35.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.454 | Acc: 5.297,19.493,35.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.563 | Acc: 5.059,19.659,34.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 3.168 | Acc: 58.594,69.531,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.040 | Acc: 54.799,72.954,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.997 | Acc: 55.507,72.904,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 55.558,73.092,92.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.998 | Acc: 55.710,73.129,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.013 | Acc: 55.546,73.082,92.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.030 | Acc: 55.462,73.031,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.033 | Acc: 55.491,73.033,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.016 | Acc: 55.677,73.141,91.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.025 | Acc: 55.633,72.937,91.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.043 | Acc: 55.473,72.645,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.060 | Acc: 55.299,72.529,91.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.066 | Acc: 55.371,72.462,91.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.071 | Acc: 55.298,72.438,91.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.073 | Acc: 55.333,72.345,91.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.082 | Acc: 55.246,72.225,91.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.092 | Acc: 55.182,72.099,90.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.099 | Acc: 55.114,72.029,90.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.104 | Acc: 55.066,71.962,90.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.114 | Acc: 54.905,71.844,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.223 | Acc: 7.031,10.156,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.509 | Acc: 5.841,7.701,38.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.569 | Acc: 5.755,7.832,37.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.651 | Acc: 5.533,7.941,37.679,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 2.917 | Acc: 57.812,77.344,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.907 | Acc: 56.696,74.330,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.969 | Acc: 56.879,73.895,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.981 | Acc: 57.018,73.988,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.002 | Acc: 56.453,73.679,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.026 | Acc: 56.320,73.283,91.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.047 | Acc: 55.959,73.063,91.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.053 | Acc: 55.690,72.889,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.048 | Acc: 55.765,72.952,91.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.041 | Acc: 55.689,73.002,91.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.049 | Acc: 55.686,72.843,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.047 | Acc: 55.670,72.840,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.056 | Acc: 55.592,72.643,91.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.059 | Acc: 55.588,72.581,91.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.067 | Acc: 55.549,72.459,90.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.085 | Acc: 55.310,72.311,90.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.089 | Acc: 55.257,72.255,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.099 | Acc: 55.159,72.228,90.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.103 | Acc: 55.099,72.202,90.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.114 | Acc: 55.024,72.066,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.554 | Acc: 5.469,35.156,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.253 | Acc: 4.427,26.376,49.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.277 | Acc: 4.497,25.877,48.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.395 | Acc: 4.290,25.948,48.694,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 2.365 | Acc: 64.062,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.908 | Acc: 56.138,74.479,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.979 | Acc: 55.793,73.628,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.007 | Acc: 55.994,73.245,91.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.007 | Acc: 55.787,73.206,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.003 | Acc: 55.631,73.074,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.017 | Acc: 55.637,72.740,90.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.023 | Acc: 55.607,72.762,90.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.033 | Acc: 55.488,72.579,90.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.035 | Acc: 55.490,72.579,90.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.043 | Acc: 55.422,72.547,90.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.055 | Acc: 55.320,72.384,90.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.070 | Acc: 55.109,72.384,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.070 | Acc: 55.175,72.411,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.071 | Acc: 55.277,72.342,90.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.072 | Acc: 55.292,72.321,90.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.075 | Acc: 55.347,72.345,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.083 | Acc: 55.272,72.242,90.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.094 | Acc: 55.155,72.215,90.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.100 | Acc: 55.102,72.176,90.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.593 | Acc: 3.125,14.844,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.631 | Acc: 2.976,7.329,23.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.681 | Acc: 3.239,7.412,23.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.833 | Acc: 3.125,7.620,22.528,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.838 | Acc: 63.281,73.438,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.952 | Acc: 56.436,73.698,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.046 | Acc: 55.202,72.656,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.005 | Acc: 55.366,73.463,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.996 | Acc: 55.411,73.524,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.021 | Acc: 55.391,73.229,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.009 | Acc: 55.495,73.095,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.011 | Acc: 55.386,72.994,90.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.025 | Acc: 55.246,72.913,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.033 | Acc: 55.283,72.907,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.044 | Acc: 55.263,72.761,90.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.047 | Acc: 55.395,72.706,90.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.058 | Acc: 55.320,72.692,90.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.059 | Acc: 55.298,72.641,90.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.069 | Acc: 55.196,72.520,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.076 | Acc: 55.201,72.397,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.080 | Acc: 55.152,72.384,90.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.085 | Acc: 55.178,72.262,90.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.091 | Acc: 55.097,72.258,90.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.096 | Acc: 55.106,72.234,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.646 | Acc: 3.906,15.625,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.377 | Acc: 3.609,11.458,46.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.474 | Acc: 3.868,11.719,45.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.563 | Acc: 3.637,11.232,45.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.841 | Acc: 57.031,71.875,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.099 | Acc: 55.394,72.582,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.051 | Acc: 55.412,72.942,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.022 | Acc: 55.943,73.322,91.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.012 | Acc: 55.575,73.447,91.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.013 | Acc: 55.399,73.198,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.000 | Acc: 55.772,73.321,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.018 | Acc: 55.801,72.944,91.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.026 | Acc: 55.571,72.947,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.036 | Acc: 55.486,72.868,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.032 | Acc: 55.616,72.932,91.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.039 | Acc: 55.518,72.794,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.061 | Acc: 55.365,72.497,90.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.070 | Acc: 55.346,72.414,90.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.074 | Acc: 55.380,72.362,90.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.075 | Acc: 55.370,72.311,90.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.080 | Acc: 55.376,72.247,90.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.095 | Acc: 55.263,72.157,90.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.104 | Acc: 55.250,72.007,90.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.110 | Acc: 55.210,71.908,90.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.562 | Acc: 3.125,19.531,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.123 | Acc: 2.009,12.500,41.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.146 | Acc: 2.363,12.405,40.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.259 | Acc: 2.280,12.218,40.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 3.123 | Acc: 53.906,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.025 | Acc: 56.399,72.805,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.013 | Acc: 55.850,73.533,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.992 | Acc: 56.327,73.694,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.024 | Acc: 55.990,73.042,90.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.021 | Acc: 55.886,72.780,91.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.042 | Acc: 55.262,72.437,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.049 | Acc: 55.186,72.429,90.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.035 | Acc: 55.333,72.734,90.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.042 | Acc: 55.244,72.639,91.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.035 | Acc: 55.473,72.757,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.035 | Acc: 55.387,72.773,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.045 | Acc: 55.371,72.634,90.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.060 | Acc: 55.262,72.426,90.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.065 | Acc: 55.149,72.439,90.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.078 | Acc: 55.007,72.340,90.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.078 | Acc: 55.011,72.298,90.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.085 | Acc: 55.056,72.228,90.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.092 | Acc: 55.003,72.217,90.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.096 | Acc: 55.057,72.121,90.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.508 | Acc: 4.688,15.625,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.949 | Acc: 3.906,13.802,44.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.998 | Acc: 4.097,14.596,44.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.082 | Acc: 3.842,14.203,43.712,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 2.974 | Acc: 54.688,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.033 | Acc: 56.138,73.363,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.040 | Acc: 55.145,73.114,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.983 | Acc: 55.840,74.321,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.986 | Acc: 55.334,73.997,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.979 | Acc: 55.391,73.685,91.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.978 | Acc: 55.449,73.541,91.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.977 | Acc: 55.657,73.565,91.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.973 | Acc: 55.838,73.797,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.993 | Acc: 55.685,73.645,91.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.998 | Acc: 55.725,73.554,91.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.002 | Acc: 55.790,73.413,91.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.009 | Acc: 55.867,73.295,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.021 | Acc: 55.909,73.180,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.038 | Acc: 55.800,72.973,90.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.052 | Acc: 55.635,72.750,90.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.060 | Acc: 55.481,72.656,90.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.069 | Acc: 55.416,72.574,90.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.077 | Acc: 55.402,72.379,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.088 | Acc: 55.292,72.226,90.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.382 | Acc: 3.906,16.406,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.050 | Acc: 2.530,17.894,43.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.084 | Acc: 2.877,17.931,42.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.163 | Acc: 2.715,17.546,42.585,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 3.755 | Acc: 57.031,68.750,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.005 | Acc: 56.064,73.251,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.049 | Acc: 55.488,73.037,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.003 | Acc: 56.058,73.578,91.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.004 | Acc: 55.855,73.717,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.005 | Acc: 55.886,73.739,91.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.023 | Acc: 55.708,73.366,91.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.021 | Acc: 55.768,73.371,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.026 | Acc: 55.935,73.423,90.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.029 | Acc: 55.918,73.334,90.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.040 | Acc: 55.745,73.158,90.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.055 | Acc: 55.631,73.013,90.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.066 | Acc: 55.602,72.929,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.065 | Acc: 55.636,72.839,90.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.060 | Acc: 55.647,72.798,90.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.066 | Acc: 55.541,72.773,90.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.074 | Acc: 55.530,72.688,90.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.078 | Acc: 55.510,72.590,90.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.084 | Acc: 55.391,72.509,90.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.095 | Acc: 55.266,72.422,90.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.090 | Acc: 3.125,26.562,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.887 | Acc: 1.786,19.457,51.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.936 | Acc: 2.039,19.436,50.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.040 | Acc: 1.998,18.776,51.101,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 2.989 | Acc: 51.562,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.988 | Acc: 54.613,73.363,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.987 | Acc: 54.954,73.228,91.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.014 | Acc: 54.918,73.194,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.019 | Acc: 54.697,73.177,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.026 | Acc: 55.067,73.136,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.032 | Acc: 55.327,73.347,90.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.035 | Acc: 55.352,73.133,90.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.045 | Acc: 55.532,72.977,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.064 | Acc: 55.318,72.561,90.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.066 | Acc: 55.368,72.489,90.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.059 | Acc: 55.596,72.515,90.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.061 | Acc: 55.543,72.358,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.070 | Acc: 55.475,72.366,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.078 | Acc: 55.344,72.309,90.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.084 | Acc: 55.274,72.311,90.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.084 | Acc: 55.281,72.281,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.089 | Acc: 55.258,72.187,90.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.105 | Acc: 55.200,72.020,89.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.105 | Acc: 55.145,72.074,89.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.954 | Acc: 2.344,25.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.757 | Acc: 1.786,18.378,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.805 | Acc: 2.153,18.617,50.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.899 | Acc: 2.100,18.340,49.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.594 | Acc: 56.250,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.998 | Acc: 54.799,73.847,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 55.564,74.333,91.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.989 | Acc: 55.315,74.001,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.991 | Acc: 55.430,73.727,91.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.992 | Acc: 55.856,73.693,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.001 | Acc: 55.934,73.489,90.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.996 | Acc: 56.056,73.548,91.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.017 | Acc: 56.007,73.239,90.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.033 | Acc: 55.771,73.027,90.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.039 | Acc: 55.912,72.959,90.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.061 | Acc: 55.773,72.702,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.064 | Acc: 55.751,72.721,90.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.071 | Acc: 55.588,72.626,90.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.077 | Acc: 55.547,72.556,90.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.083 | Acc: 55.497,72.547,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.093 | Acc: 55.386,72.391,90.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.101 | Acc: 55.361,72.271,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.109 | Acc: 55.304,72.195,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.114 | Acc: 55.225,72.105,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.580 | Acc: 4.688,32.031,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.061 | Acc: 3.237,27.493,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.084 | Acc: 3.544,27.896,56.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.154 | Acc: 3.509,27.907,56.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 2.977 | Acc: 57.031,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.953 | Acc: 55.878,74.182,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.869 | Acc: 56.383,75.362,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.776 | Acc: 56.903,76.217,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.695 | Acc: 57.716,77.151,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.669 | Acc: 58.091,77.081,93.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.662 | Acc: 58.077,77.286,93.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.638 | Acc: 58.084,77.527,94.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.603 | Acc: 58.531,77.858,94.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.587 | Acc: 58.779,77.983,94.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.563 | Acc: 59.017,78.284,94.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.553 | Acc: 59.156,78.390,94.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.538 | Acc: 59.203,78.537,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.529 | Acc: 59.294,78.715,95.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.519 | Acc: 59.492,78.873,95.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.509 | Acc: 59.510,79.000,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.502 | Acc: 59.628,79.086,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 59.776,79.238,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.480 | Acc: 59.936,79.348,95.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.476 | Acc: 59.947,79.400,95.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.009 | Acc: 3.906,35.156,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.671 | Acc: 3.162,31.213,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.713 | Acc: 3.506,31.536,58.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.793 | Acc: 3.304,31.122,58.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 2.701 | Acc: 54.688,77.344,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.386 | Acc: 60.528,81.473,97.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.340 | Acc: 60.899,81.936,97.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.334 | Acc: 60.899,81.762,97.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.312 | Acc: 61.391,82.051,97.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.314 | Acc: 61.069,81.869,97.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.308 | Acc: 61.293,81.967,97.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.298 | Acc: 61.420,82.081,97.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.285 | Acc: 61.340,82.230,97.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.300 | Acc: 61.309,82.083,97.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.301 | Acc: 61.252,81.981,97.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.302 | Acc: 61.344,81.925,97.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.304 | Acc: 61.304,81.915,97.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.298 | Acc: 61.303,82.010,97.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.296 | Acc: 61.321,82.037,97.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.293 | Acc: 61.314,82.042,97.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.295 | Acc: 61.283,82.007,97.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.296 | Acc: 61.251,81.988,97.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.294 | Acc: 61.234,82.033,97.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.291 | Acc: 61.300,82.093,97.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.685 | Acc: 7.031,32.031,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.348 | Acc: 4.129,27.902,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.370 | Acc: 4.325,28.277,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.447 | Acc: 4.098,27.651,55.686,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 2.113 | Acc: 64.844,81.250,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.103 | Acc: 64.137,83.966,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.114 | Acc: 63.091,84.337,98.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.143 | Acc: 62.513,83.965,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.168 | Acc: 61.979,83.642,98.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.167 | Acc: 62.167,83.733,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.185 | Acc: 62.151,83.497,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.180 | Acc: 62.179,83.549,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.187 | Acc: 62.044,83.579,98.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.186 | Acc: 62.060,83.585,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.187 | Acc: 62.022,83.570,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.194 | Acc: 62.065,83.452,98.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.195 | Acc: 62.049,83.428,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.200 | Acc: 61.913,83.417,98.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.196 | Acc: 61.986,83.430,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.196 | Acc: 61.890,83.409,98.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.198 | Acc: 61.860,83.382,98.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.196 | Acc: 61.936,83.358,98.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.198 | Acc: 61.957,83.349,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.200 | Acc: 61.905,83.290,98.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.632 | Acc: 8.594,35.938,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.245 | Acc: 5.320,31.548,56.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.266 | Acc: 5.469,32.088,55.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.342 | Acc: 5.136,31.711,55.392,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.793 | Acc: 75.000,88.281,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.121 | Acc: 63.765,83.594,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.122 | Acc: 62.976,83.937,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.125 | Acc: 63.064,84.068,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.162 | Acc: 62.201,83.951,98.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.163 | Acc: 62.369,83.803,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.144 | Acc: 62.668,83.942,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.144 | Acc: 62.722,83.810,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.143 | Acc: 62.747,83.865,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.153 | Acc: 62.552,83.745,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.153 | Acc: 62.504,83.745,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.157 | Acc: 62.369,83.689,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.153 | Acc: 62.247,83.873,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.160 | Acc: 62.138,83.767,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.155 | Acc: 62.216,83.830,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.151 | Acc: 62.261,83.864,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.154 | Acc: 62.220,83.832,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.159 | Acc: 62.195,83.740,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.159 | Acc: 62.225,83.674,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.161 | Acc: 62.172,83.668,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.254 | Acc: 5.469,31.250,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.077 | Acc: 3.943,24.628,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.109 | Acc: 4.040,24.581,54.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.194 | Acc: 3.791,24.180,54.688,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 2.177 | Acc: 63.281,82.031,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.065 | Acc: 63.095,84.635,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.091 | Acc: 62.824,84.642,98.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.111 | Acc: 62.282,84.862,98.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.136 | Acc: 61.786,84.761,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.141 | Acc: 61.974,84.762,98.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.136 | Acc: 61.996,84.827,98.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.129 | Acc: 61.940,84.818,98.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.133 | Acc: 61.772,84.666,98.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.131 | Acc: 61.943,84.647,98.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.133 | Acc: 61.956,84.620,98.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.122 | Acc: 62.235,84.700,98.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.125 | Acc: 62.124,84.582,98.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.128 | Acc: 62.123,84.498,98.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.126 | Acc: 62.200,84.542,98.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.131 | Acc: 62.108,84.507,98.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.130 | Acc: 62.145,84.499,98.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.129 | Acc: 62.237,84.512,98.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.132 | Acc: 62.286,84.446,98.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.130 | Acc: 62.365,84.455,98.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.792 | Acc: 3.906,22.656,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.602 | Acc: 2.455,20.424,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.609 | Acc: 2.782,20.808,58.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.699 | Acc: 2.626,20.415,57.979,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.900 | Acc: 68.750,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 64.695,85.565,98.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.050 | Acc: 63.758,85.156,98.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.078 | Acc: 63.089,84.977,98.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.100 | Acc: 62.423,84.838,98.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.113 | Acc: 62.307,84.700,98.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.106 | Acc: 62.461,84.840,98.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.103 | Acc: 62.472,84.768,98.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.099 | Acc: 62.680,84.812,98.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.097 | Acc: 62.586,84.919,98.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.096 | Acc: 62.414,84.989,98.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.099 | Acc: 62.341,84.965,98.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.104 | Acc: 62.270,84.829,98.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.101 | Acc: 62.350,84.800,98.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.100 | Acc: 62.297,84.903,98.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.098 | Acc: 62.316,84.892,98.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.096 | Acc: 62.327,84.903,98.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.099 | Acc: 62.280,84.902,98.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.098 | Acc: 62.299,84.892,98.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.100 | Acc: 62.276,84.884,98.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.029 | Acc: 8.594,34.375,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.811 | Acc: 5.022,30.320,60.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.829 | Acc: 5.221,30.450,60.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.912 | Acc: 4.969,29.790,60.156,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 2.219 | Acc: 62.500,84.375,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.083 | Acc: 63.356,85.751,99.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.063 | Acc: 63.548,85.614,99.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.056 | Acc: 63.281,85.669,99.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.052 | Acc: 63.108,85.774,98.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.061 | Acc: 62.840,85.744,98.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.054 | Acc: 63.029,85.673,98.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.065 | Acc: 63.098,85.478,98.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.072 | Acc: 63.000,85.350,98.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.069 | Acc: 62.979,85.264,98.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.063 | Acc: 62.978,85.327,98.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.068 | Acc: 62.808,85.234,98.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.073 | Acc: 62.763,85.231,98.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.068 | Acc: 62.850,85.246,98.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.074 | Acc: 62.806,85.245,98.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.081 | Acc: 62.656,85.112,98.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.083 | Acc: 62.678,85.095,98.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.074 | Acc: 62.750,85.172,98.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.077 | Acc: 62.751,85.139,98.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.079 | Acc: 62.707,85.101,98.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.784 | Acc: 3.906,31.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.698 | Acc: 2.604,25.707,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.695 | Acc: 2.858,25.819,64.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.801 | Acc: 2.728,25.269,64.267,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.845 | Acc: 67.188,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.034 | Acc: 62.872,86.384,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.072 | Acc: 62.729,85.442,98.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.056 | Acc: 62.769,85.464,98.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.049 | Acc: 62.924,85.542,99.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.043 | Acc: 62.956,85.458,99.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.048 | Acc: 62.810,85.486,99.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.051 | Acc: 62.755,85.367,99.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.060 | Acc: 62.665,85.229,99.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.059 | Acc: 62.789,85.294,99.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.055 | Acc: 62.854,85.351,99.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.054 | Acc: 62.917,85.333,99.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.053 | Acc: 62.944,85.364,99.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.055 | Acc: 62.979,85.411,99.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.057 | Acc: 62.861,85.429,99.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.051 | Acc: 62.889,85.522,99.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.051 | Acc: 62.819,85.487,99.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.053 | Acc: 62.802,85.417,99.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.051 | Acc: 62.825,85.386,99.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.055 | Acc: 62.742,85.357,99.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.906 | Acc: 6.250,39.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.786 | Acc: 4.315,34.040,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.804 | Acc: 4.478,33.689,65.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.882 | Acc: 4.175,33.171,66.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.666 | Acc: 67.969,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.061 | Acc: 62.574,86.347,98.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.044 | Acc: 62.710,86.071,98.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.054 | Acc: 62.961,85.540,99.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.044 | Acc: 63.156,85.793,99.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.039 | Acc: 62.848,85.899,99.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.047 | Acc: 62.894,85.776,99.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.050 | Acc: 62.888,85.732,99.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.039 | Acc: 63.189,85.700,99.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.048 | Acc: 62.958,85.653,99.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.041 | Acc: 63.029,85.735,99.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.038 | Acc: 63.147,85.747,99.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.037 | Acc: 63.139,85.737,99.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.043 | Acc: 63.105,85.620,99.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.044 | Acc: 62.987,85.551,99.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.045 | Acc: 62.936,85.509,99.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.046 | Acc: 62.911,85.504,99.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.039 | Acc: 63.054,85.578,99.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.037 | Acc: 63.063,85.660,99.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.033 | Acc: 63.142,85.714,99.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.619 | Acc: 4.688,31.250,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.489 | Acc: 2.865,24.144,60.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.497 | Acc: 3.182,23.780,60.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.601 | Acc: 3.023,23.181,60.848,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 2.040 | Acc: 65.625,84.375,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.112 | Acc: 62.128,85.491,99.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.075 | Acc: 62.119,85.976,99.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.056 | Acc: 62.346,86.296,99.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.050 | Acc: 62.664,86.236,99.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.043 | Acc: 62.802,86.286,99.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.042 | Acc: 62.765,86.247,99.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.045 | Acc: 62.921,86.131,99.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.048 | Acc: 62.961,86.146,99.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.053 | Acc: 62.906,86.063,99.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.046 | Acc: 62.990,85.984,99.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.045 | Acc: 62.924,86.022,99.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.046 | Acc: 62.980,85.976,99.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.037 | Acc: 63.102,85.958,99.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.037 | Acc: 63.095,85.985,99.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.040 | Acc: 63.066,85.914,99.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.040 | Acc: 62.975,85.942,99.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.042 | Acc: 62.997,85.889,99.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.042 | Acc: 62.983,85.851,99.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.042 | Acc: 62.908,85.812,99.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.921 | Acc: 5.469,27.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.688 | Acc: 3.683,28.534,65.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.693 | Acc: 3.925,28.678,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.785 | Acc: 3.650,28.291,65.036,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.893 | Acc: 61.719,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.033 | Acc: 63.095,86.644,99.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.000 | Acc: 63.262,86.662,99.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.029 | Acc: 62.654,86.258,99.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.019 | Acc: 63.098,86.294,99.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.010 | Acc: 62.972,86.371,99.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.004 | Acc: 62.965,86.383,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.008 | Acc: 62.993,86.364,99.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.001 | Acc: 63.194,86.442,99.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.995 | Acc: 63.294,86.455,99.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.013 | Acc: 63.067,86.350,99.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.013 | Acc: 63.020,86.319,99.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.012 | Acc: 63.051,86.284,99.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.010 | Acc: 63.129,86.234,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.004 | Acc: 63.203,86.271,99.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.013 | Acc: 63.076,86.223,99.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.013 | Acc: 63.087,86.144,99.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.007 | Acc: 63.226,86.201,99.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.009 | Acc: 63.218,86.160,99.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.010 | Acc: 63.220,86.130,99.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.476 | Acc: 3.906,23.438,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.249 | Acc: 3.051,22.470,62.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.257 | Acc: 3.354,22.771,61.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.360 | Acc: 3.125,22.195,61.437,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 2.390 | Acc: 58.594,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.006 | Acc: 62.351,85.677,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.975 | Acc: 63.014,86.300,99.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.978 | Acc: 63.345,86.155,99.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.978 | Acc: 63.571,86.497,99.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.984 | Acc: 63.467,86.564,99.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.976 | Acc: 63.468,86.764,99.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.985 | Acc: 63.303,86.625,99.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.981 | Acc: 63.354,86.617,99.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.997 | Acc: 63.104,86.589,99.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.999 | Acc: 63.157,86.517,99.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.002 | Acc: 63.034,86.570,99.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.997 | Acc: 63.155,86.573,99.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.997 | Acc: 63.147,86.563,99.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.990 | Acc: 63.240,86.569,99.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.992 | Acc: 63.175,86.509,99.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.994 | Acc: 63.228,86.468,99.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.991 | Acc: 63.217,86.467,99.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.993 | Acc: 63.184,86.388,99.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.992 | Acc: 63.255,86.382,99.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.168 | Acc: 5.469,28.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.843 | Acc: 4.315,24.702,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.851 | Acc: 4.535,24.714,61.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.941 | Acc: 4.329,24.372,61.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.964 | Acc: 66.406,85.156,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.973 | Acc: 64.360,87.240,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.964 | Acc: 64.501,87.138,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 63.973,87.065,99.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.953 | Acc: 64.400,87.047,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.969 | Acc: 64.194,86.912,99.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.966 | Acc: 64.082,86.932,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.975 | Acc: 63.952,86.835,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.981 | Acc: 63.703,86.738,99.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.982 | Acc: 63.652,86.719,99.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.986 | Acc: 63.561,86.692,99.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.988 | Acc: 63.614,86.584,99.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.987 | Acc: 63.631,86.583,99.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.989 | Acc: 63.536,86.533,99.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.987 | Acc: 63.615,86.596,99.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.988 | Acc: 63.575,86.605,99.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.989 | Acc: 63.529,86.541,99.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.988 | Acc: 63.522,86.558,99.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.992 | Acc: 63.448,86.533,99.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.988 | Acc: 63.464,86.616,99.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.079 | Acc: 5.469,25.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.867 | Acc: 3.683,22.098,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.883 | Acc: 3.887,22.370,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.987 | Acc: 3.637,21.811,58.991,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 2.270 | Acc: 61.719,82.812,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.918 | Acc: 63.690,87.500,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.923 | Acc: 63.834,87.424,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.935 | Acc: 63.960,87.231,99.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.952 | Acc: 63.638,86.892,99.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.958 | Acc: 63.722,86.858,99.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.949 | Acc: 63.604,86.964,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.950 | Acc: 63.564,86.951,99.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.959 | Acc: 63.475,86.918,99.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.957 | Acc: 63.475,86.956,99.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.960 | Acc: 63.324,86.866,99.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.963 | Acc: 63.355,86.825,99.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.958 | Acc: 63.515,86.858,99.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.963 | Acc: 63.476,86.856,99.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.960 | Acc: 63.545,86.911,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.960 | Acc: 63.567,86.833,99.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.970 | Acc: 63.435,86.787,99.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.974 | Acc: 63.421,86.739,99.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.973 | Acc: 63.402,86.723,99.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.972 | Acc: 63.408,86.729,99.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.075 | Acc: 6.250,32.031,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.838 | Acc: 4.613,28.906,59.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.849 | Acc: 4.840,28.239,58.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.944 | Acc: 4.598,27.971,58.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.800 | Acc: 67.969,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.904 | Acc: 64.286,87.686,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.888 | Acc: 64.806,88.281,99.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.904 | Acc: 64.344,87.859,99.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.924 | Acc: 64.400,87.519,99.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.924 | Acc: 64.070,87.415,99.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.925 | Acc: 64.114,87.268,99.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.923 | Acc: 64.112,87.389,99.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.941 | Acc: 63.985,87.257,99.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.949 | Acc: 63.829,87.206,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.956 | Acc: 63.635,87.142,99.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.943 | Acc: 63.850,87.270,99.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.945 | Acc: 63.930,87.244,99.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.943 | Acc: 64.024,87.278,99.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.949 | Acc: 63.921,87.180,99.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.953 | Acc: 63.803,87.209,99.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.951 | Acc: 63.831,87.132,99.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.957 | Acc: 63.785,87.083,99.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.953 | Acc: 63.837,87.084,99.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.949 | Acc: 63.896,87.117,99.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.566 | Acc: 4.688,28.125,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.289 | Acc: 3.981,27.232,65.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.302 | Acc: 4.306,26.944,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.410 | Acc: 4.022,26.550,65.484,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 2.027 | Acc: 60.938,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.852 | Acc: 64.881,88.095,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.881 | Acc: 64.348,88.224,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.917 | Acc: 64.267,88.115,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.950 | Acc: 64.024,87.703,99.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.948 | Acc: 64.062,87.662,99.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.930 | Acc: 64.263,87.629,99.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.929 | Acc: 64.340,87.583,99.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.929 | Acc: 64.334,87.519,99.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.933 | Acc: 64.257,87.427,99.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.933 | Acc: 64.230,87.391,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.942 | Acc: 64.084,87.291,99.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.946 | Acc: 63.910,87.263,99.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.940 | Acc: 64.039,87.326,99.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.941 | Acc: 63.987,87.314,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.942 | Acc: 63.992,87.282,99.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.943 | Acc: 63.958,87.240,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.943 | Acc: 63.973,87.253,99.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.943 | Acc: 63.967,87.234,99.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.940 | Acc: 63.898,87.262,99.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.872 | Acc: 4.688,28.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.661 | Acc: 3.385,23.512,62.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.674 | Acc: 3.639,23.228,62.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.777 | Acc: 3.484,22.784,62.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.671 | Acc: 67.969,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.862 | Acc: 64.658,88.579,99.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.861 | Acc: 64.920,88.129,99.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.873 | Acc: 64.895,87.974,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.894 | Acc: 64.660,87.809,99.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.916 | Acc: 64.279,87.546,99.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.922 | Acc: 64.314,87.545,99.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.913 | Acc: 64.323,87.633,99.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.921 | Acc: 64.179,87.505,99.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.930 | Acc: 63.976,87.444,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.928 | Acc: 64.031,87.461,99.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.932 | Acc: 63.964,87.362,99.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.936 | Acc: 63.881,87.351,99.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.940 | Acc: 63.832,87.267,99.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.939 | Acc: 63.912,87.236,99.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.941 | Acc: 63.876,87.202,99.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.936 | Acc: 63.965,87.276,99.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.931 | Acc: 64.035,87.349,99.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.929 | Acc: 63.967,87.355,99.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.929 | Acc: 63.935,87.352,99.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.805 | Acc: 4.688,33.594,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.533 | Acc: 3.943,28.981,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.537 | Acc: 4.268,28.678,56.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.623 | Acc: 4.022,28.240,56.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.930 | Acc: 67.188,85.938,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.998 | Acc: 62.686,87.091,99.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 64.062,87.729,99.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.920 | Acc: 64.037,87.654,99.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.925 | Acc: 63.773,87.847,99.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.921 | Acc: 63.900,87.894,99.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.923 | Acc: 64.101,87.758,99.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.917 | Acc: 64.013,87.866,99.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.916 | Acc: 64.266,87.820,99.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.915 | Acc: 64.330,87.802,99.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.914 | Acc: 64.335,87.733,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.905 | Acc: 64.441,87.776,99.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.911 | Acc: 64.293,87.763,99.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.915 | Acc: 64.245,87.695,99.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.910 | Acc: 64.268,87.675,99.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.915 | Acc: 64.161,87.656,99.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.920 | Acc: 64.109,87.622,99.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.916 | Acc: 64.161,87.631,99.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.923 | Acc: 64.097,87.522,99.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.927 | Acc: 64.017,87.463,99.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.947 | Acc: 3.906,29.688,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.648 | Acc: 2.976,23.512,64.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.657 | Acc: 3.296,23.399,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.757 | Acc: 3.112,22.951,64.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.196 | Acc: 62.500,83.594,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.975 | Acc: 62.872,86.570,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.917 | Acc: 63.586,87.538,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.887 | Acc: 64.306,87.666,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.879 | Acc: 64.120,88.098,99.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.902 | Acc: 63.846,87.616,99.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.910 | Acc: 63.817,87.500,99.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.909 | Acc: 63.941,87.522,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.915 | Acc: 64.053,87.549,99.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.927 | Acc: 63.976,87.405,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.917 | Acc: 64.090,87.488,99.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.917 | Acc: 64.098,87.433,99.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.910 | Acc: 64.092,87.487,99.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.907 | Acc: 64.197,87.512,99.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.911 | Acc: 64.115,87.531,99.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.916 | Acc: 64.018,87.466,99.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.913 | Acc: 64.189,87.446,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.915 | Acc: 64.198,87.392,99.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.919 | Acc: 64.197,87.366,99.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.920 | Acc: 64.130,87.338,99.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.224 | Acc: 3.906,28.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.027 | Acc: 2.790,23.363,62.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.018 | Acc: 3.182,23.514,62.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.134 | Acc: 2.984,22.951,62.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.538 | Acc: 77.344,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.834 | Acc: 65.327,88.095,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.844 | Acc: 65.244,88.567,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.867 | Acc: 64.549,88.217,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.849 | Acc: 64.660,88.590,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.848 | Acc: 64.542,88.730,99.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.865 | Acc: 64.347,88.578,99.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.871 | Acc: 64.373,88.348,99.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.879 | Acc: 64.208,88.199,99.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.882 | Acc: 64.192,88.040,99.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.888 | Acc: 64.164,87.994,99.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.892 | Acc: 64.161,87.931,99.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.890 | Acc: 64.189,87.957,99.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.895 | Acc: 64.036,87.892,99.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.895 | Acc: 64.065,87.842,99.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.893 | Acc: 64.127,87.780,99.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.893 | Acc: 64.160,87.787,99.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.893 | Acc: 64.152,87.791,99.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.897 | Acc: 64.065,87.751,99.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.904 | Acc: 63.954,87.697,99.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.703 | Acc: 6.250,27.344,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.499 | Acc: 4.241,22.135,63.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.509 | Acc: 4.364,22.027,62.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.621 | Acc: 4.073,21.555,62.961,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 1.782 | Acc: 61.719,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.864 | Acc: 64.137,88.430,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.909 | Acc: 63.281,88.243,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.899 | Acc: 63.832,88.256,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.898 | Acc: 64.140,88.127,99.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.919 | Acc: 63.846,87.956,99.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.911 | Acc: 63.991,88.088,99.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.914 | Acc: 64.013,88.060,99.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.910 | Acc: 63.917,88.073,99.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.925 | Acc: 63.808,87.906,99.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.921 | Acc: 63.771,87.928,99.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.919 | Acc: 63.872,87.945,99.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.914 | Acc: 63.926,87.999,99.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.917 | Acc: 63.916,87.934,99.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.911 | Acc: 64.043,87.903,99.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.912 | Acc: 64.044,87.850,99.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.912 | Acc: 64.033,87.836,99.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.913 | Acc: 64.081,87.825,99.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.910 | Acc: 64.117,87.818,99.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.911 | Acc: 64.099,87.771,99.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.161 | Acc: 7.031,32.031,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.971 | Acc: 5.692,26.004,62.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.961 | Acc: 5.964,26.105,62.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.037 | Acc: 5.674,25.602,62.244,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 2.066 | Acc: 63.281,85.938,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.808 | Acc: 65.365,89.435,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.822 | Acc: 64.787,89.291,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.823 | Acc: 64.869,88.947,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.855 | Acc: 64.892,88.513,99.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.860 | Acc: 64.898,88.390,99.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.866 | Acc: 64.882,88.359,99.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.871 | Acc: 64.522,88.392,99.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.868 | Acc: 64.611,88.291,99.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.868 | Acc: 64.624,88.242,99.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.868 | Acc: 64.533,88.184,99.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.877 | Acc: 64.444,88.020,99.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.886 | Acc: 64.341,87.895,99.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.881 | Acc: 64.377,87.943,99.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.892 | Acc: 64.099,87.878,99.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.891 | Acc: 64.140,87.882,99.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.897 | Acc: 64.136,87.824,99.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.891 | Acc: 64.152,87.928,99.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.890 | Acc: 64.095,87.887,99.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.892 | Acc: 64.104,87.871,99.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.161 | Acc: 11.719,32.031,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.870 | Acc: 7.440,28.571,63.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.866 | Acc: 7.717,29.059,63.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.927 | Acc: 7.428,28.535,63.217,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 1.865 | Acc: 66.406,86.719,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.865 | Acc: 65.625,88.058,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.877 | Acc: 64.253,88.472,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.893 | Acc: 63.947,88.064,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.896 | Acc: 64.246,88.011,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.866 | Acc: 64.705,88.173,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.871 | Acc: 64.682,88.094,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.869 | Acc: 64.772,88.187,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.870 | Acc: 64.543,88.189,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.869 | Acc: 64.576,88.251,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.869 | Acc: 64.467,88.215,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.877 | Acc: 64.356,88.073,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.884 | Acc: 64.263,88.035,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.882 | Acc: 64.209,88.000,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.881 | Acc: 64.249,87.964,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.885 | Acc: 64.229,87.946,99.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.888 | Acc: 64.179,87.953,99.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.888 | Acc: 64.184,87.935,99.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.888 | Acc: 64.149,87.985,99.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.892 | Acc: 64.126,87.955,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.330 | Acc: 6.250,20.312,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.159 | Acc: 4.055,17.783,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.125 | Acc: 4.249,18.236,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.229 | Acc: 4.009,17.610,58.786,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.738 | Acc: 64.062,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.864 | Acc: 64.546,88.690,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.858 | Acc: 64.120,88.700,99.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.858 | Acc: 63.691,88.998,99.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.835 | Acc: 64.226,89.091,99.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.854 | Acc: 63.838,88.745,99.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.858 | Acc: 64.108,88.733,99.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.859 | Acc: 64.195,88.713,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.863 | Acc: 64.135,88.665,99.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.870 | Acc: 64.140,88.549,99.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.865 | Acc: 64.121,88.650,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.867 | Acc: 64.041,88.635,99.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.868 | Acc: 63.923,88.644,99.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.868 | Acc: 63.961,88.566,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.864 | Acc: 64.104,88.568,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.863 | Acc: 64.169,88.572,99.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.858 | Acc: 64.338,88.590,99.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.861 | Acc: 64.370,88.538,99.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.864 | Acc: 64.272,88.485,99.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.870 | Acc: 64.177,88.415,99.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.111 | Acc: 4.688,21.094,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.965 | Acc: 3.423,17.671,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.964 | Acc: 3.735,17.835,57.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.062 | Acc: 3.496,17.444,57.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 2.118 | Acc: 62.500,85.156,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.894 | Acc: 63.579,88.765,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.864 | Acc: 64.386,88.624,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.859 | Acc: 64.472,88.614,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.832 | Acc: 64.988,88.706,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.823 | Acc: 65.362,88.885,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.830 | Acc: 65.108,88.791,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.832 | Acc: 65.093,88.891,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.832 | Acc: 64.960,88.733,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.842 | Acc: 64.943,88.627,99.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.851 | Acc: 64.929,88.573,99.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.859 | Acc: 64.865,88.511,99.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.855 | Acc: 64.857,88.495,99.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.852 | Acc: 64.793,88.548,99.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.855 | Acc: 64.735,88.501,99.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.865 | Acc: 64.576,88.351,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.866 | Acc: 64.525,88.327,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.868 | Acc: 64.555,88.293,99.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.868 | Acc: 64.536,88.253,99.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.872 | Acc: 64.489,88.168,99.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.566 | Acc: 6.250,25.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.368 | Acc: 3.906,21.875,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.352 | Acc: 4.078,21.837,60.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.466 | Acc: 3.804,21.004,60.528,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.806 | Acc: 65.625,83.594,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.803 | Acc: 64.732,89.583,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.835 | Acc: 64.120,89.005,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.836 | Acc: 64.191,88.665,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.857 | Acc: 63.908,88.870,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.849 | Acc: 64.217,88.993,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.848 | Acc: 64.263,88.901,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.863 | Acc: 64.013,88.846,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.859 | Acc: 64.082,88.810,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.859 | Acc: 64.179,88.670,99.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.859 | Acc: 64.226,88.596,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.864 | Acc: 64.144,88.486,99.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.856 | Acc: 64.296,88.424,99.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.854 | Acc: 64.371,88.425,99.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.849 | Acc: 64.421,88.459,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.853 | Acc: 64.392,88.491,99.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.863 | Acc: 64.247,88.369,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.861 | Acc: 64.287,88.375,99.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.862 | Acc: 64.329,88.370,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.863 | Acc: 64.331,88.378,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.725 | Acc: 7.812,25.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.522 | Acc: 5.357,24.070,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.518 | Acc: 5.583,24.600,57.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.612 | Acc: 5.353,23.796,57.390,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.968 | Acc: 63.281,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.956 | Acc: 62.909,88.579,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.874 | Acc: 64.062,88.853,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.862 | Acc: 64.216,88.819,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.848 | Acc: 64.458,89.005,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.834 | Acc: 64.759,89.001,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.839 | Acc: 64.560,88.959,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.842 | Acc: 64.317,88.935,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.849 | Acc: 64.208,88.873,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.859 | Acc: 64.170,88.773,99.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.867 | Acc: 64.082,88.678,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.870 | Acc: 64.176,88.589,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.864 | Acc: 64.202,88.657,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.865 | Acc: 64.119,88.593,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.867 | Acc: 64.065,88.579,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.869 | Acc: 64.000,88.536,99.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.868 | Acc: 64.036,88.554,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.868 | Acc: 64.067,88.563,99.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.870 | Acc: 64.056,88.521,99.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.867 | Acc: 64.097,88.515,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.892 | Acc: 4.688,27.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.536 | Acc: 3.795,23.028,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.541 | Acc: 4.021,23.495,56.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.640 | Acc: 3.753,23.373,56.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.025 | Acc: 63.281,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.824 | Acc: 65.625,89.174,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.801 | Acc: 66.216,89.253,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.821 | Acc: 65.535,89.306,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.807 | Acc: 65.625,89.448,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.811 | Acc: 65.130,89.310,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.807 | Acc: 65.063,89.295,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.812 | Acc: 65.010,89.074,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.822 | Acc: 64.853,89.058,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.830 | Acc: 64.710,88.976,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.831 | Acc: 64.587,88.942,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.840 | Acc: 64.473,88.815,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.849 | Acc: 64.439,88.654,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.850 | Acc: 64.410,88.643,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.854 | Acc: 64.404,88.593,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.855 | Acc: 64.501,88.559,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.852 | Acc: 64.532,88.527,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.857 | Acc: 64.491,88.510,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.856 | Acc: 64.541,88.452,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.851 | Acc: 64.571,88.503,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.024 | Acc: 5.469,24.219,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.775 | Acc: 4.576,22.135,60.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.774 | Acc: 4.688,22.294,60.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.870 | Acc: 4.483,22.093,60.003,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.940 | Acc: 56.250,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.839 | Acc: 64.509,89.844,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.837 | Acc: 64.806,89.501,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.817 | Acc: 64.933,89.434,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.803 | Acc: 64.988,89.497,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.795 | Acc: 65.145,89.387,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.791 | Acc: 65.199,89.372,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.806 | Acc: 65.088,89.162,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.811 | Acc: 64.946,89.135,99.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.813 | Acc: 64.960,89.067,99.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.818 | Acc: 64.925,88.930,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.821 | Acc: 64.883,88.914,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.824 | Acc: 64.886,88.891,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.839 | Acc: 64.664,88.712,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.838 | Acc: 64.660,88.748,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.840 | Acc: 64.722,88.702,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.840 | Acc: 64.683,88.683,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.838 | Acc: 64.681,88.714,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.841 | Acc: 64.612,88.736,99.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.843 | Acc: 64.585,88.716,99.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.099 | Acc: 5.469,22.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.744 | Acc: 3.869,21.354,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.762 | Acc: 4.040,21.646,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.858 | Acc: 3.753,21.260,60.733,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.878 | Acc: 64.062,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.777 | Acc: 65.923,89.062,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.757 | Acc: 66.254,89.272,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.764 | Acc: 66.304,89.536,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.803 | Acc: 65.885,89.101,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.817 | Acc: 65.501,89.062,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.810 | Acc: 65.560,89.146,99.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.805 | Acc: 65.509,89.101,99.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.811 | Acc: 65.344,89.062,99.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.817 | Acc: 65.124,89.006,99.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.826 | Acc: 64.863,88.915,99.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.830 | Acc: 64.879,88.758,99.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.831 | Acc: 64.831,88.777,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.836 | Acc: 64.619,88.733,99.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.835 | Acc: 64.699,88.709,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.833 | Acc: 64.774,88.728,99.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.836 | Acc: 64.705,88.702,99.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.835 | Acc: 64.754,88.739,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.835 | Acc: 64.764,88.697,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.835 | Acc: 64.774,88.681,99.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.143 | Acc: 4.688,27.344,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.935 | Acc: 3.311,24.144,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.930 | Acc: 3.659,24.333,64.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.034 | Acc: 3.432,24.232,64.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.852 | Acc: 67.188,91.406,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.809 | Acc: 65.811,89.695,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.837 | Acc: 65.396,89.386,99.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.802 | Acc: 65.702,89.434,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.806 | Acc: 65.394,89.429,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.801 | Acc: 65.308,89.519,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.807 | Acc: 65.199,89.398,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.807 | Acc: 65.276,89.384,99.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.818 | Acc: 64.931,89.261,99.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.824 | Acc: 64.645,89.119,99.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.828 | Acc: 64.688,89.020,99.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.828 | Acc: 64.653,89.055,99.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.829 | Acc: 64.672,89.011,99.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.833 | Acc: 64.571,88.952,99.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.833 | Acc: 64.518,88.951,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.833 | Acc: 64.543,88.966,99.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.832 | Acc: 64.620,88.897,99.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.835 | Acc: 64.599,88.817,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.835 | Acc: 64.599,88.805,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.836 | Acc: 64.567,88.814,99.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.175 | Acc: 5.469,25.000,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.830 | Acc: 3.683,22.433,52.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.841 | Acc: 3.925,22.447,52.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.942 | Acc: 3.624,22.170,52.126,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.837 | Acc: 62.500,85.156,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.837 | Acc: 64.286,89.509,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.801 | Acc: 65.225,89.463,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.798 | Acc: 65.305,89.331,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.803 | Acc: 65.114,89.410,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.816 | Acc: 64.975,89.302,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.806 | Acc: 65.115,89.366,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.805 | Acc: 65.204,89.423,99.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.812 | Acc: 65.072,89.286,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.819 | Acc: 65.047,89.205,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.819 | Acc: 64.929,89.144,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.817 | Acc: 64.985,89.062,99.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.811 | Acc: 65.045,89.095,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.806 | Acc: 65.173,89.125,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.810 | Acc: 65.091,89.113,99.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.815 | Acc: 65.038,89.081,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.820 | Acc: 64.951,89.045,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.819 | Acc: 65.020,89.042,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.819 | Acc: 65.006,89.013,99.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.819 | Acc: 64.954,89.009,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.563 | Acc: 5.469,15.625,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.295 | Acc: 3.460,12.128,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.288 | Acc: 3.754,12.767,57.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.388 | Acc: 3.484,12.462,57.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.247 | Acc: 53.906,85.156,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.782 | Acc: 64.621,90.365,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.786 | Acc: 64.405,89.425,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.810 | Acc: 64.319,89.242,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.837 | Acc: 64.140,88.899,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.846 | Acc: 63.970,88.877,99.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.816 | Acc: 64.392,89.056,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.825 | Acc: 64.351,88.941,99.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.833 | Acc: 64.344,88.922,99.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.834 | Acc: 64.386,88.860,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.827 | Acc: 64.447,88.946,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.830 | Acc: 64.487,88.935,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.833 | Acc: 64.445,88.816,99.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.832 | Acc: 64.404,88.853,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.832 | Acc: 64.382,88.896,99.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.832 | Acc: 64.434,88.886,99.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.826 | Acc: 64.564,88.909,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.832 | Acc: 64.493,88.810,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.830 | Acc: 64.567,88.807,99.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.835 | Acc: 64.483,88.788,99.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.086 | Acc: 5.469,23.438,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.860 | Acc: 4.613,19.010,60.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.850 | Acc: 4.859,20.598,60.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.951 | Acc: 4.623,20.543,60.412,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.663 | Acc: 65.625,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.841 | Acc: 64.769,88.542,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.764 | Acc: 65.320,89.672,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.764 | Acc: 65.279,90.036,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.776 | Acc: 65.403,89.680,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.787 | Acc: 65.192,89.442,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.786 | Acc: 65.263,89.347,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.773 | Acc: 65.597,89.489,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.779 | Acc: 65.625,89.422,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.782 | Acc: 65.608,89.365,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.786 | Acc: 65.473,89.373,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.790 | Acc: 65.356,89.331,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.793 | Acc: 65.408,89.280,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.802 | Acc: 65.239,89.194,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.805 | Acc: 65.241,89.146,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.807 | Acc: 65.290,89.088,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.820 | Acc: 65.172,88.926,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.818 | Acc: 65.123,88.966,99.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.818 | Acc: 65.039,88.978,99.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.826 | Acc: 64.907,88.876,99.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.290 | Acc: 6.250,21.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.064 | Acc: 4.204,18.341,56.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.053 | Acc: 4.383,18.502,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.164 | Acc: 4.201,18.315,56.519,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.558 | Acc: 62.500,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.786 | Acc: 65.179,89.546,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.776 | Acc: 65.854,89.710,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.766 | Acc: 66.137,89.793,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.761 | Acc: 65.866,89.998,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.771 | Acc: 65.602,89.867,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.782 | Acc: 65.483,89.708,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.778 | Acc: 65.403,89.744,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.779 | Acc: 65.310,89.659,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.787 | Acc: 65.249,89.537,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.793 | Acc: 65.159,89.385,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.787 | Acc: 65.190,89.480,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.789 | Acc: 65.259,89.471,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.790 | Acc: 65.254,89.362,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.798 | Acc: 65.097,89.299,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.807 | Acc: 64.974,89.213,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.808 | Acc: 64.878,89.123,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.812 | Acc: 64.748,89.053,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.815 | Acc: 64.636,89.013,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.816 | Acc: 64.680,89.021,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.260 | Acc: 9.375,25.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.090 | Acc: 5.841,19.457,56.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.071 | Acc: 6.155,20.160,55.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.152 | Acc: 5.879,19.736,55.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 2.169 | Acc: 57.812,87.500,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.756 | Acc: 66.592,89.955,99.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.793 | Acc: 65.873,89.653,99.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.773 | Acc: 65.868,89.793,99.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.790 | Acc: 65.442,89.699,99.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.800 | Acc: 65.176,89.689,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.794 | Acc: 65.270,89.540,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.810 | Acc: 65.071,89.317,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.819 | Acc: 64.892,89.160,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.820 | Acc: 64.870,89.157,99.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.820 | Acc: 64.782,89.175,99.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.819 | Acc: 64.851,89.200,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.822 | Acc: 64.844,89.108,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.819 | Acc: 64.856,89.128,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.821 | Acc: 64.841,89.118,99.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.820 | Acc: 64.792,89.096,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.818 | Acc: 64.832,89.077,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.816 | Acc: 64.906,89.072,99.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.817 | Acc: 64.898,89.052,99.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.821 | Acc: 64.795,88.989,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.002 | Acc: 5.469,17.188,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.831 | Acc: 4.092,15.141,60.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.832 | Acc: 4.173,15.777,60.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.942 | Acc: 3.970,15.279,60.656,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.649 | Acc: 67.969,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.682 | Acc: 65.737,90.848,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.759 | Acc: 65.911,90.130,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.771 | Acc: 65.689,90.202,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.774 | Acc: 65.442,90.162,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.770 | Acc: 65.687,90.192,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.774 | Acc: 65.696,89.928,99.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.789 | Acc: 65.442,89.783,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.792 | Acc: 65.426,89.810,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.793 | Acc: 65.452,89.719,99.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.795 | Acc: 65.435,89.614,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.801 | Acc: 65.310,89.465,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.800 | Acc: 65.275,89.429,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.801 | Acc: 65.170,89.437,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.805 | Acc: 65.133,89.316,99.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.807 | Acc: 65.088,89.268,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.810 | Acc: 65.092,89.240,99.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.812 | Acc: 65.061,89.159,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.809 | Acc: 65.149,89.143,99.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.814 | Acc: 65.018,89.147,99.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.078 | Acc: 5.469,17.188,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.009 | Acc: 3.497,9.859,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.001 | Acc: 3.849,10.804,57.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.116 | Acc: 3.599,10.425,57.313,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.744 | Acc: 66.406,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.838 | Acc: 64.137,89.249,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.788 | Acc: 65.282,89.748,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.780 | Acc: 65.382,89.946,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.786 | Acc: 64.940,90.008,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.781 | Acc: 64.960,90.045,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.783 | Acc: 65.154,89.831,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.796 | Acc: 64.899,89.827,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.798 | Acc: 64.941,89.756,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.797 | Acc: 65.047,89.826,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.805 | Acc: 64.910,89.692,99.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.814 | Acc: 64.893,89.533,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.812 | Acc: 64.980,89.439,99.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.813 | Acc: 65.002,89.371,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.814 | Acc: 64.963,89.332,99.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.814 | Acc: 64.989,89.340,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.815 | Acc: 64.956,89.272,99.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.817 | Acc: 64.940,89.237,99.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.822 | Acc: 64.863,89.173,99.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.817 | Acc: 64.973,89.183,99.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.910 | Acc: 5.469,18.750,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.569 | Acc: 4.874,14.881,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.534 | Acc: 5.030,15.854,52.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.635 | Acc: 4.803,15.599,52.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.930 | Acc: 60.156,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.857 | Acc: 63.914,89.918,99.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.817 | Acc: 65.053,90.434,99.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.798 | Acc: 65.292,90.100,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.797 | Acc: 65.384,90.027,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.810 | Acc: 65.192,89.929,99.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.812 | Acc: 65.257,89.844,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.812 | Acc: 65.021,89.905,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.815 | Acc: 64.936,89.659,99.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.802 | Acc: 65.133,89.762,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.808 | Acc: 65.085,89.739,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.810 | Acc: 64.971,89.621,99.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.802 | Acc: 64.977,89.627,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.807 | Acc: 64.907,89.628,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.807 | Acc: 64.835,89.527,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.807 | Acc: 64.810,89.519,99.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.812 | Acc: 64.664,89.481,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.810 | Acc: 64.667,89.489,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.809 | Acc: 64.707,89.463,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.811 | Acc: 64.643,89.432,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.504 | Acc: 5.469,19.531,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.182 | Acc: 5.097,14.397,54.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.150 | Acc: 5.373,14.882,53.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.254 | Acc: 5.110,14.460,53.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.987 | Acc: 60.938,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.728 | Acc: 65.811,90.960,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.768 | Acc: 65.091,90.625,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.749 | Acc: 65.266,90.587,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.759 | Acc: 65.365,90.355,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.761 | Acc: 65.486,90.331,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.769 | Acc: 65.541,90.238,99.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.774 | Acc: 65.381,90.099,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.776 | Acc: 65.276,89.936,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.786 | Acc: 65.241,89.736,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.790 | Acc: 65.190,89.599,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.795 | Acc: 65.211,89.497,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.802 | Acc: 65.174,89.364,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.806 | Acc: 65.224,89.347,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.814 | Acc: 65.072,89.218,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.819 | Acc: 64.999,89.153,99.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.817 | Acc: 64.990,89.177,99.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.821 | Acc: 64.892,89.134,99.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.822 | Acc: 64.844,89.160,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.823 | Acc: 64.784,89.167,99.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.493 | Acc: 7.031,20.312,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.278 | Acc: 5.432,15.811,55.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.269 | Acc: 5.736,16.692,54.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.374 | Acc: 5.430,16.176,54.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.641 | Acc: 62.500,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.712 | Acc: 66.667,89.955,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.768 | Acc: 65.873,89.405,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.743 | Acc: 66.457,89.511,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.737 | Acc: 66.262,89.873,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.745 | Acc: 66.236,89.851,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.765 | Acc: 65.851,89.824,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.763 | Acc: 65.752,89.811,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.767 | Acc: 65.581,89.737,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.772 | Acc: 65.483,89.723,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.783 | Acc: 65.295,89.653,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.787 | Acc: 65.169,89.632,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.792 | Acc: 65.142,89.549,99.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.791 | Acc: 65.131,89.529,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.789 | Acc: 65.208,89.463,99.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.791 | Acc: 65.238,89.400,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.790 | Acc: 65.148,89.355,99.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.791 | Acc: 65.132,89.328,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.795 | Acc: 65.028,89.307,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.796 | Acc: 64.983,89.325,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.228 | Acc: 5.469,21.094,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.079 | Acc: 4.315,15.848,51.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.060 | Acc: 4.516,16.978,51.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.160 | Acc: 4.278,16.560,51.691,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.546 | Acc: 67.969,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.734 | Acc: 66.704,90.960,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.752 | Acc: 66.235,90.130,99.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.723 | Acc: 66.739,90.433,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.745 | Acc: 66.107,90.432,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.751 | Acc: 65.842,90.292,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.758 | Acc: 65.664,90.050,99.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.760 | Acc: 65.592,90.032,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.755 | Acc: 65.698,90.057,99.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.752 | Acc: 65.681,90.077,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.751 | Acc: 65.850,90.050,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.753 | Acc: 65.834,89.999,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.755 | Acc: 65.800,89.970,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.758 | Acc: 65.580,89.865,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.759 | Acc: 65.503,89.849,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.769 | Acc: 65.373,89.781,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.768 | Acc: 65.270,89.763,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.774 | Acc: 65.158,89.693,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.772 | Acc: 65.175,89.701,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.773 | Acc: 65.213,89.610,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.190 | Acc: 5.469,13.281,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.026 | Acc: 4.055,8.259,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.022 | Acc: 4.268,8.365,60.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.147 | Acc: 4.060,8.145,60.323,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 2.050 | Acc: 63.281,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.734 | Acc: 66.964,89.695,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.722 | Acc: 67.035,90.072,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.765 | Acc: 66.099,89.690,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.767 | Acc: 65.818,89.969,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.779 | Acc: 65.640,89.821,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.769 | Acc: 65.690,89.850,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.768 | Acc: 65.608,89.849,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.762 | Acc: 65.814,89.742,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.764 | Acc: 65.660,89.779,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.770 | Acc: 65.512,89.739,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.781 | Acc: 65.459,89.610,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.784 | Acc: 65.398,89.546,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.799 | Acc: 65.203,89.452,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.800 | Acc: 65.177,89.449,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.808 | Acc: 65.028,89.343,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.804 | Acc: 65.148,89.391,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.801 | Acc: 65.100,89.399,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.799 | Acc: 65.171,89.398,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.796 | Acc: 65.196,89.364,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.453 | Acc: 6.250,19.531,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.193 | Acc: 4.427,18.378,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.189 | Acc: 4.726,18.807,63.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.301 | Acc: 4.470,18.263,62.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 1.531 | Acc: 67.188,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.783 | Acc: 66.146,89.695,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.747 | Acc: 66.082,90.091,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.736 | Acc: 66.406,90.126,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.731 | Acc: 66.319,90.220,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.737 | Acc: 66.151,90.029,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.731 | Acc: 66.213,90.128,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.736 | Acc: 66.223,89.988,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.741 | Acc: 65.931,90.023,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.742 | Acc: 65.880,89.973,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.751 | Acc: 65.800,89.968,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.748 | Acc: 65.837,89.999,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.753 | Acc: 65.735,89.944,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.757 | Acc: 65.610,89.868,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.762 | Acc: 65.517,89.741,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.761 | Acc: 65.537,89.732,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.763 | Acc: 65.496,89.705,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.762 | Acc: 65.533,89.702,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.765 | Acc: 65.443,89.677,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.768 | Acc: 65.412,89.620,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.741 | Acc: 5.469,20.312,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.393 | Acc: 4.278,17.671,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.399 | Acc: 4.440,18.140,56.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.514 | Acc: 4.175,17.687,56.404,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.724 | Acc: 61.719,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.722 | Acc: 65.923,90.476,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.768 | Acc: 65.854,90.434,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.792 | Acc: 65.484,89.959,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.806 | Acc: 65.278,89.873,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.784 | Acc: 65.463,90.107,99.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.780 | Acc: 65.619,89.824,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.772 | Acc: 65.658,89.860,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.768 | Acc: 65.596,89.824,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.772 | Acc: 65.426,89.809,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.766 | Acc: 65.501,89.898,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.773 | Acc: 65.346,89.808,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.776 | Acc: 65.262,89.815,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.773 | Acc: 65.290,89.778,99.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.775 | Acc: 65.275,89.758,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.773 | Acc: 65.295,89.748,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.771 | Acc: 65.413,89.749,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.770 | Acc: 65.368,89.775,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.773 | Acc: 65.318,89.718,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.770 | Acc: 65.375,89.733,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.238 | Acc: 7.812,24.219,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.023 | Acc: 4.985,17.932,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.053 | Acc: 5.278,17.854,55.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.138 | Acc: 5.059,17.533,55.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.477 | Acc: 75.000,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.677 | Acc: 66.815,90.848,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.718 | Acc: 66.254,90.358,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.722 | Acc: 66.586,90.190,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.730 | Acc: 66.011,90.374,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.732 | Acc: 65.679,90.548,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.750 | Acc: 65.819,90.263,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.739 | Acc: 66.035,90.337,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.738 | Acc: 65.902,90.353,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.739 | Acc: 65.906,90.375,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.742 | Acc: 65.847,90.322,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.750 | Acc: 65.766,90.215,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.763 | Acc: 65.690,89.960,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.761 | Acc: 65.718,90.014,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.767 | Acc: 65.695,89.938,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.775 | Acc: 65.542,89.849,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.774 | Acc: 65.567,89.866,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.779 | Acc: 65.478,89.860,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.777 | Acc: 65.413,89.865,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.775 | Acc: 65.457,89.868,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.579 | Acc: 4.688,17.969,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.181 | Acc: 4.167,14.621,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.176 | Acc: 4.402,15.225,56.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.278 | Acc: 4.150,14.933,56.583,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.769 | Acc: 64.062,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.803 | Acc: 65.216,89.062,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.767 | Acc: 64.901,89.463,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.747 | Acc: 65.394,90.036,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.743 | Acc: 65.451,90.249,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.746 | Acc: 65.416,90.261,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.752 | Acc: 65.238,90.134,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.748 | Acc: 65.148,90.099,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.748 | Acc: 65.266,89.926,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.752 | Acc: 65.185,89.917,99.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.748 | Acc: 65.306,89.929,99.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.752 | Acc: 65.261,89.883,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.755 | Acc: 65.336,89.857,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.755 | Acc: 65.335,89.916,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.750 | Acc: 65.328,89.902,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.746 | Acc: 65.441,89.961,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.751 | Acc: 65.382,89.878,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.755 | Acc: 65.311,89.796,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.758 | Acc: 65.242,89.772,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.758 | Acc: 65.260,89.731,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.664 | Acc: 4.688,10.156,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.607 | Acc: 5.022,8.594,57.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.587 | Acc: 5.278,8.403,57.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.710 | Acc: 4.969,8.107,57.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.613 | Acc: 61.719,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.682 | Acc: 65.997,90.588,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.719 | Acc: 66.406,89.920,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.733 | Acc: 65.932,89.767,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.740 | Acc: 65.606,90.008,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.753 | Acc: 65.323,90.037,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.750 | Acc: 65.283,90.128,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.747 | Acc: 65.254,90.276,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.751 | Acc: 65.339,90.280,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.749 | Acc: 65.426,90.249,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.753 | Acc: 65.485,90.197,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.751 | Acc: 65.477,90.162,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.750 | Acc: 65.502,90.136,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.760 | Acc: 65.293,89.990,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.761 | Acc: 65.350,89.969,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.764 | Acc: 65.295,89.880,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.764 | Acc: 65.309,89.834,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.766 | Acc: 65.302,89.812,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.773 | Acc: 65.253,89.744,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.771 | Acc: 65.324,89.760,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.974 | Acc: 7.031,21.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.717 | Acc: 5.208,19.531,58.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.722 | Acc: 5.507,20.027,58.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.819 | Acc: 5.264,19.928,58.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.918 | Acc: 56.250,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.755 | Acc: 66.109,90.551,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 66.406,90.835,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.717 | Acc: 66.355,90.523,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.703 | Acc: 66.686,90.422,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.703 | Acc: 66.515,90.633,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.705 | Acc: 66.510,90.451,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.709 | Acc: 66.351,90.392,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.717 | Acc: 66.202,90.368,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.718 | Acc: 66.238,90.284,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.716 | Acc: 66.266,90.279,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.721 | Acc: 66.123,90.226,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.734 | Acc: 65.832,90.080,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.742 | Acc: 65.763,90.023,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.749 | Acc: 65.803,89.860,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.750 | Acc: 65.718,89.836,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.753 | Acc: 65.637,89.827,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.757 | Acc: 65.577,89.809,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.762 | Acc: 65.497,89.779,99.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.766 | Acc: 65.352,89.708,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.591 | Acc: 6.250,13.281,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.596 | Acc: 4.539,9.226,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.590 | Acc: 4.821,9.623,54.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.705 | Acc: 4.611,9.503,53.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 2.258 | Acc: 52.344,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.726 | Acc: 65.625,90.699,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.710 | Acc: 66.159,90.377,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.707 | Acc: 65.932,90.561,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.714 | Acc: 65.982,90.451,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.716 | Acc: 65.826,90.656,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.743 | Acc: 65.522,90.238,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.739 | Acc: 65.625,90.248,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.744 | Acc: 65.547,90.242,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.737 | Acc: 65.767,90.327,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.738 | Acc: 65.784,90.318,99.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.746 | Acc: 65.576,90.247,99.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.745 | Acc: 65.512,90.230,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.746 | Acc: 65.580,90.131,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.754 | Acc: 65.503,90.022,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.756 | Acc: 65.461,90.044,99.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.755 | Acc: 65.528,89.975,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.760 | Acc: 65.421,89.899,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.761 | Acc: 65.359,89.904,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.758 | Acc: 65.438,89.881,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.709 | Acc: 5.469,20.312,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.617 | Acc: 4.278,12.835,58.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.592 | Acc: 4.478,13.281,58.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.727 | Acc: 4.290,12.987,58.491,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 2.216 | Acc: 57.812,87.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.751 | Acc: 65.402,90.699,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.686 | Acc: 66.825,91.159,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.707 | Acc: 66.534,90.920,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.714 | Acc: 66.155,90.750,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.708 | Acc: 66.259,90.818,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.723 | Acc: 65.890,90.567,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.723 | Acc: 66.079,90.481,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.720 | Acc: 66.071,90.431,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.730 | Acc: 65.953,90.275,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.735 | Acc: 65.862,90.197,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.731 | Acc: 65.894,90.268,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.739 | Acc: 65.826,90.165,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.743 | Acc: 65.748,90.206,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.752 | Acc: 65.578,90.141,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.754 | Acc: 65.516,90.101,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.756 | Acc: 65.435,90.060,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.755 | Acc: 65.444,90.013,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.759 | Acc: 65.398,89.909,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.763 | Acc: 65.344,89.860,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.672 | Acc: 6.250,26.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.452 | Acc: 5.060,18.378,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.393 | Acc: 5.354,19.093,54.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.530 | Acc: 5.110,18.519,53.881,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.502 | Acc: 68.750,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.712 | Acc: 67.076,90.513,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.728 | Acc: 66.502,90.701,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.752 | Acc: 66.060,90.254,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.749 | Acc: 66.107,90.172,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.753 | Acc: 65.919,89.921,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.741 | Acc: 65.851,90.128,99.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.740 | Acc: 65.946,90.193,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.733 | Acc: 66.149,90.213,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.731 | Acc: 66.126,90.180,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.741 | Acc: 65.967,90.073,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.745 | Acc: 65.894,90.017,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.743 | Acc: 65.985,89.928,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.744 | Acc: 65.951,89.943,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.742 | Acc: 65.917,89.944,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.741 | Acc: 65.830,89.893,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.743 | Acc: 65.793,89.815,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.744 | Acc: 65.827,89.770,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.750 | Acc: 65.649,89.744,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.746 | Acc: 65.736,89.760,99.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.458 | Acc: 7.031,21.875,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.241 | Acc: 5.246,18.936,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.218 | Acc: 5.469,19.436,58.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.329 | Acc: 5.264,18.878,58.107,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.634 | Acc: 64.844,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.689 | Acc: 65.662,91.667,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.671 | Acc: 66.082,91.197,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.699 | Acc: 66.035,90.958,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.708 | Acc: 66.155,90.914,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.701 | Acc: 66.244,90.710,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.702 | Acc: 66.174,90.651,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.705 | Acc: 66.234,90.614,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.712 | Acc: 66.144,90.504,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.719 | Acc: 66.147,90.340,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.717 | Acc: 66.088,90.322,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.728 | Acc: 66.007,90.148,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.733 | Acc: 65.897,90.123,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.738 | Acc: 65.709,90.098,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.736 | Acc: 65.653,90.113,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.736 | Acc: 65.700,90.077,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.736 | Acc: 65.713,90.085,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.740 | Acc: 65.666,89.961,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.742 | Acc: 65.638,89.952,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.744 | Acc: 65.594,89.934,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.226 | Acc: 5.469,21.875,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.951 | Acc: 4.018,17.039,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.936 | Acc: 4.230,17.607,52.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.061 | Acc: 3.983,17.200,52.228,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.679 | Acc: 66.406,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.698 | Acc: 64.769,91.220,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.733 | Acc: 65.263,90.892,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.705 | Acc: 66.048,90.881,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.695 | Acc: 66.020,90.770,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.700 | Acc: 66.027,90.679,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.703 | Acc: 66.264,90.586,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.708 | Acc: 66.234,90.547,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.706 | Acc: 66.193,90.601,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.704 | Acc: 66.264,90.547,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.711 | Acc: 66.103,90.365,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.711 | Acc: 66.116,90.388,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.723 | Acc: 66.037,90.262,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.719 | Acc: 66.077,90.263,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.718 | Acc: 66.187,90.250,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.723 | Acc: 66.235,90.150,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.727 | Acc: 66.143,90.099,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.736 | Acc: 66.044,90.038,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.739 | Acc: 65.926,89.978,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.742 | Acc: 65.834,89.952,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.418 | Acc: 5.469,13.281,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.236 | Acc: 4.390,8.854,61.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.229 | Acc: 4.688,8.975,60.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.354 | Acc: 4.559,8.940,60.566,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.683 | Acc: 68.750,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.707 | Acc: 67.001,90.327,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.723 | Acc: 67.378,90.587,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.717 | Acc: 67.188,90.484,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 66.744,90.355,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.715 | Acc: 66.754,90.308,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.723 | Acc: 66.432,90.334,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.727 | Acc: 66.223,90.387,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.745 | Acc: 65.926,90.295,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.747 | Acc: 65.992,90.262,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.754 | Acc: 65.854,90.151,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.755 | Acc: 65.883,90.123,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.754 | Acc: 65.842,90.142,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.751 | Acc: 65.805,90.158,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.754 | Acc: 65.758,90.002,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.752 | Acc: 65.731,89.992,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.753 | Acc: 65.666,89.963,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.757 | Acc: 65.577,89.947,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.756 | Acc: 65.616,89.937,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.756 | Acc: 65.633,89.926,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.183 | Acc: 6.250,16.406,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.845 | Acc: 4.948,15.551,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.818 | Acc: 5.278,16.254,55.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.934 | Acc: 4.956,15.868,55.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.409 | Acc: 70.312,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.700 | Acc: 66.741,90.699,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.661 | Acc: 67.130,90.796,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.676 | Acc: 66.355,90.561,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.693 | Acc: 65.905,90.625,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.706 | Acc: 65.772,90.455,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.717 | Acc: 65.793,90.515,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.724 | Acc: 65.553,90.520,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.722 | Acc: 65.625,90.479,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.713 | Acc: 65.910,90.483,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.714 | Acc: 65.889,90.524,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.719 | Acc: 65.763,90.522,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.713 | Acc: 65.930,90.576,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.714 | Acc: 66.002,90.568,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.715 | Acc: 65.995,90.442,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.722 | Acc: 65.957,90.306,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.727 | Acc: 65.924,90.277,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.725 | Acc: 65.943,90.295,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.727 | Acc: 65.919,90.313,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.729 | Acc: 65.939,90.225,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.410 | Acc: 6.250,21.875,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.163 | Acc: 5.134,18.750,52.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.142 | Acc: 5.316,19.417,52.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.264 | Acc: 5.033,19.416,52.190,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.562 | Acc: 61.719,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.647 | Acc: 66.295,91.146,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.645 | Acc: 66.997,91.216,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.678 | Acc: 66.688,90.791,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 65.943,90.394,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.741 | Acc: 65.671,90.354,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.748 | Acc: 65.386,90.270,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.734 | Acc: 65.625,90.365,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.732 | Acc: 65.674,90.353,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.727 | Acc: 65.742,90.435,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.728 | Acc: 65.823,90.349,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.734 | Acc: 65.685,90.293,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.735 | Acc: 65.537,90.291,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.740 | Acc: 65.565,90.191,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.732 | Acc: 65.619,90.239,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.732 | Acc: 65.669,90.181,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.731 | Acc: 65.700,90.197,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.730 | Acc: 65.705,90.203,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.734 | Acc: 65.612,90.168,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.731 | Acc: 65.676,90.151,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.647 | Acc: 9.375,25.781,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.439 | Acc: 7.403,20.945,62.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.410 | Acc: 7.508,21.056,62.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.510 | Acc: 7.185,20.774,62.564,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.474 | Acc: 66.406,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.646 | Acc: 68.155,91.146,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.704 | Acc: 67.016,90.816,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.702 | Acc: 66.278,90.984,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 65.924,90.693,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.723 | Acc: 66.081,90.679,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.726 | Acc: 65.922,90.631,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.733 | Acc: 65.941,90.531,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.741 | Acc: 65.805,90.436,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.740 | Acc: 65.724,90.401,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.740 | Acc: 65.734,90.376,99.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.732 | Acc: 65.735,90.342,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.727 | Acc: 65.784,90.366,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.730 | Acc: 65.805,90.329,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.732 | Acc: 65.789,90.302,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.735 | Acc: 65.641,90.293,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.740 | Acc: 65.644,90.294,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.744 | Acc: 65.641,90.222,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.748 | Acc: 65.497,90.147,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.746 | Acc: 65.541,90.112,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.332 | Acc: 4.688,23.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.083 | Acc: 3.832,19.531,59.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.062 | Acc: 4.116,19.493,59.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.201 | Acc: 3.855,19.096,58.927,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.845 | Acc: 63.281,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.675 | Acc: 67.001,91.555,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.725 | Acc: 65.816,90.854,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.724 | Acc: 65.599,90.804,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.719 | Acc: 65.741,90.712,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.714 | Acc: 65.780,90.780,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.714 | Acc: 65.980,90.715,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.733 | Acc: 65.802,90.520,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.728 | Acc: 65.916,90.567,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.731 | Acc: 65.975,90.521,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.740 | Acc: 65.955,90.400,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.748 | Acc: 65.834,90.325,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.745 | Acc: 65.836,90.265,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.740 | Acc: 65.760,90.287,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.740 | Acc: 65.586,90.339,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.736 | Acc: 65.672,90.293,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.743 | Acc: 65.593,90.250,99.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.742 | Acc: 65.517,90.181,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.744 | Acc: 65.484,90.151,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.745 | Acc: 65.525,90.110,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 15.437 | Acc: 10.938,15.625,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.050 | Acc: 7.552,13.170,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.035 | Acc: 7.698,13.700,55.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.132 | Acc: 7.313,13.204,55.546,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.837 | Acc: 64.844,86.719,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.696 | Acc: 66.034,90.923,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.689 | Acc: 66.540,90.835,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.697 | Acc: 66.445,90.804,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.710 | Acc: 66.194,90.750,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.694 | Acc: 66.569,90.780,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.693 | Acc: 66.451,90.748,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.703 | Acc: 66.273,90.581,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.708 | Acc: 66.217,90.528,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.711 | Acc: 66.195,90.422,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.705 | Acc: 66.204,90.505,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.702 | Acc: 66.300,90.501,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.703 | Acc: 66.351,90.466,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.704 | Acc: 66.295,90.418,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.710 | Acc: 66.167,90.411,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.716 | Acc: 66.144,90.324,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.719 | Acc: 66.012,90.296,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.718 | Acc: 65.994,90.307,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.717 | Acc: 65.993,90.277,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.719 | Acc: 65.969,90.272,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.623 | Acc: 3.906,12.500,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.145 | Acc: 3.423,13.058,44.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.128 | Acc: 3.773,13.891,43.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.267 | Acc: 3.484,13.525,43.737,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.805 | Acc: 73.438,89.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.743 | Acc: 66.183,90.662,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.676 | Acc: 67.130,91.311,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.688 | Acc: 66.944,91.240,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.684 | Acc: 66.696,91.136,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.675 | Acc: 66.808,91.074,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.685 | Acc: 66.884,90.870,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.694 | Acc: 66.683,90.802,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.691 | Acc: 66.639,90.868,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.689 | Acc: 66.695,90.884,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.703 | Acc: 66.247,90.819,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.710 | Acc: 66.035,90.770,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.716 | Acc: 65.936,90.622,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.716 | Acc: 65.897,90.631,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.725 | Acc: 65.742,90.517,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.726 | Acc: 65.747,90.441,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.725 | Acc: 65.805,90.418,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.725 | Acc: 65.783,90.442,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.724 | Acc: 65.776,90.443,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.728 | Acc: 65.781,90.438,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.148 | Acc: 5.469,19.531,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.874 | Acc: 4.204,20.461,55.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.866 | Acc: 4.497,20.103,54.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.999 | Acc: 4.265,19.518,54.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.642 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.638 | Acc: 67.336,92.746,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 66.997,91.730,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.692 | Acc: 66.906,91.457,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.688 | Acc: 66.898,91.184,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.694 | Acc: 66.631,91.159,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.713 | Acc: 66.368,90.877,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.720 | Acc: 66.102,90.791,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.719 | Acc: 66.178,90.693,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.721 | Acc: 66.234,90.660,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.727 | Acc: 66.029,90.578,99.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.730 | Acc: 66.003,90.466,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.737 | Acc: 65.914,90.437,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.736 | Acc: 65.775,90.448,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.733 | Acc: 65.808,90.500,99.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.728 | Acc: 65.882,90.459,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.733 | Acc: 65.764,90.406,99.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.739 | Acc: 65.696,90.343,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.738 | Acc: 65.748,90.365,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.737 | Acc: 65.779,90.344,99.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.746 | Acc: 5.469,10.156,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.431 | Acc: 4.167,7.812,46.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.406 | Acc: 4.421,8.175,45.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.517 | Acc: 4.252,7.889,45.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 2.070 | Acc: 60.938,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.707 | Acc: 65.960,91.146,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.697 | Acc: 66.197,91.273,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.691 | Acc: 66.201,91.381,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.706 | Acc: 66.339,91.127,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.699 | Acc: 66.406,91.197,99.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.698 | Acc: 66.219,91.219,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.703 | Acc: 66.046,91.157,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.701 | Acc: 66.042,91.120,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.712 | Acc: 65.906,90.906,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.713 | Acc: 65.792,90.850,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.710 | Acc: 65.880,90.851,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.713 | Acc: 65.816,90.794,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.715 | Acc: 65.805,90.715,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.724 | Acc: 65.728,90.581,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.725 | Acc: 65.672,90.480,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.725 | Acc: 65.671,90.537,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.725 | Acc: 65.641,90.536,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.730 | Acc: 65.603,90.497,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.731 | Acc: 65.588,90.475,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.775 | Acc: 4.688,21.875,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.384 | Acc: 4.055,18.155,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.382 | Acc: 4.421,18.407,61.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.510 | Acc: 4.111,18.199,61.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.588 | Acc: 61.719,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.752 | Acc: 65.179,90.179,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.709 | Acc: 66.292,90.682,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.725 | Acc: 66.035,90.433,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.710 | Acc: 66.368,90.586,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.696 | Acc: 66.399,90.834,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.717 | Acc: 66.135,90.677,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.701 | Acc: 66.307,90.880,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.698 | Acc: 66.367,90.756,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.694 | Acc: 66.177,90.742,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.696 | Acc: 66.053,90.679,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.690 | Acc: 66.138,90.720,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.694 | Acc: 66.183,90.661,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.698 | Acc: 66.227,90.583,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.707 | Acc: 66.053,90.536,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.714 | Acc: 65.911,90.495,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.718 | Acc: 65.829,90.413,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.723 | Acc: 65.769,90.405,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.723 | Acc: 65.761,90.404,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.727 | Acc: 65.736,90.385,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.387 | Acc: 6.250,13.281,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.883 | Acc: 4.092,13.318,49.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.890 | Acc: 4.402,13.567,48.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.014 | Acc: 4.150,13.217,48.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 1.374 | Acc: 73.438,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.722 | Acc: 66.295,90.960,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.675 | Acc: 66.292,91.330,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.699 | Acc: 66.163,91.317,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.681 | Acc: 66.850,91.358,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.702 | Acc: 66.623,91.112,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.700 | Acc: 66.671,90.967,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.699 | Acc: 66.534,91.035,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.696 | Acc: 66.542,91.013,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.707 | Acc: 66.234,90.793,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.703 | Acc: 66.329,90.780,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.701 | Acc: 66.350,90.731,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.702 | Acc: 66.354,90.602,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.706 | Acc: 66.242,90.619,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.704 | Acc: 66.253,90.628,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.712 | Acc: 66.183,90.568,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.710 | Acc: 66.272,90.574,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.711 | Acc: 66.168,90.513,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.715 | Acc: 66.149,90.474,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.720 | Acc: 66.043,90.387,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.290 | Acc: 7.031,7.812,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.749 | Acc: 5.692,6.920,45.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.757 | Acc: 5.831,7.069,44.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.852 | Acc: 5.597,7.031,44.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.670 | Acc: 64.844,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.613 | Acc: 66.481,92.150,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.625 | Acc: 67.283,91.673,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.627 | Acc: 67.136,91.586,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.635 | Acc: 67.101,91.281,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.656 | Acc: 66.808,91.027,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.658 | Acc: 66.561,91.116,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.663 | Acc: 66.633,91.057,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.662 | Acc: 66.639,91.096,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.669 | Acc: 66.506,91.022,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.668 | Acc: 66.492,91.002,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.677 | Acc: 66.438,90.925,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.680 | Acc: 66.461,90.875,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.685 | Acc: 66.400,90.876,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.693 | Acc: 66.340,90.764,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.696 | Acc: 66.352,90.711,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.697 | Acc: 66.379,90.717,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.698 | Acc: 66.344,90.691,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.706 | Acc: 66.246,90.653,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.711 | Acc: 66.150,90.594,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.810 | Acc: 3.906,9.375,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 23.275 | Acc: 3.237,7.329,52.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 23.267 | Acc: 3.582,7.184,51.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 23.416 | Acc: 3.253,7.006,51.831,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 1.525 | Acc: 67.969,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.744 | Acc: 66.406,89.993,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.698 | Acc: 66.559,90.339,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.699 | Acc: 66.662,90.343,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.718 | Acc: 66.281,90.451,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.718 | Acc: 66.159,90.463,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.709 | Acc: 66.232,90.470,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.708 | Acc: 66.196,90.509,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.721 | Acc: 65.974,90.392,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.723 | Acc: 65.759,90.448,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.721 | Acc: 65.664,90.485,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.716 | Acc: 65.706,90.508,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.725 | Acc: 65.531,90.414,99.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.717 | Acc: 65.670,90.511,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.712 | Acc: 65.814,90.592,99.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.714 | Acc: 65.846,90.539,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.713 | Acc: 65.839,90.528,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.710 | Acc: 65.907,90.474,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.710 | Acc: 65.926,90.450,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.714 | Acc: 65.834,90.379,99.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.033 | Acc: 3.906,17.188,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.698 | Acc: 3.051,13.504,40.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.692 | Acc: 3.239,13.834,39.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.831 | Acc: 3.010,13.448,38.973,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.513 | Acc: 65.625,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.694 | Acc: 66.815,90.737,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.684 | Acc: 66.845,90.530,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.657 | Acc: 66.867,90.996,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.658 | Acc: 66.686,90.943,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.661 | Acc: 66.793,91.097,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.675 | Acc: 66.619,91.019,99.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.686 | Acc: 66.451,90.941,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.688 | Acc: 66.382,90.877,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.686 | Acc: 66.385,90.906,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.690 | Acc: 66.348,90.917,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.691 | Acc: 66.318,90.837,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.700 | Acc: 66.137,90.807,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.698 | Acc: 66.110,90.823,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.698 | Acc: 66.173,90.750,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.700 | Acc: 66.105,90.737,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.702 | Acc: 66.097,90.679,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.705 | Acc: 66.008,90.636,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.702 | Acc: 66.097,90.651,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.702 | Acc: 66.058,90.641,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.176 | Acc: 6.250,20.312,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.894 | Acc: 5.394,18.713,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.862 | Acc: 5.621,18.693,56.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.006 | Acc: 5.418,17.982,56.493,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.513 | Acc: 67.188,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.692 | Acc: 65.848,91.518,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.681 | Acc: 66.063,91.025,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.697 | Acc: 66.547,90.996,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.698 | Acc: 66.310,90.818,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.705 | Acc: 66.213,90.880,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.703 | Acc: 66.322,90.903,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.704 | Acc: 66.174,90.836,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.708 | Acc: 65.999,90.717,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.714 | Acc: 65.897,90.754,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.710 | Acc: 65.866,90.874,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.711 | Acc: 65.819,90.763,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.708 | Acc: 65.810,90.800,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.707 | Acc: 65.912,90.730,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.707 | Acc: 65.981,90.653,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.706 | Acc: 65.965,90.604,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.709 | Acc: 65.968,90.613,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.712 | Acc: 65.909,90.618,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.717 | Acc: 65.919,90.536,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.721 | Acc: 65.902,90.488,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.331 | Acc: 3.906,19.531,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.192 | Acc: 3.609,15.885,40.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.181 | Acc: 3.849,16.216,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.322 | Acc: 3.509,15.471,40.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.851 | Acc: 68.750,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.702 | Acc: 65.923,90.625,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.699 | Acc: 65.777,90.835,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.695 | Acc: 65.817,90.881,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.700 | Acc: 65.509,90.847,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.705 | Acc: 65.455,90.873,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.704 | Acc: 65.619,90.845,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.706 | Acc: 65.752,90.680,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.713 | Acc: 65.659,90.533,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.719 | Acc: 65.513,90.392,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.716 | Acc: 65.660,90.423,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.723 | Acc: 65.657,90.339,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.723 | Acc: 65.641,90.259,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.722 | Acc: 65.676,90.266,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.720 | Acc: 65.664,90.250,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.717 | Acc: 65.827,90.210,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.720 | Acc: 65.790,90.226,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.720 | Acc: 65.788,90.222,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.726 | Acc: 65.735,90.246,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.730 | Acc: 65.680,90.211,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.151 | Acc: 7.031,19.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.970 | Acc: 5.841,14.025,50.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.985 | Acc: 6.193,14.196,50.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.105 | Acc: 5.955,13.896,50.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.716 | Acc: 66.406,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.684 | Acc: 67.634,90.402,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.694 | Acc: 67.473,90.625,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.706 | Acc: 67.059,90.548,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 66.561,90.818,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.704 | Acc: 66.244,90.780,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.716 | Acc: 66.058,90.748,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.708 | Acc: 66.179,90.736,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.711 | Acc: 66.062,90.722,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.713 | Acc: 66.113,90.746,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.712 | Acc: 66.041,90.707,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.708 | Acc: 66.145,90.770,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.705 | Acc: 66.160,90.784,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.707 | Acc: 66.113,90.694,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.708 | Acc: 66.003,90.683,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.707 | Acc: 66.118,90.685,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.707 | Acc: 66.080,90.662,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.711 | Acc: 66.037,90.547,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.711 | Acc: 66.099,90.536,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.712 | Acc: 66.097,90.457,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.788 | Acc: 5.469,14.844,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.415 | Acc: 3.981,13.021,38.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.390 | Acc: 4.249,13.034,37.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.549 | Acc: 3.970,12.423,37.052,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 1.529 | Acc: 72.656,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.637 | Acc: 67.894,91.853,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.632 | Acc: 67.664,91.654,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.652 | Acc: 67.034,91.201,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.655 | Acc: 66.753,91.339,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.653 | Acc: 66.499,91.236,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.657 | Acc: 66.464,91.245,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.667 | Acc: 66.356,91.074,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.671 | Acc: 66.164,91.086,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 66.165,91.048,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.682 | Acc: 66.107,90.971,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.685 | Acc: 66.251,90.834,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.689 | Acc: 66.290,90.768,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.695 | Acc: 66.233,90.682,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.696 | Acc: 66.167,90.703,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.698 | Acc: 66.219,90.682,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.697 | Acc: 66.260,90.696,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.699 | Acc: 66.202,90.652,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.700 | Acc: 66.270,90.575,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.703 | Acc: 66.172,90.572,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.098 | Acc: 4.688,14.062,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.801 | Acc: 4.204,14.844,35.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.771 | Acc: 4.440,15.034,34.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.900 | Acc: 4.226,14.652,34.234,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.939 | Acc: 63.281,87.500,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.637 | Acc: 66.183,91.853,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.668 | Acc: 65.873,91.311,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.640 | Acc: 66.790,91.189,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.656 | Acc: 66.358,91.184,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.673 | Acc: 66.058,91.236,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.667 | Acc: 66.096,91.284,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.680 | Acc: 65.935,91.262,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.678 | Acc: 66.236,91.246,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.679 | Acc: 66.208,91.225,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.678 | Acc: 66.192,91.169,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.679 | Acc: 66.268,91.085,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.674 | Acc: 66.413,91.076,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.676 | Acc: 66.409,91.038,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 66.398,90.986,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.681 | Acc: 66.339,90.908,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 66.348,90.902,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.688 | Acc: 66.202,90.813,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.689 | Acc: 66.203,90.811,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.695 | Acc: 66.185,90.771,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.533 | Acc: 3.906,14.844,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.197 | Acc: 4.092,10.528,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.169 | Acc: 4.306,10.652,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.292 | Acc: 4.047,10.284,55.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.688 | Acc: 68.750,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.675 | Acc: 67.894,91.146,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.667 | Acc: 67.893,91.330,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.685 | Acc: 67.597,91.227,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.699 | Acc: 66.850,90.963,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.685 | Acc: 66.909,91.058,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.686 | Acc: 66.652,91.083,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.683 | Acc: 66.744,90.963,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.680 | Acc: 66.833,91.023,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.683 | Acc: 66.730,90.953,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.684 | Acc: 66.620,90.917,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.690 | Acc: 66.569,90.805,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.693 | Acc: 66.578,90.774,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.694 | Acc: 66.544,90.778,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.695 | Acc: 66.548,90.761,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.690 | Acc: 66.492,90.776,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.694 | Acc: 66.411,90.703,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.692 | Acc: 66.344,90.707,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.695 | Acc: 66.322,90.647,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.697 | Acc: 66.320,90.623,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.501 | Acc: 6.250,18.750,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.059 | Acc: 5.878,16.555,54.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.056 | Acc: 5.945,16.578,54.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.165 | Acc: 5.776,16.457,54.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.804 | Acc: 60.156,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.616 | Acc: 67.783,92.225,99.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.635 | Acc: 66.673,91.921,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.673 | Acc: 66.483,91.406,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.679 | Acc: 66.744,91.310,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.677 | Acc: 66.576,91.190,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.678 | Acc: 66.477,91.167,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.677 | Acc: 66.584,91.113,99.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.672 | Acc: 66.673,91.139,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.676 | Acc: 66.544,91.083,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.681 | Acc: 66.519,91.021,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.678 | Acc: 66.587,90.961,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.684 | Acc: 66.481,90.995,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.685 | Acc: 66.430,90.975,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.685 | Acc: 66.398,90.973,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.689 | Acc: 66.339,90.929,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.692 | Acc: 66.321,90.881,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.695 | Acc: 66.244,90.817,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.694 | Acc: 66.246,90.818,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.695 | Acc: 66.228,90.775,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.317 | Acc: 8.594,20.312,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.803 | Acc: 7.812,16.927,43.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.774 | Acc: 7.908,16.845,43.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.873 | Acc: 7.646,16.624,43.443,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.114 | Acc: 60.156,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.697 | Acc: 66.071,91.183,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.621 | Acc: 67.721,91.730,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.633 | Acc: 67.431,91.816,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.639 | Acc: 67.583,91.483,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.637 | Acc: 67.365,91.677,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.635 | Acc: 67.129,91.813,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.628 | Acc: 66.894,92.049,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.616 | Acc: 67.066,92.183,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.616 | Acc: 67.054,92.136,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.618 | Acc: 67.020,92.203,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.611 | Acc: 67.145,92.237,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.611 | Acc: 67.213,92.239,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.614 | Acc: 67.238,92.271,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.612 | Acc: 67.251,92.285,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.612 | Acc: 67.219,92.250,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.615 | Acc: 67.175,92.209,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.615 | Acc: 67.135,92.256,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.609 | Acc: 67.285,92.320,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.605 | Acc: 67.360,92.395,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.848 | Acc: 5.469,14.844,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.281 | Acc: 4.167,12.500,38.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.276 | Acc: 4.421,12.405,37.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.397 | Acc: 4.124,12.205,37.359,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.945 | Acc: 60.156,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.642 | Acc: 65.439,93.192,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.616 | Acc: 66.559,93.026,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.628 | Acc: 66.637,93.033,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.627 | Acc: 66.782,92.612,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.616 | Acc: 67.010,92.698,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.596 | Acc: 67.355,92.936,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.596 | Acc: 67.276,92.880,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.590 | Acc: 67.323,92.886,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.591 | Acc: 67.326,92.930,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.591 | Acc: 67.370,92.930,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.589 | Acc: 67.438,92.873,99.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.587 | Acc: 67.505,92.907,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.590 | Acc: 67.418,92.957,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.589 | Acc: 67.466,92.991,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.586 | Acc: 67.494,92.982,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.579 | Acc: 67.606,93.051,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.579 | Acc: 67.655,93.049,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.577 | Acc: 67.707,93.034,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.582 | Acc: 67.594,92.995,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.711 | Acc: 6.250,12.500,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.316 | Acc: 5.432,9.598,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.301 | Acc: 5.545,10.004,53.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.418 | Acc: 5.264,9.644,53.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.261 | Acc: 73.438,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.545 | Acc: 68.452,93.527,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.564 | Acc: 67.664,93.445,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.559 | Acc: 68.263,93.353,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.541 | Acc: 68.403,93.596,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.546 | Acc: 68.131,93.433,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.545 | Acc: 68.175,93.376,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.545 | Acc: 68.063,93.340,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.541 | Acc: 68.240,93.372,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.545 | Acc: 67.986,93.530,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.551 | Acc: 67.949,93.474,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.548 | Acc: 67.884,93.520,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.544 | Acc: 67.917,93.497,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.543 | Acc: 68.014,93.528,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.542 | Acc: 68.027,93.475,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.544 | Acc: 68.065,93.459,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.544 | Acc: 68.059,93.409,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.543 | Acc: 68.067,93.480,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.542 | Acc: 68.118,93.454,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.540 | Acc: 68.168,93.494,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.312 | Acc: 6.250,17.969,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.949 | Acc: 5.506,11.235,55.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.929 | Acc: 5.659,11.319,54.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.049 | Acc: 5.353,11.002,54.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.590 | Acc: 69.531,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.528 | Acc: 68.862,93.527,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.558 | Acc: 68.407,93.750,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.590 | Acc: 67.841,93.302,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.584 | Acc: 67.641,93.258,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.576 | Acc: 67.768,93.363,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.566 | Acc: 68.001,93.421,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.568 | Acc: 67.969,93.479,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.556 | Acc: 68.119,93.546,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.550 | Acc: 68.280,93.474,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.551 | Acc: 68.319,93.470,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.552 | Acc: 68.202,93.428,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.560 | Acc: 68.098,93.371,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.557 | Acc: 68.145,93.385,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.559 | Acc: 68.122,93.377,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.557 | Acc: 68.135,93.397,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.564 | Acc: 67.993,93.400,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.564 | Acc: 67.964,93.374,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.565 | Acc: 67.971,93.404,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.562 | Acc: 67.993,93.408,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.857 | Acc: 7.031,15.625,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.442 | Acc: 5.655,10.938,51.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.422 | Acc: 5.888,11.090,50.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.535 | Acc: 5.674,10.861,50.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.580 | Acc: 68.750,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.486 | Acc: 69.085,93.862,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.514 | Acc: 68.483,93.274,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.521 | Acc: 68.494,93.199,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.524 | Acc: 68.538,93.084,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.536 | Acc: 68.425,93.170,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.540 | Acc: 68.201,93.304,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.538 | Acc: 68.080,93.406,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.547 | Acc: 67.697,93.347,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.546 | Acc: 67.610,93.396,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.544 | Acc: 67.693,93.431,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.543 | Acc: 67.757,93.428,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.545 | Acc: 67.625,93.500,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.539 | Acc: 67.735,93.543,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.544 | Acc: 67.602,93.478,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.541 | Acc: 67.681,93.493,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.539 | Acc: 67.759,93.485,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.534 | Acc: 67.831,93.523,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.531 | Acc: 67.856,93.525,99.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.531 | Acc: 67.854,93.492,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 24.885 | Acc: 3.906,5.469,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 25.429 | Acc: 3.720,4.874,45.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 25.383 | Acc: 4.040,4.992,44.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 25.537 | Acc: 3.804,4.969,44.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.819 | Acc: 65.625,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.510 | Acc: 69.085,94.829,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.482 | Acc: 68.960,95.027,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.501 | Acc: 68.340,94.544,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.513 | Acc: 68.432,94.194,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.532 | Acc: 68.178,93.998,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.530 | Acc: 68.188,94.060,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.536 | Acc: 68.141,93.933,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.536 | Acc: 68.008,94.007,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.536 | Acc: 68.163,93.931,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.541 | Acc: 68.155,93.859,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.541 | Acc: 68.163,93.874,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.544 | Acc: 68.189,93.831,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.546 | Acc: 68.068,93.864,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.550 | Acc: 68.013,93.786,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.546 | Acc: 68.010,93.849,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.540 | Acc: 68.069,93.862,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.547 | Acc: 67.962,93.794,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.541 | Acc: 68.034,93.826,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.538 | Acc: 68.032,93.846,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.001 | Acc: 6.250,21.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.651 | Acc: 5.283,17.857,53.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.629 | Acc: 5.431,18.064,52.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.746 | Acc: 5.200,17.585,52.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.659 | Acc: 64.844,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.483 | Acc: 69.382,94.457,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.491 | Acc: 69.665,94.512,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.497 | Acc: 69.262,94.070,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.512 | Acc: 68.962,94.107,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.521 | Acc: 68.588,94.199,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.521 | Acc: 68.621,94.163,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.516 | Acc: 68.783,94.160,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.525 | Acc: 68.439,94.138,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.521 | Acc: 68.500,94.104,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.520 | Acc: 68.451,94.092,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.517 | Acc: 68.591,94.050,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.522 | Acc: 68.429,94.042,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.522 | Acc: 68.409,94.037,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.521 | Acc: 68.453,94.009,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.518 | Acc: 68.496,94.041,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.519 | Acc: 68.424,94.010,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.518 | Acc: 68.416,93.986,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.519 | Acc: 68.443,93.960,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.520 | Acc: 68.391,93.943,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.030 | Acc: 5.469,19.531,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.739 | Acc: 4.464,12.277,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.708 | Acc: 4.688,12.862,55.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.831 | Acc: 4.393,12.410,56.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.228 | Acc: 72.656,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.484 | Acc: 67.634,93.713,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.513 | Acc: 67.835,94.074,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.508 | Acc: 67.994,94.057,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.477 | Acc: 68.663,94.280,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.484 | Acc: 68.711,94.222,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.471 | Acc: 68.756,94.305,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.479 | Acc: 68.733,94.215,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.474 | Acc: 69.065,94.206,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.482 | Acc: 68.819,94.242,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.493 | Acc: 68.602,94.170,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.486 | Acc: 68.761,94.181,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.486 | Acc: 68.756,94.188,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.495 | Acc: 68.555,94.118,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.500 | Acc: 68.486,94.050,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.502 | Acc: 68.449,94.030,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.506 | Acc: 68.358,94.003,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.506 | Acc: 68.441,94.007,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.506 | Acc: 68.456,94.012,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.508 | Acc: 68.408,93.978,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.549 | Acc: 6.250,17.969,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.350 | Acc: 5.394,13.988,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.317 | Acc: 5.545,13.986,60.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.441 | Acc: 5.264,13.678,59.990,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.440 | Acc: 70.312,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.498 | Acc: 68.899,93.713,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.566 | Acc: 67.035,93.369,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.545 | Acc: 67.239,93.801,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.524 | Acc: 67.949,93.895,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.524 | Acc: 67.984,93.851,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.523 | Acc: 67.736,93.866,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.517 | Acc: 67.836,93.900,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.516 | Acc: 67.940,93.900,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.522 | Acc: 67.908,93.875,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.524 | Acc: 68.035,93.909,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.524 | Acc: 68.018,93.842,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.524 | Acc: 67.953,93.896,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.523 | Acc: 67.954,93.927,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.520 | Acc: 67.935,93.870,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.520 | Acc: 67.984,93.880,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.520 | Acc: 68.034,93.860,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.519 | Acc: 68.104,93.839,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.520 | Acc: 68.081,93.847,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.519 | Acc: 68.102,93.859,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.722 | Acc: 6.250,20.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.400 | Acc: 4.650,12.872,52.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.379 | Acc: 4.764,12.862,52.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.503 | Acc: 4.521,12.513,52.126,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.263 | Acc: 71.875,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.515 | Acc: 68.229,94.085,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.517 | Acc: 68.750,94.169,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.531 | Acc: 68.571,93.929,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.526 | Acc: 68.750,93.904,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.508 | Acc: 68.704,94.114,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.499 | Acc: 68.976,94.189,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.507 | Acc: 68.733,94.166,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.505 | Acc: 68.779,94.211,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.513 | Acc: 68.720,94.130,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.519 | Acc: 68.560,94.069,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.522 | Acc: 68.439,94.068,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.518 | Acc: 68.497,94.051,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.515 | Acc: 68.540,94.037,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.516 | Acc: 68.530,94.056,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.512 | Acc: 68.555,94.046,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.513 | Acc: 68.550,94.035,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.513 | Acc: 68.615,94.020,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.516 | Acc: 68.510,94.027,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.517 | Acc: 68.529,94.025,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.319 | Acc: 6.250,21.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.022 | Acc: 5.432,14.509,49.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.003 | Acc: 5.697,14.425,48.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.123 | Acc: 5.469,14.088,47.964,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.844 | Acc: 64.062,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.490 | Acc: 69.643,93.564,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.522 | Acc: 68.998,93.712,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.514 | Acc: 68.904,93.904,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.520 | Acc: 68.586,93.904,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.527 | Acc: 68.193,93.897,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.539 | Acc: 67.898,93.853,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.542 | Acc: 67.952,93.756,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.537 | Acc: 67.949,93.842,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.530 | Acc: 68.025,93.888,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.533 | Acc: 67.868,93.948,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.530 | Acc: 67.986,93.867,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.527 | Acc: 68.037,93.860,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.525 | Acc: 68.071,93.864,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.526 | Acc: 68.005,93.881,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.522 | Acc: 68.083,93.890,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.527 | Acc: 68.093,93.830,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.530 | Acc: 68.111,93.855,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 68.051,93.850,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.530 | Acc: 68.069,93.824,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.221 | Acc: 5.469,14.062,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.894 | Acc: 5.097,9.040,51.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.876 | Acc: 5.221,9.318,50.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.006 | Acc: 4.931,9.106,50.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.955 | Acc: 69.531,89.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.529 | Acc: 67.932,93.824,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.500 | Acc: 68.788,94.531,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.504 | Acc: 68.750,94.390,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.503 | Acc: 68.702,94.338,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.498 | Acc: 68.657,94.307,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.517 | Acc: 68.388,94.137,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.525 | Acc: 68.251,94.138,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.525 | Acc: 68.498,94.119,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.523 | Acc: 68.353,94.164,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.520 | Acc: 68.497,94.119,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.513 | Acc: 68.665,94.157,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.518 | Acc: 68.491,94.129,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.521 | Acc: 68.442,94.124,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.522 | Acc: 68.389,94.120,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.521 | Acc: 68.467,94.124,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.520 | Acc: 68.497,94.147,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.517 | Acc: 68.473,94.160,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.520 | Acc: 68.406,94.098,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.523 | Acc: 68.348,94.047,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.266 | Acc: 4.688,13.281,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.900 | Acc: 4.315,10.417,50.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.861 | Acc: 4.516,10.880,49.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.987 | Acc: 4.214,10.540,48.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.364 | Acc: 68.750,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.541 | Acc: 67.522,93.080,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.554 | Acc: 67.626,93.617,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.532 | Acc: 68.148,93.904,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.528 | Acc: 67.892,93.769,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.515 | Acc: 68.162,93.781,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.519 | Acc: 68.066,93.905,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.510 | Acc: 68.318,93.988,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.506 | Acc: 68.372,94.061,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 68.379,93.992,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.511 | Acc: 68.354,94.069,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.507 | Acc: 68.421,94.079,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.515 | Acc: 68.286,94.035,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.511 | Acc: 68.355,94.058,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 68.430,94.042,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.513 | Acc: 68.368,94.038,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.508 | Acc: 68.451,94.079,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.507 | Acc: 68.452,94.073,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.516 | Acc: 68.244,94.016,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.518 | Acc: 68.235,93.996,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.011 | Acc: 7.812,19.531,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.727 | Acc: 6.362,16.071,52.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.689 | Acc: 6.421,16.044,51.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.798 | Acc: 6.160,15.638,51.524,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.765 | Acc: 66.406,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.517 | Acc: 68.006,94.308,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.502 | Acc: 67.683,94.207,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.520 | Acc: 67.508,94.608,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.536 | Acc: 67.660,94.271,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.525 | Acc: 67.992,94.322,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.526 | Acc: 67.969,94.267,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.531 | Acc: 67.991,94.249,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.531 | Acc: 67.891,94.230,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.526 | Acc: 67.908,94.212,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.531 | Acc: 67.813,94.162,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.535 | Acc: 67.827,94.185,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.538 | Acc: 67.732,94.210,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.530 | Acc: 67.924,94.193,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.529 | Acc: 68.008,94.173,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.528 | Acc: 68.073,94.134,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.526 | Acc: 67.993,94.161,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.527 | Acc: 67.939,94.139,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.525 | Acc: 67.975,94.198,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.526 | Acc: 67.868,94.189,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.942 | Acc: 6.250,17.969,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.546 | Acc: 5.506,13.170,54.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.526 | Acc: 5.640,13.186,54.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.645 | Acc: 5.379,12.884,54.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.694 | Acc: 63.281,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 67.001,94.457,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.531 | Acc: 67.416,94.169,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.515 | Acc: 67.764,94.121,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.517 | Acc: 67.785,94.300,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.507 | Acc: 68.154,94.315,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.496 | Acc: 68.395,94.428,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.512 | Acc: 68.141,94.238,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.519 | Acc: 68.076,94.133,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.520 | Acc: 68.021,94.212,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.524 | Acc: 68.058,94.123,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.522 | Acc: 68.050,94.164,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.520 | Acc: 68.060,94.133,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.521 | Acc: 68.062,94.142,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.523 | Acc: 68.122,94.156,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.522 | Acc: 68.213,94.157,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.529 | Acc: 68.051,94.115,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.530 | Acc: 68.028,94.080,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.526 | Acc: 68.077,94.114,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.525 | Acc: 67.944,94.121,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 23.747 | Acc: 3.906,18.750,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 24.357 | Acc: 3.609,14.100,49.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 24.331 | Acc: 3.868,14.101,48.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 24.482 | Acc: 3.560,13.563,47.976,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.762 | Acc: 65.625,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.580 | Acc: 66.555,94.457,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.543 | Acc: 68.045,94.341,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.545 | Acc: 67.738,94.237,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.553 | Acc: 67.795,94.107,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.534 | Acc: 68.038,94.183,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.527 | Acc: 68.304,94.196,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.516 | Acc: 68.390,94.254,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.511 | Acc: 68.498,94.211,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.512 | Acc: 68.599,94.242,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.517 | Acc: 68.424,94.185,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.518 | Acc: 68.379,94.195,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.531 | Acc: 68.173,94.081,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.532 | Acc: 68.160,94.100,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.529 | Acc: 68.213,94.125,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.525 | Acc: 68.275,94.124,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.522 | Acc: 68.312,94.139,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.525 | Acc: 68.255,94.128,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.523 | Acc: 68.324,94.131,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.526 | Acc: 68.219,94.183,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.389 | Acc: 5.469,15.625,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.034 | Acc: 5.022,11.868,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.993 | Acc: 5.221,11.928,47.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.122 | Acc: 4.931,11.693,47.605,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.151 | Acc: 71.875,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.499 | Acc: 67.746,94.643,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.491 | Acc: 68.121,94.303,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.485 | Acc: 68.417,94.288,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.481 | Acc: 68.576,94.473,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.490 | Acc: 68.464,94.508,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.498 | Acc: 68.369,94.480,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.496 | Acc: 68.423,94.459,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.497 | Acc: 68.435,94.512,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.507 | Acc: 68.262,94.423,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.502 | Acc: 68.354,94.496,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 68.248,94.453,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.515 | Acc: 68.115,94.350,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.511 | Acc: 68.106,94.391,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.513 | Acc: 68.008,94.356,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.509 | Acc: 68.135,94.391,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.508 | Acc: 68.151,94.410,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.511 | Acc: 68.205,94.357,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.514 | Acc: 68.140,94.362,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.516 | Acc: 68.086,94.332,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 24.519 | Acc: 3.906,14.062,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 25.159 | Acc: 3.274,10.045,51.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 25.130 | Acc: 3.468,10.080,50.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 25.282 | Acc: 3.176,9.990,50.717,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.496 | Acc: 68.750,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.510 | Acc: 67.857,93.527,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.467 | Acc: 68.598,94.188,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.474 | Acc: 68.840,94.173,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.478 | Acc: 68.711,94.097,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.496 | Acc: 68.510,94.152,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.498 | Acc: 68.698,94.183,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 68.501,94.260,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.501 | Acc: 68.522,94.206,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.504 | Acc: 68.400,94.216,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.498 | Acc: 68.602,94.189,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.490 | Acc: 68.736,94.287,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.494 | Acc: 68.750,94.207,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.496 | Acc: 68.720,94.157,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 68.672,94.195,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.502 | Acc: 68.620,94.103,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.503 | Acc: 68.546,94.132,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 68.544,94.094,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.500 | Acc: 68.531,94.137,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.505 | Acc: 68.514,94.092,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.984 | Acc: 6.250,18.750,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.653 | Acc: 5.097,13.318,48.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.634 | Acc: 5.335,13.262,47.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.752 | Acc: 5.020,12.999,47.157,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.243 | Acc: 73.438,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.464 | Acc: 69.159,94.792,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.498 | Acc: 68.407,94.722,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.519 | Acc: 68.058,94.672,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.499 | Acc: 68.171,94.618,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.499 | Acc: 68.294,94.384,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.499 | Acc: 68.434,94.247,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.498 | Acc: 68.595,94.304,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.515 | Acc: 68.226,94.177,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.514 | Acc: 68.064,94.216,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.517 | Acc: 68.085,94.209,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.516 | Acc: 68.057,94.273,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.507 | Acc: 68.222,94.350,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.503 | Acc: 68.340,94.406,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 68.241,94.378,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.508 | Acc: 68.304,94.355,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.516 | Acc: 68.132,94.312,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.518 | Acc: 68.125,94.302,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.514 | Acc: 68.159,94.341,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.514 | Acc: 68.188,94.347,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.946 | Acc: 4.688,17.188,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.584 | Acc: 3.795,12.500,47.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.566 | Acc: 4.116,12.443,46.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.698 | Acc: 3.791,12.090,46.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.201 | Acc: 76.562,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.419 | Acc: 70.796,95.275,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.473 | Acc: 69.722,94.646,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.498 | Acc: 69.121,94.454,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.498 | Acc: 69.068,94.252,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.495 | Acc: 68.998,94.237,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.496 | Acc: 68.892,94.299,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 68.628,94.265,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.512 | Acc: 68.372,94.235,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.512 | Acc: 68.379,94.264,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.508 | Acc: 68.447,94.267,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 68.471,94.305,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 68.591,94.327,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.500 | Acc: 68.621,94.361,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 68.633,94.381,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.498 | Acc: 68.618,94.435,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.499 | Acc: 68.582,94.412,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.497 | Acc: 68.638,94.410,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.501 | Acc: 68.586,94.401,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 68.609,94.406,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 23.005 | Acc: 3.906,7.031,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 23.519 | Acc: 3.757,5.692,51.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 23.500 | Acc: 4.116,6.098,50.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 23.635 | Acc: 3.804,5.955,50.576,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.488 | Acc: 66.406,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.453 | Acc: 69.457,95.275,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.515 | Acc: 69.017,94.607,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.513 | Acc: 69.249,94.634,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.526 | Acc: 68.451,94.676,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.533 | Acc: 68.154,94.570,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.525 | Acc: 68.285,94.576,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.515 | Acc: 68.373,94.670,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.515 | Acc: 68.396,94.575,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.522 | Acc: 68.271,94.514,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.515 | Acc: 68.466,94.523,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.514 | Acc: 68.386,94.450,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.509 | Acc: 68.513,94.447,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.510 | Acc: 68.543,94.441,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 68.553,94.442,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.504 | Acc: 68.535,94.472,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 68.533,94.434,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.505 | Acc: 68.555,94.412,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.506 | Acc: 68.503,94.345,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.503 | Acc: 68.592,94.359,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.312 | Acc: 4.688,14.844,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.986 | Acc: 4.018,10.789,50.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.958 | Acc: 4.306,10.823,49.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.093 | Acc: 3.970,10.656,49.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.775 | Acc: 61.719,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.446 | Acc: 69.234,94.382,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.484 | Acc: 69.112,94.569,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.499 | Acc: 68.891,94.429,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.492 | Acc: 69.030,94.329,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.512 | Acc: 68.464,94.315,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.527 | Acc: 68.195,94.234,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.533 | Acc: 68.107,94.204,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.530 | Acc: 68.221,94.128,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.525 | Acc: 68.154,94.169,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.520 | Acc: 68.260,94.189,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.511 | Acc: 68.439,94.270,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.509 | Acc: 68.410,94.275,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.512 | Acc: 68.250,94.256,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.506 | Acc: 68.375,94.270,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.507 | Acc: 68.345,94.259,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.510 | Acc: 68.280,94.264,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.509 | Acc: 68.228,94.286,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.508 | Acc: 68.265,94.317,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 68.332,94.271,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.080 | Acc: 6.250,18.750,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.729 | Acc: 5.134,13.765,43.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.707 | Acc: 5.335,13.624,42.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.822 | Acc: 5.059,13.307,42.149,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.326 | Acc: 74.219,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 69.903,94.308,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 68.979,94.055,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.494 | Acc: 68.827,94.006,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.516 | Acc: 67.969,94.030,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.505 | Acc: 67.976,94.206,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.517 | Acc: 67.911,94.124,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.519 | Acc: 67.952,94.177,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.514 | Acc: 67.993,94.303,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.517 | Acc: 67.913,94.350,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 67.996,94.298,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.515 | Acc: 68.015,94.270,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.508 | Acc: 68.121,94.324,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.509 | Acc: 68.112,94.331,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 68.163,94.312,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.508 | Acc: 68.231,94.259,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.510 | Acc: 68.144,94.229,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.509 | Acc: 68.122,94.270,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.509 | Acc: 68.144,94.239,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.508 | Acc: 68.166,94.224,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.333 | Acc: 4.688,18.750,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.014 | Acc: 4.129,13.914,48.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.987 | Acc: 4.497,14.158,47.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.111 | Acc: 4.239,13.922,47.439,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.234 | Acc: 75.781,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.455 | Acc: 69.754,94.792,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.442 | Acc: 70.198,94.950,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.496 | Acc: 68.648,94.557,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.503 | Acc: 68.422,94.502,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.510 | Acc: 68.448,94.400,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 68.595,94.460,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 68.656,94.371,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.508 | Acc: 68.566,94.400,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 68.664,94.337,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.509 | Acc: 68.606,94.205,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 68.665,94.224,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.502 | Acc: 68.692,94.278,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.505 | Acc: 68.618,94.307,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 68.575,94.259,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.509 | Acc: 68.545,94.225,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 68.606,94.232,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 68.716,94.254,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 68.672,94.252,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.503 | Acc: 68.647,94.246,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.852 | Acc: 6.250,25.000,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.459 | Acc: 4.278,17.634,44.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.451 | Acc: 4.592,18.026,43.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.574 | Acc: 4.290,17.738,43.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.329 | Acc: 70.312,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.490 | Acc: 69.048,94.717,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.524 | Acc: 68.483,94.455,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 68.571,94.442,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.496 | Acc: 69.030,94.637,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.502 | Acc: 68.789,94.500,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.500 | Acc: 68.698,94.460,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 68.495,94.509,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.499 | Acc: 68.570,94.439,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.498 | Acc: 68.724,94.350,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.495 | Acc: 68.668,94.465,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 68.718,94.425,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.494 | Acc: 68.789,94.405,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.494 | Acc: 68.714,94.438,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.493 | Acc: 68.708,94.470,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.496 | Acc: 68.615,94.430,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.496 | Acc: 68.592,94.407,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.495 | Acc: 68.567,94.421,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.499 | Acc: 68.529,94.401,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.505 | Acc: 68.406,94.332,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.941 | Acc: 4.688,14.062,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.657 | Acc: 4.390,11.124,52.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.632 | Acc: 4.630,11.452,51.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.773 | Acc: 4.342,11.078,51.076,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.268 | Acc: 75.000,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.471 | Acc: 69.271,95.424,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.435 | Acc: 70.503,95.484,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.446 | Acc: 70.300,95.184,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.469 | Acc: 69.975,94.956,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.475 | Acc: 69.554,95.026,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.489 | Acc: 69.234,94.848,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 69.127,94.842,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.497 | Acc: 68.934,94.648,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 68.992,94.570,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.491 | Acc: 68.999,94.555,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 68.959,94.567,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.484 | Acc: 68.883,94.580,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.483 | Acc: 68.852,94.600,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 68.875,94.595,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.484 | Acc: 68.851,94.568,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 68.840,94.568,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.486 | Acc: 68.750,94.552,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.491 | Acc: 68.746,94.507,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.494 | Acc: 68.744,94.507,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.474 | Acc: 6.250,23.438,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.268 | Acc: 5.171,19.866,62.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.257 | Acc: 5.431,20.198,62.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.373 | Acc: 5.174,19.736,63.012,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.527 | Acc: 66.406,92.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.581 | Acc: 67.336,93.452,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.527 | Acc: 68.178,93.902,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.528 | Acc: 68.148,94.249,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.527 | Acc: 68.412,94.261,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.529 | Acc: 68.572,94.191,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.523 | Acc: 68.601,94.202,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.516 | Acc: 68.700,94.210,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.504 | Acc: 69.036,94.245,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.506 | Acc: 68.888,94.229,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.500 | Acc: 69.053,94.317,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.495 | Acc: 69.096,94.347,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.498 | Acc: 68.938,94.395,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.503 | Acc: 68.867,94.420,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.502 | Acc: 68.847,94.428,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.504 | Acc: 68.820,94.376,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.503 | Acc: 68.821,94.329,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.505 | Acc: 68.771,94.337,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.511 | Acc: 68.655,94.293,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.513 | Acc: 68.578,94.279,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.243 | Acc: 3.906,16.406,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.970 | Acc: 3.757,12.091,50.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.933 | Acc: 3.906,12.100,49.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 23.081 | Acc: 3.573,11.616,49.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.289 | Acc: 71.094,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.466 | Acc: 68.936,95.238,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.440 | Acc: 69.474,94.989,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.452 | Acc: 69.224,94.634,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.445 | Acc: 69.126,94.637,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.451 | Acc: 69.168,94.763,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.465 | Acc: 69.047,94.706,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.468 | Acc: 69.110,94.659,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.477 | Acc: 68.799,94.609,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.482 | Acc: 68.707,94.510,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.482 | Acc: 68.836,94.419,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.481 | Acc: 68.771,94.404,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.483 | Acc: 68.760,94.402,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.487 | Acc: 68.570,94.462,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.489 | Acc: 68.547,94.428,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.493 | Acc: 68.496,94.396,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.495 | Acc: 68.516,94.356,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.493 | Acc: 68.535,94.378,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.494 | Acc: 68.484,94.378,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.495 | Acc: 68.453,94.343,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.858 | Acc: 5.469,21.875,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.591 | Acc: 4.799,16.443,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.580 | Acc: 5.030,16.349,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.704 | Acc: 4.777,15.779,54.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.591 | Acc: 67.188,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.514 | Acc: 67.150,95.089,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.511 | Acc: 67.511,94.779,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.509 | Acc: 67.815,94.595,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.498 | Acc: 68.113,94.551,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.505 | Acc: 68.085,94.570,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.521 | Acc: 67.975,94.499,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 68.467,94.504,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.499 | Acc: 68.444,94.580,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.495 | Acc: 68.487,94.574,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.496 | Acc: 68.552,94.551,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.500 | Acc: 68.573,94.461,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.500 | Acc: 68.607,94.376,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 68.505,94.400,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 68.461,94.389,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.506 | Acc: 68.452,94.347,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.507 | Acc: 68.426,94.339,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.507 | Acc: 68.404,94.332,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.509 | Acc: 68.283,94.347,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.510 | Acc: 68.268,94.330,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.750 | Acc: 6.250,19.531,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.376 | Acc: 4.725,12.686,45.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.357 | Acc: 4.878,12.481,44.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.489 | Acc: 4.611,12.129,44.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.239 | Acc: 76.562,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.483 | Acc: 68.229,94.345,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.503 | Acc: 68.426,94.322,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.488 | Acc: 68.724,94.454,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.493 | Acc: 68.846,94.560,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.499 | Acc: 68.781,94.524,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 68.744,94.447,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.500 | Acc: 68.756,94.404,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.509 | Acc: 68.541,94.439,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.504 | Acc: 68.642,94.518,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.497 | Acc: 68.843,94.539,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.497 | Acc: 68.853,94.595,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.492 | Acc: 68.951,94.664,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 68.945,94.669,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.490 | Acc: 68.872,94.617,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.487 | Acc: 68.888,94.578,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.488 | Acc: 68.855,94.563,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.486 | Acc: 68.904,94.545,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.486 | Acc: 68.906,94.564,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.484 | Acc: 68.859,94.572,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 24.232 | Acc: 3.906,12.500,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 24.868 | Acc: 3.237,8.557,48.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 24.843 | Acc: 3.544,8.784,47.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 24.986 | Acc: 3.253,8.594,47.195,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.698 | Acc: 65.625,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.460 | Acc: 69.420,94.680,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.428 | Acc: 69.455,94.398,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.438 | Acc: 69.288,94.570,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.480 | Acc: 68.692,94.300,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.499 | Acc: 68.340,94.160,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.488 | Acc: 68.556,94.260,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.489 | Acc: 68.517,94.260,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.495 | Acc: 68.488,94.167,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.494 | Acc: 68.474,94.147,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.497 | Acc: 68.389,94.189,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.497 | Acc: 68.315,94.270,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 68.202,94.288,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.501 | Acc: 68.292,94.322,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.501 | Acc: 68.230,94.314,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 68.213,94.350,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.501 | Acc: 68.215,94.356,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.504 | Acc: 68.150,94.364,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.501 | Acc: 68.157,94.388,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.499 | Acc: 68.217,94.361,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.847 | Acc: 3.906,21.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.513 | Acc: 3.981,15.551,51.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.490 | Acc: 4.173,15.739,50.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.623 | Acc: 3.893,15.394,50.512,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.753 | Acc: 64.062,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.501 | Acc: 68.080,95.647,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.527 | Acc: 67.988,95.046,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.532 | Acc: 67.918,94.877,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.557 | Acc: 67.593,94.657,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.549 | Acc: 67.752,94.454,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.543 | Acc: 67.949,94.389,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.548 | Acc: 67.919,94.326,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.538 | Acc: 67.954,94.381,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.536 | Acc: 68.051,94.432,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.533 | Acc: 68.054,94.372,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.531 | Acc: 68.170,94.365,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.528 | Acc: 68.141,94.405,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.520 | Acc: 68.247,94.438,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.520 | Acc: 68.202,94.378,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.518 | Acc: 68.285,94.386,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.515 | Acc: 68.339,94.405,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.514 | Acc: 68.367,94.408,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.516 | Acc: 68.309,94.408,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.517 | Acc: 68.256,94.414,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.036 | Acc: 5.469,10.938,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.663 | Acc: 4.948,8.371,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.633 | Acc: 5.126,8.479,53.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.772 | Acc: 4.816,8.350,53.356,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.447 | Acc: 67.188,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.482 | Acc: 68.638,94.457,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 68.617,94.360,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.475 | Acc: 68.673,94.557,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.469 | Acc: 68.779,94.454,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.467 | Acc: 69.036,94.524,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.470 | Acc: 68.924,94.525,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.474 | Acc: 68.889,94.470,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 68.706,94.391,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 68.698,94.389,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.489 | Acc: 68.684,94.380,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.491 | Acc: 68.584,94.390,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.490 | Acc: 68.669,94.398,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.490 | Acc: 68.606,94.355,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 68.703,94.364,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.489 | Acc: 68.693,94.357,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.491 | Acc: 68.636,94.383,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.495 | Acc: 68.599,94.378,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.495 | Acc: 68.605,94.352,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.493 | Acc: 68.555,94.398,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.194 | Acc: 5.469,13.281,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.854 | Acc: 4.762,9.152,50.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.815 | Acc: 5.011,9.204,49.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.957 | Acc: 4.662,8.991,49.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.291 | Acc: 78.125,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.504 | Acc: 67.448,94.531,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.513 | Acc: 67.778,93.979,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.512 | Acc: 67.892,94.121,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.518 | Acc: 67.949,94.242,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.519 | Acc: 67.830,94.299,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 67.949,94.473,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.506 | Acc: 68.041,94.487,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.505 | Acc: 68.168,94.507,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 68.176,94.557,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.505 | Acc: 68.256,94.481,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.505 | Acc: 68.149,94.439,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.498 | Acc: 68.261,94.505,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.498 | Acc: 68.295,94.453,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.504 | Acc: 68.255,94.442,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.508 | Acc: 68.171,94.383,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.503 | Acc: 68.373,94.385,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.505 | Acc: 68.322,94.387,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.513 | Acc: 68.252,94.326,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.510 | Acc: 68.377,94.300,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 24.126 | Acc: 3.906,8.594,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 24.724 | Acc: 3.832,6.362,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 24.692 | Acc: 4.173,6.993,55.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 24.849 | Acc: 3.906,6.865,55.994,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.231 | Acc: 75.781,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.438 | Acc: 69.531,94.643,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.479 | Acc: 69.264,94.436,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.476 | Acc: 69.237,94.390,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.470 | Acc: 69.194,94.396,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.468 | Acc: 69.021,94.361,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.474 | Acc: 69.105,94.325,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 68.900,94.243,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.494 | Acc: 68.930,94.269,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.490 | Acc: 68.897,94.277,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.500 | Acc: 68.711,94.236,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.502 | Acc: 68.711,94.270,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.506 | Acc: 68.620,94.285,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.501 | Acc: 68.753,94.292,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.501 | Acc: 68.669,94.342,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 68.779,94.287,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.501 | Acc: 68.731,94.305,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 68.674,94.334,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.506 | Acc: 68.609,94.311,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.506 | Acc: 68.555,94.336,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 14.971 | Acc: 13.281,26.562,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 15.524 | Acc: 8.854,21.317,45.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 15.510 | Acc: 8.937,22.161,45.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 15.605 | Acc: 8.658,21.785,44.864,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 1.600 | Acc: 71.094,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.476 | Acc: 68.750,94.159,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.450 | Acc: 69.226,94.455,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.471 | Acc: 68.814,94.634,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.472 | Acc: 69.030,94.579,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.475 | Acc: 69.400,94.570,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 69.053,94.576,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.498 | Acc: 68.805,94.548,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.500 | Acc: 68.668,94.497,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.485 | Acc: 69.113,94.544,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.483 | Acc: 69.158,94.562,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.488 | Acc: 69.047,94.510,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.496 | Acc: 68.919,94.457,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.490 | Acc: 68.936,94.465,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 68.800,94.339,99.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.507 | Acc: 68.654,94.381,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.509 | Acc: 68.648,94.341,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.511 | Acc: 68.576,94.323,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.510 | Acc: 68.594,94.311,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.512 | Acc: 68.508,94.304,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.990 | Acc: 6.250,14.844,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.600 | Acc: 4.799,12.537,50.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.573 | Acc: 5.011,12.633,50.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.703 | Acc: 4.675,12.308,49.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.344 | Acc: 69.531,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.455 | Acc: 69.606,95.015,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.471 | Acc: 69.226,95.103,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.460 | Acc: 69.416,95.044,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.466 | Acc: 69.387,94.859,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.468 | Acc: 69.338,94.748,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.466 | Acc: 69.002,94.777,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.469 | Acc: 68.750,94.731,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.472 | Acc: 68.745,94.788,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.472 | Acc: 68.763,94.786,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.470 | Acc: 68.769,94.733,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.475 | Acc: 68.750,94.715,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.477 | Acc: 68.776,94.654,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.476 | Acc: 68.747,94.711,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.482 | Acc: 68.611,94.698,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.483 | Acc: 68.644,94.666,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 68.648,94.575,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 68.670,94.602,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.483 | Acc: 68.603,94.564,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.486 | Acc: 68.524,94.507,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.792 | Acc: 3.906,16.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 23.337 | Acc: 3.906,12.426,47.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 23.314 | Acc: 4.116,12.671,46.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 23.450 | Acc: 3.881,12.359,46.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.233 | Acc: 71.094,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.420 | Acc: 69.866,95.424,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.461 | Acc: 68.750,95.103,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.443 | Acc: 68.776,95.274,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.466 | Acc: 68.519,95.245,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.462 | Acc: 68.580,94.995,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.468 | Acc: 68.337,94.828,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 68.395,94.842,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.465 | Acc: 68.600,94.866,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.463 | Acc: 68.621,94.877,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.470 | Acc: 68.579,94.834,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.472 | Acc: 68.538,94.772,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.480 | Acc: 68.286,94.735,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.479 | Acc: 68.328,94.720,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.479 | Acc: 68.439,94.748,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.482 | Acc: 68.431,94.731,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.485 | Acc: 68.456,94.702,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.484 | Acc: 68.512,94.698,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.483 | Acc: 68.557,94.767,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 68.533,94.794,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.334 | Acc: 5.469,18.750,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.028 | Acc: 5.060,17.671,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.002 | Acc: 5.240,18.255,54.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.131 | Acc: 4.931,17.841,54.316,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.757 | Acc: 62.500,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 67.485,94.048,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.472 | Acc: 68.407,94.588,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.455 | Acc: 69.160,94.647,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.463 | Acc: 68.856,94.637,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.458 | Acc: 68.827,94.817,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.461 | Acc: 68.995,94.757,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 68.800,94.637,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.484 | Acc: 68.609,94.662,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.488 | Acc: 68.513,94.743,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.486 | Acc: 68.556,94.729,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.490 | Acc: 68.404,94.662,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.494 | Acc: 68.244,94.674,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.491 | Acc: 68.277,94.732,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 68.286,94.779,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.481 | Acc: 68.444,94.734,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.485 | Acc: 68.402,94.687,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 68.459,94.715,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.484 | Acc: 68.428,94.735,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 68.479,94.734,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.018 | Acc: 4.688,13.281,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.648 | Acc: 4.241,9.412,48.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.629 | Acc: 4.478,9.794,47.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.773 | Acc: 4.226,9.567,47.093,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.524 | Acc: 71.875,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.542 | Acc: 68.527,93.936,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.470 | Acc: 69.245,94.341,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.508 | Acc: 68.353,94.249,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.496 | Acc: 68.200,94.406,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.503 | Acc: 68.015,94.431,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.495 | Acc: 68.150,94.454,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.500 | Acc: 68.118,94.476,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 68.318,94.512,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.493 | Acc: 68.331,94.579,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.492 | Acc: 68.462,94.570,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.485 | Acc: 68.591,94.605,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.486 | Acc: 68.543,94.632,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.485 | Acc: 68.490,94.621,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 68.475,94.617,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.487 | Acc: 68.496,94.594,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.482 | Acc: 68.638,94.638,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.484 | Acc: 68.651,94.605,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.481 | Acc: 68.653,94.631,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.483 | Acc: 68.682,94.634,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.927 | Acc: 6.250,29.688,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.541 | Acc: 5.469,26.116,51.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.528 | Acc: 5.678,26.639,50.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.639 | Acc: 5.456,26.306,50.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.646 | Acc: 64.062,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.526 | Acc: 67.299,94.122,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 68.388,94.436,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.481 | Acc: 68.852,94.634,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.488 | Acc: 68.846,94.608,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 68.998,94.817,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.489 | Acc: 68.989,94.693,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.484 | Acc: 69.044,94.709,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.481 | Acc: 69.158,94.720,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.479 | Acc: 69.246,94.695,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.480 | Acc: 69.189,94.768,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.481 | Acc: 69.125,94.726,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.489 | Acc: 68.987,94.697,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.491 | Acc: 68.933,94.717,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 69.020,94.756,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.484 | Acc: 69.030,94.754,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.487 | Acc: 68.925,94.733,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.489 | Acc: 68.887,94.703,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.489 | Acc: 68.834,94.722,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 68.853,94.726,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.952 | Acc: 3.906,9.375,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 23.580 | Acc: 4.055,7.775,42.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 23.550 | Acc: 4.364,8.308,41.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 23.689 | Acc: 4.009,8.043,41.227,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.266 | Acc: 71.094,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.421 | Acc: 70.685,94.978,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.447 | Acc: 69.912,94.836,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.444 | Acc: 69.915,94.954,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.446 | Acc: 69.618,94.936,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.434 | Acc: 69.910,95.065,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.446 | Acc: 69.673,94.886,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.443 | Acc: 69.703,94.947,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.445 | Acc: 69.609,95.007,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.453 | Acc: 69.423,94.902,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.453 | Acc: 69.504,94.866,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.456 | Acc: 69.436,94.881,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.462 | Acc: 69.285,94.849,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.462 | Acc: 69.325,94.792,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.459 | Acc: 69.334,94.779,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.463 | Acc: 69.202,94.760,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.462 | Acc: 69.183,94.755,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.462 | Acc: 69.080,94.731,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.464 | Acc: 69.044,94.724,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.467 | Acc: 68.998,94.683,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 16.180 | Acc: 11.719,21.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 16.775 | Acc: 7.738,15.960,46.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 16.757 | Acc: 7.889,16.159,45.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 16.852 | Acc: 7.620,15.740,45.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.793 | Acc: 67.188,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.548 | Acc: 67.150,94.494,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.543 | Acc: 67.835,94.245,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.527 | Acc: 68.097,94.480,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.509 | Acc: 67.988,94.637,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.503 | Acc: 68.147,94.686,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.500 | Acc: 68.156,94.809,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.493 | Acc: 68.240,94.842,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.495 | Acc: 68.231,94.866,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.494 | Acc: 68.353,94.898,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.495 | Acc: 68.330,94.846,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 68.365,94.825,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.492 | Acc: 68.413,94.907,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.491 | Acc: 68.409,94.914,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.493 | Acc: 68.389,94.859,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.496 | Acc: 68.358,94.850,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.499 | Acc: 68.309,94.818,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.496 | Acc: 68.393,94.783,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.496 | Acc: 68.428,94.752,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.492 | Acc: 68.463,94.820,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.548 | Acc: 5.469,17.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.109 | Acc: 4.464,11.607,46.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.093 | Acc: 4.516,11.890,45.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.225 | Acc: 4.355,11.578,45.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.765 | Acc: 63.281,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.572 | Acc: 67.188,93.750,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.550 | Acc: 67.321,94.150,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.540 | Acc: 67.482,94.467,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.533 | Acc: 67.699,94.425,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.520 | Acc: 68.178,94.330,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.515 | Acc: 68.214,94.389,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 68.340,94.581,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.504 | Acc: 68.250,94.580,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 68.215,94.492,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.499 | Acc: 68.354,94.601,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 68.315,94.591,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.499 | Acc: 68.325,94.557,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.490 | Acc: 68.454,94.651,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.496 | Acc: 68.380,94.620,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.491 | Acc: 68.532,94.583,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.487 | Acc: 68.679,94.568,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.485 | Acc: 68.732,94.607,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.485 | Acc: 68.687,94.607,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.485 | Acc: 68.721,94.603,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 23.515 | Acc: 3.906,13.281,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 24.240 | Acc: 3.423,9.710,51.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 24.203 | Acc: 3.697,9.928,51.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 24.352 | Acc: 3.420,9.823,51.127,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 1.384 | Acc: 68.750,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.480 | Acc: 69.457,95.052,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.450 | Acc: 69.112,95.065,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.465 | Acc: 69.109,94.647,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.465 | Acc: 69.223,94.647,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.469 | Acc: 69.175,94.516,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.474 | Acc: 68.989,94.635,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.474 | Acc: 69.005,94.725,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.468 | Acc: 68.857,94.798,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.468 | Acc: 68.785,94.825,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.468 | Acc: 68.828,94.877,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.471 | Acc: 68.796,94.895,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.474 | Acc: 68.669,94.846,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.473 | Acc: 68.705,94.786,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.473 | Acc: 68.686,94.823,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.472 | Acc: 68.672,94.819,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.471 | Acc: 68.689,94.835,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.472 | Acc: 68.741,94.843,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.469 | Acc: 68.765,94.834,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.469 | Acc: 68.723,94.800,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.860 | Acc: 5.469,19.531,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.488 | Acc: 4.613,14.807,54.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.477 | Acc: 4.916,14.863,53.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.609 | Acc: 4.611,14.370,53.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.635 | Acc: 70.312,88.281,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.545 | Acc: 67.969,94.048,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 68.350,94.646,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.479 | Acc: 68.814,94.787,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.477 | Acc: 69.068,94.975,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.480 | Acc: 68.812,94.841,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.468 | Acc: 68.853,94.925,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.469 | Acc: 68.949,94.925,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.477 | Acc: 68.871,94.793,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.474 | Acc: 68.918,94.842,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.477 | Acc: 68.867,94.807,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.478 | Acc: 68.831,94.800,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.479 | Acc: 68.789,94.768,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.480 | Acc: 68.828,94.807,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.475 | Acc: 68.920,94.795,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 68.872,94.741,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.479 | Acc: 68.791,94.745,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.480 | Acc: 68.752,94.749,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.478 | Acc: 68.759,94.761,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.477 | Acc: 68.809,94.757,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.850 | Acc: 7.031,21.094,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.427 | Acc: 5.915,17.336,44.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.408 | Acc: 6.136,17.778,43.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.519 | Acc: 5.917,17.674,43.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.772 | Acc: 66.406,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.450 | Acc: 69.494,95.089,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.475 | Acc: 68.655,94.722,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.479 | Acc: 68.648,94.775,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.488 | Acc: 69.020,94.618,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.479 | Acc: 69.307,94.616,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.485 | Acc: 69.124,94.609,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.484 | Acc: 69.121,94.559,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.483 | Acc: 68.920,94.594,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.478 | Acc: 69.026,94.730,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.474 | Acc: 69.053,94.671,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.478 | Acc: 69.019,94.605,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.480 | Acc: 68.996,94.619,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.491 | Acc: 68.714,94.585,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.491 | Acc: 68.692,94.581,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.490 | Acc: 68.724,94.599,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.490 | Acc: 68.682,94.616,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.488 | Acc: 68.755,94.623,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.485 | Acc: 68.837,94.618,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.483 | Acc: 68.797,94.662,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.038 | Acc: 3.906,14.062,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.598 | Acc: 3.981,10.156,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.572 | Acc: 4.211,10.423,52.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.711 | Acc: 3.893,10.105,51.870,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.588 | Acc: 63.281,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.368 | Acc: 70.499,95.387,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.432 | Acc: 69.912,94.741,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.443 | Acc: 69.544,94.723,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.452 | Acc: 69.223,94.743,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.454 | Acc: 69.222,94.787,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.462 | Acc: 69.157,94.893,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.471 | Acc: 68.972,94.842,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.467 | Acc: 69.002,94.847,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.464 | Acc: 69.087,94.846,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.461 | Acc: 69.146,94.862,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.468 | Acc: 68.881,94.842,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.463 | Acc: 68.948,94.862,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.469 | Acc: 68.897,94.801,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.466 | Acc: 68.908,94.779,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.464 | Acc: 69.010,94.801,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.464 | Acc: 68.984,94.782,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.464 | Acc: 68.924,94.811,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.460 | Acc: 69.051,94.823,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.466 | Acc: 68.939,94.759,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.490 | Acc: 5.469,15.625,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.056 | Acc: 4.799,11.421,52.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.024 | Acc: 4.916,11.490,51.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.158 | Acc: 4.636,11.181,51.639,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.635 | Acc: 63.281,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.523 | Acc: 67.746,94.122,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.547 | Acc: 67.740,94.055,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.522 | Acc: 68.122,94.390,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.507 | Acc: 68.152,94.599,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.493 | Acc: 68.688,94.554,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.485 | Acc: 68.847,94.589,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.483 | Acc: 68.889,94.631,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.473 | Acc: 68.968,94.813,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.483 | Acc: 68.728,94.751,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.487 | Acc: 68.563,94.761,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.480 | Acc: 68.644,94.786,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.482 | Acc: 68.617,94.810,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.482 | Acc: 68.573,94.816,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.483 | Acc: 68.519,94.793,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.481 | Acc: 68.594,94.770,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.480 | Acc: 68.565,94.779,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.478 | Acc: 68.647,94.806,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.478 | Acc: 68.642,94.823,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.478 | Acc: 68.600,94.775,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.942 | Acc: 3.906,17.969,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 23.521 | Acc: 4.055,12.054,54.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 23.473 | Acc: 4.249,12.367,54.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 23.616 | Acc: 4.022,11.847,54.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.577 | Acc: 67.188,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.512 | Acc: 68.824,94.643,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.504 | Acc: 68.426,95.065,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.475 | Acc: 68.404,95.159,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.457 | Acc: 68.538,95.274,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.470 | Acc: 68.379,95.104,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.472 | Acc: 68.401,95.061,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.476 | Acc: 68.434,95.002,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.493 | Acc: 68.168,94.808,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.501 | Acc: 68.236,94.743,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.494 | Acc: 68.408,94.784,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.493 | Acc: 68.499,94.765,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.492 | Acc: 68.474,94.791,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 68.412,94.756,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 68.478,94.695,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.493 | Acc: 68.459,94.648,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.494 | Acc: 68.429,94.651,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.489 | Acc: 68.587,94.701,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.489 | Acc: 68.624,94.702,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.491 | Acc: 68.551,94.710,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.262 | Acc: 5.469,15.625,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.832 | Acc: 4.688,10.528,47.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.803 | Acc: 4.935,10.747,46.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.941 | Acc: 4.675,10.438,45.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.526 | Acc: 68.750,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.477 | Acc: 67.634,94.754,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.465 | Acc: 67.893,95.008,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.482 | Acc: 67.802,94.980,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.490 | Acc: 67.853,94.888,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.491 | Acc: 67.899,94.848,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.490 | Acc: 68.001,94.809,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.480 | Acc: 68.329,94.814,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.474 | Acc: 68.439,94.852,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.469 | Acc: 68.543,94.920,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.477 | Acc: 68.579,94.897,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.479 | Acc: 68.563,94.768,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.483 | Acc: 68.471,94.732,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.481 | Acc: 68.523,94.711,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.474 | Acc: 68.683,94.743,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 68.695,94.716,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.477 | Acc: 68.689,94.719,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.479 | Acc: 68.674,94.671,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.474 | Acc: 68.728,94.694,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.474 | Acc: 68.617,94.722,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.811 | Acc: 5.469,19.531,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.505 | Acc: 4.018,16.629,48.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.483 | Acc: 4.364,17.188,47.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.620 | Acc: 4.047,16.739,47.426,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.223 | Acc: 72.656,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 69.568,94.568,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.478 | Acc: 68.921,94.741,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.480 | Acc: 68.865,95.005,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.487 | Acc: 68.981,94.898,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.490 | Acc: 68.564,94.895,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.485 | Acc: 68.815,94.957,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.485 | Acc: 68.833,94.925,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.481 | Acc: 68.857,94.876,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.490 | Acc: 68.551,94.885,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.482 | Acc: 68.878,94.920,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.483 | Acc: 68.888,94.934,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.486 | Acc: 68.815,94.852,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 68.885,94.825,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 68.922,94.832,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.490 | Acc: 68.747,94.783,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.494 | Acc: 68.665,94.787,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.496 | Acc: 68.567,94.770,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.490 | Acc: 68.679,94.776,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.491 | Acc: 68.604,94.792,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.230 | Acc: 6.250,22.656,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.794 | Acc: 5.655,16.741,41.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.781 | Acc: 6.002,17.340,40.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.888 | Acc: 5.725,17.085,40.663,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.625 | Acc: 62.500,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.462 | Acc: 68.043,95.275,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 68.121,94.607,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 68.340,94.839,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.490 | Acc: 68.364,94.946,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.492 | Acc: 68.386,94.918,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 68.453,94.809,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.485 | Acc: 68.373,94.819,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 68.439,94.822,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 68.448,94.790,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.481 | Acc: 68.501,94.831,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.483 | Acc: 68.478,94.779,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 68.367,94.748,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 68.427,94.729,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.481 | Acc: 68.547,94.745,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.483 | Acc: 68.529,94.786,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.483 | Acc: 68.560,94.787,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.481 | Acc: 68.617,94.804,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.481 | Acc: 68.560,94.810,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 68.551,94.827,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.604 | Acc: 4.688,19.531,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.213 | Acc: 4.204,15.030,51.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.189 | Acc: 4.459,15.168,49.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.325 | Acc: 4.098,14.716,50.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.339 | Acc: 74.219,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.541 | Acc: 67.225,95.015,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.501 | Acc: 67.721,94.893,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 67.687,94.851,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.471 | Acc: 68.113,94.936,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.473 | Acc: 68.170,94.864,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 68.033,94.822,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.483 | Acc: 68.196,94.803,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.481 | Acc: 68.129,94.784,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.480 | Acc: 68.172,94.777,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.473 | Acc: 68.190,94.796,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.479 | Acc: 68.209,94.789,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.480 | Acc: 68.212,94.787,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.481 | Acc: 68.328,94.753,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.476 | Acc: 68.422,94.806,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.472 | Acc: 68.576,94.788,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.471 | Acc: 68.597,94.799,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.473 | Acc: 68.592,94.788,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.474 | Acc: 68.601,94.748,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.469 | Acc: 68.691,94.761,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 23.616 | Acc: 3.906,8.594,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 24.171 | Acc: 3.757,8.110,44.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 24.136 | Acc: 3.963,8.613,43.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 24.280 | Acc: 3.714,8.466,42.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.944 | Acc: 60.156,87.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.490 | Acc: 68.787,94.531,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.506 | Acc: 69.169,94.264,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.517 | Acc: 68.916,94.249,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.508 | Acc: 68.885,94.416,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.493 | Acc: 68.982,94.562,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 69.176,94.602,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.477 | Acc: 69.282,94.770,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.472 | Acc: 69.158,94.852,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.471 | Acc: 69.290,94.881,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.480 | Acc: 69.178,94.846,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.479 | Acc: 69.096,94.803,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.478 | Acc: 69.149,94.859,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.477 | Acc: 69.172,94.843,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.474 | Acc: 69.184,94.882,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 68.999,94.882,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.480 | Acc: 68.920,94.845,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.479 | Acc: 68.991,94.847,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.479 | Acc: 68.949,94.858,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.482 | Acc: 68.885,94.837,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 24.325 | Acc: 3.906,8.594,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 24.888 | Acc: 3.125,7.812,51.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 24.865 | Acc: 3.392,8.213,50.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 25.014 | Acc: 3.176,8.069,50.410,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.360 | Acc: 71.875,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.512 | Acc: 69.606,95.015,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.559 | Acc: 68.426,94.607,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.525 | Acc: 68.635,94.826,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.509 | Acc: 68.827,95.052,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.492 | Acc: 69.191,95.073,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.478 | Acc: 69.415,95.190,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 69.271,94.969,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.472 | Acc: 69.167,95.016,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.470 | Acc: 69.290,94.928,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.468 | Acc: 69.345,94.939,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.470 | Acc: 69.270,94.906,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.465 | Acc: 69.282,94.904,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.464 | Acc: 69.349,94.932,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.462 | Acc: 69.359,94.909,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.470 | Acc: 69.145,94.850,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.472 | Acc: 69.113,94.838,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.475 | Acc: 69.043,94.861,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.474 | Acc: 69.053,94.916,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.475 | Acc: 69.008,94.861,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.478 | Acc: 4.688,14.062,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.014 | Acc: 4.427,10.119,50.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.979 | Acc: 4.707,10.499,49.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.107 | Acc: 4.521,10.118,49.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.669 | Acc: 59.375,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.511 | Acc: 67.634,95.015,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.520 | Acc: 67.473,94.741,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.507 | Acc: 67.789,94.877,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.508 | Acc: 67.959,94.878,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.503 | Acc: 67.891,94.810,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 67.885,94.873,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.494 | Acc: 67.919,94.858,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 68.114,94.852,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.483 | Acc: 68.392,94.885,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.478 | Acc: 68.587,94.831,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.475 | Acc: 68.655,94.842,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.473 | Acc: 68.766,94.868,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.475 | Acc: 68.798,94.878,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.476 | Acc: 68.706,94.837,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.474 | Acc: 68.745,94.812,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.475 | Acc: 68.750,94.777,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.475 | Acc: 68.787,94.765,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.475 | Acc: 68.789,94.774,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.479 | Acc: 68.701,94.763,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.254 | Acc: 5.469,17.969,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.862 | Acc: 5.097,11.942,44.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.821 | Acc: 5.297,12.176,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.951 | Acc: 4.956,11.872,43.417,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 1.706 | Acc: 66.406,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.450 | Acc: 68.824,94.717,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.471 | Acc: 69.150,94.836,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.472 | Acc: 69.147,94.685,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.479 | Acc: 68.914,94.743,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.477 | Acc: 68.920,94.887,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.461 | Acc: 69.260,94.880,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.471 | Acc: 68.889,94.786,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.477 | Acc: 68.648,94.788,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.473 | Acc: 68.797,94.885,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.475 | Acc: 68.707,94.869,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.475 | Acc: 68.736,94.825,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.483 | Acc: 68.640,94.794,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.485 | Acc: 68.591,94.768,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 68.642,94.720,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.482 | Acc: 68.672,94.806,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.482 | Acc: 68.694,94.828,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.481 | Acc: 68.764,94.836,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.483 | Acc: 68.754,94.834,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.480 | Acc: 68.848,94.859,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.438 | Acc: 5.469,11.719,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.052 | Acc: 4.501,9.412,54.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.019 | Acc: 4.764,10.042,54.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.153 | Acc: 4.470,9.631,54.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.310 | Acc: 72.656,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.452 | Acc: 68.415,95.424,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.466 | Acc: 68.197,94.950,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.463 | Acc: 68.545,94.967,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.480 | Acc: 68.547,94.907,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.472 | Acc: 68.688,94.817,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.468 | Acc: 68.614,94.912,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.472 | Acc: 68.556,94.803,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.479 | Acc: 68.464,94.832,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.488 | Acc: 68.284,94.799,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.485 | Acc: 68.501,94.788,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.483 | Acc: 68.584,94.750,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.487 | Acc: 68.513,94.716,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.484 | Acc: 68.597,94.708,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.480 | Acc: 68.717,94.712,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.482 | Acc: 68.711,94.695,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.483 | Acc: 68.636,94.750,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 68.642,94.758,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.484 | Acc: 68.579,94.743,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.483 | Acc: 68.592,94.708,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.428 | Acc: 5.469,19.531,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.065 | Acc: 4.278,14.769,51.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.037 | Acc: 4.459,14.672,49.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.177 | Acc: 4.150,14.293,50.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.602 | Acc: 64.062,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.529 | Acc: 69.048,94.531,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 68.731,94.684,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.486 | Acc: 69.403,94.531,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.463 | Acc: 69.589,94.859,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.472 | Acc: 69.098,94.841,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 68.750,94.777,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.494 | Acc: 68.650,94.697,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 68.634,94.720,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 68.828,94.661,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.492 | Acc: 68.696,94.617,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 68.619,94.655,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.489 | Acc: 68.662,94.629,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.491 | Acc: 68.600,94.660,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.493 | Acc: 68.594,94.665,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.488 | Acc: 68.708,94.721,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.489 | Acc: 68.655,94.765,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.488 | Acc: 68.619,94.779,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.489 | Acc: 68.646,94.780,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.489 | Acc: 68.588,94.804,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 21.743 | Acc: 6.250,15.625,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.414 | Acc: 4.688,10.305,50.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.370 | Acc: 4.859,10.747,48.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.503 | Acc: 4.688,10.310,48.847,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.494 | Acc: 68.750,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.493 | Acc: 68.936,94.531,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.479 | Acc: 68.712,94.703,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.465 | Acc: 68.904,94.954,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.469 | Acc: 68.837,94.753,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.465 | Acc: 69.121,94.678,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.467 | Acc: 68.918,94.783,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.462 | Acc: 68.949,94.797,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.458 | Acc: 68.881,94.764,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.467 | Acc: 68.884,94.829,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.462 | Acc: 68.917,94.827,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.463 | Acc: 68.807,94.867,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.458 | Acc: 68.932,94.933,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.460 | Acc: 68.870,94.935,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.463 | Acc: 68.864,94.868,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.463 | Acc: 68.888,94.838,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.464 | Acc: 68.906,94.809,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.461 | Acc: 68.908,94.861,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.463 | Acc: 68.901,94.847,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.462 | Acc: 68.941,94.857,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.143 | Acc: 6.250,15.625,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.777 | Acc: 4.725,10.119,52.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.744 | Acc: 4.859,10.232,51.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 22.880 | Acc: 4.534,9.926,51.409,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.100 | Acc: 74.219,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.444 | Acc: 68.787,95.052,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.450 | Acc: 69.341,94.531,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.466 | Acc: 68.814,94.659,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.458 | Acc: 69.252,94.715,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.453 | Acc: 69.206,94.918,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.473 | Acc: 68.789,94.790,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 68.739,94.797,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.475 | Acc: 68.716,94.784,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.468 | Acc: 68.793,94.786,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.469 | Acc: 68.696,94.819,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.470 | Acc: 68.633,94.849,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.471 | Acc: 68.614,94.898,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.470 | Acc: 68.636,94.864,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.469 | Acc: 68.789,94.848,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.468 | Acc: 68.773,94.879,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.470 | Acc: 68.667,94.906,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.473 | Acc: 68.592,94.907,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.471 | Acc: 68.618,94.945,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.471 | Acc: 68.650,94.909,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.305 | Acc: 6.250,23.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 17.875 | Acc: 5.469,18.750,51.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.865 | Acc: 5.774,19.588,50.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 17.971 | Acc: 5.520,19.237,50.435,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.462 | Acc: 63.281,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.418 | Acc: 69.382,94.606,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.451 | Acc: 69.341,95.008,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.444 | Acc: 69.390,94.941,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.442 | Acc: 69.107,94.917,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.430 | Acc: 69.222,95.142,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.443 | Acc: 69.079,95.074,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.446 | Acc: 68.999,95.019,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.452 | Acc: 68.959,94.997,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.454 | Acc: 68.996,94.972,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.456 | Acc: 69.080,94.970,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.453 | Acc: 69.107,94.984,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.454 | Acc: 69.026,94.943,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.450 | Acc: 69.070,94.941,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.449 | Acc: 69.131,94.934,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.451 | Acc: 69.134,94.928,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.452 | Acc: 69.127,94.935,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.452 | Acc: 69.162,94.912,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.453 | Acc: 69.166,94.893,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.455 | Acc: 69.127,94.894,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.400 | Acc: 5.469,17.969,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 21.054 | Acc: 4.874,12.984,47.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 21.027 | Acc: 4.973,13.186,46.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.154 | Acc: 4.726,12.666,46.145,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.493 | Acc: 71.875,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.448 | Acc: 69.643,95.201,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.406 | Acc: 69.931,95.484,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.430 | Acc: 69.980,95.197,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.443 | Acc: 69.637,95.081,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.433 | Acc: 69.988,95.158,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.426 | Acc: 70.080,95.158,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.428 | Acc: 70.085,95.041,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.429 | Acc: 70.026,95.026,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.439 | Acc: 69.665,94.967,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.445 | Acc: 69.426,95.013,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.450 | Acc: 69.365,94.927,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.444 | Acc: 69.470,94.995,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.454 | Acc: 69.142,94.950,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.456 | Acc: 69.111,94.912,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.459 | Acc: 69.085,94.926,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.460 | Acc: 68.989,94.921,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.459 | Acc: 68.968,94.921,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.456 | Acc: 68.999,94.934,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.456 | Acc: 69.017,94.909,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 18.248 | Acc: 7.812,21.094,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.912 | Acc: 5.655,17.597,47.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 18.887 | Acc: 5.926,18.064,46.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.003 | Acc: 5.622,17.815,46.350,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.387 | Acc: 67.188,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.421 | Acc: 70.759,94.643,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.434 | Acc: 69.874,95.179,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.458 | Acc: 69.173,95.095,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.462 | Acc: 69.252,94.985,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.475 | Acc: 69.206,94.794,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.469 | Acc: 69.331,94.854,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.465 | Acc: 69.354,94.880,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.472 | Acc: 69.206,94.856,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.480 | Acc: 69.074,94.782,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.474 | Acc: 69.096,94.897,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.471 | Acc: 69.100,94.927,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.471 | Acc: 69.058,94.872,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.470 | Acc: 69.091,94.914,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.467 | Acc: 69.178,94.968,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.469 | Acc: 69.168,94.944,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.467 | Acc: 69.171,94.967,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.465 | Acc: 69.160,94.992,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.468 | Acc: 69.085,94.988,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.466 | Acc: 69.125,95.005,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 20.306 | Acc: 5.469,12.500,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.965 | Acc: 4.948,10.007,55.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.941 | Acc: 5.088,10.252,54.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 21.066 | Acc: 4.816,9.862,54.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.657 | Acc: 63.281,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.430 | Acc: 68.750,95.126,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.467 | Acc: 68.598,94.836,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.459 | Acc: 69.006,95.018,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.454 | Acc: 68.808,95.158,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.459 | Acc: 68.998,95.042,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.456 | Acc: 69.060,94.899,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.464 | Acc: 68.922,94.814,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.469 | Acc: 68.842,94.788,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.472 | Acc: 68.763,94.751,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.468 | Acc: 68.820,94.733,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.471 | Acc: 68.729,94.761,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.484 | Acc: 68.633,94.706,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.478 | Acc: 68.813,94.723,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.478 | Acc: 68.822,94.756,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.474 | Acc: 68.862,94.744,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.482 | Acc: 68.731,94.677,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.479 | Acc: 68.748,94.703,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.481 | Acc: 68.700,94.730,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.479 | Acc: 68.713,94.742,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.555 | Acc: 5.469,20.312,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.227 | Acc: 4.315,18.936,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.210 | Acc: 4.535,19.417,59.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.342 | Acc: 4.239,18.968,59.349,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.563 | Acc: 64.844,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 67.969,95.312,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.492 | Acc: 68.731,94.684,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.518 | Acc: 67.738,94.736,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.499 | Acc: 68.152,94.830,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.495 | Acc: 68.363,94.763,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.495 | Acc: 68.382,94.738,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.489 | Acc: 68.490,94.681,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.477 | Acc: 68.648,94.798,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.483 | Acc: 68.720,94.777,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.479 | Acc: 68.886,94.753,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.474 | Acc: 68.891,94.779,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.472 | Acc: 68.909,94.826,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.477 | Acc: 68.705,94.831,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.478 | Acc: 68.750,94.804,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.475 | Acc: 68.753,94.812,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.476 | Acc: 68.740,94.821,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.477 | Acc: 68.663,94.875,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.481 | Acc: 68.573,94.893,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.486 | Acc: 68.498,94.833,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.913 | Acc: 5.469,18.750,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.550 | Acc: 4.427,14.137,49.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.528 | Acc: 4.726,14.425,48.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.653 | Acc: 4.419,14.050,48.758,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.397 | Acc: 75.000,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.528 | Acc: 67.708,94.531,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.501 | Acc: 68.598,94.874,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.500 | Acc: 68.404,94.992,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.482 | Acc: 68.451,94.927,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.477 | Acc: 68.982,94.887,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 68.711,94.912,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.478 | Acc: 68.844,94.919,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.477 | Acc: 68.876,94.944,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.478 | Acc: 68.802,94.881,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.474 | Acc: 68.874,94.881,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.473 | Acc: 68.796,94.878,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.477 | Acc: 68.812,94.859,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.479 | Acc: 68.744,94.819,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.477 | Acc: 68.797,94.840,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.476 | Acc: 68.779,94.861,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.476 | Acc: 68.757,94.862,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.477 | Acc: 68.709,94.879,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.474 | Acc: 68.761,94.901,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.474 | Acc: 68.738,94.950,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.368 | Acc: 4.688,17.188,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 22.986 | Acc: 4.167,12.165,37.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 22.954 | Acc: 4.287,12.233,36.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 23.091 | Acc: 4.009,11.885,36.104,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.341 | Acc: 67.969,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.522 | Acc: 68.415,93.713,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.522 | Acc: 68.769,93.807,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.527 | Acc: 68.046,94.083,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.506 | Acc: 68.248,94.338,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.497 | Acc: 68.487,94.415,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.499 | Acc: 68.292,94.499,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.498 | Acc: 68.412,94.614,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.497 | Acc: 68.430,94.614,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.491 | Acc: 68.465,94.622,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 68.509,94.702,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.493 | Acc: 68.549,94.598,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.491 | Acc: 68.526,94.583,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.493 | Acc: 68.433,94.591,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.492 | Acc: 68.469,94.579,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.493 | Acc: 68.436,94.643,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.490 | Acc: 68.538,94.660,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.488 | Acc: 68.551,94.708,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 68.629,94.687,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.485 | Acc: 68.713,94.685,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 17.342 | Acc: 8.594,25.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 18.012 | Acc: 5.878,21.689,49.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 17.992 | Acc: 6.040,22.256,47.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 18.106 | Acc: 5.827,21.773,47.733,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.099 | Acc: 75.000,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.431 | Acc: 68.862,94.606,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.437 | Acc: 69.360,94.798,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.457 | Acc: 69.288,94.672,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.460 | Acc: 69.059,94.821,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.460 | Acc: 68.943,94.895,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.454 | Acc: 68.886,94.886,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.461 | Acc: 68.805,94.875,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.461 | Acc: 68.668,94.910,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.466 | Acc: 68.629,94.911,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.462 | Acc: 68.715,94.963,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.461 | Acc: 68.729,94.941,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.460 | Acc: 68.825,94.949,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.463 | Acc: 68.777,94.917,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.466 | Acc: 68.775,94.929,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.463 | Acc: 68.885,94.910,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.468 | Acc: 68.750,94.928,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.465 | Acc: 68.819,94.957,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.467 | Acc: 68.834,94.940,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.470 | Acc: 68.820,94.921,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 22.592 | Acc: 4.688,17.188,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 23.198 | Acc: 4.129,12.686,48.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 23.160 | Acc: 4.345,13.014,47.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 23.301 | Acc: 4.111,12.679,47.669,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.626 | Acc: 67.969,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.424 | Acc: 70.275,94.494,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.447 | Acc: 69.360,94.436,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.449 | Acc: 69.365,94.736,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.444 | Acc: 69.628,94.830,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.453 | Acc: 69.338,94.787,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.450 | Acc: 69.254,94.893,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.438 | Acc: 69.470,95.002,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.450 | Acc: 69.342,94.968,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.453 | Acc: 69.220,94.967,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.460 | Acc: 69.053,94.951,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.467 | Acc: 68.853,94.948,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.468 | Acc: 68.815,94.946,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.469 | Acc: 68.732,94.861,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.470 | Acc: 68.672,94.859,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.474 | Acc: 68.553,94.863,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.475 | Acc: 68.533,94.901,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.477 | Acc: 68.519,94.863,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.480 | Acc: 68.449,94.836,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 68.535,94.808,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 23.274 | Acc: 5.469,9.375,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 23.850 | Acc: 4.278,7.478,39.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 23.815 | Acc: 4.497,8.175,38.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 23.960 | Acc: 4.214,8.056,38.332,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.349 | Acc: 71.875,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.435 | Acc: 69.159,95.982,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.416 | Acc: 69.188,95.541,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.421 | Acc: 69.378,95.338,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.451 | Acc: 69.155,95.158,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.451 | Acc: 69.183,95.142,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.452 | Acc: 69.105,95.170,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.447 | Acc: 69.249,95.235,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.453 | Acc: 69.119,95.148,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.460 | Acc: 68.858,95.136,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.461 | Acc: 68.727,95.165,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.455 | Acc: 68.913,95.203,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.456 | Acc: 69.000,95.202,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.461 | Acc: 69.004,95.148,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.462 | Acc: 68.995,95.162,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.459 | Acc: 69.061,95.144,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.464 | Acc: 68.945,95.113,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.466 | Acc: 68.858,95.125,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.468 | Acc: 68.821,95.135,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.469 | Acc: 68.787,95.132,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.193 | Acc: 5.469,14.844,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.829 | Acc: 4.874,11.905,52.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.807 | Acc: 5.011,12.214,51.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.922 | Acc: 4.790,11.898,52.113,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.354 | Acc: 69.531,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.512 | Acc: 67.894,95.052,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.501 | Acc: 68.255,95.122,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.512 | Acc: 68.225,95.018,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.499 | Acc: 68.528,95.110,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.494 | Acc: 68.472,94.980,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.499 | Acc: 68.447,94.944,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.492 | Acc: 68.606,94.936,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.483 | Acc: 68.643,94.983,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.477 | Acc: 68.711,95.010,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.468 | Acc: 68.859,95.017,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.469 | Acc: 68.768,94.980,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.470 | Acc: 68.873,94.953,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.470 | Acc: 68.813,94.902,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.469 | Acc: 68.833,94.937,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.467 | Acc: 68.792,94.965,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.474 | Acc: 68.709,94.938,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.474 | Acc: 68.823,94.941,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.478 | Acc: 68.676,94.882,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.478 | Acc: 68.625,94.902,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.127 | Acc: 6.250,20.312,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 19.717 | Acc: 5.060,16.667,43.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 19.703 | Acc: 5.278,17.016,42.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 19.828 | Acc: 4.982,16.496,42.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.847 | Acc: 67.188,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.484 | Acc: 69.903,94.345,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.474 | Acc: 70.065,94.226,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.471 | Acc: 69.326,94.595,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.477 | Acc: 69.242,94.647,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.482 | Acc: 68.998,94.640,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 69.105,94.583,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.485 | Acc: 69.166,94.697,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 69.046,94.628,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.490 | Acc: 69.108,94.678,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.488 | Acc: 69.224,94.632,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 69.234,94.595,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.492 | Acc: 69.145,94.635,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.487 | Acc: 69.265,94.627,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 69.231,94.612,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.487 | Acc: 69.142,94.591,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.487 | Acc: 69.156,94.592,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.484 | Acc: 69.135,94.623,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.483 | Acc: 69.118,94.668,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.482 | Acc: 69.066,94.718,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 19.704 | Acc: 5.469,17.969,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 20.319 | Acc: 4.985,14.658,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 20.293 | Acc: 5.240,14.615,52.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 20.421 | Acc: 4.956,14.075,52.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 1.439 | Acc: 69.531,95.312,100.000,% | Adaptive Acc: 92.969% | clf_exit: 0.539 0.383 0.078
Batch: 20 | Loss: 1.546 | Acc: 67.225,94.717,99.888,% | Adaptive Acc: 93.043% | clf_exit: 0.520 0.392 0.088
Batch: 40 | Loss: 1.496 | Acc: 68.445,95.160,99.867,% | Adaptive Acc: 93.121% | clf_exit: 0.534 0.385 0.082
Batch: 60 | Loss: 1.496 | Acc: 68.686,94.915,99.821,% | Adaptive Acc: 92.853% | clf_exit: 0.534 0.388 0.078
Batch: 80 | Loss: 1.487 | Acc: 68.682,94.907,99.797,% | Adaptive Acc: 92.930% | clf_exit: 0.535 0.388 0.077
Batch: 100 | Loss: 1.482 | Acc: 68.920,94.957,99.799,% | Adaptive Acc: 92.845% | clf_exit: 0.534 0.390 0.076
Batch: 120 | Loss: 1.484 | Acc: 68.789,95.112,99.819,% | Adaptive Acc: 92.904% | clf_exit: 0.528 0.398 0.073
Batch: 140 | Loss: 1.485 | Acc: 68.805,94.919,99.806,% | Adaptive Acc: 92.758% | clf_exit: 0.528 0.400 0.073
Batch: 160 | Loss: 1.480 | Acc: 68.716,94.939,99.801,% | Adaptive Acc: 92.731% | clf_exit: 0.527 0.401 0.071
Batch: 180 | Loss: 1.480 | Acc: 68.625,94.920,99.801,% | Adaptive Acc: 92.645% | clf_exit: 0.526 0.403 0.070
Batch: 200 | Loss: 1.476 | Acc: 68.664,94.885,99.802,% | Adaptive Acc: 92.658% | clf_exit: 0.526 0.404 0.070
Batch: 220 | Loss: 1.479 | Acc: 68.672,94.835,99.809,% | Adaptive Acc: 92.686% | clf_exit: 0.525 0.404 0.071
Batch: 240 | Loss: 1.468 | Acc: 68.928,94.881,99.818,% | Adaptive Acc: 92.790% | clf_exit: 0.527 0.403 0.070
Batch: 260 | Loss: 1.470 | Acc: 68.864,94.849,99.811,% | Adaptive Acc: 92.714% | clf_exit: 0.527 0.404 0.068
Batch: 280 | Loss: 1.473 | Acc: 68.847,94.837,99.808,% | Adaptive Acc: 92.721% | clf_exit: 0.527 0.404 0.070
Batch: 300 | Loss: 1.472 | Acc: 68.880,94.843,99.816,% | Adaptive Acc: 92.699% | clf_exit: 0.528 0.402 0.070
Batch: 320 | Loss: 1.470 | Acc: 68.923,94.860,99.820,% | Adaptive Acc: 92.694% | clf_exit: 0.528 0.403 0.069
Batch: 340 | Loss: 1.469 | Acc: 68.920,94.854,99.824,% | Adaptive Acc: 92.744% | clf_exit: 0.528 0.404 0.068
Batch: 360 | Loss: 1.471 | Acc: 68.925,94.862,99.825,% | Adaptive Acc: 92.772% | clf_exit: 0.527 0.404 0.069
Batch: 380 | Loss: 1.477 | Acc: 68.814,94.847,99.820,% | Adaptive Acc: 92.790% | clf_exit: 0.524 0.406 0.069
Batch: 0 | Loss: 15.611 | Acc: 10.156,24.219,53.906,% | Adaptive Acc: 25.781% | clf_exit: 0.781 0.008 0.211
Batch: 20 | Loss: 16.160 | Acc: 7.589,19.271,47.879,% | Adaptive Acc: 17.746% | clf_exit: 0.795 0.006 0.198
Batch: 40 | Loss: 16.144 | Acc: 7.793,20.046,46.723,% | Adaptive Acc: 18.140% | clf_exit: 0.785 0.009 0.207
Batch: 60 | Loss: 16.238 | Acc: 7.518,19.634,46.709,% | Adaptive Acc: 17.661% | clf_exit: 0.782 0.009 0.209
Evaluate with different circles:
circles: 0
Batch: 0 | Loss: 15.611 | Acc: 10.156,24.219,53.906,% | Adaptive Acc: 25.781% | clf_exit: 0.781 0.008 0.211
Batch: 20 | Loss: 16.160 | Acc: 7.589,19.271,47.879,% | Adaptive Acc: 17.746% | clf_exit: 0.795 0.006 0.198
Batch: 40 | Loss: 16.144 | Acc: 7.793,20.046,46.723,% | Adaptive Acc: 18.140% | clf_exit: 0.785 0.009 0.207
Batch: 60 | Loss: 16.238 | Acc: 7.518,19.634,46.709,% | Adaptive Acc: 17.661% | clf_exit: 0.782 0.009 0.209
circles: 1
Batch: 0 | Loss: 7.473 | Acc: 26.562,62.500,74.219,% | Adaptive Acc: 26.562% | clf_exit: 0.969 0.016 0.016
Batch: 20 | Loss: 7.829 | Acc: 18.973,62.388,71.949,% | Adaptive Acc: 21.429% | clf_exit: 0.942 0.035 0.023
Batch: 40 | Loss: 7.856 | Acc: 18.331,62.481,71.494,% | Adaptive Acc: 21.113% | clf_exit: 0.942 0.037 0.021
Batch: 60 | Loss: 7.852 | Acc: 18.199,62.538,71.376,% | Adaptive Acc: 20.991% | clf_exit: 0.944 0.034 0.022
circles: 2
Batch: 0 | Loss: 9.159 | Acc: 21.094,60.938,76.562,% | Adaptive Acc: 30.469% | clf_exit: 0.852 0.086 0.062
Batch: 20 | Loss: 9.679 | Acc: 13.728,58.705,72.693,% | Adaptive Acc: 24.182% | clf_exit: 0.834 0.100 0.066
Batch: 40 | Loss: 9.760 | Acc: 13.034,58.632,72.428,% | Adaptive Acc: 23.342% | clf_exit: 0.835 0.098 0.068
Batch: 60 | Loss: 9.727 | Acc: 13.268,58.683,72.336,% | Adaptive Acc: 23.681% | clf_exit: 0.830 0.099 0.071
circles: 3
Batch: 0 | Loss: 13.754 | Acc: 6.250,46.875,69.531,% | Adaptive Acc: 10.156% | clf_exit: 0.922 0.039 0.039
Batch: 20 | Loss: 14.393 | Acc: 6.324,43.527,69.792,% | Adaptive Acc: 11.272% | clf_exit: 0.917 0.049 0.034
Batch: 40 | Loss: 14.552 | Acc: 6.517,42.721,69.284,% | Adaptive Acc: 11.128% | clf_exit: 0.921 0.045 0.034
Batch: 60 | Loss: 14.516 | Acc: 6.647,42.367,69.147,% | Adaptive Acc: 11.245% | clf_exit: 0.920 0.043 0.036
circles: 4
Batch: 0 | Loss: 20.676 | Acc: 3.125,26.562,61.719,% | Adaptive Acc: 5.469% | clf_exit: 0.953 0.016 0.031
Batch: 20 | Loss: 21.388 | Acc: 4.278,25.781,58.222,% | Adaptive Acc: 7.106% | clf_exit: 0.933 0.037 0.029
Batch: 40 | Loss: 21.615 | Acc: 4.516,24.943,57.736,% | Adaptive Acc: 7.069% | clf_exit: 0.933 0.037 0.030
Batch: 60 | Loss: 21.570 | Acc: 4.713,24.898,57.889,% | Adaptive Acc: 7.287% | clf_exit: 0.931 0.040 0.029
circles: 5
Batch: 0 | Loss: 37.560 | Acc: 2.344,1.562,43.750,% | Adaptive Acc: 2.344% | clf_exit: 0.945 0.055 0.000
Batch: 20 | Loss: 38.516 | Acc: 3.423,2.827,36.793,% | Adaptive Acc: 3.497% | clf_exit: 0.932 0.068 0.001
Batch: 40 | Loss: 38.828 | Acc: 3.449,2.896,36.261,% | Adaptive Acc: 3.525% | clf_exit: 0.929 0.070 0.001
Batch: 60 | Loss: 38.749 | Acc: 3.714,2.971,36.539,% | Adaptive Acc: 3.727% | clf_exit: 0.929 0.070 0.001

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 11.617 |  Acc: 9.336,11.836,15.216,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=0 | Loss: 13.557 |  Acc: 2.740,1.000,4.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 10.044 |  Acc: 15.844,20.298,27.218,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=1 | Loss: 13.117 |  Acc: 3.760,1.760,8.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 9.100 |  Acc: 20.576,25.382,34.886,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=2 | Loss: 12.744 |  Acc: 7.180,1.100,9.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 8.386 |  Acc: 23.984,29.754,40.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=3 | Loss: 12.359 |  Acc: 7.420,2.410,12.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 7.876 |  Acc: 26.030,32.880,45.036,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=4 | Loss: 12.096 |  Acc: 6.800,9.730,8.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 7.466 |  Acc: 28.116,35.810,48.512,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=5 | Loss: 12.041 |  Acc: 7.390,8.600,11.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 7.111 |  Acc: 30.304,37.982,51.894,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=6 | Loss: 11.717 |  Acc: 13.870,11.210,10.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 6.785 |  Acc: 31.818,40.486,54.528,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=7 | Loss: 11.541 |  Acc: 9.390,11.060,16.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 6.512 |  Acc: 33.620,42.620,57.196,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=8 | Loss: 11.268 |  Acc: 10.270,13.490,17.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 6.282 |  Acc: 34.586,44.236,59.276,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=9 | Loss: 11.484 |  Acc: 6.370,16.000,18.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 6.065 |  Acc: 35.934,46.020,60.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=10 | Loss: 11.024 |  Acc: 9.490,17.850,24.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 5.857 |  Acc: 37.512,47.494,62.994,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=11 | Loss: 12.485 |  Acc: 4.630,13.960,17.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 5.688 |  Acc: 38.182,48.802,64.342,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=12 | Loss: 12.490 |  Acc: 6.100,14.610,23.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 5.499 |  Acc: 39.278,50.146,66.266,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=13 | Loss: 11.663 |  Acc: 6.160,19.740,26.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 5.360 |  Acc: 39.866,51.244,67.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=14 | Loss: 11.713 |  Acc: 6.360,14.030,29.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 5.234 |  Acc: 40.694,52.564,69.210,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=15 | Loss: 15.380 |  Acc: 1.860,13.250,37.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 5.110 |  Acc: 41.618,53.230,70.228,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=16 | Loss: 13.216 |  Acc: 3.830,12.490,36.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 5.007 |  Acc: 41.928,54.328,71.524,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=17 | Loss: 12.777 |  Acc: 2.530,14.430,26.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.928 |  Acc: 42.312,54.936,72.274,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=18 | Loss: 14.928 |  Acc: 2.040,15.060,39.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.837 |  Acc: 42.942,55.516,73.624,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=19 | Loss: 11.089 |  Acc: 7.310,13.640,29.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.737 |  Acc: 43.550,56.614,74.808,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=20 | Loss: 11.760 |  Acc: 6.630,20.090,32.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.687 |  Acc: 43.786,57.080,75.340,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=21 | Loss: 13.183 |  Acc: 2.290,14.900,36.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 4.589 |  Acc: 44.126,57.578,76.460,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=22 | Loss: 15.029 |  Acc: 1.340,12.160,26.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 4.528 |  Acc: 44.648,58.402,76.994,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=23 | Loss: 12.596 |  Acc: 3.050,23.480,38.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 4.464 |  Acc: 44.856,58.638,77.756,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=24 | Loss: 13.012 |  Acc: 2.900,16.890,50.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 4.408 |  Acc: 45.530,58.986,78.482,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=25 | Loss: 11.858 |  Acc: 3.070,23.440,47.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 4.358 |  Acc: 45.298,59.690,79.210,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=26 | Loss: 13.321 |  Acc: 2.410,25.390,40.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 4.274 |  Acc: 46.096,60.134,79.924,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=27 | Loss: 13.675 |  Acc: 1.420,30.670,42.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 4.242 |  Acc: 46.320,60.622,80.164,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=28 | Loss: 13.567 |  Acc: 1.630,26.910,44.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 4.202 |  Acc: 46.502,60.752,81.042,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=29 | Loss: 11.459 |  Acc: 5.540,29.120,33.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 4.163 |  Acc: 46.574,61.116,81.194,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=30 | Loss: 16.570 |  Acc: 1.060,15.010,52.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 4.120 |  Acc: 47.022,61.702,81.818,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=31 | Loss: 15.178 |  Acc: 2.150,22.770,38.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 4.069 |  Acc: 47.496,62.022,82.450,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=32 | Loss: 14.753 |  Acc: 1.880,18.510,31.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 4.033 |  Acc: 47.656,62.402,82.544,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=33 | Loss: 14.839 |  Acc: 1.770,9.830,39.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 4.005 |  Acc: 47.782,62.686,83.266,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=34 | Loss: 13.120 |  Acc: 2.370,28.190,46.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 3.989 |  Acc: 48.088,62.950,83.242,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=35 | Loss: 14.685 |  Acc: 2.350,12.220,51.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.934 |  Acc: 48.412,63.460,83.778,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=36 | Loss: 17.512 |  Acc: 1.320,18.750,33.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.902 |  Acc: 48.712,63.586,84.018,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=37 | Loss: 16.505 |  Acc: 1.530,11.520,33.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.904 |  Acc: 48.592,63.478,84.122,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=38 | Loss: 16.031 |  Acc: 1.760,18.790,32.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.861 |  Acc: 48.886,63.744,84.678,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=39 | Loss: 17.027 |  Acc: 1.800,13.640,44.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.832 |  Acc: 49.096,64.556,84.732,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=40 | Loss: 15.918 |  Acc: 2.300,17.300,47.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.824 |  Acc: 49.050,64.116,85.336,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=41 | Loss: 16.931 |  Acc: 1.720,18.660,37.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.786 |  Acc: 49.262,64.294,85.458,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=42 | Loss: 13.450 |  Acc: 4.220,19.360,37.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.788 |  Acc: 49.402,64.576,85.264,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=43 | Loss: 14.677 |  Acc: 2.700,20.830,48.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.764 |  Acc: 49.832,64.668,85.664,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=44 | Loss: 14.254 |  Acc: 3.420,21.130,48.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.723 |  Acc: 49.822,65.068,86.090,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=45 | Loss: 15.583 |  Acc: 1.810,23.670,47.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.728 |  Acc: 49.866,65.008,85.902,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=46 | Loss: 15.590 |  Acc: 2.480,18.430,31.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.693 |  Acc: 50.178,65.218,86.476,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=47 | Loss: 16.315 |  Acc: 2.300,18.200,41.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.709 |  Acc: 50.156,65.262,86.154,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=48 | Loss: 12.295 |  Acc: 5.270,31.570,45.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.657 |  Acc: 50.416,65.586,86.416,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=49 | Loss: 15.074 |  Acc: 3.280,22.010,43.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.641 |  Acc: 50.314,65.926,87.066,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=50 | Loss: 16.410 |  Acc: 1.900,27.380,33.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.628 |  Acc: 50.708,65.888,87.062,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=51 | Loss: 16.284 |  Acc: 1.670,19.040,56.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.631 |  Acc: 50.738,66.126,86.798,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=52 | Loss: 15.165 |  Acc: 3.200,25.930,38.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.609 |  Acc: 50.680,66.082,87.002,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=53 | Loss: 13.225 |  Acc: 5.510,23.760,33.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.591 |  Acc: 51.092,66.392,86.920,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=54 | Loss: 14.870 |  Acc: 3.380,11.060,42.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.580 |  Acc: 51.096,66.526,87.202,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=55 | Loss: 15.587 |  Acc: 3.120,14.730,44.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.567 |  Acc: 50.904,66.842,87.678,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=56 | Loss: 13.906 |  Acc: 6.450,17.160,36.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.593 |  Acc: 50.854,66.368,87.158,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=57 | Loss: 20.400 |  Acc: 1.280,10.110,38.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.558 |  Acc: 51.116,66.566,87.250,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=58 | Loss: 17.559 |  Acc: 1.670,14.480,46.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.536 |  Acc: 51.548,66.876,87.484,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=59 | Loss: 13.710 |  Acc: 3.320,25.200,44.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.513 |  Acc: 51.242,67.308,87.998,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=60 | Loss: 17.365 |  Acc: 2.250,19.090,48.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.530 |  Acc: 51.524,66.884,88.068,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=61 | Loss: 14.255 |  Acc: 4.150,18.430,53.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.496 |  Acc: 52.018,67.390,87.872,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=62 | Loss: 16.089 |  Acc: 2.460,27.800,42.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.486 |  Acc: 51.870,67.552,88.148,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=63 | Loss: 14.642 |  Acc: 2.210,32.410,43.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 3.496 |  Acc: 51.550,67.364,88.006,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=64 | Loss: 14.916 |  Acc: 3.100,25.170,29.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 3.478 |  Acc: 51.988,67.734,88.130,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=65 | Loss: 16.601 |  Acc: 2.090,23.090,28.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 3.464 |  Acc: 51.684,68.096,88.126,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=66 | Loss: 14.883 |  Acc: 3.780,23.340,33.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 3.486 |  Acc: 51.756,67.284,87.876,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=67 | Loss: 16.254 |  Acc: 3.930,11.500,30.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 3.455 |  Acc: 52.046,67.980,88.344,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=68 | Loss: 14.649 |  Acc: 4.010,29.920,44.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 3.455 |  Acc: 52.052,67.922,88.218,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=69 | Loss: 16.856 |  Acc: 1.720,22.680,47.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 3.451 |  Acc: 52.010,67.752,88.316,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=70 | Loss: 14.981 |  Acc: 2.760,19.680,34.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 3.410 |  Acc: 52.344,68.632,88.604,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=71 | Loss: 17.845 |  Acc: 1.690,22.940,33.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 3.413 |  Acc: 52.366,68.038,88.628,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=72 | Loss: 18.514 |  Acc: 1.160,21.640,37.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 3.429 |  Acc: 52.302,68.324,88.652,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=73 | Loss: 16.031 |  Acc: 2.410,15.160,35.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 3.400 |  Acc: 52.460,68.690,88.666,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=74 | Loss: 17.488 |  Acc: 1.480,10.480,31.130,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 3.419 |  Acc: 52.442,68.324,88.542,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=75 | Loss: 15.712 |  Acc: 3.020,15.510,41.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 3.378 |  Acc: 52.608,68.994,88.752,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=76 | Loss: 16.157 |  Acc: 1.750,18.240,49.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 3.383 |  Acc: 52.406,68.550,88.752,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=77 | Loss: 18.279 |  Acc: 1.300,14.470,39.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 3.407 |  Acc: 52.562,68.338,88.446,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=78 | Loss: 20.464 |  Acc: 1.150,16.970,32.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 3.369 |  Acc: 52.692,68.804,89.014,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=79 | Loss: 17.880 |  Acc: 1.590,13.530,39.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 3.365 |  Acc: 52.812,68.766,88.872,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=80 | Loss: 15.462 |  Acc: 2.270,19.190,47.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 3.347 |  Acc: 53.144,69.074,88.886,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=81 | Loss: 20.125 |  Acc: 1.110,11.510,33.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 3.331 |  Acc: 53.148,69.034,89.182,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=82 | Loss: 20.081 |  Acc: 1.170,11.330,50.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 3.352 |  Acc: 53.016,69.092,89.142,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=83 | Loss: 16.145 |  Acc: 1.620,13.540,54.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 3.347 |  Acc: 52.774,69.212,89.080,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=84 | Loss: 15.797 |  Acc: 2.380,21.060,52.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 3.332 |  Acc: 52.818,69.282,89.424,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=85 | Loss: 18.409 |  Acc: 1.590,12.960,40.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 3.336 |  Acc: 52.970,69.258,89.266,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=86 | Loss: 16.577 |  Acc: 2.070,18.180,45.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 3.352 |  Acc: 53.124,69.022,88.782,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=87 | Loss: 16.611 |  Acc: 2.190,15.940,45.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 3.326 |  Acc: 53.358,69.288,89.136,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=88 | Loss: 14.968 |  Acc: 4.560,19.600,40.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 3.312 |  Acc: 53.482,69.498,89.162,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=89 | Loss: 18.843 |  Acc: 1.370,16.580,38.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 3.285 |  Acc: 53.396,69.712,89.506,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=90 | Loss: 14.644 |  Acc: 4.160,15.690,48.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 3.327 |  Acc: 53.080,69.460,89.056,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=91 | Loss: 17.988 |  Acc: 1.480,11.160,34.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 3.276 |  Acc: 53.552,70.240,89.630,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=92 | Loss: 15.016 |  Acc: 3.260,20.990,44.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 3.298 |  Acc: 53.656,69.264,89.498,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=93 | Loss: 14.668 |  Acc: 3.660,30.370,45.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 3.314 |  Acc: 53.546,69.760,88.914,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=94 | Loss: 18.132 |  Acc: 1.700,11.470,42.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 3.294 |  Acc: 53.422,69.780,89.320,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=95 | Loss: 16.224 |  Acc: 1.680,17.080,47.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 3.279 |  Acc: 53.400,69.928,89.516,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=96 | Loss: 16.247 |  Acc: 2.310,24.990,33.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 3.285 |  Acc: 53.392,69.796,89.426,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=97 | Loss: 12.509 |  Acc: 8.790,21.370,42.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 3.265 |  Acc: 53.586,69.864,89.448,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=98 | Loss: 15.142 |  Acc: 3.730,17.810,34.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 3.260 |  Acc: 53.824,69.926,89.664,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=99 | Loss: 16.276 |  Acc: 2.190,20.970,43.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 3.273 |  Acc: 53.688,69.960,89.354,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=100 | Loss: 14.009 |  Acc: 4.970,25.030,42.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 3.240 |  Acc: 53.716,70.482,89.692,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=101 | Loss: 17.048 |  Acc: 2.830,11.240,31.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 3.252 |  Acc: 53.738,70.254,89.420,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=102 | Loss: 20.745 |  Acc: 1.120,8.430,50.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 3.250 |  Acc: 53.700,70.188,89.700,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=103 | Loss: 13.946 |  Acc: 5.870,10.280,40.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 3.260 |  Acc: 53.696,69.990,89.636,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=104 | Loss: 18.452 |  Acc: 1.440,17.730,43.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 3.219 |  Acc: 53.948,70.604,89.812,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=105 | Loss: 17.858 |  Acc: 2.370,13.680,47.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 3.247 |  Acc: 54.112,70.286,89.706,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=106 | Loss: 15.944 |  Acc: 2.360,17.930,49.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 3.219 |  Acc: 53.964,70.926,90.046,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=107 | Loss: 13.459 |  Acc: 5.350,22.740,46.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 3.218 |  Acc: 54.332,70.508,89.646,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=108 | Loss: 20.368 |  Acc: 1.290,13.360,47.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 3.216 |  Acc: 54.066,70.600,89.816,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=109 | Loss: 21.798 |  Acc: 1.280,17.950,41.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 3.212 |  Acc: 54.190,70.676,89.774,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=110 | Loss: 15.381 |  Acc: 4.520,20.870,49.530,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 3.226 |  Acc: 54.242,70.412,89.670,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=111 | Loss: 14.631 |  Acc: 3.970,25.570,48.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 3.224 |  Acc: 54.366,70.450,89.536,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=112 | Loss: 20.065 |  Acc: 2.000,13.380,28.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 3.204 |  Acc: 54.268,70.648,89.754,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=113 | Loss: 15.960 |  Acc: 2.300,18.920,42.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 3.224 |  Acc: 54.250,70.834,89.434,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=114 | Loss: 17.820 |  Acc: 1.890,23.430,36.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 3.200 |  Acc: 54.120,71.020,89.986,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=115 | Loss: 13.715 |  Acc: 6.090,26.060,51.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 3.199 |  Acc: 54.544,71.116,89.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=116 | Loss: 16.790 |  Acc: 2.820,23.510,39.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 3.194 |  Acc: 54.454,70.712,89.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=117 | Loss: 20.792 |  Acc: 1.450,18.120,35.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 3.198 |  Acc: 54.452,70.666,89.874,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=118 | Loss: 16.122 |  Acc: 3.810,18.150,38.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 3.188 |  Acc: 54.344,71.098,90.074,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=119 | Loss: 14.994 |  Acc: 4.340,22.280,45.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 3.179 |  Acc: 54.662,70.912,89.904,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=120 | Loss: 19.558 |  Acc: 1.300,21.010,39.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 3.188 |  Acc: 54.342,71.240,89.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=121 | Loss: 17.035 |  Acc: 3.010,11.630,44.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 3.169 |  Acc: 54.594,71.210,90.020,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=122 | Loss: 17.060 |  Acc: 3.000,17.620,47.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 3.162 |  Acc: 54.568,71.462,90.196,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=123 | Loss: 14.199 |  Acc: 5.080,14.720,46.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 3.152 |  Acc: 54.628,71.532,89.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=124 | Loss: 18.444 |  Acc: 1.820,18.360,36.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 3.182 |  Acc: 54.432,71.334,89.874,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=125 | Loss: 14.686 |  Acc: 3.710,23.080,42.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 3.150 |  Acc: 54.822,71.598,90.112,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=126 | Loss: 18.669 |  Acc: 1.680,14.380,43.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 3.169 |  Acc: 54.470,71.226,89.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=127 | Loss: 18.253 |  Acc: 1.690,9.520,33.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 3.148 |  Acc: 54.660,71.560,90.120,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=128 | Loss: 16.600 |  Acc: 1.580,26.380,47.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 3.151 |  Acc: 54.700,71.598,90.056,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=129 | Loss: 14.131 |  Acc: 3.670,24.620,46.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 3.146 |  Acc: 54.558,71.512,90.134,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=130 | Loss: 14.898 |  Acc: 3.760,22.340,50.530,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 3.118 |  Acc: 54.762,71.940,90.300,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=131 | Loss: 16.573 |  Acc: 3.170,15.840,50.520,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 3.125 |  Acc: 54.802,71.750,90.312,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=132 | Loss: 18.177 |  Acc: 1.810,14.560,39.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 3.120 |  Acc: 54.998,72.006,90.022,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=133 | Loss: 14.344 |  Acc: 4.080,29.740,56.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 3.126 |  Acc: 54.550,71.780,90.160,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=134 | Loss: 17.095 |  Acc: 3.090,19.540,46.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 3.141 |  Acc: 54.604,71.640,89.910,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=135 | Loss: 16.124 |  Acc: 3.570,29.160,44.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 3.141 |  Acc: 54.440,71.406,90.384,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=136 | Loss: 12.444 |  Acc: 10.460,25.840,33.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 3.132 |  Acc: 54.858,71.896,89.878,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=137 | Loss: 17.547 |  Acc: 2.760,20.190,32.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 3.124 |  Acc: 55.106,71.808,90.336,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=138 | Loss: 15.834 |  Acc: 4.760,15.040,49.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 3.101 |  Acc: 55.010,71.812,90.176,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=139 | Loss: 15.579 |  Acc: 4.990,19.620,34.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 3.119 |  Acc: 54.840,71.840,90.516,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=140 | Loss: 16.654 |  Acc: 5.530,7.930,37.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 3.123 |  Acc: 54.916,71.994,90.340,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=141 | Loss: 14.387 |  Acc: 4.220,26.020,48.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 3.104 |  Acc: 55.086,72.146,90.128,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=142 | Loss: 19.822 |  Acc: 3.040,7.640,22.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 3.099 |  Acc: 55.108,72.166,90.402,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=143 | Loss: 16.541 |  Acc: 3.490,11.050,46.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 3.111 |  Acc: 55.178,71.908,90.136,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=144 | Loss: 18.260 |  Acc: 2.170,12.210,40.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 3.100 |  Acc: 55.016,72.112,90.342,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=145 | Loss: 18.100 |  Acc: 3.750,14.190,43.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 3.094 |  Acc: 55.244,72.142,90.348,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=146 | Loss: 17.178 |  Acc: 2.640,17.310,42.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 3.096 |  Acc: 55.288,72.388,90.080,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=147 | Loss: 18.013 |  Acc: 1.880,19.120,51.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 3.110 |  Acc: 55.116,72.026,89.872,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=148 | Loss: 17.884 |  Acc: 2.010,18.500,50.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 3.115 |  Acc: 55.238,72.100,90.042,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=149 | Loss: 15.157 |  Acc: 3.340,28.240,56.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.475 |  Acc: 59.946,79.396,95.608,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=150 | Loss: 15.794 |  Acc: 3.160,31.320,58.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 2.290 |  Acc: 61.280,82.096,97.532,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=151 | Loss: 15.454 |  Acc: 4.000,27.910,55.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 2.202 |  Acc: 61.884,83.258,98.238,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=152 | Loss: 14.339 |  Acc: 5.060,31.850,55.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 2.164 |  Acc: 62.096,83.642,98.488,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=153 | Loss: 16.207 |  Acc: 3.700,24.410,54.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 2.125 |  Acc: 62.402,84.484,98.628,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=154 | Loss: 18.710 |  Acc: 2.540,20.560,58.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 2.103 |  Acc: 62.278,84.862,98.748,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=155 | Loss: 14.924 |  Acc: 4.890,29.880,60.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 2.078 |  Acc: 62.768,85.094,98.898,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=156 | Loss: 18.822 |  Acc: 2.600,25.370,64.520,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 2.056 |  Acc: 62.702,85.374,99.026,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=157 | Loss: 14.877 |  Acc: 4.120,33.140,66.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 2.033 |  Acc: 63.158,85.702,99.066,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=158 | Loss: 18.598 |  Acc: 2.930,23.380,60.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 2.041 |  Acc: 62.936,85.844,99.110,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=159 | Loss: 15.780 |  Acc: 3.580,28.590,65.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 2.011 |  Acc: 63.198,86.086,99.190,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=160 | Loss: 18.361 |  Acc: 3.050,22.490,61.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.991 |  Acc: 63.226,86.414,99.164,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=161 | Loss: 15.931 |  Acc: 4.260,24.610,61.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.987 |  Acc: 63.442,86.620,99.206,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=162 | Loss: 17.980 |  Acc: 3.560,22.140,59.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.973 |  Acc: 63.422,86.692,99.294,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=163 | Loss: 15.939 |  Acc: 4.520,28.220,58.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.950 |  Acc: 63.872,87.036,99.264,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=164 | Loss: 17.410 |  Acc: 3.960,26.550,65.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.940 |  Acc: 63.886,87.242,99.326,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=165 | Loss: 17.772 |  Acc: 3.390,23.070,62.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.933 |  Acc: 63.850,87.292,99.268,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=166 | Loss: 16.618 |  Acc: 3.970,28.440,57.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.925 |  Acc: 64.016,87.498,99.304,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=167 | Loss: 18.754 |  Acc: 3.030,23.330,64.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.919 |  Acc: 64.110,87.326,99.310,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=168 | Loss: 20.126 |  Acc: 2.980,23.240,62.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.901 |  Acc: 64.018,87.712,99.372,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=169 | Loss: 17.622 |  Acc: 4.020,21.860,63.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.917 |  Acc: 64.008,87.752,99.366,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=170 | Loss: 15.027 |  Acc: 5.610,25.870,62.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.892 |  Acc: 64.114,87.912,99.414,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=171 | Loss: 12.911 |  Acc: 7.500,28.760,63.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.892 |  Acc: 64.122,87.948,99.432,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=172 | Loss: 18.225 |  Acc: 3.950,17.730,58.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.870 |  Acc: 64.174,88.434,99.422,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=173 | Loss: 19.057 |  Acc: 3.450,17.550,57.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.871 |  Acc: 64.540,88.150,99.422,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=174 | Loss: 18.475 |  Acc: 3.760,21.200,60.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.864 |  Acc: 64.290,88.374,99.476,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=175 | Loss: 16.601 |  Acc: 5.250,24.040,57.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.868 |  Acc: 64.106,88.502,99.432,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=176 | Loss: 17.632 |  Acc: 3.690,23.700,56.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.853 |  Acc: 64.548,88.470,99.506,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=177 | Loss: 17.862 |  Acc: 4.410,22.430,60.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.842 |  Acc: 64.630,88.698,99.458,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=178 | Loss: 18.851 |  Acc: 3.670,21.720,60.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.834 |  Acc: 64.742,88.694,99.432,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=179 | Loss: 19.032 |  Acc: 3.380,24.390,64.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.834 |  Acc: 64.648,88.798,99.456,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=180 | Loss: 18.939 |  Acc: 3.510,22.130,52.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.817 |  Acc: 64.970,89.054,99.464,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=181 | Loss: 20.378 |  Acc: 3.430,12.740,57.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.835 |  Acc: 64.464,88.790,99.472,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=182 | Loss: 17.946 |  Acc: 4.580,20.760,60.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.824 |  Acc: 64.968,88.892,99.516,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=183 | Loss: 19.151 |  Acc: 4.120,18.530,56.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.818 |  Acc: 64.656,89.016,99.466,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=184 | Loss: 16.138 |  Acc: 5.740,19.990,55.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.824 |  Acc: 64.772,88.960,99.476,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=185 | Loss: 18.928 |  Acc: 3.900,15.650,60.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.812 |  Acc: 64.998,89.148,99.458,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=186 | Loss: 20.107 |  Acc: 3.540,10.740,57.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.817 |  Acc: 64.980,89.208,99.454,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=187 | Loss: 18.648 |  Acc: 4.730,15.660,52.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.810 |  Acc: 64.668,89.444,99.502,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=188 | Loss: 18.246 |  Acc: 5.020,14.680,53.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.823 |  Acc: 64.780,89.150,99.472,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=189 | Loss: 17.370 |  Acc: 5.360,16.370,54.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.799 |  Acc: 64.934,89.278,99.492,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=190 | Loss: 19.159 |  Acc: 4.210,16.870,51.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.772 |  Acc: 65.264,89.616,99.502,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=191 | Loss: 22.143 |  Acc: 4.010,8.300,60.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.796 |  Acc: 65.182,89.334,99.512,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=192 | Loss: 19.292 |  Acc: 4.450,18.360,63.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.772 |  Acc: 65.410,89.564,99.528,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=193 | Loss: 19.512 |  Acc: 4.120,17.810,56.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.770 |  Acc: 65.346,89.744,99.510,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=194 | Loss: 18.140 |  Acc: 4.960,17.610,55.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.774 |  Acc: 65.478,89.840,99.544,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=195 | Loss: 20.269 |  Acc: 4.140,15.440,56.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.758 |  Acc: 65.276,89.730,99.528,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=196 | Loss: 20.720 |  Acc: 4.890,8.380,58.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.774 |  Acc: 65.316,89.706,99.550,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=197 | Loss: 16.810 |  Acc: 5.240,19.980,58.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.768 |  Acc: 65.318,89.692,99.508,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=198 | Loss: 19.697 |  Acc: 4.570,9.800,53.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.759 |  Acc: 65.418,89.852,99.494,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=199 | Loss: 21.725 |  Acc: 4.210,13.420,58.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.764 |  Acc: 65.372,89.880,99.546,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=200 | Loss: 20.540 |  Acc: 5.050,18.750,54.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.750 |  Acc: 65.718,89.722,99.528,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=201 | Loss: 18.330 |  Acc: 5.190,19.150,58.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.746 |  Acc: 65.562,89.908,99.548,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=202 | Loss: 20.054 |  Acc: 3.960,17.390,52.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.745 |  Acc: 65.742,89.932,99.576,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=203 | Loss: 20.356 |  Acc: 4.490,9.230,60.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.758 |  Acc: 65.632,89.896,99.554,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=204 | Loss: 18.943 |  Acc: 4.880,15.950,55.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.730 |  Acc: 65.936,90.240,99.556,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=205 | Loss: 19.259 |  Acc: 4.930,19.740,52.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.735 |  Acc: 65.638,90.130,99.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=206 | Loss: 16.493 |  Acc: 7.180,21.170,62.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.746 |  Acc: 65.526,90.132,99.536,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=207 | Loss: 20.198 |  Acc: 3.840,19.360,59.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.747 |  Acc: 65.476,90.100,99.500,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=208 | Loss: 16.114 |  Acc: 7.290,13.690,55.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.720 |  Acc: 65.964,90.260,99.584,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=209 | Loss: 20.256 |  Acc: 3.460,13.980,43.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.732 |  Acc: 65.760,90.398,99.544,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=210 | Loss: 18.996 |  Acc: 4.240,19.620,55.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.741 |  Acc: 65.692,90.302,99.512,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=211 | Loss: 21.516 |  Acc: 4.210,8.180,45.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.735 |  Acc: 65.540,90.438,99.546,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=212 | Loss: 19.510 |  Acc: 4.070,18.660,61.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.728 |  Acc: 65.730,90.356,99.602,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=213 | Loss: 20.000 |  Acc: 4.140,13.630,48.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.722 |  Acc: 65.998,90.378,99.576,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=214 | Loss: 17.837 |  Acc: 5.540,7.210,44.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.709 |  Acc: 66.156,90.580,99.626,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=215 | Loss: 23.419 |  Acc: 3.250,7.200,51.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.714 |  Acc: 65.836,90.364,99.534,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=216 | Loss: 22.833 |  Acc: 3.000,13.690,38.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.705 |  Acc: 66.054,90.622,99.538,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=217 | Loss: 18.995 |  Acc: 5.380,18.290,56.590,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.721 |  Acc: 65.910,90.476,99.542,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=218 | Loss: 21.317 |  Acc: 3.460,15.710,40.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.730 |  Acc: 65.662,90.198,99.618,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=219 | Loss: 18.105 |  Acc: 5.930,14.020,50.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.714 |  Acc: 66.098,90.420,99.542,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=220 | Loss: 22.578 |  Acc: 3.980,12.720,37.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.709 |  Acc: 66.106,90.518,99.544,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=221 | Loss: 20.912 |  Acc: 4.180,14.980,34.520,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.694 |  Acc: 66.178,90.786,99.566,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=222 | Loss: 22.296 |  Acc: 4.020,10.470,55.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.698 |  Acc: 66.268,90.614,99.540,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=223 | Loss: 19.164 |  Acc: 5.710,16.770,54.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.700 |  Acc: 66.136,90.736,99.532,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=224 | Loss: 17.876 |  Acc: 7.550,17.020,43.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.604 |  Acc: 67.450,92.378,99.628,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=225 | Loss: 22.407 |  Acc: 4.030,12.400,37.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.581 |  Acc: 67.560,93.016,99.702,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=226 | Loss: 20.420 |  Acc: 5.190,9.920,53.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.542 |  Acc: 68.166,93.486,99.778,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=227 | Loss: 20.056 |  Acc: 5.290,11.060,54.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.563 |  Acc: 68.018,93.386,99.752,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=228 | Loss: 19.543 |  Acc: 5.610,11.040,50.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.529 |  Acc: 67.902,93.508,99.724,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=229 | Loss: 25.559 |  Acc: 3.770,5.120,44.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.540 |  Acc: 67.970,93.864,99.752,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=230 | Loss: 19.751 |  Acc: 5.180,17.710,52.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.519 |  Acc: 68.390,93.930,99.756,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=231 | Loss: 20.834 |  Acc: 4.340,12.700,56.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.510 |  Acc: 68.402,93.962,99.752,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=232 | Loss: 20.452 |  Acc: 5.190,13.840,60.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.520 |  Acc: 68.100,93.836,99.782,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=233 | Loss: 20.508 |  Acc: 4.480,12.730,52.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.519 |  Acc: 68.508,94.018,99.768,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=234 | Loss: 19.125 |  Acc: 5.400,14.410,47.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.530 |  Acc: 68.100,93.836,99.756,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=235 | Loss: 21.011 |  Acc: 4.860,9.390,50.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.522 |  Acc: 68.330,94.076,99.728,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=236 | Loss: 23.000 |  Acc: 4.180,10.830,48.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.519 |  Acc: 68.212,93.980,99.788,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=237 | Loss: 18.808 |  Acc: 6.060,15.680,51.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.530 |  Acc: 67.852,94.146,99.806,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=238 | Loss: 19.655 |  Acc: 5.320,13.050,54.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.527 |  Acc: 67.908,94.110,99.772,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=239 | Loss: 24.494 |  Acc: 3.490,13.780,47.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.525 |  Acc: 68.236,94.154,99.774,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=240 | Loss: 21.131 |  Acc: 4.860,11.850,47.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.517 |  Acc: 68.126,94.288,99.786,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=241 | Loss: 25.298 |  Acc: 3.140,10.150,50.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.507 |  Acc: 68.494,94.070,99.728,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=242 | Loss: 19.753 |  Acc: 4.930,13.290,47.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.511 |  Acc: 68.212,94.342,99.806,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=243 | Loss: 22.705 |  Acc: 3.750,12.420,46.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.501 |  Acc: 68.624,94.392,99.744,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=244 | Loss: 23.646 |  Acc: 3.770,6.150,50.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.504 |  Acc: 68.582,94.322,99.736,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=245 | Loss: 22.105 |  Acc: 3.950,10.930,49.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.507 |  Acc: 68.302,94.286,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=246 | Loss: 19.826 |  Acc: 5.010,13.590,42.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.508 |  Acc: 68.138,94.210,99.728,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=247 | Loss: 21.119 |  Acc: 4.180,14.080,47.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.501 |  Acc: 68.684,94.254,99.784,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=248 | Loss: 20.573 |  Acc: 4.210,18.020,43.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.505 |  Acc: 68.380,94.322,99.772,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=249 | Loss: 22.785 |  Acc: 4.270,11.390,51.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.498 |  Acc: 68.688,94.470,99.808,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=250 | Loss: 18.377 |  Acc: 5.090,19.940,63.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.511 |  Acc: 68.574,94.276,99.784,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=251 | Loss: 23.088 |  Acc: 3.560,11.940,49.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.496 |  Acc: 68.468,94.332,99.726,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=252 | Loss: 19.708 |  Acc: 4.730,15.910,54.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.510 |  Acc: 68.284,94.328,99.838,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=253 | Loss: 21.502 |  Acc: 4.590,12.530,44.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.485 |  Acc: 68.808,94.554,99.760,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=254 | Loss: 24.995 |  Acc: 3.180,8.960,47.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.499 |  Acc: 68.220,94.372,99.738,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=255 | Loss: 21.630 |  Acc: 3.860,15.720,50.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.518 |  Acc: 68.212,94.404,99.784,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=256 | Loss: 21.786 |  Acc: 4.780,8.570,53.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.496 |  Acc: 68.578,94.372,99.786,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=257 | Loss: 22.972 |  Acc: 4.600,9.360,49.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.508 |  Acc: 68.444,94.278,99.774,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=258 | Loss: 24.859 |  Acc: 3.860,7.170,56.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.509 |  Acc: 68.558,94.316,99.776,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=259 | Loss: 15.595 |  Acc: 8.550,22.140,44.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.511 |  Acc: 68.518,94.304,99.744,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=260 | Loss: 20.708 |  Acc: 4.670,12.620,49.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.485 |  Acc: 68.572,94.508,99.790,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=261 | Loss: 23.460 |  Acc: 3.880,12.570,46.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.484 |  Acc: 68.472,94.770,99.782,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=262 | Loss: 20.135 |  Acc: 4.890,18.030,54.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.483 |  Acc: 68.460,94.718,99.774,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=263 | Loss: 22.786 |  Acc: 4.170,9.800,47.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.487 |  Acc: 68.640,94.616,99.772,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=264 | Loss: 17.635 |  Acc: 5.390,26.470,50.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.490 |  Acc: 68.810,94.704,99.780,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=265 | Loss: 23.697 |  Acc: 4.010,8.420,41.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.471 |  Acc: 68.946,94.684,99.800,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=266 | Loss: 16.848 |  Acc: 7.550,15.980,45.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.490 |  Acc: 68.474,94.834,99.782,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=267 | Loss: 21.228 |  Acc: 4.290,11.900,45.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.485 |  Acc: 68.722,94.612,99.778,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=268 | Loss: 24.358 |  Acc: 3.380,10.040,51.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.469 |  Acc: 68.748,94.782,99.780,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=269 | Loss: 20.608 |  Acc: 4.560,14.670,53.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.479 |  Acc: 68.788,94.738,99.812,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=270 | Loss: 18.520 |  Acc: 5.890,17.880,43.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.483 |  Acc: 68.780,94.676,99.768,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=271 | Loss: 22.717 |  Acc: 3.860,10.300,51.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.467 |  Acc: 68.950,94.760,99.812,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=272 | Loss: 21.164 |  Acc: 4.620,11.520,51.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.479 |  Acc: 68.588,94.774,99.778,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=273 | Loss: 23.625 |  Acc: 4.000,12.130,54.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.489 |  Acc: 68.556,94.714,99.826,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=274 | Loss: 21.954 |  Acc: 4.630,10.780,45.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.474 |  Acc: 68.658,94.720,99.786,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=275 | Loss: 21.620 |  Acc: 3.980,16.960,47.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.491 |  Acc: 68.604,94.772,99.788,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=276 | Loss: 17.882 |  Acc: 5.660,17.360,40.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.480 |  Acc: 68.610,94.850,99.758,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=277 | Loss: 22.333 |  Acc: 4.050,14.970,50.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.467 |  Acc: 68.742,94.772,99.776,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=278 | Loss: 24.292 |  Acc: 3.690,8.740,42.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.481 |  Acc: 68.878,94.830,99.776,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=279 | Loss: 25.026 |  Acc: 3.110,8.290,50.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.475 |  Acc: 69.042,94.874,99.766,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=280 | Loss: 22.121 |  Acc: 4.510,10.420,49.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.481 |  Acc: 68.682,94.742,99.784,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=281 | Loss: 20.954 |  Acc: 4.910,12.180,43.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.477 |  Acc: 68.880,94.886,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=282 | Loss: 22.157 |  Acc: 4.410,9.900,54.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.487 |  Acc: 68.546,94.666,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=283 | Loss: 22.186 |  Acc: 4.130,14.490,50.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.490 |  Acc: 68.556,94.808,99.828,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=284 | Loss: 22.520 |  Acc: 4.680,10.590,48.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.462 |  Acc: 68.924,94.878,99.832,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=285 | Loss: 22.890 |  Acc: 4.460,10.220,51.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.473 |  Acc: 68.594,94.898,99.810,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=286 | Loss: 17.968 |  Acc: 5.490,19.380,50.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.454 |  Acc: 69.096,94.894,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=287 | Loss: 21.162 |  Acc: 4.680,12.940,46.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.461 |  Acc: 68.900,94.898,99.776,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=288 | Loss: 19.000 |  Acc: 5.560,18.020,46.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.465 |  Acc: 69.110,95.018,99.808,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=289 | Loss: 21.074 |  Acc: 4.770,10.170,54.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.481 |  Acc: 68.694,94.740,99.816,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=290 | Loss: 20.351 |  Acc: 4.210,19.120,59.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.486 |  Acc: 68.518,94.842,99.828,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=291 | Loss: 20.658 |  Acc: 4.410,14.310,48.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.477 |  Acc: 68.706,94.884,99.754,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=292 | Loss: 23.104 |  Acc: 3.940,12.110,36.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.489 |  Acc: 68.660,94.634,99.780,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=293 | Loss: 18.109 |  Acc: 5.780,21.870,47.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.473 |  Acc: 68.772,94.896,99.796,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=294 | Loss: 23.314 |  Acc: 4.110,12.990,47.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.478 |  Acc: 68.568,94.814,99.784,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=295 | Loss: 23.971 |  Acc: 4.130,8.350,38.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.470 |  Acc: 68.784,95.116,99.812,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=296 | Loss: 19.923 |  Acc: 4.750,12.170,52.130,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.479 |  Acc: 68.596,94.882,99.806,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=297 | Loss: 19.831 |  Acc: 4.970,16.710,42.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.483 |  Acc: 69.090,94.702,99.800,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=298 | Loss: 20.420 |  Acc: 4.950,14.440,52.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelC_dp2', batch_size=128, circles=5, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.478 |  Acc: 68.792,94.860,99.818,% | Adaptive Acc:92.784% | clf_exit: 0.524 0.407 0.069 
Testing: Epoch=299 | Loss: 16.226 |  Acc: 7.450,20.000,46.680,% | Adaptive Acc:17.490% | clf_exit: 0.781 0.010 0.208 
Testing: Epoch=299 | Loss: 16.226 |  Acc: 7.450,20.000,46.680,% | Adaptive Acc:17.490% | clf_exit: 0.781 0.010 0.208 
Testing: Epoch=299 | Loss: 7.787 |  Acc: 18.470,63.240,71.810,% | Adaptive Acc:21.260% | clf_exit: 0.944 0.035 0.021 
Testing: Epoch=299 | Loss: 9.637 |  Acc: 13.230,59.350,72.810,% | Adaptive Acc:23.530% | clf_exit: 0.830 0.099 0.071 
Testing: Epoch=299 | Loss: 14.381 |  Acc: 6.840,43.080,69.680,% | Adaptive Acc:11.530% | clf_exit: 0.920 0.043 0.037 
Testing: Epoch=299 | Loss: 21.377 |  Acc: 4.850,25.050,58.220,% | Adaptive Acc:7.600% | clf_exit: 0.930 0.040 0.029 
Testing: Epoch=299 | Loss: 38.507 |  Acc: 3.860,2.980,36.750,% | Adaptive Acc:3.860% | clf_exit: 0.929 0.070 0.001 
