==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=128, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=128, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=288, out_features=72, bias=True)
      (linear): Linear(in_features=72, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x72])
      (linear_bw): Linear(in_features=72, out_features=288, bias=True)
      (BN1d): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=584, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=584, out_features=100, bias=True)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 14.418 | Acc: 0.781,0.000,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.625 | Acc: 1.525,1.674,3.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.370 | Acc: 2.039,2.687,6.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.194 | Acc: 2.395,3.599,7.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.057 | Acc: 2.758,4.273,8.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.936 | Acc: 3.117,4.881,9.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.833 | Acc: 3.286,5.411,9.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.743 | Acc: 3.563,5.762,10.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.659 | Acc: 3.751,6.216,10.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.568 | Acc: 3.962,6.699,11.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.498 | Acc: 4.171,7.016,11.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.432 | Acc: 4.348,7.318,12.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.366 | Acc: 4.555,7.647,12.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.311 | Acc: 4.661,7.968,13.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.255 | Acc: 4.771,8.207,13.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.184 | Acc: 4.952,8.474,13.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.132 | Acc: 5.074,8.694,14.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.076 | Acc: 5.230,8.912,14.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.017 | Acc: 5.380,9.189,15.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.969 | Acc: 5.481,9.377,15.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.171 | Acc: 8.594,10.938,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.413 | Acc: 5.990,9.784,19.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.373 | Acc: 5.983,10.385,19.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.368 | Acc: 6.455,10.925,19.915,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 10.778 | Acc: 7.812,13.281,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.842 | Acc: 8.296,13.132,22.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.798 | Acc: 8.518,13.796,23.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.796 | Acc: 8.453,14.165,23.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.752 | Acc: 8.488,14.574,23.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.705 | Acc: 8.741,15.099,24.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.674 | Acc: 8.846,15.263,24.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.642 | Acc: 8.921,15.420,24.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.599 | Acc: 9.176,15.620,24.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.566 | Acc: 9.336,15.694,24.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.528 | Acc: 9.495,15.913,25.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.484 | Acc: 9.732,16.173,25.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.453 | Acc: 9.887,16.426,25.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.433 | Acc: 10.001,16.568,26.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.400 | Acc: 10.109,16.726,26.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.366 | Acc: 10.247,16.928,26.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.335 | Acc: 10.353,17.114,26.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.302 | Acc: 10.482,17.240,26.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.274 | Acc: 10.606,17.369,27.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.237 | Acc: 10.753,17.602,27.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.808 | Acc: 13.281,17.969,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.981 | Acc: 11.384,17.262,28.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.949 | Acc: 10.785,17.302,28.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.931 | Acc: 11.104,17.546,28.881,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 9.607 | Acc: 12.500,18.750,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.501 | Acc: 13.244,22.359,33.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.494 | Acc: 13.624,22.104,32.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.498 | Acc: 13.717,21.798,32.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.459 | Acc: 13.677,22.049,33.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.463 | Acc: 13.575,22.254,32.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.420 | Acc: 13.882,22.430,33.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.399 | Acc: 14.013,22.579,33.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.382 | Acc: 14.019,22.598,33.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.354 | Acc: 14.188,22.764,33.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.334 | Acc: 14.175,22.726,33.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.323 | Acc: 14.246,22.759,33.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.301 | Acc: 14.416,22.893,33.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.273 | Acc: 14.589,23.117,34.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.247 | Acc: 14.621,23.324,34.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.222 | Acc: 14.745,23.497,34.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.196 | Acc: 14.941,23.691,34.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.177 | Acc: 15.043,23.820,35.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.159 | Acc: 15.220,23.957,35.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.132 | Acc: 15.367,24.104,35.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.858 | Acc: 16.406,24.219,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.967 | Acc: 15.699,24.330,35.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.939 | Acc: 16.139,23.838,35.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.936 | Acc: 16.060,23.809,35.566,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 7.912 | Acc: 20.312,31.250,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.573 | Acc: 17.820,26.228,40.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.604 | Acc: 17.626,26.353,40.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.565 | Acc: 17.956,26.844,40.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.515 | Acc: 18.171,27.209,40.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.526 | Acc: 18.054,26.949,40.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.512 | Acc: 18.162,27.157,40.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.491 | Acc: 18.357,27.344,40.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.472 | Acc: 18.575,27.562,40.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.466 | Acc: 18.612,27.698,40.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.456 | Acc: 18.630,27.799,40.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.460 | Acc: 18.626,27.662,40.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.451 | Acc: 18.685,27.801,41.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.436 | Acc: 18.756,27.841,41.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.417 | Acc: 18.856,28.000,41.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.399 | Acc: 19.015,28.109,41.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.391 | Acc: 19.013,28.166,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.380 | Acc: 19.139,28.288,41.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.366 | Acc: 19.120,28.354,41.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.360 | Acc: 19.066,28.400,41.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.305 | Acc: 19.531,29.688,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.479 | Acc: 18.378,25.670,42.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.467 | Acc: 18.312,25.934,42.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.484 | Acc: 18.532,25.832,41.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 7.881 | Acc: 17.188,25.000,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.852 | Acc: 21.019,31.696,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.901 | Acc: 21.303,30.983,44.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.925 | Acc: 21.107,31.096,44.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.891 | Acc: 21.132,31.211,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.877 | Acc: 21.233,31.296,45.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.850 | Acc: 21.494,31.424,45.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.847 | Acc: 21.543,31.389,45.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.854 | Acc: 21.545,31.231,45.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.831 | Acc: 21.672,31.401,45.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.834 | Acc: 21.603,31.374,45.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.826 | Acc: 21.606,31.505,45.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.829 | Acc: 21.564,31.477,45.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.822 | Acc: 21.701,31.672,45.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.808 | Acc: 21.789,31.814,45.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.807 | Acc: 21.828,31.894,45.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.800 | Acc: 21.890,32.031,45.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.793 | Acc: 21.905,32.063,45.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.783 | Acc: 21.912,32.113,45.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.772 | Acc: 21.971,32.199,46.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.935 | Acc: 23.438,36.719,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.039 | Acc: 20.015,31.585,47.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.026 | Acc: 19.341,30.450,46.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.011 | Acc: 19.006,30.827,46.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 7.457 | Acc: 25.781,32.812,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.443 | Acc: 22.619,33.185,50.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.410 | Acc: 23.609,34.184,49.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.417 | Acc: 23.770,34.388,49.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.422 | Acc: 23.515,34.500,49.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.429 | Acc: 23.430,34.561,49.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.438 | Acc: 23.366,34.607,49.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.434 | Acc: 23.454,34.635,49.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.424 | Acc: 23.651,34.652,49.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.407 | Acc: 23.740,34.880,49.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.410 | Acc: 23.756,34.892,49.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.409 | Acc: 23.957,34.817,49.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.389 | Acc: 24.141,34.890,49.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.362 | Acc: 24.213,35.093,49.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.352 | Acc: 24.185,35.212,50.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.343 | Acc: 24.206,35.208,49.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.334 | Acc: 24.233,35.329,50.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.329 | Acc: 24.232,35.351,50.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.319 | Acc: 24.290,35.427,50.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.313 | Acc: 24.459,35.585,50.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.294 | Acc: 22.656,41.406,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.326 | Acc: 23.028,36.086,50.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.321 | Acc: 23.533,36.033,50.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.321 | Acc: 22.964,36.027,50.666,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 7.084 | Acc: 28.125,40.625,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.978 | Acc: 25.893,38.095,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.975 | Acc: 26.143,38.434,53.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.941 | Acc: 26.114,38.345,53.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.932 | Acc: 26.264,38.349,53.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.936 | Acc: 26.145,38.529,53.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.921 | Acc: 26.149,38.720,53.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.921 | Acc: 26.291,38.830,53.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.946 | Acc: 26.009,38.854,53.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.950 | Acc: 25.984,38.942,53.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.956 | Acc: 25.964,38.802,53.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.946 | Acc: 26.089,39.027,53.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.949 | Acc: 26.070,38.959,53.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.949 | Acc: 26.075,39.006,53.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.937 | Acc: 26.162,39.107,53.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.941 | Acc: 26.181,39.013,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.938 | Acc: 26.309,39.031,53.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.931 | Acc: 26.427,39.145,53.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.927 | Acc: 26.413,39.184,53.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.921 | Acc: 26.454,39.245,53.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.224 | Acc: 26.562,38.281,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.301 | Acc: 23.177,37.351,53.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.263 | Acc: 23.609,37.100,52.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.252 | Acc: 23.143,37.065,52.946,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 6.798 | Acc: 29.688,36.719,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.689 | Acc: 27.009,40.104,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.634 | Acc: 27.954,40.530,56.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.590 | Acc: 27.869,41.906,57.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.601 | Acc: 27.855,42.226,56.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.619 | Acc: 27.808,42.002,56.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.630 | Acc: 27.731,41.897,56.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.636 | Acc: 27.848,41.883,56.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.641 | Acc: 27.635,41.858,56.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.639 | Acc: 27.611,41.734,56.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.639 | Acc: 27.627,41.702,56.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.657 | Acc: 27.574,41.569,55.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.647 | Acc: 27.603,41.601,56.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.641 | Acc: 27.709,41.628,56.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.639 | Acc: 27.638,41.656,56.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.628 | Acc: 27.681,41.674,56.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.627 | Acc: 27.687,41.667,56.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.626 | Acc: 27.706,41.667,56.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.621 | Acc: 27.744,41.748,56.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.616 | Acc: 27.828,41.853,56.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.823 | Acc: 26.562,42.188,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.988 | Acc: 22.879,40.141,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.999 | Acc: 22.828,40.091,53.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.996 | Acc: 23.079,39.805,54.201,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 6.106 | Acc: 33.594,50.000,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.303 | Acc: 29.836,44.420,60.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.265 | Acc: 29.916,44.169,60.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.273 | Acc: 29.444,43.904,60.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.285 | Acc: 29.340,44.039,60.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.292 | Acc: 29.247,43.974,60.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.318 | Acc: 29.184,43.944,59.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.316 | Acc: 29.266,44.010,59.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.320 | Acc: 29.333,44.051,59.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.334 | Acc: 29.157,43.970,59.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.350 | Acc: 29.085,43.859,59.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.340 | Acc: 29.182,43.980,58.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.351 | Acc: 29.033,43.821,58.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.346 | Acc: 29.074,43.903,58.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.343 | Acc: 29.120,43.853,58.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.343 | Acc: 29.205,43.890,58.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.335 | Acc: 29.320,43.942,58.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.329 | Acc: 29.319,44.103,58.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.330 | Acc: 29.313,44.059,58.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.332 | Acc: 29.314,44.092,58.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.585 | Acc: 35.938,46.094,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.688 | Acc: 24.926,43.638,57.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.663 | Acc: 24.962,43.540,56.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.659 | Acc: 24.910,43.379,57.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 5.997 | Acc: 33.594,46.875,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.939 | Acc: 31.436,47.805,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.011 | Acc: 30.354,46.818,62.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.998 | Acc: 30.353,46.657,62.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.014 | Acc: 30.237,46.653,62.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.017 | Acc: 30.167,46.550,62.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.034 | Acc: 29.933,46.455,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.044 | Acc: 29.865,46.254,61.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.046 | Acc: 30.042,46.103,61.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.056 | Acc: 30.020,46.241,61.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.049 | Acc: 30.088,46.412,61.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.052 | Acc: 30.034,46.423,61.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.055 | Acc: 30.025,46.291,61.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.038 | Acc: 30.241,46.492,61.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.036 | Acc: 30.274,46.483,61.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.037 | Acc: 30.342,46.582,61.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.032 | Acc: 30.461,46.690,61.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.034 | Acc: 30.570,46.776,61.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.038 | Acc: 30.625,46.756,61.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.028 | Acc: 30.711,46.896,61.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.490 | Acc: 29.688,51.562,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.561 | Acc: 26.190,44.866,59.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.542 | Acc: 26.582,44.264,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.540 | Acc: 26.537,43.942,58.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 5.925 | Acc: 26.562,48.438,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.811 | Acc: 32.031,47.954,64.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.805 | Acc: 32.069,47.923,64.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.766 | Acc: 32.403,48.642,64.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.782 | Acc: 32.378,48.428,64.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.795 | Acc: 32.163,48.453,64.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.817 | Acc: 32.070,48.270,63.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.820 | Acc: 32.076,48.404,63.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.805 | Acc: 32.293,48.656,63.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.810 | Acc: 32.161,48.563,63.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.815 | Acc: 32.039,48.577,63.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.829 | Acc: 31.922,48.529,63.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.829 | Acc: 31.953,48.483,63.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.835 | Acc: 31.926,48.417,63.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.836 | Acc: 31.948,48.390,63.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.830 | Acc: 32.018,48.492,63.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.830 | Acc: 32.068,48.562,63.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.830 | Acc: 32.054,48.495,63.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.827 | Acc: 32.049,48.541,63.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.828 | Acc: 32.054,48.626,63.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.108 | Acc: 32.812,46.094,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.385 | Acc: 27.604,46.094,61.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.398 | Acc: 27.287,45.560,61.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.398 | Acc: 27.241,45.197,60.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 5.277 | Acc: 34.375,52.344,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.524 | Acc: 32.775,50.818,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.492 | Acc: 32.603,51.429,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.520 | Acc: 32.877,50.832,66.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.518 | Acc: 33.295,50.907,66.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.526 | Acc: 33.300,50.743,66.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.548 | Acc: 33.323,50.549,65.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.568 | Acc: 33.184,50.299,65.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.591 | Acc: 33.099,50.082,65.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.587 | Acc: 33.063,50.147,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.599 | Acc: 33.050,50.132,65.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.594 | Acc: 33.155,50.156,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.603 | Acc: 33.065,50.172,65.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.612 | Acc: 33.088,50.186,65.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.613 | Acc: 33.104,50.170,65.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.608 | Acc: 33.194,50.215,65.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.608 | Acc: 33.258,50.258,65.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.603 | Acc: 33.333,50.298,65.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.597 | Acc: 33.343,50.333,65.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.602 | Acc: 33.276,50.330,65.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.368 | Acc: 26.562,50.000,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.232 | Acc: 28.757,47.135,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.203 | Acc: 28.849,46.761,61.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.224 | Acc: 28.509,46.440,61.117,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 5.312 | Acc: 31.250,54.688,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.301 | Acc: 35.565,53.757,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.404 | Acc: 33.803,52.401,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.398 | Acc: 33.709,52.485,68.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.424 | Acc: 33.642,51.871,68.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.413 | Acc: 33.810,51.802,68.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.410 | Acc: 33.729,51.782,68.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.414 | Acc: 33.815,51.751,67.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.427 | Acc: 33.943,51.757,67.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.428 | Acc: 34.030,51.796,67.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.424 | Acc: 33.947,51.885,67.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.422 | Acc: 34.124,52.040,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.415 | Acc: 34.236,52.055,67.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.420 | Acc: 34.237,51.982,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.414 | Acc: 34.278,52.021,67.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.416 | Acc: 34.261,51.975,67.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.418 | Acc: 34.290,52.018,66.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.420 | Acc: 34.309,51.998,66.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.423 | Acc: 34.310,52.034,66.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.424 | Acc: 34.285,52.077,66.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.919 | Acc: 32.812,50.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.088 | Acc: 30.878,48.549,62.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.084 | Acc: 30.393,47.942,61.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.082 | Acc: 29.931,48.245,61.655,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 5.293 | Acc: 36.719,53.125,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.130 | Acc: 34.226,54.129,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.142 | Acc: 35.309,54.345,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.154 | Acc: 35.284,54.380,71.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.173 | Acc: 35.127,54.186,70.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.181 | Acc: 35.079,54.123,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.189 | Acc: 35.163,53.958,69.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.185 | Acc: 35.367,54.034,69.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.205 | Acc: 35.185,53.926,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.223 | Acc: 35.079,53.712,69.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.245 | Acc: 35.129,53.463,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.257 | Acc: 35.107,53.387,68.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.257 | Acc: 35.095,53.381,68.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.254 | Acc: 35.189,53.538,68.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.257 | Acc: 35.281,53.539,68.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.254 | Acc: 35.317,53.532,68.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.259 | Acc: 35.312,53.507,68.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.262 | Acc: 35.321,53.553,68.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.261 | Acc: 35.301,53.538,68.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.267 | Acc: 35.261,53.498,68.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.927 | Acc: 31.250,51.562,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.031 | Acc: 28.571,49.665,63.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.010 | Acc: 28.620,49.409,62.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.008 | Acc: 28.496,49.116,62.807,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 5.027 | Acc: 37.500,60.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.988 | Acc: 36.644,56.473,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.009 | Acc: 36.566,55.869,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.015 | Acc: 36.040,55.443,71.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.054 | Acc: 35.947,55.122,71.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.050 | Acc: 36.139,55.244,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.037 | Acc: 36.357,55.391,71.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.053 | Acc: 36.215,55.269,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.057 | Acc: 36.238,55.226,70.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.071 | Acc: 36.106,55.236,70.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.074 | Acc: 36.171,55.193,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.082 | Acc: 36.079,55.154,70.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.096 | Acc: 35.921,54.995,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.105 | Acc: 35.872,54.936,70.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.100 | Acc: 36.038,55.054,70.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.104 | Acc: 36.047,55.022,70.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.106 | Acc: 36.069,54.933,70.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.112 | Acc: 36.054,54.933,69.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.121 | Acc: 36.050,54.858,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.113 | Acc: 36.056,54.964,69.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.240 | Acc: 38.281,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.757 | Acc: 31.287,52.902,63.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.791 | Acc: 31.098,51.886,63.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.801 | Acc: 30.866,51.857,63.332,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 4.347 | Acc: 47.656,61.719,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.926 | Acc: 36.719,56.287,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.872 | Acc: 37.024,57.050,72.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.888 | Acc: 37.039,56.993,73.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.909 | Acc: 36.796,56.568,72.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.908 | Acc: 36.982,56.575,72.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.907 | Acc: 37.022,56.521,72.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.908 | Acc: 36.907,56.544,72.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.908 | Acc: 36.937,56.604,72.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.923 | Acc: 36.913,56.436,72.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.933 | Acc: 36.804,56.215,72.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.944 | Acc: 36.761,56.183,72.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.953 | Acc: 36.709,56.098,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.956 | Acc: 36.758,56.040,71.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.966 | Acc: 36.649,55.975,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.970 | Acc: 36.646,55.972,71.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.970 | Acc: 36.636,56.053,71.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.975 | Acc: 36.629,56.014,71.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.981 | Acc: 36.652,55.977,71.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.983 | Acc: 36.758,55.981,71.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.730 | Acc: 31.250,48.438,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.895 | Acc: 30.432,50.037,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.889 | Acc: 30.088,50.400,63.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.889 | Acc: 29.854,50.359,63.845,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 4.741 | Acc: 30.469,54.688,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.711 | Acc: 39.211,58.185,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.734 | Acc: 38.415,57.851,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.747 | Acc: 37.833,57.326,74.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.772 | Acc: 37.375,57.234,74.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.787 | Acc: 37.237,57.039,74.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.773 | Acc: 37.700,57.199,74.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.772 | Acc: 37.694,57.286,74.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.771 | Acc: 37.796,57.487,73.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.780 | Acc: 37.871,57.381,73.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.797 | Acc: 37.795,57.389,73.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.805 | Acc: 37.656,57.335,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.806 | Acc: 37.685,57.446,73.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.820 | Acc: 37.590,57.358,73.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.829 | Acc: 37.606,57.312,73.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.828 | Acc: 37.674,57.296,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.834 | Acc: 37.612,57.299,73.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.830 | Acc: 37.683,57.402,73.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.836 | Acc: 37.602,57.300,72.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.841 | Acc: 37.611,57.277,72.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.373 | Acc: 34.375,54.688,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.689 | Acc: 32.850,52.083,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.706 | Acc: 32.755,51.867,64.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.718 | Acc: 32.748,51.601,63.678,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 4.568 | Acc: 41.406,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.641 | Acc: 38.579,59.487,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 39.634,59.889,75.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 39.472,59.439,75.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.645 | Acc: 38.927,59.018,75.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.648 | Acc: 38.769,58.981,75.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.642 | Acc: 38.830,58.942,75.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.624 | Acc: 38.979,59.098,75.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.644 | Acc: 38.786,58.909,75.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.664 | Acc: 38.536,58.693,75.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.669 | Acc: 38.511,58.706,74.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.672 | Acc: 38.522,58.626,74.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.683 | Acc: 38.541,58.574,74.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.697 | Acc: 38.395,58.387,74.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.700 | Acc: 38.373,58.458,74.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.700 | Acc: 38.468,58.438,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.704 | Acc: 38.435,58.421,74.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.708 | Acc: 38.552,58.406,74.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.715 | Acc: 38.517,58.222,74.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.729 | Acc: 38.462,58.095,73.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.294 | Acc: 32.031,53.906,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.805 | Acc: 32.068,51.711,64.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.816 | Acc: 31.860,51.029,63.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.786 | Acc: 31.954,51.332,63.537,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 4.168 | Acc: 42.188,57.031,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.661 | Acc: 37.798,57.701,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 38.739,58.594,76.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.561 | Acc: 38.947,59.311,76.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.516 | Acc: 39.130,59.703,76.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.551 | Acc: 38.815,59.244,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.562 | Acc: 38.740,59.233,76.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.579 | Acc: 38.558,59.087,76.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.610 | Acc: 38.364,58.827,76.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.609 | Acc: 38.415,58.935,75.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.609 | Acc: 38.514,59.060,75.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.606 | Acc: 38.596,59.067,75.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.625 | Acc: 38.479,58.992,75.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.637 | Acc: 38.413,58.860,75.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.640 | Acc: 38.326,58.877,75.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.631 | Acc: 38.468,59.071,75.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.630 | Acc: 38.478,59.156,75.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.631 | Acc: 38.533,59.183,75.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.635 | Acc: 38.589,59.068,74.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.636 | Acc: 38.574,59.002,74.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.593 | Acc: 33.594,54.688,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.852 | Acc: 31.362,51.488,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.831 | Acc: 31.707,50.877,64.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.829 | Acc: 31.801,50.948,64.357,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 3.968 | Acc: 44.531,65.625,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.271 | Acc: 41.406,62.202,78.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.269 | Acc: 40.949,62.538,79.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.301 | Acc: 40.100,61.732,78.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.366 | Acc: 39.767,60.754,78.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.374 | Acc: 39.573,61.054,78.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.411 | Acc: 39.159,60.744,77.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.433 | Acc: 39.107,60.627,77.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.453 | Acc: 39.019,60.593,77.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.476 | Acc: 39.106,60.432,77.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.490 | Acc: 39.043,60.456,76.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.498 | Acc: 38.910,60.428,76.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.496 | Acc: 39.017,60.464,76.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.509 | Acc: 38.901,60.372,76.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.517 | Acc: 38.918,60.201,76.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.523 | Acc: 38.943,60.169,76.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.532 | Acc: 38.977,60.005,76.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.541 | Acc: 38.911,59.982,75.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.550 | Acc: 38.870,59.866,75.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.555 | Acc: 38.849,59.824,75.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.555 | Acc: 31.250,51.562,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.609 | Acc: 36.421,52.641,64.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.593 | Acc: 35.518,52.458,64.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.615 | Acc: 35.374,52.459,64.229,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 4.325 | Acc: 35.156,60.938,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.300 | Acc: 40.365,62.351,79.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 40.701,61.700,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.326 | Acc: 40.856,61.680,79.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.353 | Acc: 40.326,61.719,79.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.366 | Acc: 40.060,61.920,79.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.373 | Acc: 39.954,61.783,79.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.369 | Acc: 40.060,61.719,78.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.378 | Acc: 40.130,61.597,78.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.376 | Acc: 40.133,61.667,78.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.387 | Acc: 40.182,61.489,78.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.404 | Acc: 40.134,61.238,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.411 | Acc: 40.100,61.142,77.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.418 | Acc: 40.098,61.126,77.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.429 | Acc: 40.019,61.079,77.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.428 | Acc: 40.080,61.202,77.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.439 | Acc: 40.090,61.054,77.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.437 | Acc: 40.137,61.043,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.448 | Acc: 40.036,61.046,76.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.456 | Acc: 39.963,60.921,76.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.340 | Acc: 39.062,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.422 | Acc: 35.045,55.729,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.446 | Acc: 35.252,55.202,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.439 | Acc: 35.041,55.085,65.958,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 4.171 | Acc: 40.625,68.750,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.330 | Acc: 39.918,61.644,79.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.302 | Acc: 39.691,61.928,79.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.306 | Acc: 39.985,61.757,79.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.298 | Acc: 40.355,61.834,79.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.303 | Acc: 40.231,61.873,79.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.306 | Acc: 40.205,61.964,79.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.330 | Acc: 39.799,61.597,79.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.338 | Acc: 39.926,61.442,78.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.341 | Acc: 39.995,61.473,78.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.349 | Acc: 39.949,61.493,78.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.354 | Acc: 40.063,61.507,78.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.338 | Acc: 40.320,61.683,78.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.348 | Acc: 40.284,61.569,78.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.353 | Acc: 40.236,61.577,78.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.352 | Acc: 40.381,61.579,78.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.352 | Acc: 40.350,61.578,78.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.347 | Acc: 40.387,61.659,78.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.352 | Acc: 40.376,61.591,78.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.354 | Acc: 40.393,61.594,78.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.487 | Acc: 29.688,54.688,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.434 | Acc: 36.049,54.576,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.458 | Acc: 36.052,54.306,65.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.490 | Acc: 35.758,53.996,65.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 4.205 | Acc: 38.281,62.500,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.195 | Acc: 40.513,61.830,81.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.159 | Acc: 40.244,62.005,81.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.174 | Acc: 40.356,62.308,81.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.165 | Acc: 40.548,62.577,81.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.174 | Acc: 40.524,62.585,81.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.188 | Acc: 40.619,62.713,80.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.196 | Acc: 40.730,62.777,80.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.189 | Acc: 40.824,62.733,80.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.189 | Acc: 40.742,62.884,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.203 | Acc: 40.734,62.706,80.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.228 | Acc: 40.583,62.528,79.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.237 | Acc: 40.719,62.588,79.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.239 | Acc: 40.766,62.575,79.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.253 | Acc: 40.653,62.439,79.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.256 | Acc: 40.682,62.433,79.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.264 | Acc: 40.630,62.376,79.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.272 | Acc: 40.568,62.292,79.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.285 | Acc: 40.560,62.154,78.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.295 | Acc: 40.504,62.078,78.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.219 | Acc: 36.719,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.802 | Acc: 33.891,52.939,64.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.774 | Acc: 33.613,53.468,64.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.786 | Acc: 33.133,53.291,64.267,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 3.731 | Acc: 49.219,68.750,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.078 | Acc: 40.737,64.695,82.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.092 | Acc: 41.235,64.310,81.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.087 | Acc: 41.842,64.165,81.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.097 | Acc: 41.512,63.696,81.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.115 | Acc: 41.275,63.668,81.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.100 | Acc: 41.451,63.869,81.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.120 | Acc: 41.168,63.664,81.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.140 | Acc: 41.149,63.369,80.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.147 | Acc: 41.225,63.424,80.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.157 | Acc: 41.235,63.375,80.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.176 | Acc: 41.233,63.288,79.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.192 | Acc: 41.228,63.148,79.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.205 | Acc: 41.077,63.048,79.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.213 | Acc: 41.048,62.962,79.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.214 | Acc: 41.092,62.866,79.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.223 | Acc: 41.121,62.855,79.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.223 | Acc: 41.102,62.844,79.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.233 | Acc: 40.986,62.792,79.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.238 | Acc: 41.033,62.758,79.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.331 | Acc: 38.281,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.522 | Acc: 35.603,54.836,65.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.573 | Acc: 35.366,53.811,64.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.569 | Acc: 35.156,53.663,64.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 3.971 | Acc: 42.969,67.969,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.042 | Acc: 40.699,65.439,82.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.068 | Acc: 40.663,64.691,81.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.095 | Acc: 40.779,64.178,81.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.099 | Acc: 40.885,64.053,81.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.113 | Acc: 40.973,63.946,81.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.122 | Acc: 41.135,64.095,81.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.116 | Acc: 41.329,64.251,81.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.111 | Acc: 41.236,64.431,81.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.121 | Acc: 41.121,64.192,80.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.122 | Acc: 41.103,64.167,80.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.119 | Acc: 41.244,64.041,80.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.121 | Acc: 41.403,64.011,80.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.129 | Acc: 41.331,63.868,80.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.133 | Acc: 41.337,63.815,80.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.140 | Acc: 41.305,63.816,80.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.141 | Acc: 41.382,63.829,80.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.148 | Acc: 41.393,63.778,80.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.152 | Acc: 41.374,63.705,79.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.145 | Acc: 41.531,63.734,80.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.076 | Acc: 42.969,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.329 | Acc: 37.388,55.469,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.309 | Acc: 37.729,55.507,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.335 | Acc: 37.321,55.341,66.176,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 3.608 | Acc: 51.562,68.750,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.963 | Acc: 42.671,64.955,82.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.982 | Acc: 41.768,64.748,82.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.997 | Acc: 41.381,64.677,82.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.990 | Acc: 41.821,64.757,82.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.015 | Acc: 41.530,64.503,82.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.039 | Acc: 41.380,64.288,82.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.030 | Acc: 41.534,64.495,82.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.055 | Acc: 41.343,64.130,81.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.039 | Acc: 41.605,64.192,81.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.054 | Acc: 41.515,64.167,81.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.062 | Acc: 41.565,64.077,81.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.071 | Acc: 41.465,64.095,81.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.072 | Acc: 41.499,64.113,81.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.092 | Acc: 41.442,63.954,81.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.099 | Acc: 41.604,63.834,81.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.099 | Acc: 41.557,63.829,80.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.105 | Acc: 41.635,63.794,80.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.112 | Acc: 41.519,63.747,80.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.116 | Acc: 41.517,63.656,80.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.502 | Acc: 32.812,53.125,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.584 | Acc: 31.808,55.952,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.606 | Acc: 32.317,54.973,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.621 | Acc: 32.544,54.623,65.599,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 3.558 | Acc: 42.969,72.656,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.956 | Acc: 42.188,65.551,84.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.961 | Acc: 41.425,65.777,83.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.951 | Acc: 41.919,65.920,83.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.967 | Acc: 42.052,65.422,83.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.960 | Acc: 42.188,65.432,83.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.961 | Acc: 42.472,65.457,83.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.964 | Acc: 42.332,65.586,83.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.967 | Acc: 42.372,65.431,83.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.967 | Acc: 42.317,65.366,83.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.965 | Acc: 42.188,65.318,83.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.975 | Acc: 42.131,65.296,82.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.977 | Acc: 42.282,65.362,82.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.991 | Acc: 42.199,65.245,82.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.001 | Acc: 42.129,65.111,82.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.007 | Acc: 42.110,65.028,82.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.014 | Acc: 42.083,65.031,82.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.013 | Acc: 42.199,64.981,81.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.022 | Acc: 42.162,64.909,81.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.030 | Acc: 42.124,64.805,81.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.245 | Acc: 42.969,54.688,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.294 | Acc: 38.393,56.250,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.388 | Acc: 37.919,54.688,65.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.390 | Acc: 38.179,54.572,65.279,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 3.610 | Acc: 40.625,69.531,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.820 | Acc: 42.671,66.220,83.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.777 | Acc: 42.530,66.959,83.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.803 | Acc: 42.661,67.072,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.811 | Acc: 42.573,66.773,83.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.834 | Acc: 42.729,66.213,83.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.863 | Acc: 42.556,66.142,83.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.864 | Acc: 42.575,66.268,83.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.874 | Acc: 42.818,66.246,83.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.885 | Acc: 42.671,66.078,83.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.901 | Acc: 42.627,65.920,83.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.921 | Acc: 42.537,65.692,82.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.935 | Acc: 42.502,65.489,82.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.949 | Acc: 42.433,65.362,82.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.955 | Acc: 42.588,65.314,82.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.970 | Acc: 42.473,65.220,82.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.977 | Acc: 42.484,65.126,82.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.985 | Acc: 42.462,65.075,82.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.998 | Acc: 42.447,64.984,81.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.000 | Acc: 42.528,64.920,81.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.175 | Acc: 32.031,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.488 | Acc: 34.524,58.036,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.479 | Acc: 35.099,57.355,66.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.514 | Acc: 35.041,56.609,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 3.854 | Acc: 41.406,68.750,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.753 | Acc: 43.750,68.006,84.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.752 | Acc: 44.074,67.797,85.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.739 | Acc: 43.916,67.738,85.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.753 | Acc: 43.798,67.390,85.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.776 | Acc: 43.804,67.365,85.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.805 | Acc: 43.434,66.942,84.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.810 | Acc: 43.384,66.916,84.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.819 | Acc: 43.415,66.770,84.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.834 | Acc: 43.275,66.665,83.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.851 | Acc: 43.284,66.418,83.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.863 | Acc: 43.283,66.240,83.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.873 | Acc: 43.273,66.046,83.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.878 | Acc: 43.286,66.032,83.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.890 | Acc: 43.149,65.914,83.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.897 | Acc: 43.169,65.812,83.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.910 | Acc: 43.047,65.688,82.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.915 | Acc: 43.037,65.641,82.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.920 | Acc: 43.090,65.601,82.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.928 | Acc: 43.088,65.453,82.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.471 | Acc: 35.938,60.156,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.494 | Acc: 34.301,56.957,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.498 | Acc: 34.280,56.002,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.502 | Acc: 34.682,55.840,66.867,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 3.663 | Acc: 42.188,72.656,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.773 | Acc: 43.638,67.448,84.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.784 | Acc: 43.274,66.883,84.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.799 | Acc: 43.430,66.919,84.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.798 | Acc: 43.528,66.840,84.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.824 | Acc: 43.023,66.515,84.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.828 | Acc: 42.930,66.406,84.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.823 | Acc: 43.024,66.367,84.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.838 | Acc: 42.862,66.319,83.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.853 | Acc: 42.736,66.298,83.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.859 | Acc: 42.724,66.255,83.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.865 | Acc: 42.594,66.120,83.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.871 | Acc: 42.557,66.134,83.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.876 | Acc: 42.598,66.179,83.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.882 | Acc: 42.657,66.050,83.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.881 | Acc: 42.714,66.040,83.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.888 | Acc: 42.694,66.012,83.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.890 | Acc: 42.744,65.925,82.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.896 | Acc: 42.778,65.798,82.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.904 | Acc: 42.770,65.707,82.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.346 | Acc: 32.812,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.337 | Acc: 36.979,58.371,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.371 | Acc: 36.166,57.412,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.405 | Acc: 35.681,56.980,65.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 4.063 | Acc: 35.156,64.062,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.765 | Acc: 43.973,66.964,84.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.782 | Acc: 43.521,66.406,84.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.733 | Acc: 43.852,66.931,85.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.741 | Acc: 44.078,66.792,85.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.722 | Acc: 44.137,66.948,85.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.723 | Acc: 44.196,66.987,85.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.715 | Acc: 44.348,67.099,85.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.741 | Acc: 44.128,66.833,84.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.762 | Acc: 43.815,66.808,84.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.771 | Acc: 43.734,66.908,84.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.788 | Acc: 43.651,66.696,84.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.791 | Acc: 43.753,66.675,84.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.796 | Acc: 43.768,66.619,84.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.813 | Acc: 43.678,66.417,83.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.814 | Acc: 43.701,66.476,83.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.825 | Acc: 43.679,66.384,83.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.831 | Acc: 43.647,66.321,83.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.841 | Acc: 43.594,66.181,83.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.848 | Acc: 43.580,66.103,83.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.442 | Acc: 38.281,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.372 | Acc: 36.161,58.110,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.385 | Acc: 36.223,57.241,65.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.394 | Acc: 36.206,57.403,65.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 3.746 | Acc: 45.312,60.938,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.659 | Acc: 44.010,69.085,85.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.719 | Acc: 43.540,68.140,85.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.714 | Acc: 43.315,68.148,85.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.703 | Acc: 43.490,67.872,85.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.711 | Acc: 43.603,67.760,85.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.722 | Acc: 43.447,67.601,85.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.733 | Acc: 43.318,67.343,85.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.735 | Acc: 43.425,67.236,84.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.747 | Acc: 43.521,67.218,84.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.751 | Acc: 43.641,67.141,84.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.755 | Acc: 43.715,67.103,84.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.764 | Acc: 43.695,67.045,84.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.774 | Acc: 43.717,66.870,84.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.785 | Acc: 43.689,66.737,84.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.792 | Acc: 43.690,66.575,84.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.803 | Acc: 43.679,66.457,83.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.810 | Acc: 43.661,66.370,83.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.820 | Acc: 43.583,66.248,83.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.831 | Acc: 43.570,66.189,83.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.319 | Acc: 38.281,53.906,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.393 | Acc: 38.616,57.180,65.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.370 | Acc: 38.662,56.460,65.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.388 | Acc: 38.448,56.160,65.023,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 3.841 | Acc: 42.969,66.406,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.717 | Acc: 43.601,67.039,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.707 | Acc: 43.617,67.588,85.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.693 | Acc: 43.584,67.290,86.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.692 | Acc: 43.673,67.602,86.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.672 | Acc: 44.036,67.845,85.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.689 | Acc: 44.124,67.672,85.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.686 | Acc: 44.282,67.753,85.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.688 | Acc: 44.192,67.843,85.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.690 | Acc: 44.320,67.710,85.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.696 | Acc: 44.216,67.634,85.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.697 | Acc: 44.227,67.672,85.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.708 | Acc: 44.145,67.580,85.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.719 | Acc: 44.079,67.424,84.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.730 | Acc: 44.059,67.310,84.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.735 | Acc: 44.157,67.237,84.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.741 | Acc: 44.079,67.139,84.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.753 | Acc: 44.112,67.057,84.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.762 | Acc: 44.034,66.960,84.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.771 | Acc: 43.912,66.939,84.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.185 | Acc: 37.500,57.031,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.242 | Acc: 37.760,57.031,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.264 | Acc: 37.767,57.317,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.287 | Acc: 38.102,57.351,66.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 4.289 | Acc: 35.156,66.406,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.689 | Acc: 42.634,68.118,85.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.627 | Acc: 43.674,68.598,86.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.603 | Acc: 44.442,68.750,86.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.614 | Acc: 44.743,68.866,86.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.630 | Acc: 44.469,68.642,86.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.644 | Acc: 44.312,68.492,85.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.647 | Acc: 44.393,68.517,85.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.656 | Acc: 44.473,68.338,85.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.672 | Acc: 44.376,68.029,85.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.671 | Acc: 44.395,67.973,85.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.683 | Acc: 44.294,67.803,85.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.693 | Acc: 44.220,67.703,85.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.694 | Acc: 44.373,67.672,85.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.703 | Acc: 44.378,67.666,85.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.711 | Acc: 44.386,67.540,85.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.716 | Acc: 44.402,67.487,85.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.724 | Acc: 44.279,67.364,84.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.730 | Acc: 44.315,67.278,84.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.733 | Acc: 44.339,67.229,84.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.192 | Acc: 37.500,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.800 | Acc: 30.134,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.845 | Acc: 29.745,57.393,66.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.832 | Acc: 29.790,57.313,66.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 3.599 | Acc: 39.844,72.656,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.613 | Acc: 43.080,69.010,86.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.616 | Acc: 43.388,68.769,86.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.585 | Acc: 43.584,69.173,87.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.552 | Acc: 44.088,69.454,87.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.578 | Acc: 44.090,69.214,87.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.597 | Acc: 44.118,68.950,86.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.601 | Acc: 44.077,69.021,86.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.624 | Acc: 44.017,68.663,86.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.632 | Acc: 44.061,68.543,86.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.640 | Acc: 44.310,68.334,86.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.647 | Acc: 44.291,68.244,85.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.668 | Acc: 44.152,68.082,85.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.679 | Acc: 44.142,67.984,85.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.690 | Acc: 44.198,67.824,85.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.699 | Acc: 44.165,67.733,85.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.705 | Acc: 44.086,67.618,85.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.709 | Acc: 44.091,67.623,85.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.715 | Acc: 44.051,67.490,84.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.722 | Acc: 44.008,67.395,84.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.087 | Acc: 39.844,57.812,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.350 | Acc: 37.835,58.259,65.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.351 | Acc: 38.129,57.298,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.381 | Acc: 37.820,57.249,65.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 3.609 | Acc: 43.750,70.312,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.562 | Acc: 44.903,70.275,85.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.603 | Acc: 45.274,69.207,85.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.577 | Acc: 45.044,69.147,86.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.549 | Acc: 45.525,69.464,86.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.568 | Acc: 45.467,69.307,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.581 | Acc: 45.325,68.950,86.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.585 | Acc: 45.335,68.756,86.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.590 | Acc: 45.225,68.634,86.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.598 | Acc: 45.136,68.543,86.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.607 | Acc: 45.044,68.408,86.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.614 | Acc: 44.892,68.389,86.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.623 | Acc: 44.823,68.189,85.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.633 | Acc: 44.858,68.044,85.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.642 | Acc: 44.890,67.966,85.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.646 | Acc: 44.884,67.995,85.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.655 | Acc: 44.831,67.901,85.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.660 | Acc: 44.825,67.914,85.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.664 | Acc: 44.806,67.828,85.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.673 | Acc: 44.701,67.774,85.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.762 | Acc: 36.719,57.812,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.809 | Acc: 32.738,57.775,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.752 | Acc: 32.774,56.803,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.777 | Acc: 32.941,56.737,65.958,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 3.411 | Acc: 45.312,71.094,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.584 | Acc: 44.717,68.676,87.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.540 | Acc: 45.351,69.627,87.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.556 | Acc: 44.762,69.467,87.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.558 | Acc: 44.811,69.271,86.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.576 | Acc: 44.701,68.943,86.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.582 | Acc: 44.318,68.827,86.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.589 | Acc: 44.476,68.717,86.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.600 | Acc: 44.570,68.575,86.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.606 | Acc: 44.553,68.551,86.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.603 | Acc: 44.609,68.622,86.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.604 | Acc: 44.655,68.676,86.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.604 | Acc: 44.703,68.624,86.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.611 | Acc: 44.675,68.612,86.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.618 | Acc: 44.737,68.458,85.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.636 | Acc: 44.607,68.189,85.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.651 | Acc: 44.541,68.064,85.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.654 | Acc: 44.536,68.049,85.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.667 | Acc: 44.497,67.899,85.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.668 | Acc: 44.556,67.950,85.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.326 | Acc: 39.062,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.302 | Acc: 36.347,59.040,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.301 | Acc: 36.681,58.079,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.327 | Acc: 36.463,57.697,66.586,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 3.377 | Acc: 35.938,64.844,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.459 | Acc: 45.089,70.685,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.455 | Acc: 45.827,70.579,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.493 | Acc: 45.351,69.454,87.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.507 | Acc: 45.544,69.271,87.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.504 | Acc: 45.800,69.206,87.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.512 | Acc: 45.706,69.383,87.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.530 | Acc: 45.495,69.121,87.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.538 | Acc: 45.492,69.114,87.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.545 | Acc: 45.334,68.914,86.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.556 | Acc: 45.141,68.785,86.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.563 | Acc: 45.224,68.736,86.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.567 | Acc: 45.309,68.659,86.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.571 | Acc: 45.324,68.624,86.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.575 | Acc: 45.326,68.608,86.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.586 | Acc: 45.229,68.506,86.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.595 | Acc: 45.149,68.490,86.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.601 | Acc: 45.102,68.420,86.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.609 | Acc: 45.070,68.352,85.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.620 | Acc: 44.980,68.293,85.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.185 | Acc: 38.281,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.273 | Acc: 38.356,58.222,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.277 | Acc: 38.777,57.241,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.284 | Acc: 39.050,56.929,65.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.009 | Acc: 46.875,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.511 | Acc: 43.713,69.345,87.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.476 | Acc: 44.836,70.065,87.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.487 | Acc: 45.018,69.992,87.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.518 | Acc: 44.917,69.464,87.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.489 | Acc: 45.320,69.802,87.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.486 | Acc: 45.235,69.912,87.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.493 | Acc: 45.301,69.814,87.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.505 | Acc: 45.240,69.575,87.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.513 | Acc: 45.295,69.454,86.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.519 | Acc: 45.219,69.372,86.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.538 | Acc: 45.199,69.121,86.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.550 | Acc: 45.202,68.948,86.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.557 | Acc: 45.295,68.891,86.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.566 | Acc: 45.376,68.833,86.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.571 | Acc: 45.427,68.737,86.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.577 | Acc: 45.373,68.653,86.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.583 | Acc: 45.441,68.665,85.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.586 | Acc: 45.486,68.573,85.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.596 | Acc: 45.479,68.465,85.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.593 | Acc: 38.281,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.549 | Acc: 34.040,58.408,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.530 | Acc: 35.061,57.851,65.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.551 | Acc: 34.939,57.633,65.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 3.842 | Acc: 46.875,65.625,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.380 | Acc: 46.689,71.391,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.452 | Acc: 45.522,70.960,87.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.479 | Acc: 45.735,70.505,87.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.471 | Acc: 45.804,70.197,87.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.486 | Acc: 45.645,69.655,87.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.478 | Acc: 45.739,69.751,87.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.478 | Acc: 45.662,69.858,87.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.494 | Acc: 45.453,69.633,87.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.497 | Acc: 45.589,69.695,87.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.498 | Acc: 45.779,69.764,87.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.498 | Acc: 45.836,69.747,87.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.502 | Acc: 45.841,69.768,87.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.508 | Acc: 45.815,69.726,87.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.524 | Acc: 45.730,69.498,86.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.526 | Acc: 45.738,69.456,86.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.537 | Acc: 45.568,69.329,86.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.544 | Acc: 45.432,69.224,86.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.550 | Acc: 45.455,69.150,86.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.561 | Acc: 45.343,69.045,86.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.212 | Acc: 39.844,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.405 | Acc: 36.830,58.668,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.425 | Acc: 36.662,57.565,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.426 | Acc: 36.475,57.659,65.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.258 | Acc: 46.875,71.094,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.393 | Acc: 45.908,70.573,88.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.403 | Acc: 46.361,71.056,87.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.404 | Acc: 46.196,70.761,87.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.421 | Acc: 46.132,70.448,87.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.446 | Acc: 46.132,70.104,87.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.446 | Acc: 46.397,70.248,87.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.459 | Acc: 46.011,70.091,87.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.476 | Acc: 46.060,69.915,87.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.486 | Acc: 46.202,69.760,86.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.493 | Acc: 46.296,69.698,86.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.496 | Acc: 46.299,69.666,86.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.508 | Acc: 46.197,69.515,86.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.520 | Acc: 46.022,69.322,86.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.524 | Acc: 46.013,69.306,86.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.543 | Acc: 45.894,69.108,86.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.546 | Acc: 45.894,68.991,86.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.559 | Acc: 45.839,68.803,86.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.566 | Acc: 45.810,68.720,86.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.574 | Acc: 45.786,68.627,86.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.919 | Acc: 43.750,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.260 | Acc: 38.021,58.371,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.278 | Acc: 38.586,58.041,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.260 | Acc: 38.640,58.069,67.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 3.684 | Acc: 46.875,74.219,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.470 | Acc: 46.243,69.606,86.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.399 | Acc: 46.246,70.370,88.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.382 | Acc: 46.939,71.081,87.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.376 | Acc: 46.750,71.065,87.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.398 | Acc: 46.720,70.622,87.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.419 | Acc: 46.552,70.274,87.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.418 | Acc: 46.565,70.224,87.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.407 | Acc: 46.608,70.303,88.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.404 | Acc: 46.642,70.364,87.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.418 | Acc: 46.498,70.398,87.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.432 | Acc: 46.401,70.316,87.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.442 | Acc: 46.308,70.199,87.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.459 | Acc: 46.193,70.022,87.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.472 | Acc: 46.088,69.943,87.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.479 | Acc: 46.081,69.882,87.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.493 | Acc: 45.965,69.685,87.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.500 | Acc: 45.927,69.650,86.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.502 | Acc: 45.975,69.609,86.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.510 | Acc: 45.967,69.503,86.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.405 | Acc: 34.375,55.469,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.380 | Acc: 38.095,57.850,65.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.382 | Acc: 37.957,57.641,65.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.381 | Acc: 38.192,57.569,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.453 | Acc: 44.531,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.427 | Acc: 45.015,70.796,87.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.430 | Acc: 45.865,71.170,87.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.403 | Acc: 45.927,71.580,88.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.415 | Acc: 45.409,71.296,88.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.414 | Acc: 45.668,71.163,88.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.394 | Acc: 46.113,71.281,88.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.395 | Acc: 46.061,71.271,88.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.414 | Acc: 46.016,71.089,88.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.413 | Acc: 46.089,71.025,88.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.421 | Acc: 46.067,70.857,88.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.435 | Acc: 45.966,70.786,87.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.450 | Acc: 45.805,70.546,87.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.454 | Acc: 45.863,70.447,87.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.458 | Acc: 45.919,70.340,87.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.467 | Acc: 45.863,70.185,87.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.479 | Acc: 45.814,70.047,87.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.488 | Acc: 45.750,69.969,87.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.486 | Acc: 45.849,69.951,86.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.500 | Acc: 45.677,69.816,86.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.195 | Acc: 42.969,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.510 | Acc: 34.635,58.780,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.540 | Acc: 34.661,58.365,66.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.515 | Acc: 34.849,58.081,66.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 3.932 | Acc: 44.531,67.969,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.294 | Acc: 47.507,71.763,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.274 | Acc: 47.961,71.608,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.312 | Acc: 47.426,71.427,88.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.341 | Acc: 47.164,70.920,88.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.348 | Acc: 47.092,70.978,88.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.346 | Acc: 47.011,70.913,88.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.359 | Acc: 46.753,70.922,88.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.367 | Acc: 46.831,70.788,88.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.368 | Acc: 46.910,70.839,88.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.377 | Acc: 46.805,70.709,88.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.376 | Acc: 46.833,70.730,88.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.391 | Acc: 46.625,70.582,88.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.407 | Acc: 46.462,70.408,88.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.418 | Acc: 46.319,70.279,87.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.437 | Acc: 46.127,70.167,87.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.450 | Acc: 46.030,70.023,87.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.454 | Acc: 46.036,69.978,87.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.462 | Acc: 46.037,69.819,87.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.471 | Acc: 45.960,69.697,87.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.288 | Acc: 39.062,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.420 | Acc: 36.049,57.366,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.381 | Acc: 37.062,56.955,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.375 | Acc: 37.577,56.673,66.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 3.405 | Acc: 47.656,69.531,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.449 | Acc: 45.350,70.350,87.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.348 | Acc: 46.437,71.513,88.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.384 | Acc: 45.940,71.414,88.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.366 | Acc: 45.756,71.595,88.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.384 | Acc: 45.630,71.395,88.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.364 | Acc: 45.835,71.346,88.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.379 | Acc: 45.905,71.199,88.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.377 | Acc: 46.147,71.162,88.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.385 | Acc: 46.128,71.007,88.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.399 | Acc: 46.086,70.829,88.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.413 | Acc: 45.942,70.634,88.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.423 | Acc: 45.870,70.458,88.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.427 | Acc: 45.896,70.348,87.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.425 | Acc: 45.930,70.349,87.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.434 | Acc: 45.928,70.261,87.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.444 | Acc: 45.948,70.193,87.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.448 | Acc: 45.924,70.118,87.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.460 | Acc: 45.910,69.999,87.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.466 | Acc: 45.952,69.868,87.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.101 | Acc: 35.938,61.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.411 | Acc: 36.347,57.403,66.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.464 | Acc: 37.100,56.726,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.482 | Acc: 36.591,56.865,65.625,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 3.292 | Acc: 48.438,74.219,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.451 | Acc: 45.610,69.420,87.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.399 | Acc: 46.227,70.293,88.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.370 | Acc: 46.145,70.364,88.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.341 | Acc: 46.431,71.074,88.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.368 | Acc: 46.295,70.707,88.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.377 | Acc: 46.320,70.480,88.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.366 | Acc: 46.531,70.689,88.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.371 | Acc: 46.429,70.701,88.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.380 | Acc: 46.448,70.537,88.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.393 | Acc: 46.447,70.472,88.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.402 | Acc: 46.486,70.309,88.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.416 | Acc: 46.366,70.196,88.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.419 | Acc: 46.462,70.217,87.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.431 | Acc: 46.436,70.040,87.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.437 | Acc: 46.405,70.004,87.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.445 | Acc: 46.320,69.982,87.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.446 | Acc: 46.394,69.946,87.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.452 | Acc: 46.408,69.906,87.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.454 | Acc: 46.328,69.929,87.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.961 | Acc: 34.375,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.428 | Acc: 37.314,59.635,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.471 | Acc: 37.119,58.575,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.490 | Acc: 36.488,58.145,65.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 3.662 | Acc: 39.062,69.531,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.303 | Acc: 47.061,71.615,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.330 | Acc: 46.818,71.418,88.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.298 | Acc: 47.336,71.721,88.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.312 | Acc: 46.991,71.914,88.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.321 | Acc: 46.744,71.782,88.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.331 | Acc: 46.578,71.681,88.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.340 | Acc: 46.653,71.531,88.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.352 | Acc: 46.642,71.298,88.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.359 | Acc: 46.702,71.025,88.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.363 | Acc: 46.716,70.997,88.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.367 | Acc: 46.663,70.896,88.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.369 | Acc: 46.671,70.847,88.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.386 | Acc: 46.573,70.687,88.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.393 | Acc: 46.533,70.604,88.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.405 | Acc: 46.449,70.463,87.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.408 | Acc: 46.481,70.410,87.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.414 | Acc: 46.460,70.331,87.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.418 | Acc: 46.468,70.198,87.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.428 | Acc: 46.401,70.107,87.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.107 | Acc: 43.750,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.383 | Acc: 39.807,56.585,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.412 | Acc: 39.596,55.945,65.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.449 | Acc: 39.562,55.917,66.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 3.415 | Acc: 44.531,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.385 | Acc: 45.908,71.429,88.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.336 | Acc: 46.818,71.151,89.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.346 | Acc: 46.465,71.132,89.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.355 | Acc: 46.074,71.036,88.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.339 | Acc: 46.481,71.372,89.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.338 | Acc: 46.643,71.326,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.336 | Acc: 46.731,71.332,88.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.348 | Acc: 46.720,71.036,88.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.355 | Acc: 46.810,70.930,88.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.360 | Acc: 46.665,70.888,88.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.371 | Acc: 46.628,70.680,88.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.376 | Acc: 46.609,70.705,88.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.387 | Acc: 46.591,70.549,88.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.391 | Acc: 46.603,70.474,88.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.393 | Acc: 46.631,70.502,88.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.395 | Acc: 46.542,70.468,88.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.404 | Acc: 46.479,70.335,88.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.408 | Acc: 46.550,70.328,87.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.413 | Acc: 46.526,70.294,87.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.145 | Acc: 40.625,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.370 | Acc: 36.942,58.668,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.355 | Acc: 37.557,57.908,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.371 | Acc: 37.359,57.761,66.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.108 | Acc: 47.656,72.656,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.306 | Acc: 47.619,71.689,87.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.298 | Acc: 47.409,71.646,88.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.288 | Acc: 47.592,71.773,88.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.292 | Acc: 47.512,72.106,88.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.326 | Acc: 47.099,71.581,88.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.311 | Acc: 47.314,71.849,88.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.309 | Acc: 47.291,71.864,88.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.319 | Acc: 47.224,71.793,88.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.333 | Acc: 47.065,71.577,88.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.346 | Acc: 46.929,71.393,88.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.346 | Acc: 46.967,71.430,88.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.357 | Acc: 47.040,71.314,88.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.367 | Acc: 46.920,71.240,88.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.377 | Acc: 47.006,71.119,87.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.388 | Acc: 46.974,70.959,87.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.388 | Acc: 47.009,70.928,87.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.390 | Acc: 47.017,70.890,87.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.396 | Acc: 46.981,70.832,87.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.399 | Acc: 46.996,70.772,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.728 | Acc: 42.188,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.058 | Acc: 40.513,59.673,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.070 | Acc: 40.644,59.432,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.078 | Acc: 40.689,59.606,67.021,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 3.226 | Acc: 42.188,76.562,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.228 | Acc: 46.875,73.140,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.180 | Acc: 47.923,73.361,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.184 | Acc: 48.079,73.169,89.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.184 | Acc: 47.994,73.129,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.205 | Acc: 47.780,72.912,89.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.234 | Acc: 47.495,72.379,89.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.262 | Acc: 47.174,72.058,89.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.279 | Acc: 47.074,71.802,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.278 | Acc: 47.289,71.771,89.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.285 | Acc: 47.330,71.708,88.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.287 | Acc: 47.469,71.734,88.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.304 | Acc: 47.293,71.638,88.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.314 | Acc: 47.321,71.546,88.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.331 | Acc: 47.311,71.383,88.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.340 | Acc: 47.168,71.283,88.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.350 | Acc: 47.145,71.159,88.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.357 | Acc: 47.200,71.096,88.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.361 | Acc: 47.252,71.037,87.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.373 | Acc: 47.170,70.977,87.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.557 | Acc: 46.875,61.719,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.148 | Acc: 41.667,58.631,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.154 | Acc: 41.197,58.594,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.193 | Acc: 40.804,57.684,67.777,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 3.475 | Acc: 48.438,67.969,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.275 | Acc: 46.726,71.057,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.264 | Acc: 46.818,71.989,89.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.277 | Acc: 46.913,71.926,89.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.277 | Acc: 46.692,71.856,89.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.299 | Acc: 46.890,71.635,89.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.281 | Acc: 47.017,71.869,89.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.273 | Acc: 46.908,71.820,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.280 | Acc: 46.778,71.695,89.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.293 | Acc: 46.728,71.681,89.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.297 | Acc: 46.801,71.700,88.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.320 | Acc: 46.656,71.507,88.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.327 | Acc: 46.706,71.457,88.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.339 | Acc: 46.683,71.279,88.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.348 | Acc: 46.566,71.144,88.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.353 | Acc: 46.595,71.112,88.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.357 | Acc: 46.590,71.062,88.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.366 | Acc: 46.563,70.972,88.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.370 | Acc: 46.661,70.942,88.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.375 | Acc: 46.766,70.883,87.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.237 | Acc: 32.031,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.566 | Acc: 34.970,58.519,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.552 | Acc: 36.128,58.251,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.550 | Acc: 35.681,57.877,66.598,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 3.017 | Acc: 47.656,74.219,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.316 | Acc: 47.396,71.540,87.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.270 | Acc: 47.828,71.780,87.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.248 | Acc: 47.669,72.541,88.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.246 | Acc: 47.550,72.840,88.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.236 | Acc: 47.780,72.904,88.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.236 | Acc: 47.940,72.921,88.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.256 | Acc: 47.850,72.656,88.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.270 | Acc: 47.778,72.559,88.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.284 | Acc: 47.570,72.333,88.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.289 | Acc: 47.505,72.151,88.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.304 | Acc: 47.352,71.946,88.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.306 | Acc: 47.345,71.856,88.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.312 | Acc: 47.300,71.815,88.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.318 | Acc: 47.289,71.780,88.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.324 | Acc: 47.228,71.680,88.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.332 | Acc: 47.179,71.644,87.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.344 | Acc: 47.134,71.451,87.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.355 | Acc: 47.024,71.330,87.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.359 | Acc: 46.959,71.278,87.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.037 | Acc: 41.406,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.205 | Acc: 39.249,59.673,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.249 | Acc: 39.615,59.089,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.276 | Acc: 39.344,59.209,66.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.560 | Acc: 43.750,70.312,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.148 | Acc: 48.140,74.182,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.072 | Acc: 48.838,74.581,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.095 | Acc: 48.527,74.206,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.114 | Acc: 48.380,74.055,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.148 | Acc: 48.074,73.608,90.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.183 | Acc: 47.908,73.244,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.212 | Acc: 47.678,72.944,89.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.217 | Acc: 47.773,72.744,89.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.222 | Acc: 47.894,72.661,89.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.226 | Acc: 47.893,72.785,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.241 | Acc: 47.748,72.674,89.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.249 | Acc: 47.637,72.549,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.256 | Acc: 47.674,72.450,88.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.266 | Acc: 47.539,72.331,88.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.280 | Acc: 47.521,72.054,88.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.297 | Acc: 47.459,71.865,88.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.310 | Acc: 47.466,71.776,88.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.321 | Acc: 47.390,71.639,88.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.334 | Acc: 47.365,71.514,88.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.440 | Acc: 39.844,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.704 | Acc: 34.635,57.515,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.667 | Acc: 35.004,57.184,65.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.667 | Acc: 34.951,57.377,64.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 2.718 | Acc: 53.125,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.153 | Acc: 47.470,73.996,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.198 | Acc: 47.904,73.075,88.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.206 | Acc: 47.887,73.015,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.218 | Acc: 47.695,72.704,89.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.219 | Acc: 47.571,72.710,89.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.206 | Acc: 47.656,72.708,89.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.208 | Acc: 47.773,72.734,89.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.222 | Acc: 47.807,72.501,89.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.225 | Acc: 47.885,72.548,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.227 | Acc: 47.921,72.466,89.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.240 | Acc: 47.798,72.359,89.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.237 | Acc: 47.854,72.394,89.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.246 | Acc: 47.830,72.255,89.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.254 | Acc: 47.829,72.136,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.264 | Acc: 47.742,72.096,88.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.280 | Acc: 47.530,71.914,88.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.291 | Acc: 47.464,71.786,88.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.301 | Acc: 47.375,71.641,88.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.315 | Acc: 47.283,71.448,88.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.799 | Acc: 47.656,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.158 | Acc: 41.071,60.342,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.163 | Acc: 40.263,59.318,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.188 | Acc: 40.049,58.517,66.842,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 3.010 | Acc: 51.562,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.246 | Acc: 48.475,71.801,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.273 | Acc: 47.942,71.665,89.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.246 | Acc: 47.848,72.323,89.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.235 | Acc: 47.666,72.367,89.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.220 | Acc: 47.803,72.494,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.231 | Acc: 47.689,72.463,89.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.231 | Acc: 47.872,72.484,89.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.243 | Acc: 47.807,72.181,89.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.249 | Acc: 47.682,72.125,89.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.258 | Acc: 47.641,71.984,89.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.271 | Acc: 47.547,71.833,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.273 | Acc: 47.527,71.849,88.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.272 | Acc: 47.602,71.824,88.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.280 | Acc: 47.528,71.703,88.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.284 | Acc: 47.568,71.763,88.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.296 | Acc: 47.571,71.741,88.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.299 | Acc: 47.555,71.694,88.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.309 | Acc: 47.492,71.559,88.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.318 | Acc: 47.398,71.453,88.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.652 | Acc: 45.312,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.446 | Acc: 37.426,58.557,66.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.439 | Acc: 37.443,57.927,66.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.406 | Acc: 37.410,58.338,66.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 3.193 | Acc: 48.438,71.094,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.202 | Acc: 48.958,72.247,89.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.201 | Acc: 48.533,72.713,89.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.192 | Acc: 48.489,72.579,89.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.193 | Acc: 48.380,72.801,89.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.198 | Acc: 48.105,72.618,89.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.235 | Acc: 47.837,72.191,89.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.229 | Acc: 47.906,72.324,89.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.227 | Acc: 47.943,72.385,89.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.240 | Acc: 47.764,72.186,89.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.253 | Acc: 47.785,72.100,89.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.271 | Acc: 47.653,71.939,88.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.272 | Acc: 47.721,71.907,88.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.273 | Acc: 47.776,71.947,88.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.287 | Acc: 47.615,71.747,88.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.292 | Acc: 47.524,71.657,88.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.301 | Acc: 47.522,71.507,88.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.305 | Acc: 47.505,71.547,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.307 | Acc: 47.505,71.557,88.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.309 | Acc: 47.568,71.535,88.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.991 | Acc: 40.625,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.214 | Acc: 40.290,60.268,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.228 | Acc: 40.701,59.985,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.234 | Acc: 40.369,59.631,66.765,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 3.160 | Acc: 53.125,75.000,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.191 | Acc: 48.028,73.214,88.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.180 | Acc: 48.095,73.285,89.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.171 | Acc: 48.578,73.169,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.172 | Acc: 48.428,73.139,89.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.158 | Acc: 48.801,73.236,89.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.177 | Acc: 48.470,72.908,89.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.194 | Acc: 48.232,72.806,89.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.197 | Acc: 48.234,72.792,89.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.195 | Acc: 48.248,72.738,89.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.198 | Acc: 48.224,72.722,89.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.218 | Acc: 48.070,72.533,89.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.227 | Acc: 48.061,72.332,89.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.243 | Acc: 47.971,72.108,88.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.258 | Acc: 47.873,71.964,88.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.267 | Acc: 47.864,71.852,88.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.281 | Acc: 47.841,71.765,88.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.287 | Acc: 47.888,71.598,88.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.293 | Acc: 47.905,71.568,88.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.299 | Acc: 47.888,71.420,88.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.375 | Acc: 47.656,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.239 | Acc: 37.351,60.603,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.255 | Acc: 38.148,59.356,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.263 | Acc: 38.038,59.042,67.469,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 3.091 | Acc: 46.875,77.344,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.183 | Acc: 46.354,73.586,90.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.195 | Acc: 47.123,72.980,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.190 | Acc: 47.093,72.925,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.191 | Acc: 47.541,72.811,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.205 | Acc: 47.842,72.571,89.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.202 | Acc: 48.018,72.747,89.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.208 | Acc: 48.077,72.806,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.219 | Acc: 47.894,72.719,89.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.209 | Acc: 47.932,72.756,89.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.210 | Acc: 47.998,72.707,89.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.224 | Acc: 47.999,72.586,89.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.239 | Acc: 47.873,72.358,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.244 | Acc: 47.914,72.303,89.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.246 | Acc: 47.959,72.256,89.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.251 | Acc: 47.970,72.251,89.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.259 | Acc: 47.946,72.228,88.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.259 | Acc: 47.979,72.187,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.267 | Acc: 47.942,72.089,88.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.268 | Acc: 47.900,72.031,88.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.452 | Acc: 38.281,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.365 | Acc: 38.058,58.668,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.366 | Acc: 39.386,57.927,65.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.377 | Acc: 39.690,57.825,65.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.088 | Acc: 52.344,78.125,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.219 | Acc: 47.582,72.917,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.159 | Acc: 48.171,73.495,89.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.120 | Acc: 48.796,73.758,90.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.127 | Acc: 48.495,73.669,90.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.117 | Acc: 48.793,73.623,90.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.130 | Acc: 48.676,73.747,90.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.127 | Acc: 48.803,73.753,90.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.145 | Acc: 48.670,73.646,90.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.155 | Acc: 48.701,73.593,89.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.152 | Acc: 48.752,73.651,89.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.166 | Acc: 48.650,73.353,89.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.174 | Acc: 48.509,73.172,89.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.193 | Acc: 48.270,72.896,89.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.200 | Acc: 48.109,72.876,89.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.198 | Acc: 48.186,72.835,89.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.203 | Acc: 48.182,72.776,89.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.210 | Acc: 48.144,72.681,89.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.224 | Acc: 48.013,72.589,89.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.241 | Acc: 47.890,72.396,88.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.929 | Acc: 41.406,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.183 | Acc: 42.039,59.598,66.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.187 | Acc: 41.425,58.632,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.163 | Acc: 41.650,58.376,66.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 2.789 | Acc: 55.469,80.469,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.209 | Acc: 48.586,71.540,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.144 | Acc: 48.780,72.828,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.145 | Acc: 48.373,72.976,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.151 | Acc: 48.370,73.351,90.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.132 | Acc: 48.554,73.530,90.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.122 | Acc: 48.670,73.638,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.127 | Acc: 48.654,73.648,90.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.135 | Acc: 48.772,73.515,90.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.144 | Acc: 48.947,73.399,89.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.154 | Acc: 48.811,73.282,89.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.164 | Acc: 48.749,73.194,89.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.173 | Acc: 48.609,73.078,89.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.189 | Acc: 48.470,72.896,89.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.208 | Acc: 48.374,72.704,89.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.213 | Acc: 48.417,72.630,89.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.219 | Acc: 48.472,72.522,89.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.224 | Acc: 48.339,72.475,88.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.236 | Acc: 48.301,72.416,88.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.245 | Acc: 48.196,72.330,88.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.961 | Acc: 47.656,60.156,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.255 | Acc: 41.481,58.408,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.282 | Acc: 41.349,58.289,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.272 | Acc: 41.432,58.133,67.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 3.271 | Acc: 48.438,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.166 | Acc: 48.251,73.847,89.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.126 | Acc: 48.761,74.028,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.112 | Acc: 48.642,73.937,90.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.126 | Acc: 48.563,73.708,90.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.133 | Acc: 48.724,73.554,89.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.157 | Acc: 48.483,73.011,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.168 | Acc: 48.570,72.955,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.185 | Acc: 48.331,72.719,89.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.189 | Acc: 48.343,72.730,89.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.193 | Acc: 48.278,72.645,89.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.191 | Acc: 48.384,72.706,89.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.195 | Acc: 48.295,72.698,89.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.207 | Acc: 48.225,72.623,89.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.210 | Acc: 48.246,72.640,89.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.219 | Acc: 48.245,72.550,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.227 | Acc: 48.180,72.483,89.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.234 | Acc: 48.112,72.457,88.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.236 | Acc: 48.158,72.455,88.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.245 | Acc: 48.111,72.322,88.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.418 | Acc: 34.375,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.526 | Acc: 37.351,56.548,64.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.544 | Acc: 37.538,56.688,64.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.527 | Acc: 37.513,56.878,64.575,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 2.995 | Acc: 47.656,76.562,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.156 | Acc: 49.219,72.842,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.139 | Acc: 48.552,73.704,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.120 | Acc: 49.027,74.065,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.091 | Acc: 49.026,74.421,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.082 | Acc: 49.281,74.489,90.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.092 | Acc: 49.148,74.374,90.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.106 | Acc: 49.202,74.219,90.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.128 | Acc: 48.971,73.729,90.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.142 | Acc: 48.839,73.593,89.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.157 | Acc: 48.620,73.399,89.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.176 | Acc: 48.413,73.194,89.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.178 | Acc: 48.447,73.081,89.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.182 | Acc: 48.473,73.030,89.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.188 | Acc: 48.560,72.918,89.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.190 | Acc: 48.502,72.877,89.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.193 | Acc: 48.496,72.904,89.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.197 | Acc: 48.451,72.840,89.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.212 | Acc: 48.325,72.717,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.220 | Acc: 48.282,72.648,88.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.337 | Acc: 38.281,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.178 | Acc: 39.249,61.458,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.184 | Acc: 39.615,60.537,67.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.205 | Acc: 39.921,60.079,67.021,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 3.225 | Acc: 45.312,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.078 | Acc: 49.554,74.926,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.057 | Acc: 49.276,75.057,90.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.070 | Acc: 48.886,75.064,90.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.068 | Acc: 49.190,75.029,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.085 | Acc: 49.041,74.691,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.107 | Acc: 48.722,74.380,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.124 | Acc: 48.643,74.091,90.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.136 | Acc: 48.627,73.962,89.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.140 | Acc: 48.744,73.886,89.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.143 | Acc: 48.853,73.710,89.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.148 | Acc: 48.706,73.579,89.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.162 | Acc: 48.538,73.512,89.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.174 | Acc: 48.381,73.276,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.175 | Acc: 48.438,73.243,89.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.184 | Acc: 48.453,73.056,89.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.189 | Acc: 48.435,73.012,89.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.196 | Acc: 48.419,72.927,89.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.204 | Acc: 48.364,72.797,88.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.213 | Acc: 48.337,72.671,88.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.485 | Acc: 42.969,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.134 | Acc: 40.885,60.379,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.170 | Acc: 41.139,59.623,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.171 | Acc: 41.073,59.657,66.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 3.353 | Acc: 46.094,72.656,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.098 | Acc: 49.293,74.963,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.094 | Acc: 49.886,74.619,89.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.088 | Acc: 49.654,74.654,90.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.095 | Acc: 49.460,74.190,90.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.095 | Acc: 49.203,74.080,90.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.096 | Acc: 49.219,73.902,90.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.108 | Acc: 48.992,73.836,90.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.115 | Acc: 48.918,73.894,90.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.121 | Acc: 48.891,73.817,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.146 | Acc: 48.675,73.438,89.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.155 | Acc: 48.699,73.363,89.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.163 | Acc: 48.616,73.321,89.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.167 | Acc: 48.626,73.246,89.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.167 | Acc: 48.704,73.187,89.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.183 | Acc: 48.583,72.931,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.194 | Acc: 48.530,72.849,89.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.199 | Acc: 48.492,72.801,89.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.204 | Acc: 48.476,72.741,88.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.212 | Acc: 48.401,72.638,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.934 | Acc: 39.844,67.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.287 | Acc: 39.025,59.152,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.272 | Acc: 39.710,58.613,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.280 | Acc: 40.061,58.517,66.176,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 3.039 | Acc: 47.656,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.084 | Acc: 50.037,74.516,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.123 | Acc: 48.838,73.819,89.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.126 | Acc: 48.950,73.706,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.127 | Acc: 48.862,73.457,90.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.127 | Acc: 48.909,73.484,90.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.130 | Acc: 48.870,73.237,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.136 | Acc: 48.992,73.232,90.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.142 | Acc: 48.991,73.049,89.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.150 | Acc: 48.964,73.092,89.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.157 | Acc: 48.733,72.940,89.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.168 | Acc: 48.519,72.812,89.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.181 | Acc: 48.438,72.724,89.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.189 | Acc: 48.342,72.614,89.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.197 | Acc: 48.365,72.534,89.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.200 | Acc: 48.331,72.565,89.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.208 | Acc: 48.328,72.525,89.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.208 | Acc: 48.318,72.620,89.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.210 | Acc: 48.366,72.632,88.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.217 | Acc: 48.378,72.574,88.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.998 | Acc: 46.094,64.062,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.270 | Acc: 40.848,59.152,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.282 | Acc: 41.025,58.175,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.306 | Acc: 40.702,57.915,65.599,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 2.771 | Acc: 53.906,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.138 | Acc: 48.847,73.698,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.113 | Acc: 48.552,74.714,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.124 | Acc: 48.578,74.180,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.128 | Acc: 48.717,73.775,90.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.149 | Acc: 48.407,73.213,90.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.144 | Acc: 48.476,73.024,90.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.147 | Acc: 48.183,73.011,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.156 | Acc: 48.122,72.938,90.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.164 | Acc: 48.161,72.790,89.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.166 | Acc: 48.263,72.851,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.170 | Acc: 48.307,72.907,89.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.166 | Acc: 48.363,72.909,89.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.167 | Acc: 48.452,72.899,89.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.173 | Acc: 48.332,72.829,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.168 | Acc: 48.378,72.970,89.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.180 | Acc: 48.326,72.814,89.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.193 | Acc: 48.277,72.723,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.199 | Acc: 48.277,72.671,89.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.204 | Acc: 48.296,72.621,89.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.827 | Acc: 45.312,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.218 | Acc: 40.513,60.454,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.190 | Acc: 40.377,59.909,67.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.208 | Acc: 40.202,59.554,67.175,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 3.300 | Acc: 49.219,65.625,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.122 | Acc: 48.363,74.256,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.138 | Acc: 48.666,74.104,90.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.121 | Acc: 48.732,74.014,90.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.083 | Acc: 49.228,74.383,90.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.093 | Acc: 49.072,74.211,90.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.093 | Acc: 49.012,74.193,90.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.106 | Acc: 48.886,73.964,90.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.108 | Acc: 48.865,73.879,90.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.114 | Acc: 48.955,73.709,89.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.126 | Acc: 48.838,73.585,89.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.135 | Acc: 48.759,73.522,89.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.136 | Acc: 48.732,73.596,89.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.145 | Acc: 48.716,73.512,89.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.156 | Acc: 48.607,73.421,89.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.168 | Acc: 48.463,73.230,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.173 | Acc: 48.467,73.211,89.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.176 | Acc: 48.440,73.153,89.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.181 | Acc: 48.463,73.054,88.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.185 | Acc: 48.515,73.038,88.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.767 | Acc: 39.844,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.124 | Acc: 40.885,61.310,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.157 | Acc: 40.701,60.156,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.145 | Acc: 40.305,60.041,67.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 3.327 | Acc: 51.562,66.406,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.000 | Acc: 51.376,75.000,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.994 | Acc: 50.743,74.924,91.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.043 | Acc: 50.051,74.565,91.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.048 | Acc: 49.865,74.402,90.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.048 | Acc: 49.489,74.335,90.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.058 | Acc: 49.128,74.322,90.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.067 | Acc: 49.169,74.174,90.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.078 | Acc: 48.962,74.141,90.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.086 | Acc: 48.761,74.076,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.098 | Acc: 48.776,73.853,90.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.101 | Acc: 48.802,73.777,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.111 | Acc: 48.745,73.642,89.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.122 | Acc: 48.737,73.509,89.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.123 | Acc: 48.810,73.493,89.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.130 | Acc: 48.767,73.425,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.132 | Acc: 48.764,73.386,89.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.138 | Acc: 48.735,73.321,89.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.148 | Acc: 48.678,73.258,89.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.156 | Acc: 48.638,73.150,89.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.500 | Acc: 37.500,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.425 | Acc: 38.430,58.296,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.466 | Acc: 38.491,57.622,65.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.510 | Acc: 38.230,57.211,65.471,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 3.216 | Acc: 45.312,69.531,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.110 | Acc: 48.810,74.033,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.044 | Acc: 49.162,74.981,90.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.039 | Acc: 49.078,74.974,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.047 | Acc: 48.775,74.894,90.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.044 | Acc: 48.840,74.961,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.057 | Acc: 48.728,74.554,90.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.067 | Acc: 48.726,74.318,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.081 | Acc: 48.670,74.204,90.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.075 | Acc: 48.860,74.201,90.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.078 | Acc: 48.850,74.223,89.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.097 | Acc: 48.759,73.943,89.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.107 | Acc: 48.745,73.758,89.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.117 | Acc: 48.806,73.608,89.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.124 | Acc: 48.729,73.563,89.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.127 | Acc: 48.713,73.534,89.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.134 | Acc: 48.579,73.435,89.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.141 | Acc: 48.577,73.337,89.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.149 | Acc: 48.572,73.243,89.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.160 | Acc: 48.501,73.198,89.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.870 | Acc: 40.625,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.218 | Acc: 39.807,61.086,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.224 | Acc: 40.625,60.023,66.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.255 | Acc: 40.138,59.785,66.406,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 3.180 | Acc: 49.219,73.438,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.055 | Acc: 49.963,74.144,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.044 | Acc: 49.733,73.800,90.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.037 | Acc: 49.539,74.603,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.024 | Acc: 49.508,74.740,91.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.021 | Acc: 49.582,74.869,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.024 | Acc: 49.780,74.910,91.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.044 | Acc: 49.645,74.690,91.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.043 | Acc: 49.748,74.723,90.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.051 | Acc: 49.668,74.456,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.063 | Acc: 49.522,74.464,90.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.074 | Acc: 49.544,74.325,90.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.089 | Acc: 49.426,74.164,90.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.105 | Acc: 49.201,74.018,90.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.120 | Acc: 49.032,73.796,89.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.130 | Acc: 48.964,73.656,89.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.135 | Acc: 48.917,73.618,89.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.140 | Acc: 48.903,73.596,89.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.148 | Acc: 48.890,73.438,89.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.154 | Acc: 48.829,73.308,89.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.277 | Acc: 38.281,64.844,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.241 | Acc: 40.513,60.082,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.261 | Acc: 41.540,59.318,65.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.261 | Acc: 41.227,59.247,66.035,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 3.137 | Acc: 47.656,78.906,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.040 | Acc: 48.847,74.888,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.999 | Acc: 49.848,75.171,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.024 | Acc: 49.552,74.936,90.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.006 | Acc: 49.817,75.039,90.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.013 | Acc: 49.636,75.023,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.020 | Acc: 49.587,74.877,90.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.037 | Acc: 49.324,74.523,90.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.042 | Acc: 49.219,74.563,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.054 | Acc: 49.176,74.417,90.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.051 | Acc: 49.324,74.429,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.058 | Acc: 49.159,74.286,90.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.074 | Acc: 49.076,74.157,90.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.078 | Acc: 49.144,74.096,90.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.087 | Acc: 49.021,74.146,90.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.098 | Acc: 48.998,74.053,89.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.108 | Acc: 48.956,73.939,89.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.123 | Acc: 48.836,73.756,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.131 | Acc: 48.862,73.660,89.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.146 | Acc: 48.723,73.520,89.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.877 | Acc: 41.406,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.362 | Acc: 39.174,61.458,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.388 | Acc: 38.415,60.823,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.396 | Acc: 38.601,60.643,67.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 2.851 | Acc: 50.000,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.102 | Acc: 49.033,74.814,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.157 | Acc: 48.399,73.666,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.115 | Acc: 48.975,73.963,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.099 | Acc: 48.929,74.315,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.104 | Acc: 48.801,74.219,90.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.095 | Acc: 48.999,74.283,90.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.098 | Acc: 49.136,74.352,90.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.094 | Acc: 49.209,74.359,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.104 | Acc: 49.391,74.223,89.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.105 | Acc: 49.339,74.195,89.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.111 | Acc: 49.236,74.155,89.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.116 | Acc: 49.186,74.138,89.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.121 | Acc: 49.072,73.991,89.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.127 | Acc: 49.108,73.855,89.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.136 | Acc: 48.967,73.746,89.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.146 | Acc: 48.900,73.678,89.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.146 | Acc: 48.978,73.641,89.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.154 | Acc: 48.966,73.470,89.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.157 | Acc: 48.932,73.419,89.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.359 | Acc: 39.062,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.504 | Acc: 37.277,57.961,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.555 | Acc: 38.053,57.527,65.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.572 | Acc: 37.782,57.198,65.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 3.325 | Acc: 45.312,72.656,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.071 | Acc: 48.028,75.112,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.068 | Acc: 48.628,74.886,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.036 | Acc: 48.706,75.461,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.028 | Acc: 48.843,75.656,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.028 | Acc: 48.693,75.596,90.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.032 | Acc: 48.806,75.213,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.054 | Acc: 48.565,74.972,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.068 | Acc: 48.438,74.743,90.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.073 | Acc: 48.507,74.637,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.078 | Acc: 48.620,74.479,90.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.091 | Acc: 48.650,74.339,90.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.101 | Acc: 48.677,74.228,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.104 | Acc: 48.752,74.168,89.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.113 | Acc: 48.791,74.055,89.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.118 | Acc: 48.816,74.021,89.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.126 | Acc: 48.817,73.929,89.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.132 | Acc: 48.948,73.809,89.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.134 | Acc: 48.896,73.784,89.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.139 | Acc: 48.921,73.708,89.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.822 | Acc: 49.219,67.188,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.126 | Acc: 41.927,60.119,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.176 | Acc: 41.921,59.909,66.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.195 | Acc: 41.752,59.144,66.522,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 2.999 | Acc: 49.219,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.063 | Acc: 49.851,73.996,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.066 | Acc: 49.809,74.009,90.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.063 | Acc: 49.769,74.257,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.079 | Acc: 49.325,74.344,90.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.073 | Acc: 49.435,74.420,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.065 | Acc: 49.445,74.761,90.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.067 | Acc: 49.523,74.612,90.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.073 | Acc: 49.296,74.374,90.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.059 | Acc: 49.396,74.378,90.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.059 | Acc: 49.401,74.386,90.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.058 | Acc: 49.275,74.466,90.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.065 | Acc: 49.238,74.368,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.081 | Acc: 49.111,74.111,89.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.085 | Acc: 49.044,74.024,89.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.090 | Acc: 49.099,74.011,89.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.092 | Acc: 49.185,73.985,89.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.102 | Acc: 49.077,73.827,89.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.113 | Acc: 48.959,73.764,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.113 | Acc: 49.042,73.733,89.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.327 | Acc: 46.875,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.393 | Acc: 40.885,57.961,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.382 | Acc: 40.320,57.698,65.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.352 | Acc: 40.484,57.761,65.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 2.704 | Acc: 57.812,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.105 | Acc: 49.442,74.107,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.032 | Acc: 49.905,74.962,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.034 | Acc: 49.513,74.846,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.021 | Acc: 49.846,75.010,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.043 | Acc: 49.544,74.791,90.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.041 | Acc: 49.600,74.903,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.043 | Acc: 49.573,74.751,90.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.053 | Acc: 49.655,74.597,90.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.046 | Acc: 49.594,74.728,90.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.058 | Acc: 49.518,74.518,90.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.066 | Acc: 49.342,74.498,90.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.078 | Acc: 49.232,74.407,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.089 | Acc: 49.240,74.192,90.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.093 | Acc: 49.194,74.149,90.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.101 | Acc: 49.136,74.115,90.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.100 | Acc: 49.197,74.065,89.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.110 | Acc: 49.026,73.948,89.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.118 | Acc: 48.950,73.872,89.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.124 | Acc: 48.882,73.819,89.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.117 | Acc: 39.062,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.050 | Acc: 41.592,60.082,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.096 | Acc: 41.292,59.413,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.108 | Acc: 40.984,59.439,67.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 2.944 | Acc: 50.781,82.031,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.999 | Acc: 50.037,75.967,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.953 | Acc: 50.572,76.124,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.971 | Acc: 50.243,75.807,90.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.973 | Acc: 50.010,75.694,90.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.974 | Acc: 50.093,75.603,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.984 | Acc: 50.200,75.491,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.007 | Acc: 49.961,75.222,90.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.007 | Acc: 49.932,75.286,90.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.018 | Acc: 49.732,75.134,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.018 | Acc: 49.782,75.190,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.031 | Acc: 49.738,74.897,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.047 | Acc: 49.514,74.737,90.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.055 | Acc: 49.437,74.623,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.065 | Acc: 49.397,74.430,90.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.072 | Acc: 49.369,74.395,89.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.084 | Acc: 49.236,74.207,89.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.095 | Acc: 49.290,74.040,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.097 | Acc: 49.279,73.953,89.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.110 | Acc: 49.190,73.794,89.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.159 | Acc: 38.281,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.306 | Acc: 40.327,60.565,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.298 | Acc: 40.587,59.661,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.312 | Acc: 40.138,59.734,65.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 3.219 | Acc: 49.219,78.906,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.120 | Acc: 48.326,75.484,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.112 | Acc: 48.514,75.419,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.062 | Acc: 48.476,75.615,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.045 | Acc: 49.257,75.424,90.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.065 | Acc: 49.126,75.147,90.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.065 | Acc: 49.193,75.006,90.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.070 | Acc: 49.080,74.823,90.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.075 | Acc: 49.054,74.631,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.064 | Acc: 49.201,74.741,90.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.069 | Acc: 49.199,74.588,89.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.066 | Acc: 49.258,74.579,89.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.066 | Acc: 49.416,74.527,89.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.074 | Acc: 49.374,74.458,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.085 | Acc: 49.383,74.272,89.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.086 | Acc: 49.349,74.214,89.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.090 | Acc: 49.284,74.180,89.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.093 | Acc: 49.313,74.166,89.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.098 | Acc: 49.275,74.093,89.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.099 | Acc: 49.311,74.057,89.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.096 | Acc: 41.406,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.227 | Acc: 39.025,60.379,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.252 | Acc: 38.815,60.137,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.294 | Acc: 38.486,59.836,67.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 3.257 | Acc: 45.312,74.219,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.993 | Acc: 50.298,76.042,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.013 | Acc: 49.905,75.438,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 49.962,75.615,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.003 | Acc: 49.961,75.367,90.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.027 | Acc: 49.373,75.046,90.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.033 | Acc: 49.322,75.097,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.034 | Acc: 49.224,75.161,90.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.045 | Acc: 49.267,75.175,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.053 | Acc: 49.344,74.991,90.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.057 | Acc: 49.273,74.922,90.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.051 | Acc: 49.265,74.905,90.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.054 | Acc: 49.342,74.763,90.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.057 | Acc: 49.455,74.704,90.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.063 | Acc: 49.352,74.675,90.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.071 | Acc: 49.369,74.548,90.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.080 | Acc: 49.394,74.455,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.088 | Acc: 49.331,74.310,89.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.094 | Acc: 49.282,74.223,89.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.096 | Acc: 49.266,74.202,89.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.769 | Acc: 36.719,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.150 | Acc: 41.295,60.342,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.180 | Acc: 41.044,60.061,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.192 | Acc: 40.382,60.015,67.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 3.274 | Acc: 44.531,71.875,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.995 | Acc: 48.847,75.484,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.938 | Acc: 50.057,76.181,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.929 | Acc: 50.461,76.306,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.941 | Acc: 50.502,76.138,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.940 | Acc: 50.503,76.191,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.960 | Acc: 50.207,75.910,91.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.982 | Acc: 50.044,75.560,91.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.004 | Acc: 49.806,75.238,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.020 | Acc: 49.629,75.030,90.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.028 | Acc: 49.588,74.802,90.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.033 | Acc: 49.608,74.696,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.036 | Acc: 49.566,74.624,90.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.042 | Acc: 49.416,74.554,90.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.045 | Acc: 49.555,74.488,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.044 | Acc: 49.644,74.437,90.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.050 | Acc: 49.564,74.416,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.063 | Acc: 49.478,74.196,90.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.072 | Acc: 49.444,74.121,90.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.079 | Acc: 49.366,74.022,89.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.959 | Acc: 45.312,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.185 | Acc: 41.518,60.342,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.190 | Acc: 41.311,60.137,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.179 | Acc: 40.984,60.259,66.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 2.843 | Acc: 57.812,81.250,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.938 | Acc: 50.670,76.116,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.959 | Acc: 50.305,75.800,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.996 | Acc: 50.256,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.988 | Acc: 50.154,75.000,90.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.989 | Acc: 50.147,74.783,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.999 | Acc: 50.039,74.587,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.011 | Acc: 50.050,74.629,90.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.035 | Acc: 49.646,74.471,90.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.041 | Acc: 49.784,74.348,90.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.045 | Acc: 49.565,74.296,90.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.052 | Acc: 49.466,74.106,90.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.059 | Acc: 49.472,74.115,90.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.068 | Acc: 49.377,74.015,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.074 | Acc: 49.324,74.030,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.080 | Acc: 49.323,73.977,90.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.086 | Acc: 49.333,73.971,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.092 | Acc: 49.326,73.848,89.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.101 | Acc: 49.342,73.669,89.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.108 | Acc: 49.319,73.538,89.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.412 | Acc: 39.062,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.353 | Acc: 39.732,60.007,66.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.395 | Acc: 40.091,58.803,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.398 | Acc: 39.793,58.645,65.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 2.864 | Acc: 53.906,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.010 | Acc: 50.707,75.818,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.982 | Acc: 50.610,75.610,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.968 | Acc: 50.512,75.909,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.980 | Acc: 50.164,75.820,90.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.969 | Acc: 50.193,75.766,90.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.983 | Acc: 49.942,75.478,90.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.998 | Acc: 49.751,75.321,90.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.996 | Acc: 49.922,75.345,90.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.005 | Acc: 49.858,75.134,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.019 | Acc: 49.623,74.981,90.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.023 | Acc: 49.636,74.958,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.037 | Acc: 49.523,74.757,90.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.042 | Acc: 49.446,74.740,90.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.053 | Acc: 49.355,74.589,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.055 | Acc: 49.416,74.600,89.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.062 | Acc: 49.287,74.535,89.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.066 | Acc: 49.265,74.494,89.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.077 | Acc: 49.236,74.392,89.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.088 | Acc: 49.190,74.284,89.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.988 | Acc: 41.406,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.464 | Acc: 38.988,58.594,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.500 | Acc: 38.891,57.870,65.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.475 | Acc: 39.370,58.094,65.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 3.119 | Acc: 53.125,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.135 | Acc: 47.619,73.661,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.070 | Acc: 48.857,74.562,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.033 | Acc: 49.052,74.898,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.020 | Acc: 49.171,74.961,91.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.018 | Acc: 49.250,74.853,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.014 | Acc: 49.406,75.039,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.019 | Acc: 49.258,75.050,90.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.026 | Acc: 49.141,74.966,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.048 | Acc: 49.042,74.672,90.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.048 | Acc: 49.149,74.639,90.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.045 | Acc: 49.219,74.646,90.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.050 | Acc: 49.339,74.559,90.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.060 | Acc: 49.330,74.518,90.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.067 | Acc: 49.344,74.422,90.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.074 | Acc: 49.216,74.398,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.077 | Acc: 49.226,74.353,90.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.077 | Acc: 49.253,74.393,90.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.079 | Acc: 49.316,74.392,89.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.080 | Acc: 49.348,74.356,89.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.828 | Acc: 39.844,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.210 | Acc: 40.997,59.970,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.197 | Acc: 41.159,59.832,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.217 | Acc: 40.727,59.670,67.585,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 2.669 | Acc: 52.344,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.872 | Acc: 51.414,76.860,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.855 | Acc: 51.562,77.153,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.877 | Acc: 51.691,76.691,91.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.875 | Acc: 51.553,76.852,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.900 | Acc: 51.083,76.199,91.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.930 | Acc: 50.549,75.762,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.948 | Acc: 50.222,75.593,91.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.956 | Acc: 50.053,75.616,91.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.972 | Acc: 49.922,75.410,90.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.986 | Acc: 49.817,75.233,90.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.989 | Acc: 49.915,75.198,90.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.997 | Acc: 49.783,75.130,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.014 | Acc: 49.560,74.964,90.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.027 | Acc: 49.466,74.778,90.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.041 | Acc: 49.387,74.522,90.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.047 | Acc: 49.435,74.506,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.049 | Acc: 49.503,74.464,90.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.053 | Acc: 49.498,74.411,90.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.063 | Acc: 49.442,74.258,90.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.872 | Acc: 48.438,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.105 | Acc: 41.555,60.751,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.116 | Acc: 42.073,59.394,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.104 | Acc: 42.123,59.247,67.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 2.484 | Acc: 57.812,82.031,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.835 | Acc: 51.972,76.228,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.902 | Acc: 50.495,75.896,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.917 | Acc: 50.897,75.909,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.953 | Acc: 50.077,75.675,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.961 | Acc: 50.031,75.673,91.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.945 | Acc: 50.336,75.852,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.958 | Acc: 50.172,75.765,91.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.972 | Acc: 50.029,75.563,91.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.971 | Acc: 50.207,75.591,91.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.971 | Acc: 50.008,75.599,91.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.985 | Acc: 49.951,75.375,90.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.000 | Acc: 49.861,75.256,90.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.002 | Acc: 49.811,75.168,90.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.005 | Acc: 49.739,75.150,90.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.009 | Acc: 49.824,75.070,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.022 | Acc: 49.691,74.920,90.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.031 | Acc: 49.755,74.812,90.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.039 | Acc: 49.758,74.686,90.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.046 | Acc: 49.735,74.582,90.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.388 | Acc: 40.625,60.156,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.435 | Acc: 39.955,58.519,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.502 | Acc: 39.348,57.527,66.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.485 | Acc: 39.395,57.364,66.176,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 2.528 | Acc: 54.688,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.003 | Acc: 50.446,74.516,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.945 | Acc: 50.648,75.534,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.956 | Acc: 50.256,75.269,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.936 | Acc: 50.502,75.434,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.947 | Acc: 50.085,75.379,90.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.962 | Acc: 50.013,75.336,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.961 | Acc: 50.089,75.294,90.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.964 | Acc: 49.913,75.320,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.972 | Acc: 49.741,75.276,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.984 | Acc: 49.708,75.190,90.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.982 | Acc: 49.823,75.156,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.989 | Acc: 49.974,75.055,90.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.995 | Acc: 49.895,75.108,90.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.003 | Acc: 49.914,75.017,90.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.017 | Acc: 49.727,74.943,90.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.027 | Acc: 49.601,74.701,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.031 | Acc: 49.615,74.693,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.038 | Acc: 49.591,74.546,90.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.046 | Acc: 49.590,74.430,89.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.856 | Acc: 40.625,60.938,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.645 | Acc: 36.310,59.152,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.756 | Acc: 36.490,57.927,64.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.777 | Acc: 36.309,57.992,64.639,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 2.743 | Acc: 49.219,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.918 | Acc: 49.814,76.116,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.954 | Acc: 50.114,75.572,90.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.952 | Acc: 50.512,75.564,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.950 | Acc: 50.241,75.714,90.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.970 | Acc: 50.170,75.526,90.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.964 | Acc: 50.323,75.626,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.965 | Acc: 50.305,75.643,90.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.972 | Acc: 50.296,75.446,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.979 | Acc: 50.199,75.393,90.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.989 | Acc: 50.171,75.303,90.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.989 | Acc: 50.262,75.311,90.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.995 | Acc: 50.314,75.162,90.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.004 | Acc: 50.323,74.988,90.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.011 | Acc: 50.203,74.900,90.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.015 | Acc: 50.228,74.787,90.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.023 | Acc: 50.136,74.688,90.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.029 | Acc: 50.082,74.656,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.035 | Acc: 49.978,74.584,90.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.044 | Acc: 49.916,74.459,90.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.587 | Acc: 34.375,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.367 | Acc: 38.095,60.863,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.334 | Acc: 38.739,60.690,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.372 | Acc: 38.794,59.990,65.894,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 2.912 | Acc: 46.875,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.893 | Acc: 51.451,76.711,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.888 | Acc: 51.677,76.410,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.905 | Acc: 51.281,76.140,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.932 | Acc: 51.206,75.936,91.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.934 | Acc: 50.967,76.238,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.925 | Acc: 50.781,76.304,91.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.932 | Acc: 50.654,76.130,91.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.945 | Acc: 50.422,76.024,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.956 | Acc: 50.272,75.924,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.966 | Acc: 50.167,75.719,91.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.972 | Acc: 50.117,75.672,90.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.976 | Acc: 50.130,75.564,90.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.976 | Acc: 50.150,75.545,90.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.987 | Acc: 50.042,75.478,90.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.997 | Acc: 49.883,75.371,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.004 | Acc: 49.847,75.234,90.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.020 | Acc: 49.762,75.041,90.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.028 | Acc: 49.721,74.963,90.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.036 | Acc: 49.660,74.902,90.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.775 | Acc: 42.969,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.123 | Acc: 42.857,60.603,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.147 | Acc: 43.731,59.585,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.147 | Acc: 43.353,59.618,66.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.057 | Acc: 50.000,74.219,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.833 | Acc: 52.790,76.860,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.871 | Acc: 51.200,76.410,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.861 | Acc: 51.178,76.793,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.904 | Acc: 50.444,76.215,91.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.898 | Acc: 50.743,76.292,91.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.906 | Acc: 50.704,76.265,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.926 | Acc: 50.510,75.964,90.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.937 | Acc: 50.548,75.849,90.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.944 | Acc: 50.678,75.712,90.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.958 | Acc: 50.548,75.505,90.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.974 | Acc: 50.435,75.336,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.989 | Acc: 50.266,75.139,90.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.006 | Acc: 50.156,74.844,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.013 | Acc: 50.125,74.797,90.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.021 | Acc: 50.016,74.735,90.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.027 | Acc: 50.029,74.737,90.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.032 | Acc: 50.018,74.659,89.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.043 | Acc: 49.874,74.587,89.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.056 | Acc: 49.754,74.506,89.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.287 | Acc: 38.281,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.407 | Acc: 37.946,58.780,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.441 | Acc: 38.072,57.889,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.448 | Acc: 38.512,57.864,66.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 3.039 | Acc: 42.188,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.956 | Acc: 50.558,76.376,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.928 | Acc: 50.762,76.181,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.886 | Acc: 51.486,76.575,91.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.896 | Acc: 51.447,76.534,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.905 | Acc: 51.075,76.547,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.905 | Acc: 50.975,76.517,91.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.917 | Acc: 50.981,76.529,91.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.929 | Acc: 50.990,76.296,91.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.940 | Acc: 50.941,76.161,91.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.945 | Acc: 50.933,76.077,91.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.956 | Acc: 50.898,75.937,90.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.966 | Acc: 50.788,75.765,90.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.978 | Acc: 50.727,75.709,90.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.990 | Acc: 50.659,75.514,90.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.998 | Acc: 50.602,75.449,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.005 | Acc: 50.579,75.346,90.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.020 | Acc: 50.394,75.167,90.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.030 | Acc: 50.247,75.052,90.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.045 | Acc: 50.082,74.813,90.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.045 | Acc: 41.406,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.261 | Acc: 40.625,59.673,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.286 | Acc: 41.120,59.165,65.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.296 | Acc: 41.112,59.593,65.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 2.767 | Acc: 54.688,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.933 | Acc: 50.298,76.265,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 50.057,76.467,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.903 | Acc: 50.115,76.281,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.927 | Acc: 49.884,76.100,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.920 | Acc: 50.054,76.183,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.924 | Acc: 50.181,76.059,91.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.923 | Acc: 50.382,76.069,91.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.936 | Acc: 50.286,76.024,91.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.957 | Acc: 50.164,75.820,91.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.970 | Acc: 50.105,75.657,91.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.971 | Acc: 50.237,75.555,90.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.980 | Acc: 50.052,75.441,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.988 | Acc: 50.039,75.317,90.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.002 | Acc: 49.950,75.158,90.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.009 | Acc: 49.920,75.049,90.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.013 | Acc: 49.971,75.019,90.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.022 | Acc: 49.938,74.915,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.026 | Acc: 50.006,74.829,90.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.036 | Acc: 49.936,74.694,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.325 | Acc: 38.281,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.471 | Acc: 38.356,57.850,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.477 | Acc: 38.948,57.393,65.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.499 | Acc: 38.704,57.249,65.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 2.884 | Acc: 53.125,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.034 | Acc: 50.260,75.670,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.953 | Acc: 50.305,76.448,91.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.961 | Acc: 49.757,76.511,91.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.925 | Acc: 50.077,76.659,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.911 | Acc: 50.271,76.632,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.903 | Acc: 50.562,76.627,91.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.915 | Acc: 50.554,76.291,91.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.922 | Acc: 50.345,76.082,91.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.923 | Acc: 50.376,76.122,91.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.928 | Acc: 50.416,76.108,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.938 | Acc: 50.371,75.962,90.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.949 | Acc: 50.266,75.901,90.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.953 | Acc: 50.278,75.844,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.962 | Acc: 50.161,75.653,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.973 | Acc: 50.140,75.493,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.979 | Acc: 50.105,75.360,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.984 | Acc: 50.108,75.309,90.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.997 | Acc: 49.944,75.167,90.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.007 | Acc: 49.922,75.135,90.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.786 | Acc: 45.312,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.387 | Acc: 37.574,59.970,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.393 | Acc: 38.262,59.756,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.388 | Acc: 38.268,59.926,67.175,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 3.207 | Acc: 50.000,71.094,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.936 | Acc: 50.446,75.744,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.964 | Acc: 49.619,75.819,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.958 | Acc: 49.565,75.999,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.962 | Acc: 49.325,76.032,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.959 | Acc: 49.343,75.982,91.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.951 | Acc: 49.387,75.956,91.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.939 | Acc: 49.656,76.036,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.950 | Acc: 49.655,75.907,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.959 | Acc: 49.745,75.751,90.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.971 | Acc: 49.856,75.692,90.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.983 | Acc: 49.841,75.566,90.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.985 | Acc: 49.945,75.515,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.995 | Acc: 49.970,75.365,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.003 | Acc: 49.939,75.278,90.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.015 | Acc: 49.826,75.140,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.020 | Acc: 49.871,75.134,89.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.028 | Acc: 49.792,75.048,89.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.040 | Acc: 49.719,74.955,89.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.043 | Acc: 49.742,74.971,89.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.076 | Acc: 40.625,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.144 | Acc: 42.113,61.310,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.165 | Acc: 42.321,60.556,66.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.153 | Acc: 42.444,60.643,66.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 2.547 | Acc: 53.906,80.469,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.894 | Acc: 50.558,77.381,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 50.857,76.905,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.890 | Acc: 51.127,77.139,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.883 | Acc: 51.273,76.987,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.888 | Acc: 51.400,76.833,91.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.897 | Acc: 51.175,76.491,91.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.908 | Acc: 51.213,76.424,91.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.909 | Acc: 50.961,76.398,91.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.911 | Acc: 50.932,76.407,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.917 | Acc: 50.960,76.283,91.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.922 | Acc: 50.983,76.230,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.934 | Acc: 50.866,76.112,90.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.935 | Acc: 50.916,76.084,90.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.949 | Acc: 50.790,75.884,90.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.966 | Acc: 50.594,75.667,90.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.978 | Acc: 50.489,75.621,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.986 | Acc: 50.461,75.522,90.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.995 | Acc: 50.474,75.381,90.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.001 | Acc: 50.459,75.246,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.474 | Acc: 41.406,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.321 | Acc: 40.402,58.780,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.337 | Acc: 41.159,58.765,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.316 | Acc: 41.304,58.696,66.522,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 2.844 | Acc: 49.219,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.868 | Acc: 51.451,76.302,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.832 | Acc: 52.077,76.582,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.893 | Acc: 51.473,75.884,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.930 | Acc: 50.743,75.829,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.931 | Acc: 50.673,76.037,91.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.950 | Acc: 50.504,75.814,90.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.953 | Acc: 50.360,75.925,90.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.962 | Acc: 50.141,75.825,90.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.969 | Acc: 50.237,75.570,90.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.978 | Acc: 50.086,75.447,90.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.972 | Acc: 50.166,75.548,90.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.977 | Acc: 50.233,75.528,90.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.986 | Acc: 50.159,75.419,90.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.988 | Acc: 50.153,75.448,90.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.991 | Acc: 50.239,75.426,90.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.000 | Acc: 50.168,75.346,90.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.006 | Acc: 50.188,75.250,90.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.016 | Acc: 50.123,75.128,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.019 | Acc: 50.168,75.012,90.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.156 | Acc: 36.719,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.299 | Acc: 40.327,59.598,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.310 | Acc: 39.825,59.223,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.348 | Acc: 39.203,59.042,67.405,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 2.924 | Acc: 47.656,77.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.876 | Acc: 50.781,77.790,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.856 | Acc: 51.239,76.848,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.873 | Acc: 50.871,76.255,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.871 | Acc: 51.032,76.543,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.882 | Acc: 50.959,76.532,91.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.887 | Acc: 50.865,76.362,91.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.899 | Acc: 50.848,76.285,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.909 | Acc: 50.922,76.053,91.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.933 | Acc: 50.747,75.773,91.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.944 | Acc: 50.630,75.641,91.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.965 | Acc: 50.488,75.431,90.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.971 | Acc: 50.451,75.522,90.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.971 | Acc: 50.437,75.479,90.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.977 | Acc: 50.392,75.381,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.991 | Acc: 50.257,75.301,90.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.997 | Acc: 50.236,75.134,90.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.005 | Acc: 50.158,74.943,90.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.011 | Acc: 50.158,74.790,90.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.021 | Acc: 50.109,74.660,90.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.914 | Acc: 42.969,62.500,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.022 | Acc: 42.671,61.384,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.116 | Acc: 42.664,60.385,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.120 | Acc: 42.597,60.284,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 2.817 | Acc: 50.781,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.861 | Acc: 51.079,77.121,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.852 | Acc: 51.086,77.344,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.864 | Acc: 51.409,77.152,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.887 | Acc: 51.215,76.842,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.883 | Acc: 51.284,76.764,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.887 | Acc: 51.194,76.634,90.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.906 | Acc: 51.014,76.446,90.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.914 | Acc: 50.830,76.514,90.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.928 | Acc: 50.496,76.308,90.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.932 | Acc: 50.517,76.232,90.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.944 | Acc: 50.428,76.061,90.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.960 | Acc: 50.457,75.882,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.975 | Acc: 50.314,75.647,90.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.981 | Acc: 50.339,75.545,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.985 | Acc: 50.356,75.504,90.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.996 | Acc: 50.302,75.333,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.002 | Acc: 50.314,75.266,90.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.015 | Acc: 50.182,75.089,89.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.021 | Acc: 50.066,74.982,89.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.157 | Acc: 36.719,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.152 | Acc: 41.778,61.161,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.207 | Acc: 41.521,60.061,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.253 | Acc: 40.984,60.028,66.355,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 2.559 | Acc: 54.688,84.375,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.812 | Acc: 53.832,78.274,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.814 | Acc: 52.896,78.068,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.845 | Acc: 51.960,77.523,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.853 | Acc: 51.813,77.411,91.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.859 | Acc: 51.655,77.235,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.888 | Acc: 51.156,76.730,91.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.898 | Acc: 51.169,76.529,91.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.920 | Acc: 50.975,76.150,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.920 | Acc: 51.019,76.148,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.931 | Acc: 51.007,76.007,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.937 | Acc: 50.912,75.923,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.935 | Acc: 50.879,75.921,91.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.934 | Acc: 50.949,76.030,91.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.938 | Acc: 50.856,75.979,90.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.947 | Acc: 50.745,75.818,90.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.953 | Acc: 50.750,75.723,90.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.961 | Acc: 50.747,75.536,90.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.967 | Acc: 50.762,75.472,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.974 | Acc: 50.652,75.363,90.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.991 | Acc: 46.875,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.253 | Acc: 40.848,59.301,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.270 | Acc: 40.758,58.994,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.284 | Acc: 40.510,59.298,66.342,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 3.042 | Acc: 46.094,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.835 | Acc: 52.046,77.083,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.824 | Acc: 51.734,77.096,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.856 | Acc: 51.883,76.627,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.877 | Acc: 51.630,76.717,92.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.867 | Acc: 51.423,76.918,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.882 | Acc: 51.414,76.653,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.889 | Acc: 51.413,76.618,91.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.903 | Acc: 51.169,76.465,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.910 | Acc: 51.144,76.433,91.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.909 | Acc: 51.077,76.376,91.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.925 | Acc: 50.951,76.110,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.933 | Acc: 50.921,76.070,91.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.931 | Acc: 50.907,76.060,90.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.928 | Acc: 50.837,75.998,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.950 | Acc: 50.581,75.737,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.959 | Acc: 50.538,75.655,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.970 | Acc: 50.532,75.488,90.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.978 | Acc: 50.504,75.368,90.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.983 | Acc: 50.500,75.334,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.769 | Acc: 40.625,60.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.987 | Acc: 43.601,61.979,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.043 | Acc: 43.445,60.918,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.060 | Acc: 43.007,60.771,67.943,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 2.526 | Acc: 57.812,82.031,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.824 | Acc: 51.972,77.716,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.825 | Acc: 52.020,77.782,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.848 | Acc: 51.217,77.613,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.873 | Acc: 51.186,77.373,91.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.865 | Acc: 51.346,77.251,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.849 | Acc: 51.646,77.466,91.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.858 | Acc: 51.507,77.344,91.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.865 | Acc: 51.480,77.295,91.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.877 | Acc: 51.381,77.102,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.878 | Acc: 51.353,76.940,91.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.892 | Acc: 51.287,76.683,91.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.897 | Acc: 51.238,76.618,91.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.898 | Acc: 51.281,76.548,91.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.910 | Acc: 51.062,76.332,91.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.921 | Acc: 50.981,76.207,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.934 | Acc: 50.830,76.110,90.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.946 | Acc: 50.758,76.017,90.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.955 | Acc: 50.712,75.872,90.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.965 | Acc: 50.636,75.796,90.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.899 | Acc: 50.000,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.152 | Acc: 42.299,59.673,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.195 | Acc: 42.702,59.184,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.213 | Acc: 42.111,59.042,66.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 2.506 | Acc: 58.594,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.830 | Acc: 50.818,77.865,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.822 | Acc: 51.315,77.858,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.829 | Acc: 51.691,77.843,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.808 | Acc: 52.209,78.096,91.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.828 | Acc: 51.833,77.754,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.851 | Acc: 51.446,77.428,91.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.861 | Acc: 51.352,77.172,91.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.879 | Acc: 51.257,76.888,91.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.888 | Acc: 51.165,76.791,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.905 | Acc: 51.003,76.430,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.924 | Acc: 50.788,76.202,91.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.933 | Acc: 50.778,75.998,90.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.936 | Acc: 50.841,75.955,90.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.948 | Acc: 50.703,75.806,90.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.952 | Acc: 50.688,75.698,90.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.963 | Acc: 50.650,75.657,90.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.965 | Acc: 50.729,75.603,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.972 | Acc: 50.645,75.498,90.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.980 | Acc: 50.611,75.414,90.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.385 | Acc: 39.062,60.938,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.561 | Acc: 38.132,59.003,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.659 | Acc: 37.519,57.965,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.697 | Acc: 37.500,57.505,65.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.826 | Acc: 53.906,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.842 | Acc: 51.637,77.530,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.852 | Acc: 50.953,76.925,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.849 | Acc: 51.217,76.678,91.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.860 | Acc: 51.196,76.881,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.865 | Acc: 51.106,77.019,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.871 | Acc: 51.123,76.692,91.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.888 | Acc: 51.025,76.441,91.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.896 | Acc: 50.903,76.334,91.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.899 | Acc: 50.868,76.325,91.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.910 | Acc: 50.793,76.162,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.914 | Acc: 50.831,76.071,91.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.925 | Acc: 50.739,75.888,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.923 | Acc: 50.862,75.958,91.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.932 | Acc: 50.776,75.848,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.946 | Acc: 50.600,75.696,90.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.964 | Acc: 50.489,75.528,90.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.972 | Acc: 50.550,75.472,90.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.975 | Acc: 50.571,75.452,90.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.982 | Acc: 50.547,75.330,90.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.853 | Acc: 41.406,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.109 | Acc: 40.551,61.049,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.164 | Acc: 40.663,60.899,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.188 | Acc: 40.638,60.758,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.653 | Acc: 56.250,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.931 | Acc: 51.525,76.637,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.911 | Acc: 51.505,76.277,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.916 | Acc: 50.909,76.012,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.919 | Acc: 50.781,76.032,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.901 | Acc: 51.006,76.122,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.891 | Acc: 51.175,76.285,91.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.887 | Acc: 51.169,76.446,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.893 | Acc: 51.068,76.373,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.915 | Acc: 50.859,76.131,91.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.922 | Acc: 50.847,76.061,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.931 | Acc: 50.781,75.926,91.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.944 | Acc: 50.707,75.853,91.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.954 | Acc: 50.644,75.796,90.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.955 | Acc: 50.720,75.731,90.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.966 | Acc: 50.646,75.553,90.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.972 | Acc: 50.557,75.477,90.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.979 | Acc: 50.525,75.451,90.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.979 | Acc: 50.537,75.409,90.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.987 | Acc: 50.537,75.355,90.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.213 | Acc: 41.406,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.169 | Acc: 40.513,60.677,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.245 | Acc: 40.320,60.061,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.253 | Acc: 40.177,60.028,66.547,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 2.474 | Acc: 54.688,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.911 | Acc: 50.670,76.674,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.853 | Acc: 51.410,76.867,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.867 | Acc: 51.063,76.294,91.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.857 | Acc: 51.466,76.312,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.865 | Acc: 51.485,76.493,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.865 | Acc: 51.337,76.672,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.864 | Acc: 51.330,76.817,91.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.880 | Acc: 51.247,76.742,91.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.882 | Acc: 51.329,76.731,91.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.887 | Acc: 51.236,76.539,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.906 | Acc: 50.979,76.205,91.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.925 | Acc: 50.917,76.083,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.937 | Acc: 50.799,75.964,90.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.945 | Acc: 50.734,75.815,90.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.949 | Acc: 50.784,75.781,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.950 | Acc: 50.876,75.716,90.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.956 | Acc: 50.779,75.687,90.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.965 | Acc: 50.693,75.599,90.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.973 | Acc: 50.630,75.517,90.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.948 | Acc: 50.000,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.208 | Acc: 41.555,61.161,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.238 | Acc: 42.588,60.290,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.256 | Acc: 42.405,59.951,66.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 2.839 | Acc: 52.344,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.994 | Acc: 49.591,76.265,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.921 | Acc: 50.457,76.867,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.877 | Acc: 50.602,76.767,91.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.866 | Acc: 50.974,77.016,91.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.874 | Acc: 50.650,76.740,91.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.867 | Acc: 50.775,76.814,91.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.887 | Acc: 50.748,76.474,90.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.895 | Acc: 50.835,76.368,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.913 | Acc: 50.492,76.204,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.906 | Acc: 50.785,76.170,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.910 | Acc: 50.802,76.191,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.924 | Acc: 50.733,75.943,90.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.931 | Acc: 50.787,75.904,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.941 | Acc: 50.742,75.815,90.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.949 | Acc: 50.711,75.742,90.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.957 | Acc: 50.801,75.630,90.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.963 | Acc: 50.768,75.495,90.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.968 | Acc: 50.712,75.396,90.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.975 | Acc: 50.646,75.344,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.778 | Acc: 42.969,60.156,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.091 | Acc: 42.448,61.235,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.060 | Acc: 42.321,60.652,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.102 | Acc: 42.175,60.361,67.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 3.042 | Acc: 45.312,74.219,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.900 | Acc: 51.711,77.009,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.899 | Acc: 51.162,76.601,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.900 | Acc: 50.922,76.537,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.875 | Acc: 51.225,76.746,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.867 | Acc: 51.462,76.810,92.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.861 | Acc: 51.375,76.982,92.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.855 | Acc: 51.396,76.973,91.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.857 | Acc: 51.417,76.849,91.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.865 | Acc: 51.351,76.714,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.868 | Acc: 51.376,76.578,91.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.872 | Acc: 51.280,76.531,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.875 | Acc: 51.280,76.478,91.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.882 | Acc: 51.227,76.428,91.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.899 | Acc: 51.062,76.259,91.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.909 | Acc: 51.004,76.202,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.922 | Acc: 50.888,76.054,90.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.926 | Acc: 50.930,76.063,90.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.936 | Acc: 50.842,75.991,90.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.942 | Acc: 50.859,75.874,90.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.193 | Acc: 39.062,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.171 | Acc: 41.109,61.384,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.053 | Acc: 41.311,61.814,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.104 | Acc: 41.201,61.194,67.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 2.706 | Acc: 56.250,71.875,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.758 | Acc: 53.311,77.046,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.786 | Acc: 52.572,77.630,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.767 | Acc: 52.715,77.856,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.770 | Acc: 52.662,77.826,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.788 | Acc: 52.491,77.738,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.813 | Acc: 52.266,77.382,91.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.821 | Acc: 51.950,77.349,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.844 | Acc: 51.533,77.023,91.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.857 | Acc: 51.485,76.739,91.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.869 | Acc: 51.314,76.516,91.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.875 | Acc: 51.290,76.464,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.887 | Acc: 51.274,76.313,91.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.901 | Acc: 51.194,76.137,91.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.909 | Acc: 51.193,76.132,90.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.922 | Acc: 51.046,75.999,90.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.930 | Acc: 50.918,75.920,90.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.940 | Acc: 50.729,75.806,90.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.952 | Acc: 50.708,75.727,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.959 | Acc: 50.757,75.675,90.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.389 | Acc: 39.062,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.450 | Acc: 37.686,60.379,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.491 | Acc: 38.167,59.966,65.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.467 | Acc: 37.999,59.862,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 2.710 | Acc: 52.344,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.780 | Acc: 50.856,78.460,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.836 | Acc: 50.762,77.649,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.837 | Acc: 51.409,77.536,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.840 | Acc: 51.553,77.209,91.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.858 | Acc: 51.400,77.243,91.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.864 | Acc: 51.356,77.247,91.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.860 | Acc: 51.346,77.388,91.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.874 | Acc: 51.364,77.159,91.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.874 | Acc: 51.230,77.011,91.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.879 | Acc: 51.220,76.920,91.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.884 | Acc: 51.248,76.768,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.898 | Acc: 51.112,76.595,91.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.904 | Acc: 51.093,76.488,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.913 | Acc: 51.073,76.362,90.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.924 | Acc: 51.049,76.238,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.927 | Acc: 50.998,76.139,90.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.931 | Acc: 50.999,76.061,90.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.942 | Acc: 50.920,75.922,90.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.949 | Acc: 50.863,75.876,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.881 | Acc: 47.656,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.142 | Acc: 42.485,60.789,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.234 | Acc: 42.264,60.137,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.270 | Acc: 41.675,59.721,67.354,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.266 | Acc: 57.031,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.807 | Acc: 51.525,77.567,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.818 | Acc: 51.067,77.801,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.816 | Acc: 51.729,77.613,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.834 | Acc: 51.842,77.402,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.837 | Acc: 51.717,77.537,91.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.838 | Acc: 51.511,77.376,91.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.857 | Acc: 51.263,77.067,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.865 | Acc: 51.451,76.917,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.879 | Acc: 51.472,76.727,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.879 | Acc: 51.493,76.730,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.893 | Acc: 51.280,76.552,91.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.898 | Acc: 51.248,76.475,91.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.903 | Acc: 51.248,76.338,91.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.904 | Acc: 51.393,76.298,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.918 | Acc: 51.248,76.100,91.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.932 | Acc: 51.115,75.920,90.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.939 | Acc: 51.056,75.871,90.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.940 | Acc: 51.060,75.876,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.948 | Acc: 51.025,75.746,90.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.048 | Acc: 42.969,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.371 | Acc: 39.844,59.859,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.404 | Acc: 39.653,59.642,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.407 | Acc: 38.998,58.952,66.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 3.088 | Acc: 54.688,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.936 | Acc: 51.153,75.260,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.905 | Acc: 50.362,76.448,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.867 | Acc: 50.871,76.960,91.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.855 | Acc: 51.167,76.861,91.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.863 | Acc: 50.859,76.972,91.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.862 | Acc: 50.917,77.008,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.881 | Acc: 50.981,76.729,91.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.885 | Acc: 50.970,76.529,91.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.885 | Acc: 51.032,76.429,91.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.894 | Acc: 51.112,76.384,90.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.909 | Acc: 50.962,76.223,90.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.912 | Acc: 50.989,76.261,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.927 | Acc: 50.886,76.057,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.931 | Acc: 50.917,76.006,90.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.934 | Acc: 50.901,75.966,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.941 | Acc: 50.830,75.896,90.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.947 | Acc: 50.774,75.825,90.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.954 | Acc: 50.701,75.779,90.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.962 | Acc: 50.591,75.681,90.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.839 | Acc: 39.062,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.213 | Acc: 39.695,60.975,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.192 | Acc: 40.339,61.319,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.248 | Acc: 39.882,60.707,65.868,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 2.832 | Acc: 44.531,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.828 | Acc: 51.674,78.311,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.836 | Acc: 51.143,78.106,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.822 | Acc: 51.383,77.984,91.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.829 | Acc: 51.408,77.652,91.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 51.300,77.468,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.851 | Acc: 50.917,77.376,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.862 | Acc: 50.914,77.017,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.878 | Acc: 50.762,76.703,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.889 | Acc: 50.617,76.532,91.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.900 | Acc: 50.665,76.318,91.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.909 | Acc: 50.753,76.181,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.919 | Acc: 50.639,76.086,90.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.920 | Acc: 50.685,76.012,90.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.926 | Acc: 50.770,75.909,90.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.935 | Acc: 50.760,75.833,90.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.942 | Acc: 50.716,75.747,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.951 | Acc: 50.680,75.658,90.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.955 | Acc: 50.729,75.617,90.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.955 | Acc: 50.742,75.603,90.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.056 | Acc: 45.312,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.155 | Acc: 42.225,60.417,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.227 | Acc: 41.921,59.280,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.275 | Acc: 41.714,58.696,67.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 2.842 | Acc: 52.344,78.125,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.760 | Acc: 52.641,78.162,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.821 | Acc: 50.838,77.439,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.826 | Acc: 51.101,77.113,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.839 | Acc: 51.177,77.189,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.842 | Acc: 51.075,77.027,91.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.852 | Acc: 51.104,76.911,91.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.856 | Acc: 51.280,76.928,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.852 | Acc: 51.427,76.941,91.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.866 | Acc: 51.338,76.856,91.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.872 | Acc: 51.283,76.776,91.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.877 | Acc: 51.262,76.661,91.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.880 | Acc: 51.183,76.595,91.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.886 | Acc: 51.155,76.458,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.899 | Acc: 51.037,76.348,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.905 | Acc: 51.056,76.274,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.921 | Acc: 50.883,76.076,90.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.930 | Acc: 50.839,76.015,90.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.938 | Acc: 50.805,75.937,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.945 | Acc: 50.707,75.810,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.008 | Acc: 44.531,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.907 | Acc: 45.201,62.872,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.978 | Acc: 44.798,61.357,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.014 | Acc: 44.467,61.270,67.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 2.357 | Acc: 57.812,84.375,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.804 | Acc: 52.158,77.641,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.825 | Acc: 51.562,77.229,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.796 | Acc: 51.755,78.112,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.786 | Acc: 51.919,78.424,92.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.804 | Acc: 51.856,77.769,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.825 | Acc: 51.575,77.344,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.829 | Acc: 51.346,77.316,91.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.840 | Acc: 51.140,77.140,91.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 51.066,76.847,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.854 | Acc: 51.294,76.710,91.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.867 | Acc: 51.149,76.545,91.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.875 | Acc: 51.102,76.293,91.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.886 | Acc: 51.060,76.245,91.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 51.070,76.254,91.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.910 | Acc: 50.919,76.007,91.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.915 | Acc: 50.986,75.971,91.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.927 | Acc: 50.896,75.898,90.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.933 | Acc: 50.952,75.855,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.936 | Acc: 50.962,75.800,90.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.362 | Acc: 39.844,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.387 | Acc: 40.179,60.193,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.437 | Acc: 40.263,59.280,66.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.470 | Acc: 40.010,59.004,66.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 2.680 | Acc: 54.688,77.344,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.902 | Acc: 51.451,75.818,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.882 | Acc: 50.915,75.953,90.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.873 | Acc: 50.973,76.306,91.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.883 | Acc: 50.627,76.408,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.873 | Acc: 50.657,76.586,91.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.881 | Acc: 50.542,76.537,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.874 | Acc: 50.604,76.701,91.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.880 | Acc: 50.568,76.601,91.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.883 | Acc: 50.570,76.558,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.887 | Acc: 50.645,76.493,91.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.887 | Acc: 50.707,76.471,91.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.896 | Acc: 50.616,76.459,91.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.903 | Acc: 50.590,76.392,91.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.909 | Acc: 50.573,76.343,91.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.915 | Acc: 50.532,76.259,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.921 | Acc: 50.479,76.117,90.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.924 | Acc: 50.442,76.070,90.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.931 | Acc: 50.461,76.004,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.936 | Acc: 50.513,75.925,90.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.900 | Acc: 45.312,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.277 | Acc: 41.257,60.565,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.232 | Acc: 42.035,60.232,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.234 | Acc: 41.855,60.015,66.662,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.698 | Acc: 52.344,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.824 | Acc: 52.530,77.753,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.825 | Acc: 51.620,77.306,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.828 | Acc: 51.383,77.587,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.835 | Acc: 51.321,77.566,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.840 | Acc: 51.439,77.382,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.838 | Acc: 51.324,77.260,91.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.856 | Acc: 51.191,76.928,91.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.868 | Acc: 51.194,76.766,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.874 | Acc: 51.096,76.709,91.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.883 | Acc: 51.081,76.617,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.884 | Acc: 51.156,76.573,91.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.890 | Acc: 51.135,76.488,91.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.905 | Acc: 51.066,76.344,90.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.912 | Acc: 51.084,76.254,90.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.918 | Acc: 51.069,76.152,90.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.925 | Acc: 51.025,76.088,90.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.931 | Acc: 51.040,76.061,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.936 | Acc: 51.073,75.972,90.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.944 | Acc: 50.995,75.859,90.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.435 | Acc: 40.625,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.342 | Acc: 41.518,59.896,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.416 | Acc: 40.987,58.803,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.408 | Acc: 40.779,58.440,66.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 2.974 | Acc: 38.281,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.832 | Acc: 51.600,76.860,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.821 | Acc: 52.153,77.210,91.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.805 | Acc: 52.382,77.305,91.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 52.305,77.585,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.803 | Acc: 52.297,77.382,92.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.825 | Acc: 51.969,77.150,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.825 | Acc: 51.851,77.189,91.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.818 | Acc: 51.931,77.164,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.820 | Acc: 51.951,77.102,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.824 | Acc: 51.897,77.060,91.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.838 | Acc: 51.630,77.019,91.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.850 | Acc: 51.507,76.864,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.865 | Acc: 51.344,76.832,91.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.865 | Acc: 51.396,76.899,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.878 | Acc: 51.298,76.708,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.893 | Acc: 51.278,76.567,91.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.901 | Acc: 51.178,76.498,91.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.905 | Acc: 51.177,76.456,90.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.916 | Acc: 51.144,76.308,90.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.649 | Acc: 47.656,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.266 | Acc: 42.820,59.598,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.207 | Acc: 43.102,59.432,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.232 | Acc: 42.841,59.042,66.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 3.351 | Acc: 50.781,69.531,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.909 | Acc: 50.335,75.000,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.858 | Acc: 51.086,76.200,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.822 | Acc: 51.204,76.780,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.814 | Acc: 51.543,76.997,91.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.831 | Acc: 51.439,76.655,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.831 | Acc: 51.446,76.821,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.832 | Acc: 51.380,76.939,91.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.846 | Acc: 51.325,76.810,91.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.855 | Acc: 51.230,76.653,91.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.858 | Acc: 51.213,76.702,91.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.864 | Acc: 51.340,76.640,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.875 | Acc: 51.164,76.575,91.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.882 | Acc: 51.209,76.554,91.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.884 | Acc: 51.232,76.460,91.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.895 | Acc: 51.108,76.355,90.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.904 | Acc: 50.991,76.261,90.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.909 | Acc: 50.974,76.107,90.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.917 | Acc: 50.954,76.056,90.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.923 | Acc: 50.886,75.995,90.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.895 | Acc: 50.781,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.002 | Acc: 46.094,61.533,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.020 | Acc: 45.979,61.223,67.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.044 | Acc: 44.941,61.219,67.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 2.526 | Acc: 56.250,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.850 | Acc: 51.116,76.674,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.819 | Acc: 51.448,77.572,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.821 | Acc: 51.575,77.382,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.820 | Acc: 51.408,77.373,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.800 | Acc: 51.640,77.645,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.826 | Acc: 51.253,77.389,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.833 | Acc: 51.119,77.233,91.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.860 | Acc: 51.038,76.994,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.869 | Acc: 51.049,76.990,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.873 | Acc: 51.178,76.940,91.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.878 | Acc: 51.160,76.803,91.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.882 | Acc: 51.219,76.676,91.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.889 | Acc: 51.299,76.571,91.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.897 | Acc: 51.271,76.421,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.899 | Acc: 51.194,76.378,90.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.902 | Acc: 51.251,76.285,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.912 | Acc: 51.347,76.141,90.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.917 | Acc: 51.311,76.073,90.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.925 | Acc: 51.284,76.009,90.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.289 | Acc: 39.062,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.249 | Acc: 41.555,61.905,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.217 | Acc: 41.921,61.795,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.208 | Acc: 41.983,61.668,66.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 2.928 | Acc: 53.125,77.344,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.755 | Acc: 52.269,78.646,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.807 | Acc: 51.620,78.144,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.821 | Acc: 51.921,77.971,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.839 | Acc: 51.948,77.411,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.833 | Acc: 52.158,77.413,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.841 | Acc: 51.905,77.176,91.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.840 | Acc: 51.873,77.111,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.852 | Acc: 51.718,76.810,91.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.856 | Acc: 51.558,76.705,91.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.867 | Acc: 51.516,76.582,91.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.876 | Acc: 51.290,76.495,91.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.884 | Acc: 51.277,76.345,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.886 | Acc: 51.152,76.368,91.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.892 | Acc: 51.134,76.198,91.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.894 | Acc: 51.184,76.155,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.899 | Acc: 51.183,76.122,90.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.902 | Acc: 51.226,76.127,90.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.908 | Acc: 51.221,76.076,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.919 | Acc: 51.159,75.947,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.413 | Acc: 45.312,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.329 | Acc: 39.769,59.598,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.319 | Acc: 40.244,59.642,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.303 | Acc: 40.343,59.362,66.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.946 | Acc: 46.875,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.869 | Acc: 51.823,76.711,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.779 | Acc: 52.725,77.896,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.751 | Acc: 52.933,78.099,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.774 | Acc: 52.180,77.971,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.792 | Acc: 51.632,77.800,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.802 | Acc: 51.550,77.525,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.804 | Acc: 51.418,77.493,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.814 | Acc: 51.548,77.412,91.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.831 | Acc: 51.442,77.391,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.843 | Acc: 51.403,77.181,91.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.851 | Acc: 51.350,77.121,91.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.856 | Acc: 51.381,77.065,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.855 | Acc: 51.577,77.014,91.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.858 | Acc: 51.507,76.985,91.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.867 | Acc: 51.456,76.858,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.873 | Acc: 51.409,76.784,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.883 | Acc: 51.292,76.608,90.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.891 | Acc: 51.268,76.521,90.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.902 | Acc: 51.175,76.429,90.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.452 | Acc: 37.500,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.681 | Acc: 37.463,59.710,65.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.651 | Acc: 37.900,59.508,65.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.631 | Acc: 37.679,59.324,65.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 2.767 | Acc: 50.000,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.846 | Acc: 51.414,78.199,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.768 | Acc: 52.801,78.506,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.763 | Acc: 52.984,78.035,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 52.691,77.797,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.799 | Acc: 52.406,77.413,91.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.815 | Acc: 52.085,77.382,91.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.820 | Acc: 52.133,77.105,91.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.841 | Acc: 51.791,76.917,91.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.848 | Acc: 51.765,76.886,91.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.859 | Acc: 51.594,76.675,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.875 | Acc: 51.315,76.605,91.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.883 | Acc: 51.258,76.462,90.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.884 | Acc: 51.149,76.419,90.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 51.132,76.365,90.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.901 | Acc: 51.054,76.241,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.903 | Acc: 51.098,76.275,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.907 | Acc: 50.985,76.212,90.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.910 | Acc: 51.030,76.240,90.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.918 | Acc: 51.017,76.118,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.946 | Acc: 41.406,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.167 | Acc: 43.266,58.891,66.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.153 | Acc: 43.750,59.318,66.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.165 | Acc: 43.750,59.413,66.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 2.675 | Acc: 50.781,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.839 | Acc: 52.307,77.083,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.841 | Acc: 51.944,77.477,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.855 | Acc: 52.062,76.947,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.824 | Acc: 52.209,77.431,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.798 | Acc: 52.259,77.607,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.823 | Acc: 52.027,77.311,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.814 | Acc: 52.117,77.266,91.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.830 | Acc: 52.004,77.150,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.855 | Acc: 51.636,76.843,91.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.861 | Acc: 51.578,76.730,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.869 | Acc: 51.509,76.654,91.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.870 | Acc: 51.420,76.637,91.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.874 | Acc: 51.500,76.512,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.872 | Acc: 51.451,76.585,91.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.879 | Acc: 51.368,76.521,90.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.883 | Acc: 51.424,76.414,90.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.887 | Acc: 51.416,76.333,90.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.894 | Acc: 51.381,76.290,90.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.905 | Acc: 51.292,76.152,90.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.175 | Acc: 39.062,57.812,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.267 | Acc: 40.960,59.077,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.288 | Acc: 41.349,58.689,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.319 | Acc: 40.817,59.068,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.657 | Acc: 50.000,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.790 | Acc: 52.567,77.455,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.786 | Acc: 52.153,77.820,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.808 | Acc: 51.358,77.959,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.826 | Acc: 51.379,77.701,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.816 | Acc: 51.562,77.653,91.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.838 | Acc: 51.356,77.234,91.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.829 | Acc: 51.601,77.438,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.839 | Acc: 51.601,77.222,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.835 | Acc: 51.774,77.244,91.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.829 | Acc: 51.920,77.266,91.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.836 | Acc: 51.944,77.093,91.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.845 | Acc: 51.806,77.042,91.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.862 | Acc: 51.634,76.844,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.864 | Acc: 51.674,76.854,91.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.875 | Acc: 51.526,76.734,91.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.884 | Acc: 51.536,76.623,90.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.888 | Acc: 51.514,76.519,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.896 | Acc: 51.461,76.463,90.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.906 | Acc: 51.380,76.347,90.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.225 | Acc: 46.875,56.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.163 | Acc: 43.750,61.719,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.163 | Acc: 43.693,61.261,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.154 | Acc: 43.673,60.912,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 2.812 | Acc: 56.250,79.688,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.784 | Acc: 52.939,77.232,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.776 | Acc: 52.858,77.668,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.746 | Acc: 52.894,78.202,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.755 | Acc: 52.720,78.057,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.771 | Acc: 52.282,78.063,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.783 | Acc: 52.350,77.744,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.787 | Acc: 52.311,77.748,91.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.797 | Acc: 52.121,77.591,91.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.804 | Acc: 52.020,77.430,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.808 | Acc: 51.959,77.367,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.819 | Acc: 51.874,77.153,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.827 | Acc: 51.815,77.156,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.835 | Acc: 51.748,77.131,91.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.841 | Acc: 51.790,77.055,91.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.848 | Acc: 51.659,76.890,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.860 | Acc: 51.592,76.801,91.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.870 | Acc: 51.588,76.592,91.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.876 | Acc: 51.599,76.558,91.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.882 | Acc: 51.577,76.476,91.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.832 | Acc: 46.094,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.257 | Acc: 42.374,59.449,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.231 | Acc: 42.854,59.375,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.247 | Acc: 42.405,58.645,66.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 2.690 | Acc: 54.688,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.703 | Acc: 53.795,78.125,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.698 | Acc: 53.392,78.220,92.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.742 | Acc: 52.882,78.125,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.782 | Acc: 52.421,77.739,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.794 | Acc: 52.112,77.444,92.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.791 | Acc: 52.021,77.389,92.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.794 | Acc: 51.934,77.405,91.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.798 | Acc: 52.038,77.538,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.804 | Acc: 51.886,77.594,91.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.810 | Acc: 51.765,77.437,91.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.819 | Acc: 51.838,77.238,91.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.831 | Acc: 51.780,77.146,91.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.838 | Acc: 51.763,76.937,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.849 | Acc: 51.576,76.849,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.861 | Acc: 51.542,76.723,91.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.863 | Acc: 51.565,76.677,91.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.868 | Acc: 51.519,76.631,91.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.876 | Acc: 51.487,76.643,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.879 | Acc: 51.454,76.575,91.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.883 | Acc: 40.625,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.446 | Acc: 39.583,58.631,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.447 | Acc: 39.291,59.204,66.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.429 | Acc: 39.498,59.209,66.342,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 2.721 | Acc: 46.875,83.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.857 | Acc: 51.004,77.083,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.858 | Acc: 51.925,76.791,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.844 | Acc: 51.627,77.011,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.813 | Acc: 51.910,77.373,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.830 | Acc: 51.733,77.305,91.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 51.621,77.292,91.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.843 | Acc: 51.596,76.989,91.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.836 | Acc: 51.543,77.087,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.840 | Acc: 51.416,76.934,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.844 | Acc: 51.395,76.823,91.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.849 | Acc: 51.357,76.810,91.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.859 | Acc: 51.358,76.754,91.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.870 | Acc: 51.239,76.634,91.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.877 | Acc: 51.279,76.543,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.888 | Acc: 51.306,76.386,91.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.893 | Acc: 51.302,76.334,91.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.896 | Acc: 51.306,76.336,91.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.906 | Acc: 51.210,76.218,90.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.916 | Acc: 51.204,76.033,90.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.889 | Acc: 45.312,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.039 | Acc: 43.155,60.751,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.997 | Acc: 43.941,59.870,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.036 | Acc: 43.737,59.362,66.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 2.634 | Acc: 49.219,82.031,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.786 | Acc: 52.232,77.269,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.770 | Acc: 52.306,77.763,91.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.785 | Acc: 52.088,77.561,91.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.800 | Acc: 51.794,77.267,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.816 | Acc: 51.663,76.965,91.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.819 | Acc: 51.717,76.750,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.806 | Acc: 51.840,76.978,91.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.813 | Acc: 51.776,76.965,91.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.817 | Acc: 51.662,76.929,91.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.827 | Acc: 51.570,76.765,91.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.835 | Acc: 51.683,76.711,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.834 | Acc: 51.763,76.767,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.850 | Acc: 51.592,76.631,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.866 | Acc: 51.451,76.407,90.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.874 | Acc: 51.391,76.300,90.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.879 | Acc: 51.419,76.239,90.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.884 | Acc: 51.411,76.152,90.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.892 | Acc: 51.474,76.028,90.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.899 | Acc: 51.468,75.964,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.132 | Acc: 47.656,60.938,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.055 | Acc: 44.866,61.235,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.064 | Acc: 44.798,60.194,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.098 | Acc: 44.736,59.900,66.675,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.834 | Acc: 57.031,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.740 | Acc: 53.534,78.237,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.722 | Acc: 53.049,78.563,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.725 | Acc: 52.843,78.535,92.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.735 | Acc: 52.585,78.328,92.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.749 | Acc: 52.707,78.171,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.753 | Acc: 52.776,78.086,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.769 | Acc: 52.759,77.837,92.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.776 | Acc: 52.499,77.747,92.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.795 | Acc: 52.266,77.478,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.806 | Acc: 52.200,77.227,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.816 | Acc: 52.054,77.216,91.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.830 | Acc: 51.802,77.071,91.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.850 | Acc: 51.539,76.853,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.854 | Acc: 51.646,76.835,91.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.869 | Acc: 51.441,76.648,91.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.876 | Acc: 51.441,76.553,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.879 | Acc: 51.496,76.450,91.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.882 | Acc: 51.459,76.387,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.888 | Acc: 51.433,76.347,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.112 | Acc: 48.438,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.529 | Acc: 40.513,58.743,66.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.515 | Acc: 40.434,58.422,65.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.538 | Acc: 40.215,58.555,65.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 2.492 | Acc: 53.125,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.850 | Acc: 50.112,77.604,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.829 | Acc: 50.572,77.782,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.815 | Acc: 51.153,77.920,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.822 | Acc: 51.090,77.778,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.819 | Acc: 51.593,77.676,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.831 | Acc: 51.511,77.382,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.831 | Acc: 51.513,77.432,91.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.843 | Acc: 51.334,77.159,91.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.855 | Acc: 51.174,76.912,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.865 | Acc: 51.150,76.889,91.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.858 | Acc: 51.294,76.951,91.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.869 | Acc: 51.268,76.796,91.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.875 | Acc: 51.281,76.757,91.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.875 | Acc: 51.512,76.710,90.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.882 | Acc: 51.391,76.633,90.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.887 | Acc: 51.358,76.640,90.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.890 | Acc: 51.416,76.627,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.896 | Acc: 51.359,76.495,90.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.900 | Acc: 51.298,76.483,90.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.672 | Acc: 44.531,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.084 | Acc: 42.671,61.012,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.178 | Acc: 41.654,60.423,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.195 | Acc: 41.278,60.438,67.508,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 2.883 | Acc: 53.906,71.875,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.780 | Acc: 52.009,78.385,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 52.630,78.830,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.739 | Acc: 53.099,78.368,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.759 | Acc: 52.652,78.299,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.776 | Acc: 52.321,77.947,91.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.767 | Acc: 52.389,78.112,91.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.780 | Acc: 52.250,77.793,91.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.800 | Acc: 52.077,77.504,91.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.821 | Acc: 51.869,77.236,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.829 | Acc: 51.920,77.146,91.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.836 | Acc: 51.859,77.128,91.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.841 | Acc: 51.776,77.033,91.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.847 | Acc: 51.808,76.946,91.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.851 | Acc: 51.799,76.863,91.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.866 | Acc: 51.736,76.708,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.877 | Acc: 51.626,76.548,90.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.879 | Acc: 51.629,76.519,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.880 | Acc: 51.638,76.528,90.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.885 | Acc: 51.591,76.444,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.954 | Acc: 40.625,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.612 | Acc: 39.509,57.552,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.589 | Acc: 40.034,57.412,65.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.622 | Acc: 39.985,56.814,64.588,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 2.851 | Acc: 53.906,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.814 | Acc: 51.451,77.604,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 51.677,78.163,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.772 | Acc: 51.358,78.253,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.774 | Acc: 51.437,78.260,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.806 | Acc: 51.075,77.777,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.807 | Acc: 51.240,77.789,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.819 | Acc: 51.258,77.549,91.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.828 | Acc: 51.276,77.363,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.838 | Acc: 51.321,77.184,91.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.846 | Acc: 51.287,77.060,91.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.854 | Acc: 51.273,76.895,91.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.862 | Acc: 51.183,76.757,90.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.867 | Acc: 51.215,76.703,90.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.873 | Acc: 51.240,76.543,90.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.876 | Acc: 51.311,76.490,90.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.884 | Acc: 51.270,76.404,90.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.894 | Acc: 51.226,76.269,90.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.898 | Acc: 51.244,76.257,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.901 | Acc: 51.308,76.216,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.880 | Acc: 46.094,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.950 | Acc: 45.461,61.049,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.001 | Acc: 45.636,60.004,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.016 | Acc: 45.377,60.105,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 2.628 | Acc: 54.688,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.677 | Acc: 52.493,78.051,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.684 | Acc: 53.144,78.335,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.707 | Acc: 52.433,78.586,92.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.705 | Acc: 52.749,78.704,92.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.732 | Acc: 52.475,78.280,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.760 | Acc: 52.066,78.035,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.775 | Acc: 51.900,77.859,92.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.778 | Acc: 52.169,77.829,91.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.785 | Acc: 51.990,77.629,91.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.790 | Acc: 51.928,77.666,91.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.800 | Acc: 51.958,77.485,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.809 | Acc: 51.812,77.516,91.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 51.751,77.487,91.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.826 | Acc: 51.693,77.419,91.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.836 | Acc: 51.656,77.204,91.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 51.592,77.171,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 51.535,77.138,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.853 | Acc: 51.493,77.026,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.859 | Acc: 51.439,76.936,91.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.975 | Acc: 39.844,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.095 | Acc: 43.601,61.310,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.116 | Acc: 44.226,60.537,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.108 | Acc: 43.968,60.771,66.714,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 2.660 | Acc: 59.375,82.812,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.780 | Acc: 53.348,79.092,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.803 | Acc: 51.715,78.144,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.799 | Acc: 51.883,77.677,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.798 | Acc: 51.939,77.652,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.798 | Acc: 51.934,77.545,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.794 | Acc: 51.931,77.654,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.797 | Acc: 51.995,77.765,91.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.811 | Acc: 51.970,77.455,91.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.821 | Acc: 51.809,77.262,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.821 | Acc: 51.858,77.231,91.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.828 | Acc: 51.828,77.259,91.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.846 | Acc: 51.640,77.068,91.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.855 | Acc: 51.613,77.014,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.864 | Acc: 51.599,76.816,90.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.868 | Acc: 51.723,76.713,90.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.875 | Acc: 51.713,76.648,90.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.888 | Acc: 51.636,76.528,90.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.892 | Acc: 51.645,76.430,90.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.899 | Acc: 51.622,76.419,90.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.958 | Acc: 39.844,65.625,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.330 | Acc: 41.220,60.045,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.301 | Acc: 41.864,60.213,65.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.301 | Acc: 41.522,60.207,65.292,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 2.640 | Acc: 52.344,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.825 | Acc: 51.265,77.455,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.839 | Acc: 50.877,77.782,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.821 | Acc: 51.434,77.766,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.826 | Acc: 51.611,77.894,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.819 | Acc: 51.570,78.055,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.825 | Acc: 51.782,77.763,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.827 | Acc: 51.834,77.621,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.829 | Acc: 51.786,77.436,91.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.832 | Acc: 51.718,77.244,91.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.833 | Acc: 51.792,77.227,91.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.836 | Acc: 51.867,77.305,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.841 | Acc: 51.819,77.221,91.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.844 | Acc: 51.736,77.158,91.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.856 | Acc: 51.588,77.046,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.868 | Acc: 51.409,76.897,90.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.874 | Acc: 51.319,76.835,90.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.886 | Acc: 51.274,76.672,90.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.891 | Acc: 51.348,76.556,90.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.894 | Acc: 51.345,76.517,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.071 | Acc: 43.750,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.320 | Acc: 39.658,61.049,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.337 | Acc: 39.367,60.518,67.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.373 | Acc: 38.973,60.195,67.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 3.023 | Acc: 44.531,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.690 | Acc: 52.344,79.799,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.711 | Acc: 53.087,79.688,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.744 | Acc: 52.613,78.919,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.744 | Acc: 52.459,78.607,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.739 | Acc: 52.777,78.504,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.773 | Acc: 52.382,78.299,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.771 | Acc: 52.349,78.358,91.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.791 | Acc: 52.159,77.999,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.789 | Acc: 52.201,77.892,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.799 | Acc: 52.017,77.756,91.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.806 | Acc: 51.955,77.598,91.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.813 | Acc: 51.887,77.405,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.818 | Acc: 51.877,77.308,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.821 | Acc: 51.907,77.308,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.823 | Acc: 51.954,77.266,91.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.834 | Acc: 51.915,77.127,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.843 | Acc: 51.865,77.046,91.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.853 | Acc: 51.840,76.985,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.857 | Acc: 51.854,76.975,90.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.028 | Acc: 39.844,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.195 | Acc: 41.332,61.124,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.128 | Acc: 42.188,61.090,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.153 | Acc: 41.778,60.848,67.533,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 2.719 | Acc: 53.125,82.812,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.679 | Acc: 53.199,79.353,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.687 | Acc: 53.335,79.116,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.729 | Acc: 52.805,78.650,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.734 | Acc: 52.922,78.665,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.748 | Acc: 52.305,78.558,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.750 | Acc: 52.311,78.525,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.755 | Acc: 52.144,78.380,92.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.772 | Acc: 51.946,78.203,91.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 51.929,78.017,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.795 | Acc: 51.885,77.814,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 51.884,77.581,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.808 | Acc: 51.809,77.516,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.822 | Acc: 51.655,77.371,91.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.834 | Acc: 51.537,77.185,91.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.842 | Acc: 51.513,77.131,91.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.849 | Acc: 51.463,77.005,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.856 | Acc: 51.508,76.924,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.863 | Acc: 51.530,76.811,90.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.869 | Acc: 51.542,76.724,90.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.809 | Acc: 38.281,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.414 | Acc: 38.393,61.570,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.419 | Acc: 38.586,61.261,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.404 | Acc: 38.896,61.168,67.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 2.819 | Acc: 54.688,76.562,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.849 | Acc: 52.083,76.265,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.792 | Acc: 52.153,76.677,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.793 | Acc: 51.601,76.780,92.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.782 | Acc: 51.939,77.064,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.768 | Acc: 52.189,77.290,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.782 | Acc: 52.027,77.260,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.801 | Acc: 51.956,77.083,91.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.813 | Acc: 51.907,76.936,91.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.824 | Acc: 51.809,76.869,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.823 | Acc: 51.846,76.881,91.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.827 | Acc: 51.863,76.937,91.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.832 | Acc: 51.757,76.929,91.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.833 | Acc: 51.766,76.967,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.836 | Acc: 51.788,76.955,91.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.849 | Acc: 51.794,76.788,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.854 | Acc: 51.789,76.709,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.866 | Acc: 51.702,76.627,91.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.877 | Acc: 51.543,76.465,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.880 | Acc: 51.585,76.351,90.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.988 | Acc: 48.438,64.844,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.088 | Acc: 45.052,59.970,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.139 | Acc: 44.550,58.994,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.143 | Acc: 44.403,59.068,66.573,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 3.047 | Acc: 46.875,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.869 | Acc: 51.190,75.818,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.873 | Acc: 51.296,76.467,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.848 | Acc: 51.511,76.601,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.826 | Acc: 51.669,77.170,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.811 | Acc: 51.918,77.351,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.809 | Acc: 51.737,77.441,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.811 | Acc: 51.801,77.244,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.811 | Acc: 51.878,77.286,91.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 51.821,77.339,91.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.810 | Acc: 51.835,77.336,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.813 | Acc: 51.877,77.301,91.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.820 | Acc: 51.896,77.217,91.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.828 | Acc: 51.850,77.191,91.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.830 | Acc: 51.857,77.182,91.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.841 | Acc: 51.879,76.962,91.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.861 | Acc: 51.808,76.738,90.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.865 | Acc: 51.824,76.700,90.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.872 | Acc: 51.809,76.617,90.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.879 | Acc: 51.782,76.466,90.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.030 | Acc: 43.750,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.242 | Acc: 40.997,61.049,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.216 | Acc: 41.692,60.404,66.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.197 | Acc: 41.342,60.489,66.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 3.009 | Acc: 46.875,71.875,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.754 | Acc: 51.860,77.902,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.779 | Acc: 51.772,77.934,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.757 | Acc: 52.088,77.907,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.749 | Acc: 52.064,78.154,92.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.767 | Acc: 51.965,77.939,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.765 | Acc: 52.228,77.944,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.788 | Acc: 52.105,77.732,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.805 | Acc: 51.975,77.615,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.832 | Acc: 51.683,77.335,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.842 | Acc: 51.687,77.270,91.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.842 | Acc: 51.764,77.188,91.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.852 | Acc: 51.634,77.007,91.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.856 | Acc: 51.643,76.949,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.857 | Acc: 51.638,76.893,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.857 | Acc: 51.679,76.864,90.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.858 | Acc: 51.838,76.823,90.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.859 | Acc: 51.826,76.837,90.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.865 | Acc: 51.824,76.762,90.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.871 | Acc: 51.798,76.679,90.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.642 | Acc: 50.000,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.140 | Acc: 43.490,60.454,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.155 | Acc: 43.426,59.699,66.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.183 | Acc: 42.969,59.426,65.958,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 3.055 | Acc: 53.906,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.788 | Acc: 52.567,78.981,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.775 | Acc: 52.915,79.325,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.813 | Acc: 52.241,78.714,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.802 | Acc: 52.257,78.424,91.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.796 | Acc: 52.321,78.427,91.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.782 | Acc: 52.557,78.254,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.782 | Acc: 52.660,78.097,91.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.785 | Acc: 52.543,77.902,91.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.789 | Acc: 52.417,77.827,91.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.795 | Acc: 52.278,77.806,91.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.800 | Acc: 52.270,77.694,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.809 | Acc: 52.146,77.577,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.822 | Acc: 52.038,77.428,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.827 | Acc: 52.021,77.327,91.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.836 | Acc: 51.991,77.227,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.848 | Acc: 51.855,77.151,91.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.852 | Acc: 51.853,77.112,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.857 | Acc: 51.827,77.058,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.862 | Acc: 51.829,76.981,90.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.006 | Acc: 40.625,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.303 | Acc: 41.220,60.454,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.301 | Acc: 41.387,60.118,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.301 | Acc: 41.445,59.490,66.227,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 2.717 | Acc: 53.906,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.722 | Acc: 52.046,78.385,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.685 | Acc: 53.030,79.211,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.670 | Acc: 52.805,79.137,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.689 | Acc: 52.527,78.723,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.690 | Acc: 52.537,78.767,92.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.705 | Acc: 52.479,78.422,92.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.716 | Acc: 52.632,78.374,92.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.728 | Acc: 52.484,78.188,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.740 | Acc: 52.266,77.991,91.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.743 | Acc: 52.340,77.977,91.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.757 | Acc: 52.075,77.856,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.762 | Acc: 52.007,77.785,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.768 | Acc: 51.919,77.709,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.787 | Acc: 51.757,77.511,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.794 | Acc: 51.742,77.442,91.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.805 | Acc: 51.757,77.317,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 51.727,77.250,91.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.825 | Acc: 51.617,77.125,91.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.834 | Acc: 51.630,77.040,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.971 | Acc: 42.969,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.351 | Acc: 41.518,59.673,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.396 | Acc: 41.845,58.765,65.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.371 | Acc: 41.893,58.658,65.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 2.786 | Acc: 53.125,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.712 | Acc: 52.418,78.385,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 52.153,78.277,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.717 | Acc: 52.203,78.599,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.732 | Acc: 52.209,78.588,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.742 | Acc: 51.972,78.342,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.753 | Acc: 52.047,78.202,92.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.754 | Acc: 52.410,78.108,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.766 | Acc: 52.339,78.038,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.793 | Acc: 52.037,77.762,91.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.794 | Acc: 52.048,77.725,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 51.948,77.489,91.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 51.922,77.454,91.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.823 | Acc: 51.769,77.311,91.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.837 | Acc: 51.643,77.135,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.838 | Acc: 51.690,77.159,91.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.846 | Acc: 51.691,77.064,90.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.860 | Acc: 51.650,76.897,90.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.870 | Acc: 51.584,76.764,90.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.875 | Acc: 51.595,76.686,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.712 | Acc: 49.219,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.098 | Acc: 44.196,60.975,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.137 | Acc: 43.902,60.728,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.129 | Acc: 43.584,60.400,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 2.911 | Acc: 53.125,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.760 | Acc: 52.344,80.543,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.793 | Acc: 51.848,78.982,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.768 | Acc: 52.113,78.881,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.732 | Acc: 52.595,79.215,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.734 | Acc: 52.390,79.092,92.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.750 | Acc: 52.202,78.745,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.760 | Acc: 52.238,78.513,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.765 | Acc: 52.281,78.465,92.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.783 | Acc: 52.037,78.272,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.797 | Acc: 51.877,78.109,91.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.797 | Acc: 51.955,78.047,91.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.802 | Acc: 52.020,77.879,91.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.810 | Acc: 52.053,77.790,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.821 | Acc: 51.941,77.561,91.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.830 | Acc: 51.903,77.453,91.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.837 | Acc: 51.765,77.361,91.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.843 | Acc: 51.824,77.243,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.852 | Acc: 51.695,77.086,91.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.858 | Acc: 51.655,76.991,91.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.519 | Acc: 46.875,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.764 | Acc: 45.201,63.951,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.805 | Acc: 45.103,62.614,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.823 | Acc: 44.787,62.538,67.623,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 2.601 | Acc: 48.438,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.732 | Acc: 53.274,77.567,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.704 | Acc: 53.525,78.601,92.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.690 | Acc: 53.407,78.753,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.714 | Acc: 52.643,78.617,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.727 | Acc: 52.800,78.311,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.738 | Acc: 52.673,78.131,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.753 | Acc: 52.499,77.898,92.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.762 | Acc: 52.383,77.902,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.775 | Acc: 52.301,77.715,91.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.782 | Acc: 52.247,77.600,91.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.782 | Acc: 52.439,77.538,91.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.786 | Acc: 52.438,77.392,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.791 | Acc: 52.362,77.293,91.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.809 | Acc: 52.160,77.032,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.815 | Acc: 52.183,77.045,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 52.078,76.903,91.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.829 | Acc: 52.016,76.876,91.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.837 | Acc: 51.976,76.863,91.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.846 | Acc: 51.895,76.778,91.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.220 | Acc: 37.500,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.548 | Acc: 39.881,58.780,65.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.659 | Acc: 38.891,58.155,64.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.651 | Acc: 38.794,58.120,64.460,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.967 | Acc: 44.531,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.884 | Acc: 50.149,76.935,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.813 | Acc: 51.810,77.077,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.784 | Acc: 52.177,77.497,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.757 | Acc: 52.566,77.816,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.736 | Acc: 52.792,78.179,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.744 | Acc: 52.763,78.035,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.756 | Acc: 52.709,77.809,91.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.752 | Acc: 52.795,77.945,91.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.762 | Acc: 52.650,77.844,91.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.784 | Acc: 52.305,77.596,91.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.791 | Acc: 52.407,77.513,91.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.798 | Acc: 52.360,77.464,91.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.803 | Acc: 52.335,77.422,91.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.816 | Acc: 52.294,77.255,91.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.823 | Acc: 52.198,77.284,91.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.825 | Acc: 52.329,77.242,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.836 | Acc: 52.259,77.128,90.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.851 | Acc: 52.175,76.915,90.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.866 | Acc: 52.055,76.751,90.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.276 | Acc: 42.969,66.406,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.495 | Acc: 38.467,60.863,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.518 | Acc: 38.129,59.737,65.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.491 | Acc: 37.756,60.067,65.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.991 | Acc: 49.219,75.000,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.690 | Acc: 52.121,79.427,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.688 | Acc: 53.144,79.154,92.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.692 | Acc: 53.227,79.009,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.692 | Acc: 53.434,78.974,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.690 | Acc: 53.450,78.922,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.695 | Acc: 53.693,78.738,92.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.716 | Acc: 53.408,78.474,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.733 | Acc: 53.251,78.285,91.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.750 | Acc: 52.952,78.095,91.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.762 | Acc: 52.888,77.861,91.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.776 | Acc: 52.814,77.743,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 52.704,77.506,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.801 | Acc: 52.634,77.431,91.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.807 | Acc: 52.508,77.330,91.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.821 | Acc: 52.403,77.256,91.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.836 | Acc: 52.266,77.032,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.849 | Acc: 52.122,76.851,90.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.857 | Acc: 52.123,76.725,90.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.856 | Acc: 52.163,76.692,90.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.912 | Acc: 47.656,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.078 | Acc: 43.452,60.417,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.131 | Acc: 44.036,59.604,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.160 | Acc: 43.353,59.298,66.534,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 2.588 | Acc: 60.938,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.747 | Acc: 53.460,78.088,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.776 | Acc: 52.077,78.773,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.733 | Acc: 52.152,79.150,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.725 | Acc: 52.054,79.147,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.735 | Acc: 52.282,78.744,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.734 | Acc: 52.273,78.719,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.739 | Acc: 52.371,78.590,91.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.754 | Acc: 52.451,78.285,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.767 | Acc: 52.478,78.207,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.761 | Acc: 52.538,78.273,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.758 | Acc: 52.566,78.365,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.758 | Acc: 52.483,78.329,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.768 | Acc: 52.425,78.191,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.782 | Acc: 52.260,77.994,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.785 | Acc: 52.313,77.936,91.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.796 | Acc: 52.244,77.745,91.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.810 | Acc: 52.174,77.600,91.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.821 | Acc: 52.158,77.441,91.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 52.085,77.395,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.019 | Acc: 39.844,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.309 | Acc: 39.509,60.342,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.376 | Acc: 38.929,59.718,66.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.411 | Acc: 38.845,59.426,66.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 2.981 | Acc: 53.906,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.774 | Acc: 51.823,79.390,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 52.401,79.078,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.732 | Acc: 52.638,79.086,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.766 | Acc: 52.392,78.665,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.757 | Acc: 52.382,78.821,91.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.758 | Acc: 52.466,78.661,91.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.772 | Acc: 52.205,78.324,91.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.783 | Acc: 52.174,78.183,91.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.777 | Acc: 52.288,78.259,92.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.770 | Acc: 52.480,78.238,92.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.766 | Acc: 52.552,78.213,92.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.777 | Acc: 52.402,78.119,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.775 | Acc: 52.463,78.053,91.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.789 | Acc: 52.352,77.836,91.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.792 | Acc: 52.346,77.718,91.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.796 | Acc: 52.312,77.609,91.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.808 | Acc: 52.080,77.497,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.823 | Acc: 52.026,77.329,91.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.829 | Acc: 51.975,77.256,91.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.217 | Acc: 42.188,56.250,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.133 | Acc: 43.676,60.677,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.168 | Acc: 43.598,60.480,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.198 | Acc: 43.238,60.297,67.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 2.726 | Acc: 53.906,79.688,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.734 | Acc: 52.902,78.013,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.650 | Acc: 53.639,79.345,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.703 | Acc: 53.227,78.765,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.693 | Acc: 53.202,78.839,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.708 | Acc: 53.110,78.651,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.705 | Acc: 53.409,78.545,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.717 | Acc: 53.180,78.352,91.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.728 | Acc: 53.207,78.106,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.742 | Acc: 53.108,77.935,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.755 | Acc: 52.861,77.810,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.772 | Acc: 52.680,77.658,91.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.783 | Acc: 52.616,77.525,91.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.787 | Acc: 52.589,77.440,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.793 | Acc: 52.502,77.347,91.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.806 | Acc: 52.354,77.157,91.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.814 | Acc: 52.307,77.025,91.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.824 | Acc: 52.167,76.957,91.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.837 | Acc: 52.082,76.822,91.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.840 | Acc: 52.046,76.706,90.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.056 | Acc: 45.312,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.129 | Acc: 43.378,62.202,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.151 | Acc: 43.140,61.433,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.132 | Acc: 42.841,61.475,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 2.404 | Acc: 53.906,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.727 | Acc: 52.418,77.716,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 53.125,77.992,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.741 | Acc: 52.664,77.830,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.734 | Acc: 52.614,78.250,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.722 | Acc: 52.761,78.380,92.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.726 | Acc: 52.789,78.345,92.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.745 | Acc: 52.660,78.275,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.752 | Acc: 52.446,78.193,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.764 | Acc: 52.249,78.013,92.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.772 | Acc: 52.227,77.938,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.785 | Acc: 52.054,77.757,91.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.788 | Acc: 52.042,77.652,91.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.798 | Acc: 51.865,77.646,91.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.798 | Acc: 51.929,77.677,91.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.794 | Acc: 52.043,77.668,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.805 | Acc: 52.066,77.587,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 52.087,77.484,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.819 | Acc: 51.989,77.443,91.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.828 | Acc: 51.878,77.329,91.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.886 | Acc: 40.625,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.279 | Acc: 42.076,60.565,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.269 | Acc: 42.168,59.508,65.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.250 | Acc: 42.418,59.977,65.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.343 | Acc: 54.688,86.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.704 | Acc: 53.720,78.348,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 52.515,77.477,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.756 | Acc: 52.818,77.779,91.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.750 | Acc: 52.894,78.048,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.758 | Acc: 52.870,77.955,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.771 | Acc: 52.679,77.822,91.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.775 | Acc: 52.538,77.903,91.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.770 | Acc: 52.523,77.819,91.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 52.465,77.762,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 52.340,77.678,91.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.798 | Acc: 52.220,77.694,91.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 52.169,77.567,91.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.805 | Acc: 52.209,77.443,91.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.804 | Acc: 52.241,77.416,91.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.811 | Acc: 52.266,77.370,91.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.818 | Acc: 52.232,77.261,91.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.819 | Acc: 52.236,77.211,91.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.829 | Acc: 52.130,77.101,91.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.832 | Acc: 52.169,77.040,90.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.059 | Acc: 45.312,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.379 | Acc: 40.327,61.012,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.417 | Acc: 40.796,60.652,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.422 | Acc: 40.702,60.476,66.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 2.644 | Acc: 47.656,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.668 | Acc: 52.716,80.320,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.562 | Acc: 54.402,81.441,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.507 | Acc: 55.008,82.275,93.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.454 | Acc: 55.363,83.102,93.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.405 | Acc: 55.879,83.725,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.359 | Acc: 56.476,84.259,94.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.334 | Acc: 56.688,84.469,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.314 | Acc: 56.658,84.710,95.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.301 | Acc: 56.699,84.738,95.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.292 | Acc: 56.887,84.841,95.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.281 | Acc: 56.911,84.951,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.263 | Acc: 57.041,85.202,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.254 | Acc: 57.184,85.336,95.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.244 | Acc: 57.270,85.454,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.237 | Acc: 57.348,85.530,95.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.229 | Acc: 57.416,85.560,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.224 | Acc: 57.437,85.617,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.222 | Acc: 57.347,85.658,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.218 | Acc: 57.314,85.685,96.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.064 | Acc: 57.812,71.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.043 | Acc: 52.604,69.643,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.063 | Acc: 52.306,68.769,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.059 | Acc: 51.998,68.993,73.489,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 2.154 | Acc: 54.688,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.074 | Acc: 57.626,87.388,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.038 | Acc: 58.537,88.072,98.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.049 | Acc: 58.414,87.999,97.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.043 | Acc: 58.304,88.137,97.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.040 | Acc: 58.230,88.181,98.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.035 | Acc: 58.381,88.320,98.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.036 | Acc: 58.455,88.298,98.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.036 | Acc: 58.332,88.291,98.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.034 | Acc: 58.378,88.368,98.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.029 | Acc: 58.493,88.487,98.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.024 | Acc: 58.558,88.522,98.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.016 | Acc: 58.704,88.528,98.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.015 | Acc: 58.705,88.491,98.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.015 | Acc: 58.622,88.506,98.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.014 | Acc: 58.648,88.515,98.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.014 | Acc: 58.642,88.583,98.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.014 | Acc: 58.649,88.568,98.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.015 | Acc: 58.600,88.550,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.014 | Acc: 58.596,88.564,98.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.944 | Acc: 55.469,75.781,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.027 | Acc: 52.307,69.680,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.047 | Acc: 52.496,68.826,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.041 | Acc: 52.228,68.904,74.193,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 2.295 | Acc: 49.219,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.970 | Acc: 57.217,90.067,98.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.954 | Acc: 58.155,89.882,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.930 | Acc: 59.132,90.061,98.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.947 | Acc: 58.700,89.902,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.950 | Acc: 58.625,89.890,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.947 | Acc: 58.826,89.818,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.947 | Acc: 58.838,89.766,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.956 | Acc: 58.623,89.582,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.963 | Acc: 58.438,89.347,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.964 | Acc: 58.547,89.288,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.960 | Acc: 58.597,89.359,98.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.957 | Acc: 58.591,89.357,98.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.954 | Acc: 58.630,89.389,98.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.955 | Acc: 58.635,89.304,98.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.956 | Acc: 58.648,89.319,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.952 | Acc: 58.750,89.379,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.950 | Acc: 58.864,89.372,98.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.949 | Acc: 58.882,89.342,98.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.950 | Acc: 58.873,89.331,98.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.910 | Acc: 56.250,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.044 | Acc: 52.344,69.717,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.062 | Acc: 52.477,68.883,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.055 | Acc: 52.280,68.955,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.798 | Acc: 58.594,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.929 | Acc: 58.110,89.174,98.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.890 | Acc: 58.880,89.863,98.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.882 | Acc: 59.285,89.908,99.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.895 | Acc: 59.066,89.844,98.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.898 | Acc: 59.158,89.859,98.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.908 | Acc: 59.155,89.947,98.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.908 | Acc: 59.120,90.071,98.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.909 | Acc: 59.220,90.115,98.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.904 | Acc: 59.358,90.185,98.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.899 | Acc: 59.484,90.147,98.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.895 | Acc: 59.789,90.116,98.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.901 | Acc: 59.608,90.074,98.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.897 | Acc: 59.623,90.080,98.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.896 | Acc: 59.581,90.052,98.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.894 | Acc: 59.632,90.020,98.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.893 | Acc: 59.648,89.997,98.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.896 | Acc: 59.565,90.011,98.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.899 | Acc: 59.470,89.961,98.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.900 | Acc: 59.478,89.952,98.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.849 | Acc: 56.250,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.998 | Acc: 52.604,69.866,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.031 | Acc: 52.744,69.093,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.032 | Acc: 52.408,69.185,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 2.002 | Acc: 54.688,92.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.843 | Acc: 61.942,90.365,99.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.826 | Acc: 60.671,91.025,99.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.833 | Acc: 59.990,91.124,99.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.833 | Acc: 60.031,91.127,99.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.853 | Acc: 59.886,90.888,99.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.848 | Acc: 60.066,90.954,99.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.853 | Acc: 59.918,90.808,99.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.854 | Acc: 59.889,90.649,99.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.859 | Acc: 59.794,90.586,99.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.862 | Acc: 59.841,90.524,99.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.860 | Acc: 59.750,90.586,99.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.862 | Acc: 59.748,90.512,99.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.864 | Acc: 59.815,90.490,99.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.862 | Acc: 59.811,90.530,99.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.865 | Acc: 59.808,90.503,99.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.867 | Acc: 59.762,90.496,99.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.870 | Acc: 59.645,90.458,99.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.871 | Acc: 59.643,90.497,98.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.874 | Acc: 59.586,90.473,98.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.965 | Acc: 56.250,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.008 | Acc: 51.935,69.717,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.038 | Acc: 52.134,68.845,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.040 | Acc: 51.806,69.070,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.869 | Acc: 58.594,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.854 | Acc: 59.301,90.737,98.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.817 | Acc: 59.851,90.968,98.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.844 | Acc: 59.644,90.587,98.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.838 | Acc: 59.674,90.693,98.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.839 | Acc: 59.708,90.718,98.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.834 | Acc: 59.853,90.832,98.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.822 | Acc: 60.123,90.946,98.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.829 | Acc: 60.035,90.882,98.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.832 | Acc: 60.066,90.871,98.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.839 | Acc: 59.873,90.742,98.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.840 | Acc: 59.870,90.745,98.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.838 | Acc: 59.809,90.832,98.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.838 | Acc: 59.749,90.876,98.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.836 | Acc: 59.803,90.906,98.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.838 | Acc: 59.723,90.916,98.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.842 | Acc: 59.716,90.856,98.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.846 | Acc: 59.675,90.813,98.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.848 | Acc: 59.695,90.757,98.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.845 | Acc: 59.765,90.769,98.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.907 | Acc: 53.906,75.000,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.033 | Acc: 52.567,70.312,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.063 | Acc: 52.134,69.169,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.065 | Acc: 51.806,69.249,74.718,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.623 | Acc: 65.625,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.720 | Acc: 61.496,91.927,99.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.769 | Acc: 60.080,91.540,99.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.794 | Acc: 59.823,91.637,99.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.793 | Acc: 59.684,91.561,99.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.803 | Acc: 59.483,91.344,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.804 | Acc: 59.504,91.245,99.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.806 | Acc: 59.680,91.268,99.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.809 | Acc: 59.773,91.324,99.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.812 | Acc: 59.699,91.363,99.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.812 | Acc: 59.624,91.297,99.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.811 | Acc: 59.757,91.275,99.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.814 | Acc: 59.738,91.234,99.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.816 | Acc: 59.764,91.182,99.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.819 | Acc: 59.745,91.131,99.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.820 | Acc: 59.733,91.136,99.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.819 | Acc: 59.747,91.124,99.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.817 | Acc: 59.785,91.161,99.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.817 | Acc: 59.851,91.162,99.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.819 | Acc: 59.799,91.080,99.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.859 | Acc: 57.812,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.048 | Acc: 52.083,70.052,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.066 | Acc: 52.420,68.960,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.068 | Acc: 52.216,69.019,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.984 | Acc: 53.906,89.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.772 | Acc: 60.007,92.113,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.784 | Acc: 60.137,91.978,99.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.798 | Acc: 60.105,91.650,99.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.809 | Acc: 59.944,91.397,99.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.811 | Acc: 59.932,91.267,99.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.801 | Acc: 60.130,91.387,99.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.794 | Acc: 60.317,91.428,99.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.793 | Acc: 60.248,91.474,99.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.796 | Acc: 60.294,91.458,99.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.798 | Acc: 60.300,91.433,99.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.798 | Acc: 60.248,91.410,99.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.799 | Acc: 60.205,91.367,99.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.798 | Acc: 60.189,91.367,99.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.796 | Acc: 60.245,91.390,99.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.799 | Acc: 60.221,91.313,99.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.803 | Acc: 60.125,91.326,99.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.804 | Acc: 60.108,91.294,99.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.806 | Acc: 60.152,91.287,99.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.807 | Acc: 60.062,91.322,99.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.953 | Acc: 57.031,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.029 | Acc: 51.897,69.978,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.057 | Acc: 52.382,69.055,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.060 | Acc: 52.241,69.237,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.875 | Acc: 60.938,91.406,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.767 | Acc: 60.640,92.448,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.767 | Acc: 60.671,91.997,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.778 | Acc: 60.681,91.829,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.784 | Acc: 60.446,91.879,99.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.773 | Acc: 60.659,91.870,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.766 | Acc: 60.828,91.916,99.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.771 | Acc: 60.738,91.800,99.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.772 | Acc: 60.583,91.814,99.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.776 | Acc: 60.527,91.795,99.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.775 | Acc: 60.522,91.908,99.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.777 | Acc: 60.393,91.855,99.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.776 | Acc: 60.377,91.854,99.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.777 | Acc: 60.378,91.834,99.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.780 | Acc: 60.298,91.740,99.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.779 | Acc: 60.398,91.710,99.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.778 | Acc: 60.373,91.732,99.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.783 | Acc: 60.241,91.729,99.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.784 | Acc: 60.236,91.711,99.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.785 | Acc: 60.246,91.681,99.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.072 | Acc: 57.031,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.041 | Acc: 53.423,70.201,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.075 | Acc: 53.125,68.979,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.070 | Acc: 52.882,69.339,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 1.650 | Acc: 60.156,94.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.764 | Acc: 60.045,92.485,99.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.792 | Acc: 58.727,92.302,99.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.780 | Acc: 59.221,92.367,99.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.791 | Acc: 59.298,91.975,99.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.769 | Acc: 59.839,92.218,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.768 | Acc: 60.118,92.239,99.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.774 | Acc: 60.018,92.199,99.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.780 | Acc: 59.899,92.178,99.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.775 | Acc: 60.027,92.226,99.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.773 | Acc: 60.141,92.090,99.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.775 | Acc: 60.156,91.986,99.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.770 | Acc: 60.270,92.019,99.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.773 | Acc: 60.276,91.960,99.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.773 | Acc: 60.348,91.960,99.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.771 | Acc: 60.317,92.011,99.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.770 | Acc: 60.310,92.029,99.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.771 | Acc: 60.301,91.981,99.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.771 | Acc: 60.310,91.947,99.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.768 | Acc: 60.390,91.931,99.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.005 | Acc: 57.031,75.000,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.038 | Acc: 53.051,69.903,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.084 | Acc: 52.744,69.017,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.090 | Acc: 52.561,69.211,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.657 | Acc: 61.719,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.726 | Acc: 60.193,92.374,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.678 | Acc: 61.643,92.740,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.695 | Acc: 61.155,92.789,99.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.703 | Acc: 60.918,92.718,99.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.715 | Acc: 61.054,92.567,99.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.730 | Acc: 60.750,92.536,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.741 | Acc: 60.544,92.393,99.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.744 | Acc: 60.409,92.411,99.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.748 | Acc: 60.368,92.364,99.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.755 | Acc: 60.347,92.300,99.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.751 | Acc: 60.411,92.322,99.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.755 | Acc: 60.399,92.233,99.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.754 | Acc: 60.480,92.268,99.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.751 | Acc: 60.543,92.307,99.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.749 | Acc: 60.535,92.263,99.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.753 | Acc: 60.482,92.243,99.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.754 | Acc: 60.479,92.279,99.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.754 | Acc: 60.446,92.255,99.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.755 | Acc: 60.398,92.229,99.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.052 | Acc: 55.469,74.219,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.088 | Acc: 52.679,69.829,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.111 | Acc: 52.687,68.788,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.111 | Acc: 52.638,69.045,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.836 | Acc: 58.594,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.788 | Acc: 60.417,91.555,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.743 | Acc: 60.861,91.578,99.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.722 | Acc: 61.014,91.855,99.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.739 | Acc: 60.465,92.014,99.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.732 | Acc: 60.744,92.218,99.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.725 | Acc: 60.938,92.330,99.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.725 | Acc: 60.960,92.304,99.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.727 | Acc: 60.938,92.333,99.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.733 | Acc: 60.838,92.205,99.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.730 | Acc: 60.875,92.289,99.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.732 | Acc: 60.775,92.262,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.736 | Acc: 60.756,92.243,99.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.733 | Acc: 60.836,92.292,99.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.734 | Acc: 60.835,92.251,99.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.732 | Acc: 60.857,92.315,99.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.733 | Acc: 60.852,92.346,99.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.734 | Acc: 60.848,92.297,99.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.737 | Acc: 60.747,92.276,99.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.739 | Acc: 60.696,92.278,99.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.013 | Acc: 54.688,74.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.102 | Acc: 52.716,69.978,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.122 | Acc: 53.144,69.017,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.128 | Acc: 52.651,69.147,74.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.546 | Acc: 60.156,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.685 | Acc: 60.007,93.304,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.693 | Acc: 60.385,93.369,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.710 | Acc: 60.681,92.956,99.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.705 | Acc: 60.947,92.853,99.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.704 | Acc: 61.108,92.683,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.706 | Acc: 61.131,92.639,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.701 | Acc: 61.143,92.736,99.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.706 | Acc: 61.039,92.755,99.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.712 | Acc: 60.860,92.766,99.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.717 | Acc: 60.856,92.712,99.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.720 | Acc: 60.771,92.665,99.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.721 | Acc: 60.737,92.654,99.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.724 | Acc: 60.704,92.628,99.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.725 | Acc: 60.707,92.582,99.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.721 | Acc: 60.771,92.616,99.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.720 | Acc: 60.843,92.570,99.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.721 | Acc: 60.889,92.547,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.723 | Acc: 60.825,92.573,99.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.726 | Acc: 60.732,92.565,99.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.989 | Acc: 57.812,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.082 | Acc: 52.530,69.457,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.100 | Acc: 52.934,68.769,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.093 | Acc: 52.651,68.865,74.206,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.757 | Acc: 54.688,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.649 | Acc: 62.388,93.192,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.656 | Acc: 61.966,93.255,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.655 | Acc: 62.129,93.340,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.664 | Acc: 61.912,93.248,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.679 | Acc: 61.742,93.178,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.685 | Acc: 61.686,93.169,99.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.696 | Acc: 61.403,93.063,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.700 | Acc: 61.175,92.974,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.701 | Acc: 61.149,92.956,99.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.705 | Acc: 61.074,92.930,99.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.701 | Acc: 61.181,92.937,99.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.706 | Acc: 61.057,92.894,99.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.706 | Acc: 60.991,92.897,99.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.707 | Acc: 60.915,92.891,99.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.711 | Acc: 60.782,92.782,99.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.716 | Acc: 60.718,92.686,99.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.717 | Acc: 60.736,92.641,99.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.718 | Acc: 60.676,92.597,99.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.720 | Acc: 60.595,92.616,99.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.049 | Acc: 57.812,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.061 | Acc: 52.939,70.015,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.096 | Acc: 53.030,69.093,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.098 | Acc: 52.907,69.249,74.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.623 | Acc: 58.594,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.713 | Acc: 61.049,92.857,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.708 | Acc: 60.537,93.197,99.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.707 | Acc: 60.400,93.097,99.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.703 | Acc: 60.571,93.383,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.692 | Acc: 60.961,93.487,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.691 | Acc: 60.899,93.356,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.687 | Acc: 60.893,93.373,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.693 | Acc: 60.787,93.274,99.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.693 | Acc: 60.761,93.150,99.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.691 | Acc: 60.697,93.144,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.693 | Acc: 60.778,93.078,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.697 | Acc: 60.636,93.017,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.699 | Acc: 60.635,93.005,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.695 | Acc: 60.771,92.963,99.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.693 | Acc: 60.860,92.971,99.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.697 | Acc: 60.753,92.920,99.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.698 | Acc: 60.724,92.907,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.700 | Acc: 60.756,92.904,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.703 | Acc: 60.706,92.854,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.051 | Acc: 55.469,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.072 | Acc: 52.604,69.234,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.115 | Acc: 52.801,68.636,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.125 | Acc: 52.638,68.891,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.416 | Acc: 67.969,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.729 | Acc: 59.970,92.932,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.706 | Acc: 59.870,93.388,99.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.695 | Acc: 60.015,93.430,99.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.697 | Acc: 60.089,93.133,99.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.691 | Acc: 60.342,93.294,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.694 | Acc: 60.415,93.240,99.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.699 | Acc: 60.284,93.168,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.701 | Acc: 60.321,93.134,99.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.699 | Acc: 60.441,93.206,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.698 | Acc: 60.498,93.186,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.695 | Acc: 60.556,93.135,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.695 | Acc: 60.513,93.189,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.696 | Acc: 60.617,93.148,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.695 | Acc: 60.582,93.191,99.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.697 | Acc: 60.603,93.174,99.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.697 | Acc: 60.643,93.120,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.698 | Acc: 60.722,93.088,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.700 | Acc: 60.686,93.088,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.697 | Acc: 60.763,93.086,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.038 | Acc: 57.031,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.100 | Acc: 52.902,69.606,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.141 | Acc: 52.877,68.883,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.136 | Acc: 52.830,69.109,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.629 | Acc: 64.844,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.664 | Acc: 61.124,92.932,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.624 | Acc: 62.081,93.255,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.629 | Acc: 62.129,93.302,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.639 | Acc: 62.027,93.065,99.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.653 | Acc: 61.796,93.154,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.657 | Acc: 61.667,93.259,99.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.663 | Acc: 61.475,93.368,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.667 | Acc: 61.369,93.439,99.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.678 | Acc: 61.011,93.284,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.683 | Acc: 60.906,93.167,99.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.682 | Acc: 60.874,93.191,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.687 | Acc: 60.759,93.102,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.688 | Acc: 60.734,93.082,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.690 | Acc: 60.693,93.077,99.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.688 | Acc: 60.777,93.073,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.686 | Acc: 60.821,93.083,99.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.686 | Acc: 60.754,93.088,99.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.688 | Acc: 60.743,93.083,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.688 | Acc: 60.784,93.108,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.000 | Acc: 54.688,75.000,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.106 | Acc: 53.088,69.048,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.126 | Acc: 53.468,68.540,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.133 | Acc: 53.125,68.788,74.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.724 | Acc: 61.719,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.621 | Acc: 61.570,94.085,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.647 | Acc: 60.880,94.169,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.667 | Acc: 60.284,93.673,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.658 | Acc: 60.870,93.692,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.663 | Acc: 60.976,93.634,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.672 | Acc: 60.841,93.589,99.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.671 | Acc: 60.976,93.551,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.669 | Acc: 60.971,93.473,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.664 | Acc: 61.158,93.534,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.669 | Acc: 61.140,93.517,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.671 | Acc: 61.090,93.471,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.671 | Acc: 61.132,93.487,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.675 | Acc: 60.967,93.508,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.677 | Acc: 60.932,93.494,99.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.678 | Acc: 61.000,93.423,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.677 | Acc: 60.989,93.395,99.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.675 | Acc: 61.047,93.377,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.677 | Acc: 60.987,93.343,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.675 | Acc: 61.034,93.358,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.920 | Acc: 54.688,74.219,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.102 | Acc: 51.860,69.643,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.133 | Acc: 52.325,68.864,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.142 | Acc: 52.216,68.724,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.474 | Acc: 71.094,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.662 | Acc: 61.049,93.973,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.660 | Acc: 61.280,93.902,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.681 | Acc: 60.643,93.699,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.659 | Acc: 61.024,93.875,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.659 | Acc: 60.968,93.704,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.658 | Acc: 60.976,93.627,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.663 | Acc: 60.838,93.484,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.665 | Acc: 60.904,93.473,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.665 | Acc: 60.946,93.405,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.666 | Acc: 60.922,93.427,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.664 | Acc: 61.001,93.407,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.670 | Acc: 60.843,93.380,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.665 | Acc: 60.899,93.427,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.665 | Acc: 60.874,93.400,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.667 | Acc: 60.813,93.444,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.669 | Acc: 60.799,93.448,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.672 | Acc: 60.724,93.422,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.675 | Acc: 60.734,93.371,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.674 | Acc: 60.755,93.381,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.089 | Acc: 54.688,74.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.157 | Acc: 52.121,69.420,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.180 | Acc: 52.248,68.617,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.175 | Acc: 52.280,68.673,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.493 | Acc: 61.719,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.635 | Acc: 61.310,94.010,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.638 | Acc: 61.261,93.960,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.628 | Acc: 61.578,94.109,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.633 | Acc: 61.400,94.068,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.634 | Acc: 61.224,94.028,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.634 | Acc: 61.273,93.989,99.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.642 | Acc: 61.331,93.922,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.639 | Acc: 61.496,93.968,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.643 | Acc: 61.447,93.897,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.638 | Acc: 61.742,93.956,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.638 | Acc: 61.698,93.951,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.639 | Acc: 61.673,93.970,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.639 | Acc: 61.716,93.942,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.648 | Acc: 61.482,93.917,99.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.647 | Acc: 61.550,93.888,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.647 | Acc: 61.485,93.877,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.650 | Acc: 61.444,93.816,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.652 | Acc: 61.427,93.808,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.654 | Acc: 61.362,93.783,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.100 | Acc: 57.812,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.155 | Acc: 52.158,69.531,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.187 | Acc: 51.982,68.693,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.180 | Acc: 52.011,68.827,74.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 1.559 | Acc: 58.594,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.584 | Acc: 63.132,94.196,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.599 | Acc: 62.957,94.207,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.609 | Acc: 62.474,93.801,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.617 | Acc: 62.307,93.981,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.618 | Acc: 62.051,93.889,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.623 | Acc: 61.745,93.892,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.633 | Acc: 61.619,93.783,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.635 | Acc: 61.505,93.799,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.637 | Acc: 61.486,93.733,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.633 | Acc: 61.536,93.707,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.639 | Acc: 61.415,93.732,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.643 | Acc: 61.356,93.679,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.645 | Acc: 61.297,93.669,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.644 | Acc: 61.341,93.719,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.645 | Acc: 61.394,93.685,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.648 | Acc: 61.383,93.672,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.648 | Acc: 61.361,93.690,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.649 | Acc: 61.366,93.702,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.649 | Acc: 61.329,93.715,99.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.026 | Acc: 56.250,71.875,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.123 | Acc: 52.939,69.048,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.149 | Acc: 52.915,68.674,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.158 | Acc: 52.664,68.673,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.615 | Acc: 64.062,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.642 | Acc: 61.570,94.345,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.609 | Acc: 61.719,94.836,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.612 | Acc: 61.527,94.698,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.604 | Acc: 61.603,94.473,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.607 | Acc: 61.409,94.539,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.617 | Acc: 61.312,94.518,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.621 | Acc: 61.492,94.481,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.625 | Acc: 61.491,94.381,99.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.621 | Acc: 61.542,94.393,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.618 | Acc: 61.571,94.352,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.629 | Acc: 61.330,94.231,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.630 | Acc: 61.398,94.158,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.634 | Acc: 61.309,94.088,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.639 | Acc: 61.279,94.025,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.641 | Acc: 61.254,93.991,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.644 | Acc: 61.230,93.974,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.643 | Acc: 61.270,93.929,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.645 | Acc: 61.243,93.893,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.646 | Acc: 61.206,93.861,99.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.045 | Acc: 57.812,74.219,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.153 | Acc: 52.976,69.568,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.177 | Acc: 52.782,68.655,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.192 | Acc: 52.472,68.852,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 1.422 | Acc: 64.844,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.660 | Acc: 60.751,93.936,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.678 | Acc: 60.595,93.731,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.643 | Acc: 61.475,94.032,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.637 | Acc: 61.535,94.126,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.641 | Acc: 61.317,94.090,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.632 | Acc: 61.506,94.163,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.632 | Acc: 61.630,94.149,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.634 | Acc: 61.559,94.002,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.638 | Acc: 61.443,94.022,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.636 | Acc: 61.532,93.991,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.638 | Acc: 61.461,94.050,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.634 | Acc: 61.576,94.058,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.631 | Acc: 61.638,94.070,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.628 | Acc: 61.658,94.036,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.628 | Acc: 61.589,94.041,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.628 | Acc: 61.529,94.018,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.631 | Acc: 61.483,93.954,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.632 | Acc: 61.552,93.932,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.633 | Acc: 61.579,93.930,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.092 | Acc: 56.250,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.150 | Acc: 52.716,69.531,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.171 | Acc: 52.820,68.540,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.174 | Acc: 52.600,68.904,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.627 | Acc: 57.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.604 | Acc: 62.314,94.643,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.601 | Acc: 61.928,94.417,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.614 | Acc: 61.501,94.608,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.609 | Acc: 61.806,94.425,99.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.605 | Acc: 61.982,94.516,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.608 | Acc: 61.900,94.486,99.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.609 | Acc: 61.846,94.443,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.613 | Acc: 61.772,94.376,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.613 | Acc: 61.835,94.320,99.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.616 | Acc: 61.765,94.325,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.616 | Acc: 61.860,94.301,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.616 | Acc: 61.868,94.314,99.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.619 | Acc: 61.785,94.340,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.618 | Acc: 61.788,94.334,99.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.618 | Acc: 61.846,94.295,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.617 | Acc: 61.877,94.234,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.618 | Acc: 61.792,94.213,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.624 | Acc: 61.706,94.142,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.626 | Acc: 61.620,94.115,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.017 | Acc: 55.469,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.127 | Acc: 52.976,69.568,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.176 | Acc: 52.706,68.559,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.190 | Acc: 52.318,68.840,74.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.697 | Acc: 61.719,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.596 | Acc: 62.760,94.829,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.590 | Acc: 62.309,95.046,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.594 | Acc: 61.936,94.839,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.604 | Acc: 61.970,94.715,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.603 | Acc: 61.989,94.686,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.606 | Acc: 61.861,94.570,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.612 | Acc: 61.929,94.548,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.606 | Acc: 62.005,94.488,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.606 | Acc: 62.047,94.536,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.606 | Acc: 62.174,94.457,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.608 | Acc: 62.016,94.415,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.611 | Acc: 61.887,94.385,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.616 | Acc: 61.827,94.325,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.615 | Acc: 61.872,94.312,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.615 | Acc: 61.916,94.329,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.619 | Acc: 61.806,94.283,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.622 | Acc: 61.735,94.254,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.626 | Acc: 61.643,94.222,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.627 | Acc: 61.678,94.201,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.048 | Acc: 57.031,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.168 | Acc: 52.046,69.531,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.212 | Acc: 52.591,68.826,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.219 | Acc: 52.318,68.852,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.482 | Acc: 69.531,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.590 | Acc: 61.682,95.461,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.591 | Acc: 61.490,94.607,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.611 | Acc: 61.168,94.288,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.600 | Acc: 61.429,94.319,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.601 | Acc: 61.301,94.245,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.608 | Acc: 61.306,94.279,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.607 | Acc: 61.514,94.287,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.607 | Acc: 61.593,94.269,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.606 | Acc: 61.650,94.259,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.609 | Acc: 61.583,94.267,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.615 | Acc: 61.386,94.277,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.618 | Acc: 61.314,94.324,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.613 | Acc: 61.518,94.334,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.612 | Acc: 61.513,94.364,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.612 | Acc: 61.509,94.373,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.615 | Acc: 61.488,94.322,99.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.620 | Acc: 61.409,94.291,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.619 | Acc: 61.403,94.278,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.619 | Acc: 61.417,94.242,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.080 | Acc: 57.812,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.160 | Acc: 52.493,69.792,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.194 | Acc: 52.687,68.636,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.200 | Acc: 52.638,68.788,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.854 | Acc: 56.250,92.969,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.591 | Acc: 60.789,94.717,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.587 | Acc: 61.452,94.760,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.585 | Acc: 61.578,94.903,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.588 | Acc: 61.458,94.859,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.582 | Acc: 61.843,94.949,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.592 | Acc: 61.803,94.751,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.596 | Acc: 61.636,94.753,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.594 | Acc: 61.835,94.691,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.596 | Acc: 61.801,94.687,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.591 | Acc: 61.991,94.679,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.594 | Acc: 61.973,94.613,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.593 | Acc: 61.936,94.616,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.600 | Acc: 61.871,94.525,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.601 | Acc: 61.819,94.445,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.601 | Acc: 61.771,94.435,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.601 | Acc: 61.680,94.407,99.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.601 | Acc: 61.714,94.417,99.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.604 | Acc: 61.637,94.345,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.604 | Acc: 61.713,94.357,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.031 | Acc: 57.031,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.113 | Acc: 52.641,69.866,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.162 | Acc: 52.954,69.017,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.175 | Acc: 52.766,69.160,74.334,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.699 | Acc: 57.031,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.562 | Acc: 61.235,95.647,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.581 | Acc: 61.757,95.027,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.586 | Acc: 61.450,94.864,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.596 | Acc: 61.333,94.743,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.596 | Acc: 61.347,94.647,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.598 | Acc: 61.441,94.615,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.597 | Acc: 61.303,94.637,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.602 | Acc: 61.321,94.604,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.605 | Acc: 61.218,94.553,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.602 | Acc: 61.377,94.601,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.597 | Acc: 61.524,94.655,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.595 | Acc: 61.453,94.560,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.594 | Acc: 61.503,94.558,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.596 | Acc: 61.599,94.562,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.601 | Acc: 61.516,94.523,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.602 | Acc: 61.449,94.522,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.606 | Acc: 61.375,94.481,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.605 | Acc: 61.468,94.445,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.607 | Acc: 61.430,94.404,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.129 | Acc: 58.594,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.169 | Acc: 53.571,69.754,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.187 | Acc: 53.601,68.750,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.196 | Acc: 53.087,68.865,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.556 | Acc: 64.062,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.526 | Acc: 63.802,95.201,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.552 | Acc: 62.805,95.103,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.560 | Acc: 62.257,95.261,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.573 | Acc: 61.970,95.091,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.572 | Acc: 62.152,95.150,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.570 | Acc: 62.300,95.138,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.574 | Acc: 62.350,95.035,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.579 | Acc: 62.257,94.915,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.578 | Acc: 62.250,94.872,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.578 | Acc: 62.286,94.897,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.585 | Acc: 62.132,94.853,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.583 | Acc: 62.137,94.820,99.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.581 | Acc: 62.198,94.783,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.582 | Acc: 62.164,94.729,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.586 | Acc: 62.054,94.697,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.589 | Acc: 62.035,94.655,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.589 | Acc: 62.097,94.607,99.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.589 | Acc: 62.063,94.575,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.593 | Acc: 61.938,94.562,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.346 | Acc: 54.688,72.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.167 | Acc: 53.199,69.085,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.207 | Acc: 53.182,68.178,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.207 | Acc: 52.702,68.404,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.500 | Acc: 64.062,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.558 | Acc: 63.021,94.940,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.544 | Acc: 62.976,95.351,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.556 | Acc: 62.436,95.312,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.571 | Acc: 62.201,95.177,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.575 | Acc: 62.508,95.057,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.570 | Acc: 62.681,94.951,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.576 | Acc: 62.533,94.836,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.573 | Acc: 62.529,94.793,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.576 | Acc: 62.427,94.700,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.576 | Acc: 62.473,94.640,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.582 | Acc: 62.295,94.623,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.584 | Acc: 62.186,94.583,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.586 | Acc: 62.165,94.597,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.582 | Acc: 62.108,94.665,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.581 | Acc: 62.121,94.661,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.583 | Acc: 62.035,94.677,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.589 | Acc: 61.838,94.623,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.591 | Acc: 61.751,94.596,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.594 | Acc: 61.708,94.558,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.994 | Acc: 56.250,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.184 | Acc: 51.786,69.457,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.214 | Acc: 52.115,68.236,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.214 | Acc: 51.998,68.481,74.296,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.289 | Acc: 64.062,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.580 | Acc: 61.756,94.531,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.576 | Acc: 61.814,94.836,99.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.588 | Acc: 61.258,94.813,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.590 | Acc: 61.121,94.715,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.592 | Acc: 61.231,94.601,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.595 | Acc: 61.215,94.686,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.589 | Acc: 61.464,94.620,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.588 | Acc: 61.447,94.623,99.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.587 | Acc: 61.611,94.661,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.587 | Acc: 61.734,94.683,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.586 | Acc: 61.860,94.673,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.587 | Acc: 61.764,94.671,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.588 | Acc: 61.859,94.672,99.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.589 | Acc: 61.805,94.631,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.586 | Acc: 61.882,94.661,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.584 | Acc: 61.928,94.692,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.585 | Acc: 61.904,94.682,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.587 | Acc: 61.885,94.657,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.590 | Acc: 61.889,94.619,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.132 | Acc: 54.688,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.237 | Acc: 52.269,69.643,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.259 | Acc: 52.820,68.693,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.258 | Acc: 52.459,68.686,74.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.523 | Acc: 63.281,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.620 | Acc: 61.124,95.052,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.608 | Acc: 60.976,95.027,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.610 | Acc: 61.206,94.980,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.600 | Acc: 61.574,94.994,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.598 | Acc: 61.510,94.918,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.588 | Acc: 61.712,94.951,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.582 | Acc: 61.929,94.975,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.586 | Acc: 61.762,94.939,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.582 | Acc: 61.930,94.915,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.589 | Acc: 61.715,94.858,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.588 | Acc: 61.761,94.750,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.587 | Acc: 61.709,94.784,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.587 | Acc: 61.761,94.765,99.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.584 | Acc: 61.794,94.781,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.581 | Acc: 61.895,94.786,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.582 | Acc: 61.933,94.787,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.585 | Acc: 61.904,94.740,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.588 | Acc: 61.922,94.707,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.591 | Acc: 61.856,94.693,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.108 | Acc: 55.469,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.199 | Acc: 52.716,69.382,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.226 | Acc: 53.144,68.731,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.234 | Acc: 52.946,68.724,74.129,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 1.622 | Acc: 63.281,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.562 | Acc: 62.277,95.685,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.526 | Acc: 62.710,95.675,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.527 | Acc: 63.192,95.402,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.526 | Acc: 63.272,95.264,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.535 | Acc: 63.103,95.196,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.538 | Acc: 62.939,95.164,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.534 | Acc: 62.871,95.119,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.541 | Acc: 62.718,95.041,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.545 | Acc: 62.578,95.062,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.557 | Acc: 62.352,94.955,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.564 | Acc: 62.136,94.818,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.563 | Acc: 62.325,94.839,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.566 | Acc: 62.246,94.819,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.567 | Acc: 62.239,94.801,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.571 | Acc: 62.129,94.767,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.572 | Acc: 62.079,94.772,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.579 | Acc: 62.023,94.712,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.583 | Acc: 61.922,94.724,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.583 | Acc: 61.905,94.697,99.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.181 | Acc: 53.125,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.235 | Acc: 51.823,68.936,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.277 | Acc: 52.115,67.835,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.282 | Acc: 52.164,68.084,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.656 | Acc: 59.375,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.573 | Acc: 61.421,96.019,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.550 | Acc: 62.119,95.675,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.545 | Acc: 62.218,95.607,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.555 | Acc: 62.365,95.351,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.549 | Acc: 62.662,95.320,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.559 | Acc: 62.481,95.280,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.558 | Acc: 62.489,95.307,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.554 | Acc: 62.418,95.191,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.549 | Acc: 62.621,95.265,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.557 | Acc: 62.290,95.270,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.563 | Acc: 62.182,95.267,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.566 | Acc: 62.273,95.196,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.566 | Acc: 62.234,95.199,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.565 | Acc: 62.269,95.162,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.565 | Acc: 62.235,95.196,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.565 | Acc: 62.276,95.125,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.570 | Acc: 62.177,95.070,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.573 | Acc: 62.113,95.031,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.576 | Acc: 62.073,94.984,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.199 | Acc: 57.031,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.180 | Acc: 52.716,69.717,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.241 | Acc: 52.820,68.693,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.253 | Acc: 52.497,68.929,74.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.441 | Acc: 62.500,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.571 | Acc: 62.277,94.903,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.567 | Acc: 62.710,95.293,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.561 | Acc: 62.731,95.261,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.560 | Acc: 62.654,95.255,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.565 | Acc: 62.430,95.065,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.562 | Acc: 62.506,95.093,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.557 | Acc: 62.744,95.157,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.553 | Acc: 62.738,95.157,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.556 | Acc: 62.595,95.222,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.554 | Acc: 62.636,95.192,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.554 | Acc: 62.677,95.189,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.553 | Acc: 62.814,95.134,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.557 | Acc: 62.793,95.088,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.559 | Acc: 62.795,95.085,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.561 | Acc: 62.708,95.071,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.562 | Acc: 62.627,95.037,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.560 | Acc: 62.738,95.063,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.563 | Acc: 62.587,95.016,99.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.565 | Acc: 62.479,95.003,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.047 | Acc: 56.250,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.209 | Acc: 52.604,69.196,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.272 | Acc: 52.553,68.350,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.284 | Acc: 52.113,68.199,74.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 1.356 | Acc: 67.188,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.479 | Acc: 64.062,95.499,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.498 | Acc: 63.891,96.018,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.492 | Acc: 63.883,95.761,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.500 | Acc: 63.465,95.583,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.513 | Acc: 63.096,95.421,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.520 | Acc: 62.939,95.409,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.524 | Acc: 62.916,95.318,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.528 | Acc: 62.806,95.288,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.537 | Acc: 62.617,95.192,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.539 | Acc: 62.593,95.122,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.547 | Acc: 62.405,95.019,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.550 | Acc: 62.422,95.037,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.554 | Acc: 62.338,95.010,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.556 | Acc: 62.305,94.990,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.560 | Acc: 62.191,94.965,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.564 | Acc: 62.128,94.923,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.570 | Acc: 62.014,94.914,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.572 | Acc: 61.935,94.906,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.573 | Acc: 61.852,94.888,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.217 | Acc: 57.031,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.246 | Acc: 52.232,69.457,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.278 | Acc: 52.382,68.388,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.277 | Acc: 52.049,68.558,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.613 | Acc: 60.938,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.550 | Acc: 62.388,95.424,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.560 | Acc: 62.024,95.332,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.562 | Acc: 62.193,95.479,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.553 | Acc: 62.288,95.351,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.560 | Acc: 62.028,95.359,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.558 | Acc: 62.035,95.358,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.554 | Acc: 62.156,95.324,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.555 | Acc: 62.088,95.371,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.556 | Acc: 62.047,95.373,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.557 | Acc: 62.107,95.347,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.554 | Acc: 62.129,95.358,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.553 | Acc: 62.062,95.355,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.553 | Acc: 62.078,95.330,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.552 | Acc: 62.116,95.338,99.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.552 | Acc: 62.064,95.310,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.552 | Acc: 62.023,95.291,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.555 | Acc: 62.044,95.225,99.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.557 | Acc: 62.033,95.206,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.561 | Acc: 61.969,95.177,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.137 | Acc: 55.469,74.219,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.205 | Acc: 52.865,69.420,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.254 | Acc: 52.820,68.579,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.261 | Acc: 52.421,68.737,74.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.135 | Acc: 67.969,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.488 | Acc: 63.281,95.461,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.505 | Acc: 62.786,95.503,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.502 | Acc: 63.025,95.569,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.516 | Acc: 62.654,95.669,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.519 | Acc: 62.601,95.521,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.506 | Acc: 63.113,95.597,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.513 | Acc: 63.037,95.601,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.517 | Acc: 62.840,95.570,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.520 | Acc: 62.819,95.507,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.521 | Acc: 62.846,95.499,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.525 | Acc: 62.755,95.500,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.528 | Acc: 62.733,95.488,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.530 | Acc: 62.683,95.441,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.530 | Acc: 62.725,95.435,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.534 | Acc: 62.583,95.419,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.537 | Acc: 62.519,95.400,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.543 | Acc: 62.413,95.335,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.546 | Acc: 62.407,95.278,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.552 | Acc: 62.318,95.259,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.217 | Acc: 56.250,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.245 | Acc: 51.860,69.308,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.276 | Acc: 52.591,68.693,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.284 | Acc: 52.472,68.545,74.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.527 | Acc: 61.719,99.219,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.557 | Acc: 62.537,95.126,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.536 | Acc: 62.957,95.312,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.524 | Acc: 63.064,95.530,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.531 | Acc: 62.809,95.563,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.546 | Acc: 62.454,95.514,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.542 | Acc: 62.565,95.545,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.546 | Acc: 62.334,95.479,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.541 | Acc: 62.393,95.497,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.540 | Acc: 62.358,95.554,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.540 | Acc: 62.446,95.499,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.539 | Acc: 62.429,95.525,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.544 | Acc: 62.374,95.471,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.542 | Acc: 62.464,95.471,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.544 | Acc: 62.506,95.385,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.546 | Acc: 62.560,95.354,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.547 | Acc: 62.505,95.349,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.548 | Acc: 62.406,95.319,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.547 | Acc: 62.424,95.310,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.550 | Acc: 62.352,95.315,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.970 | Acc: 55.469,74.219,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.207 | Acc: 52.567,69.754,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.244 | Acc: 52.839,69.188,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.252 | Acc: 52.561,68.891,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.521 | Acc: 61.719,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.482 | Acc: 63.765,95.796,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.527 | Acc: 62.633,95.427,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.517 | Acc: 62.462,95.569,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.526 | Acc: 62.635,95.515,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.523 | Acc: 62.809,95.568,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.526 | Acc: 62.649,95.551,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.523 | Acc: 62.583,95.595,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.517 | Acc: 62.728,95.589,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.523 | Acc: 62.612,95.507,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.533 | Acc: 62.484,95.398,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.534 | Acc: 62.564,95.457,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.533 | Acc: 62.519,95.429,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.534 | Acc: 62.419,95.429,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.543 | Acc: 62.172,95.363,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.546 | Acc: 62.100,95.315,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.545 | Acc: 62.145,95.303,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.547 | Acc: 62.140,95.255,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.547 | Acc: 62.173,95.241,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.547 | Acc: 62.194,95.208,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.085 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.226 | Acc: 52.827,69.048,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.275 | Acc: 52.858,68.274,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.287 | Acc: 52.587,68.340,74.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.591 | Acc: 61.719,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.500 | Acc: 63.058,95.871,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.503 | Acc: 63.529,95.560,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 62.999,95.453,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.517 | Acc: 62.944,95.505,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.511 | Acc: 63.134,95.537,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.512 | Acc: 63.159,95.603,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.514 | Acc: 63.237,95.512,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.517 | Acc: 63.136,95.434,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.523 | Acc: 62.958,95.459,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.524 | Acc: 63.021,95.472,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.526 | Acc: 62.921,95.479,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.528 | Acc: 62.824,95.429,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.531 | Acc: 62.716,95.423,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.534 | Acc: 62.595,95.401,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.536 | Acc: 62.477,95.427,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.536 | Acc: 62.510,95.422,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.533 | Acc: 62.628,95.425,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.534 | Acc: 62.532,95.438,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.535 | Acc: 62.535,95.419,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.159 | Acc: 56.250,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.235 | Acc: 53.311,69.234,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.289 | Acc: 52.763,68.159,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.303 | Acc: 52.587,68.135,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.348 | Acc: 61.719,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.573 | Acc: 61.421,95.461,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.530 | Acc: 62.576,95.789,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 62.782,95.761,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.518 | Acc: 62.654,95.747,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.526 | Acc: 62.361,95.614,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.532 | Acc: 62.339,95.551,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.526 | Acc: 62.539,95.518,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.527 | Acc: 62.665,95.424,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.536 | Acc: 62.453,95.399,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.531 | Acc: 62.465,95.421,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.534 | Acc: 62.366,95.436,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.535 | Acc: 62.438,95.364,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.535 | Acc: 62.434,95.348,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.535 | Acc: 62.494,95.351,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.540 | Acc: 62.549,95.268,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.542 | Acc: 62.502,95.218,99.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.544 | Acc: 62.392,95.216,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.546 | Acc: 62.385,95.200,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.544 | Acc: 62.432,95.220,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.241 | Acc: 53.906,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.233 | Acc: 52.493,69.159,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.281 | Acc: 52.515,68.083,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.282 | Acc: 52.433,68.212,74.193,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 1.535 | Acc: 59.375,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.492 | Acc: 64.062,95.945,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.477 | Acc: 63.472,96.037,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.492 | Acc: 63.358,95.620,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.505 | Acc: 63.002,95.438,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.508 | Acc: 62.794,95.653,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.515 | Acc: 62.810,95.603,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.519 | Acc: 62.788,95.650,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.517 | Acc: 62.728,95.676,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.518 | Acc: 62.629,95.662,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.523 | Acc: 62.535,95.623,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.520 | Acc: 62.528,95.655,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.522 | Acc: 62.490,95.646,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.523 | Acc: 62.500,95.627,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.523 | Acc: 62.497,95.629,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.525 | Acc: 62.370,95.588,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.528 | Acc: 62.352,95.575,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.531 | Acc: 62.404,95.523,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 62.396,95.499,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.535 | Acc: 62.340,95.433,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.347 | Acc: 54.688,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.288 | Acc: 52.493,68.936,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.335 | Acc: 52.934,68.197,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.330 | Acc: 52.485,68.251,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 1.405 | Acc: 68.750,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.480 | Acc: 64.621,95.647,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.491 | Acc: 63.548,96.227,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.519 | Acc: 63.012,95.953,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.508 | Acc: 62.838,95.833,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.514 | Acc: 62.492,95.893,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.518 | Acc: 62.526,95.816,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.523 | Acc: 62.417,95.706,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.525 | Acc: 62.549,95.652,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.527 | Acc: 62.504,95.645,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.530 | Acc: 62.453,95.588,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.529 | Acc: 62.472,95.609,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.531 | Acc: 62.370,95.575,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.531 | Acc: 62.428,95.570,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.534 | Acc: 62.408,95.490,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.535 | Acc: 62.430,95.481,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.535 | Acc: 62.478,95.449,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.538 | Acc: 62.429,95.409,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.540 | Acc: 62.370,95.382,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.540 | Acc: 62.350,95.370,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.204 | Acc: 51.562,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.261 | Acc: 51.786,69.048,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.295 | Acc: 52.058,68.064,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.293 | Acc: 52.164,67.905,74.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.603 | Acc: 58.594,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.559 | Acc: 62.351,95.499,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.534 | Acc: 62.595,95.312,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.507 | Acc: 63.243,95.556,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.507 | Acc: 63.407,95.679,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.507 | Acc: 63.219,95.622,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.511 | Acc: 63.088,95.603,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 63.320,95.628,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.508 | Acc: 63.048,95.618,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 63.018,95.533,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.512 | Acc: 62.939,95.538,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.517 | Acc: 62.804,95.546,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.522 | Acc: 62.733,95.533,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.526 | Acc: 62.698,95.531,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.526 | Acc: 62.650,95.515,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.527 | Acc: 62.627,95.507,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.528 | Acc: 62.583,95.488,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.532 | Acc: 62.498,95.416,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 62.543,95.384,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.532 | Acc: 62.531,95.378,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.235 | Acc: 57.031,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.219 | Acc: 52.567,69.122,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.280 | Acc: 52.954,67.988,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.278 | Acc: 52.587,67.956,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.289 | Acc: 67.969,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.483 | Acc: 64.397,96.205,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.482 | Acc: 64.329,95.713,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.475 | Acc: 64.152,95.658,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.482 | Acc: 63.764,95.631,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.481 | Acc: 63.939,95.676,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.493 | Acc: 63.552,95.816,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.497 | Acc: 63.564,95.673,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.500 | Acc: 63.301,95.599,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.499 | Acc: 63.186,95.619,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.504 | Acc: 63.040,95.627,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.509 | Acc: 62.988,95.588,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.513 | Acc: 62.938,95.598,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.516 | Acc: 62.904,95.633,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.515 | Acc: 62.936,95.618,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.516 | Acc: 62.954,95.608,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.517 | Acc: 62.958,95.600,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.520 | Acc: 62.949,95.576,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.518 | Acc: 63.037,95.583,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.521 | Acc: 62.931,95.573,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.215 | Acc: 53.906,71.875,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.304 | Acc: 51.860,68.862,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.359 | Acc: 52.268,67.893,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.369 | Acc: 51.396,67.994,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.752 | Acc: 60.156,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.552 | Acc: 62.388,96.019,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.540 | Acc: 61.966,95.941,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.533 | Acc: 62.154,95.953,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.527 | Acc: 62.510,95.997,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.515 | Acc: 62.864,95.924,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.512 | Acc: 62.926,95.881,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.508 | Acc: 62.993,95.911,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.509 | Acc: 62.985,95.919,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.510 | Acc: 63.052,95.861,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.515 | Acc: 63.110,95.752,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.519 | Acc: 62.942,95.680,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.514 | Acc: 63.006,95.685,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.512 | Acc: 63.081,95.708,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.516 | Acc: 62.959,95.716,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.513 | Acc: 63.004,95.712,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.514 | Acc: 62.923,95.692,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.514 | Acc: 62.931,95.695,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.520 | Acc: 62.781,95.654,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.520 | Acc: 62.803,95.624,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.210 | Acc: 55.469,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.266 | Acc: 52.158,68.973,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.320 | Acc: 52.134,68.026,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.319 | Acc: 52.100,68.212,74.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.361 | Acc: 66.406,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.518 | Acc: 62.314,96.540,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.526 | Acc: 62.176,96.322,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 62.398,95.914,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.512 | Acc: 62.461,95.824,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.517 | Acc: 62.562,95.722,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.526 | Acc: 62.364,95.655,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.522 | Acc: 62.472,95.689,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.521 | Acc: 62.442,95.710,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.520 | Acc: 62.483,95.731,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.528 | Acc: 62.251,95.620,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.523 | Acc: 62.380,95.613,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.521 | Acc: 62.506,95.614,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.519 | Acc: 62.587,95.654,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.521 | Acc: 62.531,95.604,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.523 | Acc: 62.474,95.577,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.524 | Acc: 62.510,95.561,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.526 | Acc: 62.486,95.514,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.530 | Acc: 62.426,95.449,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.529 | Acc: 62.465,95.438,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.216 | Acc: 56.250,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.220 | Acc: 53.497,68.601,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.297 | Acc: 53.392,67.912,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.304 | Acc: 52.561,67.982,74.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.625 | Acc: 60.156,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.499 | Acc: 62.574,95.908,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.481 | Acc: 63.453,96.018,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.487 | Acc: 62.935,95.876,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.480 | Acc: 63.339,95.872,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.495 | Acc: 62.933,95.893,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.493 | Acc: 62.978,95.919,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.496 | Acc: 62.860,95.839,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.494 | Acc: 62.912,95.861,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 62.975,95.813,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.495 | Acc: 62.795,95.798,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.503 | Acc: 62.694,95.765,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 62.730,95.760,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.506 | Acc: 62.704,95.738,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 62.767,95.727,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.513 | Acc: 62.697,95.686,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.514 | Acc: 62.712,95.656,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.516 | Acc: 62.670,95.620,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.520 | Acc: 62.636,95.557,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.520 | Acc: 62.627,95.552,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.097 | Acc: 54.688,73.438,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.253 | Acc: 52.381,68.713,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.317 | Acc: 52.649,67.816,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.329 | Acc: 52.228,68.097,74.283,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.355 | Acc: 64.062,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.463 | Acc: 64.100,96.168,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.462 | Acc: 64.215,96.056,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.484 | Acc: 63.794,95.799,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.476 | Acc: 63.937,95.862,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 63.645,95.877,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.484 | Acc: 63.552,95.848,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.489 | Acc: 63.470,95.795,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 63.427,95.822,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.496 | Acc: 63.156,95.818,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.499 | Acc: 63.040,95.736,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.499 | Acc: 62.988,95.776,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.499 | Acc: 62.973,95.783,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 62.850,95.794,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.502 | Acc: 62.850,95.807,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.504 | Acc: 62.856,95.746,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 62.870,95.738,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.508 | Acc: 62.800,95.661,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.512 | Acc: 62.777,95.620,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.516 | Acc: 62.713,95.565,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.137 | Acc: 57.031,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.323 | Acc: 51.935,68.787,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.373 | Acc: 52.096,67.645,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.372 | Acc: 51.780,67.879,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.788 | Acc: 54.688,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.520 | Acc: 63.095,95.647,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.508 | Acc: 63.415,95.960,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.501 | Acc: 62.948,96.043,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.493 | Acc: 63.291,96.007,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.490 | Acc: 63.320,96.016,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.493 | Acc: 63.249,96.029,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.497 | Acc: 63.109,95.972,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.492 | Acc: 63.272,95.948,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.494 | Acc: 63.333,95.917,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.496 | Acc: 63.297,95.861,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 63.423,95.899,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.495 | Acc: 63.314,95.886,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.496 | Acc: 63.290,95.902,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 63.198,95.835,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 63.126,95.837,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.503 | Acc: 63.014,95.831,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.507 | Acc: 62.979,95.755,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.509 | Acc: 62.939,95.758,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.511 | Acc: 62.914,95.760,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.369 | Acc: 55.469,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 51.376,69.271,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.347 | Acc: 51.486,68.121,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.356 | Acc: 51.473,68.148,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.682 | Acc: 56.250,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.470 | Acc: 64.174,96.280,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.470 | Acc: 63.681,96.418,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.482 | Acc: 63.601,96.324,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.484 | Acc: 63.465,96.229,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 63.606,96.156,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 63.520,96.120,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.493 | Acc: 63.248,96.088,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.500 | Acc: 62.966,96.074,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.505 | Acc: 62.880,96.076,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.508 | Acc: 62.780,96.094,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.508 | Acc: 62.790,96.030,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.507 | Acc: 62.772,96.016,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 62.757,95.953,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 62.781,95.919,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.509 | Acc: 62.780,95.868,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.507 | Acc: 62.819,95.877,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.507 | Acc: 62.844,95.872,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.509 | Acc: 62.788,95.841,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.509 | Acc: 62.756,95.827,99.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.023 | Acc: 57.031,73.438,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.247 | Acc: 52.753,68.564,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.290 | Acc: 52.668,67.873,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.296 | Acc: 52.459,67.866,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.579 | Acc: 61.719,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.472 | Acc: 64.137,95.647,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.453 | Acc: 64.215,96.265,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.451 | Acc: 64.152,96.171,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.458 | Acc: 64.034,95.997,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.473 | Acc: 63.660,95.900,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.477 | Acc: 63.520,95.835,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 63.564,95.867,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.481 | Acc: 63.339,95.866,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.484 | Acc: 63.260,95.809,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.486 | Acc: 63.254,95.864,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.488 | Acc: 63.182,95.868,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.490 | Acc: 63.126,95.860,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 63.153,95.884,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.492 | Acc: 63.139,95.849,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.496 | Acc: 63.074,95.793,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.494 | Acc: 63.133,95.821,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.495 | Acc: 63.116,95.826,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.497 | Acc: 63.043,95.810,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.501 | Acc: 62.992,95.760,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.294 | Acc: 55.469,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 52.009,68.378,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.342 | Acc: 52.325,67.816,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.349 | Acc: 51.998,67.828,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.316 | Acc: 66.406,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.467 | Acc: 63.988,96.429,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.459 | Acc: 64.120,96.208,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.470 | Acc: 63.268,96.132,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.484 | Acc: 63.175,96.152,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.488 | Acc: 63.142,96.156,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.482 | Acc: 63.320,96.216,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 63.337,96.049,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.486 | Acc: 63.500,96.050,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.488 | Acc: 63.506,95.973,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 63.359,95.954,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 63.242,95.966,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.498 | Acc: 63.071,95.925,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.504 | Acc: 62.997,95.884,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 62.906,95.860,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.510 | Acc: 62.832,95.852,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.512 | Acc: 62.765,95.807,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.510 | Acc: 62.802,95.800,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.512 | Acc: 62.766,95.769,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.510 | Acc: 62.793,95.778,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.240 | Acc: 55.469,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.317 | Acc: 51.451,67.932,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.386 | Acc: 52.020,67.111,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.387 | Acc: 51.755,67.354,74.168,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.601 | Acc: 52.344,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 63.281,96.466,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.477 | Acc: 63.605,96.456,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.507 | Acc: 62.795,96.363,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.505 | Acc: 62.953,96.123,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.495 | Acc: 63.134,96.132,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.499 | Acc: 63.171,96.016,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.498 | Acc: 63.198,95.977,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.502 | Acc: 63.005,95.934,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.504 | Acc: 62.888,95.904,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.505 | Acc: 62.737,95.899,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 62.829,95.822,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.511 | Acc: 62.724,95.770,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.514 | Acc: 62.719,95.702,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.515 | Acc: 62.681,95.693,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.516 | Acc: 62.669,95.694,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.514 | Acc: 62.697,95.721,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.513 | Acc: 62.725,95.727,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.511 | Acc: 62.727,95.724,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.510 | Acc: 62.736,95.716,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.229 | Acc: 51.562,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 51.488,68.713,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.353 | Acc: 51.791,67.893,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.357 | Acc: 51.460,68.199,74.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.521 | Acc: 64.844,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.421 | Acc: 64.918,96.540,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.438 | Acc: 63.872,96.361,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.439 | Acc: 64.037,96.542,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.457 | Acc: 63.619,96.499,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.464 | Acc: 63.544,96.357,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.469 | Acc: 63.520,96.378,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.472 | Acc: 63.492,96.282,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.472 | Acc: 63.524,96.254,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.472 | Acc: 63.432,96.262,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.475 | Acc: 63.367,96.222,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.477 | Acc: 63.324,96.172,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.481 | Acc: 63.233,96.123,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.485 | Acc: 63.203,96.091,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.490 | Acc: 63.078,96.069,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.496 | Acc: 62.975,95.951,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.501 | Acc: 62.897,95.901,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 62.940,95.878,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.505 | Acc: 62.952,95.817,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 62.888,95.807,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.315 | Acc: 56.250,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.326 | Acc: 52.195,68.304,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.379 | Acc: 52.439,67.435,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.369 | Acc: 52.254,67.559,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.358 | Acc: 67.188,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.432 | Acc: 65.179,97.024,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.457 | Acc: 64.444,96.475,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.467 | Acc: 63.922,96.311,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.467 | Acc: 63.725,96.316,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.471 | Acc: 63.513,96.163,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 62.952,96.132,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 63.065,96.155,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.480 | Acc: 63.136,96.171,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.480 | Acc: 63.113,96.158,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.481 | Acc: 63.118,96.070,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.484 | Acc: 63.104,96.044,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 62.999,96.052,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.490 | Acc: 62.970,96.007,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.490 | Acc: 63.023,95.994,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.494 | Acc: 62.998,95.938,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.498 | Acc: 62.955,95.887,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.498 | Acc: 62.933,95.858,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.499 | Acc: 62.916,95.845,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.499 | Acc: 63.000,95.833,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.297 | Acc: 53.906,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 52.195,67.634,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.382 | Acc: 52.210,67.130,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.381 | Acc: 51.831,67.072,74.142,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.263 | Acc: 62.500,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.383 | Acc: 65.179,96.726,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.436 | Acc: 64.291,96.456,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.463 | Acc: 63.525,96.273,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.467 | Acc: 63.127,96.277,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.473 | Acc: 62.809,96.241,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.476 | Acc: 62.694,96.249,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.479 | Acc: 62.849,96.232,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 62.655,96.079,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.491 | Acc: 62.500,96.055,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.491 | Acc: 62.624,96.028,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 62.861,96.012,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.491 | Acc: 62.766,96.006,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.497 | Acc: 62.701,95.980,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 62.689,95.944,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 62.713,95.938,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.500 | Acc: 62.721,95.919,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 62.658,95.851,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.499 | Acc: 62.684,95.836,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.499 | Acc: 62.738,95.846,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.400 | Acc: 56.250,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.351 | Acc: 52.232,68.415,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.373 | Acc: 52.515,67.340,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.360 | Acc: 52.369,67.597,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.602 | Acc: 63.281,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.524 | Acc: 61.272,95.461,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.467 | Acc: 62.633,95.770,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.476 | Acc: 62.807,95.825,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.486 | Acc: 62.828,95.901,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 63.011,95.808,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.489 | Acc: 62.661,95.971,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 62.688,95.972,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.491 | Acc: 62.743,96.002,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.493 | Acc: 62.647,96.033,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.491 | Acc: 62.733,95.985,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.490 | Acc: 62.793,95.991,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.489 | Acc: 62.853,95.980,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.495 | Acc: 62.763,95.956,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.496 | Acc: 62.797,95.952,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.497 | Acc: 62.806,95.925,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.497 | Acc: 62.819,95.897,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.497 | Acc: 62.823,95.876,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.496 | Acc: 62.870,95.882,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.497 | Acc: 62.867,95.883,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.480 | Acc: 55.469,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.342 | Acc: 51.488,68.266,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.420 | Acc: 51.639,67.721,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.423 | Acc: 51.191,67.815,74.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.768 | Acc: 60.938,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.487 | Acc: 64.286,95.796,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.490 | Acc: 63.777,95.979,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.495 | Acc: 63.691,95.940,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.495 | Acc: 63.436,95.939,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 63.637,95.985,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.480 | Acc: 63.520,96.055,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 63.398,95.988,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 63.301,95.982,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.490 | Acc: 63.342,96.012,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 63.266,95.981,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 63.104,95.942,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.500 | Acc: 63.048,95.954,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.496 | Acc: 63.090,95.926,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 63.070,95.924,99.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.499 | Acc: 63.081,95.938,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.500 | Acc: 62.992,95.892,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 63.077,95.835,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.501 | Acc: 63.089,95.797,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.501 | Acc: 63.103,95.801,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.396 | Acc: 56.250,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.380 | Acc: 51.935,68.378,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.408 | Acc: 52.515,67.359,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.409 | Acc: 52.280,67.367,73.988,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.471 | Acc: 60.156,94.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.451 | Acc: 63.914,96.429,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.427 | Acc: 64.787,96.170,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.429 | Acc: 64.357,96.388,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.430 | Acc: 64.284,96.229,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.425 | Acc: 64.240,96.287,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.432 | Acc: 64.030,96.287,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.440 | Acc: 63.968,96.249,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.441 | Acc: 64.121,96.210,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.449 | Acc: 63.989,96.158,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.449 | Acc: 63.950,96.156,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.455 | Acc: 63.766,96.157,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.458 | Acc: 63.738,96.103,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.462 | Acc: 63.685,96.097,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.469 | Acc: 63.554,96.049,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.474 | Acc: 63.442,96.039,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.477 | Acc: 63.418,96.043,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.477 | Acc: 63.416,96.027,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.480 | Acc: 63.292,96.014,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 63.226,95.983,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.438 | Acc: 52.344,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.406 | Acc: 50.818,68.229,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.445 | Acc: 51.105,67.340,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.446 | Acc: 51.165,67.597,73.706,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.537 | Acc: 60.156,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.467 | Acc: 63.802,95.871,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.457 | Acc: 63.853,96.361,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.457 | Acc: 63.730,96.299,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.458 | Acc: 63.667,96.287,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.463 | Acc: 63.351,96.303,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.469 | Acc: 63.178,96.300,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.479 | Acc: 63.026,96.382,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.478 | Acc: 63.102,96.370,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.480 | Acc: 63.234,96.357,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.482 | Acc: 63.196,96.315,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.477 | Acc: 63.271,96.369,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.480 | Acc: 63.200,96.376,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.481 | Acc: 63.182,96.312,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 63.064,96.299,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.486 | Acc: 62.952,96.247,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 62.992,96.235,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.486 | Acc: 63.020,96.201,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.486 | Acc: 63.037,96.202,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.487 | Acc: 63.054,96.163,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.364 | Acc: 55.469,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.366 | Acc: 52.158,68.824,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.395 | Acc: 52.496,67.759,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.405 | Acc: 51.985,67.789,73.899,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 1.560 | Acc: 59.375,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.445 | Acc: 64.062,95.871,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.448 | Acc: 64.539,96.113,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.455 | Acc: 64.280,96.196,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.458 | Acc: 64.005,96.393,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.473 | Acc: 63.622,96.171,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.478 | Acc: 63.527,96.087,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 63.630,96.127,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.481 | Acc: 63.398,96.099,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.480 | Acc: 63.355,96.098,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.483 | Acc: 63.285,96.020,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.485 | Acc: 63.182,96.055,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.485 | Acc: 63.197,96.048,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.487 | Acc: 63.206,95.998,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.490 | Acc: 63.073,95.985,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.489 | Acc: 63.097,95.995,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.489 | Acc: 63.067,96.018,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.491 | Acc: 63.011,95.986,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.491 | Acc: 62.954,95.983,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.490 | Acc: 62.980,95.944,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.333 | Acc: 56.250,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.362 | Acc: 51.637,68.527,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.403 | Acc: 52.439,67.550,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.386 | Acc: 52.216,67.841,73.745,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.699 | Acc: 57.812,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.458 | Acc: 62.463,96.615,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.441 | Acc: 63.834,96.646,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.446 | Acc: 63.781,96.478,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.454 | Acc: 63.551,96.383,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.450 | Acc: 63.591,96.341,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.460 | Acc: 63.669,96.229,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.468 | Acc: 63.409,96.216,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.470 | Acc: 63.335,96.176,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.471 | Acc: 63.199,96.189,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.472 | Acc: 63.227,96.148,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.472 | Acc: 63.363,96.157,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.471 | Acc: 63.395,96.116,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.472 | Acc: 63.368,96.133,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.473 | Acc: 63.301,96.091,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.475 | Acc: 63.320,96.127,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.477 | Acc: 63.284,96.101,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.480 | Acc: 63.217,96.039,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 63.214,95.994,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.484 | Acc: 63.234,95.946,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 57.812,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.351 | Acc: 52.121,68.713,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.393 | Acc: 52.572,67.511,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.395 | Acc: 52.203,67.661,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 1.490 | Acc: 63.281,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.455 | Acc: 63.430,96.354,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.464 | Acc: 62.976,96.608,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.443 | Acc: 63.678,96.606,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.460 | Acc: 63.445,96.537,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.462 | Acc: 63.397,96.457,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.469 | Acc: 63.126,96.320,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.469 | Acc: 63.226,96.293,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.470 | Acc: 63.247,96.268,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.472 | Acc: 63.191,96.249,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.475 | Acc: 63.207,96.179,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.476 | Acc: 63.285,96.104,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.475 | Acc: 63.281,96.116,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.480 | Acc: 63.206,96.112,99.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.478 | Acc: 63.281,96.124,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 63.276,96.148,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.477 | Acc: 63.298,96.164,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.479 | Acc: 63.272,96.117,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.480 | Acc: 63.221,96.105,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 63.222,96.133,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.401 | Acc: 51.562,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.360 | Acc: 52.009,67.932,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.421 | Acc: 52.325,67.397,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.397 | Acc: 51.998,67.764,74.283,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.301 | Acc: 71.094,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.378 | Acc: 65.662,97.024,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.410 | Acc: 65.111,96.894,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.433 | Acc: 64.549,96.696,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.445 | Acc: 63.918,96.634,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.457 | Acc: 63.529,96.527,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.463 | Acc: 63.397,96.488,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.467 | Acc: 63.265,96.393,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.468 | Acc: 63.373,96.375,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.459 | Acc: 63.583,96.430,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.464 | Acc: 63.526,96.397,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.470 | Acc: 63.412,96.369,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.475 | Acc: 63.382,96.347,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.476 | Acc: 63.428,96.318,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.474 | Acc: 63.429,96.288,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.476 | Acc: 63.411,96.286,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.476 | Acc: 63.401,96.242,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.477 | Acc: 63.352,96.211,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.479 | Acc: 63.322,96.176,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 63.277,96.139,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.438 | Acc: 55.469,73.438,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.358 | Acc: 52.121,68.899,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.403 | Acc: 52.534,67.626,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.399 | Acc: 52.126,67.533,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 1.430 | Acc: 64.844,94.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.449 | Acc: 64.100,96.057,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.456 | Acc: 63.700,96.094,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.471 | Acc: 63.473,96.145,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.468 | Acc: 63.638,96.103,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.466 | Acc: 63.753,96.071,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.474 | Acc: 63.753,96.049,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.478 | Acc: 63.558,96.110,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.473 | Acc: 63.708,96.123,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.480 | Acc: 63.570,96.025,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.483 | Acc: 63.460,95.973,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.485 | Acc: 63.345,95.988,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.480 | Acc: 63.498,95.967,99.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.482 | Acc: 63.329,95.977,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 63.184,95.938,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.485 | Acc: 63.167,95.959,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.488 | Acc: 63.150,95.901,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.483 | Acc: 63.194,95.938,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 63.160,95.897,99.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.489 | Acc: 63.130,95.891,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.559 | Acc: 53.906,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.345 | Acc: 53.385,68.192,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.414 | Acc: 52.973,67.340,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.410 | Acc: 52.613,67.623,73.758,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.381 | Acc: 59.375,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.393 | Acc: 64.472,97.098,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.433 | Acc: 63.624,96.589,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.435 | Acc: 64.024,96.388,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.430 | Acc: 64.024,96.470,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.449 | Acc: 63.823,96.403,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.449 | Acc: 63.811,96.481,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.459 | Acc: 63.719,96.415,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.464 | Acc: 63.616,96.370,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.467 | Acc: 63.527,96.262,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.467 | Acc: 63.530,96.152,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.465 | Acc: 63.642,96.193,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.467 | Acc: 63.479,96.207,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.471 | Acc: 63.413,96.199,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.475 | Acc: 63.309,96.183,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.475 | Acc: 63.289,96.130,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.479 | Acc: 63.191,96.084,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.480 | Acc: 63.219,96.071,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 63.210,96.018,99.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.484 | Acc: 63.177,96.012,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.467 | Acc: 52.344,72.656,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.412 | Acc: 51.897,67.820,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.452 | Acc: 52.058,67.397,73.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.445 | Acc: 51.588,67.469,73.309,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.150 | Acc: 71.094,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.439 | Acc: 63.728,96.280,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.427 | Acc: 64.005,96.513,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.433 | Acc: 64.075,96.452,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.436 | Acc: 64.130,96.557,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.448 | Acc: 63.900,96.589,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.454 | Acc: 63.830,96.604,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.458 | Acc: 63.819,96.531,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.457 | Acc: 63.970,96.424,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.462 | Acc: 63.842,96.361,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.468 | Acc: 63.713,96.339,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.468 | Acc: 63.645,96.334,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.466 | Acc: 63.664,96.334,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.470 | Acc: 63.560,96.273,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.474 | Acc: 63.470,96.197,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.474 | Acc: 63.484,96.138,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.475 | Acc: 63.449,96.111,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.477 | Acc: 63.423,96.073,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.479 | Acc: 63.322,96.048,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.479 | Acc: 63.318,96.022,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.356 | Acc: 53.906,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.390 | Acc: 52.418,68.080,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.452 | Acc: 52.229,67.188,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.447 | Acc: 51.755,67.188,74.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.514 | Acc: 63.281,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.465 | Acc: 63.095,96.391,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.442 | Acc: 63.872,96.456,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.452 | Acc: 63.665,96.350,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.446 | Acc: 63.899,96.547,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.449 | Acc: 63.908,96.395,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.450 | Acc: 64.017,96.326,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.455 | Acc: 63.930,96.360,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.455 | Acc: 63.941,96.399,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.457 | Acc: 63.911,96.323,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.450 | Acc: 64.059,96.420,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.454 | Acc: 63.914,96.398,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.459 | Acc: 63.761,96.337,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.459 | Acc: 63.820,96.333,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.464 | Acc: 63.673,96.330,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.463 | Acc: 63.655,96.338,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.464 | Acc: 63.566,96.291,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.469 | Acc: 63.501,96.222,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.472 | Acc: 63.413,96.167,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.472 | Acc: 63.410,96.143,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 54.688,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.441 | Acc: 51.265,67.894,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.488 | Acc: 51.696,67.302,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.480 | Acc: 51.486,67.149,73.899,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.447 | Acc: 61.719,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.434 | Acc: 63.876,96.652,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.476 | Acc: 63.338,96.303,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.480 | Acc: 63.281,96.235,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.481 | Acc: 63.310,96.267,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.482 | Acc: 63.026,96.248,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.492 | Acc: 62.784,96.210,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.486 | Acc: 63.165,96.193,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.481 | Acc: 63.296,96.205,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.484 | Acc: 63.268,96.163,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.479 | Acc: 63.301,96.187,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.474 | Acc: 63.444,96.172,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.472 | Acc: 63.460,96.201,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.473 | Acc: 63.443,96.196,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.472 | Acc: 63.476,96.197,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.478 | Acc: 63.336,96.161,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.479 | Acc: 63.264,96.142,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.479 | Acc: 63.339,96.119,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.480 | Acc: 63.368,96.076,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.478 | Acc: 63.421,96.090,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.376 | Acc: 53.906,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.447 | Acc: 49.628,68.043,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.486 | Acc: 50.915,67.283,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.481 | Acc: 50.794,67.252,73.860,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 1.317 | Acc: 66.406,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.461 | Acc: 63.616,96.354,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.468 | Acc: 63.243,96.018,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.479 | Acc: 63.217,96.094,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.472 | Acc: 63.040,96.181,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.462 | Acc: 63.598,96.132,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.459 | Acc: 63.662,96.281,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.462 | Acc: 63.381,96.282,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.464 | Acc: 63.330,96.317,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.465 | Acc: 63.419,96.305,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.467 | Acc: 63.316,96.249,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.469 | Acc: 63.264,96.217,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.466 | Acc: 63.323,96.249,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.464 | Acc: 63.407,96.234,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.468 | Acc: 63.276,96.227,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.468 | Acc: 63.302,96.195,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.471 | Acc: 63.225,96.172,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.475 | Acc: 63.174,96.151,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.475 | Acc: 63.216,96.139,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.473 | Acc: 63.306,96.145,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.400 | Acc: 53.906,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.414 | Acc: 51.302,68.452,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.433 | Acc: 51.410,67.473,73.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.423 | Acc: 51.114,67.405,73.924,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.291 | Acc: 72.656,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.485 | Acc: 63.579,96.429,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.463 | Acc: 63.472,96.723,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.465 | Acc: 63.563,96.619,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.473 | Acc: 63.339,96.557,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.472 | Acc: 63.498,96.411,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.465 | Acc: 63.559,96.468,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.463 | Acc: 63.442,96.487,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.469 | Acc: 63.242,96.453,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.472 | Acc: 63.117,96.452,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.463 | Acc: 63.308,96.447,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.461 | Acc: 63.401,96.433,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.468 | Acc: 63.307,96.360,99.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.467 | Acc: 63.389,96.357,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.465 | Acc: 63.437,96.350,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.464 | Acc: 63.468,96.333,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.466 | Acc: 63.437,96.305,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.466 | Acc: 63.460,96.307,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.466 | Acc: 63.515,96.258,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.466 | Acc: 63.515,96.237,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.425 | Acc: 57.031,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.446 | Acc: 52.158,67.708,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.498 | Acc: 52.344,66.845,73.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.506 | Acc: 51.460,66.995,73.758,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.394 | Acc: 66.406,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.425 | Acc: 63.876,96.838,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.447 | Acc: 63.910,96.494,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.456 | Acc: 63.870,96.299,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.454 | Acc: 63.956,96.238,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.452 | Acc: 64.047,96.287,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.454 | Acc: 63.804,96.294,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.456 | Acc: 63.592,96.221,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.458 | Acc: 63.572,96.268,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.459 | Acc: 63.588,96.284,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.457 | Acc: 63.616,96.261,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.460 | Acc: 63.624,96.239,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.461 | Acc: 63.664,96.197,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.460 | Acc: 63.619,96.199,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.463 | Acc: 63.562,96.155,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.467 | Acc: 63.484,96.096,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.469 | Acc: 63.547,96.067,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.473 | Acc: 63.536,96.004,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.473 | Acc: 63.606,96.014,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.473 | Acc: 63.634,95.991,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.403 | Acc: 52.344,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.405 | Acc: 50.930,68.266,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.442 | Acc: 51.105,67.626,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.448 | Acc: 50.845,67.354,74.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.588 | Acc: 63.281,95.312,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.440 | Acc: 63.281,96.391,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.437 | Acc: 64.101,96.380,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.432 | Acc: 64.357,96.286,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.441 | Acc: 64.072,96.431,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.436 | Acc: 64.256,96.434,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.444 | Acc: 63.991,96.352,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.441 | Acc: 63.896,96.321,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.447 | Acc: 63.762,96.293,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.455 | Acc: 63.527,96.219,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.460 | Acc: 63.456,96.206,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.461 | Acc: 63.391,96.193,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.462 | Acc: 63.398,96.185,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.466 | Acc: 63.224,96.225,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.465 | Acc: 63.326,96.222,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.465 | Acc: 63.354,96.239,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.467 | Acc: 63.325,96.191,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.470 | Acc: 63.284,96.153,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.474 | Acc: 63.212,96.076,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.474 | Acc: 63.199,96.073,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.478 | Acc: 58.594,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.396 | Acc: 52.418,67.969,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.449 | Acc: 52.572,67.092,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.451 | Acc: 52.203,67.123,73.783,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.534 | Acc: 58.594,100.000,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.407 | Acc: 64.174,96.577,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.397 | Acc: 64.234,97.142,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.400 | Acc: 63.973,97.041,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.399 | Acc: 64.014,97.020,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.391 | Acc: 64.418,97.037,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.382 | Acc: 64.824,97.146,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.386 | Acc: 64.799,97.202,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.381 | Acc: 64.965,97.210,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.382 | Acc: 64.870,97.276,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.380 | Acc: 65.030,97.252,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.378 | Acc: 65.084,97.285,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.377 | Acc: 65.103,97.319,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.375 | Acc: 65.116,97.342,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.374 | Acc: 65.141,97.359,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.375 | Acc: 65.160,97.350,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.375 | Acc: 65.094,97.389,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.375 | Acc: 65.064,97.409,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.376 | Acc: 65.021,97.412,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.375 | Acc: 65.080,97.412,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.364 | Acc: 57.812,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.278 | Acc: 53.609,69.196,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.323 | Acc: 53.620,68.445,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.315 | Acc: 53.599,68.417,73.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.394 | Acc: 64.062,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.368 | Acc: 65.699,98.103,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.339 | Acc: 66.006,98.095,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.333 | Acc: 66.189,98.040,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.344 | Acc: 65.808,97.946,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.348 | Acc: 65.919,97.842,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.342 | Acc: 65.967,97.927,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.338 | Acc: 66.124,97.928,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.338 | Acc: 66.023,97.923,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.344 | Acc: 65.763,97.876,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.346 | Acc: 65.695,97.862,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.347 | Acc: 65.643,97.882,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.344 | Acc: 65.755,97.893,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.344 | Acc: 65.763,97.884,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.343 | Acc: 65.797,97.884,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.345 | Acc: 65.716,97.859,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.346 | Acc: 65.681,97.849,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.345 | Acc: 65.703,97.826,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.347 | Acc: 65.640,97.829,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.348 | Acc: 65.646,97.826,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.329 | Acc: 57.812,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.241 | Acc: 54.167,69.159,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.293 | Acc: 53.887,68.312,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.290 | Acc: 53.778,68.366,74.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.394 | Acc: 64.844,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.305 | Acc: 66.071,98.103,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.318 | Acc: 66.197,97.923,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.324 | Acc: 66.124,97.784,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.337 | Acc: 65.683,97.820,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.342 | Acc: 65.455,97.857,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.335 | Acc: 65.573,98.005,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.335 | Acc: 65.725,98.033,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.337 | Acc: 65.698,98.059,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.339 | Acc: 65.565,98.010,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.336 | Acc: 65.528,98.014,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.340 | Acc: 65.381,98.017,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.339 | Acc: 65.434,97.964,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.336 | Acc: 65.553,97.965,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.336 | Acc: 65.567,97.954,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.340 | Acc: 65.469,97.957,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.341 | Acc: 65.501,97.941,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.342 | Acc: 65.549,97.920,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.341 | Acc: 65.551,97.940,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.341 | Acc: 65.553,97.952,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.303 | Acc: 57.812,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.247 | Acc: 53.646,69.531,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.307 | Acc: 53.659,68.483,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.304 | Acc: 53.522,68.481,74.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.314 | Acc: 67.188,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.346 | Acc: 65.960,98.140,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.340 | Acc: 65.701,98.095,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.329 | Acc: 65.791,98.258,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.332 | Acc: 65.731,98.254,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.343 | Acc: 65.555,98.144,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.341 | Acc: 65.489,98.153,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.338 | Acc: 65.642,98.166,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.335 | Acc: 65.581,98.200,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.335 | Acc: 65.651,98.226,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.336 | Acc: 65.551,98.247,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.334 | Acc: 65.650,98.222,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.334 | Acc: 65.622,98.211,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.336 | Acc: 65.568,98.168,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.334 | Acc: 65.644,98.154,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.333 | Acc: 65.708,98.142,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.332 | Acc: 65.674,98.124,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.330 | Acc: 65.719,98.108,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.331 | Acc: 65.664,98.089,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.330 | Acc: 65.672,98.109,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.331 | Acc: 57.031,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.250 | Acc: 53.683,69.382,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.296 | Acc: 53.678,68.388,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.298 | Acc: 53.612,68.366,74.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.416 | Acc: 58.594,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.316 | Acc: 67.113,98.177,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.320 | Acc: 66.063,98.209,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.316 | Acc: 66.278,98.194,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.321 | Acc: 66.136,98.158,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.322 | Acc: 66.105,98.175,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.327 | Acc: 65.883,98.121,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.328 | Acc: 65.813,98.133,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.327 | Acc: 65.911,98.088,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.326 | Acc: 65.957,98.088,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.325 | Acc: 65.983,98.068,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.328 | Acc: 65.996,98.038,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.332 | Acc: 65.810,97.997,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.331 | Acc: 65.784,98.015,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.327 | Acc: 65.889,98.040,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.325 | Acc: 66.007,98.043,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.326 | Acc: 65.949,98.048,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.328 | Acc: 65.861,98.018,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.327 | Acc: 65.848,98.013,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.328 | Acc: 65.851,98.029,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.310 | Acc: 56.250,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.247 | Acc: 53.460,69.494,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.309 | Acc: 53.430,68.579,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.307 | Acc: 53.343,68.673,74.168,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.375 | Acc: 62.500,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.349 | Acc: 65.067,98.326,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.333 | Acc: 65.339,98.133,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.322 | Acc: 66.048,98.169,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.335 | Acc: 65.644,98.023,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.329 | Acc: 65.640,98.128,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.329 | Acc: 65.528,98.160,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.330 | Acc: 65.575,98.166,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.325 | Acc: 65.669,98.205,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.326 | Acc: 65.578,98.200,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.325 | Acc: 65.602,98.220,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.326 | Acc: 65.657,98.211,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.324 | Acc: 65.693,98.237,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.324 | Acc: 65.697,98.216,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.327 | Acc: 65.622,98.207,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.328 | Acc: 65.635,98.209,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.328 | Acc: 65.671,98.214,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.328 | Acc: 65.717,98.206,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.329 | Acc: 65.757,98.210,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.329 | Acc: 65.680,98.218,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.265 | Acc: 58.594,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.243 | Acc: 53.571,69.494,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.299 | Acc: 53.639,68.617,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 53.586,68.532,74.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.455 | Acc: 63.281,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.350 | Acc: 65.737,97.879,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.372 | Acc: 65.263,97.942,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.346 | Acc: 65.971,97.976,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.336 | Acc: 66.155,97.907,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.325 | Acc: 66.406,97.989,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.333 | Acc: 66.006,98.018,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.334 | Acc: 66.052,98.022,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.333 | Acc: 66.096,98.010,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.329 | Acc: 66.247,98.040,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.331 | Acc: 66.150,98.057,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.334 | Acc: 65.940,98.010,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.335 | Acc: 65.771,98.023,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.337 | Acc: 65.682,98.036,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.337 | Acc: 65.628,98.043,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.333 | Acc: 65.768,98.069,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.331 | Acc: 65.842,98.036,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.330 | Acc: 65.905,98.050,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.328 | Acc: 65.967,98.061,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.330 | Acc: 65.963,98.042,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.331 | Acc: 56.250,71.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.240 | Acc: 53.683,69.754,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.293 | Acc: 53.639,68.559,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.298 | Acc: 53.496,68.353,74.296,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.341 | Acc: 67.188,99.219,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.340 | Acc: 65.402,98.214,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.322 | Acc: 65.911,98.304,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.322 | Acc: 65.971,98.335,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.325 | Acc: 65.500,98.312,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.328 | Acc: 65.470,98.267,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.326 | Acc: 65.464,98.270,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.325 | Acc: 65.570,98.266,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.322 | Acc: 65.640,98.302,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.325 | Acc: 65.565,98.278,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.327 | Acc: 65.571,98.259,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.324 | Acc: 65.632,98.240,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.319 | Acc: 65.797,98.259,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.322 | Acc: 65.667,98.288,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.325 | Acc: 65.592,98.260,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.322 | Acc: 65.682,98.266,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.325 | Acc: 65.586,98.265,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.323 | Acc: 65.648,98.250,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.323 | Acc: 65.692,98.243,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.325 | Acc: 65.680,98.220,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.362 | Acc: 56.250,72.656,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.265 | Acc: 53.720,69.234,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.313 | Acc: 53.659,68.197,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.316 | Acc: 53.535,68.186,74.142,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.400 | Acc: 63.281,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.368 | Acc: 64.807,98.326,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.329 | Acc: 65.777,98.228,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.311 | Acc: 65.984,98.194,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.317 | Acc: 66.069,98.235,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.321 | Acc: 65.896,98.244,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.317 | Acc: 66.109,98.289,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.311 | Acc: 66.279,98.305,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.313 | Acc: 66.246,98.273,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.309 | Acc: 66.406,98.325,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.310 | Acc: 66.305,98.333,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.314 | Acc: 66.152,98.339,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.315 | Acc: 66.137,98.311,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.315 | Acc: 66.218,98.321,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.315 | Acc: 66.228,98.301,99.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.313 | Acc: 66.282,98.305,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.316 | Acc: 66.238,98.287,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.319 | Acc: 66.232,98.252,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.323 | Acc: 66.127,98.210,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.323 | Acc: 66.078,98.208,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.212 | Acc: 58.594,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.252 | Acc: 53.981,69.568,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.297 | Acc: 53.582,68.598,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 53.432,68.571,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.400 | Acc: 64.062,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.288 | Acc: 66.332,98.624,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.297 | Acc: 66.597,98.342,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.321 | Acc: 66.035,98.271,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.318 | Acc: 66.165,98.370,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.327 | Acc: 65.981,98.430,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.318 | Acc: 66.206,98.379,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.320 | Acc: 66.212,98.343,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.316 | Acc: 66.367,98.365,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.314 | Acc: 66.419,98.338,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.310 | Acc: 66.569,98.321,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.313 | Acc: 66.579,98.275,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.319 | Acc: 66.380,98.298,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.322 | Acc: 66.361,98.297,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.322 | Acc: 66.356,98.265,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.320 | Acc: 66.437,98.266,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.320 | Acc: 66.426,98.265,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.319 | Acc: 66.360,98.275,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.318 | Acc: 66.365,98.275,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.320 | Acc: 66.298,98.280,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.304 | Acc: 58.594,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.243 | Acc: 54.055,69.420,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.298 | Acc: 53.982,68.464,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.302 | Acc: 53.855,68.545,74.039,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.487 | Acc: 64.062,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.323 | Acc: 65.923,98.512,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.323 | Acc: 65.777,98.323,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.332 | Acc: 65.241,98.284,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.318 | Acc: 65.750,98.274,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.309 | Acc: 66.259,98.267,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.317 | Acc: 66.077,98.186,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.316 | Acc: 66.124,98.172,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.312 | Acc: 66.280,98.171,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.313 | Acc: 66.190,98.209,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.315 | Acc: 66.165,98.231,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.317 | Acc: 66.145,98.236,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.316 | Acc: 66.105,98.227,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.317 | Acc: 66.089,98.252,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.319 | Acc: 65.920,98.251,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.320 | Acc: 65.864,98.232,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.320 | Acc: 65.907,98.248,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.320 | Acc: 65.969,98.245,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.320 | Acc: 65.963,98.247,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.320 | Acc: 65.961,98.239,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.245 | Acc: 59.375,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.260 | Acc: 54.390,69.680,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 54.021,68.540,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.320 | Acc: 53.804,68.430,74.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.358 | Acc: 64.062,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.296 | Acc: 67.001,98.251,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.332 | Acc: 66.025,98.304,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.323 | Acc: 66.201,98.271,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.315 | Acc: 66.233,98.312,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.315 | Acc: 66.259,98.352,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.317 | Acc: 66.180,98.328,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.314 | Acc: 66.284,98.316,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.308 | Acc: 66.431,98.331,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.312 | Acc: 66.393,98.317,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.313 | Acc: 66.445,98.263,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.314 | Acc: 66.275,98.187,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.314 | Acc: 66.335,98.188,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.317 | Acc: 66.337,98.192,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.316 | Acc: 66.356,98.198,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.316 | Acc: 66.313,98.194,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.317 | Acc: 66.280,98.175,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.319 | Acc: 66.198,98.165,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.319 | Acc: 66.214,98.173,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.320 | Acc: 66.170,98.193,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.263 | Acc: 56.250,72.656,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.252 | Acc: 54.055,69.606,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.308 | Acc: 53.811,68.502,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.310 | Acc: 53.573,68.468,74.129,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.506 | Acc: 58.594,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.340 | Acc: 65.923,98.177,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.313 | Acc: 66.444,98.361,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.303 | Acc: 66.726,98.373,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.300 | Acc: 66.551,98.351,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.307 | Acc: 66.399,98.283,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.309 | Acc: 66.658,98.315,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.312 | Acc: 66.489,98.249,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.313 | Acc: 66.411,98.277,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.309 | Acc: 66.359,98.269,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.309 | Acc: 66.220,98.259,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.308 | Acc: 66.145,98.278,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.309 | Acc: 66.108,98.275,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.310 | Acc: 66.062,98.282,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.312 | Acc: 66.006,98.276,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.313 | Acc: 66.069,98.271,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.314 | Acc: 66.012,98.279,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.316 | Acc: 66.003,98.275,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.314 | Acc: 66.008,98.282,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.315 | Acc: 66.017,98.304,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.306 | Acc: 57.812,72.656,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.259 | Acc: 53.795,69.754,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.308 | Acc: 53.601,68.426,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.313 | Acc: 53.612,68.327,74.244,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.310 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.298 | Acc: 66.629,98.400,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.320 | Acc: 65.873,98.399,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.301 | Acc: 66.240,98.502,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.292 | Acc: 66.782,98.447,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.293 | Acc: 66.677,98.321,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.291 | Acc: 66.723,98.373,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.294 | Acc: 66.589,98.377,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.300 | Acc: 66.431,98.360,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.300 | Acc: 66.385,98.394,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.300 | Acc: 66.383,98.403,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.300 | Acc: 66.399,98.392,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.302 | Acc: 66.325,98.369,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.302 | Acc: 66.367,98.366,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.303 | Acc: 66.320,98.362,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.305 | Acc: 66.393,98.336,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.304 | Acc: 66.387,98.343,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.308 | Acc: 66.299,98.337,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.309 | Acc: 66.263,98.325,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.309 | Acc: 66.248,98.294,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.335 | Acc: 58.594,71.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.251 | Acc: 53.832,69.606,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.303 | Acc: 53.716,68.312,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.311 | Acc: 53.573,68.353,74.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.271 | Acc: 69.531,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.324 | Acc: 65.811,98.326,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.303 | Acc: 66.635,98.209,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.315 | Acc: 66.381,98.169,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.315 | Acc: 66.020,98.100,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.306 | Acc: 66.530,98.182,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.310 | Acc: 66.258,98.147,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.316 | Acc: 66.079,98.100,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.311 | Acc: 66.304,98.093,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.313 | Acc: 66.303,98.109,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.313 | Acc: 66.387,98.158,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.314 | Acc: 66.410,98.119,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.310 | Acc: 66.426,98.133,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.312 | Acc: 66.334,98.141,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.314 | Acc: 66.226,98.137,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.316 | Acc: 66.178,98.144,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.317 | Acc: 66.182,98.165,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.315 | Acc: 66.232,98.192,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.316 | Acc: 66.214,98.176,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.318 | Acc: 66.146,98.177,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.273 | Acc: 56.250,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.264 | Acc: 53.423,69.606,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 53.563,68.464,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.323 | Acc: 53.343,68.443,74.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.490 | Acc: 66.406,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.315 | Acc: 65.699,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.318 | Acc: 65.777,98.514,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.316 | Acc: 66.278,98.258,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.320 | Acc: 66.020,98.370,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.310 | Acc: 66.290,98.352,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.311 | Acc: 66.290,98.373,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.310 | Acc: 66.390,98.260,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.307 | Acc: 66.474,98.282,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.313 | Acc: 66.281,98.256,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.316 | Acc: 66.220,98.243,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.312 | Acc: 66.350,98.225,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.314 | Acc: 66.231,98.214,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.313 | Acc: 66.212,98.243,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.312 | Acc: 66.220,98.237,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.311 | Acc: 66.258,98.238,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.311 | Acc: 66.275,98.231,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.310 | Acc: 66.278,98.250,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.309 | Acc: 66.287,98.247,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.308 | Acc: 66.277,98.259,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.309 | Acc: 58.594,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.246 | Acc: 54.055,69.382,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.313 | Acc: 53.868,68.197,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.319 | Acc: 53.624,68.289,73.988,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.296 | Acc: 62.500,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.307 | Acc: 66.257,98.847,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.316 | Acc: 66.006,98.590,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.299 | Acc: 66.265,98.604,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.308 | Acc: 66.155,98.438,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.301 | Acc: 66.545,98.430,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.309 | Acc: 66.690,98.418,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.314 | Acc: 66.401,98.449,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.307 | Acc: 66.576,98.438,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.305 | Acc: 66.436,98.429,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.308 | Acc: 66.352,98.399,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.305 | Acc: 66.413,98.381,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.308 | Acc: 66.306,98.363,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.308 | Acc: 66.272,98.345,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.308 | Acc: 66.342,98.360,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.309 | Acc: 66.240,98.375,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.309 | Acc: 66.221,98.391,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.309 | Acc: 66.218,98.369,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.309 | Acc: 66.242,98.381,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.307 | Acc: 66.214,98.384,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.265 | Acc: 56.250,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.266 | Acc: 53.348,69.643,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.318 | Acc: 53.430,68.559,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.320 | Acc: 53.189,68.596,74.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.229 | Acc: 60.156,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.292 | Acc: 66.629,98.586,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.295 | Acc: 66.120,98.761,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.289 | Acc: 65.894,98.681,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.295 | Acc: 65.693,98.582,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.298 | Acc: 65.656,98.608,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.300 | Acc: 65.948,98.592,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.297 | Acc: 66.146,98.526,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.302 | Acc: 66.139,98.481,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.301 | Acc: 66.177,98.489,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.305 | Acc: 66.010,98.496,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.304 | Acc: 66.007,98.455,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.306 | Acc: 65.978,98.457,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.305 | Acc: 66.044,98.455,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.303 | Acc: 66.034,98.485,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.307 | Acc: 66.004,98.448,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.305 | Acc: 66.056,98.423,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.306 | Acc: 66.001,98.389,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.305 | Acc: 66.030,98.375,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.306 | Acc: 66.047,98.374,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.307 | Acc: 59.375,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.264 | Acc: 54.167,69.308,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.315 | Acc: 54.059,68.312,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.317 | Acc: 53.727,68.289,74.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.537 | Acc: 60.938,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.324 | Acc: 65.439,98.438,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.285 | Acc: 66.692,98.418,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.284 | Acc: 66.790,98.361,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.288 | Acc: 66.445,98.428,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.299 | Acc: 66.375,98.314,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.301 | Acc: 66.251,98.302,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.305 | Acc: 66.196,98.343,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.304 | Acc: 66.382,98.394,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.294 | Acc: 66.704,98.377,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.294 | Acc: 66.612,98.403,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.296 | Acc: 66.636,98.406,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.299 | Acc: 66.452,98.379,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.298 | Acc: 66.418,98.381,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.298 | Acc: 66.423,98.407,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.303 | Acc: 66.282,98.391,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.303 | Acc: 66.241,98.391,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.306 | Acc: 66.175,98.387,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.307 | Acc: 66.097,98.375,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.311 | Acc: 66.047,98.351,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.274 | Acc: 57.031,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 53.869,69.085,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.335 | Acc: 53.697,68.007,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.339 | Acc: 53.484,68.033,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.244 | Acc: 71.875,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.282 | Acc: 66.815,98.400,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.284 | Acc: 66.521,98.285,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.292 | Acc: 66.240,98.309,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.290 | Acc: 66.252,98.409,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.304 | Acc: 65.942,98.360,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.297 | Acc: 66.077,98.412,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.297 | Acc: 66.240,98.438,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.297 | Acc: 66.343,98.399,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.299 | Acc: 66.298,98.377,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.301 | Acc: 66.247,98.344,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.301 | Acc: 66.240,98.339,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.303 | Acc: 66.238,98.337,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.306 | Acc: 66.134,98.321,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.307 | Acc: 66.117,98.340,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.308 | Acc: 66.113,98.352,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.306 | Acc: 66.165,98.357,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.307 | Acc: 66.175,98.357,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.307 | Acc: 66.181,98.357,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.304 | Acc: 66.285,98.355,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.320 | Acc: 57.812,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.289 | Acc: 53.385,69.531,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.336 | Acc: 53.525,68.350,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.338 | Acc: 53.163,68.302,74.078,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.063 | Acc: 76.562,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.307 | Acc: 66.109,98.438,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.313 | Acc: 66.197,98.495,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.318 | Acc: 66.022,98.463,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.304 | Acc: 66.474,98.438,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.295 | Acc: 66.778,98.445,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.294 | Acc: 66.826,98.457,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.295 | Acc: 66.938,98.449,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.293 | Acc: 66.964,98.476,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.293 | Acc: 66.993,98.468,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.293 | Acc: 67.020,98.476,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.295 | Acc: 66.915,98.423,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.294 | Acc: 66.954,98.460,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.296 | Acc: 66.840,98.467,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.299 | Acc: 66.695,98.432,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.299 | Acc: 66.622,98.412,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.299 | Acc: 66.579,98.416,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.303 | Acc: 66.450,98.405,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.305 | Acc: 66.341,98.394,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.307 | Acc: 66.298,98.388,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.261 | Acc: 57.031,71.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.267 | Acc: 54.241,69.420,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.310 | Acc: 54.040,68.350,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.310 | Acc: 53.868,68.353,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.171 | Acc: 71.094,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.298 | Acc: 66.555,98.363,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.315 | Acc: 65.911,98.380,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.301 | Acc: 66.483,98.348,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.311 | Acc: 66.165,98.312,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.320 | Acc: 66.105,98.306,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.320 | Acc: 66.038,98.308,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.313 | Acc: 66.395,98.365,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.312 | Acc: 66.348,98.370,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.307 | Acc: 66.514,98.377,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.306 | Acc: 66.468,98.340,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.305 | Acc: 66.449,98.370,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.304 | Acc: 66.426,98.373,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.301 | Acc: 66.430,98.399,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.303 | Acc: 66.426,98.379,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.304 | Acc: 66.365,98.380,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.301 | Acc: 66.421,98.362,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.301 | Acc: 66.459,98.350,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.301 | Acc: 66.458,98.366,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.302 | Acc: 66.412,98.362,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.321 | Acc: 56.250,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.252 | Acc: 53.943,69.978,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.309 | Acc: 53.620,68.483,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.311 | Acc: 53.407,68.366,74.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.127 | Acc: 68.750,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.225 | Acc: 67.671,98.624,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.230 | Acc: 67.264,98.723,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.251 | Acc: 67.034,98.732,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.271 | Acc: 66.705,98.669,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.281 | Acc: 66.468,98.685,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.289 | Acc: 66.400,98.638,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.293 | Acc: 66.329,98.620,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.297 | Acc: 66.266,98.515,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.300 | Acc: 66.238,98.520,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.302 | Acc: 66.150,98.507,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.304 | Acc: 66.162,98.462,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.306 | Acc: 66.160,98.460,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.307 | Acc: 66.173,98.443,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.308 | Acc: 66.081,98.449,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.307 | Acc: 66.154,98.453,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.306 | Acc: 66.216,98.442,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.305 | Acc: 66.260,98.451,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.304 | Acc: 66.281,98.450,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.305 | Acc: 66.224,98.417,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.266 | Acc: 59.375,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.257 | Acc: 54.055,70.089,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.310 | Acc: 53.982,68.731,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.315 | Acc: 53.727,68.545,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.364 | Acc: 63.281,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.293 | Acc: 67.113,98.438,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.300 | Acc: 66.654,98.399,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.314 | Acc: 66.099,98.297,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.311 | Acc: 66.194,98.254,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.308 | Acc: 66.337,98.275,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.311 | Acc: 66.439,98.308,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.310 | Acc: 66.223,98.316,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.307 | Acc: 66.159,98.336,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.305 | Acc: 66.294,98.334,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.304 | Acc: 66.344,98.278,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.303 | Acc: 66.396,98.321,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.305 | Acc: 66.322,98.327,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.308 | Acc: 66.218,98.324,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.306 | Acc: 66.289,98.340,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.307 | Acc: 66.300,98.321,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.306 | Acc: 66.350,98.335,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.303 | Acc: 66.406,98.346,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.303 | Acc: 66.406,98.331,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.303 | Acc: 66.423,98.339,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.281 | Acc: 59.375,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.273 | Acc: 54.278,69.606,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.330 | Acc: 54.154,68.312,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.331 | Acc: 53.829,68.353,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.535 | Acc: 62.500,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.284 | Acc: 66.220,98.624,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.331 | Acc: 65.492,98.228,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.308 | Acc: 66.035,98.361,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.299 | Acc: 66.223,98.409,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.297 | Acc: 66.344,98.430,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.296 | Acc: 66.464,98.438,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.300 | Acc: 66.356,98.449,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.300 | Acc: 66.338,98.462,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.299 | Acc: 66.393,98.459,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.302 | Acc: 66.340,98.480,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.302 | Acc: 66.304,98.452,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.302 | Acc: 66.290,98.441,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.301 | Acc: 66.367,98.414,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.303 | Acc: 66.348,98.390,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.304 | Acc: 66.318,98.380,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.304 | Acc: 66.287,98.382,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.300 | Acc: 66.381,98.383,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.299 | Acc: 66.294,98.383,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.302 | Acc: 66.172,98.380,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.292 | Acc: 57.812,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.272 | Acc: 53.683,69.420,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.329 | Acc: 53.620,68.140,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.335 | Acc: 53.560,68.122,74.168,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.153 | Acc: 67.188,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.291 | Acc: 65.625,98.921,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.277 | Acc: 66.616,98.609,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.292 | Acc: 66.534,98.514,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.294 | Acc: 66.744,98.447,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.292 | Acc: 66.685,98.414,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.292 | Acc: 66.665,98.476,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.300 | Acc: 66.462,98.438,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.295 | Acc: 66.532,98.486,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.298 | Acc: 66.506,98.399,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.301 | Acc: 66.507,98.352,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.302 | Acc: 66.534,98.356,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.303 | Acc: 66.468,98.353,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.303 | Acc: 66.520,98.351,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.304 | Acc: 66.415,98.371,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.303 | Acc: 66.380,98.380,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.300 | Acc: 66.479,98.377,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.302 | Acc: 66.349,98.383,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.298 | Acc: 66.398,98.377,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.299 | Acc: 66.375,98.358,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.271 | Acc: 57.031,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.262 | Acc: 53.460,69.420,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.317 | Acc: 53.316,68.064,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.319 | Acc: 53.343,68.071,74.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.122 | Acc: 73.438,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.306 | Acc: 66.406,98.661,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.298 | Acc: 65.854,98.361,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.294 | Acc: 66.214,98.450,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.284 | Acc: 66.397,98.505,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.291 | Acc: 66.058,98.484,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.295 | Acc: 66.025,98.483,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.298 | Acc: 65.957,98.476,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.299 | Acc: 65.979,98.442,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.300 | Acc: 65.906,98.433,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.296 | Acc: 66.053,98.430,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.299 | Acc: 65.925,98.427,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.302 | Acc: 65.868,98.434,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.302 | Acc: 65.855,98.438,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.302 | Acc: 65.953,98.443,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.301 | Acc: 66.012,98.438,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.302 | Acc: 65.922,98.442,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.302 | Acc: 65.962,98.417,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.303 | Acc: 65.958,98.425,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.303 | Acc: 65.982,98.423,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.258 | Acc: 59.375,71.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.269 | Acc: 53.869,69.196,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.322 | Acc: 53.792,68.178,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.323 | Acc: 53.727,68.238,74.193,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.258 | Acc: 67.188,99.219,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.236 | Acc: 68.304,98.549,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.259 | Acc: 66.654,98.438,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.256 | Acc: 67.188,98.489,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.256 | Acc: 67.313,98.534,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.270 | Acc: 66.824,98.538,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.280 | Acc: 66.619,98.554,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.283 | Acc: 66.628,98.565,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.287 | Acc: 66.566,98.501,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.292 | Acc: 66.484,98.511,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.292 | Acc: 66.558,98.500,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.303 | Acc: 66.272,98.473,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.304 | Acc: 66.325,98.450,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.301 | Acc: 66.433,98.470,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.298 | Acc: 66.498,98.465,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.300 | Acc: 66.507,98.458,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.301 | Acc: 66.433,98.479,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.298 | Acc: 66.484,98.495,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.300 | Acc: 66.424,98.496,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.300 | Acc: 66.425,98.487,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.306 | Acc: 57.812,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.279 | Acc: 54.241,69.606,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.325 | Acc: 53.944,68.274,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.329 | Acc: 53.663,68.148,74.283,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.201 | Acc: 70.312,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.249 | Acc: 68.006,98.512,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.269 | Acc: 67.588,98.438,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.269 | Acc: 67.380,98.450,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.287 | Acc: 66.676,98.515,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.290 | Acc: 66.638,98.515,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.294 | Acc: 66.458,98.554,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.288 | Acc: 66.495,98.559,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.288 | Acc: 66.518,98.530,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.288 | Acc: 66.501,98.524,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.292 | Acc: 66.511,98.500,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.297 | Acc: 66.318,98.505,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.295 | Acc: 66.397,98.486,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.294 | Acc: 66.445,98.494,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.293 | Acc: 66.387,98.499,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.298 | Acc: 66.318,98.482,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.298 | Acc: 66.302,98.484,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.297 | Acc: 66.335,98.479,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.299 | Acc: 66.283,98.481,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.297 | Acc: 66.375,98.462,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.212 | Acc: 57.812,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.272 | Acc: 53.869,69.494,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.322 | Acc: 53.773,68.350,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.326 | Acc: 53.484,68.251,74.078,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.393 | Acc: 66.406,95.312,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.264 | Acc: 66.741,98.772,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.278 | Acc: 66.254,98.609,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.298 | Acc: 65.830,98.489,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.295 | Acc: 65.876,98.505,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.307 | Acc: 65.880,98.461,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.305 | Acc: 65.870,98.425,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.306 | Acc: 65.863,98.432,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.304 | Acc: 65.795,98.447,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.302 | Acc: 65.966,98.425,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.303 | Acc: 65.804,98.445,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.307 | Acc: 65.664,98.445,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.308 | Acc: 65.657,98.444,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.306 | Acc: 65.796,98.438,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.305 | Acc: 65.870,98.426,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.303 | Acc: 65.960,98.417,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.304 | Acc: 66.000,98.413,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.303 | Acc: 66.076,98.421,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.303 | Acc: 66.110,98.407,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.302 | Acc: 66.172,98.394,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.239 | Acc: 59.375,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.264 | Acc: 53.534,68.973,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.307 | Acc: 53.792,68.178,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.314 | Acc: 53.637,68.302,74.193,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.421 | Acc: 64.844,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.260 | Acc: 67.262,98.363,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.237 | Acc: 68.388,98.552,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.254 | Acc: 67.930,98.566,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.257 | Acc: 67.940,98.447,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.270 | Acc: 67.404,98.422,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.266 | Acc: 67.388,98.425,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.269 | Acc: 67.171,98.377,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.270 | Acc: 67.178,98.433,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.275 | Acc: 67.023,98.416,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.280 | Acc: 66.853,98.414,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.283 | Acc: 66.816,98.434,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.286 | Acc: 66.734,98.450,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.288 | Acc: 66.658,98.446,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.288 | Acc: 66.623,98.476,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.290 | Acc: 66.544,98.487,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.292 | Acc: 66.504,98.472,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.294 | Acc: 66.415,98.460,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.295 | Acc: 66.382,98.474,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.296 | Acc: 66.390,98.472,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.284 | Acc: 56.250,71.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.271 | Acc: 53.832,69.048,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.320 | Acc: 53.716,68.159,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.323 | Acc: 53.663,68.046,74.052,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.112 | Acc: 70.312,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.260 | Acc: 67.969,98.586,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.259 | Acc: 67.607,98.571,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.277 | Acc: 66.893,98.514,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.274 | Acc: 67.052,98.495,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.275 | Acc: 66.955,98.507,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.274 | Acc: 66.955,98.521,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.280 | Acc: 66.633,98.498,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.283 | Acc: 66.634,98.467,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.288 | Acc: 66.553,98.472,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.286 | Acc: 66.601,98.410,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.288 | Acc: 66.636,98.370,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.286 | Acc: 66.646,98.369,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.286 | Acc: 66.655,98.387,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.285 | Acc: 66.648,98.379,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.285 | Acc: 66.606,98.393,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.285 | Acc: 66.574,98.391,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.288 | Acc: 66.502,98.387,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.291 | Acc: 66.465,98.370,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.291 | Acc: 66.496,98.392,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.257 | Acc: 56.250,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.264 | Acc: 54.167,69.345,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 54.135,68.121,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.326 | Acc: 53.778,67.956,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.355 | Acc: 63.281,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.252 | Acc: 67.485,98.177,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.294 | Acc: 66.444,98.361,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.281 | Acc: 66.778,98.373,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.295 | Acc: 66.445,98.389,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.288 | Acc: 66.476,98.476,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.288 | Acc: 66.484,98.450,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.285 | Acc: 66.517,98.410,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.288 | Acc: 66.445,98.457,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.285 | Acc: 66.506,98.450,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.288 | Acc: 66.340,98.418,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.291 | Acc: 66.413,98.392,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.290 | Acc: 66.481,98.386,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.293 | Acc: 66.436,98.417,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.294 | Acc: 66.420,98.404,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.296 | Acc: 66.331,98.414,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.299 | Acc: 66.224,98.420,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.297 | Acc: 66.294,98.412,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.294 | Acc: 66.413,98.412,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.295 | Acc: 66.423,98.419,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.302 | Acc: 60.156,71.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.270 | Acc: 53.981,69.345,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.323 | Acc: 53.735,67.988,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.336 | Acc: 53.612,68.020,74.193,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.369 | Acc: 69.531,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.266 | Acc: 67.001,98.251,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.267 | Acc: 67.378,98.285,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.287 | Acc: 66.675,98.309,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.293 | Acc: 66.426,98.370,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.293 | Acc: 66.522,98.430,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.296 | Acc: 66.542,98.438,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.296 | Acc: 66.567,98.454,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.293 | Acc: 66.697,98.486,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.296 | Acc: 66.609,98.450,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.299 | Acc: 66.492,98.441,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.299 | Acc: 66.459,98.455,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.300 | Acc: 66.455,98.415,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.299 | Acc: 66.538,98.363,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.303 | Acc: 66.417,98.335,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.305 | Acc: 66.339,98.316,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.303 | Acc: 66.399,98.313,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.304 | Acc: 66.340,98.307,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.303 | Acc: 66.385,98.325,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.301 | Acc: 66.466,98.329,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.336 | Acc: 57.812,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.305 | Acc: 53.385,69.196,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.348 | Acc: 53.373,68.293,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.350 | Acc: 53.317,68.135,74.244,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.546 | Acc: 60.156,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.300 | Acc: 66.629,98.586,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.324 | Acc: 66.578,98.495,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.309 | Acc: 66.688,98.297,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.302 | Acc: 66.869,98.293,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.291 | Acc: 67.002,98.298,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.290 | Acc: 66.949,98.341,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.290 | Acc: 66.750,98.354,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.289 | Acc: 66.688,98.340,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.293 | Acc: 66.493,98.334,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.293 | Acc: 66.523,98.313,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.297 | Acc: 66.417,98.339,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.294 | Acc: 66.442,98.334,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.293 | Acc: 66.493,98.360,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.293 | Acc: 66.526,98.354,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.292 | Acc: 66.523,98.383,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.295 | Acc: 66.445,98.374,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.298 | Acc: 66.406,98.357,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.298 | Acc: 66.391,98.360,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.298 | Acc: 66.400,98.366,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.347 | Acc: 57.031,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.313 | Acc: 53.609,69.048,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.357 | Acc: 53.354,68.007,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.357 | Acc: 53.189,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 1.329 | Acc: 64.844,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.263 | Acc: 67.857,98.586,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.265 | Acc: 68.102,98.476,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.293 | Acc: 67.469,98.476,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.299 | Acc: 66.821,98.495,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.295 | Acc: 66.654,98.546,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.289 | Acc: 66.736,98.547,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.289 | Acc: 66.650,98.598,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.292 | Acc: 66.595,98.602,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.289 | Acc: 66.583,98.619,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.291 | Acc: 66.535,98.620,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.289 | Acc: 66.565,98.579,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.291 | Acc: 66.500,98.561,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.293 | Acc: 66.463,98.554,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.290 | Acc: 66.537,98.571,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.291 | Acc: 66.533,98.557,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.291 | Acc: 66.550,98.545,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.288 | Acc: 66.670,98.527,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.290 | Acc: 66.633,98.505,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.291 | Acc: 66.585,98.481,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.277 | Acc: 57.031,71.875,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.280 | Acc: 53.869,69.606,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.333 | Acc: 53.563,68.312,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.337 | Acc: 53.496,68.148,74.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.280 | Acc: 65.625,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.278 | Acc: 67.634,98.512,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.290 | Acc: 66.864,98.418,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.295 | Acc: 67.098,98.386,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.297 | Acc: 66.869,98.370,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.285 | Acc: 66.994,98.507,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.287 | Acc: 66.858,98.444,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.283 | Acc: 67.093,98.460,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.281 | Acc: 67.120,98.442,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.286 | Acc: 66.989,98.412,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.285 | Acc: 67.013,98.395,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.283 | Acc: 67.000,98.430,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.280 | Acc: 67.077,98.450,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.282 | Acc: 66.933,98.446,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.285 | Acc: 66.751,98.424,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.289 | Acc: 66.616,98.406,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.288 | Acc: 66.579,98.428,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.291 | Acc: 66.473,98.419,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.291 | Acc: 66.434,98.422,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.293 | Acc: 66.365,98.415,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.307 | Acc: 57.812,71.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.294 | Acc: 53.460,69.271,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.343 | Acc: 53.392,68.197,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.343 | Acc: 53.394,68.148,73.975,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.312 | Acc: 64.844,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.263 | Acc: 67.188,98.921,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.289 | Acc: 67.054,98.666,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.280 | Acc: 66.957,98.655,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.283 | Acc: 66.618,98.669,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.288 | Acc: 66.631,98.561,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.293 | Acc: 66.464,98.547,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.292 | Acc: 66.451,98.587,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.291 | Acc: 66.397,98.578,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.291 | Acc: 66.540,98.567,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.294 | Acc: 66.410,98.531,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.287 | Acc: 66.661,98.526,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.288 | Acc: 66.630,98.502,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.285 | Acc: 66.721,98.527,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.284 | Acc: 66.779,98.526,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.285 | Acc: 66.689,98.549,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.285 | Acc: 66.793,98.545,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.285 | Acc: 66.709,98.570,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.281 | Acc: 66.794,98.565,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.281 | Acc: 66.786,98.571,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.254 | Acc: 57.031,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.280 | Acc: 53.981,69.010,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.331 | Acc: 53.811,67.969,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.339 | Acc: 53.778,67.905,73.886,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.247 | Acc: 64.844,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.237 | Acc: 67.448,98.996,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.252 | Acc: 67.626,98.895,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.268 | Acc: 67.328,98.770,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.268 | Acc: 66.995,98.679,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.276 | Acc: 66.576,98.569,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.283 | Acc: 66.419,98.605,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.283 | Acc: 66.500,98.526,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.282 | Acc: 66.591,98.559,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.280 | Acc: 66.639,98.567,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.282 | Acc: 66.593,98.585,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.284 | Acc: 66.632,98.572,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.282 | Acc: 66.662,98.593,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.285 | Acc: 66.544,98.560,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.283 | Acc: 66.562,98.560,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.283 | Acc: 66.528,98.570,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.284 | Acc: 66.574,98.554,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.283 | Acc: 66.580,98.538,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.285 | Acc: 66.549,98.552,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.282 | Acc: 66.628,98.548,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.147 | Acc: 59.375,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 53.981,69.196,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.328 | Acc: 53.735,68.178,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.329 | Acc: 53.560,68.122,74.283,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.223 | Acc: 67.969,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.280 | Acc: 68.229,98.438,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.267 | Acc: 67.873,98.533,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.268 | Acc: 67.405,98.489,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.266 | Acc: 67.641,98.418,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.282 | Acc: 67.218,98.422,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.277 | Acc: 67.052,98.502,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.272 | Acc: 67.121,98.510,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.273 | Acc: 67.066,98.564,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.276 | Acc: 67.002,98.558,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.277 | Acc: 66.978,98.496,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.278 | Acc: 66.901,98.494,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.282 | Acc: 66.789,98.489,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.281 | Acc: 66.756,98.530,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.281 | Acc: 66.798,98.521,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.279 | Acc: 66.790,98.534,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.280 | Acc: 66.759,98.542,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.278 | Acc: 66.828,98.554,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.276 | Acc: 66.919,98.572,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.278 | Acc: 66.892,98.579,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.251 | Acc: 57.812,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 53.981,69.085,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.336 | Acc: 53.963,68.293,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.338 | Acc: 53.765,68.084,74.014,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.233 | Acc: 65.625,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.292 | Acc: 65.811,98.400,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.285 | Acc: 66.273,98.571,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.277 | Acc: 66.163,98.642,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.278 | Acc: 66.339,98.582,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.279 | Acc: 65.965,98.592,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.273 | Acc: 66.329,98.605,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.273 | Acc: 66.412,98.593,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.271 | Acc: 66.547,98.583,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.275 | Acc: 66.531,98.602,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.275 | Acc: 66.589,98.609,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.271 | Acc: 66.731,98.625,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.273 | Acc: 66.727,98.593,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.275 | Acc: 66.652,98.581,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.279 | Acc: 66.537,98.560,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.279 | Acc: 66.596,98.570,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.277 | Acc: 66.725,98.559,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.278 | Acc: 66.677,98.527,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.279 | Acc: 66.666,98.544,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.279 | Acc: 66.673,98.548,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.239 | Acc: 57.812,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 54.055,69.122,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.324 | Acc: 53.735,68.140,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.331 | Acc: 53.573,68.084,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.248 | Acc: 68.750,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.265 | Acc: 66.518,98.624,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.263 | Acc: 66.692,98.647,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.262 | Acc: 66.829,98.617,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.278 | Acc: 66.493,98.630,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.282 | Acc: 66.545,98.631,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.279 | Acc: 66.626,98.625,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.278 | Acc: 66.733,98.659,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.276 | Acc: 66.891,98.675,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.278 | Acc: 66.903,98.679,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.280 | Acc: 66.900,98.640,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.275 | Acc: 66.990,98.660,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.278 | Acc: 66.935,98.651,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.277 | Acc: 67.005,98.647,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.280 | Acc: 66.907,98.643,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.282 | Acc: 66.798,98.635,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.282 | Acc: 66.779,98.627,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.283 | Acc: 66.791,98.593,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.283 | Acc: 66.826,98.578,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.282 | Acc: 66.878,98.567,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.279 | Acc: 59.375,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.279 | Acc: 54.018,69.159,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.331 | Acc: 53.601,67.969,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.329 | Acc: 53.509,67.828,74.168,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.159 | Acc: 64.844,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.225 | Acc: 68.527,98.400,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.278 | Acc: 66.959,98.552,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.293 | Acc: 66.432,98.514,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.299 | Acc: 66.194,98.601,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.300 | Acc: 66.081,98.600,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.305 | Acc: 65.974,98.580,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.298 | Acc: 66.002,98.604,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.289 | Acc: 66.193,98.641,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.287 | Acc: 66.216,98.658,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.289 | Acc: 66.157,98.690,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.291 | Acc: 66.113,98.664,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.288 | Acc: 66.176,98.694,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.290 | Acc: 66.155,98.698,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.288 | Acc: 66.248,98.696,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.287 | Acc: 66.266,98.702,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.287 | Acc: 66.275,98.691,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.283 | Acc: 66.349,98.692,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.284 | Acc: 66.352,98.691,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.283 | Acc: 66.435,98.690,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.313 | Acc: 59.375,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.281 | Acc: 54.353,69.048,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.334 | Acc: 53.887,67.950,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.337 | Acc: 53.714,67.892,74.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.301 | Acc: 67.969,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.272 | Acc: 68.043,98.586,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.257 | Acc: 68.007,98.666,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.257 | Acc: 67.572,98.630,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.264 | Acc: 67.226,98.630,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.267 | Acc: 67.118,98.646,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.272 | Acc: 66.916,98.676,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.278 | Acc: 66.672,98.643,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.279 | Acc: 66.683,98.646,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.275 | Acc: 66.769,98.658,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.274 | Acc: 66.690,98.667,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.275 | Acc: 66.785,98.625,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.275 | Acc: 66.880,98.619,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.276 | Acc: 66.867,98.596,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 66.832,98.610,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.277 | Acc: 66.827,98.588,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.278 | Acc: 66.805,98.564,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.278 | Acc: 66.787,98.559,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.281 | Acc: 66.746,98.561,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.280 | Acc: 66.759,98.552,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.291 | Acc: 56.250,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.294 | Acc: 53.757,69.457,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.341 | Acc: 53.563,68.293,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.342 | Acc: 53.368,68.199,74.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 1.176 | Acc: 71.875,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.293 | Acc: 65.923,98.772,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.288 | Acc: 66.521,98.819,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.266 | Acc: 67.175,98.706,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.273 | Acc: 66.995,98.640,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.268 | Acc: 67.180,98.592,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.270 | Acc: 67.233,98.625,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.269 | Acc: 67.143,98.620,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.270 | Acc: 67.197,98.593,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.271 | Acc: 67.105,98.606,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.273 | Acc: 66.939,98.659,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.275 | Acc: 66.841,98.681,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.274 | Acc: 66.883,98.674,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.274 | Acc: 66.864,98.653,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.273 | Acc: 66.862,98.693,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.275 | Acc: 66.783,98.697,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.275 | Acc: 66.740,98.674,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.274 | Acc: 66.757,98.678,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.273 | Acc: 66.761,98.682,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.276 | Acc: 66.712,98.673,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.303 | Acc: 56.250,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 54.055,69.159,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.334 | Acc: 53.868,68.159,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.341 | Acc: 53.689,68.058,74.014,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.345 | Acc: 62.500,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.268 | Acc: 66.704,99.144,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.271 | Acc: 66.616,98.914,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.269 | Acc: 67.200,98.796,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.259 | Acc: 67.342,98.794,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.262 | Acc: 67.288,98.724,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.262 | Acc: 67.284,98.702,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.270 | Acc: 67.260,98.659,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.270 | Acc: 67.144,98.685,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.265 | Acc: 67.278,98.684,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.273 | Acc: 67.013,98.659,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.276 | Acc: 66.975,98.671,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.274 | Acc: 66.996,98.642,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.271 | Acc: 67.089,98.653,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.273 | Acc: 67.004,98.640,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.277 | Acc: 66.980,98.619,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.278 | Acc: 66.891,98.613,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 66.938,98.618,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.279 | Acc: 66.802,98.595,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.278 | Acc: 66.788,98.597,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.293 | Acc: 56.250,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.279 | Acc: 53.869,69.606,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.337 | Acc: 53.754,68.274,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.342 | Acc: 53.573,68.238,74.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.019 | Acc: 74.219,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.244 | Acc: 67.820,98.847,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.258 | Acc: 67.588,98.761,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.260 | Acc: 67.533,98.745,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.272 | Acc: 67.255,98.736,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.278 | Acc: 67.087,98.670,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.280 | Acc: 67.136,98.625,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.278 | Acc: 67.232,98.615,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.278 | Acc: 67.032,98.578,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.276 | Acc: 67.101,98.589,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.278 | Acc: 67.118,98.574,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.280 | Acc: 66.915,98.551,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.282 | Acc: 66.909,98.532,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.280 | Acc: 66.888,98.578,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.284 | Acc: 66.795,98.549,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.283 | Acc: 66.832,98.562,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.280 | Acc: 66.835,98.571,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.281 | Acc: 66.846,98.561,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.280 | Acc: 66.768,98.572,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.284 | Acc: 66.669,98.567,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.346 | Acc: 57.031,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.278 | Acc: 53.795,69.420,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.340 | Acc: 53.639,68.255,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.348 | Acc: 53.471,68.033,74.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.285 | Acc: 67.969,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.265 | Acc: 68.378,98.549,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.289 | Acc: 67.226,98.666,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.257 | Acc: 67.841,98.706,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.271 | Acc: 67.660,98.640,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.275 | Acc: 67.466,98.654,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.272 | Acc: 67.426,98.605,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.275 | Acc: 67.409,98.565,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.273 | Acc: 67.416,98.569,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.276 | Acc: 67.153,98.584,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.278 | Acc: 67.106,98.612,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.279 | Acc: 67.060,98.597,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.278 | Acc: 67.029,98.561,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.278 | Acc: 67.050,98.569,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 67.115,98.579,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.280 | Acc: 66.977,98.557,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.279 | Acc: 66.964,98.562,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.280 | Acc: 66.853,98.568,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.280 | Acc: 66.837,98.565,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.279 | Acc: 66.894,98.540,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.332 | Acc: 56.250,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.291 | Acc: 54.167,69.308,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.344 | Acc: 53.792,68.178,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.342 | Acc: 53.637,68.122,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.255 | Acc: 66.406,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.242 | Acc: 67.411,98.512,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.243 | Acc: 67.588,98.495,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.261 | Acc: 67.034,98.476,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.258 | Acc: 67.236,98.573,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.269 | Acc: 67.126,98.499,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.278 | Acc: 66.832,98.483,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.276 | Acc: 66.766,98.498,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.273 | Acc: 66.809,98.535,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.273 | Acc: 66.777,98.545,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.276 | Acc: 66.690,98.542,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.274 | Acc: 66.597,98.558,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.273 | Acc: 66.679,98.574,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.276 | Acc: 66.628,98.569,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.280 | Acc: 66.590,98.557,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.278 | Acc: 66.635,98.562,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.278 | Acc: 66.708,98.557,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.277 | Acc: 66.727,98.568,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.279 | Acc: 66.705,98.561,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.278 | Acc: 66.743,98.556,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.327 | Acc: 57.031,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 53.795,68.824,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.341 | Acc: 53.582,68.026,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.353 | Acc: 53.381,67.994,73.706,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.210 | Acc: 72.656,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.260 | Acc: 67.374,98.884,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.261 | Acc: 67.683,98.647,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.260 | Acc: 67.725,98.591,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.257 | Acc: 67.728,98.592,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.261 | Acc: 67.652,98.546,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.263 | Acc: 67.646,98.586,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.263 | Acc: 67.492,98.593,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.267 | Acc: 67.382,98.612,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.274 | Acc: 67.157,98.584,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.278 | Acc: 67.009,98.581,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.276 | Acc: 67.060,98.611,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.276 | Acc: 67.035,98.606,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.280 | Acc: 66.891,98.581,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 66.943,98.568,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.275 | Acc: 66.925,98.567,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.275 | Acc: 66.932,98.576,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.275 | Acc: 66.858,98.568,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.275 | Acc: 66.833,98.563,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.277 | Acc: 66.775,98.567,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.298 | Acc: 58.594,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.286 | Acc: 54.167,69.085,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.338 | Acc: 53.811,68.102,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.340 | Acc: 53.701,68.046,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.405 | Acc: 65.625,100.000,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.309 | Acc: 66.592,98.624,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.313 | Acc: 66.025,98.590,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.306 | Acc: 65.932,98.630,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.292 | Acc: 66.377,98.611,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.289 | Acc: 66.561,98.670,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.280 | Acc: 66.903,98.663,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.273 | Acc: 67.082,98.703,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.268 | Acc: 67.270,98.704,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.270 | Acc: 67.118,98.714,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.268 | Acc: 67.160,98.671,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.273 | Acc: 66.961,98.653,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.273 | Acc: 66.905,98.658,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.275 | Acc: 66.831,98.617,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.274 | Acc: 66.868,98.596,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 66.754,98.601,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.277 | Acc: 66.706,98.613,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.279 | Acc: 66.709,98.600,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.279 | Acc: 66.707,98.587,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.278 | Acc: 66.667,98.591,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.296 | Acc: 57.812,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.266 | Acc: 54.092,69.271,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.320 | Acc: 53.792,68.350,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.330 | Acc: 53.599,68.122,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.263 | Acc: 64.062,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.258 | Acc: 66.071,98.400,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.272 | Acc: 66.578,98.571,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.271 | Acc: 66.547,98.604,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.264 | Acc: 66.821,98.630,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.262 | Acc: 66.901,98.654,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.268 | Acc: 66.710,98.599,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.272 | Acc: 66.700,98.565,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.270 | Acc: 66.693,98.569,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.273 | Acc: 66.648,98.571,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.267 | Acc: 66.764,98.609,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.267 | Acc: 66.834,98.597,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.267 | Acc: 66.928,98.564,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.269 | Acc: 66.873,98.572,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.270 | Acc: 66.818,98.596,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.269 | Acc: 66.905,98.609,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.273 | Acc: 66.796,98.576,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.275 | Acc: 66.738,98.582,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.274 | Acc: 66.820,98.600,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.274 | Acc: 66.841,98.604,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.193 | Acc: 57.031,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.285 | Acc: 54.018,69.308,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 53.697,68.293,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.328 | Acc: 53.573,68.238,73.924,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.233 | Acc: 69.531,98.438,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.253 | Acc: 67.374,98.624,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.287 | Acc: 66.368,98.514,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.285 | Acc: 66.457,98.502,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.281 | Acc: 66.744,98.553,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.277 | Acc: 66.669,98.530,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.278 | Acc: 66.600,98.560,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.273 | Acc: 66.789,98.582,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.273 | Acc: 66.828,98.602,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.275 | Acc: 66.777,98.658,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.280 | Acc: 66.535,98.640,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 66.714,98.657,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.277 | Acc: 66.685,98.648,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.278 | Acc: 66.631,98.644,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.275 | Acc: 66.751,98.640,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 66.783,98.596,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.274 | Acc: 66.844,98.593,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.275 | Acc: 66.821,98.605,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.274 | Acc: 66.895,98.613,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.276 | Acc: 66.818,98.593,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.285 | Acc: 57.812,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 54.464,69.085,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.326 | Acc: 54.002,68.178,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.332 | Acc: 53.778,68.084,74.078,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.198 | Acc: 71.094,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.267 | Acc: 67.262,98.810,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.267 | Acc: 66.463,98.742,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.271 | Acc: 66.675,98.783,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.258 | Acc: 67.110,98.727,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.256 | Acc: 67.319,98.708,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.259 | Acc: 67.304,98.715,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.262 | Acc: 67.309,98.615,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.268 | Acc: 67.197,98.622,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.270 | Acc: 67.127,98.606,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.270 | Acc: 67.020,98.593,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.267 | Acc: 67.043,98.590,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.267 | Acc: 66.980,98.593,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.269 | Acc: 66.945,98.596,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 66.762,98.607,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.280 | Acc: 66.655,98.593,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.280 | Acc: 66.674,98.593,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.279 | Acc: 66.718,98.602,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.277 | Acc: 66.759,98.617,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.277 | Acc: 66.689,98.630,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.269 | Acc: 57.812,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.291 | Acc: 54.315,69.382,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.336 | Acc: 53.773,68.197,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.340 | Acc: 53.624,68.238,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.197 | Acc: 68.750,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.272 | Acc: 66.332,98.921,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.291 | Acc: 66.101,98.628,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.298 | Acc: 66.227,98.617,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.293 | Acc: 66.435,98.688,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.290 | Acc: 66.662,98.639,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.293 | Acc: 66.555,98.605,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.286 | Acc: 66.861,98.626,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.283 | Acc: 66.843,98.670,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.283 | Acc: 66.851,98.662,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.281 | Acc: 66.845,98.616,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.282 | Acc: 66.760,98.646,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.276 | Acc: 67.022,98.635,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.276 | Acc: 67.011,98.638,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.277 | Acc: 67.048,98.621,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.280 | Acc: 66.975,98.632,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.280 | Acc: 66.915,98.644,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.280 | Acc: 66.901,98.644,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.280 | Acc: 66.889,98.643,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.279 | Acc: 66.894,98.655,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.249 | Acc: 57.812,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.288 | Acc: 53.906,69.234,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.335 | Acc: 53.678,68.140,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.341 | Acc: 53.509,68.084,73.873,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.170 | Acc: 71.875,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.263 | Acc: 67.225,98.475,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.268 | Acc: 66.921,98.647,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.271 | Acc: 66.778,98.681,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.278 | Acc: 66.435,98.630,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.281 | Acc: 66.429,98.584,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.281 | Acc: 66.503,98.534,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.282 | Acc: 66.495,98.521,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.285 | Acc: 66.552,98.544,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.284 | Acc: 66.536,98.550,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.283 | Acc: 66.593,98.535,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.283 | Acc: 66.629,98.558,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.287 | Acc: 66.536,98.564,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.287 | Acc: 66.487,98.545,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.285 | Acc: 66.490,98.546,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.286 | Acc: 66.482,98.544,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.284 | Acc: 66.508,98.523,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.282 | Acc: 66.537,98.531,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.281 | Acc: 66.582,98.541,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.282 | Acc: 66.548,98.548,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.314 | Acc: 57.031,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.285 | Acc: 54.204,69.308,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.332 | Acc: 53.830,68.236,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.339 | Acc: 53.650,68.251,73.911,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.263 | Acc: 62.500,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.301 | Acc: 66.443,98.549,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.299 | Acc: 66.349,98.590,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.287 | Acc: 66.650,98.694,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.284 | Acc: 66.782,98.698,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.281 | Acc: 66.692,98.716,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.283 | Acc: 66.626,98.715,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.282 | Acc: 66.667,98.681,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.284 | Acc: 66.654,98.704,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.283 | Acc: 66.549,98.684,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.278 | Acc: 66.741,98.671,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 66.739,98.667,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.277 | Acc: 66.692,98.661,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.278 | Acc: 66.700,98.689,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.278 | Acc: 66.715,98.674,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.277 | Acc: 66.798,98.671,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.278 | Acc: 66.793,98.676,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 66.821,98.673,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.275 | Acc: 66.830,98.671,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.276 | Acc: 66.851,98.653,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.280 | Acc: 57.812,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 54.204,69.159,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.320 | Acc: 53.906,68.274,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.326 | Acc: 53.714,68.276,74.283,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 1.329 | Acc: 65.625,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.305 | Acc: 65.551,98.251,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.296 | Acc: 66.216,98.399,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.275 | Acc: 66.893,98.463,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.276 | Acc: 66.782,98.524,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.280 | Acc: 66.747,98.577,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.278 | Acc: 66.916,98.547,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.275 | Acc: 66.977,98.559,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.277 | Acc: 66.887,98.617,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.281 | Acc: 66.687,98.584,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.283 | Acc: 66.729,98.566,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.280 | Acc: 66.785,98.554,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.280 | Acc: 66.795,98.557,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.282 | Acc: 66.810,98.554,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.284 | Acc: 66.693,98.565,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.283 | Acc: 66.692,98.575,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.281 | Acc: 66.759,98.564,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.282 | Acc: 66.704,98.568,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.281 | Acc: 66.748,98.559,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.280 | Acc: 66.788,98.571,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.296 | Acc: 56.250,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.287 | Acc: 54.315,69.085,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.328 | Acc: 53.849,68.216,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.332 | Acc: 53.624,68.071,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.301 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.304 | Acc: 66.741,98.661,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.292 | Acc: 66.845,98.628,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.281 | Acc: 67.021,98.694,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.279 | Acc: 66.782,98.698,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.280 | Acc: 67.056,98.708,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.278 | Acc: 67.052,98.735,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.278 | Acc: 66.789,98.726,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.277 | Acc: 66.838,98.685,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.279 | Acc: 66.734,98.675,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.278 | Acc: 66.760,98.671,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.280 | Acc: 66.689,98.635,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.280 | Acc: 66.698,98.606,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.279 | Acc: 66.762,98.608,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.278 | Acc: 66.795,98.610,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 66.816,98.617,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.276 | Acc: 66.813,98.625,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.275 | Acc: 66.819,98.625,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.275 | Acc: 66.787,98.619,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.274 | Acc: 66.833,98.624,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.330 | Acc: 57.031,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.291 | Acc: 53.981,68.899,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.345 | Acc: 53.716,68.083,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.354 | Acc: 53.509,67.943,74.116,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.174 | Acc: 65.625,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.303 | Acc: 66.295,98.847,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.305 | Acc: 66.159,98.476,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.286 | Acc: 66.278,98.502,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.281 | Acc: 66.551,98.640,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.273 | Acc: 66.770,98.569,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.274 | Acc: 66.826,98.541,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.272 | Acc: 66.844,98.570,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.271 | Acc: 66.809,98.617,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.270 | Acc: 66.790,98.576,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.274 | Acc: 66.655,98.601,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 66.604,98.586,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.275 | Acc: 66.649,98.587,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.275 | Acc: 66.649,98.572,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.273 | Acc: 66.659,98.563,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.273 | Acc: 66.715,98.575,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.275 | Acc: 66.667,98.569,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.274 | Acc: 66.704,98.598,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.274 | Acc: 66.735,98.598,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.275 | Acc: 66.743,98.583,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.285 | Acc: 57.812,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.282 | Acc: 53.832,69.048,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.328 | Acc: 53.697,68.083,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.334 | Acc: 53.445,68.033,74.129,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.396 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.293 | Acc: 66.443,98.065,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.304 | Acc: 65.873,98.552,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.291 | Acc: 66.163,98.540,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.277 | Acc: 66.464,98.563,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.275 | Acc: 66.692,98.615,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.271 | Acc: 66.923,98.638,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.282 | Acc: 66.595,98.604,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.279 | Acc: 66.629,98.598,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.282 | Acc: 66.635,98.593,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.283 | Acc: 66.636,98.597,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.282 | Acc: 66.625,98.572,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.283 | Acc: 66.633,98.548,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.280 | Acc: 66.712,98.554,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 66.779,98.582,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 66.835,98.578,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.273 | Acc: 66.927,98.584,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 66.821,98.561,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.275 | Acc: 66.826,98.574,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.277 | Acc: 66.816,98.583,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.296 | Acc: 57.812,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.285 | Acc: 54.204,68.601,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.329 | Acc: 53.906,67.950,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.336 | Acc: 53.714,67.969,74.142,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.297 | Acc: 67.969,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.231 | Acc: 68.378,98.661,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.265 | Acc: 66.749,98.647,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.286 | Acc: 66.342,98.655,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.285 | Acc: 66.291,98.611,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.286 | Acc: 66.236,98.584,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.278 | Acc: 66.484,98.567,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.281 | Acc: 66.572,98.604,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.280 | Acc: 66.532,98.607,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.276 | Acc: 66.682,98.636,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.277 | Acc: 66.636,98.616,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.280 | Acc: 66.640,98.604,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.280 | Acc: 66.601,98.603,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.283 | Acc: 66.583,98.602,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.283 | Acc: 66.590,98.627,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.284 | Acc: 66.494,98.627,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.282 | Acc: 66.567,98.622,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.281 | Acc: 66.546,98.644,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.279 | Acc: 66.605,98.634,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.278 | Acc: 66.679,98.624,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.314 | Acc: 57.031,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.287 | Acc: 54.278,68.936,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.334 | Acc: 53.925,68.026,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.341 | Acc: 53.714,67.956,74.116,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.379 | Acc: 67.188,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.340 | Acc: 65.625,98.512,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.292 | Acc: 66.959,98.514,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.277 | Acc: 67.123,98.591,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.273 | Acc: 67.149,98.592,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.280 | Acc: 66.731,98.623,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.279 | Acc: 66.665,98.676,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.278 | Acc: 66.744,98.715,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.273 | Acc: 66.911,98.724,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.270 | Acc: 67.049,98.735,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.272 | Acc: 66.900,98.717,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.271 | Acc: 66.852,98.688,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.273 | Acc: 66.782,98.671,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.269 | Acc: 66.855,98.677,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.269 | Acc: 66.904,98.693,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.266 | Acc: 67.011,98.679,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.270 | Acc: 66.964,98.630,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.271 | Acc: 66.954,98.632,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.273 | Acc: 66.926,98.637,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.276 | Acc: 66.886,98.641,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.259 | Acc: 57.031,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.282 | Acc: 54.427,69.159,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.336 | Acc: 54.211,68.197,73.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.344 | Acc: 53.881,68.110,73.988,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.147 | Acc: 64.844,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.284 | Acc: 67.894,98.400,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.296 | Acc: 66.902,98.495,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.282 | Acc: 67.354,98.438,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.283 | Acc: 67.062,98.447,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.280 | Acc: 66.909,98.577,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.280 | Acc: 66.903,98.567,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.278 | Acc: 67.016,98.593,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.278 | Acc: 67.008,98.569,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.280 | Acc: 66.808,98.593,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.281 | Acc: 66.717,98.616,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.279 | Acc: 66.618,98.653,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.280 | Acc: 66.656,98.651,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.281 | Acc: 66.622,98.629,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.281 | Acc: 66.651,98.604,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.278 | Acc: 66.728,98.617,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.279 | Acc: 66.691,98.625,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.280 | Acc: 66.672,98.623,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.279 | Acc: 66.694,98.591,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.280 | Acc: 66.658,98.585,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.255 | Acc: 57.031,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.288 | Acc: 54.613,69.382,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.340 | Acc: 53.982,68.312,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.341 | Acc: 53.727,68.186,73.758,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.153 | Acc: 68.750,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.247 | Acc: 68.378,98.661,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.271 | Acc: 67.492,98.209,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.272 | Acc: 67.585,98.309,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.260 | Acc: 67.554,98.370,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.271 | Acc: 67.149,98.360,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.268 | Acc: 67.175,98.373,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.274 | Acc: 66.916,98.360,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.278 | Acc: 66.925,98.374,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.276 | Acc: 66.976,98.347,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.273 | Acc: 67.009,98.364,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.272 | Acc: 67.032,98.395,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.274 | Acc: 67.022,98.399,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.277 | Acc: 67.005,98.408,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.275 | Acc: 66.985,98.440,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 67.019,98.440,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.274 | Acc: 67.061,98.442,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 67.023,98.449,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.277 | Acc: 66.895,98.446,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.278 | Acc: 66.861,98.472,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.250 | Acc: 56.250,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.275 | Acc: 54.204,69.717,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 54.040,68.445,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.340 | Acc: 53.765,68.225,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.249 | Acc: 69.531,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.300 | Acc: 66.667,98.884,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.317 | Acc: 66.063,98.723,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.287 | Acc: 66.752,98.719,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.283 | Acc: 66.435,98.736,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.278 | Acc: 66.731,98.716,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.276 | Acc: 66.736,98.689,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.282 | Acc: 66.622,98.692,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.276 | Acc: 66.770,98.743,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.271 | Acc: 66.881,98.753,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.275 | Acc: 66.733,98.807,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 66.753,98.759,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.275 | Acc: 66.679,98.739,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.274 | Acc: 66.709,98.722,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.276 | Acc: 66.681,98.691,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 66.604,98.687,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.277 | Acc: 66.591,98.671,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.277 | Acc: 66.615,98.662,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.278 | Acc: 66.696,98.630,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.278 | Acc: 66.706,98.624,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.322 | Acc: 57.031,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.280 | Acc: 54.315,69.457,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.333 | Acc: 53.944,68.312,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.345 | Acc: 53.650,68.110,73.886,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.191 | Acc: 69.531,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.325 | Acc: 65.923,98.661,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.296 | Acc: 66.768,98.609,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.285 | Acc: 66.816,98.591,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.280 | Acc: 66.734,98.592,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.274 | Acc: 66.747,98.592,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.282 | Acc: 66.561,98.534,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.283 | Acc: 66.600,98.515,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.284 | Acc: 66.595,98.554,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.284 | Acc: 66.588,98.567,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.284 | Acc: 66.612,98.546,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.280 | Acc: 66.792,98.579,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.279 | Acc: 66.792,98.587,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.277 | Acc: 66.846,98.578,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.277 | Acc: 66.807,98.571,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.279 | Acc: 66.785,98.562,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.278 | Acc: 66.796,98.564,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.279 | Acc: 66.798,98.557,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.279 | Acc: 66.789,98.539,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.279 | Acc: 66.771,98.534,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.291 | Acc: 58.594,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 54.167,69.345,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.342 | Acc: 54.002,68.293,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.346 | Acc: 53.817,68.033,74.168,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.208 | Acc: 71.094,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.292 | Acc: 67.746,98.661,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.274 | Acc: 67.492,98.609,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.270 | Acc: 67.405,98.655,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.277 | Acc: 67.159,98.708,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.281 | Acc: 67.017,98.646,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.280 | Acc: 67.013,98.644,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.280 | Acc: 66.894,98.681,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.276 | Acc: 66.974,98.641,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.272 | Acc: 67.032,98.671,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.271 | Acc: 67.048,98.678,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.268 | Acc: 67.032,98.696,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.271 | Acc: 66.925,98.720,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.273 | Acc: 66.912,98.677,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.272 | Acc: 66.932,98.713,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.271 | Acc: 67.008,98.720,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.271 | Acc: 67.017,98.717,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.271 | Acc: 67.036,98.708,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.272 | Acc: 66.969,98.717,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.271 | Acc: 66.976,98.729,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.306 | Acc: 58.594,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.296 | Acc: 54.055,69.606,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.335 | Acc: 53.830,68.426,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.339 | Acc: 53.624,68.225,73.886,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.138 | Acc: 67.969,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.271 | Acc: 66.704,98.884,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.256 | Acc: 67.016,98.857,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.274 | Acc: 66.714,98.719,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.270 | Acc: 66.686,98.756,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.272 | Acc: 66.631,98.778,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.272 | Acc: 66.606,98.747,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.271 | Acc: 66.700,98.737,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.269 | Acc: 66.663,98.738,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.265 | Acc: 66.708,98.666,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.267 | Acc: 66.741,98.624,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.271 | Acc: 66.696,98.544,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.274 | Acc: 66.627,98.548,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.279 | Acc: 66.505,98.554,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.275 | Acc: 66.604,98.560,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.276 | Acc: 66.572,98.559,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.277 | Acc: 66.552,98.562,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.276 | Acc: 66.539,98.547,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.275 | Acc: 66.638,98.563,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.275 | Acc: 66.712,98.573,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.307 | Acc: 58.594,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.286 | Acc: 54.018,69.159,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 53.868,68.236,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.332 | Acc: 53.663,68.020,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.597 | Acc: 55.469,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.272 | Acc: 67.188,98.251,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.292 | Acc: 66.387,98.399,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.295 | Acc: 66.265,98.399,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.291 | Acc: 66.300,98.466,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.281 | Acc: 66.607,98.554,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.287 | Acc: 66.477,98.483,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.284 | Acc: 66.545,98.548,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.287 | Acc: 66.455,98.520,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.284 | Acc: 66.536,98.537,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.281 | Acc: 66.620,98.558,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.289 | Acc: 66.413,98.565,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.286 | Acc: 66.523,98.538,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.284 | Acc: 66.556,98.554,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.283 | Acc: 66.587,98.563,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.283 | Acc: 66.627,98.557,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.282 | Acc: 66.642,98.564,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.283 | Acc: 66.649,98.559,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.283 | Acc: 66.705,98.531,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.282 | Acc: 66.726,98.546,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.308 | Acc: 58.594,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 54.464,69.345,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.337 | Acc: 53.982,68.293,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.340 | Acc: 53.689,67.982,74.116,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.271 | Acc: 67.969,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.230 | Acc: 68.676,98.958,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.245 | Acc: 67.950,98.857,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.262 | Acc: 67.546,98.796,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.267 | Acc: 67.342,98.736,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.274 | Acc: 67.334,98.646,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.271 | Acc: 67.233,98.638,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.276 | Acc: 66.938,98.676,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.279 | Acc: 66.785,98.646,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.276 | Acc: 66.885,98.640,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.279 | Acc: 66.818,98.655,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.275 | Acc: 66.883,98.625,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.274 | Acc: 66.893,98.622,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.275 | Acc: 66.834,98.620,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.273 | Acc: 66.851,98.629,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.272 | Acc: 66.873,98.619,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.274 | Acc: 66.852,98.627,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.273 | Acc: 66.837,98.637,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.276 | Acc: 66.753,98.645,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.276 | Acc: 66.749,98.636,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.238 | Acc: 57.812,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.270 | Acc: 54.018,69.159,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.310 | Acc: 53.868,68.312,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.321 | Acc: 53.676,68.186,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.212 | Acc: 70.312,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.287 | Acc: 66.257,98.921,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.288 | Acc: 66.159,98.819,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.279 | Acc: 66.278,98.706,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.270 | Acc: 66.541,98.765,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.268 | Acc: 66.909,98.739,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.271 | Acc: 66.710,98.715,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.279 | Acc: 66.578,98.648,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.274 | Acc: 66.702,98.612,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.270 | Acc: 66.985,98.636,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.273 | Acc: 66.962,98.659,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.275 | Acc: 66.820,98.685,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.273 | Acc: 66.795,98.694,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.271 | Acc: 66.867,98.635,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.271 | Acc: 66.873,98.635,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.270 | Acc: 66.899,98.653,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.268 | Acc: 66.964,98.649,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.269 | Acc: 66.906,98.657,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.270 | Acc: 66.898,98.656,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.273 | Acc: 66.841,98.657,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.317 | Acc: 58.594,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 54.129,69.531,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.334 | Acc: 53.716,68.426,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.338 | Acc: 53.586,68.251,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.314 | Acc: 64.062,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.308 | Acc: 66.406,98.438,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.292 | Acc: 67.035,98.438,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.266 | Acc: 67.661,98.489,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.268 | Acc: 67.737,98.611,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.273 | Acc: 67.559,98.631,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.274 | Acc: 67.407,98.573,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.278 | Acc: 67.171,98.598,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.275 | Acc: 67.149,98.627,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.277 | Acc: 67.093,98.610,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.277 | Acc: 66.989,98.640,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 67.007,98.632,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.278 | Acc: 66.957,98.642,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.278 | Acc: 66.915,98.617,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.278 | Acc: 66.948,98.638,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.280 | Acc: 66.798,98.640,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.278 | Acc: 66.871,98.635,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.278 | Acc: 66.903,98.662,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.278 | Acc: 66.876,98.652,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.277 | Acc: 66.931,98.659,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.248 | Acc: 57.812,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.292 | Acc: 54.278,69.196,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.333 | Acc: 54.078,68.140,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.341 | Acc: 53.855,68.007,74.334,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.307 | Acc: 66.406,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.269 | Acc: 66.927,98.921,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.265 | Acc: 67.226,98.876,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.261 | Acc: 67.469,98.783,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.269 | Acc: 67.265,98.746,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.271 | Acc: 67.079,98.786,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.271 | Acc: 67.155,98.754,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.271 | Acc: 67.071,98.748,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.268 | Acc: 67.188,98.758,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.271 | Acc: 67.157,98.714,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.272 | Acc: 67.090,98.725,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.273 | Acc: 66.975,98.720,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.273 | Acc: 66.938,98.710,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.274 | Acc: 66.882,98.710,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.272 | Acc: 66.957,98.702,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.269 | Acc: 67.071,98.705,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.269 | Acc: 67.005,98.720,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.269 | Acc: 67.023,98.724,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.270 | Acc: 66.973,98.721,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.270 | Acc: 66.999,98.698,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.271 | Acc: 59.375,71.875,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.285 | Acc: 54.241,69.085,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.332 | Acc: 53.830,68.102,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.332 | Acc: 53.650,68.020,74.155,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 1.476 | Acc: 60.156,98.438,100.000,% | Adaptive Acc: 89.844% | clf_exit: 0.578 0.406 0.016
Batch: 20 | Loss: 1.292 | Acc: 66.369,98.698,99.888,% | Adaptive Acc: 91.071% | clf_exit: 0.583 0.407 0.010
Batch: 40 | Loss: 1.293 | Acc: 66.368,98.380,99.943,% | Adaptive Acc: 91.120% | clf_exit: 0.576 0.413 0.012
Batch: 60 | Loss: 1.281 | Acc: 66.765,98.502,99.936,% | Adaptive Acc: 91.457% | clf_exit: 0.578 0.411 0.011
Batch: 80 | Loss: 1.288 | Acc: 66.454,98.495,99.923,% | Adaptive Acc: 91.310% | clf_exit: 0.580 0.409 0.011
Batch: 100 | Loss: 1.282 | Acc: 66.584,98.499,99.899,% | Adaptive Acc: 91.491% | clf_exit: 0.577 0.411 0.012
Batch: 120 | Loss: 1.280 | Acc: 66.742,98.534,99.871,% | Adaptive Acc: 91.574% | clf_exit: 0.578 0.410 0.012
Batch: 140 | Loss: 1.275 | Acc: 66.827,98.504,99.850,% | Adaptive Acc: 91.622% | clf_exit: 0.579 0.409 0.012
Batch: 160 | Loss: 1.276 | Acc: 66.930,98.476,99.854,% | Adaptive Acc: 91.547% | clf_exit: 0.581 0.408 0.012
Batch: 180 | Loss: 1.273 | Acc: 67.058,98.446,99.871,% | Adaptive Acc: 91.661% | clf_exit: 0.581 0.407 0.012
Batch: 200 | Loss: 1.270 | Acc: 67.110,98.507,99.864,% | Adaptive Acc: 91.678% | clf_exit: 0.580 0.407 0.012
Batch: 220 | Loss: 1.272 | Acc: 67.081,98.491,99.866,% | Adaptive Acc: 91.753% | clf_exit: 0.580 0.408 0.012
Batch: 240 | Loss: 1.273 | Acc: 67.016,98.509,99.874,% | Adaptive Acc: 91.727% | clf_exit: 0.580 0.408 0.012
Batch: 260 | Loss: 1.275 | Acc: 67.020,98.509,99.871,% | Adaptive Acc: 91.765% | clf_exit: 0.580 0.408 0.012
Batch: 280 | Loss: 1.275 | Acc: 66.985,98.538,99.867,% | Adaptive Acc: 91.734% | clf_exit: 0.579 0.409 0.012
Batch: 300 | Loss: 1.277 | Acc: 66.918,98.531,99.870,% | Adaptive Acc: 91.731% | clf_exit: 0.579 0.409 0.012
Batch: 320 | Loss: 1.278 | Acc: 66.857,98.520,99.869,% | Adaptive Acc: 91.752% | clf_exit: 0.578 0.410 0.012
Batch: 340 | Loss: 1.278 | Acc: 66.878,98.547,99.869,% | Adaptive Acc: 91.768% | clf_exit: 0.579 0.409 0.012
Batch: 360 | Loss: 1.278 | Acc: 66.852,98.546,99.872,% | Adaptive Acc: 91.729% | clf_exit: 0.578 0.410 0.012
Batch: 380 | Loss: 1.280 | Acc: 66.781,98.563,99.873,% | Adaptive Acc: 91.763% | clf_exit: 0.577 0.411 0.012
Batch: 0 | Loss: 4.289 | Acc: 58.594,68.750,72.656,% | Adaptive Acc: 69.531% | clf_exit: 0.594 0.320 0.086
Batch: 20 | Loss: 4.285 | Acc: 54.241,69.122,75.112,% | Adaptive Acc: 66.443% | clf_exit: 0.576 0.319 0.106
Batch: 40 | Loss: 4.328 | Acc: 53.963,68.140,74.047,% | Adaptive Acc: 65.758% | clf_exit: 0.575 0.321 0.104
Batch: 60 | Loss: 4.335 | Acc: 53.650,68.084,73.886,% | Adaptive Acc: 65.689% | clf_exit: 0.571 0.324 0.105
model is save as models/modelG_0con1_2con3_cifar100_adaptive0_circles5_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 11.236 | Acc: 13.281,18.750,8.594,% | Adaptive Acc: 11.719% | clf_exit: 0.055 0.023 0.922
Batch: 20 | Loss: 11.473 | Acc: 11.905,15.067,9.784,% | Adaptive Acc: 11.682% | clf_exit: 0.059 0.018 0.923
Batch: 40 | Loss: 11.464 | Acc: 12.309,15.206,10.194,% | Adaptive Acc: 12.271% | clf_exit: 0.058 0.015 0.927
Batch: 60 | Loss: 11.447 | Acc: 12.321,15.010,10.105,% | Adaptive Acc: 12.295% | clf_exit: 0.056 0.014 0.930
Batch: 0 | Loss: 7.815 | Acc: 26.562,50.781,50.781,% | Adaptive Acc: 50.781% | clf_exit: 0.125 0.172 0.703
Batch: 20 | Loss: 8.253 | Acc: 24.182,46.801,42.560,% | Adaptive Acc: 43.676% | clf_exit: 0.110 0.120 0.769
Batch: 40 | Loss: 8.256 | Acc: 24.695,46.284,41.921,% | Adaptive Acc: 43.464% | clf_exit: 0.108 0.121 0.771
Batch: 60 | Loss: 8.265 | Acc: 24.834,46.337,41.393,% | Adaptive Acc: 43.161% | clf_exit: 0.104 0.122 0.774
Batch: 0 | Loss: 5.521 | Acc: 42.188,65.625,66.406,% | Adaptive Acc: 65.625% | clf_exit: 0.281 0.211 0.508
Batch: 20 | Loss: 5.930 | Acc: 38.690,62.277,64.397,% | Adaptive Acc: 62.612% | clf_exit: 0.211 0.288 0.501
Batch: 40 | Loss: 5.942 | Acc: 38.967,61.128,63.910,% | Adaptive Acc: 62.691% | clf_exit: 0.216 0.282 0.502
Batch: 60 | Loss: 5.963 | Acc: 39.075,61.142,63.806,% | Adaptive Acc: 62.871% | clf_exit: 0.215 0.281 0.504
Batch: 0 | Loss: 4.340 | Acc: 53.906,69.531,71.094,% | Adaptive Acc: 70.312% | clf_exit: 0.406 0.297 0.297
Batch: 20 | Loss: 4.617 | Acc: 47.805,66.927,72.507,% | Adaptive Acc: 68.341% | clf_exit: 0.355 0.347 0.297
Batch: 40 | Loss: 4.636 | Acc: 48.609,66.235,71.913,% | Adaptive Acc: 67.664% | clf_exit: 0.360 0.345 0.295
Batch: 60 | Loss: 4.654 | Acc: 48.425,66.201,71.888,% | Adaptive Acc: 67.623% | clf_exit: 0.357 0.349 0.294
Batch: 0 | Loss: 4.008 | Acc: 57.031,69.531,72.656,% | Adaptive Acc: 70.312% | clf_exit: 0.531 0.352 0.117
Batch: 20 | Loss: 4.139 | Acc: 52.865,68.638,74.442,% | Adaptive Acc: 68.080% | clf_exit: 0.477 0.349 0.174
Batch: 40 | Loss: 4.167 | Acc: 53.030,67.683,73.685,% | Adaptive Acc: 68.007% | clf_exit: 0.479 0.347 0.174
Batch: 60 | Loss: 4.178 | Acc: 52.843,67.777,73.553,% | Adaptive Acc: 67.802% | clf_exit: 0.479 0.347 0.174
Batch: 0 | Loss: 4.289 | Acc: 58.594,68.750,72.656,% | Adaptive Acc: 69.531% | clf_exit: 0.594 0.320 0.086
Batch: 20 | Loss: 4.285 | Acc: 54.241,69.122,75.112,% | Adaptive Acc: 66.443% | clf_exit: 0.576 0.319 0.106
Batch: 40 | Loss: 4.328 | Acc: 53.963,68.140,74.047,% | Adaptive Acc: 65.758% | clf_exit: 0.575 0.321 0.104
Batch: 60 | Loss: 4.335 | Acc: 53.650,68.084,73.886,% | Adaptive Acc: 65.689% | clf_exit: 0.571 0.324 0.105







Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 11.943 |  Acc: 5.572,9.462,15.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 11.346 |  Acc: 6.690,10.890,20.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 10.220 |  Acc: 10.798,17.678,27.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 9.919 |  Acc: 11.060,17.440,28.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 9.119 |  Acc: 15.416,24.150,35.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 8.924 |  Acc: 16.170,23.350,35.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 8.353 |  Acc: 19.114,28.452,41.552,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 8.483 |  Acc: 18.480,25.860,41.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 7.764 |  Acc: 22.004,32.296,46.136,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 7.990 |  Acc: 19.030,30.620,46.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 7.311 |  Acc: 24.470,35.634,50.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 7.307 |  Acc: 22.960,35.760,51.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 6.920 |  Acc: 26.414,39.226,53.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 7.223 |  Acc: 23.440,36.800,53.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 6.607 |  Acc: 27.890,41.922,56.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 6.994 |  Acc: 23.340,39.560,54.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 6.330 |  Acc: 29.358,44.102,58.764,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 6.630 |  Acc: 25.260,43.210,57.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 6.033 |  Acc: 30.630,46.886,61.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 6.521 |  Acc: 26.620,43.950,58.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 5.830 |  Acc: 32.034,48.600,63.158,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 6.362 |  Acc: 27.330,45.400,61.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 5.605 |  Acc: 33.320,50.310,65.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 6.190 |  Acc: 28.800,46.400,61.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 5.432 |  Acc: 34.242,52.032,66.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 6.055 |  Acc: 30.210,48.200,61.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 5.270 |  Acc: 35.250,53.458,68.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 5.991 |  Acc: 28.680,48.940,62.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 5.113 |  Acc: 36.112,54.972,69.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 5.767 |  Acc: 30.950,51.950,63.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 4.984 |  Acc: 36.750,55.934,71.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 5.856 |  Acc: 30.180,50.630,64.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 4.841 |  Acc: 37.592,57.290,72.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 5.701 |  Acc: 32.880,51.880,63.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 4.736 |  Acc: 38.404,58.022,73.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 5.742 |  Acc: 31.930,51.780,64.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.642 |  Acc: 38.538,58.956,74.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 5.764 |  Acc: 32.200,51.420,64.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.553 |  Acc: 38.894,59.858,75.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 5.553 |  Acc: 35.850,52.790,64.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.459 |  Acc: 39.894,60.876,76.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 5.399 |  Acc: 35.250,55.080,66.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.357 |  Acc: 40.404,61.570,78.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 5.470 |  Acc: 35.810,53.900,65.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 4.296 |  Acc: 40.492,62.040,78.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 5.771 |  Acc: 33.230,53.300,64.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 4.242 |  Acc: 40.986,62.708,79.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 5.538 |  Acc: 35.380,53.990,64.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 4.145 |  Acc: 41.570,63.744,80.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 5.301 |  Acc: 37.550,55.540,66.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 4.120 |  Acc: 41.546,63.610,80.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 5.586 |  Acc: 32.900,55.200,65.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 4.034 |  Acc: 42.112,64.764,81.612,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 5.351 |  Acc: 38.360,54.830,65.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 3.999 |  Acc: 42.558,64.926,81.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 5.489 |  Acc: 35.270,56.580,66.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 3.932 |  Acc: 43.054,65.444,82.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 5.458 |  Acc: 35.070,56.140,67.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 3.910 |  Acc: 42.800,65.628,82.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 5.379 |  Acc: 36.050,57.140,66.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 3.849 |  Acc: 43.578,66.096,83.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 5.325 |  Acc: 36.790,57.890,66.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 3.834 |  Acc: 43.578,66.182,83.608,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 5.354 |  Acc: 38.610,56.450,65.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 3.771 |  Acc: 43.944,66.964,84.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 5.243 |  Acc: 38.550,57.730,67.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 3.738 |  Acc: 44.302,67.164,84.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 5.807 |  Acc: 29.970,57.250,66.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 3.726 |  Acc: 44.004,67.300,84.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 5.342 |  Acc: 37.860,57.270,65.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 3.676 |  Acc: 44.720,67.736,85.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 5.745 |  Acc: 33.220,56.680,66.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.674 |  Acc: 44.532,67.890,85.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 5.293 |  Acc: 36.610,57.890,66.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.626 |  Acc: 44.938,68.244,85.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 5.235 |  Acc: 39.550,57.280,66.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.600 |  Acc: 45.444,68.414,85.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 5.539 |  Acc: 34.720,57.620,66.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.568 |  Acc: 45.276,68.968,86.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 5.382 |  Acc: 36.720,57.900,66.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.575 |  Acc: 45.760,68.622,86.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 5.219 |  Acc: 38.700,58.280,67.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.510 |  Acc: 45.984,69.524,86.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 5.330 |  Acc: 38.510,57.630,66.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.506 |  Acc: 45.688,69.780,86.774,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 5.490 |  Acc: 34.760,58.450,67.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.478 |  Acc: 45.960,69.634,87.254,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 5.341 |  Acc: 37.620,56.690,67.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.466 |  Acc: 45.992,69.884,87.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 5.433 |  Acc: 37.140,57.220,66.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.454 |  Acc: 46.354,69.898,87.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 5.469 |  Acc: 36.570,57.960,66.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.437 |  Acc: 46.378,70.068,87.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 5.406 |  Acc: 39.600,55.910,66.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.416 |  Acc: 46.530,70.302,87.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 5.321 |  Acc: 37.660,58.040,66.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.403 |  Acc: 46.982,70.744,87.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 5.047 |  Acc: 40.820,59.850,67.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.378 |  Acc: 47.100,70.926,87.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 5.172 |  Acc: 41.080,58.240,67.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.379 |  Acc: 46.788,70.826,87.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 5.525 |  Acc: 35.880,58.270,66.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.359 |  Acc: 46.958,71.272,87.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 5.244 |  Acc: 39.510,59.550,67.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.339 |  Acc: 47.320,71.436,87.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 5.642 |  Acc: 35.220,57.610,65.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.324 |  Acc: 47.268,71.348,88.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 5.188 |  Acc: 40.150,58.830,66.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.324 |  Acc: 47.358,71.438,88.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 5.396 |  Acc: 37.590,58.410,66.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.311 |  Acc: 47.550,71.528,88.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 5.186 |  Acc: 40.700,60.010,67.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.303 |  Acc: 47.836,71.420,88.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 5.217 |  Acc: 38.180,59.490,67.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.270 |  Acc: 47.878,72.012,88.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 5.332 |  Acc: 39.750,58.020,66.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.249 |  Acc: 47.864,72.354,88.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 5.126 |  Acc: 41.870,58.660,66.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.246 |  Acc: 48.240,72.352,88.736,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 5.234 |  Acc: 41.560,58.110,67.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.249 |  Acc: 48.094,72.284,88.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 5.494 |  Acc: 37.470,56.940,64.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.224 |  Acc: 48.264,72.622,88.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 5.153 |  Acc: 40.170,60.500,67.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.221 |  Acc: 48.290,72.586,88.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 5.132 |  Acc: 41.190,59.510,67.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.218 |  Acc: 48.368,72.578,88.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 5.251 |  Acc: 40.360,59.030,66.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 3.217 |  Acc: 48.416,72.592,88.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 5.252 |  Acc: 40.890,58.070,66.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 3.208 |  Acc: 48.256,72.586,89.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 5.179 |  Acc: 40.570,59.720,67.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 3.189 |  Acc: 48.510,72.996,88.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 5.099 |  Acc: 40.640,60.420,68.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 3.162 |  Acc: 48.608,73.112,89.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 5.460 |  Acc: 38.520,57.400,65.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 3.163 |  Acc: 48.524,73.162,89.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 5.239 |  Acc: 39.940,59.910,66.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 3.156 |  Acc: 48.804,73.244,89.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 5.212 |  Acc: 41.480,59.480,66.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 3.149 |  Acc: 48.738,73.482,89.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 5.363 |  Acc: 38.840,60.830,67.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 3.164 |  Acc: 48.950,73.396,89.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 5.517 |  Acc: 37.900,57.830,65.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 3.142 |  Acc: 48.946,73.666,89.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 5.158 |  Acc: 42.170,59.640,67.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 3.117 |  Acc: 48.998,73.674,89.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 5.320 |  Acc: 40.610,58.160,66.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 3.128 |  Acc: 48.892,73.808,89.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 5.076 |  Acc: 41.190,59.690,67.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 3.112 |  Acc: 49.190,73.786,89.626,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 5.251 |  Acc: 40.320,60.050,66.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 3.103 |  Acc: 49.312,74.018,89.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 5.233 |  Acc: 38.570,60.230,67.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 3.102 |  Acc: 49.212,74.098,89.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 5.157 |  Acc: 40.730,60.360,67.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 3.080 |  Acc: 49.430,74.050,89.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 5.153 |  Acc: 41.250,60.460,66.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 3.109 |  Acc: 49.314,73.526,89.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 5.343 |  Acc: 39.970,59.060,65.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 3.093 |  Acc: 49.180,74.258,89.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 5.427 |  Acc: 39.770,58.570,66.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 3.083 |  Acc: 49.340,74.336,89.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 5.170 |  Acc: 41.140,60.050,67.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 3.064 |  Acc: 49.448,74.246,89.968,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 5.039 |  Acc: 42.170,59.640,67.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 3.048 |  Acc: 49.706,74.560,90.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 5.433 |  Acc: 39.610,57.760,66.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 3.052 |  Acc: 49.602,74.396,89.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 5.713 |  Acc: 36.510,58.500,65.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 3.048 |  Acc: 49.896,74.396,90.008,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 5.333 |  Acc: 39.240,60.280,66.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 3.040 |  Acc: 49.674,74.864,90.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 5.114 |  Acc: 43.210,59.750,67.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 3.064 |  Acc: 49.740,74.424,89.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 5.399 |  Acc: 39.020,58.290,66.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 3.054 |  Acc: 50.000,74.694,89.986,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 5.240 |  Acc: 41.220,59.800,66.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 3.042 |  Acc: 49.908,74.640,90.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 5.443 |  Acc: 39.130,57.690,65.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 3.013 |  Acc: 49.914,75.056,90.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 5.330 |  Acc: 38.550,60.160,67.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 3.042 |  Acc: 49.808,74.996,89.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 5.098 |  Acc: 42.820,60.890,67.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 3.007 |  Acc: 50.416,75.168,90.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 5.253 |  Acc: 41.560,59.110,67.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 3.021 |  Acc: 50.192,75.006,90.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 5.303 |  Acc: 39.640,59.110,67.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 3.022 |  Acc: 50.088,74.652,90.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 5.075 |  Acc: 42.680,60.620,67.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 3.024 |  Acc: 50.056,74.962,89.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 5.219 |  Acc: 40.950,60.170,66.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 2.979 |  Acc: 50.636,75.320,90.512,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 5.235 |  Acc: 40.870,59.560,66.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 2.989 |  Acc: 50.474,75.272,90.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 5.038 |  Acc: 43.030,60.820,67.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 2.965 |  Acc: 50.648,75.800,90.440,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 5.177 |  Acc: 41.870,59.520,66.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 2.983 |  Acc: 50.568,75.368,90.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 5.643 |  Acc: 37.660,57.930,66.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 2.986 |  Acc: 50.516,75.322,90.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 5.148 |  Acc: 40.750,61.110,66.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 2.988 |  Acc: 50.558,75.346,90.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 5.208 |  Acc: 40.240,60.460,67.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 2.977 |  Acc: 50.604,75.456,90.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 5.198 |  Acc: 42.760,60.200,66.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 2.981 |  Acc: 50.616,75.306,90.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 5.067 |  Acc: 42.730,60.500,67.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 2.945 |  Acc: 50.866,75.840,90.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 5.073 |  Acc: 41.300,61.390,68.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 2.962 |  Acc: 50.730,75.662,90.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 5.428 |  Acc: 38.100,60.320,65.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 2.952 |  Acc: 50.834,75.824,90.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 5.221 |  Acc: 41.600,60.100,68.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 2.955 |  Acc: 50.972,75.644,90.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 5.377 |  Acc: 39.190,59.370,66.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 2.964 |  Acc: 50.554,75.656,90.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 5.201 |  Acc: 40.200,60.930,66.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 2.958 |  Acc: 50.712,75.586,90.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 5.222 |  Acc: 41.940,58.800,67.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 2.947 |  Acc: 50.716,75.764,90.524,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 4.968 |  Acc: 44.550,61.560,67.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 2.939 |  Acc: 50.960,75.778,90.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 5.413 |  Acc: 40.480,59.410,66.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 2.939 |  Acc: 50.534,75.884,90.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 5.171 |  Acc: 42.150,60.720,67.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 2.946 |  Acc: 50.964,75.826,90.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 5.375 |  Acc: 40.920,58.560,66.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 2.921 |  Acc: 51.126,76.240,90.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 5.189 |  Acc: 42.860,59.100,66.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 2.925 |  Acc: 50.900,75.982,90.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 5.002 |  Acc: 45.210,61.420,67.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 2.923 |  Acc: 51.302,76.008,90.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 5.187 |  Acc: 41.870,61.730,66.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 2.917 |  Acc: 51.206,75.958,90.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 5.234 |  Acc: 40.800,59.870,67.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 2.905 |  Acc: 51.110,76.380,90.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 5.597 |  Acc: 37.650,59.550,65.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 2.923 |  Acc: 51.004,76.038,90.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 5.115 |  Acc: 43.880,59.830,66.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 2.913 |  Acc: 51.268,76.098,90.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 5.284 |  Acc: 40.960,59.150,66.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 2.913 |  Acc: 51.322,76.342,90.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 5.101 |  Acc: 43.830,61.420,67.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 2.887 |  Acc: 51.540,76.468,91.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 5.222 |  Acc: 42.200,58.880,67.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 2.890 |  Acc: 51.328,76.420,90.940,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 5.379 |  Acc: 39.520,59.490,66.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 2.915 |  Acc: 51.252,76.044,90.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 5.019 |  Acc: 43.520,59.540,67.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 2.901 |  Acc: 51.446,75.952,90.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 5.046 |  Acc: 44.750,60.400,67.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 2.892 |  Acc: 51.406,76.300,90.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 5.476 |  Acc: 40.400,58.630,66.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 2.906 |  Acc: 51.282,76.372,90.614,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 5.159 |  Acc: 41.360,60.500,67.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 2.890 |  Acc: 51.604,76.382,90.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 5.565 |  Acc: 40.020,57.040,65.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 2.905 |  Acc: 51.274,76.226,90.502,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 4.979 |  Acc: 45.450,60.290,67.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 2.860 |  Acc: 51.436,76.950,91.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 5.058 |  Acc: 44.210,61.150,67.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 2.902 |  Acc: 51.532,76.400,90.348,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 5.236 |  Acc: 41.790,60.670,65.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 2.898 |  Acc: 51.328,76.508,90.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 5.329 |  Acc: 39.080,60.350,67.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 2.863 |  Acc: 51.766,76.894,90.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 5.120 |  Acc: 41.760,60.750,67.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 2.872 |  Acc: 51.468,76.694,90.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 5.354 |  Acc: 38.920,61.360,67.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 2.885 |  Acc: 51.566,76.296,90.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 5.098 |  Acc: 44.590,59.390,66.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 2.882 |  Acc: 51.772,76.432,90.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 5.159 |  Acc: 41.450,60.440,67.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 2.872 |  Acc: 51.772,76.698,90.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 5.157 |  Acc: 43.020,59.620,66.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 2.862 |  Acc: 51.836,76.980,90.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 5.250 |  Acc: 41.620,59.820,66.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 2.841 |  Acc: 51.572,76.940,91.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 5.312 |  Acc: 42.110,58.880,66.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 2.877 |  Acc: 51.616,76.680,90.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 5.085 |  Acc: 43.560,60.600,66.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 2.864 |  Acc: 51.564,76.886,90.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 4.771 |  Acc: 45.070,62.800,68.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 2.848 |  Acc: 51.880,76.752,91.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 5.591 |  Acc: 38.850,58.080,65.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 2.871 |  Acc: 51.988,76.692,90.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 5.419 |  Acc: 38.060,60.300,65.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 2.860 |  Acc: 52.128,76.672,90.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 5.110 |  Acc: 43.600,59.800,66.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 2.831 |  Acc: 52.044,77.350,91.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 5.381 |  Acc: 39.130,59.700,66.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 2.830 |  Acc: 52.006,77.196,91.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 5.186 |  Acc: 43.290,60.160,67.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 2.847 |  Acc: 52.000,76.648,90.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 5.077 |  Acc: 42.860,61.860,67.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 2.832 |  Acc: 51.892,77.290,91.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 5.241 |  Acc: 42.280,60.230,66.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 2.835 |  Acc: 52.184,76.994,90.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 5.370 |  Acc: 40.780,60.760,67.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.217 |  Acc: 57.370,85.708,96.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.019 |  Acc: 51.750,69.420,73.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 2.016 |  Acc: 58.610,88.540,98.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 3.993 |  Acc: 52.080,69.230,74.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.948 |  Acc: 58.882,89.372,98.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.002 |  Acc: 52.190,69.320,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.902 |  Acc: 59.410,89.962,98.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 3.986 |  Acc: 52.390,69.470,74.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.873 |  Acc: 59.574,90.480,99.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 3.994 |  Acc: 51.930,69.310,74.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.844 |  Acc: 59.784,90.774,98.944,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.012 |  Acc: 51.820,69.560,74.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.821 |  Acc: 59.794,91.058,99.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.020 |  Acc: 52.170,69.400,74.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.806 |  Acc: 60.048,91.336,99.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.007 |  Acc: 52.350,69.490,74.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.786 |  Acc: 60.288,91.656,99.232,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.021 |  Acc: 52.790,69.740,74.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.768 |  Acc: 60.368,91.960,99.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.047 |  Acc: 52.660,69.460,74.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 1.755 |  Acc: 60.366,92.244,99.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.064 |  Acc: 52.660,69.420,75.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.742 |  Acc: 60.622,92.244,99.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.079 |  Acc: 52.500,69.370,74.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.726 |  Acc: 60.708,92.572,99.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.044 |  Acc: 52.600,69.260,74.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.719 |  Acc: 60.552,92.650,99.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.052 |  Acc: 52.840,69.600,75.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.702 |  Acc: 60.720,92.882,99.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.080 |  Acc: 52.670,69.310,74.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.696 |  Acc: 60.844,93.088,99.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.080 |  Acc: 52.970,69.390,74.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.688 |  Acc: 60.840,93.122,99.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.077 |  Acc: 53.200,69.170,74.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.677 |  Acc: 60.950,93.324,99.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.091 |  Acc: 52.250,69.220,74.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.675 |  Acc: 60.784,93.384,99.526,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.116 |  Acc: 52.510,69.010,74.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.655 |  Acc: 61.378,93.770,99.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.127 |  Acc: 52.140,69.040,74.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.649 |  Acc: 61.310,93.712,99.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.110 |  Acc: 52.750,68.890,74.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.648 |  Acc: 61.146,93.846,99.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.137 |  Acc: 52.650,69.160,74.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.634 |  Acc: 61.588,93.922,99.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.120 |  Acc: 52.680,69.210,75.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.630 |  Acc: 61.558,94.090,99.544,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.139 |  Acc: 52.420,69.120,74.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.626 |  Acc: 61.704,94.188,99.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.176 |  Acc: 52.370,69.110,74.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.619 |  Acc: 61.442,94.244,99.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.147 |  Acc: 52.830,69.130,75.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.604 |  Acc: 61.698,94.360,99.536,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.129 |  Acc: 52.870,69.530,74.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.610 |  Acc: 61.418,94.390,99.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.145 |  Acc: 53.240,69.180,74.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.595 |  Acc: 61.894,94.566,99.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.158 |  Acc: 52.740,68.700,74.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.596 |  Acc: 61.690,94.560,99.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.164 |  Acc: 52.080,68.770,74.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.591 |  Acc: 61.880,94.612,99.588,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.193 |  Acc: 52.620,69.080,74.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.590 |  Acc: 61.836,94.708,99.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.176 |  Acc: 53.040,69.180,74.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.583 |  Acc: 61.924,94.696,99.614,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.222 |  Acc: 52.210,68.570,74.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.576 |  Acc: 62.106,94.984,99.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.192 |  Acc: 52.630,69.130,74.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.568 |  Acc: 62.434,94.966,99.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.221 |  Acc: 52.260,68.500,74.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.574 |  Acc: 61.832,94.880,99.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.218 |  Acc: 52.060,68.850,74.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.561 |  Acc: 61.976,95.196,99.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.205 |  Acc: 52.700,69.160,74.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.553 |  Acc: 62.332,95.272,99.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.212 |  Acc: 52.680,68.940,74.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.551 |  Acc: 62.370,95.268,99.614,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.198 |  Acc: 52.870,69.130,74.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.548 |  Acc: 62.206,95.206,99.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.229 |  Acc: 52.540,68.630,74.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.536 |  Acc: 62.546,95.420,99.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.234 |  Acc: 52.700,68.600,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.544 |  Acc: 62.438,95.234,99.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.223 |  Acc: 52.750,68.460,74.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.535 |  Acc: 62.344,95.426,99.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.280 |  Acc: 52.540,68.610,74.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.542 |  Acc: 62.324,95.362,99.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.232 |  Acc: 52.120,68.430,74.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.531 |  Acc: 62.570,95.386,99.626,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.227 |  Acc: 52.820,68.400,74.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.522 |  Acc: 62.860,95.562,99.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.319 |  Acc: 51.330,68.490,74.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.524 |  Acc: 62.742,95.590,99.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.262 |  Acc: 52.320,68.520,74.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.529 |  Acc: 62.450,95.430,99.642,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.254 |  Acc: 52.520,68.300,74.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.522 |  Acc: 62.618,95.510,99.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.281 |  Acc: 52.510,68.490,74.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.516 |  Acc: 62.746,95.574,99.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.309 |  Acc: 52.100,68.110,74.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.511 |  Acc: 62.898,95.750,99.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.298 |  Acc: 51.830,68.430,74.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.512 |  Acc: 62.758,95.806,99.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.242 |  Acc: 52.720,68.130,74.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.505 |  Acc: 62.938,95.758,99.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.295 |  Acc: 52.140,68.100,74.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.510 |  Acc: 62.778,95.778,99.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.329 |  Acc: 51.900,67.750,74.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.511 |  Acc: 62.682,95.684,99.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.305 |  Acc: 51.780,68.580,74.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.508 |  Acc: 62.876,95.774,99.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.317 |  Acc: 52.340,67.920,74.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.500 |  Acc: 62.968,95.842,99.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.338 |  Acc: 51.920,67.380,74.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.499 |  Acc: 62.764,95.846,99.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.309 |  Acc: 52.530,67.960,74.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.498 |  Acc: 62.890,95.878,99.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.366 |  Acc: 51.390,68.190,74.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.499 |  Acc: 63.144,95.800,99.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.354 |  Acc: 52.290,67.810,74.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.481 |  Acc: 63.182,95.982,99.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.386 |  Acc: 51.730,67.900,74.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.488 |  Acc: 63.004,96.138,99.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.354 |  Acc: 52.090,68.170,74.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.491 |  Acc: 62.976,95.922,99.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.313 |  Acc: 52.380,68.240,74.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.486 |  Acc: 63.192,95.918,99.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.334 |  Acc: 52.320,67.860,74.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.482 |  Acc: 63.228,96.130,99.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.329 |  Acc: 52.170,68.080,74.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.482 |  Acc: 63.280,96.120,99.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.354 |  Acc: 52.370,67.890,74.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.490 |  Acc: 63.134,95.886,99.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.355 |  Acc: 52.830,67.940,74.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.483 |  Acc: 63.154,95.998,99.666,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.391 |  Acc: 51.780,67.650,73.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.479 |  Acc: 63.292,96.022,99.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.394 |  Acc: 51.890,67.590,74.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.473 |  Acc: 63.418,96.130,99.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.405 |  Acc: 51.840,67.460,74.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.478 |  Acc: 63.436,96.072,99.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.420 |  Acc: 50.990,67.410,74.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.475 |  Acc: 63.248,96.124,99.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.373 |  Acc: 51.410,67.550,74.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.469 |  Acc: 63.464,96.232,99.654,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.465 |  Acc: 51.490,67.230,74.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.474 |  Acc: 63.630,95.978,99.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.401 |  Acc: 51.320,67.670,74.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.475 |  Acc: 63.176,96.062,99.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.398 |  Acc: 52.610,67.530,74.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.376 |  Acc: 65.078,97.410,99.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.254 |  Acc: 53.950,68.680,74.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.347 |  Acc: 65.668,97.836,99.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.237 |  Acc: 53.900,68.580,74.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.340 |  Acc: 65.588,97.936,99.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.250 |  Acc: 53.780,68.680,74.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.330 |  Acc: 65.704,98.104,99.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.243 |  Acc: 53.950,68.590,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.328 |  Acc: 65.896,98.024,99.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.257 |  Acc: 53.710,68.870,74.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.328 |  Acc: 65.702,98.214,99.774,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.244 |  Acc: 53.750,68.790,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.329 |  Acc: 65.992,98.040,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.240 |  Acc: 53.730,68.600,74.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.324 |  Acc: 65.692,98.224,99.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.262 |  Acc: 53.810,68.480,74.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.323 |  Acc: 66.074,98.208,99.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.240 |  Acc: 53.700,68.880,74.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.318 |  Acc: 66.322,98.284,99.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.248 |  Acc: 54.120,68.760,74.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.319 |  Acc: 66.044,98.240,99.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.263 |  Acc: 54.000,68.680,74.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.320 |  Acc: 66.168,98.182,99.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.256 |  Acc: 53.830,68.820,74.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.313 |  Acc: 66.060,98.308,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.260 |  Acc: 53.710,68.700,74.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.312 |  Acc: 66.196,98.292,99.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.253 |  Acc: 53.950,68.610,74.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.315 |  Acc: 66.224,98.176,99.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.267 |  Acc: 53.620,68.660,74.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.307 |  Acc: 66.346,98.250,99.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.262 |  Acc: 53.860,68.580,74.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.307 |  Acc: 66.210,98.382,99.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.264 |  Acc: 53.530,68.830,74.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.306 |  Acc: 66.084,98.372,99.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.260 |  Acc: 54.030,68.610,74.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.311 |  Acc: 66.050,98.346,99.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.284 |  Acc: 53.740,68.350,74.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.305 |  Acc: 66.248,98.340,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.280 |  Acc: 53.480,68.610,74.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.305 |  Acc: 66.348,98.394,99.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.251 |  Acc: 54.050,68.690,74.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.302 |  Acc: 66.416,98.364,99.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.257 |  Acc: 53.590,68.680,74.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.305 |  Acc: 66.228,98.428,99.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.261 |  Acc: 53.920,68.780,74.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.306 |  Acc: 66.336,98.324,99.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.273 |  Acc: 54.020,68.670,74.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.302 |  Acc: 66.196,98.390,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.276 |  Acc: 53.840,68.530,74.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.300 |  Acc: 66.348,98.366,99.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.266 |  Acc: 53.580,68.460,74.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.303 |  Acc: 65.992,98.432,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.269 |  Acc: 53.940,68.530,74.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.301 |  Acc: 66.428,98.482,99.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.267 |  Acc: 53.940,68.420,74.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.298 |  Acc: 66.358,98.456,99.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.274 |  Acc: 53.800,68.540,74.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.301 |  Acc: 66.196,98.398,99.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.257 |  Acc: 53.980,68.520,74.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.297 |  Acc: 66.366,98.464,99.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.267 |  Acc: 53.950,68.380,74.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.291 |  Acc: 66.520,98.394,99.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.273 |  Acc: 53.870,68.320,74.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.295 |  Acc: 66.408,98.404,99.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.276 |  Acc: 53.920,68.330,74.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.300 |  Acc: 66.496,98.336,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.289 |  Acc: 53.650,68.470,74.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.297 |  Acc: 66.382,98.380,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.302 |  Acc: 53.420,68.290,74.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.292 |  Acc: 66.520,98.478,99.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.280 |  Acc: 53.820,68.550,74.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.294 |  Acc: 66.360,98.406,99.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.286 |  Acc: 53.480,68.540,74.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.282 |  Acc: 66.718,98.568,99.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.283 |  Acc: 53.930,68.300,74.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.281 |  Acc: 66.670,98.552,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.277 |  Acc: 53.780,68.540,74.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.278 |  Acc: 66.866,98.578,99.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.280 |  Acc: 53.980,68.470,74.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.279 |  Acc: 66.728,98.550,99.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.271 |  Acc: 53.870,68.400,74.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.281 |  Acc: 66.912,98.558,99.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.275 |  Acc: 53.810,68.230,74.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.283 |  Acc: 66.478,98.698,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.279 |  Acc: 54.080,68.310,74.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.281 |  Acc: 66.736,98.552,99.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.281 |  Acc: 53.720,68.550,74.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.277 |  Acc: 66.700,98.670,99.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.284 |  Acc: 53.930,68.410,74.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.280 |  Acc: 66.734,98.588,99.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.284 |  Acc: 53.920,68.590,74.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.284 |  Acc: 66.716,98.564,99.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.291 |  Acc: 53.840,68.390,74.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.279 |  Acc: 66.936,98.532,99.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.285 |  Acc: 53.970,68.480,74.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.279 |  Acc: 66.740,98.550,99.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.298 |  Acc: 53.680,68.270,74.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.279 |  Acc: 66.712,98.576,99.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.278 |  Acc: 53.970,68.340,74.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.280 |  Acc: 66.634,98.584,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.275 |  Acc: 53.860,68.410,74.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.275 |  Acc: 66.818,98.604,99.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.270 |  Acc: 53.830,68.570,74.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.276 |  Acc: 66.862,98.594,99.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.278 |  Acc: 53.970,68.460,74.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.276 |  Acc: 66.722,98.642,99.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.282 |  Acc: 53.920,68.540,74.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.278 |  Acc: 66.880,98.650,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.285 |  Acc: 53.860,68.480,74.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.283 |  Acc: 66.538,98.554,99.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.283 |  Acc: 53.960,68.590,74.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.275 |  Acc: 66.890,98.642,99.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.273 |  Acc: 53.880,68.610,74.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.281 |  Acc: 66.766,98.564,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.276 |  Acc: 53.910,68.440,74.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.275 |  Acc: 66.818,98.612,99.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.299 |  Acc: 53.780,68.350,74.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.276 |  Acc: 66.720,98.584,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.280 |  Acc: 53.660,68.370,74.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.278 |  Acc: 66.826,98.588,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.275 |  Acc: 53.930,68.440,74.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.278 |  Acc: 66.680,98.616,99.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.284 |  Acc: 53.970,68.260,74.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.278 |  Acc: 66.816,98.630,99.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.286 |  Acc: 54.160,68.490,74.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.279 |  Acc: 66.690,98.586,99.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.283 |  Acc: 53.950,68.600,74.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.278 |  Acc: 66.854,98.472,99.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.285 |  Acc: 53.990,68.560,74.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.280 |  Acc: 66.674,98.618,99.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.286 |  Acc: 53.940,68.470,74.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.279 |  Acc: 66.740,98.538,99.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.287 |  Acc: 54.040,68.350,74.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.273 |  Acc: 66.944,98.720,99.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.281 |  Acc: 53.830,68.500,74.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.275 |  Acc: 66.726,98.574,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.275 |  Acc: 53.950,68.440,74.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.283 |  Acc: 66.688,98.544,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.285 |  Acc: 53.920,68.400,74.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.275 |  Acc: 66.792,98.638,99.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.265 |  Acc: 53.950,68.580,74.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.274 |  Acc: 66.812,98.664,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.282 |  Acc: 53.860,68.510,74.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.277 |  Acc: 66.920,98.656,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.281 |  Acc: 54.090,68.400,74.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.270 |  Acc: 66.988,98.696,99.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.279 |  Acc: 53.750,68.350,74.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_0con1_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.9, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='cross_entropy', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.279 |  Acc: 66.792,98.580,99.870,% | Adaptive Acc:91.768% | clf_exit: 0.578 0.410 0.012
Testing: Epoch=299 | Loss: 4.279 |  Acc: 53.860,68.480,74.450,% | Adaptive Acc:66.230% | clf_exit: 0.573 0.324 0.104

circles: 0
Testing: Epoch=299 | Loss: 11.421 |  Acc: 12.340,14.990,10.090,% | Adaptive Acc:12.210% | clf_exit: 0.054 0.014 0.931
circles: 1
Testing: Epoch=299 | Loss: 8.226 |  Acc: 25.220,46.840,41.980,% | Adaptive Acc:43.640% | clf_exit: 0.103 0.121 0.776
circles: 2
Testing: Epoch=299 | Loss: 5.919 |  Acc: 39.370,61.830,64.520,% | Adaptive Acc:63.550% | clf_exit: 0.214 0.282 0.504
circles: 3
Testing: Epoch=299 | Loss: 4.609 |  Acc: 48.690,66.730,72.460,% | Adaptive Acc:68.200% | clf_exit: 0.360 0.349 0.290
circles: 4
Testing: Epoch=299 | Loss: 4.129 |  Acc: 52.980,68.290,74.160,% | Adaptive Acc:68.340% | clf_exit: 0.480 0.349 0.171
circles: 5
Testing: Epoch=299 | Loss: 4.279 |  Acc: 53.860,68.480,74.450,% | Adaptive Acc:66.230% | clf_exit: 0.573 0.324 0.104
