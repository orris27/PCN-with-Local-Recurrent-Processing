==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=128, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=288, out_features=72, bias=True)
      (linear): Linear(in_features=72, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x72])
      (linear_bw): Linear(in_features=72, out_features=288, bias=True)
      (BN1d): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=584, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=584, out_features=100, bias=True)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 9.656 | Acc: 0.781,0.781,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.056 | Acc: 1.860,1.153,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.844 | Acc: 2.401,2.191,7.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.718 | Acc: 2.690,2.830,8.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.617 | Acc: 2.845,3.472,9.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.537 | Acc: 3.256,3.891,9.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.467 | Acc: 3.545,4.216,10.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.411 | Acc: 3.818,4.665,10.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.357 | Acc: 3.897,5.051,11.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.301 | Acc: 4.105,5.590,11.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.262 | Acc: 4.186,5.861,12.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.218 | Acc: 4.376,6.197,12.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.179 | Acc: 4.516,6.419,12.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.140 | Acc: 4.601,6.663,13.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.108 | Acc: 4.612,6.814,13.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.068 | Acc: 4.771,7.112,14.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.028 | Acc: 4.907,7.367,14.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.995 | Acc: 4.997,7.627,14.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.961 | Acc: 5.036,7.867,15.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.928 | Acc: 5.153,8.085,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.426 | Acc: 7.812,11.719,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.415 | Acc: 7.143,11.496,19.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.413 | Acc: 7.050,11.471,19.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.427 | Acc: 6.954,11.668,19.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 7.010 | Acc: 8.594,17.969,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.194 | Acc: 7.329,12.649,23.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.165 | Acc: 7.698,12.938,23.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.169 | Acc: 7.684,12.897,23.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.148 | Acc: 7.591,12.625,23.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.132 | Acc: 7.511,12.500,24.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.105 | Acc: 7.593,12.810,24.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.088 | Acc: 7.691,12.927,24.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.062 | Acc: 7.871,13.034,25.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.034 | Acc: 8.037,13.355,25.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.010 | Acc: 8.120,13.588,25.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.985 | Acc: 8.297,13.872,26.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.962 | Acc: 8.380,14.069,26.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.935 | Acc: 8.495,14.293,26.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.911 | Acc: 8.583,14.480,27.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.889 | Acc: 8.726,14.706,27.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.869 | Acc: 8.813,14.849,27.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.845 | Acc: 8.880,15.110,27.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.826 | Acc: 8.994,15.259,28.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.803 | Acc: 9.108,15.492,28.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.353 | Acc: 12.500,17.969,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.454 | Acc: 10.565,16.220,31.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.442 | Acc: 10.137,16.406,31.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.442 | Acc: 10.015,16.457,31.583,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 6.504 | Acc: 3.125,17.188,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.358 | Acc: 10.342,19.196,34.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.343 | Acc: 10.785,19.588,33.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.319 | Acc: 11.309,19.480,34.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.297 | Acc: 11.391,19.502,34.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.284 | Acc: 11.479,19.539,34.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.261 | Acc: 11.551,19.738,35.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.245 | Acc: 11.530,19.570,35.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.230 | Acc: 11.627,19.725,35.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.206 | Acc: 11.796,20.062,35.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.190 | Acc: 11.765,20.040,35.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.178 | Acc: 11.811,20.086,35.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.167 | Acc: 11.965,20.105,35.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.159 | Acc: 12.051,20.106,35.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.149 | Acc: 12.097,20.165,35.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.138 | Acc: 12.178,20.255,35.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.122 | Acc: 12.330,20.432,36.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.104 | Acc: 12.383,20.519,36.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.091 | Acc: 12.442,20.607,36.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.080 | Acc: 12.475,20.690,36.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.728 | Acc: 15.625,18.750,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.882 | Acc: 12.984,21.987,38.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.891 | Acc: 13.262,21.284,38.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.890 | Acc: 13.307,21.145,38.397,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 5.679 | Acc: 12.500,22.656,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.735 | Acc: 13.728,22.656,40.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.691 | Acc: 14.444,22.999,41.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.672 | Acc: 14.216,23.194,41.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.665 | Acc: 14.574,23.225,41.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.657 | Acc: 14.782,23.260,41.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.655 | Acc: 14.747,23.186,41.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.638 | Acc: 15.082,23.498,41.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.622 | Acc: 15.251,23.612,41.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.614 | Acc: 15.336,23.796,41.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.609 | Acc: 15.512,23.970,41.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.603 | Acc: 15.618,24.067,41.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.592 | Acc: 15.713,24.131,41.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.586 | Acc: 15.736,24.165,41.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.573 | Acc: 15.853,24.388,42.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.562 | Acc: 15.913,24.522,42.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.553 | Acc: 15.995,24.540,42.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.544 | Acc: 16.124,24.535,42.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.537 | Acc: 16.209,24.543,42.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.535 | Acc: 16.244,24.551,42.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.207 | Acc: 21.875,25.781,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.540 | Acc: 16.518,24.330,43.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.549 | Acc: 16.082,23.819,43.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.539 | Acc: 16.060,23.873,43.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 4.934 | Acc: 18.750,25.781,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.171 | Acc: 17.969,25.856,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.181 | Acc: 17.988,26.734,47.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.217 | Acc: 17.687,26.422,47.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.213 | Acc: 17.573,26.466,46.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.223 | Acc: 17.567,26.431,46.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.212 | Acc: 17.885,26.866,46.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.206 | Acc: 17.880,26.801,46.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.198 | Acc: 18.003,26.990,46.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.199 | Acc: 17.895,26.947,46.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.190 | Acc: 18.027,27.052,46.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.181 | Acc: 18.146,27.100,47.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.176 | Acc: 18.267,27.285,47.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.169 | Acc: 18.334,27.317,47.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.164 | Acc: 18.389,27.355,47.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.156 | Acc: 18.439,27.365,47.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.146 | Acc: 18.553,27.495,47.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.141 | Acc: 18.661,27.557,47.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.136 | Acc: 18.709,27.668,47.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.129 | Acc: 18.762,27.713,47.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.020 | Acc: 22.656,23.438,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.084 | Acc: 18.973,27.716,49.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.093 | Acc: 19.188,27.630,48.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.088 | Acc: 19.173,27.497,48.770,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 4.618 | Acc: 20.312,34.375,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.863 | Acc: 20.089,29.799,49.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.847 | Acc: 20.389,29.497,51.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.812 | Acc: 20.927,30.379,51.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.848 | Acc: 20.467,29.745,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.849 | Acc: 20.552,29.517,51.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.845 | Acc: 20.655,29.623,51.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.834 | Acc: 20.828,29.682,51.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.836 | Acc: 20.905,29.731,51.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.842 | Acc: 20.822,29.644,51.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.835 | Acc: 20.833,29.785,51.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.836 | Acc: 20.822,29.765,51.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.837 | Acc: 20.880,29.726,51.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.832 | Acc: 21.082,29.795,51.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.828 | Acc: 21.058,29.827,51.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.826 | Acc: 21.107,29.856,51.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.822 | Acc: 21.198,29.855,51.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.816 | Acc: 21.279,29.969,51.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.813 | Acc: 21.250,30.014,51.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.812 | Acc: 21.266,30.020,51.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.821 | Acc: 26.562,32.812,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.862 | Acc: 22.656,29.315,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.884 | Acc: 21.475,28.887,51.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.889 | Acc: 20.940,28.637,51.486,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 4.415 | Acc: 27.344,28.125,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.653 | Acc: 22.098,31.548,55.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 22.294,32.184,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 22.490,32.147,55.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.591 | Acc: 22.647,32.234,55.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.575 | Acc: 22.734,32.526,55.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.581 | Acc: 22.734,32.380,54.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.572 | Acc: 22.739,32.497,55.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.584 | Acc: 22.637,32.463,54.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.580 | Acc: 22.777,32.385,54.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.577 | Acc: 22.847,32.424,54.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.573 | Acc: 22.882,32.410,54.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.571 | Acc: 22.954,32.475,54.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.565 | Acc: 23.036,32.549,54.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.564 | Acc: 23.165,32.593,54.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.563 | Acc: 23.134,32.644,54.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.560 | Acc: 23.253,32.679,54.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.560 | Acc: 23.311,32.698,54.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.556 | Acc: 23.420,32.752,54.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.552 | Acc: 23.409,32.806,54.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.734 | Acc: 25.781,28.125,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.665 | Acc: 21.057,29.948,54.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.685 | Acc: 21.056,29.040,54.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 21.043,29.060,54.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 4.029 | Acc: 25.000,37.500,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.304 | Acc: 24.144,35.007,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.277 | Acc: 24.657,34.889,58.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.282 | Acc: 24.834,35.297,58.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.294 | Acc: 25.068,35.147,58.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.301 | Acc: 25.070,35.326,58.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.306 | Acc: 25.071,35.195,58.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.316 | Acc: 24.823,35.306,57.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.324 | Acc: 24.850,35.088,57.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.322 | Acc: 24.931,35.122,58.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.329 | Acc: 24.969,35.160,57.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.328 | Acc: 24.951,35.107,57.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.320 | Acc: 25.068,35.211,57.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.325 | Acc: 25.009,35.195,57.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.320 | Acc: 25.028,35.267,57.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.315 | Acc: 25.106,35.265,57.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.318 | Acc: 25.088,35.268,57.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.322 | Acc: 25.105,35.232,57.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.324 | Acc: 25.089,35.148,57.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.325 | Acc: 25.125,35.154,57.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.453 | Acc: 27.344,36.719,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.542 | Acc: 23.996,32.664,55.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.565 | Acc: 23.323,32.698,55.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.549 | Acc: 23.092,32.838,55.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 4.383 | Acc: 24.219,36.719,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.239 | Acc: 25.595,35.751,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.188 | Acc: 26.181,36.261,60.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.164 | Acc: 26.562,36.693,60.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.146 | Acc: 26.370,36.960,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.117 | Acc: 26.648,37.469,60.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.121 | Acc: 26.569,37.171,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.118 | Acc: 26.690,37.256,60.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.104 | Acc: 26.810,37.384,61.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.109 | Acc: 26.636,37.401,61.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.112 | Acc: 26.594,37.177,61.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.123 | Acc: 26.559,37.122,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.127 | Acc: 26.501,37.124,60.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.127 | Acc: 26.625,37.174,60.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.122 | Acc: 26.685,37.166,60.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.124 | Acc: 26.697,37.178,60.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.122 | Acc: 26.874,37.252,60.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.121 | Acc: 26.851,37.266,60.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.120 | Acc: 26.865,37.251,60.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.119 | Acc: 26.829,37.258,60.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.217 | Acc: 33.594,46.875,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.318 | Acc: 25.930,38.839,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.340 | Acc: 25.591,37.691,57.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.342 | Acc: 25.231,37.116,56.724,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 4.187 | Acc: 25.781,38.281,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.908 | Acc: 27.158,38.542,63.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.904 | Acc: 27.782,39.062,63.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.908 | Acc: 27.792,39.498,64.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.893 | Acc: 27.797,39.487,64.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.913 | Acc: 27.568,39.078,64.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.910 | Acc: 27.576,39.114,63.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.910 | Acc: 27.754,39.035,64.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.915 | Acc: 27.766,38.980,64.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.912 | Acc: 27.840,39.011,64.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.922 | Acc: 27.845,38.946,63.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.929 | Acc: 27.909,39.108,63.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.934 | Acc: 27.827,38.920,63.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.934 | Acc: 27.945,39.021,63.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.941 | Acc: 27.805,38.935,63.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.937 | Acc: 27.811,39.005,63.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.937 | Acc: 27.835,38.980,63.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.941 | Acc: 27.880,38.996,63.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.945 | Acc: 27.898,38.969,62.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.943 | Acc: 27.959,39.028,62.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.152 | Acc: 28.906,36.719,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.227 | Acc: 26.525,37.984,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.229 | Acc: 26.143,37.252,58.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.246 | Acc: 25.666,36.757,58.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 4.164 | Acc: 26.562,36.719,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.722 | Acc: 29.948,41.964,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.771 | Acc: 29.478,41.635,65.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.774 | Acc: 29.047,41.445,65.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.796 | Acc: 28.704,40.664,65.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.800 | Acc: 28.752,40.927,65.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.813 | Acc: 28.319,40.599,65.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.811 | Acc: 28.408,40.658,65.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.808 | Acc: 28.305,40.460,65.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.813 | Acc: 28.306,40.474,65.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.805 | Acc: 28.428,40.598,65.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.809 | Acc: 28.479,40.632,65.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.807 | Acc: 28.624,40.764,65.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.801 | Acc: 28.673,40.873,65.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.802 | Acc: 28.731,40.903,65.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.804 | Acc: 28.745,40.944,64.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.802 | Acc: 28.797,40.885,64.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.802 | Acc: 28.826,40.902,64.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.803 | Acc: 28.900,40.950,64.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.801 | Acc: 28.949,41.015,64.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.000 | Acc: 26.562,40.625,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.060 | Acc: 28.125,38.504,61.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.072 | Acc: 27.934,39.367,60.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.083 | Acc: 27.331,38.947,60.681,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 3.609 | Acc: 36.719,47.656,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.617 | Acc: 30.246,43.676,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.551 | Acc: 31.593,43.712,68.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.582 | Acc: 30.853,42.802,68.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.594 | Acc: 30.835,42.515,68.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.596 | Acc: 30.670,42.466,68.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.604 | Acc: 30.501,42.530,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.621 | Acc: 30.402,42.348,67.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.637 | Acc: 30.216,42.357,67.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.634 | Acc: 30.266,42.485,67.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.638 | Acc: 30.224,42.417,67.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.640 | Acc: 30.179,42.442,67.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.647 | Acc: 30.229,42.463,67.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.648 | Acc: 30.301,42.583,67.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.646 | Acc: 30.341,42.641,66.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.649 | Acc: 30.297,42.624,66.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.649 | Acc: 30.298,42.640,66.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.654 | Acc: 30.267,42.705,66.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.658 | Acc: 30.231,42.690,66.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.659 | Acc: 30.303,42.661,66.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.881 | Acc: 32.031,46.875,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.965 | Acc: 28.795,40.327,62.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.978 | Acc: 27.877,40.434,62.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.978 | Acc: 27.395,40.126,62.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 3.641 | Acc: 30.469,32.031,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.519 | Acc: 31.548,42.560,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.473 | Acc: 31.402,43.921,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.493 | Acc: 31.250,43.955,69.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.494 | Acc: 31.443,44.010,69.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.489 | Acc: 31.536,44.121,69.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.485 | Acc: 31.431,44.118,69.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.481 | Acc: 31.688,44.470,69.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.496 | Acc: 31.531,44.221,69.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.505 | Acc: 31.608,44.091,69.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.519 | Acc: 31.456,44.049,68.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.518 | Acc: 31.487,44.100,68.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.529 | Acc: 31.454,43.889,68.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.534 | Acc: 31.376,43.873,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.537 | Acc: 31.306,43.786,68.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.537 | Acc: 31.237,43.812,68.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.538 | Acc: 31.291,43.886,68.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.540 | Acc: 31.264,43.926,68.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.537 | Acc: 31.313,44.111,68.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.536 | Acc: 31.332,44.162,68.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.781 | Acc: 28.125,46.094,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.960 | Acc: 28.460,40.699,63.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.952 | Acc: 28.163,40.892,63.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.956 | Acc: 27.433,40.100,63.204,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 3.136 | Acc: 39.844,51.562,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.405 | Acc: 32.143,44.643,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.348 | Acc: 32.431,46.303,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.374 | Acc: 32.018,45.697,70.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.367 | Acc: 32.272,45.650,70.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.376 | Acc: 32.186,45.591,70.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.385 | Acc: 32.296,45.467,70.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.398 | Acc: 32.347,45.434,70.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.400 | Acc: 32.162,45.487,70.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.394 | Acc: 32.359,45.688,70.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.405 | Acc: 32.268,45.600,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.412 | Acc: 32.215,45.450,70.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.419 | Acc: 32.171,45.523,70.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.423 | Acc: 32.049,45.414,70.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.429 | Acc: 32.073,45.502,69.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.429 | Acc: 32.132,45.460,69.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.426 | Acc: 32.241,45.463,69.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.428 | Acc: 32.244,45.452,69.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.426 | Acc: 32.248,45.509,69.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.426 | Acc: 32.281,45.524,69.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.937 | Acc: 25.781,42.969,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.960 | Acc: 29.055,40.216,62.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.938 | Acc: 27.820,40.796,62.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.932 | Acc: 27.613,40.843,62.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 3.444 | Acc: 27.344,39.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.289 | Acc: 32.664,45.945,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.258 | Acc: 33.022,46.475,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.252 | Acc: 33.210,46.952,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.225 | Acc: 33.439,47.473,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.222 | Acc: 33.470,47.726,73.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.234 | Acc: 33.297,47.450,73.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.255 | Acc: 33.073,47.086,73.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.255 | Acc: 33.128,47.176,73.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.266 | Acc: 33.084,47.022,72.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.269 | Acc: 33.127,47.132,72.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.271 | Acc: 33.063,47.119,72.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.272 | Acc: 33.046,47.066,72.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.289 | Acc: 32.911,46.800,72.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.301 | Acc: 32.843,46.661,72.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.306 | Acc: 32.903,46.647,72.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.313 | Acc: 32.871,46.583,71.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.313 | Acc: 32.984,46.623,71.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.311 | Acc: 33.044,46.726,71.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.316 | Acc: 32.985,46.668,71.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.826 | Acc: 33.594,46.875,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.790 | Acc: 30.432,45.089,64.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.808 | Acc: 29.764,45.065,63.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.819 | Acc: 29.150,44.429,63.358,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 3.076 | Acc: 33.594,48.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.193 | Acc: 31.176,46.577,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.159 | Acc: 32.984,47.008,75.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.144 | Acc: 33.658,47.887,75.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.150 | Acc: 33.603,48.293,75.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.152 | Acc: 33.725,48.461,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.170 | Acc: 33.426,48.308,74.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.172 | Acc: 33.599,48.221,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.176 | Acc: 33.608,48.122,74.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.185 | Acc: 33.654,48.140,74.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.181 | Acc: 33.683,48.294,73.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.189 | Acc: 33.725,48.130,73.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.195 | Acc: 33.659,48.023,73.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.204 | Acc: 33.597,48.003,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.210 | Acc: 33.544,47.984,73.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.214 | Acc: 33.495,48.017,73.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.220 | Acc: 33.499,48.004,73.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.226 | Acc: 33.468,47.938,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.225 | Acc: 33.576,48.085,73.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.229 | Acc: 33.612,48.038,73.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.886 | Acc: 32.031,46.094,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.744 | Acc: 31.510,44.085,64.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.728 | Acc: 31.498,44.169,63.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.739 | Acc: 31.429,43.840,64.293,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 3.022 | Acc: 26.562,46.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.071 | Acc: 34.152,49.591,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.054 | Acc: 34.699,49.314,76.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.063 | Acc: 34.644,48.975,76.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.064 | Acc: 35.012,49.421,75.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.071 | Acc: 34.978,49.157,75.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.077 | Acc: 35.105,49.251,75.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.083 | Acc: 34.984,49.152,75.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.084 | Acc: 35.001,49.224,75.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.091 | Acc: 34.880,49.111,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.096 | Acc: 34.861,49.110,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.103 | Acc: 34.668,49.099,74.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.113 | Acc: 34.537,48.937,74.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.120 | Acc: 34.522,48.854,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.124 | Acc: 34.461,48.807,74.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.131 | Acc: 34.326,48.663,74.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.138 | Acc: 34.365,48.574,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.140 | Acc: 34.366,48.621,74.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.142 | Acc: 34.334,48.634,74.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.144 | Acc: 34.352,48.628,73.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.617 | Acc: 40.625,44.531,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.726 | Acc: 33.333,45.796,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.739 | Acc: 33.136,45.770,64.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.749 | Acc: 32.492,45.415,64.178,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 2.923 | Acc: 32.812,48.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.030 | Acc: 35.007,49.442,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.002 | Acc: 35.347,49.771,76.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.980 | Acc: 35.272,49.936,76.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.972 | Acc: 35.156,50.039,77.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.977 | Acc: 35.125,49.954,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.002 | Acc: 34.950,49.735,76.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.014 | Acc: 34.630,49.734,76.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.022 | Acc: 34.836,49.786,76.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.031 | Acc: 34.828,49.706,76.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.034 | Acc: 34.977,49.685,75.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.038 | Acc: 34.972,49.724,75.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.046 | Acc: 34.884,49.721,75.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.049 | Acc: 34.845,49.811,75.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.054 | Acc: 34.806,49.783,75.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.051 | Acc: 34.951,50.000,75.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.054 | Acc: 35.030,50.002,75.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.053 | Acc: 35.078,50.174,75.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.056 | Acc: 35.063,50.121,75.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.059 | Acc: 35.029,50.123,75.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.671 | Acc: 30.469,48.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.665 | Acc: 30.990,47.024,64.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.666 | Acc: 31.860,47.332,64.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.677 | Acc: 31.340,47.144,63.998,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 3.130 | Acc: 32.031,48.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.974 | Acc: 35.379,51.042,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.965 | Acc: 35.232,51.086,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.950 | Acc: 35.809,51.383,77.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.956 | Acc: 35.378,51.360,77.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.943 | Acc: 35.744,51.764,77.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.934 | Acc: 35.938,51.711,77.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.936 | Acc: 36.059,51.629,77.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.941 | Acc: 36.054,51.577,77.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.947 | Acc: 36.050,51.360,77.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.956 | Acc: 35.930,51.170,77.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.953 | Acc: 35.870,51.319,77.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.955 | Acc: 35.999,51.264,77.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.965 | Acc: 35.911,51.119,76.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.969 | Acc: 35.840,51.087,76.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.974 | Acc: 35.771,51.025,76.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.977 | Acc: 35.877,51.081,76.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.985 | Acc: 35.883,51.042,76.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.988 | Acc: 35.741,51.073,76.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.990 | Acc: 35.718,51.070,76.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.677 | Acc: 32.812,45.312,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.690 | Acc: 31.176,46.503,64.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.684 | Acc: 32.088,46.608,64.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.686 | Acc: 31.621,46.696,64.101,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 2.460 | Acc: 34.375,57.812,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.818 | Acc: 36.161,52.381,80.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.830 | Acc: 35.480,52.077,80.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.841 | Acc: 35.476,52.651,79.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.859 | Acc: 35.475,52.459,79.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.864 | Acc: 35.605,52.282,79.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.871 | Acc: 35.731,52.079,79.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.873 | Acc: 35.672,52.111,79.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.874 | Acc: 35.773,52.203,78.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.870 | Acc: 35.834,52.486,78.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.877 | Acc: 35.817,52.402,78.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.880 | Acc: 35.902,52.248,78.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.886 | Acc: 35.960,52.172,78.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.894 | Acc: 36.003,52.098,78.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.901 | Acc: 36.007,52.021,78.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.906 | Acc: 35.930,51.978,77.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.910 | Acc: 35.928,51.954,77.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.910 | Acc: 35.990,52.044,77.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.911 | Acc: 36.087,52.095,77.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.912 | Acc: 36.085,52.133,77.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.602 | Acc: 34.375,48.438,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.685 | Acc: 30.060,47.693,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.702 | Acc: 29.840,46.704,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.710 | Acc: 29.918,46.632,65.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 2.720 | Acc: 35.156,52.344,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.683 | Acc: 38.653,54.613,82.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.727 | Acc: 37.729,53.316,81.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.743 | Acc: 37.577,53.535,81.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.758 | Acc: 37.568,53.781,80.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.769 | Acc: 37.430,53.697,80.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.782 | Acc: 37.106,53.525,80.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 36.985,53.230,79.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.800 | Acc: 36.806,53.237,80.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.807 | Acc: 36.697,53.069,79.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.807 | Acc: 36.758,53.113,79.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 36.857,53.114,79.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.817 | Acc: 36.884,53.067,79.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.825 | Acc: 36.946,53.050,79.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.831 | Acc: 36.955,53.005,79.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 37.054,53.073,78.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.843 | Acc: 36.894,52.969,78.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.851 | Acc: 36.886,52.944,78.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.855 | Acc: 36.881,53.002,78.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.861 | Acc: 36.852,52.953,78.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.490 | Acc: 39.062,53.125,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.652 | Acc: 34.226,48.214,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.638 | Acc: 33.822,47.123,65.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.641 | Acc: 33.299,46.926,65.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 2.655 | Acc: 38.281,55.469,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.737 | Acc: 37.165,54.278,79.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 37.005,54.497,80.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.736 | Acc: 37.129,54.124,80.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.745 | Acc: 37.355,54.369,80.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.745 | Acc: 37.051,54.185,80.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.749 | Acc: 37.190,54.274,80.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.748 | Acc: 37.107,54.289,80.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.758 | Acc: 36.990,54.144,80.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.765 | Acc: 37.116,54.075,79.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.772 | Acc: 37.135,54.062,79.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.775 | Acc: 37.129,54.009,79.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.781 | Acc: 37.147,53.981,79.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.785 | Acc: 37.138,53.924,79.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.787 | Acc: 37.183,53.826,79.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.792 | Acc: 37.139,53.701,79.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.796 | Acc: 37.120,53.617,79.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.797 | Acc: 37.129,53.599,79.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.802 | Acc: 37.195,53.634,79.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.803 | Acc: 37.254,53.593,79.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.630 | Acc: 33.594,50.781,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.651 | Acc: 32.812,49.144,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.635 | Acc: 32.812,49.009,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.641 | Acc: 31.890,48.822,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 2.730 | Acc: 37.500,51.562,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.631 | Acc: 37.388,55.469,81.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.640 | Acc: 37.767,54.992,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.635 | Acc: 38.307,55.725,81.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.656 | Acc: 37.963,55.122,81.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.675 | Acc: 37.925,54.974,81.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.690 | Acc: 37.687,54.616,81.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.695 | Acc: 37.738,54.593,81.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.701 | Acc: 37.709,54.474,81.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.701 | Acc: 37.845,54.657,81.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.709 | Acc: 37.811,54.520,80.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.710 | Acc: 37.815,54.645,80.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.710 | Acc: 37.821,54.798,80.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.713 | Acc: 37.916,54.786,80.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.720 | Acc: 37.817,54.721,80.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.728 | Acc: 37.747,54.703,80.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.733 | Acc: 37.758,54.636,80.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.737 | Acc: 37.796,54.603,80.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.742 | Acc: 37.792,54.551,80.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.746 | Acc: 37.769,54.558,79.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.347 | Acc: 37.500,55.469,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.509 | Acc: 34.821,50.967,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.526 | Acc: 34.813,50.362,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.545 | Acc: 34.606,49.962,66.419,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 2.721 | Acc: 32.812,51.562,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.617 | Acc: 37.835,54.650,84.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.586 | Acc: 38.224,55.659,83.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.599 | Acc: 38.589,55.494,83.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.604 | Acc: 38.474,55.652,83.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.619 | Acc: 38.343,55.476,82.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.641 | Acc: 38.326,55.282,82.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.644 | Acc: 38.143,55.170,82.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.645 | Acc: 38.087,54.901,82.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.654 | Acc: 38.113,54.985,82.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.660 | Acc: 38.145,54.928,81.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.666 | Acc: 38.030,54.974,81.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.667 | Acc: 38.071,55.141,81.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.673 | Acc: 38.087,55.041,81.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.678 | Acc: 38.039,55.041,81.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.683 | Acc: 38.094,55.002,81.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.688 | Acc: 38.111,55.057,81.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.693 | Acc: 38.077,55.052,81.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.697 | Acc: 38.065,54.995,80.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.703 | Acc: 37.984,55.030,80.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.707 | Acc: 34.375,53.906,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.725 | Acc: 32.031,48.251,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.727 | Acc: 31.993,48.399,65.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.734 | Acc: 32.211,47.964,65.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 2.769 | Acc: 33.594,52.344,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.505 | Acc: 39.435,58.222,83.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.546 | Acc: 38.681,57.679,83.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.573 | Acc: 38.384,56.993,83.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.598 | Acc: 37.895,56.501,83.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.603 | Acc: 38.057,56.474,82.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.603 | Acc: 38.094,56.696,82.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.606 | Acc: 38.204,56.776,82.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.611 | Acc: 38.247,56.570,82.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.619 | Acc: 38.191,56.444,82.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.624 | Acc: 38.301,56.266,82.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.628 | Acc: 38.281,56.232,82.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.633 | Acc: 38.265,56.205,81.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.635 | Acc: 38.335,56.256,81.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.640 | Acc: 38.342,56.192,81.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.642 | Acc: 38.434,56.071,81.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.644 | Acc: 38.442,56.026,81.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.648 | Acc: 38.396,55.957,81.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.651 | Acc: 38.428,55.964,81.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.654 | Acc: 38.462,55.996,81.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.696 | Acc: 39.062,46.875,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.473 | Acc: 37.091,50.818,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.472 | Acc: 36.757,50.667,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.485 | Acc: 36.053,50.653,66.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 2.397 | Acc: 42.969,66.406,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.505 | Acc: 39.174,57.068,84.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.499 | Acc: 39.272,56.707,84.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.537 | Acc: 38.704,55.981,84.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.528 | Acc: 38.966,56.211,84.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.531 | Acc: 39.132,56.482,84.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.544 | Acc: 38.946,56.386,83.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.544 | Acc: 39.112,56.555,83.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.548 | Acc: 39.092,56.633,83.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.556 | Acc: 39.002,56.582,83.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.559 | Acc: 39.008,56.472,83.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.563 | Acc: 39.087,56.455,83.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.570 | Acc: 39.043,56.354,83.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.577 | Acc: 38.946,56.208,82.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.582 | Acc: 39.035,56.311,82.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.582 | Acc: 39.107,56.416,82.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.585 | Acc: 38.994,56.384,82.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.591 | Acc: 38.982,56.387,82.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.598 | Acc: 39.075,56.341,82.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.598 | Acc: 39.034,56.375,82.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.294 | Acc: 41.406,56.250,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.506 | Acc: 35.528,49.814,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.550 | Acc: 35.156,49.676,66.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.569 | Acc: 34.734,48.950,66.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 2.309 | Acc: 43.750,66.406,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.511 | Acc: 39.360,58.333,84.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.474 | Acc: 39.691,58.251,84.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 39.434,57.748,84.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 39.178,57.243,84.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.507 | Acc: 39.573,57.287,84.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.517 | Acc: 39.463,57.218,84.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.519 | Acc: 39.340,57.214,84.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.519 | Acc: 39.368,57.284,83.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.523 | Acc: 39.373,57.169,83.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.523 | Acc: 39.373,57.315,83.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.528 | Acc: 39.367,57.307,83.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.530 | Acc: 39.477,57.232,83.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.534 | Acc: 39.413,57.229,83.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.533 | Acc: 39.480,57.190,83.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.540 | Acc: 39.452,57.091,83.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.546 | Acc: 39.454,57.104,83.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.557 | Acc: 39.333,56.972,82.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.559 | Acc: 39.318,56.923,82.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.562 | Acc: 39.288,56.933,82.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.536 | Acc: 39.062,50.000,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.506 | Acc: 34.933,51.562,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.485 | Acc: 35.938,52.001,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.494 | Acc: 35.310,51.588,67.021,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 2.658 | Acc: 28.906,53.125,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.463 | Acc: 39.025,57.850,85.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.435 | Acc: 39.501,58.251,85.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.451 | Acc: 39.383,58.184,85.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.458 | Acc: 39.612,58.266,85.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.449 | Acc: 39.643,58.547,85.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.468 | Acc: 39.217,58.187,84.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 39.223,58.018,84.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.489 | Acc: 39.145,57.914,84.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.492 | Acc: 39.261,57.843,84.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.496 | Acc: 39.342,57.622,84.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.499 | Acc: 39.268,57.632,84.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.507 | Acc: 39.157,57.534,84.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 39.377,57.663,84.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.509 | Acc: 39.329,57.610,83.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.512 | Acc: 39.364,57.587,83.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.515 | Acc: 39.462,57.581,83.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.519 | Acc: 39.498,57.499,83.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.525 | Acc: 39.482,57.466,83.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.533 | Acc: 39.477,57.351,83.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.177 | Acc: 36.719,56.250,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.622 | Acc: 35.714,48.958,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.630 | Acc: 35.957,49.619,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.630 | Acc: 35.412,49.232,66.406,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 2.409 | Acc: 39.062,59.375,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.474 | Acc: 40.067,58.519,83.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.413 | Acc: 40.587,59.566,85.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.426 | Acc: 40.100,59.349,85.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.415 | Acc: 40.297,59.500,85.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.414 | Acc: 40.323,59.414,85.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.418 | Acc: 40.309,59.226,85.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.426 | Acc: 40.154,59.070,85.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.431 | Acc: 40.251,58.933,85.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.440 | Acc: 40.090,58.620,85.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.451 | Acc: 39.921,58.357,85.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.455 | Acc: 39.876,58.371,84.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.455 | Acc: 39.915,58.467,84.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.458 | Acc: 39.990,58.405,84.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.465 | Acc: 40.030,58.346,84.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.470 | Acc: 39.994,58.378,84.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.480 | Acc: 39.961,58.272,84.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 39.984,58.161,84.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 39.993,58.146,84.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 39.944,58.155,83.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.259 | Acc: 36.719,54.688,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.466 | Acc: 35.454,52.902,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.487 | Acc: 35.595,52.477,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.502 | Acc: 35.054,52.267,67.213,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 2.284 | Acc: 41.406,67.188,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.375 | Acc: 40.327,60.342,86.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.397 | Acc: 40.454,59.470,85.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.411 | Acc: 39.908,58.927,85.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.398 | Acc: 39.863,59.076,85.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.398 | Acc: 40.184,59.220,85.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.404 | Acc: 40.309,59.084,85.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.407 | Acc: 40.348,59.126,85.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.417 | Acc: 40.411,59.118,85.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.424 | Acc: 40.414,59.064,85.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.432 | Acc: 40.302,58.920,85.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.435 | Acc: 40.381,58.915,84.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.438 | Acc: 40.440,58.908,84.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.446 | Acc: 40.499,58.809,84.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.453 | Acc: 40.503,58.730,84.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.455 | Acc: 40.516,58.692,84.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.461 | Acc: 40.481,58.589,84.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.468 | Acc: 40.407,58.486,84.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.471 | Acc: 40.443,58.477,84.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.477 | Acc: 40.383,58.389,83.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.325 | Acc: 38.281,51.562,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.537 | Acc: 34.152,52.641,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.585 | Acc: 34.356,52.268,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.583 | Acc: 33.709,51.831,66.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 2.117 | Acc: 45.312,64.844,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.374 | Acc: 39.472,59.561,86.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.366 | Acc: 40.282,59.184,86.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.356 | Acc: 40.753,59.734,86.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.350 | Acc: 40.750,60.050,86.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.349 | Acc: 40.873,60.172,86.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.370 | Acc: 40.631,59.582,86.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.371 | Acc: 40.725,59.525,86.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.370 | Acc: 40.775,59.642,85.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.375 | Acc: 40.802,59.539,85.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.377 | Acc: 40.897,59.394,85.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.388 | Acc: 40.918,59.255,85.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.392 | Acc: 40.920,59.219,85.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.401 | Acc: 40.766,59.231,85.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.403 | Acc: 40.708,59.353,85.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.410 | Acc: 40.750,59.362,85.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.412 | Acc: 40.759,59.280,84.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.419 | Acc: 40.648,59.221,84.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.426 | Acc: 40.625,59.104,84.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.429 | Acc: 40.539,59.145,84.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.106 | Acc: 39.844,59.375,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.383 | Acc: 36.644,52.753,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.377 | Acc: 36.833,53.030,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.402 | Acc: 36.411,53.087,68.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 2.481 | Acc: 37.500,50.781,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.357 | Acc: 40.662,60.156,86.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.348 | Acc: 40.492,59.756,86.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.353 | Acc: 40.753,59.810,86.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.353 | Acc: 40.828,59.539,86.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.360 | Acc: 40.772,59.445,86.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.359 | Acc: 40.851,59.407,86.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.361 | Acc: 40.863,59.547,86.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.363 | Acc: 40.970,59.574,86.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.372 | Acc: 40.798,59.543,85.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.378 | Acc: 40.730,59.686,85.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.384 | Acc: 40.742,59.573,85.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.387 | Acc: 40.631,59.472,85.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.390 | Acc: 40.565,59.561,85.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.399 | Acc: 40.542,59.483,85.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.403 | Acc: 40.513,59.411,85.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.406 | Acc: 40.586,59.433,85.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.408 | Acc: 40.730,59.444,84.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.414 | Acc: 40.738,59.386,84.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.416 | Acc: 40.758,59.455,84.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.351 | Acc: 40.625,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.461 | Acc: 37.798,52.827,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.449 | Acc: 37.881,53.468,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.471 | Acc: 37.231,53.048,66.355,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 2.545 | Acc: 32.031,55.469,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.337 | Acc: 41.146,58.445,87.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.346 | Acc: 40.930,58.479,87.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.329 | Acc: 41.060,59.209,87.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.329 | Acc: 41.377,59.578,87.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.324 | Acc: 41.460,59.653,87.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.325 | Acc: 41.419,59.646,86.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.329 | Acc: 41.340,59.652,86.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.329 | Acc: 41.299,59.700,86.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.325 | Acc: 41.281,59.889,86.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.330 | Acc: 41.336,59.834,86.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.339 | Acc: 41.208,59.725,86.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.347 | Acc: 41.095,59.612,86.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.351 | Acc: 41.110,59.608,86.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.349 | Acc: 41.223,59.714,86.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.356 | Acc: 41.167,59.577,85.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.365 | Acc: 41.075,59.460,85.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.369 | Acc: 40.976,59.487,85.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.374 | Acc: 40.919,59.514,85.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.378 | Acc: 40.890,59.469,85.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.195 | Acc: 34.375,55.469,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.581 | Acc: 35.268,52.418,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.582 | Acc: 35.023,52.420,66.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.569 | Acc: 34.900,52.267,66.624,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 2.113 | Acc: 44.531,66.406,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.271 | Acc: 43.155,61.607,87.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.277 | Acc: 42.378,61.414,87.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.288 | Acc: 41.701,60.822,87.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.282 | Acc: 41.831,60.976,87.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.291 | Acc: 41.607,60.736,87.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.285 | Acc: 41.813,60.724,87.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.289 | Acc: 41.772,60.516,87.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.285 | Acc: 41.828,60.748,87.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.290 | Acc: 41.929,60.912,87.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.303 | Acc: 41.721,60.642,86.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.313 | Acc: 41.664,60.478,86.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.318 | Acc: 41.591,60.484,86.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.321 | Acc: 41.634,60.521,86.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.324 | Acc: 41.634,60.479,86.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.327 | Acc: 41.653,60.535,86.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.338 | Acc: 41.416,60.370,85.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.339 | Acc: 41.477,60.397,85.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.345 | Acc: 41.476,60.334,85.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.350 | Acc: 41.503,60.285,85.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.304 | Acc: 41.406,54.688,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.630 | Acc: 35.193,49.702,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.635 | Acc: 35.918,49.924,65.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.655 | Acc: 35.476,49.769,65.215,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 2.393 | Acc: 42.188,51.562,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.344 | Acc: 40.737,59.040,87.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.328 | Acc: 40.835,59.223,87.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.302 | Acc: 41.637,60.246,87.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.303 | Acc: 41.599,60.407,87.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.313 | Acc: 41.375,60.234,87.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.306 | Acc: 41.439,60.389,87.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.309 | Acc: 41.406,60.439,87.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.314 | Acc: 41.484,60.389,86.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.319 | Acc: 41.454,60.221,86.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.325 | Acc: 41.348,60.304,86.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.330 | Acc: 41.240,60.276,86.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.326 | Acc: 41.364,60.406,86.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.325 | Acc: 41.316,60.426,86.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.324 | Acc: 41.320,60.429,86.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.327 | Acc: 41.404,60.429,86.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.331 | Acc: 41.324,60.314,86.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.333 | Acc: 41.409,60.333,86.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.336 | Acc: 41.432,60.327,85.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.340 | Acc: 41.435,60.345,85.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.277 | Acc: 41.406,55.469,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.540 | Acc: 33.333,51.600,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.564 | Acc: 33.270,51.677,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.588 | Acc: 32.800,51.332,67.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 2.261 | Acc: 42.969,60.938,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.224 | Acc: 42.262,63.244,87.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.236 | Acc: 41.692,62.309,88.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.234 | Acc: 42.226,62.257,88.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.239 | Acc: 41.811,62.047,88.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.241 | Acc: 41.770,61.757,87.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.251 | Acc: 41.510,61.635,87.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.260 | Acc: 41.517,61.575,87.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.256 | Acc: 41.523,61.394,87.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.255 | Acc: 41.562,61.391,87.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.257 | Acc: 41.686,61.435,87.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.259 | Acc: 41.806,61.376,87.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.267 | Acc: 41.782,61.194,87.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.272 | Acc: 41.858,61.150,87.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.276 | Acc: 41.851,61.090,87.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.283 | Acc: 41.858,61.075,86.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.290 | Acc: 41.730,60.928,86.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.297 | Acc: 41.732,60.786,86.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.303 | Acc: 41.755,60.686,86.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.308 | Acc: 41.759,60.640,86.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.106 | Acc: 39.062,60.156,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.507 | Acc: 37.574,53.906,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.508 | Acc: 37.271,54.002,66.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.507 | Acc: 36.578,53.727,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 2.225 | Acc: 42.188,64.844,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.271 | Acc: 40.774,60.528,87.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.238 | Acc: 42.740,61.643,87.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.221 | Acc: 42.815,62.039,87.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.223 | Acc: 42.949,62.240,87.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.227 | Acc: 42.706,62.175,87.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.226 | Acc: 42.685,61.990,87.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.222 | Acc: 42.692,62.151,88.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.222 | Acc: 42.687,62.155,87.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.226 | Acc: 42.628,62.064,87.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.231 | Acc: 42.584,61.944,87.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.238 | Acc: 42.424,61.832,87.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.245 | Acc: 42.408,61.745,87.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.255 | Acc: 42.265,61.611,87.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.263 | Acc: 42.035,61.480,87.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.268 | Acc: 41.993,61.405,87.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.271 | Acc: 42.088,61.395,87.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.281 | Acc: 41.974,61.332,86.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.286 | Acc: 42.036,61.202,86.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.290 | Acc: 42.034,61.225,86.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.328 | Acc: 48.438,56.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.388 | Acc: 40.588,53.981,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.431 | Acc: 40.053,54.230,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.449 | Acc: 39.395,54.086,67.392,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 2.066 | Acc: 42.969,66.406,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.277 | Acc: 41.853,60.826,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.246 | Acc: 41.864,61.280,88.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.234 | Acc: 41.688,61.091,88.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.221 | Acc: 42.245,61.381,88.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.213 | Acc: 42.489,61.796,88.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.216 | Acc: 42.355,61.725,88.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.221 | Acc: 42.465,61.979,88.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.232 | Acc: 42.299,61.704,87.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.234 | Acc: 42.416,61.658,87.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.239 | Acc: 42.425,61.575,87.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.244 | Acc: 42.414,61.581,87.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.253 | Acc: 42.408,61.505,87.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.256 | Acc: 42.460,61.494,87.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.260 | Acc: 42.427,61.482,87.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.265 | Acc: 42.452,61.477,87.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.272 | Acc: 42.390,61.349,86.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.280 | Acc: 42.270,61.274,86.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.281 | Acc: 42.252,61.316,86.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.280 | Acc: 42.331,61.415,86.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.104 | Acc: 39.062,54.688,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.382 | Acc: 39.100,54.688,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.386 | Acc: 39.082,54.592,67.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.397 | Acc: 38.691,54.700,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 2.215 | Acc: 47.656,61.719,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.213 | Acc: 42.708,63.393,87.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.211 | Acc: 42.893,62.995,88.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.212 | Acc: 42.559,62.628,88.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.203 | Acc: 42.785,62.838,88.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.206 | Acc: 42.752,62.631,88.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.208 | Acc: 42.840,62.539,88.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.212 | Acc: 42.670,62.262,88.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.215 | Acc: 42.881,62.219,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.214 | Acc: 42.869,62.168,88.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.215 | Acc: 42.969,62.100,88.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.218 | Acc: 42.930,62.238,88.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.227 | Acc: 42.927,62.130,87.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.233 | Acc: 42.873,62.018,87.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.242 | Acc: 42.777,61.866,87.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.245 | Acc: 42.761,61.825,87.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.252 | Acc: 42.645,61.663,87.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.258 | Acc: 42.547,61.577,87.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.264 | Acc: 42.514,61.509,86.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.263 | Acc: 42.550,61.499,86.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.600 | Acc: 32.031,54.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.610 | Acc: 33.296,52.865,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.628 | Acc: 33.651,52.458,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.636 | Acc: 33.338,52.382,66.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 2.396 | Acc: 43.750,56.250,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.180 | Acc: 43.824,62.054,87.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.165 | Acc: 43.807,62.652,87.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.180 | Acc: 43.327,62.718,87.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.177 | Acc: 43.229,62.809,88.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.169 | Acc: 43.479,63.011,88.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.175 | Acc: 43.279,63.120,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.188 | Acc: 43.091,62.816,88.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.186 | Acc: 43.008,62.883,88.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.199 | Acc: 42.740,62.604,88.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.206 | Acc: 42.697,62.554,87.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.211 | Acc: 42.711,62.557,87.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.213 | Acc: 42.907,62.516,87.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.220 | Acc: 42.909,62.383,87.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.225 | Acc: 42.819,62.386,87.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.229 | Acc: 42.847,62.378,87.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.232 | Acc: 42.881,62.293,87.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.238 | Acc: 42.763,62.170,87.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.238 | Acc: 42.785,62.126,87.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.242 | Acc: 42.741,62.026,87.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.115 | Acc: 41.406,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.443 | Acc: 37.463,54.985,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.429 | Acc: 37.519,55.259,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.436 | Acc: 37.090,55.251,66.662,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 2.174 | Acc: 45.312,60.156,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.192 | Acc: 42.076,61.533,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.195 | Acc: 42.454,61.757,88.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.179 | Acc: 42.853,62.218,88.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.167 | Acc: 42.949,62.442,88.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.177 | Acc: 43.023,62.539,88.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.175 | Acc: 43.040,62.913,88.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.172 | Acc: 42.991,63.004,88.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.173 | Acc: 43.056,63.063,88.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.176 | Acc: 43.064,63.126,88.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.186 | Acc: 42.852,62.885,88.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.189 | Acc: 42.944,62.949,88.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.194 | Acc: 43.021,62.876,88.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.198 | Acc: 42.978,62.793,87.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.206 | Acc: 42.997,62.611,87.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.212 | Acc: 42.977,62.487,87.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.214 | Acc: 42.969,62.498,87.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.220 | Acc: 42.957,62.411,87.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.222 | Acc: 42.960,62.310,87.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.228 | Acc: 42.930,62.264,87.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.373 | Acc: 34.375,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.509 | Acc: 38.802,54.501,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.534 | Acc: 38.510,54.135,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.530 | Acc: 37.731,53.535,66.675,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 1.957 | Acc: 45.312,64.062,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.144 | Acc: 43.824,63.765,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.141 | Acc: 44.436,63.567,89.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.132 | Acc: 44.326,63.653,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.140 | Acc: 43.972,63.465,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.146 | Acc: 43.665,63.219,88.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.140 | Acc: 43.660,63.339,88.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.152 | Acc: 43.357,63.148,88.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.159 | Acc: 43.216,62.980,88.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.162 | Acc: 43.310,62.936,88.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.165 | Acc: 43.124,62.955,88.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.170 | Acc: 43.128,62.917,88.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.171 | Acc: 43.244,62.938,88.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.173 | Acc: 43.274,62.886,88.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.180 | Acc: 43.241,62.761,88.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.186 | Acc: 43.156,62.656,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.194 | Acc: 43.073,62.617,87.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.197 | Acc: 43.067,62.665,87.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.202 | Acc: 43.036,62.567,87.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.207 | Acc: 42.985,62.508,87.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.204 | Acc: 45.312,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.498 | Acc: 38.244,52.939,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.492 | Acc: 38.224,52.992,66.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.503 | Acc: 37.935,52.536,66.214,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 2.110 | Acc: 41.406,62.500,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.140 | Acc: 43.638,64.583,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.079 | Acc: 44.531,65.530,90.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.080 | Acc: 44.185,65.356,90.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.088 | Acc: 43.798,65.230,90.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.098 | Acc: 44.098,65.022,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.104 | Acc: 44.124,64.857,89.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.107 | Acc: 44.105,64.794,89.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.114 | Acc: 43.964,64.645,89.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.124 | Acc: 43.884,64.408,89.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.130 | Acc: 43.661,64.230,89.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.140 | Acc: 43.552,63.985,89.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.148 | Acc: 43.500,63.829,89.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.153 | Acc: 43.585,63.715,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.158 | Acc: 43.539,63.634,88.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.164 | Acc: 43.561,63.533,88.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.171 | Acc: 43.533,63.432,88.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.177 | Acc: 43.450,63.297,88.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.183 | Acc: 43.430,63.177,88.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.189 | Acc: 43.416,63.185,88.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.125 | Acc: 40.625,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.447 | Acc: 37.574,53.013,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.442 | Acc: 38.415,53.373,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.453 | Acc: 38.179,53.381,66.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 2.115 | Acc: 47.656,63.281,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.162 | Acc: 45.387,62.500,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.137 | Acc: 44.779,63.091,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.145 | Acc: 43.801,63.140,89.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.132 | Acc: 43.663,63.291,89.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.134 | Acc: 43.673,63.513,89.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.132 | Acc: 43.627,63.565,89.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.132 | Acc: 43.733,63.580,89.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.137 | Acc: 43.803,63.553,89.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.139 | Acc: 43.711,63.506,89.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.139 | Acc: 43.703,63.557,88.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.145 | Acc: 43.549,63.409,88.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.152 | Acc: 43.604,63.430,88.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.156 | Acc: 43.651,63.389,88.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.157 | Acc: 43.594,63.412,88.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.167 | Acc: 43.467,63.286,88.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.173 | Acc: 43.390,63.181,88.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.178 | Acc: 43.361,63.112,88.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.181 | Acc: 43.369,63.028,88.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.183 | Acc: 43.383,63.035,87.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.545 | Acc: 40.625,50.781,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.549 | Acc: 37.500,53.274,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.570 | Acc: 36.338,53.316,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.588 | Acc: 35.553,53.368,66.022,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 2.192 | Acc: 42.969,66.406,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.102 | Acc: 44.271,64.472,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.105 | Acc: 44.188,63.910,89.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.080 | Acc: 44.531,64.370,90.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.087 | Acc: 44.541,64.198,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.102 | Acc: 44.322,64.024,89.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.118 | Acc: 44.086,63.785,89.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.126 | Acc: 44.094,63.785,89.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.132 | Acc: 44.017,63.723,88.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.141 | Acc: 43.789,63.540,88.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.143 | Acc: 43.917,63.588,88.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.150 | Acc: 43.860,63.486,88.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.157 | Acc: 43.708,63.456,88.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.160 | Acc: 43.654,63.419,88.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.162 | Acc: 43.683,63.468,88.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.170 | Acc: 43.625,63.333,88.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.174 | Acc: 43.665,63.303,88.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.179 | Acc: 43.640,63.231,88.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.183 | Acc: 43.666,63.188,87.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.188 | Acc: 43.734,63.148,87.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.247 | Acc: 38.281,57.812,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.436 | Acc: 36.570,57.217,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.425 | Acc: 36.547,57.050,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.443 | Acc: 35.745,56.878,67.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 2.056 | Acc: 45.312,67.188,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.125 | Acc: 44.122,62.984,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.113 | Acc: 44.264,63.205,89.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.091 | Acc: 44.890,63.717,89.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.104 | Acc: 44.145,63.600,89.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.106 | Acc: 43.928,63.730,89.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.105 | Acc: 44.131,63.882,89.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.106 | Acc: 43.966,63.819,89.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.106 | Acc: 43.930,64.096,89.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.107 | Acc: 43.974,64.006,89.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.105 | Acc: 44.010,63.958,89.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.115 | Acc: 43.987,63.836,89.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.124 | Acc: 43.734,63.829,88.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.127 | Acc: 43.786,63.757,88.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.130 | Acc: 43.794,63.668,88.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.138 | Acc: 43.714,63.556,88.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.141 | Acc: 43.808,63.515,88.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.143 | Acc: 43.832,63.458,88.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.150 | Acc: 43.824,63.322,88.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.156 | Acc: 43.773,63.250,88.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.232 | Acc: 44.531,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.530 | Acc: 36.682,55.394,65.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.500 | Acc: 37.386,55.316,65.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.515 | Acc: 36.808,55.213,65.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 2.184 | Acc: 43.750,63.281,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.055 | Acc: 45.126,65.737,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.079 | Acc: 44.722,64.863,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.100 | Acc: 44.659,64.331,89.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.110 | Acc: 44.261,63.947,89.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.118 | Acc: 43.974,63.908,89.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.121 | Acc: 43.892,63.882,89.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.118 | Acc: 43.983,63.990,89.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.115 | Acc: 44.061,64.024,89.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.118 | Acc: 43.953,64.002,89.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.125 | Acc: 43.940,63.783,89.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.129 | Acc: 43.962,63.755,89.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.137 | Acc: 43.996,63.693,88.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.138 | Acc: 43.927,63.667,88.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.140 | Acc: 43.897,63.643,88.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.151 | Acc: 43.776,63.538,88.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.156 | Acc: 43.713,63.464,88.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.160 | Acc: 43.819,63.439,88.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.165 | Acc: 43.841,63.344,88.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.168 | Acc: 43.781,63.345,88.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.064 | Acc: 46.094,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.449 | Acc: 40.067,54.985,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.453 | Acc: 39.844,54.726,65.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.461 | Acc: 39.152,55.020,66.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 1.853 | Acc: 46.094,69.531,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.093 | Acc: 44.866,64.286,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.106 | Acc: 43.979,64.120,89.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.095 | Acc: 43.776,64.191,89.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.088 | Acc: 43.818,64.265,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.093 | Acc: 43.928,64.318,90.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.097 | Acc: 44.015,64.185,89.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.091 | Acc: 44.227,64.129,89.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.091 | Acc: 44.357,64.150,89.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.101 | Acc: 44.229,64.106,89.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.100 | Acc: 44.337,64.164,89.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.099 | Acc: 44.340,64.204,89.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.102 | Acc: 44.392,64.157,89.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.106 | Acc: 44.501,64.158,89.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.114 | Acc: 44.520,64.035,89.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.119 | Acc: 44.443,63.946,89.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.120 | Acc: 44.478,63.892,88.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.126 | Acc: 44.339,63.829,88.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.128 | Acc: 44.356,63.859,88.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.132 | Acc: 44.283,63.806,88.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.259 | Acc: 38.281,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.383 | Acc: 38.281,56.101,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.385 | Acc: 38.472,56.364,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.425 | Acc: 37.807,56.314,67.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 2.019 | Acc: 40.625,65.625,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.988 | Acc: 44.643,67.634,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 44.760,67.111,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.045 | Acc: 43.981,66.086,90.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.041 | Acc: 44.329,66.117,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.039 | Acc: 44.624,66.050,90.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.050 | Acc: 44.525,65.741,90.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.066 | Acc: 44.365,65.381,89.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.063 | Acc: 44.546,65.416,89.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.064 | Acc: 44.652,65.435,89.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.067 | Acc: 44.558,65.345,89.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.076 | Acc: 44.492,65.042,89.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.081 | Acc: 44.379,64.980,89.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.090 | Acc: 44.229,64.754,89.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.100 | Acc: 44.125,64.571,89.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.102 | Acc: 44.316,64.540,89.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.110 | Acc: 44.244,64.408,88.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.115 | Acc: 44.284,64.303,88.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.125 | Acc: 44.222,64.199,88.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.129 | Acc: 44.238,64.190,88.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.956 | Acc: 44.531,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.397 | Acc: 40.253,55.543,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.366 | Acc: 39.691,56.288,66.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.390 | Acc: 39.331,55.981,66.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 1.990 | Acc: 45.312,67.969,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.047 | Acc: 45.312,65.476,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.054 | Acc: 44.703,64.939,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.041 | Acc: 45.005,65.702,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.043 | Acc: 44.907,65.635,90.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.052 | Acc: 44.856,65.354,90.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.051 | Acc: 44.957,65.393,89.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.060 | Acc: 44.792,65.160,89.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.066 | Acc: 44.798,65.028,89.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.073 | Acc: 44.643,64.870,89.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.075 | Acc: 44.586,64.902,89.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.081 | Acc: 44.609,64.879,89.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.082 | Acc: 44.554,64.857,89.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.088 | Acc: 44.447,64.793,89.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.096 | Acc: 44.476,64.649,89.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.100 | Acc: 44.555,64.597,89.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.106 | Acc: 44.487,64.569,89.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.110 | Acc: 44.401,64.482,88.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.113 | Acc: 44.341,64.378,88.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.116 | Acc: 44.318,64.352,88.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.017 | Acc: 39.062,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.437 | Acc: 38.988,55.357,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.428 | Acc: 39.444,55.469,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.457 | Acc: 39.434,55.033,66.867,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 2.041 | Acc: 46.875,65.625,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.030 | Acc: 44.643,66.220,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.041 | Acc: 44.741,66.197,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.039 | Acc: 44.980,65.868,90.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.046 | Acc: 44.821,65.635,90.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.043 | Acc: 45.220,65.764,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.055 | Acc: 45.028,65.405,89.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.058 | Acc: 44.858,65.243,89.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.062 | Acc: 44.881,65.179,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.066 | Acc: 44.790,64.995,89.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.064 | Acc: 44.916,65.120,89.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.068 | Acc: 44.849,64.918,89.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.073 | Acc: 44.658,64.844,89.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.078 | Acc: 44.714,64.811,89.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.086 | Acc: 44.670,64.669,89.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.090 | Acc: 44.656,64.537,89.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.092 | Acc: 44.638,64.503,89.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.095 | Acc: 44.618,64.479,88.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.103 | Acc: 44.520,64.404,88.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.106 | Acc: 44.480,64.329,88.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.031 | Acc: 46.875,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.416 | Acc: 38.728,57.106,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.421 | Acc: 38.834,57.069,66.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.450 | Acc: 38.473,56.404,66.573,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 2.031 | Acc: 44.531,69.531,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.027 | Acc: 43.043,66.220,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.046 | Acc: 44.131,65.796,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.050 | Acc: 44.595,65.561,90.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.027 | Acc: 44.821,65.885,90.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.024 | Acc: 44.972,66.244,90.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.040 | Acc: 44.770,65.728,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.043 | Acc: 44.858,65.486,89.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.048 | Acc: 44.895,65.382,89.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.054 | Acc: 44.829,65.193,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.055 | Acc: 44.893,65.159,89.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.055 | Acc: 44.970,65.137,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.055 | Acc: 44.953,65.191,89.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.059 | Acc: 44.947,65.146,89.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.059 | Acc: 45.093,65.241,89.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.065 | Acc: 44.972,65.127,89.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.069 | Acc: 44.947,65.060,89.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.076 | Acc: 44.802,64.942,89.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.081 | Acc: 44.836,64.878,89.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.086 | Acc: 44.820,64.739,89.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.561 | Acc: 35.938,55.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.673 | Acc: 37.165,53.088,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.695 | Acc: 37.386,53.830,64.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.713 | Acc: 36.975,53.855,64.383,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 1.835 | Acc: 52.344,63.281,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.016 | Acc: 45.387,66.146,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.992 | Acc: 45.255,66.806,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 44.775,66.137,90.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.015 | Acc: 45.284,66.213,90.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.027 | Acc: 45.196,66.128,90.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.041 | Acc: 45.048,65.987,89.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.047 | Acc: 44.908,65.869,89.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.051 | Acc: 44.852,65.746,89.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.052 | Acc: 44.890,65.707,89.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.052 | Acc: 44.998,65.714,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.053 | Acc: 45.093,65.583,89.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.057 | Acc: 45.037,65.570,89.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.061 | Acc: 45.019,65.421,89.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.067 | Acc: 45.023,65.166,89.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.069 | Acc: 45.006,65.124,89.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.077 | Acc: 44.853,65.019,89.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.080 | Acc: 44.896,65.048,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.084 | Acc: 44.908,65.049,89.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.089 | Acc: 44.861,64.916,88.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.232 | Acc: 43.750,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.467 | Acc: 40.179,54.576,66.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.440 | Acc: 41.235,55.316,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.435 | Acc: 40.587,55.289,65.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 1.927 | Acc: 46.094,66.406,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.096 | Acc: 44.420,65.030,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.045 | Acc: 45.084,66.806,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.026 | Acc: 45.466,66.368,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.023 | Acc: 45.014,65.943,90.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.016 | Acc: 45.243,65.942,90.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.016 | Acc: 45.151,65.812,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.028 | Acc: 45.102,65.603,90.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.043 | Acc: 44.929,65.232,89.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.044 | Acc: 45.179,65.357,89.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.056 | Acc: 45.052,65.178,89.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.059 | Acc: 45.107,65.066,89.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.065 | Acc: 45.018,64.928,89.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.064 | Acc: 44.935,64.931,89.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.071 | Acc: 44.837,64.910,89.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.075 | Acc: 44.801,64.836,89.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.081 | Acc: 44.765,64.805,89.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.086 | Acc: 44.710,64.725,89.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.087 | Acc: 44.771,64.731,89.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.090 | Acc: 44.714,64.649,88.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.919 | Acc: 42.969,62.500,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.384 | Acc: 40.476,56.548,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.374 | Acc: 40.187,56.345,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.384 | Acc: 39.139,56.096,67.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 1.937 | Acc: 46.875,67.969,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.069 | Acc: 42.857,64.286,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.065 | Acc: 44.112,64.177,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.053 | Acc: 44.826,64.575,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.038 | Acc: 45.042,65.133,90.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.035 | Acc: 44.879,65.308,90.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.029 | Acc: 45.132,65.393,90.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.035 | Acc: 45.113,65.365,90.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.036 | Acc: 44.822,65.329,90.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.040 | Acc: 44.829,65.340,90.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.046 | Acc: 45.002,65.236,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.050 | Acc: 44.973,65.173,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.055 | Acc: 44.956,65.129,89.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.059 | Acc: 44.905,65.098,89.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.064 | Acc: 44.857,65.075,89.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.074 | Acc: 44.819,64.958,89.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.076 | Acc: 44.814,64.987,89.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.079 | Acc: 44.783,64.979,89.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.081 | Acc: 44.839,65.026,89.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.086 | Acc: 44.892,64.998,89.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.224 | Acc: 41.406,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.471 | Acc: 38.914,53.795,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.488 | Acc: 39.101,53.849,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.486 | Acc: 38.768,53.817,66.611,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 1.841 | Acc: 50.781,68.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.017 | Acc: 45.387,66.629,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.031 | Acc: 44.970,66.159,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.024 | Acc: 44.762,66.035,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.007 | Acc: 45.284,66.040,90.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.003 | Acc: 45.390,65.973,90.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.004 | Acc: 45.287,65.999,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.012 | Acc: 45.080,65.913,90.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.019 | Acc: 45.109,65.727,90.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.024 | Acc: 45.144,65.573,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.026 | Acc: 45.106,65.458,90.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.027 | Acc: 45.107,65.477,90.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.029 | Acc: 45.069,65.534,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.030 | Acc: 45.214,65.568,90.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.035 | Acc: 45.218,65.414,89.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.040 | Acc: 45.185,65.345,89.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.043 | Acc: 45.205,65.367,89.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.044 | Acc: 45.191,65.382,89.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.049 | Acc: 45.150,65.365,89.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.050 | Acc: 45.200,65.410,89.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.381 | Acc: 40.625,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.490 | Acc: 37.984,55.357,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.504 | Acc: 37.824,55.659,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.498 | Acc: 37.615,55.277,66.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 1.920 | Acc: 42.969,65.625,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.034 | Acc: 44.568,66.369,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.022 | Acc: 45.312,66.635,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.000 | Acc: 45.645,67.533,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.993 | Acc: 45.650,67.265,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.995 | Acc: 45.552,67.118,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.002 | Acc: 45.455,66.903,90.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.005 | Acc: 45.324,66.717,90.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.014 | Acc: 45.036,66.557,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.017 | Acc: 45.205,66.579,90.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.015 | Acc: 45.417,66.628,90.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.021 | Acc: 45.348,66.378,90.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.026 | Acc: 45.335,66.192,89.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.033 | Acc: 45.339,66.050,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.039 | Acc: 45.162,66.011,89.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.048 | Acc: 45.081,65.903,89.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.049 | Acc: 45.210,65.934,89.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.051 | Acc: 45.255,65.895,89.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.055 | Acc: 45.237,65.811,89.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.060 | Acc: 45.255,65.674,89.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.189 | Acc: 37.500,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.359 | Acc: 39.769,56.362,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.378 | Acc: 39.768,55.716,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.387 | Acc: 39.370,55.443,68.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 2.025 | Acc: 50.781,66.406,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.008 | Acc: 45.424,65.997,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.995 | Acc: 45.694,66.940,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.002 | Acc: 45.697,66.855,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.995 | Acc: 45.650,67.033,90.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.995 | Acc: 45.575,67.126,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.001 | Acc: 45.622,66.916,90.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.013 | Acc: 45.412,66.689,90.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.023 | Acc: 45.385,66.367,90.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.027 | Acc: 45.369,66.234,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.028 | Acc: 45.367,66.243,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.031 | Acc: 45.362,66.222,89.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.035 | Acc: 45.312,66.134,89.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.031 | Acc: 45.363,66.176,89.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.039 | Acc: 45.271,65.934,89.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.043 | Acc: 45.240,65.801,89.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.049 | Acc: 45.176,65.735,89.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.053 | Acc: 45.143,65.666,89.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.057 | Acc: 45.094,65.558,89.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.058 | Acc: 45.165,65.543,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.198 | Acc: 42.969,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.360 | Acc: 40.402,55.060,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.396 | Acc: 40.225,55.316,66.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.390 | Acc: 40.126,55.443,66.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 1.875 | Acc: 48.438,67.188,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 45.722,66.518,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.964 | Acc: 45.865,67.016,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 45.876,67.111,91.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.961 | Acc: 46.113,67.110,91.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.969 | Acc: 46.202,67.056,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.969 | Acc: 46.139,67.110,90.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.970 | Acc: 46.155,66.988,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.974 | Acc: 45.972,66.877,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.981 | Acc: 46.016,66.695,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.984 | Acc: 45.876,66.562,90.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.992 | Acc: 45.783,66.403,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.998 | Acc: 45.812,66.364,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.009 | Acc: 45.729,66.257,90.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.018 | Acc: 45.604,66.042,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.025 | Acc: 45.601,65.921,89.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.030 | Acc: 45.612,65.832,89.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.036 | Acc: 45.606,65.705,89.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.044 | Acc: 45.577,65.664,89.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.048 | Acc: 45.559,65.602,89.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.146 | Acc: 45.312,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.401 | Acc: 41.183,53.869,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.448 | Acc: 40.434,54.859,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.473 | Acc: 39.703,54.623,66.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 2.107 | Acc: 42.969,60.938,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.991 | Acc: 45.759,65.365,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.979 | Acc: 45.846,65.911,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.982 | Acc: 45.812,65.907,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.982 | Acc: 45.814,66.233,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.987 | Acc: 45.924,66.468,90.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.993 | Acc: 45.868,66.245,90.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.999 | Acc: 45.723,66.212,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.005 | Acc: 45.579,66.178,90.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.009 | Acc: 45.602,66.143,90.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.013 | Acc: 45.658,66.123,90.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.012 | Acc: 45.779,66.258,89.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.019 | Acc: 45.731,66.189,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.027 | Acc: 45.624,66.116,89.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.030 | Acc: 45.504,66.064,89.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.034 | Acc: 45.624,66.121,89.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.035 | Acc: 45.656,66.056,89.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.038 | Acc: 45.567,66.095,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.042 | Acc: 45.566,65.999,89.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.048 | Acc: 45.550,65.922,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.246 | Acc: 41.406,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.485 | Acc: 40.179,56.064,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.513 | Acc: 39.996,56.021,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.527 | Acc: 39.331,55.661,66.137,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 1.960 | Acc: 50.000,69.531,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.998 | Acc: 45.052,66.332,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.954 | Acc: 46.284,67.207,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 45.799,67.072,90.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.961 | Acc: 46.017,67.081,90.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.966 | Acc: 45.893,67.056,90.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.973 | Acc: 45.952,67.162,90.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.979 | Acc: 46.066,67.021,90.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.986 | Acc: 45.968,66.712,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.994 | Acc: 45.990,66.652,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.993 | Acc: 46.028,66.721,90.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.994 | Acc: 46.104,66.703,90.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.000 | Acc: 46.003,66.630,90.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.001 | Acc: 46.049,66.694,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.007 | Acc: 45.941,66.481,89.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.013 | Acc: 45.837,66.339,89.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.018 | Acc: 45.811,66.285,89.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.022 | Acc: 45.784,66.161,89.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.029 | Acc: 45.747,66.110,89.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.034 | Acc: 45.737,66.049,89.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.033 | Acc: 42.969,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.362 | Acc: 41.109,57.217,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.365 | Acc: 41.101,57.012,67.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.355 | Acc: 40.561,56.737,67.764,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 1.906 | Acc: 43.750,67.969,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.945 | Acc: 45.722,67.188,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 46.284,67.530,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.954 | Acc: 46.119,67.316,90.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.963 | Acc: 46.152,67.178,90.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.972 | Acc: 45.707,66.785,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.981 | Acc: 45.681,66.794,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.985 | Acc: 45.717,66.678,90.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.990 | Acc: 45.735,66.693,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.994 | Acc: 45.602,66.579,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.999 | Acc: 45.620,66.562,90.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.005 | Acc: 45.613,66.583,90.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.010 | Acc: 45.488,66.662,89.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.015 | Acc: 45.432,66.520,89.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.020 | Acc: 45.296,66.459,89.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.021 | Acc: 45.307,66.437,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.022 | Acc: 45.359,66.491,89.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.024 | Acc: 45.386,66.578,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.025 | Acc: 45.373,66.551,89.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.027 | Acc: 45.425,66.464,89.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.278 | Acc: 43.750,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.439 | Acc: 40.997,56.548,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.448 | Acc: 40.339,56.079,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.473 | Acc: 40.113,55.827,65.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 1.968 | Acc: 50.000,68.750,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.969 | Acc: 46.280,66.183,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.969 | Acc: 46.284,66.597,90.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 46.555,67.264,90.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.964 | Acc: 46.316,67.159,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.969 | Acc: 46.163,67.064,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.971 | Acc: 46.262,67.033,90.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.980 | Acc: 46.149,66.766,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.985 | Acc: 46.249,66.639,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.986 | Acc: 46.158,66.557,90.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.988 | Acc: 46.191,66.651,90.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.992 | Acc: 46.196,66.601,89.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.995 | Acc: 46.220,66.568,89.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.001 | Acc: 46.175,66.388,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.999 | Acc: 46.222,66.473,89.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.002 | Acc: 46.130,66.406,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.007 | Acc: 46.086,66.299,89.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.012 | Acc: 46.032,66.280,89.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.012 | Acc: 45.994,66.287,89.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.015 | Acc: 46.004,66.240,89.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.275 | Acc: 40.625,57.031,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.540 | Acc: 38.951,54.613,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.522 | Acc: 38.815,54.268,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.532 | Acc: 38.038,54.483,67.175,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 1.969 | Acc: 42.188,65.625,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.919 | Acc: 47.396,67.746,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.910 | Acc: 47.637,68.159,91.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.921 | Acc: 47.106,67.879,91.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.916 | Acc: 47.319,68.229,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.929 | Acc: 46.945,68.015,91.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.932 | Acc: 46.933,68.072,91.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.930 | Acc: 47.080,67.952,90.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.934 | Acc: 46.977,67.847,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.942 | Acc: 46.966,67.740,90.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.950 | Acc: 46.902,67.568,90.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.956 | Acc: 46.818,67.407,90.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.960 | Acc: 46.674,67.298,90.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.964 | Acc: 46.621,67.259,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.974 | Acc: 46.386,67.012,90.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.977 | Acc: 46.304,66.959,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.989 | Acc: 46.206,66.725,90.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.990 | Acc: 46.270,66.706,90.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.993 | Acc: 46.271,66.679,89.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.997 | Acc: 46.157,66.576,89.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.265 | Acc: 42.969,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.391 | Acc: 40.625,55.878,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.422 | Acc: 40.758,55.621,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.413 | Acc: 40.305,55.686,67.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 2.032 | Acc: 50.781,67.188,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.949 | Acc: 47.061,67.746,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 47.180,68.388,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.946 | Acc: 46.862,67.738,90.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.942 | Acc: 46.528,68.104,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.946 | Acc: 46.589,68.015,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.945 | Acc: 46.591,67.878,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.950 | Acc: 46.310,67.603,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.947 | Acc: 46.472,67.731,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.949 | Acc: 46.452,67.511,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.949 | Acc: 46.354,67.580,90.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.953 | Acc: 46.334,67.456,90.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.956 | Acc: 46.363,67.411,90.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.964 | Acc: 46.363,67.325,90.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.973 | Acc: 46.313,67.093,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.980 | Acc: 46.237,66.923,90.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.983 | Acc: 46.215,66.891,90.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.983 | Acc: 46.282,66.938,90.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.989 | Acc: 46.258,66.867,90.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.989 | Acc: 46.215,66.923,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.120 | Acc: 42.969,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.496 | Acc: 36.644,56.548,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.531 | Acc: 36.662,56.231,67.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.546 | Acc: 36.117,55.815,67.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 1.929 | Acc: 46.875,67.188,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.932 | Acc: 46.429,67.783,89.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.947 | Acc: 46.113,66.616,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.941 | Acc: 46.401,66.714,90.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.959 | Acc: 46.277,66.454,90.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.964 | Acc: 46.225,66.383,90.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.973 | Acc: 46.216,66.451,90.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.973 | Acc: 46.321,66.645,90.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.972 | Acc: 46.327,66.731,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.972 | Acc: 46.314,66.769,90.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.974 | Acc: 46.195,66.717,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.976 | Acc: 46.302,66.827,90.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.973 | Acc: 46.437,67.038,90.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.978 | Acc: 46.405,66.852,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.980 | Acc: 46.472,66.846,90.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.986 | Acc: 46.400,66.710,89.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.990 | Acc: 46.393,66.713,89.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.997 | Acc: 46.355,66.569,89.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.005 | Acc: 46.245,66.421,89.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.010 | Acc: 46.250,66.398,89.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.123 | Acc: 41.406,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.485 | Acc: 39.881,54.501,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.460 | Acc: 39.920,55.202,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.470 | Acc: 39.703,55.046,66.842,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 1.937 | Acc: 50.781,71.094,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.864 | Acc: 49.405,67.857,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.894 | Acc: 48.171,68.236,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.932 | Acc: 47.554,67.508,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.955 | Acc: 46.943,66.985,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.967 | Acc: 46.666,66.313,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.966 | Acc: 46.320,66.445,90.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.969 | Acc: 46.266,66.412,90.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.975 | Acc: 46.268,66.343,90.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.979 | Acc: 46.279,66.406,90.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.982 | Acc: 46.428,66.484,90.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.983 | Acc: 46.490,66.403,90.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.987 | Acc: 46.450,66.461,90.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.989 | Acc: 46.378,66.475,90.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.992 | Acc: 46.305,66.481,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.990 | Acc: 46.309,66.549,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.993 | Acc: 46.269,66.528,89.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.992 | Acc: 46.362,66.628,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.995 | Acc: 46.353,66.588,89.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.999 | Acc: 46.260,66.529,89.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.141 | Acc: 40.625,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.399 | Acc: 40.290,55.766,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.449 | Acc: 40.263,55.755,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.449 | Acc: 39.997,55.968,66.060,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 2.147 | Acc: 42.188,68.750,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.948 | Acc: 46.354,67.894,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.928 | Acc: 46.932,68.159,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.929 | Acc: 46.491,67.828,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.939 | Acc: 46.692,67.525,91.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.929 | Acc: 46.844,67.675,91.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.920 | Acc: 46.817,67.672,91.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.931 | Acc: 46.803,67.625,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.932 | Acc: 46.807,67.590,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.938 | Acc: 46.823,67.628,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.946 | Acc: 46.821,67.483,90.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.955 | Acc: 46.804,67.262,90.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.958 | Acc: 46.807,67.220,90.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.963 | Acc: 46.707,67.146,90.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.969 | Acc: 46.591,67.112,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.974 | Acc: 46.519,66.912,90.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.975 | Acc: 46.410,66.827,90.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.979 | Acc: 46.350,66.777,90.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.982 | Acc: 46.362,66.785,90.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.987 | Acc: 46.282,66.673,90.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.196 | Acc: 37.500,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.735 | Acc: 35.268,54.353,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.719 | Acc: 35.080,54.154,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.714 | Acc: 34.695,54.239,65.471,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 1.948 | Acc: 52.344,71.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.944 | Acc: 46.949,68.378,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 47.504,68.369,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.947 | Acc: 47.157,68.263,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.935 | Acc: 47.454,68.277,90.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.928 | Acc: 47.308,68.193,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.917 | Acc: 47.159,68.395,90.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.918 | Acc: 47.219,68.479,90.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.920 | Acc: 47.069,68.488,90.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.926 | Acc: 46.961,68.288,90.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.929 | Acc: 46.937,68.101,90.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.934 | Acc: 46.762,67.887,90.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.939 | Acc: 46.693,67.852,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.945 | Acc: 46.651,67.699,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.951 | Acc: 46.522,67.543,90.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.955 | Acc: 46.501,67.444,90.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.962 | Acc: 46.503,67.368,90.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.968 | Acc: 46.426,67.300,90.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.973 | Acc: 46.360,67.192,89.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.975 | Acc: 46.362,67.136,89.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.156 | Acc: 44.531,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.600 | Acc: 42.039,54.055,65.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.612 | Acc: 40.739,53.944,64.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.603 | Acc: 40.459,53.893,64.703,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 2.167 | Acc: 40.625,63.281,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.937 | Acc: 47.210,67.225,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.939 | Acc: 46.875,67.530,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.915 | Acc: 47.182,67.687,90.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.910 | Acc: 46.962,67.930,91.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.904 | Acc: 47.138,68.154,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.898 | Acc: 47.430,68.221,91.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.901 | Acc: 47.468,68.307,91.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.907 | Acc: 47.559,68.192,91.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.914 | Acc: 47.263,67.844,91.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.920 | Acc: 47.116,67.704,90.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.928 | Acc: 47.204,67.622,90.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.932 | Acc: 47.125,67.593,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.938 | Acc: 47.091,67.520,90.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.942 | Acc: 47.081,67.424,90.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.947 | Acc: 46.997,67.424,90.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.954 | Acc: 46.882,67.278,90.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.958 | Acc: 46.825,67.263,90.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.963 | Acc: 46.756,67.149,90.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.965 | Acc: 46.752,67.175,90.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.019 | Acc: 38.281,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.426 | Acc: 39.546,56.734,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.463 | Acc: 39.177,56.117,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.493 | Acc: 38.627,55.763,66.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 2.280 | Acc: 41.406,64.062,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.983 | Acc: 45.796,67.485,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.954 | Acc: 46.570,67.912,90.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 46.055,67.469,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.954 | Acc: 46.364,67.419,90.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.959 | Acc: 46.349,67.520,90.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.953 | Acc: 46.746,67.704,90.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.959 | Acc: 46.537,67.559,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.953 | Acc: 46.705,67.707,90.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.957 | Acc: 46.664,67.740,90.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.954 | Acc: 46.704,67.669,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.955 | Acc: 46.695,67.559,90.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.955 | Acc: 46.755,67.541,90.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.958 | Acc: 46.713,67.520,90.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.962 | Acc: 46.708,67.463,90.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.967 | Acc: 46.683,67.359,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.971 | Acc: 46.649,67.312,90.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.978 | Acc: 46.497,67.135,89.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.982 | Acc: 46.470,67.017,89.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.986 | Acc: 46.455,66.964,89.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.189 | Acc: 35.938,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.470 | Acc: 38.281,55.097,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.491 | Acc: 39.577,54.935,65.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.485 | Acc: 38.986,54.713,65.740,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 1.909 | Acc: 48.438,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.919 | Acc: 47.321,68.341,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.918 | Acc: 46.875,68.274,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.897 | Acc: 47.131,68.788,91.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.889 | Acc: 47.521,68.760,91.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.886 | Acc: 47.494,68.874,91.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.895 | Acc: 47.333,68.731,91.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.900 | Acc: 47.529,68.556,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.903 | Acc: 47.530,68.439,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.908 | Acc: 47.315,68.461,91.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.915 | Acc: 47.143,68.260,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.921 | Acc: 47.069,68.135,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.921 | Acc: 47.134,68.212,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.927 | Acc: 47.001,68.094,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.931 | Acc: 46.908,67.994,90.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.935 | Acc: 46.898,67.901,90.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.940 | Acc: 46.826,67.849,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.942 | Acc: 46.884,67.751,90.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.949 | Acc: 46.810,67.629,90.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.950 | Acc: 46.791,67.647,90.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.332 | Acc: 43.750,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.445 | Acc: 39.881,56.622,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.429 | Acc: 40.015,56.974,65.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.426 | Acc: 39.498,56.814,66.112,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 1.545 | Acc: 60.156,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.859 | Acc: 48.549,69.978,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.886 | Acc: 48.056,68.883,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.902 | Acc: 47.682,68.186,90.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.909 | Acc: 47.656,68.142,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.918 | Acc: 47.246,68.108,90.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.913 | Acc: 47.243,68.143,91.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.909 | Acc: 47.274,68.246,91.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.916 | Acc: 47.302,68.211,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.920 | Acc: 47.233,67.977,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.918 | Acc: 47.236,67.934,90.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.926 | Acc: 47.207,67.940,90.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.932 | Acc: 47.167,67.726,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.937 | Acc: 47.165,67.750,90.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.941 | Acc: 47.070,67.671,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.945 | Acc: 46.974,67.577,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.950 | Acc: 46.950,67.526,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.950 | Acc: 47.008,67.543,90.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.955 | Acc: 46.892,67.482,90.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.961 | Acc: 46.766,67.415,90.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.127 | Acc: 41.406,57.031,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.521 | Acc: 39.509,55.543,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.525 | Acc: 40.053,54.897,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.541 | Acc: 39.613,55.161,66.368,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 1.838 | Acc: 46.094,67.969,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.946 | Acc: 46.838,68.043,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.940 | Acc: 46.284,67.454,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.928 | Acc: 46.798,67.815,90.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.927 | Acc: 46.711,67.776,90.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.919 | Acc: 46.798,67.884,90.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.924 | Acc: 46.604,67.769,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.928 | Acc: 46.559,67.797,90.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.923 | Acc: 46.715,67.881,90.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.926 | Acc: 46.797,67.848,90.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.923 | Acc: 46.929,67.852,90.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.931 | Acc: 46.847,67.788,90.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.936 | Acc: 46.839,67.752,90.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.945 | Acc: 46.662,67.636,90.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.946 | Acc: 46.711,67.649,90.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.952 | Acc: 46.706,67.533,90.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.955 | Acc: 46.700,67.562,90.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.958 | Acc: 46.667,67.467,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.963 | Acc: 46.602,67.423,90.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.966 | Acc: 46.520,67.419,89.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.230 | Acc: 33.594,60.156,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.646 | Acc: 35.900,55.060,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.666 | Acc: 36.280,55.297,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.671 | Acc: 35.797,55.469,66.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 2.002 | Acc: 43.750,66.406,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.919 | Acc: 47.135,67.262,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.907 | Acc: 46.437,67.778,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.890 | Acc: 46.593,68.571,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.903 | Acc: 46.933,68.326,91.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.900 | Acc: 47.123,68.147,91.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.902 | Acc: 46.888,67.988,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.906 | Acc: 47.025,67.980,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.912 | Acc: 46.846,67.954,91.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.917 | Acc: 46.828,67.921,91.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.922 | Acc: 46.906,67.930,90.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.924 | Acc: 46.988,68.061,90.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.927 | Acc: 46.969,67.988,90.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.929 | Acc: 47.097,67.963,90.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.939 | Acc: 47.103,67.899,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.944 | Acc: 47.067,67.797,90.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.948 | Acc: 47.084,67.655,90.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.952 | Acc: 47.088,67.529,90.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.958 | Acc: 47.020,67.452,90.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.962 | Acc: 46.941,67.395,90.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.944 | Acc: 45.312,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.439 | Acc: 40.662,56.362,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.441 | Acc: 40.225,56.612,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.441 | Acc: 39.434,56.596,67.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 1.881 | Acc: 44.531,70.312,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.899 | Acc: 48.475,69.010,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.894 | Acc: 48.209,68.883,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.889 | Acc: 48.297,69.006,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.912 | Acc: 47.955,68.451,90.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.923 | Acc: 47.641,68.193,90.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.918 | Acc: 47.417,68.214,90.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.925 | Acc: 47.374,68.124,90.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.932 | Acc: 47.428,67.901,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.938 | Acc: 47.194,67.675,90.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.939 | Acc: 47.201,67.650,90.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.944 | Acc: 47.140,67.594,90.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.944 | Acc: 47.154,67.645,90.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.947 | Acc: 47.097,67.550,90.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.946 | Acc: 47.200,67.618,90.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.948 | Acc: 47.171,67.704,90.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.952 | Acc: 47.160,67.657,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.955 | Acc: 47.184,67.604,89.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.958 | Acc: 47.208,67.516,89.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.961 | Acc: 47.115,67.450,89.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.308 | Acc: 39.844,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.363 | Acc: 40.179,57.961,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.371 | Acc: 39.996,58.403,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.382 | Acc: 39.728,57.812,67.546,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 1.648 | Acc: 53.125,68.750,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.861 | Acc: 48.438,68.564,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.853 | Acc: 47.904,69.112,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.851 | Acc: 47.900,69.659,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.852 | Acc: 47.878,69.898,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.858 | Acc: 47.888,69.725,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.871 | Acc: 47.475,69.292,91.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.883 | Acc: 47.340,69.049,91.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.886 | Acc: 47.210,68.915,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.887 | Acc: 47.328,68.936,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.895 | Acc: 47.349,68.808,91.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.902 | Acc: 47.370,68.690,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.908 | Acc: 47.416,68.643,91.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.914 | Acc: 47.369,68.561,90.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.915 | Acc: 47.420,68.519,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.916 | Acc: 47.446,68.509,90.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.916 | Acc: 47.476,68.458,90.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.920 | Acc: 47.429,68.383,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.926 | Acc: 47.375,68.291,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.932 | Acc: 47.312,68.194,90.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.158 | Acc: 38.281,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.568 | Acc: 39.286,53.385,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.562 | Acc: 40.244,54.554,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.591 | Acc: 39.472,54.559,65.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 2.078 | Acc: 43.750,61.719,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.903 | Acc: 46.354,67.932,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.893 | Acc: 46.456,68.140,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.881 | Acc: 46.926,68.494,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.875 | Acc: 47.058,68.490,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.876 | Acc: 47.161,68.379,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.889 | Acc: 46.914,68.111,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.898 | Acc: 46.858,68.096,91.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.899 | Acc: 46.948,68.076,91.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.904 | Acc: 46.910,68.025,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.902 | Acc: 47.065,68.081,91.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.907 | Acc: 47.147,68.124,91.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.911 | Acc: 47.164,68.141,90.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.919 | Acc: 47.052,68.020,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.920 | Acc: 47.084,67.960,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.919 | Acc: 47.132,68.052,90.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.921 | Acc: 47.228,68.078,90.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.929 | Acc: 47.173,67.856,90.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.935 | Acc: 47.063,67.752,90.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.939 | Acc: 47.096,67.749,90.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.201 | Acc: 40.625,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.452 | Acc: 41.369,55.952,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.454 | Acc: 41.444,56.079,66.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.456 | Acc: 40.894,56.071,66.688,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 1.975 | Acc: 46.875,62.500,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.944 | Acc: 46.577,68.341,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.930 | Acc: 46.818,67.778,90.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.911 | Acc: 47.221,68.058,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.906 | Acc: 47.328,68.239,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.893 | Acc: 47.471,68.533,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.886 | Acc: 47.566,68.627,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.883 | Acc: 47.684,68.717,91.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.893 | Acc: 47.632,68.430,91.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.890 | Acc: 47.665,68.590,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.895 | Acc: 47.777,68.536,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.892 | Acc: 47.868,68.552,91.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.895 | Acc: 47.919,68.539,91.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.902 | Acc: 47.908,68.337,91.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.914 | Acc: 47.756,68.069,90.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.919 | Acc: 47.726,67.997,90.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.920 | Acc: 47.788,67.935,90.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.928 | Acc: 47.661,67.847,90.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.932 | Acc: 47.604,67.832,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.935 | Acc: 47.632,67.831,90.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.105 | Acc: 41.406,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.442 | Acc: 40.253,56.436,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.509 | Acc: 39.672,56.098,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.521 | Acc: 39.395,56.455,66.650,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 1.879 | Acc: 50.000,67.188,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.918 | Acc: 46.391,69.271,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.892 | Acc: 46.646,69.512,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.897 | Acc: 46.811,69.134,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.887 | Acc: 46.846,69.184,91.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.880 | Acc: 47.239,69.036,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.875 | Acc: 47.321,69.086,91.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.884 | Acc: 47.191,68.833,91.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.887 | Acc: 47.346,68.609,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.892 | Acc: 47.233,68.564,91.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.893 | Acc: 47.415,68.490,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.889 | Acc: 47.543,68.587,91.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.894 | Acc: 47.481,68.536,90.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.903 | Acc: 47.513,68.379,90.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.904 | Acc: 47.514,68.472,90.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.910 | Acc: 47.386,68.355,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.912 | Acc: 47.440,68.334,90.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.920 | Acc: 47.313,68.221,90.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.925 | Acc: 47.223,68.051,90.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.932 | Acc: 47.185,67.985,90.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.057 | Acc: 43.750,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.414 | Acc: 41.778,56.920,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.407 | Acc: 41.254,56.688,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.430 | Acc: 40.766,56.327,66.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 1.928 | Acc: 46.875,71.094,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.920 | Acc: 46.801,67.894,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.901 | Acc: 47.161,68.045,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.890 | Acc: 47.528,68.391,91.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.885 | Acc: 47.377,68.692,91.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.876 | Acc: 47.571,68.897,91.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.882 | Acc: 47.404,68.789,91.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.893 | Acc: 47.141,68.600,91.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.893 | Acc: 47.370,68.483,90.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.897 | Acc: 47.380,68.379,90.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.898 | Acc: 47.225,68.389,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.896 | Acc: 47.320,68.421,90.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.900 | Acc: 47.235,68.406,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.902 | Acc: 47.204,68.415,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.903 | Acc: 47.178,68.439,90.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.908 | Acc: 47.161,68.350,90.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.915 | Acc: 47.075,68.190,90.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.917 | Acc: 47.067,68.202,90.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.921 | Acc: 47.031,68.170,90.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.927 | Acc: 46.937,68.049,90.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.240 | Acc: 42.969,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.483 | Acc: 39.397,55.580,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.511 | Acc: 38.396,54.745,66.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.542 | Acc: 38.012,54.495,66.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 1.653 | Acc: 49.219,74.219,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.892 | Acc: 46.987,66.853,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.843 | Acc: 47.980,68.960,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.830 | Acc: 47.810,69.198,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.832 | Acc: 47.521,69.174,92.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.835 | Acc: 47.540,69.067,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.840 | Acc: 47.940,69.066,92.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.856 | Acc: 47.673,68.789,92.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.863 | Acc: 47.535,68.638,91.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.877 | Acc: 47.432,68.504,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.881 | Acc: 47.201,68.458,91.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.889 | Acc: 47.172,68.382,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.899 | Acc: 47.180,68.231,91.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.901 | Acc: 47.180,68.250,91.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.905 | Acc: 47.261,68.222,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.910 | Acc: 47.236,68.112,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.913 | Acc: 47.179,68.115,90.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.919 | Acc: 47.207,68.067,90.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.924 | Acc: 47.182,67.967,90.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.928 | Acc: 47.178,67.897,90.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.174 | Acc: 43.750,58.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.498 | Acc: 40.513,55.097,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.522 | Acc: 40.072,55.316,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.550 | Acc: 39.383,55.546,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 1.945 | Acc: 42.188,64.844,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.884 | Acc: 49.219,70.387,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.894 | Acc: 47.675,69.550,91.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.872 | Acc: 47.669,69.262,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.873 | Acc: 47.444,69.242,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.861 | Acc: 47.803,69.431,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.863 | Acc: 47.695,69.279,92.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.861 | Acc: 47.922,69.354,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.875 | Acc: 47.598,68.900,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.874 | Acc: 47.583,68.793,91.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.869 | Acc: 47.761,68.933,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.875 | Acc: 47.685,68.867,91.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.885 | Acc: 47.637,68.714,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.887 | Acc: 47.659,68.627,91.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.891 | Acc: 47.626,68.575,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.893 | Acc: 47.643,68.535,91.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.902 | Acc: 47.605,68.334,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.907 | Acc: 47.576,68.315,90.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.908 | Acc: 47.585,68.233,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.913 | Acc: 47.546,68.166,90.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.915 | Acc: 42.969,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.213 | Acc: 44.085,58.222,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.239 | Acc: 43.216,58.175,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.249 | Acc: 42.559,58.081,68.622,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 1.717 | Acc: 50.781,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.848 | Acc: 48.326,70.536,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.836 | Acc: 48.495,70.427,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.860 | Acc: 47.976,69.800,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.854 | Acc: 47.946,69.878,91.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.858 | Acc: 48.136,69.585,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.871 | Acc: 47.921,69.505,91.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.871 | Acc: 47.861,69.326,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.874 | Acc: 47.734,69.308,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.875 | Acc: 47.686,69.510,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.879 | Acc: 47.672,69.356,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.882 | Acc: 47.656,69.316,91.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.883 | Acc: 47.773,69.272,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.885 | Acc: 47.698,69.139,91.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.888 | Acc: 47.723,69.117,91.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.892 | Acc: 47.695,69.059,91.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.896 | Acc: 47.732,68.950,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.901 | Acc: 47.631,68.837,90.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.904 | Acc: 47.630,68.795,90.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.908 | Acc: 47.570,68.674,90.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.957 | Acc: 49.219,65.625,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.354 | Acc: 41.295,57.478,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.357 | Acc: 41.197,57.470,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.374 | Acc: 40.407,57.249,68.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 1.759 | Acc: 59.375,71.094,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.839 | Acc: 49.144,70.573,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.842 | Acc: 47.999,70.560,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.819 | Acc: 48.527,70.645,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.831 | Acc: 48.495,70.554,91.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.831 | Acc: 48.577,70.274,91.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.840 | Acc: 48.651,69.919,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.849 | Acc: 48.415,69.697,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.851 | Acc: 48.554,69.682,91.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.855 | Acc: 48.334,69.618,91.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.865 | Acc: 48.216,69.317,91.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.873 | Acc: 48.003,69.210,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.876 | Acc: 47.942,69.178,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.882 | Acc: 47.827,69.106,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.888 | Acc: 47.820,69.050,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.888 | Acc: 47.864,69.061,91.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.894 | Acc: 47.761,68.937,90.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.901 | Acc: 47.645,68.796,90.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.905 | Acc: 47.684,68.722,90.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.905 | Acc: 47.785,68.764,90.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.163 | Acc: 39.844,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.466 | Acc: 41.518,56.399,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.479 | Acc: 40.339,56.326,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.508 | Acc: 39.831,56.084,66.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 1.919 | Acc: 43.750,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.863 | Acc: 47.954,69.717,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.875 | Acc: 47.637,69.455,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.879 | Acc: 47.515,69.070,91.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.870 | Acc: 47.859,69.184,91.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.876 | Acc: 47.857,68.990,91.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.879 | Acc: 47.779,68.892,91.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.883 | Acc: 47.762,68.811,91.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.887 | Acc: 47.826,68.600,91.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.890 | Acc: 47.842,68.608,91.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.897 | Acc: 47.777,68.482,91.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.901 | Acc: 47.787,68.442,91.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.908 | Acc: 47.582,68.374,90.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.905 | Acc: 47.587,68.534,90.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.904 | Acc: 47.684,68.611,90.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.904 | Acc: 47.656,68.654,90.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.908 | Acc: 47.537,68.628,90.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.911 | Acc: 47.608,68.608,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.917 | Acc: 47.555,68.438,90.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.921 | Acc: 47.584,68.362,90.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.127 | Acc: 36.719,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.411 | Acc: 39.323,56.957,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.412 | Acc: 38.891,57.393,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.403 | Acc: 39.165,57.505,68.532,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 1.847 | Acc: 47.656,67.969,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.877 | Acc: 47.135,68.638,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.867 | Acc: 47.637,68.559,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.859 | Acc: 48.015,68.686,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.846 | Acc: 47.830,69.165,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.842 | Acc: 47.826,69.454,92.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.847 | Acc: 47.695,69.486,92.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.846 | Acc: 47.856,69.415,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.848 | Acc: 47.787,69.298,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.846 | Acc: 47.825,69.384,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.852 | Acc: 47.792,69.286,91.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.857 | Acc: 47.854,69.213,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.861 | Acc: 47.951,69.142,91.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.864 | Acc: 47.887,69.130,91.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.870 | Acc: 47.798,69.092,91.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.873 | Acc: 47.698,69.121,91.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.880 | Acc: 47.685,68.959,91.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.882 | Acc: 47.675,68.920,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.888 | Acc: 47.693,68.813,91.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.895 | Acc: 47.587,68.701,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.163 | Acc: 46.094,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.327 | Acc: 41.629,58.408,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.313 | Acc: 41.616,58.822,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.326 | Acc: 41.393,58.555,67.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 2.081 | Acc: 46.875,63.281,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.876 | Acc: 47.433,69.606,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.836 | Acc: 48.438,69.112,92.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.833 | Acc: 48.181,69.365,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.835 | Acc: 48.322,69.097,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.841 | Acc: 48.391,69.291,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.852 | Acc: 47.973,69.318,91.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.856 | Acc: 48.116,69.238,91.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.860 | Acc: 47.947,69.196,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.868 | Acc: 47.950,69.052,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.869 | Acc: 48.041,69.007,91.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.875 | Acc: 48.095,68.842,91.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.883 | Acc: 48.045,68.737,91.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.886 | Acc: 47.941,68.678,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.888 | Acc: 47.879,68.678,90.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.894 | Acc: 47.843,68.625,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.897 | Acc: 47.761,68.592,90.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.906 | Acc: 47.711,68.493,90.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.910 | Acc: 47.652,68.417,90.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.914 | Acc: 47.701,68.377,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.173 | Acc: 40.625,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.460 | Acc: 41.071,56.696,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.461 | Acc: 41.597,56.936,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.459 | Acc: 41.355,56.493,66.137,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 1.588 | Acc: 54.688,75.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.868 | Acc: 47.321,68.006,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.843 | Acc: 47.466,69.512,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.830 | Acc: 47.938,69.762,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.816 | Acc: 47.936,70.052,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.818 | Acc: 48.058,69.725,91.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.821 | Acc: 48.076,69.421,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.834 | Acc: 47.989,69.343,91.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.840 | Acc: 48.098,69.293,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.846 | Acc: 48.170,69.277,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.853 | Acc: 47.948,69.240,91.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.856 | Acc: 48.073,69.171,91.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.859 | Acc: 48.068,69.139,91.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.863 | Acc: 48.063,69.085,91.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.866 | Acc: 47.931,69.114,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.874 | Acc: 47.918,69.023,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.879 | Acc: 47.829,68.935,91.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.881 | Acc: 47.920,69.007,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.888 | Acc: 47.931,68.949,91.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.894 | Acc: 47.831,68.879,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.254 | Acc: 42.188,58.594,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.451 | Acc: 39.658,56.882,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.428 | Acc: 40.034,56.669,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.450 | Acc: 39.690,56.647,66.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 1.999 | Acc: 47.656,64.844,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.854 | Acc: 48.698,69.159,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.827 | Acc: 49.047,70.217,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.825 | Acc: 48.719,70.287,91.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.818 | Acc: 48.756,70.322,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.817 | Acc: 48.407,70.467,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.815 | Acc: 48.386,70.519,91.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.825 | Acc: 48.327,70.240,91.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.826 | Acc: 48.442,70.206,91.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.832 | Acc: 48.325,70.015,91.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.843 | Acc: 48.274,69.710,91.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.850 | Acc: 48.247,69.712,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.857 | Acc: 48.117,69.570,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.862 | Acc: 48.084,69.534,91.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.865 | Acc: 48.073,69.476,91.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.873 | Acc: 47.996,69.246,91.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.876 | Acc: 48.068,69.173,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.878 | Acc: 48.046,69.107,90.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.888 | Acc: 47.983,68.914,90.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.893 | Acc: 47.999,68.838,90.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.230 | Acc: 42.969,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.409 | Acc: 40.960,56.362,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.431 | Acc: 40.701,56.193,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.436 | Acc: 40.561,56.442,66.842,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 1.702 | Acc: 48.438,72.656,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.881 | Acc: 46.131,69.829,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.848 | Acc: 47.942,70.465,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.834 | Acc: 48.066,70.287,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.827 | Acc: 48.312,70.370,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.830 | Acc: 48.391,70.359,91.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.832 | Acc: 48.450,70.403,91.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.835 | Acc: 48.360,70.240,91.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.846 | Acc: 48.161,70.046,91.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.853 | Acc: 48.226,69.855,91.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.857 | Acc: 48.228,69.757,91.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.857 | Acc: 48.275,69.687,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.864 | Acc: 48.146,69.625,91.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.866 | Acc: 48.237,69.552,91.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.868 | Acc: 48.212,69.509,90.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.872 | Acc: 48.147,69.448,90.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.874 | Acc: 48.162,69.380,90.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.879 | Acc: 48.080,69.300,90.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.883 | Acc: 48.028,69.267,90.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.888 | Acc: 47.935,69.113,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.078 | Acc: 48.438,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.459 | Acc: 43.266,57.664,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.456 | Acc: 42.530,57.374,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.440 | Acc: 42.200,57.761,66.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 1.647 | Acc: 47.656,72.656,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.789 | Acc: 48.958,70.796,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.773 | Acc: 49.486,70.655,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.807 | Acc: 48.745,70.044,92.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.816 | Acc: 48.399,70.120,92.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.820 | Acc: 48.368,70.057,92.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.825 | Acc: 48.347,70.067,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.837 | Acc: 48.349,69.869,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.847 | Acc: 48.205,69.638,91.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.844 | Acc: 48.269,69.587,91.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.856 | Acc: 48.127,69.426,91.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.863 | Acc: 48.020,69.316,91.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.871 | Acc: 47.935,69.051,91.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.878 | Acc: 47.917,68.918,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.881 | Acc: 47.812,68.900,90.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.888 | Acc: 47.755,68.812,90.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.891 | Acc: 47.810,68.818,90.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.894 | Acc: 47.835,68.748,90.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.900 | Acc: 47.814,68.733,90.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.902 | Acc: 47.865,68.756,90.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.246 | Acc: 39.844,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.519 | Acc: 43.676,56.176,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.514 | Acc: 42.740,56.136,65.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.513 | Acc: 42.111,56.122,65.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 1.908 | Acc: 48.438,68.750,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.801 | Acc: 49.479,71.354,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.790 | Acc: 48.609,70.998,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.793 | Acc: 48.732,71.324,92.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.805 | Acc: 48.910,71.152,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.824 | Acc: 48.414,70.645,91.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.820 | Acc: 48.418,70.532,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.812 | Acc: 48.692,70.734,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.818 | Acc: 48.520,70.482,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.827 | Acc: 48.377,70.274,91.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.832 | Acc: 48.282,70.165,91.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.838 | Acc: 48.296,70.086,91.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.847 | Acc: 48.279,69.998,91.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.853 | Acc: 48.201,69.768,91.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.860 | Acc: 48.223,69.676,91.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.867 | Acc: 48.186,69.555,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.870 | Acc: 48.180,69.560,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.874 | Acc: 48.238,69.492,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.879 | Acc: 48.199,69.417,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.881 | Acc: 48.183,69.380,90.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.916 | Acc: 45.312,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.243 | Acc: 42.820,60.342,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.266 | Acc: 42.111,60.061,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.277 | Acc: 42.290,59.670,67.777,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 1.931 | Acc: 44.531,69.531,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.796 | Acc: 49.814,71.019,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.802 | Acc: 48.952,71.475,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.807 | Acc: 48.924,71.068,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.821 | Acc: 48.466,70.409,91.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.818 | Acc: 48.368,70.506,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.828 | Acc: 48.218,70.571,91.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.824 | Acc: 48.349,70.390,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.821 | Acc: 48.141,70.410,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.822 | Acc: 48.213,70.317,91.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.825 | Acc: 48.181,70.208,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.826 | Acc: 48.328,70.182,91.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.830 | Acc: 48.233,70.115,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.833 | Acc: 48.231,69.941,91.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.840 | Acc: 48.168,69.832,91.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.844 | Acc: 48.188,69.783,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.852 | Acc: 48.128,69.614,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.866 | Acc: 48.011,69.334,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.879 | Acc: 47.927,69.101,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.887 | Acc: 47.917,69.017,90.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.055 | Acc: 43.750,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.560 | Acc: 41.406,55.543,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.561 | Acc: 41.349,55.316,65.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.533 | Acc: 40.958,55.251,66.150,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 2.007 | Acc: 38.281,66.406,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.859 | Acc: 48.065,68.713,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.860 | Acc: 47.732,68.921,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.838 | Acc: 48.553,69.429,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.830 | Acc: 48.283,70.062,91.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.825 | Acc: 48.175,70.475,91.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.819 | Acc: 48.528,70.513,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.827 | Acc: 48.288,70.329,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.834 | Acc: 48.049,70.109,91.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.843 | Acc: 47.941,69.898,91.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.843 | Acc: 48.119,69.935,91.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.849 | Acc: 48.148,69.828,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.853 | Acc: 48.081,69.677,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.855 | Acc: 48.195,69.636,91.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.857 | Acc: 48.132,69.579,91.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.862 | Acc: 48.082,69.461,91.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.865 | Acc: 48.121,69.434,91.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.869 | Acc: 48.165,69.389,91.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.873 | Acc: 48.100,69.356,90.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.875 | Acc: 48.060,69.357,90.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.083 | Acc: 46.094,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.399 | Acc: 42.708,58.891,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.391 | Acc: 41.959,58.498,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.400 | Acc: 41.445,58.478,67.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 1.545 | Acc: 55.469,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.807 | Acc: 49.851,71.057,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.821 | Acc: 49.276,70.141,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.821 | Acc: 48.835,70.018,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.810 | Acc: 48.698,70.380,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.814 | Acc: 48.909,70.343,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.821 | Acc: 48.773,70.177,91.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.830 | Acc: 48.720,69.980,91.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.833 | Acc: 48.675,70.007,91.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.831 | Acc: 48.619,69.959,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.834 | Acc: 48.706,69.939,91.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.838 | Acc: 48.731,69.892,91.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.844 | Acc: 48.512,69.820,91.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.847 | Acc: 48.482,69.744,91.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.850 | Acc: 48.538,69.743,91.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.855 | Acc: 48.487,69.669,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.865 | Acc: 48.321,69.385,91.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.869 | Acc: 48.364,69.371,90.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.874 | Acc: 48.286,69.311,90.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.881 | Acc: 48.271,69.285,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.015 | Acc: 40.625,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.458 | Acc: 38.876,57.812,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.471 | Acc: 39.043,57.146,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.483 | Acc: 38.525,57.518,66.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 1.771 | Acc: 54.688,73.438,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.853 | Acc: 48.698,69.345,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.831 | Acc: 48.133,70.236,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.841 | Acc: 48.105,69.775,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.846 | Acc: 48.274,69.657,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.839 | Acc: 48.615,69.848,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.843 | Acc: 48.844,69.893,91.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.841 | Acc: 48.842,69.770,91.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.840 | Acc: 48.792,69.905,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.847 | Acc: 48.532,69.855,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.849 | Acc: 48.500,69.772,91.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.852 | Acc: 48.356,69.630,91.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.852 | Acc: 48.476,69.667,91.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.855 | Acc: 48.393,69.609,91.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.855 | Acc: 48.532,69.537,91.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.857 | Acc: 48.528,69.500,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.857 | Acc: 48.601,69.570,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.864 | Acc: 48.449,69.424,91.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.866 | Acc: 48.496,69.401,90.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.868 | Acc: 48.503,69.324,90.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.000 | Acc: 46.094,59.375,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.355 | Acc: 42.783,58.073,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.367 | Acc: 43.331,58.022,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.384 | Acc: 42.994,57.761,67.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 1.527 | Acc: 53.125,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.801 | Acc: 47.879,69.643,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.819 | Acc: 48.476,69.607,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.804 | Acc: 48.719,70.351,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.821 | Acc: 48.621,70.168,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.817 | Acc: 48.770,70.142,91.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.823 | Acc: 48.780,70.067,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.830 | Acc: 48.543,69.858,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.834 | Acc: 48.612,69.759,91.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.838 | Acc: 48.463,69.687,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.838 | Acc: 48.531,69.733,91.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.839 | Acc: 48.498,69.719,91.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.842 | Acc: 48.454,69.687,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.849 | Acc: 48.488,69.585,91.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.853 | Acc: 48.365,69.534,91.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.858 | Acc: 48.196,69.453,91.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.863 | Acc: 48.243,69.385,90.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.869 | Acc: 48.197,69.288,90.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.873 | Acc: 48.206,69.276,90.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.876 | Acc: 48.208,69.162,90.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.372 | Acc: 43.750,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.366 | Acc: 42.225,57.812,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.381 | Acc: 42.397,58.022,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.390 | Acc: 41.983,58.133,66.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 1.746 | Acc: 57.031,71.094,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.835 | Acc: 49.516,69.866,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.836 | Acc: 48.647,69.646,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.816 | Acc: 48.630,70.133,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.808 | Acc: 49.064,70.168,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.810 | Acc: 48.909,70.297,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.824 | Acc: 48.392,70.022,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.833 | Acc: 48.094,69.936,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.834 | Acc: 48.229,70.128,91.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.840 | Acc: 48.222,70.114,91.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.846 | Acc: 48.095,69.881,91.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.842 | Acc: 48.148,69.987,91.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.844 | Acc: 48.159,69.943,91.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.851 | Acc: 48.159,69.831,91.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.854 | Acc: 48.193,69.787,90.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.861 | Acc: 48.087,69.700,90.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.864 | Acc: 48.128,69.655,90.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.866 | Acc: 48.188,69.586,90.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.869 | Acc: 48.141,69.605,90.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.874 | Acc: 48.089,69.459,90.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.226 | Acc: 42.969,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.468 | Acc: 42.039,56.213,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.488 | Acc: 42.359,55.812,65.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.490 | Acc: 42.021,55.571,65.279,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 1.922 | Acc: 47.656,67.969,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.855 | Acc: 49.888,69.792,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.811 | Acc: 50.076,71.437,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.822 | Acc: 49.334,70.799,91.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.823 | Acc: 48.679,70.621,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.830 | Acc: 48.662,70.305,91.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.830 | Acc: 48.560,70.267,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.835 | Acc: 48.465,70.163,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.830 | Acc: 48.433,70.254,91.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.832 | Acc: 48.489,70.200,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.837 | Acc: 48.325,70.262,91.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.842 | Acc: 48.367,70.320,91.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.847 | Acc: 48.376,70.173,91.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.852 | Acc: 48.324,69.995,91.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.860 | Acc: 48.265,69.837,91.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.866 | Acc: 48.217,69.630,90.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.869 | Acc: 48.158,69.526,90.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.875 | Acc: 48.204,69.483,90.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.878 | Acc: 48.223,69.436,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.886 | Acc: 48.134,69.269,90.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.097 | Acc: 41.406,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.459 | Acc: 41.406,57.366,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.490 | Acc: 40.358,56.860,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.509 | Acc: 40.164,56.109,66.611,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 1.872 | Acc: 44.531,72.656,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.850 | Acc: 48.586,69.643,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.845 | Acc: 48.323,70.884,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.844 | Acc: 48.399,70.300,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.837 | Acc: 48.438,69.994,91.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.828 | Acc: 48.368,70.196,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.829 | Acc: 48.457,70.235,91.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.831 | Acc: 48.382,70.235,91.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.828 | Acc: 48.598,70.293,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.830 | Acc: 48.731,70.213,91.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.835 | Acc: 48.783,70.044,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.837 | Acc: 48.731,70.037,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.842 | Acc: 48.632,69.995,91.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.845 | Acc: 48.623,69.944,91.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.847 | Acc: 48.613,69.951,91.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.851 | Acc: 48.539,69.897,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.853 | Acc: 48.491,69.872,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.856 | Acc: 48.410,69.870,90.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.862 | Acc: 48.310,69.778,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.867 | Acc: 48.245,69.685,90.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.059 | Acc: 39.844,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.306 | Acc: 42.225,58.557,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.358 | Acc: 41.578,57.965,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.353 | Acc: 41.419,58.414,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 1.678 | Acc: 46.094,73.438,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.808 | Acc: 49.888,70.461,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.797 | Acc: 49.867,70.446,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.814 | Acc: 48.668,70.274,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.813 | Acc: 49.132,70.100,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.811 | Acc: 49.389,70.235,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.802 | Acc: 49.658,70.519,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.805 | Acc: 49.640,70.412,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.811 | Acc: 49.306,70.177,92.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.820 | Acc: 49.081,69.972,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.818 | Acc: 49.044,69.994,91.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.822 | Acc: 48.876,69.910,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.826 | Acc: 48.788,69.888,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.829 | Acc: 48.725,69.902,91.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.834 | Acc: 48.691,69.859,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.841 | Acc: 48.656,69.767,91.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.845 | Acc: 48.615,69.663,91.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.850 | Acc: 48.584,69.572,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.856 | Acc: 48.593,69.417,91.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.861 | Acc: 48.581,69.388,90.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.175 | Acc: 42.969,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.268 | Acc: 43.229,59.598,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.292 | Acc: 43.007,58.689,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.300 | Acc: 42.585,58.811,68.135,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 1.830 | Acc: 53.125,67.188,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.788 | Acc: 49.442,70.945,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.811 | Acc: 49.276,70.770,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.827 | Acc: 48.681,70.248,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.822 | Acc: 48.553,70.390,91.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.820 | Acc: 48.786,70.429,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.819 | Acc: 48.663,70.493,91.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.826 | Acc: 48.548,70.501,91.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.825 | Acc: 48.670,70.477,91.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.835 | Acc: 48.545,70.218,91.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.832 | Acc: 48.496,70.312,91.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.832 | Acc: 48.551,70.355,91.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.833 | Acc: 48.570,70.390,91.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.837 | Acc: 48.491,70.312,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.845 | Acc: 48.429,70.118,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.849 | Acc: 48.453,70.105,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.855 | Acc: 48.430,69.901,90.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.859 | Acc: 48.403,69.841,90.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.864 | Acc: 48.323,69.724,90.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.867 | Acc: 48.351,69.673,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.282 | Acc: 44.531,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.400 | Acc: 41.741,59.077,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.373 | Acc: 41.902,58.594,66.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.372 | Acc: 41.739,58.402,66.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 1.718 | Acc: 48.438,69.531,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.807 | Acc: 49.554,71.354,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.809 | Acc: 49.181,70.846,92.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.797 | Acc: 49.065,70.863,92.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.788 | Acc: 49.190,71.084,92.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.794 | Acc: 48.940,70.947,92.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.805 | Acc: 48.722,70.551,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.812 | Acc: 48.548,70.379,92.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.815 | Acc: 48.549,70.448,91.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.824 | Acc: 48.463,70.192,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.830 | Acc: 48.410,70.060,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.835 | Acc: 48.441,70.044,91.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.836 | Acc: 48.438,69.966,91.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.834 | Acc: 48.512,70.055,91.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.838 | Acc: 48.540,70.032,91.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.843 | Acc: 48.492,69.887,91.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.848 | Acc: 48.513,69.814,91.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.854 | Acc: 48.488,69.637,91.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.859 | Acc: 48.485,69.557,90.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.861 | Acc: 48.503,69.542,90.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.925 | Acc: 48.438,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.404 | Acc: 42.039,57.180,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.419 | Acc: 42.016,57.527,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.447 | Acc: 41.432,57.339,66.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 2.005 | Acc: 49.219,60.156,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.784 | Acc: 49.926,70.759,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.799 | Acc: 49.428,70.465,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.787 | Acc: 49.308,70.838,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.783 | Acc: 49.151,70.785,92.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.780 | Acc: 49.304,70.661,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.779 | Acc: 49.219,70.681,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.780 | Acc: 49.130,70.689,92.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.779 | Acc: 49.267,70.657,92.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.786 | Acc: 49.232,70.425,92.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.788 | Acc: 49.289,70.534,92.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.790 | Acc: 49.399,70.553,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.799 | Acc: 49.332,70.462,91.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.811 | Acc: 49.201,70.289,91.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.813 | Acc: 49.133,70.376,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.816 | Acc: 49.115,70.390,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.825 | Acc: 49.061,70.220,91.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.834 | Acc: 48.889,70.044,91.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.840 | Acc: 48.870,69.916,91.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.848 | Acc: 48.835,69.773,91.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.510 | Acc: 45.312,62.500,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.531 | Acc: 39.286,56.176,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.566 | Acc: 39.939,56.879,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.584 | Acc: 39.626,56.826,66.611,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 1.781 | Acc: 41.406,73.438,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.782 | Acc: 48.921,71.801,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.762 | Acc: 49.733,71.684,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.771 | Acc: 49.603,71.504,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.758 | Acc: 49.981,71.653,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.762 | Acc: 49.822,71.535,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.771 | Acc: 49.638,71.378,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.783 | Acc: 49.352,70.916,92.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.791 | Acc: 49.418,70.730,92.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.795 | Acc: 49.331,70.649,92.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.802 | Acc: 49.320,70.542,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.806 | Acc: 49.236,70.426,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.811 | Acc: 48.953,70.342,91.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.815 | Acc: 48.881,70.390,91.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.818 | Acc: 48.763,70.312,91.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.822 | Acc: 48.715,70.307,91.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.826 | Acc: 48.766,70.315,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.822 | Acc: 48.969,70.274,91.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.828 | Acc: 48.953,70.200,91.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.832 | Acc: 48.878,70.103,91.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.996 | Acc: 44.531,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.382 | Acc: 40.811,58.259,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.423 | Acc: 40.644,57.622,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.412 | Acc: 40.702,57.672,66.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 1.553 | Acc: 48.438,71.094,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.758 | Acc: 48.475,70.759,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.793 | Acc: 48.114,70.312,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.801 | Acc: 47.823,70.300,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.805 | Acc: 48.052,70.293,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.798 | Acc: 48.221,70.583,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.805 | Acc: 48.412,70.338,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.805 | Acc: 48.676,70.357,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.808 | Acc: 48.598,70.332,91.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.813 | Acc: 48.718,70.338,91.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.816 | Acc: 48.764,70.359,91.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.819 | Acc: 48.646,70.270,91.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.825 | Acc: 48.554,70.274,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.829 | Acc: 48.506,70.151,91.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.832 | Acc: 48.499,70.048,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.837 | Acc: 48.606,69.972,91.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.843 | Acc: 48.537,69.828,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.844 | Acc: 48.570,69.825,91.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.849 | Acc: 48.561,69.745,90.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.852 | Acc: 48.569,69.738,90.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.075 | Acc: 43.750,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.391 | Acc: 43.118,58.185,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.386 | Acc: 43.407,57.908,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.406 | Acc: 42.700,57.287,66.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 1.887 | Acc: 42.969,65.625,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.838 | Acc: 48.996,69.903,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.805 | Acc: 49.390,70.541,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.812 | Acc: 48.732,70.466,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.806 | Acc: 48.920,70.583,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.802 | Acc: 49.149,70.583,92.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.799 | Acc: 49.206,70.713,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.799 | Acc: 49.041,70.551,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.800 | Acc: 49.107,70.560,91.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.805 | Acc: 49.059,70.498,91.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.807 | Acc: 49.110,70.449,91.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.811 | Acc: 49.123,70.351,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.810 | Acc: 49.044,70.507,91.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.814 | Acc: 49.009,70.432,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.823 | Acc: 48.863,70.315,91.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.832 | Acc: 48.816,70.100,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.835 | Acc: 48.842,70.040,91.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.842 | Acc: 48.822,69.962,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.847 | Acc: 48.777,69.919,91.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.850 | Acc: 48.761,69.898,91.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.195 | Acc: 46.875,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.538 | Acc: 40.402,56.510,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.561 | Acc: 40.149,56.021,65.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.556 | Acc: 40.164,55.712,65.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 2.181 | Acc: 41.406,62.500,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.862 | Acc: 47.805,69.643,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.847 | Acc: 48.628,70.103,91.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.817 | Acc: 49.078,70.453,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.825 | Acc: 49.142,70.139,91.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.835 | Acc: 49.172,69.763,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.825 | Acc: 49.367,70.209,91.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.829 | Acc: 49.086,70.213,91.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.834 | Acc: 49.025,70.046,91.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.833 | Acc: 49.042,70.062,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.840 | Acc: 48.947,69.947,91.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.837 | Acc: 48.993,69.973,91.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.844 | Acc: 48.849,69.911,91.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.847 | Acc: 48.886,69.866,91.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.848 | Acc: 48.779,69.784,91.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.851 | Acc: 48.845,69.760,90.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.852 | Acc: 48.861,69.743,90.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.854 | Acc: 48.836,69.792,90.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.860 | Acc: 48.758,69.700,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.862 | Acc: 48.749,69.660,90.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.183 | Acc: 39.844,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.464 | Acc: 39.100,57.478,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.466 | Acc: 38.510,57.508,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.471 | Acc: 38.179,57.121,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 1.595 | Acc: 52.344,75.000,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.781 | Acc: 49.368,70.908,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.772 | Acc: 49.333,70.808,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.759 | Acc: 49.206,71.094,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.761 | Acc: 49.450,70.910,93.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.756 | Acc: 49.636,71.078,92.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.765 | Acc: 49.432,70.990,92.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.763 | Acc: 49.579,71.094,92.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.772 | Acc: 49.432,70.807,92.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.781 | Acc: 49.353,70.757,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.783 | Acc: 49.355,70.682,92.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.794 | Acc: 49.258,70.525,92.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.802 | Acc: 49.196,70.394,92.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.810 | Acc: 49.060,70.366,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.818 | Acc: 48.957,70.240,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.824 | Acc: 48.923,70.079,91.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.825 | Acc: 48.956,70.098,91.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.828 | Acc: 48.891,70.060,91.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.827 | Acc: 48.944,70.087,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.831 | Acc: 48.932,70.042,91.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.943 | Acc: 46.875,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.302 | Acc: 43.006,60.231,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.348 | Acc: 42.816,59.680,67.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.345 | Acc: 42.303,59.273,67.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 1.837 | Acc: 50.000,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.838 | Acc: 48.140,70.759,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.822 | Acc: 48.056,70.808,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.796 | Acc: 48.194,71.004,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.789 | Acc: 48.061,71.200,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.793 | Acc: 48.414,71.156,91.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.801 | Acc: 48.328,71.100,91.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.810 | Acc: 48.493,70.795,91.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.816 | Acc: 48.418,70.672,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.813 | Acc: 48.757,70.796,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.815 | Acc: 48.884,70.756,91.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.816 | Acc: 48.816,70.666,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.820 | Acc: 48.852,70.617,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.822 | Acc: 48.952,70.690,91.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.831 | Acc: 48.813,70.479,91.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.835 | Acc: 48.749,70.406,91.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.838 | Acc: 48.771,70.376,90.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.841 | Acc: 48.712,70.299,90.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.845 | Acc: 48.769,70.180,90.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.849 | Acc: 48.739,70.140,90.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.296 | Acc: 36.719,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.367 | Acc: 42.299,57.068,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.337 | Acc: 42.759,58.213,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.349 | Acc: 42.034,57.774,67.405,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 1.706 | Acc: 50.781,74.219,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.778 | Acc: 49.777,70.499,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.770 | Acc: 49.486,71.684,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.768 | Acc: 49.347,71.542,92.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.777 | Acc: 49.161,71.248,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.765 | Acc: 49.335,71.380,92.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.763 | Acc: 49.270,71.649,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.764 | Acc: 49.418,71.426,92.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.764 | Acc: 49.461,71.351,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.763 | Acc: 49.469,71.461,92.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.771 | Acc: 49.339,71.249,92.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.774 | Acc: 49.339,71.009,92.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.781 | Acc: 49.404,70.877,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.788 | Acc: 49.389,70.806,91.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.795 | Acc: 49.397,70.699,91.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.796 | Acc: 49.369,70.653,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.801 | Acc: 49.250,70.583,91.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.807 | Acc: 49.194,70.411,91.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.815 | Acc: 49.139,70.306,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.825 | Acc: 49.065,70.163,91.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.306 | Acc: 46.875,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.471 | Acc: 42.039,56.808,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.465 | Acc: 41.997,56.517,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.483 | Acc: 41.739,56.199,66.137,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 1.625 | Acc: 48.438,73.438,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.737 | Acc: 50.260,73.140,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.752 | Acc: 50.553,72.447,92.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.772 | Acc: 49.910,71.670,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.772 | Acc: 49.547,71.557,92.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.773 | Acc: 49.358,71.566,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.773 | Acc: 49.374,71.513,92.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.783 | Acc: 49.041,71.121,92.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.789 | Acc: 48.865,71.006,92.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.792 | Acc: 48.964,70.990,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.798 | Acc: 48.873,70.822,91.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.803 | Acc: 48.759,70.620,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.804 | Acc: 48.921,70.604,91.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.810 | Acc: 48.949,70.582,91.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.816 | Acc: 49.030,70.485,91.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.818 | Acc: 48.985,70.520,91.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.821 | Acc: 48.927,70.471,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.821 | Acc: 48.976,70.500,91.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.826 | Acc: 48.966,70.356,91.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.835 | Acc: 48.846,70.146,91.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.101 | Acc: 45.312,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.481 | Acc: 41.034,56.957,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.496 | Acc: 41.463,56.326,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.494 | Acc: 41.099,56.468,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 1.550 | Acc: 50.781,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.747 | Acc: 49.628,72.321,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.752 | Acc: 49.276,72.123,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.760 | Acc: 49.308,72.221,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.756 | Acc: 49.508,71.981,92.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.759 | Acc: 49.675,71.658,92.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.756 | Acc: 49.819,71.701,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.769 | Acc: 49.540,71.559,92.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.773 | Acc: 49.568,71.443,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.780 | Acc: 49.322,71.245,91.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.787 | Acc: 49.355,71.090,91.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.792 | Acc: 49.297,70.935,91.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.797 | Acc: 49.300,70.932,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.801 | Acc: 49.207,70.797,91.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.801 | Acc: 49.205,70.749,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.808 | Acc: 49.019,70.551,91.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.814 | Acc: 49.051,70.446,91.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.820 | Acc: 48.964,70.420,91.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.827 | Acc: 48.907,70.276,91.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.830 | Acc: 48.889,70.189,91.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.946 | Acc: 40.625,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.336 | Acc: 42.150,59.561,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.382 | Acc: 41.444,59.413,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.378 | Acc: 41.163,59.273,67.725,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 1.820 | Acc: 50.000,68.750,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.760 | Acc: 50.595,71.243,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.745 | Acc: 50.019,71.875,92.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.754 | Acc: 50.243,71.824,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.757 | Acc: 50.367,71.566,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.765 | Acc: 50.108,71.395,92.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.773 | Acc: 49.877,70.990,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.777 | Acc: 49.712,70.911,92.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.769 | Acc: 49.898,71.113,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.771 | Acc: 49.685,71.133,92.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.771 | Acc: 49.666,71.012,92.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.772 | Acc: 49.671,70.974,92.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.782 | Acc: 49.488,70.802,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.786 | Acc: 49.407,70.753,91.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.794 | Acc: 49.238,70.671,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.798 | Acc: 49.242,70.642,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.804 | Acc: 49.197,70.595,91.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.811 | Acc: 49.116,70.496,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.816 | Acc: 49.065,70.464,91.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.820 | Acc: 48.987,70.425,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.004 | Acc: 46.875,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.352 | Acc: 42.225,58.185,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.400 | Acc: 41.482,57.851,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.376 | Acc: 41.714,58.094,67.533,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 1.578 | Acc: 50.000,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.753 | Acc: 50.930,72.470,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.771 | Acc: 50.267,72.180,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.782 | Acc: 49.795,71.670,91.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.782 | Acc: 49.566,71.537,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.796 | Acc: 49.397,71.140,91.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.793 | Acc: 49.580,71.010,91.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.797 | Acc: 49.457,70.850,91.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.796 | Acc: 49.267,70.773,91.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.796 | Acc: 49.301,70.835,91.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.799 | Acc: 49.230,70.686,91.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.802 | Acc: 49.243,70.634,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.801 | Acc: 49.238,70.582,91.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.801 | Acc: 49.177,70.648,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.805 | Acc: 49.238,70.529,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.811 | Acc: 49.177,70.572,91.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.818 | Acc: 49.170,70.473,91.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.825 | Acc: 49.077,70.296,91.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.828 | Acc: 49.102,70.228,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.833 | Acc: 49.098,70.054,91.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.490 | Acc: 39.844,64.844,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.606 | Acc: 38.653,55.618,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.651 | Acc: 38.834,54.668,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.660 | Acc: 38.448,54.649,65.164,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 1.889 | Acc: 46.875,68.750,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.780 | Acc: 50.298,70.424,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.749 | Acc: 50.419,71.608,92.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.746 | Acc: 49.923,71.837,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.746 | Acc: 49.894,71.865,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.752 | Acc: 49.915,71.883,92.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.750 | Acc: 49.942,72.004,92.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.763 | Acc: 49.529,71.570,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.769 | Acc: 49.495,71.361,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.772 | Acc: 49.452,71.241,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.771 | Acc: 49.639,71.366,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.779 | Acc: 49.473,71.221,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.786 | Acc: 49.488,71.123,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.792 | Acc: 49.416,70.926,91.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.796 | Acc: 49.369,70.844,91.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.800 | Acc: 49.349,70.780,91.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.806 | Acc: 49.379,70.646,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.809 | Acc: 49.427,70.567,91.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.813 | Acc: 49.407,70.553,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.819 | Acc: 49.282,70.419,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.361 | Acc: 46.875,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.538 | Acc: 41.555,56.362,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.547 | Acc: 41.044,55.755,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.540 | Acc: 40.523,56.007,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 1.734 | Acc: 53.125,69.531,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.757 | Acc: 50.484,71.726,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.769 | Acc: 49.752,71.837,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.765 | Acc: 49.846,71.478,92.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.779 | Acc: 49.441,71.316,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.766 | Acc: 49.667,71.550,92.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.771 | Acc: 49.535,71.591,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.770 | Acc: 49.402,71.476,92.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.767 | Acc: 49.447,71.530,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.776 | Acc: 49.305,71.279,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.782 | Acc: 49.021,71.226,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.782 | Acc: 49.145,71.221,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.786 | Acc: 49.196,71.116,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.789 | Acc: 49.228,71.088,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.794 | Acc: 49.224,70.927,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.801 | Acc: 49.110,70.751,91.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.805 | Acc: 49.104,70.665,91.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.808 | Acc: 49.129,70.597,91.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.811 | Acc: 49.126,70.607,91.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.817 | Acc: 49.092,70.513,91.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.073 | Acc: 44.531,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.343 | Acc: 41.815,59.189,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.411 | Acc: 41.006,58.518,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.389 | Acc: 40.561,58.184,66.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 1.931 | Acc: 46.094,71.094,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.769 | Acc: 48.847,72.098,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.766 | Acc: 49.390,71.799,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.774 | Acc: 49.219,71.542,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.787 | Acc: 49.180,71.460,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.785 | Acc: 49.482,71.272,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.792 | Acc: 49.406,71.152,91.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.792 | Acc: 49.291,71.077,91.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.795 | Acc: 49.097,70.968,91.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.796 | Acc: 49.184,70.973,91.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.804 | Acc: 49.149,70.666,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.806 | Acc: 49.141,70.609,91.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.807 | Acc: 49.144,70.607,91.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.814 | Acc: 49.129,70.495,91.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.818 | Acc: 48.991,70.415,91.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.817 | Acc: 49.079,70.450,91.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.819 | Acc: 49.097,70.466,91.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.822 | Acc: 49.040,70.464,91.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.825 | Acc: 49.061,70.470,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.831 | Acc: 49.106,70.321,90.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.998 | Acc: 43.750,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.283 | Acc: 41.443,59.412,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.345 | Acc: 41.311,58.556,67.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.362 | Acc: 40.932,58.197,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 1.593 | Acc: 50.000,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.733 | Acc: 51.711,71.540,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.732 | Acc: 51.696,71.837,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.751 | Acc: 50.909,71.414,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.763 | Acc: 50.463,71.074,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.773 | Acc: 50.255,70.955,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.777 | Acc: 49.923,71.074,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.773 | Acc: 49.939,70.950,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.765 | Acc: 49.918,71.133,92.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.764 | Acc: 49.978,71.146,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.764 | Acc: 49.903,71.253,92.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.769 | Acc: 49.837,71.104,92.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.771 | Acc: 49.828,71.045,91.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.776 | Acc: 49.784,70.971,91.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.786 | Acc: 49.608,70.810,91.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.796 | Acc: 49.471,70.595,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.802 | Acc: 49.370,70.507,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.803 | Acc: 49.386,70.558,91.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.806 | Acc: 49.414,70.507,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.809 | Acc: 49.352,70.487,91.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.404 | Acc: 39.844,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.436 | Acc: 38.951,58.371,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.499 | Acc: 38.739,57.146,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.511 | Acc: 38.755,56.916,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 1.740 | Acc: 47.656,70.312,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.800 | Acc: 49.740,71.652,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.778 | Acc: 49.943,71.780,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.778 | Acc: 49.705,71.760,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.783 | Acc: 49.344,71.325,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.777 | Acc: 49.443,71.457,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.781 | Acc: 49.341,71.468,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.775 | Acc: 49.330,71.493,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.779 | Acc: 49.316,71.312,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.782 | Acc: 49.465,71.245,91.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.784 | Acc: 49.607,71.183,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.786 | Acc: 49.601,71.055,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.787 | Acc: 49.682,71.058,91.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.790 | Acc: 49.587,70.866,91.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.797 | Acc: 49.508,70.785,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.802 | Acc: 49.437,70.702,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.810 | Acc: 49.404,70.653,91.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.818 | Acc: 49.232,70.560,91.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.821 | Acc: 49.258,70.520,91.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.824 | Acc: 49.243,70.503,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.203 | Acc: 42.969,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.348 | Acc: 41.853,57.552,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.415 | Acc: 42.073,57.412,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.435 | Acc: 41.752,57.748,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 1.708 | Acc: 60.156,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.735 | Acc: 50.558,73.772,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.731 | Acc: 50.724,73.609,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.719 | Acc: 50.628,73.245,92.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.714 | Acc: 50.395,73.177,92.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.722 | Acc: 50.340,72.842,92.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.720 | Acc: 50.278,72.656,92.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.713 | Acc: 50.449,72.712,92.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.730 | Acc: 50.058,72.394,92.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.731 | Acc: 50.186,72.397,92.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.738 | Acc: 50.155,72.314,92.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.741 | Acc: 50.110,72.165,92.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.745 | Acc: 50.172,72.044,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.753 | Acc: 49.967,71.839,92.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.760 | Acc: 49.819,71.611,92.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.767 | Acc: 49.824,71.470,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.777 | Acc: 49.691,71.157,91.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.784 | Acc: 49.679,71.055,91.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.792 | Acc: 49.580,70.877,91.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.798 | Acc: 49.502,70.794,91.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.199 | Acc: 41.406,65.625,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.468 | Acc: 38.951,57.329,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.517 | Acc: 38.853,56.593,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.544 | Acc: 38.345,55.904,67.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 1.748 | Acc: 43.750,67.188,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.821 | Acc: 47.433,69.792,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.794 | Acc: 48.647,70.617,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.784 | Acc: 48.578,70.748,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.783 | Acc: 48.765,70.872,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.778 | Acc: 49.149,71.055,92.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.780 | Acc: 49.103,71.023,92.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.780 | Acc: 49.125,71.155,92.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.782 | Acc: 48.932,71.147,92.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.788 | Acc: 48.908,71.059,92.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.791 | Acc: 48.993,71.000,92.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.800 | Acc: 48.883,70.790,91.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.801 | Acc: 48.953,70.841,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.798 | Acc: 49.162,70.944,91.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.801 | Acc: 49.227,70.849,91.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.812 | Acc: 49.172,70.723,91.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.816 | Acc: 49.204,70.695,91.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.816 | Acc: 49.278,70.652,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.821 | Acc: 49.357,70.594,91.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.826 | Acc: 49.280,70.485,91.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.069 | Acc: 46.875,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.400 | Acc: 42.336,58.594,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.431 | Acc: 42.016,58.060,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.433 | Acc: 41.701,57.492,66.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 1.733 | Acc: 49.219,70.312,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.795 | Acc: 48.958,71.429,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.783 | Acc: 48.780,71.189,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.778 | Acc: 49.001,71.452,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.765 | Acc: 49.441,71.518,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.750 | Acc: 49.706,71.813,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.749 | Acc: 49.787,71.798,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.752 | Acc: 49.945,71.692,92.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.751 | Acc: 49.990,71.715,92.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.752 | Acc: 49.892,71.668,92.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.760 | Acc: 49.852,71.506,92.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.763 | Acc: 49.834,71.603,92.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.762 | Acc: 49.802,71.648,92.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.769 | Acc: 49.767,71.465,92.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.773 | Acc: 49.800,71.436,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.783 | Acc: 49.608,71.249,91.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.790 | Acc: 49.572,71.082,91.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.793 | Acc: 49.533,71.059,91.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.798 | Acc: 49.543,71.044,91.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.800 | Acc: 49.582,71.028,91.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.379 | Acc: 45.312,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.410 | Acc: 41.034,57.254,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.428 | Acc: 41.406,56.707,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.408 | Acc: 41.291,56.929,66.829,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 1.788 | Acc: 50.781,69.531,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.785 | Acc: 48.884,69.903,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.752 | Acc: 50.019,70.865,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.750 | Acc: 50.166,71.376,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.754 | Acc: 50.010,71.325,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.753 | Acc: 49.915,71.627,92.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.758 | Acc: 49.813,71.404,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.761 | Acc: 49.861,71.415,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.765 | Acc: 49.709,71.341,91.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.778 | Acc: 49.499,71.038,91.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.785 | Acc: 49.452,71.020,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.789 | Acc: 49.463,70.906,91.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.798 | Acc: 49.348,70.718,91.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.801 | Acc: 49.318,70.624,91.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.804 | Acc: 49.352,70.566,91.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.806 | Acc: 49.341,70.520,91.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.807 | Acc: 49.396,70.566,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.812 | Acc: 49.349,70.480,91.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.816 | Acc: 49.452,70.408,91.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.818 | Acc: 49.350,70.433,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.725 | Acc: 45.312,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.280 | Acc: 44.234,58.891,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.275 | Acc: 44.817,59.394,68.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.265 | Acc: 44.288,59.580,68.455,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 1.647 | Acc: 53.125,72.656,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.798 | Acc: 49.479,71.615,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.749 | Acc: 51.010,72.409,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.758 | Acc: 50.909,71.965,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.766 | Acc: 50.463,71.441,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.763 | Acc: 50.387,71.411,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.760 | Acc: 50.368,71.494,92.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.760 | Acc: 50.332,71.759,92.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.764 | Acc: 50.131,71.632,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.774 | Acc: 49.901,71.396,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.775 | Acc: 50.008,71.327,91.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.775 | Acc: 50.113,71.327,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.779 | Acc: 50.052,71.308,91.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.783 | Acc: 49.967,71.207,91.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.787 | Acc: 49.972,71.116,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.793 | Acc: 49.798,71.063,91.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.801 | Acc: 49.701,70.872,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.803 | Acc: 49.702,70.883,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.805 | Acc: 49.673,70.841,91.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.807 | Acc: 49.664,70.741,91.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.254 | Acc: 46.094,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.360 | Acc: 43.564,57.812,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.344 | Acc: 42.778,58.327,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.345 | Acc: 42.482,58.081,67.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 1.618 | Acc: 46.875,72.656,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.751 | Acc: 49.442,71.987,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.737 | Acc: 50.362,71.951,92.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.718 | Acc: 50.717,72.285,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 50.627,72.396,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.729 | Acc: 50.379,72.478,92.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.731 | Acc: 50.271,72.379,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.734 | Acc: 50.310,72.124,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.735 | Acc: 50.150,72.273,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.740 | Acc: 50.203,72.108,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.741 | Acc: 50.218,72.073,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.744 | Acc: 50.230,72.006,92.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.746 | Acc: 50.191,71.975,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.759 | Acc: 50.048,71.806,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.768 | Acc: 49.975,71.689,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.777 | Acc: 49.860,71.442,91.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.783 | Acc: 49.871,71.332,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.788 | Acc: 49.812,71.270,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.795 | Acc: 49.768,71.102,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.802 | Acc: 49.744,70.954,91.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.455 | Acc: 41.406,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.477 | Acc: 41.034,58.296,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.488 | Acc: 41.120,57.717,65.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.512 | Acc: 40.599,57.326,65.535,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 1.642 | Acc: 52.344,72.656,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.776 | Acc: 50.223,71.391,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.749 | Acc: 50.686,71.684,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.751 | Acc: 50.935,71.798,91.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.741 | Acc: 50.791,71.788,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.745 | Acc: 50.673,71.836,92.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.756 | Acc: 50.549,71.436,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.756 | Acc: 50.482,71.332,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.767 | Acc: 50.180,71.259,91.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.767 | Acc: 50.259,71.305,91.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.765 | Acc: 50.389,71.331,91.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.766 | Acc: 50.364,71.359,91.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.772 | Acc: 50.237,71.133,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.774 | Acc: 50.153,71.016,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.776 | Acc: 50.044,70.994,91.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.779 | Acc: 49.904,71.000,91.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.781 | Acc: 49.920,70.940,91.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.785 | Acc: 49.885,70.885,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.794 | Acc: 49.784,70.739,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.795 | Acc: 49.815,70.801,91.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.005 | Acc: 42.969,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.315 | Acc: 42.448,60.417,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.301 | Acc: 42.626,59.947,67.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.342 | Acc: 42.072,59.068,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 1.710 | Acc: 53.906,71.875,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.697 | Acc: 50.707,73.028,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.737 | Acc: 50.191,71.856,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.737 | Acc: 50.141,71.901,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.733 | Acc: 50.222,71.875,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.744 | Acc: 50.178,71.890,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.739 | Acc: 50.065,71.978,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.748 | Acc: 50.188,71.781,92.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.751 | Acc: 50.121,71.729,92.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.756 | Acc: 49.953,71.763,92.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.760 | Acc: 49.759,71.708,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.762 | Acc: 49.823,71.674,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.762 | Acc: 49.880,71.629,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.765 | Acc: 49.799,71.522,91.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.769 | Acc: 49.780,71.394,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.772 | Acc: 49.774,71.343,91.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.780 | Acc: 49.774,71.254,91.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.784 | Acc: 49.819,71.192,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.791 | Acc: 49.686,71.027,91.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.798 | Acc: 49.639,70.940,91.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.232 | Acc: 40.625,61.719,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.416 | Acc: 43.304,58.780,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.404 | Acc: 42.778,58.594,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.414 | Acc: 42.354,58.491,66.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 1.557 | Acc: 56.250,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.774 | Acc: 49.256,71.949,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.743 | Acc: 49.695,72.046,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.735 | Acc: 50.307,71.965,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.742 | Acc: 50.068,71.981,92.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.741 | Acc: 50.170,72.068,92.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.754 | Acc: 49.690,71.726,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.758 | Acc: 49.651,71.714,92.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.757 | Acc: 49.782,71.953,92.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.755 | Acc: 49.961,71.918,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.758 | Acc: 49.798,71.716,92.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.758 | Acc: 49.834,71.727,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.763 | Acc: 49.711,71.619,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.765 | Acc: 49.844,71.573,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.771 | Acc: 49.850,71.452,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.775 | Acc: 49.860,71.322,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.782 | Acc: 49.808,71.218,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.786 | Acc: 49.704,71.137,91.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.789 | Acc: 49.701,71.094,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.790 | Acc: 49.627,71.061,91.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.236 | Acc: 45.312,57.031,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.545 | Acc: 41.443,55.580,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.560 | Acc: 41.063,55.164,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.565 | Acc: 41.060,55.187,65.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 1.934 | Acc: 45.312,66.406,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.730 | Acc: 50.149,72.582,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.742 | Acc: 49.524,72.008,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.757 | Acc: 49.488,71.837,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.748 | Acc: 49.537,72.261,92.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.755 | Acc: 49.722,72.123,92.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.750 | Acc: 50.116,71.901,92.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.753 | Acc: 50.083,71.897,92.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.753 | Acc: 50.073,72.001,92.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.760 | Acc: 49.978,71.897,92.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.770 | Acc: 49.860,71.786,92.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.773 | Acc: 49.731,71.684,92.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.775 | Acc: 49.763,71.590,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.777 | Acc: 49.722,71.537,91.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.777 | Acc: 49.805,71.547,91.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.781 | Acc: 49.842,71.499,91.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.787 | Acc: 49.740,71.403,91.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.788 | Acc: 49.874,71.357,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.789 | Acc: 49.866,71.319,91.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.791 | Acc: 49.910,71.229,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.217 | Acc: 39.062,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.404 | Acc: 42.597,58.110,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.463 | Acc: 41.616,57.127,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.510 | Acc: 41.214,57.172,66.035,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 1.758 | Acc: 49.219,79.688,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.754 | Acc: 48.624,71.131,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.746 | Acc: 49.257,71.742,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.751 | Acc: 49.027,71.632,92.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.755 | Acc: 49.547,71.721,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.756 | Acc: 49.776,71.481,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.749 | Acc: 49.897,71.610,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.754 | Acc: 49.945,71.543,92.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.753 | Acc: 50.189,71.390,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.762 | Acc: 50.026,71.284,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.767 | Acc: 49.887,71.214,91.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.773 | Acc: 49.795,71.143,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.778 | Acc: 49.883,71.052,91.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.786 | Acc: 49.743,70.980,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.792 | Acc: 49.625,70.902,91.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.800 | Acc: 49.494,70.821,91.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.802 | Acc: 49.411,70.802,91.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.807 | Acc: 49.496,70.759,91.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.811 | Acc: 49.520,70.713,91.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.820 | Acc: 49.416,70.532,91.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.017 | Acc: 45.312,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.425 | Acc: 42.299,59.412,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.443 | Acc: 41.578,58.918,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.423 | Acc: 41.176,58.581,66.790,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 1.734 | Acc: 46.094,71.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.812 | Acc: 48.884,71.466,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.826 | Acc: 49.295,71.075,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.799 | Acc: 49.936,71.491,91.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.793 | Acc: 49.961,71.431,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.785 | Acc: 49.977,71.295,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.788 | Acc: 49.600,71.352,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.777 | Acc: 49.856,71.465,91.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.774 | Acc: 49.874,71.506,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.774 | Acc: 50.082,71.305,91.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.781 | Acc: 49.938,71.164,91.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.783 | Acc: 49.887,71.203,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.783 | Acc: 49.874,71.249,91.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.787 | Acc: 49.802,71.246,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.786 | Acc: 49.780,71.350,91.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.787 | Acc: 49.852,71.294,91.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.792 | Acc: 49.810,71.237,91.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.791 | Acc: 49.892,71.272,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.798 | Acc: 49.779,71.148,91.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.798 | Acc: 49.770,71.166,91.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.172 | Acc: 46.094,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.424 | Acc: 40.625,58.780,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.438 | Acc: 40.835,57.965,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.430 | Acc: 40.791,57.915,66.829,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 1.888 | Acc: 42.969,68.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.784 | Acc: 48.772,70.722,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.760 | Acc: 50.152,71.513,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.742 | Acc: 50.166,71.811,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.743 | Acc: 50.174,71.798,92.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.740 | Acc: 50.193,71.929,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.729 | Acc: 50.265,72.146,92.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.732 | Acc: 49.961,72.041,92.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.735 | Acc: 49.845,71.953,92.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.731 | Acc: 49.892,72.009,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.738 | Acc: 49.876,71.898,92.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.742 | Acc: 49.866,71.833,92.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.742 | Acc: 49.867,71.843,92.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.744 | Acc: 49.808,71.698,92.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.754 | Acc: 49.705,71.508,92.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.762 | Acc: 49.655,71.470,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.765 | Acc: 49.742,71.473,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.769 | Acc: 49.700,71.424,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.771 | Acc: 49.753,71.332,91.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.774 | Acc: 49.748,71.280,91.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.996 | Acc: 49.219,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.249 | Acc: 43.824,58.631,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.270 | Acc: 43.312,58.632,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.280 | Acc: 42.649,58.171,67.764,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 1.727 | Acc: 55.469,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.689 | Acc: 51.190,73.400,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.716 | Acc: 50.838,72.656,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.691 | Acc: 51.447,72.836,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.712 | Acc: 51.186,72.579,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.724 | Acc: 51.075,72.525,92.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.725 | Acc: 50.768,72.424,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.739 | Acc: 50.526,72.180,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.742 | Acc: 50.476,71.957,92.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.748 | Acc: 50.427,71.879,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.756 | Acc: 50.140,71.634,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.758 | Acc: 50.099,71.610,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.767 | Acc: 49.789,71.544,91.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.772 | Acc: 49.725,71.495,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.777 | Acc: 49.728,71.466,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.784 | Acc: 49.681,71.371,91.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.791 | Acc: 49.620,71.198,91.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.793 | Acc: 49.730,71.227,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.798 | Acc: 49.665,71.131,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.802 | Acc: 49.666,70.973,91.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.453 | Acc: 38.281,61.719,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.635 | Acc: 39.062,57.143,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.682 | Acc: 38.796,55.831,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.673 | Acc: 38.653,55.546,66.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 1.674 | Acc: 45.312,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.749 | Acc: 50.521,73.698,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.759 | Acc: 49.733,72.752,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.740 | Acc: 50.218,73.156,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.743 | Acc: 49.855,72.849,92.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.749 | Acc: 49.621,72.393,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.749 | Acc: 49.451,72.256,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.757 | Acc: 49.352,72.030,92.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.762 | Acc: 49.350,71.739,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.759 | Acc: 49.318,71.784,92.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.764 | Acc: 49.324,71.611,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.772 | Acc: 49.247,71.479,91.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.774 | Acc: 49.413,71.431,91.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.775 | Acc: 49.482,71.420,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.777 | Acc: 49.583,71.377,91.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.782 | Acc: 49.611,71.229,91.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.785 | Acc: 49.596,71.142,91.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.786 | Acc: 49.597,71.048,91.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.786 | Acc: 49.613,71.037,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.788 | Acc: 49.629,71.038,91.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.878 | Acc: 42.188,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.374 | Acc: 40.699,57.850,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.374 | Acc: 40.568,57.736,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.365 | Acc: 40.394,57.787,67.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 1.946 | Acc: 42.969,67.969,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.694 | Acc: 51.153,72.321,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.710 | Acc: 50.991,72.123,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.716 | Acc: 50.461,72.272,92.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.729 | Acc: 50.164,71.885,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.735 | Acc: 49.954,71.829,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.729 | Acc: 50.161,71.933,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.735 | Acc: 50.166,71.875,92.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.734 | Acc: 50.039,71.904,92.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.734 | Acc: 50.052,71.905,92.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.733 | Acc: 50.210,71.910,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.740 | Acc: 50.226,71.762,92.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.744 | Acc: 50.185,71.664,92.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.752 | Acc: 50.105,71.459,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.754 | Acc: 50.128,71.366,92.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.755 | Acc: 50.088,71.387,92.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.759 | Acc: 50.012,71.357,92.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.764 | Acc: 49.989,71.311,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.768 | Acc: 49.957,71.338,91.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.768 | Acc: 49.982,71.328,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.005 | Acc: 49.219,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.393 | Acc: 43.118,57.887,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.360 | Acc: 43.293,57.812,67.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.370 | Acc: 42.892,57.480,67.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 1.738 | Acc: 48.438,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.699 | Acc: 50.484,72.842,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.701 | Acc: 50.133,73.095,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.718 | Acc: 49.987,72.515,92.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.727 | Acc: 50.222,72.174,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.736 | Acc: 50.023,72.138,92.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.740 | Acc: 50.071,72.088,92.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.740 | Acc: 50.006,72.219,92.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.752 | Acc: 49.888,72.064,92.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.764 | Acc: 49.944,71.758,91.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.772 | Acc: 49.934,71.591,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.778 | Acc: 49.894,71.546,91.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.789 | Acc: 49.760,71.256,91.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.788 | Acc: 49.734,71.258,91.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.793 | Acc: 49.736,71.199,91.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.814 | Acc: 49.429,70.777,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.829 | Acc: 49.265,70.527,91.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.839 | Acc: 49.116,70.409,90.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.843 | Acc: 49.137,70.321,90.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.847 | Acc: 49.157,70.265,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.957 | Acc: 40.625,60.938,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.541 | Acc: 40.588,56.138,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.556 | Acc: 41.349,55.812,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.536 | Acc: 41.099,55.891,65.958,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 1.758 | Acc: 55.469,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.857 | Acc: 47.842,69.531,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.809 | Acc: 49.009,70.389,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.766 | Acc: 49.680,71.260,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.751 | Acc: 49.585,71.692,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.749 | Acc: 49.544,71.898,92.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.742 | Acc: 49.703,71.959,92.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.747 | Acc: 49.789,71.731,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.749 | Acc: 49.820,71.768,92.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.745 | Acc: 50.043,71.784,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.751 | Acc: 50.086,71.653,92.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.756 | Acc: 50.085,71.635,92.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.758 | Acc: 49.981,71.564,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.764 | Acc: 50.030,71.543,92.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.765 | Acc: 49.969,71.472,92.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.770 | Acc: 49.870,71.395,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.774 | Acc: 49.871,71.379,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.774 | Acc: 49.899,71.341,91.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.776 | Acc: 49.894,71.360,91.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.780 | Acc: 49.936,71.282,91.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.138 | Acc: 41.406,63.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.421 | Acc: 41.295,58.817,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.378 | Acc: 42.378,58.594,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.370 | Acc: 41.816,58.837,67.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 1.679 | Acc: 52.344,68.750,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.708 | Acc: 50.893,71.801,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.719 | Acc: 50.857,72.428,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.712 | Acc: 51.114,72.592,92.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.724 | Acc: 50.752,72.627,91.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.730 | Acc: 50.325,72.532,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.734 | Acc: 50.090,72.585,91.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.739 | Acc: 50.072,72.545,91.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.737 | Acc: 50.000,72.472,91.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.737 | Acc: 49.883,72.514,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.736 | Acc: 49.946,72.369,92.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.738 | Acc: 49.996,72.345,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.745 | Acc: 50.055,72.170,91.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.753 | Acc: 50.126,71.995,91.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.759 | Acc: 50.053,71.964,91.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.766 | Acc: 49.982,71.828,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.769 | Acc: 49.893,71.722,91.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.775 | Acc: 49.863,71.655,91.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.783 | Acc: 49.833,71.503,91.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.790 | Acc: 49.733,71.403,91.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.327 | Acc: 43.750,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.395 | Acc: 43.452,57.254,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.401 | Acc: 43.445,57.165,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.422 | Acc: 43.148,57.070,65.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 1.927 | Acc: 44.531,64.062,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.755 | Acc: 49.479,72.396,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.748 | Acc: 50.171,72.523,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.748 | Acc: 49.436,71.939,92.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.736 | Acc: 49.865,72.000,92.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.740 | Acc: 49.722,71.898,92.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.733 | Acc: 49.729,71.959,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.737 | Acc: 49.679,71.914,92.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.741 | Acc: 49.622,71.865,92.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.745 | Acc: 49.637,71.884,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.741 | Acc: 49.810,71.992,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.741 | Acc: 49.972,71.932,92.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.744 | Acc: 49.912,71.933,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.746 | Acc: 49.904,71.935,92.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.754 | Acc: 49.844,71.736,92.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.758 | Acc: 49.844,71.727,92.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.762 | Acc: 49.912,71.641,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.766 | Acc: 49.956,71.618,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.770 | Acc: 49.981,71.529,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.771 | Acc: 49.996,71.444,91.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.334 | Acc: 47.656,64.062,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.426 | Acc: 41.406,56.957,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.421 | Acc: 41.482,57.317,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.437 | Acc: 41.227,57.544,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 1.892 | Acc: 48.438,67.188,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.728 | Acc: 51.116,71.205,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.705 | Acc: 51.010,72.447,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.711 | Acc: 50.999,72.182,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.718 | Acc: 50.820,72.049,92.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.720 | Acc: 50.913,71.883,92.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.729 | Acc: 50.568,71.726,92.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.740 | Acc: 50.222,71.764,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.739 | Acc: 50.340,71.962,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.739 | Acc: 50.388,71.940,92.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.740 | Acc: 50.330,71.976,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.743 | Acc: 50.332,71.907,92.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.750 | Acc: 50.321,71.775,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.751 | Acc: 50.308,71.797,92.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.760 | Acc: 50.206,71.647,91.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.766 | Acc: 50.101,71.561,91.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.765 | Acc: 50.100,71.573,91.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.769 | Acc: 50.000,71.486,91.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.772 | Acc: 49.989,71.442,91.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.776 | Acc: 50.035,71.344,91.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.079 | Acc: 49.219,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.302 | Acc: 43.973,59.933,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.287 | Acc: 44.207,59.813,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.297 | Acc: 43.417,59.465,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 1.556 | Acc: 57.031,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.662 | Acc: 52.567,73.996,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.673 | Acc: 52.153,73.819,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.686 | Acc: 51.883,73.527,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 51.669,73.023,92.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.718 | Acc: 50.758,72.587,92.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.719 | Acc: 50.665,72.598,92.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.726 | Acc: 50.576,72.296,92.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.735 | Acc: 50.378,72.069,92.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.735 | Acc: 50.311,72.160,92.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.736 | Acc: 50.167,72.174,92.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.742 | Acc: 49.986,72.052,92.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.744 | Acc: 49.916,72.141,92.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.746 | Acc: 49.961,72.082,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.750 | Acc: 49.928,71.978,92.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.753 | Acc: 49.966,71.919,92.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.757 | Acc: 49.925,71.778,92.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.760 | Acc: 49.904,71.708,92.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.763 | Acc: 49.911,71.659,91.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.767 | Acc: 49.979,71.625,91.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.230 | Acc: 46.094,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.372 | Acc: 41.815,58.482,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.373 | Acc: 41.768,58.956,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.384 | Acc: 41.381,58.696,67.789,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 1.483 | Acc: 53.906,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.736 | Acc: 50.744,72.805,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.726 | Acc: 50.934,72.599,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.738 | Acc: 50.435,72.259,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.736 | Acc: 50.502,72.367,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.743 | Acc: 49.938,71.945,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.741 | Acc: 50.200,72.043,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.744 | Acc: 50.127,71.941,92.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.742 | Acc: 50.345,71.865,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.737 | Acc: 50.544,72.039,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.738 | Acc: 50.490,72.038,92.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.742 | Acc: 50.442,71.981,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.748 | Acc: 50.308,71.839,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.752 | Acc: 50.290,71.722,91.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.754 | Acc: 50.206,71.639,91.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.756 | Acc: 50.166,71.608,91.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.760 | Acc: 50.231,71.563,91.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.762 | Acc: 50.296,71.547,91.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.765 | Acc: 50.309,71.579,91.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.772 | Acc: 50.160,71.463,91.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.388 | Acc: 47.656,66.406,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.535 | Acc: 41.109,58.371,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.501 | Acc: 40.949,58.327,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.481 | Acc: 40.599,58.171,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 1.745 | Acc: 49.219,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.639 | Acc: 51.339,74.330,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.676 | Acc: 50.877,73.800,93.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.683 | Acc: 50.640,73.438,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.689 | Acc: 50.328,73.254,93.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.691 | Acc: 50.433,73.051,93.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.694 | Acc: 50.484,72.979,92.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.699 | Acc: 50.554,72.678,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.704 | Acc: 50.408,72.540,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.713 | Acc: 50.211,72.402,92.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.722 | Acc: 50.179,72.369,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.727 | Acc: 50.265,72.193,92.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.728 | Acc: 50.321,72.164,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.738 | Acc: 50.275,71.986,92.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.745 | Acc: 50.086,71.839,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.750 | Acc: 50.052,71.789,92.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.757 | Acc: 49.954,71.685,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.762 | Acc: 49.897,71.628,91.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.762 | Acc: 49.924,71.661,91.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.767 | Acc: 49.961,71.676,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.164 | Acc: 39.062,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.397 | Acc: 42.113,58.482,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.405 | Acc: 42.092,58.441,66.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.427 | Acc: 42.136,58.184,66.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 1.587 | Acc: 53.125,75.000,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.709 | Acc: 51.339,73.624,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.738 | Acc: 50.343,72.656,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.755 | Acc: 50.090,71.555,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.759 | Acc: 50.511,71.875,91.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.759 | Acc: 50.681,71.774,91.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.750 | Acc: 50.736,72.062,91.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.747 | Acc: 50.676,72.124,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.751 | Acc: 50.660,71.938,91.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.747 | Acc: 50.609,71.875,91.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.748 | Acc: 50.552,71.797,91.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.749 | Acc: 50.583,71.808,91.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.751 | Acc: 50.499,71.713,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.750 | Acc: 50.485,71.803,91.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.753 | Acc: 50.473,71.800,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.761 | Acc: 50.413,71.670,91.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.764 | Acc: 50.414,71.632,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.767 | Acc: 50.472,71.552,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.769 | Acc: 50.446,71.501,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.774 | Acc: 50.457,71.477,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.223 | Acc: 42.969,60.156,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.499 | Acc: 41.555,56.287,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.500 | Acc: 41.502,56.745,64.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.522 | Acc: 41.611,56.186,64.331,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 1.852 | Acc: 46.094,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.774 | Acc: 50.149,71.429,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.742 | Acc: 50.934,72.008,92.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.718 | Acc: 50.871,72.374,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.725 | Acc: 50.858,72.550,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.728 | Acc: 50.750,72.386,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.732 | Acc: 50.542,72.327,92.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.736 | Acc: 50.432,72.263,92.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.739 | Acc: 50.451,72.040,92.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.741 | Acc: 50.332,72.022,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.746 | Acc: 50.284,71.910,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.746 | Acc: 50.315,71.864,92.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.745 | Acc: 50.399,71.839,92.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.746 | Acc: 50.380,71.764,92.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.750 | Acc: 50.342,71.697,92.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.751 | Acc: 50.304,71.589,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.755 | Acc: 50.214,71.549,92.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.760 | Acc: 50.108,71.479,92.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.766 | Acc: 50.076,71.364,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.770 | Acc: 50.029,71.354,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.974 | Acc: 50.781,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.414 | Acc: 41.332,59.747,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.393 | Acc: 41.197,59.699,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.394 | Acc: 40.702,59.785,67.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 1.991 | Acc: 40.625,66.406,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.705 | Acc: 50.818,72.768,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.728 | Acc: 50.400,72.656,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.727 | Acc: 50.128,72.541,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 50.395,72.762,92.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.716 | Acc: 50.240,72.935,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.713 | Acc: 50.413,72.831,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.725 | Acc: 50.194,72.518,92.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.732 | Acc: 50.218,72.394,92.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.737 | Acc: 50.194,72.207,91.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.742 | Acc: 50.198,72.205,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.752 | Acc: 50.237,72.098,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.756 | Acc: 50.279,72.063,91.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.759 | Acc: 50.296,72.052,91.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.764 | Acc: 50.209,71.872,91.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.770 | Acc: 50.044,71.753,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.771 | Acc: 49.993,71.666,91.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.770 | Acc: 50.023,71.712,91.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.774 | Acc: 50.037,71.659,91.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.779 | Acc: 49.961,71.596,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.907 | Acc: 45.312,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.440 | Acc: 42.634,58.966,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.462 | Acc: 41.864,58.822,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.457 | Acc: 41.278,58.683,66.509,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 1.732 | Acc: 53.906,70.312,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.696 | Acc: 51.190,72.842,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.717 | Acc: 50.229,72.828,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.734 | Acc: 50.026,72.618,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.729 | Acc: 49.961,72.521,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.714 | Acc: 50.317,72.718,92.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.715 | Acc: 50.284,72.676,92.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.722 | Acc: 50.277,72.429,92.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.725 | Acc: 50.214,72.244,92.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.738 | Acc: 49.935,72.009,92.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.739 | Acc: 50.062,71.922,92.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.736 | Acc: 50.156,71.999,92.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.739 | Acc: 50.104,71.998,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.741 | Acc: 50.018,71.974,92.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.745 | Acc: 50.081,71.897,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.749 | Acc: 50.140,71.961,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.749 | Acc: 50.165,71.997,92.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.749 | Acc: 50.229,71.969,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.754 | Acc: 50.145,71.853,91.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.758 | Acc: 50.152,71.809,91.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.203 | Acc: 38.281,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.454 | Acc: 40.402,57.775,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.459 | Acc: 41.159,57.774,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.455 | Acc: 41.073,57.339,66.457,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 1.939 | Acc: 43.750,65.625,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.739 | Acc: 51.414,71.726,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.708 | Acc: 51.315,72.790,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.688 | Acc: 51.575,73.015,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 51.003,72.984,92.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.705 | Acc: 50.890,72.819,92.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.698 | Acc: 50.917,72.805,92.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.700 | Acc: 50.770,72.739,92.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.703 | Acc: 50.767,72.671,92.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.706 | Acc: 50.734,72.488,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.711 | Acc: 50.637,72.376,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.718 | Acc: 50.456,72.193,92.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.724 | Acc: 50.334,72.157,92.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.728 | Acc: 50.266,71.992,92.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.737 | Acc: 50.225,71.728,92.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.744 | Acc: 50.200,71.589,92.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.748 | Acc: 50.136,71.517,92.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.749 | Acc: 50.071,71.529,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.755 | Acc: 50.026,71.364,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.759 | Acc: 50.068,71.350,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.365 | Acc: 45.312,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.420 | Acc: 43.490,57.589,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.450 | Acc: 42.912,57.527,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.454 | Acc: 42.456,57.633,66.598,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 1.764 | Acc: 47.656,70.312,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.690 | Acc: 51.525,72.805,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.630 | Acc: 52.534,74.581,93.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.597 | Acc: 52.472,75.115,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.571 | Acc: 52.778,75.502,94.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.550 | Acc: 52.614,75.936,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.529 | Acc: 53.093,76.511,95.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.518 | Acc: 52.986,76.806,95.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.504 | Acc: 53.086,77.053,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.488 | Acc: 53.358,77.551,95.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.478 | Acc: 53.389,77.849,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.468 | Acc: 53.652,78.026,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.457 | Acc: 53.903,78.261,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.450 | Acc: 53.834,78.394,96.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.445 | Acc: 53.884,78.528,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.441 | Acc: 53.857,78.662,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.437 | Acc: 53.916,78.709,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.432 | Acc: 53.931,78.721,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.429 | Acc: 53.950,78.774,96.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.426 | Acc: 53.974,78.863,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.574 | Acc: 54.688,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.714 | Acc: 49.888,67.374,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.714 | Acc: 50.000,67.454,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.714 | Acc: 49.718,67.252,74.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 1.334 | Acc: 54.688,82.031,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.285 | Acc: 56.101,81.399,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.308 | Acc: 55.164,81.136,97.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.307 | Acc: 55.405,81.199,98.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.306 | Acc: 55.835,81.154,98.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.305 | Acc: 55.910,81.320,98.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.305 | Acc: 55.888,81.366,98.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.299 | Acc: 55.906,81.599,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.296 | Acc: 56.075,81.784,98.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.299 | Acc: 55.870,81.565,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.299 | Acc: 55.854,81.639,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.298 | Acc: 55.851,81.642,98.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.299 | Acc: 55.822,81.613,98.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.298 | Acc: 55.750,81.609,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.298 | Acc: 55.602,81.628,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.298 | Acc: 55.612,81.538,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.295 | Acc: 55.651,81.600,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.298 | Acc: 55.524,81.568,98.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.298 | Acc: 55.555,81.609,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.297 | Acc: 55.563,81.646,98.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.527 | Acc: 55.469,72.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.663 | Acc: 50.818,67.969,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.668 | Acc: 50.457,67.778,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.674 | Acc: 50.038,67.546,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.168 | Acc: 64.062,85.938,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.259 | Acc: 55.097,82.403,98.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.264 | Acc: 55.736,82.489,98.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.273 | Acc: 56.084,82.428,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.268 | Acc: 55.990,82.282,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.266 | Acc: 56.111,82.441,98.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.260 | Acc: 56.018,82.574,98.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.268 | Acc: 55.757,82.414,98.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.267 | Acc: 55.872,82.458,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.263 | Acc: 56.013,82.454,98.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.263 | Acc: 55.962,82.463,98.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.259 | Acc: 56.102,82.562,98.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.260 | Acc: 56.033,82.498,98.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.258 | Acc: 56.014,82.543,98.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.260 | Acc: 55.902,82.521,98.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.260 | Acc: 55.970,82.514,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.261 | Acc: 55.917,82.518,98.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.260 | Acc: 55.918,82.476,98.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.262 | Acc: 55.860,82.414,98.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.263 | Acc: 55.803,82.380,98.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.511 | Acc: 56.250,71.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.653 | Acc: 51.600,68.415,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.680 | Acc: 50.743,67.950,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.680 | Acc: 50.435,67.572,74.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.164 | Acc: 59.375,82.812,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.196 | Acc: 57.775,83.966,99.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.204 | Acc: 57.336,83.765,99.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.224 | Acc: 56.609,83.274,98.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.230 | Acc: 56.134,83.169,98.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.227 | Acc: 56.219,83.246,98.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.231 | Acc: 56.269,83.051,98.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.230 | Acc: 56.172,83.250,98.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.228 | Acc: 56.289,83.181,98.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.229 | Acc: 56.228,83.145,98.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.231 | Acc: 56.184,83.166,98.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.233 | Acc: 56.140,83.113,98.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.235 | Acc: 56.088,83.049,98.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.236 | Acc: 56.094,83.037,98.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.236 | Acc: 56.158,83.066,98.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.233 | Acc: 56.253,83.095,98.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.237 | Acc: 56.106,83.000,98.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.236 | Acc: 56.186,83.062,98.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.238 | Acc: 56.146,83.014,98.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.237 | Acc: 56.227,83.046,98.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.472 | Acc: 56.250,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.629 | Acc: 51.265,68.862,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.655 | Acc: 50.934,68.598,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.659 | Acc: 50.551,68.199,74.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.107 | Acc: 54.688,85.156,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.213 | Acc: 54.762,83.371,99.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.223 | Acc: 55.145,83.346,99.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.221 | Acc: 55.469,83.248,99.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.214 | Acc: 56.318,83.603,99.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.211 | Acc: 56.412,83.756,99.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.216 | Acc: 56.302,83.600,99.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.218 | Acc: 56.344,83.516,99.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.220 | Acc: 56.313,83.409,99.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.219 | Acc: 56.224,83.391,99.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.219 | Acc: 56.343,83.384,99.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.223 | Acc: 56.183,83.261,99.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.225 | Acc: 56.218,83.202,99.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.226 | Acc: 56.181,83.235,99.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.226 | Acc: 56.189,83.232,99.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.225 | Acc: 56.299,83.306,98.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.226 | Acc: 56.213,83.309,99.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.223 | Acc: 56.346,83.355,99.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.222 | Acc: 56.408,83.397,99.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.221 | Acc: 56.455,83.378,99.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.515 | Acc: 53.125,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.644 | Acc: 51.265,68.564,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.662 | Acc: 50.877,68.274,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.666 | Acc: 50.551,68.058,74.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.132 | Acc: 57.031,82.812,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.171 | Acc: 57.031,84.226,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.186 | Acc: 57.317,84.204,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.190 | Acc: 57.364,84.273,99.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.184 | Acc: 57.591,84.462,99.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.187 | Acc: 57.441,84.274,99.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.194 | Acc: 57.141,84.072,99.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.194 | Acc: 57.192,84.026,99.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.197 | Acc: 56.876,84.050,99.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.200 | Acc: 56.872,83.987,99.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.201 | Acc: 56.821,83.936,99.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.202 | Acc: 56.784,83.923,99.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.202 | Acc: 56.772,84.038,99.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.201 | Acc: 56.828,84.037,99.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.203 | Acc: 56.778,83.977,99.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.201 | Acc: 56.751,84.061,99.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.202 | Acc: 56.700,83.969,99.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.203 | Acc: 56.681,83.864,99.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.204 | Acc: 56.585,83.799,99.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.203 | Acc: 56.508,83.856,99.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.441 | Acc: 56.250,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.626 | Acc: 51.265,68.973,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.653 | Acc: 50.800,68.426,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.663 | Acc: 50.525,67.918,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.331 | Acc: 48.438,86.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.193 | Acc: 56.696,83.891,98.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.207 | Acc: 56.059,83.613,99.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.192 | Acc: 56.557,83.978,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.195 | Acc: 56.250,84.221,99.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.188 | Acc: 56.381,84.360,99.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.191 | Acc: 56.560,84.201,99.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.189 | Acc: 56.499,84.153,99.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.188 | Acc: 56.609,84.273,99.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.190 | Acc: 56.561,84.302,99.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.190 | Acc: 56.639,84.181,99.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.195 | Acc: 56.423,84.064,99.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.195 | Acc: 56.454,84.067,99.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.194 | Acc: 56.460,84.127,99.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.192 | Acc: 56.611,84.155,99.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.192 | Acc: 56.637,84.201,99.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.191 | Acc: 56.652,84.183,99.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.189 | Acc: 56.745,84.210,99.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.190 | Acc: 56.691,84.221,99.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.191 | Acc: 56.633,84.223,99.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.478 | Acc: 54.688,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.631 | Acc: 51.414,68.862,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.642 | Acc: 50.953,68.388,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.650 | Acc: 50.487,68.110,75.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.137 | Acc: 56.250,85.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.143 | Acc: 57.292,85.640,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.169 | Acc: 56.536,84.909,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.161 | Acc: 56.634,85.259,99.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.162 | Acc: 57.089,85.108,99.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.171 | Acc: 56.969,84.971,99.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.172 | Acc: 56.870,84.775,99.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.170 | Acc: 56.871,84.763,99.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.172 | Acc: 56.852,84.865,99.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.171 | Acc: 56.893,84.789,99.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.173 | Acc: 56.782,84.806,99.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.176 | Acc: 56.664,84.725,99.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.179 | Acc: 56.535,84.638,99.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.180 | Acc: 56.540,84.585,99.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.180 | Acc: 56.520,84.581,99.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.182 | Acc: 56.546,84.585,99.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.181 | Acc: 56.683,84.601,99.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.184 | Acc: 56.575,84.499,99.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.183 | Acc: 56.618,84.481,99.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.180 | Acc: 56.728,84.576,99.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.516 | Acc: 55.469,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.652 | Acc: 51.786,69.085,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.658 | Acc: 51.048,68.845,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.664 | Acc: 50.602,68.302,75.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.284 | Acc: 58.594,82.031,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.142 | Acc: 58.557,85.268,99.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.147 | Acc: 57.965,85.480,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.156 | Acc: 57.800,84.977,99.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.163 | Acc: 57.542,84.819,99.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.156 | Acc: 57.727,84.855,99.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.159 | Acc: 57.464,84.930,99.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.159 | Acc: 57.519,84.874,99.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.161 | Acc: 57.395,84.889,99.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.159 | Acc: 57.497,84.966,99.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.160 | Acc: 57.397,84.942,99.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.160 | Acc: 57.318,84.919,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.164 | Acc: 57.187,84.877,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.164 | Acc: 57.172,84.863,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.166 | Acc: 57.123,84.809,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.169 | Acc: 57.008,84.723,99.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.171 | Acc: 56.958,84.691,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.169 | Acc: 56.946,84.728,99.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.169 | Acc: 56.917,84.752,99.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.169 | Acc: 56.892,84.763,99.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.505 | Acc: 56.250,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.635 | Acc: 51.079,68.601,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.661 | Acc: 50.686,68.350,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.663 | Acc: 50.359,68.199,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 1.287 | Acc: 54.688,81.250,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.143 | Acc: 58.110,85.789,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.150 | Acc: 58.441,85.480,99.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.154 | Acc: 57.851,85.079,99.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.152 | Acc: 57.948,85.262,99.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.164 | Acc: 57.565,85.149,99.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.158 | Acc: 57.761,85.176,99.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.155 | Acc: 57.707,85.217,99.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.157 | Acc: 57.453,85.292,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.154 | Acc: 57.364,85.338,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.155 | Acc: 57.366,85.230,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.160 | Acc: 57.272,85.061,99.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.160 | Acc: 57.326,85.036,99.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.164 | Acc: 57.139,84.932,99.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.162 | Acc: 57.201,84.992,99.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.161 | Acc: 57.234,85.021,99.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.161 | Acc: 57.177,85.047,99.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.160 | Acc: 57.146,85.035,99.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.160 | Acc: 57.168,84.996,99.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.159 | Acc: 57.175,85.052,99.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.542 | Acc: 54.688,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.663 | Acc: 51.004,68.564,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.684 | Acc: 50.457,68.274,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.686 | Acc: 50.243,67.943,74.936,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.226 | Acc: 57.812,82.031,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.154 | Acc: 57.812,85.231,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.175 | Acc: 57.298,84.470,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.161 | Acc: 57.223,85.079,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.158 | Acc: 57.128,85.320,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.152 | Acc: 57.495,85.512,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.153 | Acc: 57.515,85.447,99.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.152 | Acc: 57.547,85.539,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.153 | Acc: 57.541,85.462,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.149 | Acc: 57.601,85.562,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.151 | Acc: 57.412,85.498,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.154 | Acc: 57.215,85.390,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.151 | Acc: 57.245,85.409,99.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.152 | Acc: 57.292,85.300,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.150 | Acc: 57.379,85.334,99.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.152 | Acc: 57.356,85.361,99.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.151 | Acc: 57.306,85.424,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.152 | Acc: 57.217,85.303,99.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.153 | Acc: 57.137,85.312,99.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.152 | Acc: 57.181,85.365,99.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.423 | Acc: 58.594,75.000,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.640 | Acc: 51.637,68.787,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.655 | Acc: 51.200,68.274,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.660 | Acc: 50.807,68.263,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.238 | Acc: 46.875,83.594,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.168 | Acc: 56.436,85.677,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.165 | Acc: 56.650,84.947,99.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.143 | Acc: 57.326,85.412,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.141 | Acc: 57.581,85.465,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.142 | Acc: 57.379,85.528,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.141 | Acc: 57.515,85.640,99.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.143 | Acc: 57.364,85.633,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.144 | Acc: 57.381,85.627,99.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.143 | Acc: 57.411,85.674,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.145 | Acc: 57.346,85.619,99.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.145 | Acc: 57.410,85.598,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.145 | Acc: 57.414,85.558,99.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.146 | Acc: 57.429,85.474,99.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.146 | Acc: 57.387,85.509,99.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.147 | Acc: 57.371,85.444,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.146 | Acc: 57.401,85.473,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.146 | Acc: 57.393,85.438,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.144 | Acc: 57.345,85.435,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.143 | Acc: 57.324,85.490,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.459 | Acc: 57.031,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.656 | Acc: 51.525,68.973,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.674 | Acc: 50.934,68.521,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.669 | Acc: 50.756,68.276,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.124 | Acc: 55.469,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.112 | Acc: 57.478,86.347,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.108 | Acc: 57.660,86.300,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.120 | Acc: 57.492,86.309,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.118 | Acc: 57.465,86.507,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.121 | Acc: 57.395,86.371,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.131 | Acc: 57.218,86.118,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.129 | Acc: 57.414,86.043,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.133 | Acc: 57.279,85.967,99.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.132 | Acc: 57.368,85.916,99.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.133 | Acc: 57.400,85.934,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.131 | Acc: 57.501,86.054,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.132 | Acc: 57.466,86.006,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.132 | Acc: 57.468,85.985,99.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.130 | Acc: 57.554,85.996,99.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.131 | Acc: 57.581,85.961,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.132 | Acc: 57.569,85.938,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.133 | Acc: 57.593,85.850,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.133 | Acc: 57.639,85.840,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.135 | Acc: 57.612,85.812,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.433 | Acc: 57.031,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.637 | Acc: 51.674,69.122,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.671 | Acc: 51.467,68.369,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.669 | Acc: 51.217,68.212,75.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.319 | Acc: 51.562,78.125,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.101 | Acc: 58.259,85.714,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.114 | Acc: 58.060,85.861,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.105 | Acc: 58.491,85.925,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.110 | Acc: 58.102,86.024,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.112 | Acc: 57.905,86.247,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.115 | Acc: 57.896,86.112,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.119 | Acc: 57.840,86.054,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.126 | Acc: 57.550,85.865,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.126 | Acc: 57.489,85.860,99.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.126 | Acc: 57.540,85.875,99.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.127 | Acc: 57.417,85.853,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.127 | Acc: 57.459,85.827,99.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.127 | Acc: 57.489,85.782,99.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.129 | Acc: 57.443,85.732,99.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.129 | Acc: 57.423,85.782,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.131 | Acc: 57.382,85.796,99.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.130 | Acc: 57.418,85.795,99.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.130 | Acc: 57.419,85.786,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.129 | Acc: 57.425,85.792,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.471 | Acc: 56.250,71.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.641 | Acc: 51.711,68.899,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.674 | Acc: 51.200,68.350,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.673 | Acc: 51.101,68.174,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.204 | Acc: 59.375,84.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.125 | Acc: 58.333,85.938,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.128 | Acc: 57.622,86.319,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.118 | Acc: 57.825,86.783,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.116 | Acc: 57.803,86.738,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.119 | Acc: 57.905,86.371,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.121 | Acc: 57.825,86.286,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.119 | Acc: 57.929,86.331,99.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.121 | Acc: 57.905,86.272,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.122 | Acc: 57.989,86.227,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.123 | Acc: 57.886,86.256,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.122 | Acc: 57.890,86.227,99.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.121 | Acc: 58.082,86.194,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.122 | Acc: 58.031,86.123,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.119 | Acc: 58.238,86.140,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.123 | Acc: 58.054,86.059,99.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.121 | Acc: 58.090,86.076,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.121 | Acc: 58.085,86.057,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.122 | Acc: 58.046,86.041,99.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.124 | Acc: 57.950,85.983,99.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.410 | Acc: 54.688,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 51.451,69.382,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.660 | Acc: 51.353,68.617,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.663 | Acc: 51.012,68.494,75.320,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.069 | Acc: 62.500,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.075 | Acc: 59.189,87.984,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.096 | Acc: 58.136,87.481,99.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.103 | Acc: 58.069,87.193,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.106 | Acc: 58.285,86.796,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.107 | Acc: 58.083,86.711,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.107 | Acc: 58.135,86.706,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.112 | Acc: 58.023,86.508,99.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.109 | Acc: 58.254,86.559,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.110 | Acc: 58.231,86.451,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.111 | Acc: 58.170,86.388,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.109 | Acc: 58.219,86.386,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.111 | Acc: 58.107,86.245,99.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.112 | Acc: 58.010,86.162,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.115 | Acc: 57.938,86.115,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.116 | Acc: 57.958,86.034,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.116 | Acc: 57.990,86.091,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.117 | Acc: 57.957,86.034,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.118 | Acc: 57.895,86.005,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.118 | Acc: 57.841,85.964,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.465 | Acc: 55.469,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.647 | Acc: 51.302,69.122,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.681 | Acc: 50.667,68.559,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.678 | Acc: 50.499,68.379,75.038,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.085 | Acc: 62.500,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.086 | Acc: 59.449,86.347,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.097 | Acc: 59.051,86.490,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.091 | Acc: 58.940,86.552,99.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.093 | Acc: 58.777,86.593,99.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.095 | Acc: 58.764,86.409,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.092 | Acc: 58.891,86.712,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.098 | Acc: 58.727,86.658,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.102 | Acc: 58.511,86.593,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.106 | Acc: 58.391,86.460,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.109 | Acc: 58.279,86.353,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.109 | Acc: 58.201,86.365,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.108 | Acc: 58.133,86.362,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.110 | Acc: 58.067,86.336,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.110 | Acc: 58.068,86.368,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.110 | Acc: 58.025,86.358,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.110 | Acc: 58.017,86.405,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.112 | Acc: 58.005,86.345,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.110 | Acc: 57.981,86.364,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.111 | Acc: 57.960,86.327,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.411 | Acc: 57.812,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.652 | Acc: 51.265,68.899,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.680 | Acc: 51.048,68.331,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.684 | Acc: 51.063,67.930,75.231,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.020 | Acc: 57.812,88.281,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.117 | Acc: 55.804,87.240,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.097 | Acc: 57.203,86.776,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.102 | Acc: 57.031,86.821,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.108 | Acc: 57.099,86.767,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.109 | Acc: 57.256,86.657,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.104 | Acc: 57.302,86.816,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.105 | Acc: 57.408,86.735,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.105 | Acc: 57.356,86.738,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.102 | Acc: 57.325,86.762,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.103 | Acc: 57.455,86.746,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.101 | Acc: 57.615,86.860,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.101 | Acc: 57.612,86.871,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.101 | Acc: 57.603,86.841,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.105 | Acc: 57.482,86.799,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.103 | Acc: 57.667,86.817,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.103 | Acc: 57.786,86.826,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.104 | Acc: 57.810,86.723,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.104 | Acc: 57.832,86.725,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.105 | Acc: 57.847,86.655,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.470 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.645 | Acc: 51.897,68.750,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.675 | Acc: 51.448,68.216,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.679 | Acc: 51.140,68.071,74.936,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.119 | Acc: 54.688,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.087 | Acc: 58.891,87.277,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.102 | Acc: 57.717,87.062,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.101 | Acc: 57.838,86.988,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.097 | Acc: 58.102,86.921,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.101 | Acc: 58.478,86.812,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.106 | Acc: 58.071,86.803,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.107 | Acc: 57.973,86.708,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.104 | Acc: 58.002,86.665,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.104 | Acc: 58.054,86.719,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.103 | Acc: 58.034,86.785,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.101 | Acc: 58.078,86.842,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.099 | Acc: 58.133,86.871,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.098 | Acc: 58.169,86.847,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.099 | Acc: 58.091,86.894,99.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.100 | Acc: 58.041,86.830,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.101 | Acc: 58.012,86.855,99.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.101 | Acc: 58.076,86.767,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.100 | Acc: 58.085,86.753,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.099 | Acc: 58.126,86.727,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.444 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.662 | Acc: 51.860,68.155,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.687 | Acc: 51.410,67.931,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.688 | Acc: 50.948,67.918,74.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 0.922 | Acc: 63.281,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.076 | Acc: 58.296,87.835,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.087 | Acc: 58.136,87.138,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.093 | Acc: 57.889,86.898,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.087 | Acc: 58.266,87.143,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.087 | Acc: 58.068,87.198,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.091 | Acc: 57.922,87.203,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.092 | Acc: 58.023,87.129,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.092 | Acc: 57.992,87.107,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.088 | Acc: 58.054,87.241,99.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.090 | Acc: 58.046,87.275,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.088 | Acc: 58.152,87.341,99.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.089 | Acc: 58.253,87.254,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.090 | Acc: 58.211,87.132,99.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.092 | Acc: 58.143,87.133,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.092 | Acc: 58.106,87.178,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.093 | Acc: 58.107,87.140,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.093 | Acc: 58.067,87.124,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.093 | Acc: 58.068,87.115,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.096 | Acc: 57.960,86.994,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.462 | Acc: 54.688,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.652 | Acc: 51.042,68.266,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.682 | Acc: 50.591,67.950,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.680 | Acc: 50.525,67.687,74.962,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 1.022 | Acc: 59.375,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.050 | Acc: 60.082,87.723,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.061 | Acc: 59.165,87.367,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.070 | Acc: 58.786,87.602,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.065 | Acc: 58.980,87.693,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.067 | Acc: 58.895,87.778,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.070 | Acc: 58.574,87.713,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.071 | Acc: 58.588,87.566,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.074 | Acc: 58.657,87.524,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.079 | Acc: 58.486,87.319,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.078 | Acc: 58.547,87.321,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.077 | Acc: 58.721,87.408,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.079 | Acc: 58.581,87.403,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.081 | Acc: 58.495,87.371,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.082 | Acc: 58.399,87.247,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.083 | Acc: 58.376,87.225,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.085 | Acc: 58.253,87.184,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.087 | Acc: 58.209,87.099,99.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.088 | Acc: 58.191,87.143,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.091 | Acc: 58.108,87.065,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.478 | Acc: 55.469,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.646 | Acc: 51.414,68.564,76.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.683 | Acc: 51.239,67.835,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.686 | Acc: 50.999,67.879,75.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.230 | Acc: 55.469,82.031,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.098 | Acc: 58.817,86.830,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.104 | Acc: 57.241,86.947,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.095 | Acc: 58.120,87.077,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.093 | Acc: 58.275,87.153,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.095 | Acc: 58.006,87.075,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.097 | Acc: 58.064,86.880,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.097 | Acc: 58.023,86.940,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.095 | Acc: 57.977,87.068,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.092 | Acc: 58.050,87.198,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.088 | Acc: 58.104,87.123,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.091 | Acc: 57.915,87.069,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.089 | Acc: 57.897,87.033,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.087 | Acc: 58.067,87.108,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.089 | Acc: 57.993,87.008,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.089 | Acc: 57.937,87.030,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.089 | Acc: 57.944,87.004,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.090 | Acc: 57.959,86.932,99.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.090 | Acc: 57.938,86.942,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.089 | Acc: 57.962,86.975,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.423 | Acc: 56.250,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.653 | Acc: 51.637,68.378,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.687 | Acc: 51.562,68.216,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.688 | Acc: 51.255,67.738,75.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 1.060 | Acc: 57.812,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.067 | Acc: 58.780,88.244,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.060 | Acc: 59.223,88.624,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.059 | Acc: 59.580,88.179,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.055 | Acc: 59.327,88.204,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.066 | Acc: 59.112,88.096,99.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.071 | Acc: 59.026,87.739,99.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.071 | Acc: 59.009,87.727,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.077 | Acc: 58.662,87.660,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.074 | Acc: 58.732,87.720,99.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.075 | Acc: 58.718,87.722,99.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.074 | Acc: 58.838,87.641,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.074 | Acc: 58.791,87.581,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.076 | Acc: 58.725,87.503,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.076 | Acc: 58.741,87.525,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.075 | Acc: 58.718,87.555,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.077 | Acc: 58.691,87.551,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.080 | Acc: 58.543,87.489,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.080 | Acc: 58.522,87.481,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.081 | Acc: 58.436,87.428,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.447 | Acc: 57.031,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.644 | Acc: 51.823,68.490,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.669 | Acc: 51.200,68.197,75.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.670 | Acc: 50.897,67.994,75.307,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.063 | Acc: 54.688,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.070 | Acc: 58.519,88.393,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.061 | Acc: 59.165,88.434,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.063 | Acc: 59.362,88.345,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.071 | Acc: 58.864,88.156,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.074 | Acc: 58.748,87.941,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.080 | Acc: 58.465,87.732,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.080 | Acc: 58.549,87.655,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.081 | Acc: 58.472,87.524,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.077 | Acc: 58.568,87.530,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.076 | Acc: 58.516,87.613,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.078 | Acc: 58.474,87.592,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.078 | Acc: 58.402,87.549,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.078 | Acc: 58.360,87.554,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.077 | Acc: 58.394,87.472,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.078 | Acc: 58.396,87.435,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.077 | Acc: 58.445,87.468,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.079 | Acc: 58.344,87.493,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.078 | Acc: 58.341,87.498,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.079 | Acc: 58.364,87.465,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.481 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.649 | Acc: 51.228,68.601,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.685 | Acc: 51.029,68.007,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.686 | Acc: 50.948,68.058,75.346,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.048 | Acc: 55.469,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.078 | Acc: 57.478,87.649,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.080 | Acc: 57.851,87.824,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.079 | Acc: 57.889,87.871,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.072 | Acc: 58.092,87.741,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.069 | Acc: 58.230,87.709,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.071 | Acc: 58.400,87.668,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.073 | Acc: 58.428,87.572,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.074 | Acc: 58.375,87.646,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.073 | Acc: 58.412,87.617,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.069 | Acc: 58.567,87.788,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.071 | Acc: 58.491,87.684,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.073 | Acc: 58.419,87.613,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.073 | Acc: 58.333,87.617,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.074 | Acc: 58.369,87.608,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.073 | Acc: 58.371,87.575,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.074 | Acc: 58.406,87.571,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.076 | Acc: 58.291,87.576,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.075 | Acc: 58.418,87.578,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.076 | Acc: 58.395,87.549,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.513 | Acc: 54.688,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.665 | Acc: 51.823,68.155,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.698 | Acc: 51.315,68.236,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.703 | Acc: 51.217,67.879,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.017 | Acc: 67.188,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.039 | Acc: 59.896,87.872,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.046 | Acc: 59.375,87.691,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.056 | Acc: 59.452,87.871,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.051 | Acc: 59.655,88.088,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.050 | Acc: 59.499,88.188,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.048 | Acc: 59.375,88.236,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.048 | Acc: 59.297,88.237,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.052 | Acc: 58.972,88.174,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.052 | Acc: 59.094,88.074,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.054 | Acc: 59.010,88.044,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.055 | Acc: 58.961,88.013,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.058 | Acc: 58.902,88.045,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.059 | Acc: 58.818,87.994,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.060 | Acc: 58.766,87.942,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.062 | Acc: 58.775,87.887,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.061 | Acc: 58.752,87.863,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.061 | Acc: 58.724,87.906,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.064 | Acc: 58.641,87.851,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.066 | Acc: 58.559,87.822,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.427 | Acc: 57.812,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.650 | Acc: 51.190,69.196,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.699 | Acc: 50.934,68.216,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.697 | Acc: 50.948,67.994,75.295,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.045 | Acc: 63.281,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.049 | Acc: 60.789,88.281,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.044 | Acc: 59.489,88.357,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.054 | Acc: 59.029,88.217,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.057 | Acc: 58.883,88.185,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.053 | Acc: 58.919,88.096,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.059 | Acc: 58.762,88.023,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.060 | Acc: 58.677,88.032,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.057 | Acc: 58.676,88.199,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.058 | Acc: 58.797,88.130,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.058 | Acc: 58.874,88.099,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.058 | Acc: 58.845,88.041,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.060 | Acc: 58.824,87.980,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.061 | Acc: 58.740,87.892,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.063 | Acc: 58.777,87.859,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.062 | Acc: 58.801,87.941,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.063 | Acc: 58.730,87.894,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.064 | Acc: 58.646,87.841,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.065 | Acc: 58.615,87.831,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.065 | Acc: 58.729,87.814,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.458 | Acc: 55.469,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.667 | Acc: 52.269,68.378,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.695 | Acc: 51.524,68.007,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.694 | Acc: 51.204,67.853,75.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 0.916 | Acc: 61.719,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.036 | Acc: 59.301,89.137,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.039 | Acc: 59.337,88.605,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.046 | Acc: 58.991,88.409,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.049 | Acc: 58.758,88.484,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.051 | Acc: 58.888,88.444,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.050 | Acc: 59.065,88.365,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.053 | Acc: 58.976,88.248,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.052 | Acc: 59.050,88.223,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.055 | Acc: 58.987,88.091,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.057 | Acc: 58.784,88.001,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.058 | Acc: 58.827,87.907,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.058 | Acc: 58.798,87.860,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.057 | Acc: 58.956,87.916,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.059 | Acc: 58.902,87.867,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.058 | Acc: 58.983,87.931,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.059 | Acc: 58.857,87.945,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.060 | Acc: 58.805,87.889,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.060 | Acc: 58.802,87.937,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.061 | Acc: 58.791,87.861,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.473 | Acc: 57.031,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.667 | Acc: 51.749,68.750,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.685 | Acc: 51.239,68.350,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.694 | Acc: 51.063,68.122,75.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.046 | Acc: 50.781,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.042 | Acc: 57.999,88.356,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.055 | Acc: 58.251,88.567,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.053 | Acc: 58.466,88.473,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.042 | Acc: 58.835,88.715,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.050 | Acc: 58.656,88.451,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.052 | Acc: 58.600,88.294,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.055 | Acc: 58.677,88.265,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.055 | Acc: 58.579,88.262,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.055 | Acc: 58.585,88.268,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.056 | Acc: 58.757,88.211,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.057 | Acc: 58.749,88.182,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.057 | Acc: 58.655,88.171,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.058 | Acc: 58.603,88.132,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.058 | Acc: 58.655,88.151,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.057 | Acc: 58.698,88.185,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.058 | Acc: 58.616,88.147,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.060 | Acc: 58.543,88.098,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.058 | Acc: 58.665,88.134,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.059 | Acc: 58.612,88.072,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.483 | Acc: 55.469,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.670 | Acc: 51.711,68.341,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.701 | Acc: 51.162,67.740,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.696 | Acc: 50.961,67.866,75.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.040 | Acc: 57.812,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.023 | Acc: 59.635,88.988,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.036 | Acc: 58.899,88.853,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.046 | Acc: 58.965,88.665,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.050 | Acc: 58.767,88.445,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.044 | Acc: 59.120,88.614,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.044 | Acc: 59.168,88.565,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.047 | Acc: 58.943,88.447,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.045 | Acc: 58.929,88.606,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.048 | Acc: 58.693,88.514,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.049 | Acc: 58.722,88.503,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.050 | Acc: 58.650,88.472,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.051 | Acc: 58.594,88.375,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.050 | Acc: 58.660,88.362,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.052 | Acc: 58.633,88.259,99.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.053 | Acc: 58.617,88.193,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.055 | Acc: 58.562,88.189,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.054 | Acc: 58.603,88.160,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.054 | Acc: 58.646,88.112,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.056 | Acc: 58.629,88.080,99.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.428 | Acc: 57.812,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.656 | Acc: 51.786,68.080,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.695 | Acc: 51.086,67.759,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.695 | Acc: 50.794,67.572,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 0.979 | Acc: 64.062,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.065 | Acc: 59.449,86.830,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.070 | Acc: 58.346,87.519,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.049 | Acc: 58.863,88.102,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.044 | Acc: 59.018,88.436,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.043 | Acc: 59.066,88.521,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.042 | Acc: 59.272,88.436,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.045 | Acc: 59.214,88.370,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.045 | Acc: 59.341,88.330,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.047 | Acc: 59.254,88.311,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.045 | Acc: 59.340,88.293,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.046 | Acc: 59.205,88.239,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.047 | Acc: 59.174,88.216,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.049 | Acc: 59.109,88.156,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.049 | Acc: 59.075,88.106,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.050 | Acc: 59.032,88.113,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.049 | Acc: 58.998,88.121,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.049 | Acc: 59.041,88.176,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.049 | Acc: 59.050,88.147,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.051 | Acc: 58.914,88.130,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.407 | Acc: 54.688,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.653 | Acc: 51.600,68.490,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.686 | Acc: 51.143,68.445,75.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.692 | Acc: 51.050,68.302,75.499,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.198 | Acc: 54.688,83.594,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.047 | Acc: 57.292,88.839,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.046 | Acc: 58.117,89.082,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.046 | Acc: 58.005,89.203,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.039 | Acc: 58.497,89.188,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.040 | Acc: 58.787,89.086,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.044 | Acc: 58.632,88.888,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.042 | Acc: 58.782,88.896,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.042 | Acc: 58.929,88.912,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.046 | Acc: 58.835,88.795,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.042 | Acc: 59.021,88.942,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.042 | Acc: 58.944,88.974,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.040 | Acc: 58.967,88.943,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.043 | Acc: 58.917,88.796,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.043 | Acc: 58.947,88.670,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.043 | Acc: 58.929,88.590,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.044 | Acc: 58.840,88.529,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.044 | Acc: 58.821,88.478,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.047 | Acc: 58.719,88.368,99.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.048 | Acc: 58.711,88.263,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.427 | Acc: 54.688,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.659 | Acc: 50.632,68.452,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.691 | Acc: 50.534,67.816,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.700 | Acc: 50.730,67.687,75.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 1.018 | Acc: 53.906,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.012 | Acc: 60.938,89.211,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.011 | Acc: 60.575,89.329,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.026 | Acc: 59.503,89.101,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.026 | Acc: 59.500,89.265,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.030 | Acc: 59.298,89.155,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.032 | Acc: 59.233,88.933,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.035 | Acc: 59.176,88.863,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.032 | Acc: 59.322,88.946,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.032 | Acc: 59.319,88.886,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.031 | Acc: 59.429,88.954,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.032 | Acc: 59.287,88.882,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.035 | Acc: 59.168,88.855,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.038 | Acc: 59.019,88.748,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.041 | Acc: 58.877,88.723,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.042 | Acc: 58.760,88.655,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.042 | Acc: 58.803,88.615,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.042 | Acc: 58.839,88.588,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.044 | Acc: 58.832,88.550,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.043 | Acc: 58.883,88.509,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.446 | Acc: 56.250,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.651 | Acc: 51.302,68.192,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.678 | Acc: 51.124,67.931,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.682 | Acc: 50.845,67.738,75.038,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.040 | Acc: 57.031,85.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.002 | Acc: 60.751,89.025,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.013 | Acc: 60.175,89.405,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.007 | Acc: 60.067,89.280,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.014 | Acc: 60.012,89.400,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.027 | Acc: 59.344,89.039,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.030 | Acc: 59.214,88.920,99.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.031 | Acc: 59.120,88.885,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.035 | Acc: 59.191,88.733,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.036 | Acc: 59.133,88.657,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.037 | Acc: 59.017,88.635,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.038 | Acc: 58.937,88.652,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.038 | Acc: 59.035,88.673,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.039 | Acc: 59.106,88.584,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.038 | Acc: 59.069,88.626,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.040 | Acc: 59.087,88.559,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.040 | Acc: 59.046,88.598,99.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.040 | Acc: 59.006,88.595,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.042 | Acc: 59.020,88.517,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.043 | Acc: 58.957,88.449,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.431 | Acc: 54.688,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.660 | Acc: 50.893,67.932,76.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.697 | Acc: 51.067,67.702,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.697 | Acc: 50.961,67.444,75.269,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.131 | Acc: 54.688,83.594,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.047 | Acc: 58.891,88.132,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.040 | Acc: 58.479,88.662,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.031 | Acc: 58.171,88.883,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.032 | Acc: 58.584,88.802,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.033 | Acc: 58.516,88.745,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.034 | Acc: 58.652,88.811,99.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.036 | Acc: 58.494,88.813,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.034 | Acc: 58.618,88.791,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.033 | Acc: 58.788,88.786,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.031 | Acc: 58.967,88.845,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.033 | Acc: 58.965,88.783,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.031 | Acc: 59.005,88.855,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.031 | Acc: 59.013,88.838,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.034 | Acc: 58.989,88.765,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.035 | Acc: 58.890,88.710,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.037 | Acc: 58.818,88.736,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.037 | Acc: 58.894,88.684,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.039 | Acc: 58.773,88.656,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.039 | Acc: 58.789,88.671,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.456 | Acc: 57.812,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.672 | Acc: 51.860,68.118,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.706 | Acc: 51.124,67.950,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.706 | Acc: 50.948,67.636,75.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 0.941 | Acc: 57.812,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.041 | Acc: 58.557,89.137,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.052 | Acc: 58.651,88.758,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.032 | Acc: 59.375,89.011,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.029 | Acc: 59.462,89.149,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.032 | Acc: 59.414,89.109,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.036 | Acc: 59.272,88.933,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.037 | Acc: 59.070,89.002,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.038 | Acc: 59.079,88.961,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.037 | Acc: 59.012,88.955,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.031 | Acc: 59.286,89.031,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.031 | Acc: 59.308,88.939,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.033 | Acc: 59.265,88.894,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.036 | Acc: 59.118,88.886,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.034 | Acc: 59.114,88.857,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.036 | Acc: 59.061,88.834,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.034 | Acc: 59.093,88.819,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.037 | Acc: 59.004,88.746,99.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.037 | Acc: 59.016,88.725,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.036 | Acc: 59.024,88.720,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.435 | Acc: 56.250,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.660 | Acc: 51.562,68.638,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.707 | Acc: 51.067,67.550,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.704 | Acc: 50.935,67.277,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.125 | Acc: 57.031,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.035 | Acc: 59.375,88.132,99.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.040 | Acc: 58.651,88.453,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.043 | Acc: 58.376,88.499,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.036 | Acc: 58.382,88.850,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.032 | Acc: 58.455,89.086,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.032 | Acc: 58.568,89.095,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.038 | Acc: 58.461,88.957,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.038 | Acc: 58.492,88.917,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.037 | Acc: 58.555,88.911,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.034 | Acc: 58.617,88.938,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.033 | Acc: 58.717,88.967,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.033 | Acc: 58.756,88.897,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.034 | Acc: 58.788,88.883,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.032 | Acc: 58.883,88.921,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.034 | Acc: 58.833,88.878,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.033 | Acc: 58.879,88.875,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.032 | Acc: 58.903,88.865,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.033 | Acc: 58.888,88.853,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.032 | Acc: 58.856,88.909,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.375 | Acc: 57.031,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.651 | Acc: 51.637,68.564,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.692 | Acc: 50.953,68.426,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.690 | Acc: 51.012,68.212,75.269,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.148 | Acc: 54.688,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.002 | Acc: 59.338,90.402,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.011 | Acc: 59.546,89.901,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.022 | Acc: 59.068,89.421,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.022 | Acc: 59.153,89.477,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.021 | Acc: 59.058,89.457,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.020 | Acc: 59.233,89.418,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.023 | Acc: 59.092,89.328,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.024 | Acc: 59.098,89.310,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.025 | Acc: 59.051,89.218,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.027 | Acc: 58.912,89.156,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.025 | Acc: 59.018,89.172,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.025 | Acc: 59.057,89.205,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.027 | Acc: 58.965,89.173,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.027 | Acc: 58.950,89.121,99.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.028 | Acc: 58.944,89.107,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.026 | Acc: 59.046,89.145,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.026 | Acc: 59.084,89.122,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.027 | Acc: 59.122,89.047,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.027 | Acc: 59.108,89.011,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.570 | Acc: 55.469,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.657 | Acc: 51.488,68.452,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.692 | Acc: 51.258,67.969,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.696 | Acc: 51.242,67.713,75.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 0.969 | Acc: 65.625,88.281,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.035 | Acc: 58.817,88.951,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.024 | Acc: 59.756,89.215,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.032 | Acc: 59.106,89.165,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.027 | Acc: 59.394,88.889,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.033 | Acc: 59.035,88.769,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.033 | Acc: 59.226,88.649,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.034 | Acc: 59.192,88.580,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.032 | Acc: 59.346,88.606,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.030 | Acc: 59.388,88.683,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.029 | Acc: 59.344,88.755,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.027 | Acc: 59.382,88.836,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.030 | Acc: 59.236,88.816,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.031 | Acc: 59.252,88.844,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.028 | Acc: 59.381,88.960,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.028 | Acc: 59.331,88.972,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.027 | Acc: 59.309,89.031,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.028 | Acc: 59.309,88.985,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.030 | Acc: 59.247,88.928,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.031 | Acc: 59.201,88.952,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.418 | Acc: 53.906,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.675 | Acc: 51.228,67.299,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.715 | Acc: 51.010,67.264,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 50.794,67.252,74.898,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 0.915 | Acc: 67.969,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.986 | Acc: 60.826,90.551,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.996 | Acc: 60.747,89.996,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.995 | Acc: 60.656,90.036,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.996 | Acc: 60.629,89.882,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.005 | Acc: 60.087,89.805,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.007 | Acc: 59.950,89.631,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.014 | Acc: 59.741,89.406,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.015 | Acc: 59.535,89.344,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.019 | Acc: 59.539,89.300,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.020 | Acc: 59.530,89.307,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.020 | Acc: 59.591,89.236,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.020 | Acc: 59.599,89.260,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.019 | Acc: 59.585,89.359,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.020 | Acc: 59.631,89.277,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.024 | Acc: 59.484,89.143,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.023 | Acc: 59.426,89.145,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.024 | Acc: 59.446,89.111,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.023 | Acc: 59.442,89.160,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.024 | Acc: 59.373,89.136,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.463 | Acc: 55.469,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.680 | Acc: 51.153,68.266,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.727 | Acc: 50.819,67.416,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.730 | Acc: 50.564,67.034,75.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 0.967 | Acc: 62.500,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.030 | Acc: 58.705,88.802,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.002 | Acc: 59.604,88.986,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.017 | Acc: 58.901,88.922,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.017 | Acc: 58.864,89.053,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.023 | Acc: 58.841,88.962,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.019 | Acc: 59.097,89.217,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.016 | Acc: 59.336,89.301,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.015 | Acc: 59.482,89.363,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.012 | Acc: 59.604,89.369,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.014 | Acc: 59.530,89.416,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.013 | Acc: 59.622,89.480,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.013 | Acc: 59.647,89.490,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.015 | Acc: 59.611,89.425,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.015 | Acc: 59.550,89.457,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.017 | Acc: 59.497,89.356,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.018 | Acc: 59.419,89.369,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.018 | Acc: 59.446,89.333,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.018 | Acc: 59.468,89.307,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.019 | Acc: 59.463,89.263,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.510 | Acc: 55.469,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.698 | Acc: 50.781,68.118,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.726 | Acc: 50.381,67.835,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.722 | Acc: 50.346,67.713,75.307,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 0.886 | Acc: 64.062,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.977 | Acc: 59.859,90.662,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.984 | Acc: 60.232,90.701,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.998 | Acc: 59.593,90.113,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.003 | Acc: 59.626,89.882,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.006 | Acc: 59.599,89.612,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.013 | Acc: 59.388,89.418,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.016 | Acc: 59.303,89.356,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.015 | Acc: 59.244,89.456,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.019 | Acc: 59.237,89.283,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.019 | Acc: 59.181,89.230,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.018 | Acc: 59.272,89.264,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.014 | Acc: 59.385,89.377,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.015 | Acc: 59.363,89.389,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.017 | Acc: 59.386,89.327,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.017 | Acc: 59.468,89.299,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.015 | Acc: 59.502,89.355,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.015 | Acc: 59.545,89.308,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.016 | Acc: 59.494,89.251,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.016 | Acc: 59.525,89.253,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.489 | Acc: 55.469,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.668 | Acc: 51.079,68.080,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.706 | Acc: 50.686,67.511,75.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 50.692,67.405,75.435,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 0.914 | Acc: 64.062,95.312,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.988 | Acc: 61.682,90.551,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.997 | Acc: 60.575,90.168,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.008 | Acc: 60.169,89.882,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.998 | Acc: 60.407,90.037,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.004 | Acc: 60.149,89.898,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.004 | Acc: 60.298,89.844,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.000 | Acc: 60.522,89.822,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.999 | Acc: 60.457,89.824,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.000 | Acc: 60.398,89.788,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.002 | Acc: 60.152,89.789,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.002 | Acc: 60.188,89.777,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.002 | Acc: 60.224,89.795,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.004 | Acc: 60.078,89.793,99.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.005 | Acc: 59.912,89.738,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.007 | Acc: 59.777,89.670,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.010 | Acc: 59.743,89.605,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.010 | Acc: 59.744,89.594,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.013 | Acc: 59.604,89.536,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.015 | Acc: 59.469,89.520,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.437 | Acc: 54.688,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.659 | Acc: 51.711,68.266,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.689 | Acc: 51.239,68.121,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.700 | Acc: 50.832,68.007,75.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 0.986 | Acc: 60.938,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.946 | Acc: 61.644,91.667,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.965 | Acc: 61.700,91.006,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.979 | Acc: 61.078,90.574,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.985 | Acc: 60.725,90.413,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.992 | Acc: 60.319,90.246,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.000 | Acc: 59.988,89.915,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.003 | Acc: 60.007,89.727,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.000 | Acc: 60.205,89.776,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.002 | Acc: 59.992,89.701,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.003 | Acc: 59.915,89.642,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.005 | Acc: 59.941,89.504,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.006 | Acc: 59.936,89.484,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.007 | Acc: 59.956,89.464,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.006 | Acc: 60.103,89.471,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.010 | Acc: 59.938,89.392,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.010 | Acc: 59.862,89.372,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.011 | Acc: 59.797,89.342,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.013 | Acc: 59.788,89.294,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.013 | Acc: 59.752,89.317,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.541 | Acc: 54.688,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.693 | Acc: 51.674,68.490,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 50.991,67.854,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.729 | Acc: 51.025,67.456,75.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.019 | Acc: 62.500,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.988 | Acc: 61.272,90.216,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.987 | Acc: 60.785,90.568,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.998 | Acc: 59.977,90.241,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.999 | Acc: 60.204,90.278,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.005 | Acc: 59.955,90.153,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.007 | Acc: 59.911,89.934,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.009 | Acc: 59.818,89.833,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.009 | Acc: 59.851,89.858,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.008 | Acc: 59.940,89.891,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.008 | Acc: 59.760,89.937,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.007 | Acc: 59.810,89.918,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.005 | Acc: 59.913,89.915,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.006 | Acc: 59.845,89.871,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.005 | Acc: 59.859,89.874,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.005 | Acc: 59.876,89.818,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.004 | Acc: 59.884,89.841,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.008 | Acc: 59.801,89.727,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.009 | Acc: 59.760,89.701,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.010 | Acc: 59.740,89.669,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.557 | Acc: 55.469,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.686 | Acc: 51.265,68.043,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.725 | Acc: 50.972,67.626,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.725 | Acc: 50.871,67.316,75.038,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.075 | Acc: 58.594,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.008 | Acc: 59.449,89.807,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.992 | Acc: 60.118,90.320,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.993 | Acc: 59.746,89.946,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.990 | Acc: 60.214,89.786,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.992 | Acc: 60.017,89.828,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.993 | Acc: 59.937,89.863,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.991 | Acc: 59.957,89.949,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.992 | Acc: 59.991,89.883,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.996 | Acc: 59.798,89.801,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.001 | Acc: 59.647,89.684,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.005 | Acc: 59.633,89.607,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.004 | Acc: 59.615,89.656,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.007 | Acc: 59.561,89.577,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.007 | Acc: 59.531,89.655,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.005 | Acc: 59.699,89.665,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.005 | Acc: 59.674,89.683,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.006 | Acc: 59.698,89.686,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.007 | Acc: 59.760,89.595,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.009 | Acc: 59.689,89.546,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.481 | Acc: 52.344,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.703 | Acc: 51.079,68.006,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.729 | Acc: 50.762,67.454,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.731 | Acc: 50.666,67.482,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.046 | Acc: 64.844,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.997 | Acc: 59.821,90.327,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.008 | Acc: 59.508,89.863,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.997 | Acc: 59.772,90.215,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.996 | Acc: 59.886,90.287,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.997 | Acc: 59.800,90.114,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.002 | Acc: 59.511,90.076,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.002 | Acc: 59.397,90.043,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.002 | Acc: 59.457,89.941,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.000 | Acc: 59.574,89.978,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.001 | Acc: 59.530,89.980,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.002 | Acc: 59.502,89.960,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.004 | Acc: 59.437,89.879,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.005 | Acc: 59.384,89.805,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.006 | Acc: 59.356,89.749,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.007 | Acc: 59.359,89.693,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.008 | Acc: 59.409,89.673,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.008 | Acc: 59.435,89.702,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.009 | Acc: 59.423,89.671,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.008 | Acc: 59.521,89.665,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.595 | Acc: 56.250,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.698 | Acc: 51.153,68.378,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.729 | Acc: 50.781,67.759,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 50.768,67.495,75.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.073 | Acc: 59.375,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.989 | Acc: 60.082,90.290,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.983 | Acc: 60.213,90.644,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.987 | Acc: 59.862,90.484,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.984 | Acc: 60.195,90.403,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.987 | Acc: 60.203,90.269,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.993 | Acc: 60.008,90.218,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.995 | Acc: 60.012,90.171,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.998 | Acc: 59.802,90.111,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.999 | Acc: 59.681,90.111,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.999 | Acc: 59.678,90.104,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.003 | Acc: 59.403,89.953,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.002 | Acc: 59.492,89.960,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.003 | Acc: 59.519,89.898,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.003 | Acc: 59.531,89.910,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.004 | Acc: 59.484,89.916,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.004 | Acc: 59.450,89.873,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.004 | Acc: 59.425,89.885,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.004 | Acc: 59.386,89.898,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.004 | Acc: 59.459,89.899,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.553 | Acc: 56.250,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.700 | Acc: 51.972,68.415,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 51.372,67.702,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.736 | Acc: 51.191,67.636,75.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 0.985 | Acc: 60.156,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.967 | Acc: 60.789,90.216,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.956 | Acc: 60.709,90.701,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.972 | Acc: 60.143,90.292,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.975 | Acc: 60.204,90.451,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.987 | Acc: 59.785,90.246,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.988 | Acc: 59.814,90.289,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.991 | Acc: 59.868,90.187,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.993 | Acc: 59.841,90.164,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.995 | Acc: 59.759,90.116,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.997 | Acc: 59.729,90.112,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.997 | Acc: 59.827,90.077,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.995 | Acc: 59.832,90.103,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.998 | Acc: 59.752,90.020,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.001 | Acc: 59.703,89.997,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.003 | Acc: 59.689,89.942,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.005 | Acc: 59.604,89.909,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.004 | Acc: 59.588,89.951,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.003 | Acc: 59.604,89.939,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.004 | Acc: 59.574,89.881,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.604 | Acc: 52.344,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.712 | Acc: 50.484,67.150,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.752 | Acc: 50.229,66.940,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.748 | Acc: 50.525,67.021,74.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.080 | Acc: 57.812,87.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.972 | Acc: 60.193,90.327,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.985 | Acc: 59.756,89.996,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.991 | Acc: 59.695,90.113,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.989 | Acc: 59.905,90.085,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.992 | Acc: 59.785,90.114,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.990 | Acc: 59.995,90.141,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.992 | Acc: 59.940,90.143,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.997 | Acc: 59.836,89.989,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.998 | Acc: 59.971,90.016,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.997 | Acc: 60.079,89.984,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.995 | Acc: 60.146,90.028,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.996 | Acc: 60.108,90.016,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.996 | Acc: 60.096,89.996,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.997 | Acc: 60.078,89.952,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.998 | Acc: 60.058,89.940,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.000 | Acc: 59.971,89.944,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.000 | Acc: 59.987,89.908,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.001 | Acc: 59.979,89.857,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.003 | Acc: 59.900,89.846,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.640 | Acc: 52.344,67.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.735 | Acc: 50.446,67.188,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.746 | Acc: 50.648,67.016,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.754 | Acc: 50.218,66.842,74.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.051 | Acc: 57.031,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.984 | Acc: 60.491,89.918,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.989 | Acc: 59.985,90.168,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.982 | Acc: 60.284,90.190,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.992 | Acc: 59.896,90.017,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.996 | Acc: 59.785,89.890,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.986 | Acc: 60.227,90.154,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.989 | Acc: 59.979,90.160,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.993 | Acc: 59.821,90.101,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.993 | Acc: 59.833,90.077,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.992 | Acc: 59.869,90.069,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.993 | Acc: 59.870,89.999,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.992 | Acc: 59.978,90.035,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.995 | Acc: 59.824,89.993,99.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.995 | Acc: 59.917,89.988,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.995 | Acc: 59.902,89.979,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.998 | Acc: 59.828,89.948,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.998 | Acc: 59.888,89.908,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.997 | Acc: 59.964,89.881,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.000 | Acc: 59.873,89.795,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.484 | Acc: 57.031,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.691 | Acc: 51.637,68.824,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.718 | Acc: 51.239,67.873,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.725 | Acc: 51.114,67.520,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 0.970 | Acc: 60.156,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.983 | Acc: 59.821,90.588,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.973 | Acc: 60.252,90.568,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.978 | Acc: 60.220,90.049,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.985 | Acc: 60.137,90.056,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.986 | Acc: 60.365,90.037,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.990 | Acc: 60.240,90.076,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.987 | Acc: 60.073,90.243,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.986 | Acc: 60.093,90.295,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.988 | Acc: 60.096,90.280,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.990 | Acc: 60.195,90.240,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.992 | Acc: 60.071,90.254,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.993 | Acc: 60.023,90.246,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.992 | Acc: 60.048,90.221,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.995 | Acc: 59.981,90.183,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.995 | Acc: 60.024,90.140,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.996 | Acc: 59.893,90.097,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.996 | Acc: 59.913,90.080,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.995 | Acc: 59.914,90.084,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.996 | Acc: 59.832,90.104,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.500 | Acc: 53.906,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.685 | Acc: 51.823,68.192,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.719 | Acc: 51.353,67.302,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.719 | Acc: 51.524,67.444,75.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.083 | Acc: 52.344,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.000 | Acc: 59.040,90.625,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.981 | Acc: 59.851,90.739,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.970 | Acc: 60.489,90.907,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.972 | Acc: 60.417,90.828,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.976 | Acc: 60.280,90.687,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.979 | Acc: 60.189,90.722,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.981 | Acc: 59.918,90.691,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.982 | Acc: 59.996,90.572,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.983 | Acc: 60.083,90.461,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.985 | Acc: 60.012,90.470,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.985 | Acc: 60.047,90.452,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.983 | Acc: 60.124,90.469,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.982 | Acc: 60.117,90.442,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.985 | Acc: 60.045,90.369,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.983 | Acc: 60.213,90.355,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.985 | Acc: 60.232,90.301,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.987 | Acc: 60.209,90.194,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.989 | Acc: 60.117,90.153,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.989 | Acc: 60.068,90.143,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.485 | Acc: 57.031,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.712 | Acc: 51.823,68.304,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 51.124,67.607,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.736 | Acc: 50.973,67.277,75.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 0.902 | Acc: 58.594,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.935 | Acc: 61.310,91.592,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.960 | Acc: 60.137,90.911,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.969 | Acc: 60.079,90.958,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.975 | Acc: 60.002,90.702,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.974 | Acc: 60.071,90.764,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.973 | Acc: 60.079,90.677,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.974 | Acc: 60.184,90.619,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.977 | Acc: 60.113,90.552,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.981 | Acc: 59.949,90.483,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.985 | Acc: 59.845,90.470,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.985 | Acc: 59.824,90.409,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.990 | Acc: 59.644,90.359,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.990 | Acc: 59.638,90.335,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.990 | Acc: 59.720,90.341,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.991 | Acc: 59.658,90.337,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.990 | Acc: 59.713,90.345,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.991 | Acc: 59.664,90.254,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.992 | Acc: 59.628,90.229,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.992 | Acc: 59.613,90.237,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.601 | Acc: 53.125,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.725 | Acc: 50.967,67.188,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.747 | Acc: 50.819,67.111,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.749 | Acc: 50.640,67.213,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.026 | Acc: 58.594,86.719,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.967 | Acc: 60.007,90.848,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.969 | Acc: 60.595,91.368,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.971 | Acc: 60.797,91.265,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.976 | Acc: 60.667,90.876,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.975 | Acc: 60.435,90.826,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.978 | Acc: 60.402,90.625,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.979 | Acc: 60.428,90.481,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.981 | Acc: 60.433,90.392,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.978 | Acc: 60.648,90.418,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.979 | Acc: 60.654,90.403,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.981 | Acc: 60.467,90.353,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.983 | Acc: 60.364,90.336,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.984 | Acc: 60.330,90.344,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.985 | Acc: 60.348,90.294,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.987 | Acc: 60.296,90.262,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.987 | Acc: 60.349,90.262,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.989 | Acc: 60.280,90.181,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.991 | Acc: 60.247,90.114,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.992 | Acc: 60.183,90.108,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.573 | Acc: 53.906,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 51.488,67.522,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 51.029,67.359,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 51.050,67.264,74.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.074 | Acc: 51.562,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.005 | Acc: 58.705,90.997,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.001 | Acc: 58.899,90.492,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.998 | Acc: 58.863,90.394,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.992 | Acc: 59.423,90.577,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.992 | Acc: 59.855,90.478,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.992 | Acc: 59.782,90.444,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.989 | Acc: 59.791,90.509,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.989 | Acc: 60.030,90.382,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.991 | Acc: 59.984,90.271,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.990 | Acc: 60.086,90.139,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.988 | Acc: 60.142,90.134,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.989 | Acc: 60.163,90.132,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.989 | Acc: 60.057,90.128,99.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.991 | Acc: 60.039,90.063,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.991 | Acc: 60.001,90.025,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.992 | Acc: 60.005,89.997,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.992 | Acc: 59.996,89.979,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.993 | Acc: 59.871,89.997,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.992 | Acc: 59.890,90.039,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.499 | Acc: 52.344,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.719 | Acc: 51.004,67.597,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.741 | Acc: 50.762,67.283,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.733 | Acc: 50.973,67.456,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 0.979 | Acc: 60.938,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.992 | Acc: 61.310,90.067,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.977 | Acc: 60.842,90.568,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.986 | Acc: 60.374,90.561,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.985 | Acc: 60.503,90.374,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.986 | Acc: 60.295,90.478,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.983 | Acc: 60.486,90.457,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.985 | Acc: 60.289,90.431,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.982 | Acc: 60.452,90.489,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.981 | Acc: 60.346,90.573,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.982 | Acc: 60.393,90.598,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.979 | Acc: 60.421,90.614,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.981 | Acc: 60.270,90.534,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.980 | Acc: 60.276,90.541,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.984 | Acc: 60.184,90.447,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.986 | Acc: 60.112,90.415,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.985 | Acc: 60.185,90.357,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.985 | Acc: 60.282,90.359,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.986 | Acc: 60.219,90.350,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.986 | Acc: 60.185,90.365,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.512 | Acc: 55.469,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.719 | Acc: 50.595,68.006,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 50.362,67.435,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.746 | Acc: 50.397,67.572,74.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 0.948 | Acc: 59.375,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.955 | Acc: 60.640,90.960,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.961 | Acc: 60.061,90.892,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.964 | Acc: 60.297,90.740,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.968 | Acc: 60.282,90.548,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.974 | Acc: 60.002,90.501,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.976 | Acc: 59.995,90.502,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.981 | Acc: 59.630,90.514,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.978 | Acc: 59.821,90.576,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.979 | Acc: 59.850,90.621,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.980 | Acc: 59.935,90.582,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.983 | Acc: 59.852,90.522,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.985 | Acc: 59.793,90.466,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.986 | Acc: 59.719,90.487,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.985 | Acc: 59.800,90.492,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.984 | Acc: 59.811,90.449,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.985 | Acc: 59.830,90.369,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.987 | Acc: 59.808,90.307,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.988 | Acc: 59.775,90.303,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.987 | Acc: 59.845,90.272,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.472 | Acc: 56.250,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.707 | Acc: 51.376,67.708,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.732 | Acc: 50.800,67.416,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.744 | Acc: 50.871,66.867,75.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 0.982 | Acc: 57.812,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.968 | Acc: 61.086,90.699,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.965 | Acc: 60.537,90.511,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.961 | Acc: 60.989,90.779,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.971 | Acc: 60.629,90.635,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.967 | Acc: 60.396,90.803,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.964 | Acc: 60.557,90.890,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.967 | Acc: 60.383,90.858,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.967 | Acc: 60.370,90.872,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.966 | Acc: 60.359,90.949,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.970 | Acc: 60.199,90.831,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.971 | Acc: 60.163,90.887,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.972 | Acc: 60.202,90.865,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.972 | Acc: 60.210,90.814,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.971 | Acc: 60.298,90.797,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.972 | Acc: 60.276,90.752,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.974 | Acc: 60.229,90.700,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.976 | Acc: 60.195,90.659,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.978 | Acc: 60.128,90.573,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.978 | Acc: 60.076,90.570,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.529 | Acc: 56.250,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.734 | Acc: 51.600,67.671,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.762 | Acc: 51.086,67.416,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.770 | Acc: 50.871,67.059,75.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.048 | Acc: 57.031,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.961 | Acc: 61.161,92.522,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.964 | Acc: 60.537,91.921,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.969 | Acc: 60.515,91.445,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.969 | Acc: 60.696,91.319,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.971 | Acc: 60.729,91.213,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.971 | Acc: 60.576,91.180,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.974 | Acc: 60.461,90.969,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.972 | Acc: 60.578,90.970,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.972 | Acc: 60.519,90.923,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.971 | Acc: 60.560,90.893,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.971 | Acc: 60.559,90.925,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.971 | Acc: 60.500,90.865,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.975 | Acc: 60.450,90.742,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.975 | Acc: 60.423,90.747,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.977 | Acc: 60.369,90.698,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.980 | Acc: 60.356,90.681,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.980 | Acc: 60.321,90.632,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.982 | Acc: 60.256,90.588,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.982 | Acc: 60.226,90.617,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.489 | Acc: 55.469,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.710 | Acc: 52.121,67.857,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.740 | Acc: 51.753,67.588,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 51.486,67.303,75.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.008 | Acc: 59.375,88.281,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.970 | Acc: 60.193,91.034,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.981 | Acc: 59.718,90.835,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.973 | Acc: 60.015,91.163,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.975 | Acc: 59.925,90.934,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.978 | Acc: 59.940,90.950,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.975 | Acc: 59.872,90.967,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.973 | Acc: 59.924,90.902,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.971 | Acc: 60.176,91.018,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.972 | Acc: 60.130,90.992,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.975 | Acc: 60.094,90.963,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.972 | Acc: 60.199,90.936,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.974 | Acc: 60.156,90.810,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.974 | Acc: 60.162,90.715,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.975 | Acc: 60.190,90.672,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.974 | Acc: 60.200,90.724,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.977 | Acc: 60.137,90.671,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.976 | Acc: 60.188,90.662,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.977 | Acc: 60.165,90.640,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.977 | Acc: 60.169,90.619,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.532 | Acc: 53.125,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.713 | Acc: 51.190,67.932,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.754 | Acc: 50.934,67.397,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.759 | Acc: 50.499,67.008,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.176 | Acc: 55.469,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.966 | Acc: 59.970,91.853,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.975 | Acc: 60.575,90.168,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.974 | Acc: 60.528,90.138,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.964 | Acc: 60.889,90.721,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.962 | Acc: 60.945,90.996,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.966 | Acc: 60.808,90.993,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.970 | Acc: 60.633,90.980,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.970 | Acc: 60.583,91.013,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.972 | Acc: 60.584,91.001,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.971 | Acc: 60.646,90.971,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.972 | Acc: 60.612,90.954,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.974 | Acc: 60.497,90.839,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.975 | Acc: 60.477,90.820,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.975 | Acc: 60.401,90.772,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.976 | Acc: 60.416,90.690,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.977 | Acc: 60.402,90.652,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.979 | Acc: 60.367,90.572,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.978 | Acc: 60.334,90.597,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.979 | Acc: 60.304,90.598,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.544 | Acc: 53.125,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.751 | Acc: 51.339,66.853,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.771 | Acc: 50.877,66.825,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.766 | Acc: 51.050,66.662,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 1.018 | Acc: 55.469,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.952 | Acc: 61.533,90.625,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.945 | Acc: 60.957,91.101,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.958 | Acc: 61.002,91.009,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.955 | Acc: 61.082,91.146,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.962 | Acc: 60.752,91.012,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.966 | Acc: 60.808,91.012,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.968 | Acc: 60.760,91.007,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.967 | Acc: 60.671,90.921,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.969 | Acc: 60.584,90.906,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.973 | Acc: 60.452,90.854,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.972 | Acc: 60.577,90.880,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.971 | Acc: 60.643,90.956,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.972 | Acc: 60.689,90.927,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.971 | Acc: 60.673,90.914,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.971 | Acc: 60.636,90.911,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.973 | Acc: 60.543,90.856,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.972 | Acc: 60.543,90.804,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.974 | Acc: 60.461,90.759,99.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.975 | Acc: 60.447,90.771,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.590 | Acc: 56.250,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.719 | Acc: 51.079,68.638,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.749 | Acc: 50.991,67.721,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.746 | Acc: 50.986,67.777,75.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 0.897 | Acc: 62.500,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.953 | Acc: 61.607,91.332,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.963 | Acc: 60.842,91.254,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.968 | Acc: 60.220,91.214,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.970 | Acc: 60.378,90.953,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.977 | Acc: 60.280,90.772,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.976 | Acc: 60.343,90.896,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.972 | Acc: 60.478,90.891,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.971 | Acc: 60.540,90.979,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.969 | Acc: 60.631,91.018,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.970 | Acc: 60.560,90.955,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.972 | Acc: 60.421,90.855,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.973 | Acc: 60.386,90.862,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.974 | Acc: 60.264,90.858,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.973 | Acc: 60.320,90.870,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.971 | Acc: 60.387,90.895,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.972 | Acc: 60.426,90.842,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.974 | Acc: 60.417,90.751,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.973 | Acc: 60.403,90.709,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.973 | Acc: 60.437,90.721,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.520 | Acc: 54.688,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.732 | Acc: 51.972,67.485,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.757 | Acc: 51.486,67.359,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.752 | Acc: 51.191,67.252,75.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 0.979 | Acc: 60.938,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.954 | Acc: 61.421,91.071,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.942 | Acc: 61.528,91.273,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.949 | Acc: 60.963,91.176,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.944 | Acc: 61.169,91.146,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.952 | Acc: 60.876,90.919,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.954 | Acc: 60.789,90.928,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.957 | Acc: 60.721,90.841,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.958 | Acc: 60.724,90.921,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.956 | Acc: 60.726,90.966,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.957 | Acc: 60.619,91.018,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.960 | Acc: 60.619,90.933,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.959 | Acc: 60.805,90.930,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.963 | Acc: 60.725,90.855,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.965 | Acc: 60.621,90.859,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.966 | Acc: 60.559,90.866,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.967 | Acc: 60.485,90.883,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.969 | Acc: 60.417,90.836,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.972 | Acc: 60.392,90.809,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.972 | Acc: 60.449,90.781,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.638 | Acc: 51.562,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.755 | Acc: 50.260,66.927,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.779 | Acc: 50.038,66.883,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.776 | Acc: 50.269,66.931,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.091 | Acc: 50.781,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.979 | Acc: 60.156,90.997,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.963 | Acc: 61.223,91.387,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.970 | Acc: 60.387,90.932,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.963 | Acc: 60.831,91.184,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.959 | Acc: 60.984,91.159,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.962 | Acc: 60.731,91.135,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.965 | Acc: 60.600,91.046,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.969 | Acc: 60.549,90.965,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.968 | Acc: 60.562,90.979,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.967 | Acc: 60.529,90.994,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.970 | Acc: 60.517,90.954,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.970 | Acc: 60.604,90.975,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.971 | Acc: 60.494,90.897,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.970 | Acc: 60.554,90.886,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.971 | Acc: 60.538,90.859,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.972 | Acc: 60.497,90.800,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.972 | Acc: 60.468,90.783,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.972 | Acc: 60.539,90.731,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.971 | Acc: 60.546,90.748,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.656 | Acc: 52.344,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.751 | Acc: 51.153,67.708,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.781 | Acc: 50.495,67.283,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.778 | Acc: 50.845,67.047,75.038,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 0.870 | Acc: 61.719,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.952 | Acc: 59.152,91.964,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.965 | Acc: 59.813,91.654,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.964 | Acc: 59.810,91.329,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.959 | Acc: 60.041,91.175,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.963 | Acc: 60.203,91.019,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.970 | Acc: 59.995,90.774,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.972 | Acc: 60.245,90.802,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.970 | Acc: 60.205,90.868,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.968 | Acc: 60.273,90.953,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.968 | Acc: 60.436,90.963,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.968 | Acc: 60.375,90.947,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.967 | Acc: 60.403,90.982,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.968 | Acc: 60.390,91.017,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.971 | Acc: 60.237,90.973,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.970 | Acc: 60.239,91.045,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.971 | Acc: 60.210,91.012,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.973 | Acc: 60.149,90.953,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.973 | Acc: 60.180,90.960,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.973 | Acc: 60.146,90.969,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.521 | Acc: 52.344,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.744 | Acc: 50.893,67.634,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.776 | Acc: 50.819,66.806,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.768 | Acc: 50.653,66.816,75.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.022 | Acc: 59.375,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.956 | Acc: 60.751,91.629,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.964 | Acc: 60.118,91.368,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.968 | Acc: 60.681,91.176,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.964 | Acc: 60.465,91.184,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.967 | Acc: 60.489,91.228,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.969 | Acc: 60.356,91.122,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.966 | Acc: 60.483,91.052,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.962 | Acc: 60.637,91.159,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.960 | Acc: 60.722,91.203,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.960 | Acc: 60.735,91.243,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.961 | Acc: 60.771,91.198,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.961 | Acc: 60.866,91.147,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.961 | Acc: 60.809,91.146,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.963 | Acc: 60.737,91.134,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.965 | Acc: 60.561,91.058,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.965 | Acc: 60.512,91.073,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.966 | Acc: 60.491,91.005,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.965 | Acc: 60.492,90.984,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.966 | Acc: 60.488,90.947,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.471 | Acc: 57.031,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.745 | Acc: 50.893,67.411,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.786 | Acc: 50.495,67.168,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.787 | Acc: 50.845,66.906,75.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 0.884 | Acc: 66.406,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.964 | Acc: 60.007,91.257,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.960 | Acc: 60.423,91.254,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.960 | Acc: 60.553,91.227,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.959 | Acc: 60.648,91.300,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.961 | Acc: 60.659,91.236,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.959 | Acc: 60.673,91.174,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.956 | Acc: 60.777,91.196,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.961 | Acc: 60.491,91.149,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.960 | Acc: 60.540,91.117,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.955 | Acc: 60.790,91.095,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.957 | Acc: 60.743,91.109,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.958 | Acc: 60.694,91.066,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.960 | Acc: 60.587,91.038,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.963 | Acc: 60.484,91.014,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.966 | Acc: 60.473,90.944,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.966 | Acc: 60.509,90.915,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.968 | Acc: 60.431,90.872,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.968 | Acc: 60.494,90.889,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.968 | Acc: 60.423,90.838,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.460 | Acc: 56.250,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.725 | Acc: 50.744,68.304,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.753 | Acc: 50.534,67.530,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.762 | Acc: 50.666,67.354,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 0.918 | Acc: 69.531,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.980 | Acc: 60.677,91.146,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.974 | Acc: 60.252,91.235,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.954 | Acc: 60.963,91.278,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.958 | Acc: 60.889,91.300,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.960 | Acc: 60.481,91.298,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.956 | Acc: 60.679,91.348,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.958 | Acc: 60.583,91.290,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.961 | Acc: 60.312,91.338,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.961 | Acc: 60.432,91.307,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.963 | Acc: 60.195,91.227,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.964 | Acc: 60.146,91.180,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.965 | Acc: 60.179,91.196,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.966 | Acc: 60.198,91.176,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.968 | Acc: 60.190,91.092,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.968 | Acc: 60.133,91.095,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.969 | Acc: 60.202,90.980,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.968 | Acc: 60.294,90.953,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.969 | Acc: 60.351,90.969,99.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.968 | Acc: 60.417,90.961,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.450 | Acc: 54.688,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.719 | Acc: 51.711,67.820,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.749 | Acc: 51.029,67.397,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.749 | Acc: 51.204,67.405,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 0.899 | Acc: 63.281,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.945 | Acc: 61.830,91.146,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.960 | Acc: 60.785,90.835,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.950 | Acc: 61.117,91.112,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.955 | Acc: 60.986,90.992,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.955 | Acc: 60.938,90.973,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.955 | Acc: 60.860,91.200,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.957 | Acc: 60.638,91.257,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.955 | Acc: 60.797,91.261,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.954 | Acc: 60.821,91.320,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.955 | Acc: 60.755,91.259,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.958 | Acc: 60.679,91.229,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.958 | Acc: 60.746,91.218,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.957 | Acc: 60.770,91.242,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.958 | Acc: 60.684,91.223,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.960 | Acc: 60.616,91.191,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.961 | Acc: 60.480,91.160,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.962 | Acc: 60.452,91.152,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.964 | Acc: 60.420,91.147,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.965 | Acc: 60.476,91.062,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.563 | Acc: 53.125,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.772 | Acc: 51.451,66.295,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.799 | Acc: 51.048,66.216,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.790 | Acc: 50.948,66.124,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 0.975 | Acc: 61.719,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.947 | Acc: 62.128,91.443,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.950 | Acc: 61.223,91.635,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.954 | Acc: 61.066,91.470,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.949 | Acc: 61.169,91.618,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.950 | Acc: 61.007,91.569,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.950 | Acc: 60.931,91.671,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.950 | Acc: 60.777,91.689,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.948 | Acc: 60.889,91.702,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.948 | Acc: 60.864,91.665,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.947 | Acc: 60.930,91.682,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.947 | Acc: 61.033,91.731,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.947 | Acc: 60.980,91.711,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.951 | Acc: 60.812,91.640,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.952 | Acc: 60.687,91.554,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.954 | Acc: 60.613,91.471,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.954 | Acc: 60.624,91.431,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.955 | Acc: 60.610,91.404,99.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.956 | Acc: 60.554,91.367,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.959 | Acc: 60.445,91.296,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.537 | Acc: 54.688,65.625,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.729 | Acc: 51.786,66.667,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 51.353,66.559,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.753 | Acc: 51.191,66.432,74.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 0.978 | Acc: 55.469,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.957 | Acc: 61.012,90.551,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.953 | Acc: 61.376,91.025,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.947 | Acc: 61.335,91.291,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.948 | Acc: 61.400,91.464,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.952 | Acc: 60.922,91.368,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.951 | Acc: 60.834,91.451,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.950 | Acc: 60.899,91.395,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.949 | Acc: 60.870,91.479,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.953 | Acc: 60.817,91.359,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.955 | Acc: 60.860,91.367,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.956 | Acc: 60.863,91.314,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.955 | Acc: 60.905,91.290,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.959 | Acc: 60.746,91.122,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.957 | Acc: 60.779,91.187,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.960 | Acc: 60.647,91.113,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.963 | Acc: 60.533,91.056,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.963 | Acc: 60.521,91.053,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.964 | Acc: 60.479,91.008,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.963 | Acc: 60.511,91.033,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.609 | Acc: 55.469,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.743 | Acc: 51.562,67.932,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.790 | Acc: 51.010,66.921,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.777 | Acc: 50.807,66.995,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 0.991 | Acc: 60.156,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.942 | Acc: 61.868,92.671,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.938 | Acc: 62.309,91.959,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.941 | Acc: 61.860,92.188,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.944 | Acc: 61.458,92.120,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.950 | Acc: 60.984,92.079,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.946 | Acc: 61.247,92.129,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.949 | Acc: 61.032,92.032,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.955 | Acc: 60.938,91.877,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.956 | Acc: 60.912,91.743,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.956 | Acc: 60.844,91.748,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.956 | Acc: 60.771,91.675,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.957 | Acc: 60.730,91.601,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.955 | Acc: 60.791,91.565,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.958 | Acc: 60.776,91.437,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.957 | Acc: 60.888,91.417,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.957 | Acc: 60.879,91.406,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.956 | Acc: 60.910,91.404,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.956 | Acc: 60.877,91.376,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.957 | Acc: 60.884,91.349,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.657 | Acc: 53.906,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.734 | Acc: 51.339,68.155,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 51.315,67.378,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.770 | Acc: 51.153,67.239,75.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 0.888 | Acc: 62.500,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.922 | Acc: 61.682,92.076,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.931 | Acc: 61.452,92.226,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.927 | Acc: 61.322,92.111,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.930 | Acc: 61.179,92.110,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.925 | Acc: 61.564,92.110,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.927 | Acc: 61.654,92.065,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.934 | Acc: 61.325,91.971,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.939 | Acc: 61.064,91.935,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.943 | Acc: 60.938,91.868,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.944 | Acc: 61.027,91.764,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.946 | Acc: 61.058,91.696,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.950 | Acc: 60.954,91.604,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.951 | Acc: 60.917,91.496,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.953 | Acc: 60.796,91.487,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.954 | Acc: 60.722,91.417,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.956 | Acc: 60.607,91.397,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.957 | Acc: 60.589,91.376,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.956 | Acc: 60.667,91.363,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.957 | Acc: 60.663,91.334,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.562 | Acc: 51.562,67.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.743 | Acc: 51.600,67.820,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.783 | Acc: 51.543,67.473,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.785 | Acc: 51.383,67.200,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.043 | Acc: 55.469,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.934 | Acc: 61.086,91.443,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.927 | Acc: 61.071,92.378,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.923 | Acc: 61.117,92.674,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.922 | Acc: 61.130,92.949,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.921 | Acc: 61.077,92.891,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.919 | Acc: 61.235,92.975,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.917 | Acc: 61.325,93.152,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.920 | Acc: 61.350,93.066,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.918 | Acc: 61.520,93.029,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.915 | Acc: 61.559,93.031,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.915 | Acc: 61.637,93.029,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.915 | Acc: 61.638,93.085,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.916 | Acc: 61.620,93.047,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.915 | Acc: 61.588,93.052,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.914 | Acc: 61.615,93.080,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.915 | Acc: 61.561,93.076,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.915 | Acc: 61.609,93.081,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.915 | Acc: 61.645,93.066,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.914 | Acc: 61.696,93.067,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.507 | Acc: 56.250,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 51.711,68.266,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 51.620,68.216,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 51.639,68.071,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 0.953 | Acc: 65.625,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.899 | Acc: 62.760,93.824,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.904 | Acc: 62.005,93.788,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.907 | Acc: 61.744,93.622,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.906 | Acc: 61.921,93.451,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.908 | Acc: 61.595,93.541,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.911 | Acc: 61.551,93.440,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.907 | Acc: 61.702,93.506,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.908 | Acc: 61.704,93.464,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.906 | Acc: 61.611,93.543,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.908 | Acc: 61.606,93.575,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.906 | Acc: 61.850,93.662,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.906 | Acc: 61.858,93.646,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.906 | Acc: 61.812,93.660,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.903 | Acc: 61.930,93.647,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.903 | Acc: 61.960,93.576,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.904 | Acc: 61.986,93.604,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.903 | Acc: 61.978,93.585,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.903 | Acc: 62.059,93.599,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.903 | Acc: 62.088,93.606,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.493 | Acc: 57.031,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.688 | Acc: 51.897,68.490,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.722 | Acc: 51.639,67.969,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.721 | Acc: 51.793,67.892,75.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 0.947 | Acc: 57.812,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.900 | Acc: 62.426,93.750,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.899 | Acc: 62.348,93.769,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.898 | Acc: 61.975,93.788,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.897 | Acc: 62.133,93.866,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.892 | Acc: 62.345,93.905,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.898 | Acc: 62.377,93.789,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.897 | Acc: 62.278,93.822,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.900 | Acc: 62.078,93.765,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.898 | Acc: 62.181,93.772,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.897 | Acc: 62.263,93.715,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.898 | Acc: 62.196,93.658,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.900 | Acc: 61.975,93.653,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.901 | Acc: 61.931,93.645,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.901 | Acc: 61.952,93.653,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.902 | Acc: 61.947,93.618,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.901 | Acc: 62.006,93.653,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.901 | Acc: 62.005,93.603,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.901 | Acc: 62.030,93.564,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.901 | Acc: 62.035,93.543,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.524 | Acc: 56.250,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.679 | Acc: 52.046,68.490,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.713 | Acc: 51.677,67.778,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.713 | Acc: 51.678,67.905,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 0.906 | Acc: 61.719,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.870 | Acc: 62.835,94.159,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.879 | Acc: 62.805,93.941,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.884 | Acc: 62.910,93.878,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.886 | Acc: 62.751,93.856,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.893 | Acc: 62.624,93.634,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.889 | Acc: 62.855,93.731,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.892 | Acc: 62.799,93.551,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.893 | Acc: 62.709,93.624,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.893 | Acc: 62.720,93.608,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.893 | Acc: 62.620,93.630,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.896 | Acc: 62.574,93.619,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.894 | Acc: 62.613,93.614,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.894 | Acc: 62.545,93.636,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.895 | Acc: 62.508,93.636,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.895 | Acc: 62.492,93.638,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.896 | Acc: 62.442,93.585,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.897 | Acc: 62.404,93.580,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.897 | Acc: 62.394,93.607,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.898 | Acc: 62.332,93.592,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.516 | Acc: 56.250,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 51.786,68.490,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.726 | Acc: 51.639,67.759,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.725 | Acc: 51.627,67.777,74.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 0.867 | Acc: 65.625,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.868 | Acc: 62.909,94.048,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.886 | Acc: 62.062,93.826,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.893 | Acc: 61.783,93.904,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.888 | Acc: 62.375,94.010,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.889 | Acc: 62.345,94.021,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.886 | Acc: 62.720,94.105,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.887 | Acc: 62.705,94.005,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.888 | Acc: 62.665,94.007,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.891 | Acc: 62.526,93.931,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.890 | Acc: 62.698,93.921,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.892 | Acc: 62.670,93.831,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.893 | Acc: 62.529,93.831,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.892 | Acc: 62.569,93.894,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.893 | Acc: 62.464,93.892,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.892 | Acc: 62.500,93.926,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.894 | Acc: 62.524,93.869,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.894 | Acc: 62.445,93.890,99.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.894 | Acc: 62.387,93.893,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.895 | Acc: 62.299,93.853,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.536 | Acc: 56.250,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.686 | Acc: 52.232,68.266,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 51.829,68.026,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 51.934,68.110,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 0.933 | Acc: 59.375,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.878 | Acc: 62.835,94.048,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.885 | Acc: 62.500,93.483,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.887 | Acc: 62.487,93.699,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.885 | Acc: 62.838,93.798,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.891 | Acc: 62.338,93.750,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.887 | Acc: 62.642,93.815,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.889 | Acc: 62.622,93.833,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.891 | Acc: 62.398,93.837,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.889 | Acc: 62.392,93.931,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.887 | Acc: 62.531,93.956,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.888 | Acc: 62.461,93.902,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.888 | Acc: 62.387,93.919,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.888 | Acc: 62.422,93.813,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.888 | Acc: 62.447,93.825,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.890 | Acc: 62.404,93.786,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.890 | Acc: 62.308,93.813,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.890 | Acc: 62.406,93.805,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.891 | Acc: 62.383,93.787,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.890 | Acc: 62.441,93.799,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.479 | Acc: 56.250,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.679 | Acc: 52.307,68.304,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.716 | Acc: 51.982,68.007,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 52.049,68.110,75.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 0.936 | Acc: 64.844,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.889 | Acc: 61.793,94.010,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.881 | Acc: 62.024,93.960,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.882 | Acc: 62.551,93.776,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.884 | Acc: 62.423,93.875,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.891 | Acc: 62.013,93.889,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.890 | Acc: 62.106,93.911,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.892 | Acc: 62.073,93.883,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.891 | Acc: 62.136,94.002,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.891 | Acc: 62.194,93.936,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.892 | Acc: 62.127,93.874,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.892 | Acc: 62.118,93.835,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.891 | Acc: 62.215,93.805,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.890 | Acc: 62.225,93.816,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.890 | Acc: 62.255,93.820,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.889 | Acc: 62.261,93.836,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.888 | Acc: 62.325,93.877,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.888 | Acc: 62.342,93.881,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.889 | Acc: 62.305,93.830,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.890 | Acc: 62.190,93.818,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.536 | Acc: 55.469,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.681 | Acc: 51.897,68.266,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.714 | Acc: 51.429,67.835,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 51.537,67.969,75.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.004 | Acc: 50.781,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.884 | Acc: 63.393,94.196,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.877 | Acc: 62.843,94.264,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.898 | Acc: 61.962,93.878,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.897 | Acc: 62.056,93.924,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.893 | Acc: 62.454,93.905,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.897 | Acc: 62.113,93.815,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.896 | Acc: 62.195,93.733,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.893 | Acc: 62.311,93.808,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.891 | Acc: 62.414,93.785,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.890 | Acc: 62.477,93.762,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.892 | Acc: 62.489,93.757,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.892 | Acc: 62.445,93.786,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.890 | Acc: 62.533,93.795,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.891 | Acc: 62.461,93.769,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.892 | Acc: 62.435,93.779,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.892 | Acc: 62.395,93.789,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.892 | Acc: 62.358,93.803,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.892 | Acc: 62.368,93.804,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.892 | Acc: 62.356,93.818,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.507 | Acc: 56.250,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.685 | Acc: 52.232,68.341,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.722 | Acc: 51.658,67.645,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 51.844,67.879,75.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 0.891 | Acc: 64.062,92.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.906 | Acc: 62.574,93.266,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.897 | Acc: 62.691,93.617,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.893 | Acc: 62.538,93.712,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.898 | Acc: 62.452,93.673,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.894 | Acc: 62.500,93.820,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.893 | Acc: 62.332,93.860,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.893 | Acc: 62.494,93.911,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.889 | Acc: 62.558,93.954,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.894 | Acc: 62.327,93.966,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.896 | Acc: 62.356,93.925,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.894 | Acc: 62.461,93.884,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.893 | Acc: 62.490,93.893,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.893 | Acc: 62.413,93.924,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.894 | Acc: 62.386,93.864,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.893 | Acc: 62.360,93.867,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.892 | Acc: 62.322,93.867,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.893 | Acc: 62.326,93.853,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.893 | Acc: 62.303,93.876,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.892 | Acc: 62.256,93.924,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.527 | Acc: 57.031,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.682 | Acc: 52.121,68.192,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.719 | Acc: 51.734,67.740,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.717 | Acc: 51.755,67.943,75.307,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.031 | Acc: 60.938,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.908 | Acc: 62.686,93.452,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.892 | Acc: 62.652,93.979,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.890 | Acc: 62.423,93.942,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.886 | Acc: 62.201,94.039,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.887 | Acc: 62.144,93.974,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.890 | Acc: 62.145,93.963,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.888 | Acc: 62.145,94.055,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.888 | Acc: 62.228,94.090,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.888 | Acc: 62.336,94.117,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.889 | Acc: 62.267,94.092,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.887 | Acc: 62.284,94.072,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.887 | Acc: 62.409,94.039,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.886 | Acc: 62.449,94.055,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.886 | Acc: 62.375,94.036,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.884 | Acc: 62.362,94.046,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.885 | Acc: 62.390,93.993,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.886 | Acc: 62.401,93.929,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.888 | Acc: 62.331,93.925,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.888 | Acc: 62.359,93.918,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.516 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.685 | Acc: 52.046,68.229,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 51.658,67.797,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.720 | Acc: 51.755,67.828,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 0.860 | Acc: 69.531,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.875 | Acc: 63.914,94.159,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.885 | Acc: 63.148,93.902,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.889 | Acc: 62.628,93.929,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.892 | Acc: 62.307,93.914,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.885 | Acc: 62.593,94.005,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.883 | Acc: 62.694,93.963,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.882 | Acc: 62.849,93.966,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.881 | Acc: 62.854,93.964,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.881 | Acc: 62.789,93.979,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.886 | Acc: 62.702,93.964,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.885 | Acc: 62.652,93.969,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.886 | Acc: 62.542,93.957,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.886 | Acc: 62.566,93.957,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.886 | Acc: 62.544,93.961,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.888 | Acc: 62.445,93.942,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.888 | Acc: 62.512,93.969,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.889 | Acc: 62.413,93.995,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.890 | Acc: 62.452,93.960,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.889 | Acc: 62.473,93.965,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.461 | Acc: 57.031,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.678 | Acc: 51.637,68.415,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.718 | Acc: 51.486,67.797,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.717 | Acc: 51.729,67.789,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 0.854 | Acc: 60.938,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.873 | Acc: 63.244,94.196,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.881 | Acc: 62.671,94.036,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.886 | Acc: 62.500,94.045,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.878 | Acc: 62.905,94.097,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.881 | Acc: 62.879,94.152,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.890 | Acc: 62.590,94.028,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.885 | Acc: 62.877,94.088,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.885 | Acc: 62.835,94.099,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.885 | Acc: 62.789,94.082,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.886 | Acc: 62.690,94.119,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.886 | Acc: 62.518,94.121,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.888 | Acc: 62.532,94.094,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.889 | Acc: 62.479,94.025,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.890 | Acc: 62.380,94.042,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.889 | Acc: 62.375,94.046,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.890 | Acc: 62.322,94.035,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.889 | Acc: 62.253,94.068,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.890 | Acc: 62.234,94.027,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.889 | Acc: 62.256,94.029,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.543 | Acc: 57.031,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.672 | Acc: 52.269,68.043,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.712 | Acc: 51.791,67.854,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 51.934,67.789,75.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 0.869 | Acc: 62.500,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.894 | Acc: 61.496,94.606,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.889 | Acc: 61.947,94.398,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.885 | Acc: 62.398,94.506,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.881 | Acc: 62.510,94.387,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.884 | Acc: 62.214,94.330,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.883 | Acc: 62.197,94.363,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.886 | Acc: 62.256,94.326,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.886 | Acc: 62.398,94.323,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.883 | Acc: 62.414,94.462,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.883 | Acc: 62.391,94.422,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.883 | Acc: 62.426,94.372,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.884 | Acc: 62.406,94.291,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.884 | Acc: 62.404,94.298,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.884 | Acc: 62.475,94.262,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.887 | Acc: 62.386,94.186,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.887 | Acc: 62.347,94.139,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.887 | Acc: 62.328,94.101,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.887 | Acc: 62.284,94.077,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.887 | Acc: 62.279,94.058,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.554 | Acc: 56.250,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.686 | Acc: 52.269,68.192,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 51.867,67.645,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.721 | Acc: 52.024,67.764,75.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 0.804 | Acc: 67.188,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.882 | Acc: 62.984,94.010,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.881 | Acc: 62.957,94.074,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.891 | Acc: 62.551,93.968,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.889 | Acc: 62.297,93.885,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.891 | Acc: 62.028,93.912,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.889 | Acc: 62.261,93.834,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.887 | Acc: 62.328,93.839,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.882 | Acc: 62.476,93.949,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.886 | Acc: 62.340,93.862,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.889 | Acc: 62.146,93.863,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.887 | Acc: 62.214,93.923,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.885 | Acc: 62.396,93.987,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.886 | Acc: 62.440,93.974,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.888 | Acc: 62.339,93.925,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.888 | Acc: 62.342,93.926,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.890 | Acc: 62.191,93.928,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.890 | Acc: 62.232,93.956,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.890 | Acc: 62.253,93.992,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.888 | Acc: 62.320,94.015,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.508 | Acc: 55.469,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.693 | Acc: 52.195,68.229,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.726 | Acc: 51.715,67.893,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.721 | Acc: 51.806,67.879,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 0.802 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.897 | Acc: 61.942,93.750,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.896 | Acc: 61.852,94.074,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.889 | Acc: 62.218,94.314,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.888 | Acc: 62.288,94.396,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.885 | Acc: 62.562,94.322,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.888 | Acc: 62.403,94.234,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.885 | Acc: 62.572,94.337,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.887 | Acc: 62.481,94.269,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.886 | Acc: 62.517,94.294,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.885 | Acc: 62.570,94.298,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.885 | Acc: 62.482,94.305,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.884 | Acc: 62.604,94.330,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.886 | Acc: 62.401,94.259,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.886 | Acc: 62.367,94.292,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.886 | Acc: 62.375,94.272,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.886 | Acc: 62.408,94.244,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.887 | Acc: 62.360,94.217,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.886 | Acc: 62.463,94.230,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.886 | Acc: 62.506,94.189,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.495 | Acc: 57.031,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.677 | Acc: 52.344,68.266,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.717 | Acc: 51.772,67.835,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 51.870,68.084,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 0.838 | Acc: 64.062,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.881 | Acc: 62.500,93.973,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.866 | Acc: 63.014,94.493,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.865 | Acc: 63.076,94.365,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.879 | Acc: 62.645,94.145,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.879 | Acc: 62.639,93.974,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.877 | Acc: 62.823,94.041,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.874 | Acc: 62.855,94.116,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.881 | Acc: 62.616,94.051,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.881 | Acc: 62.608,94.100,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.883 | Acc: 62.551,94.069,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.883 | Acc: 62.504,94.114,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.882 | Acc: 62.461,94.120,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.883 | Acc: 62.479,94.109,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.885 | Acc: 62.372,94.059,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.884 | Acc: 62.461,94.080,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.885 | Acc: 62.427,94.054,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.885 | Acc: 62.422,94.064,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.886 | Acc: 62.444,94.062,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.885 | Acc: 62.506,94.082,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.544 | Acc: 56.250,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.679 | Acc: 52.158,68.713,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.716 | Acc: 51.772,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 51.908,68.046,75.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 0.993 | Acc: 60.938,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.868 | Acc: 63.244,94.643,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.870 | Acc: 63.262,94.931,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 63.332,94.967,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.874 | Acc: 63.175,94.541,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.875 | Acc: 63.057,94.446,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.879 | Acc: 62.894,94.286,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.884 | Acc: 62.594,94.138,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.886 | Acc: 62.461,94.061,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.885 | Acc: 62.396,94.061,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.885 | Acc: 62.286,94.104,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.885 | Acc: 62.256,94.128,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.885 | Acc: 62.302,94.084,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.884 | Acc: 62.296,94.079,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.883 | Acc: 62.303,94.131,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.883 | Acc: 62.347,94.152,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.883 | Acc: 62.373,94.127,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.884 | Acc: 62.372,94.139,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.886 | Acc: 62.329,94.072,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.887 | Acc: 62.287,94.043,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.545 | Acc: 57.031,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.675 | Acc: 52.455,68.676,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.718 | Acc: 51.867,68.064,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.715 | Acc: 51.895,68.020,75.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 0.821 | Acc: 64.844,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.853 | Acc: 64.025,94.085,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.868 | Acc: 63.643,93.845,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.861 | Acc: 63.934,94.070,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.865 | Acc: 63.561,94.078,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.872 | Acc: 63.227,94.137,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.874 | Acc: 63.100,94.157,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.880 | Acc: 62.771,94.027,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.879 | Acc: 62.694,94.046,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.879 | Acc: 62.694,94.052,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.881 | Acc: 62.574,94.065,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.884 | Acc: 62.511,94.121,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.884 | Acc: 62.442,94.197,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.882 | Acc: 62.587,94.235,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.881 | Acc: 62.586,94.214,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.881 | Acc: 62.565,94.222,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.882 | Acc: 62.563,94.217,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.883 | Acc: 62.525,94.208,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.883 | Acc: 62.459,94.204,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.884 | Acc: 62.484,94.189,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.549 | Acc: 55.469,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 52.232,68.304,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.732 | Acc: 51.944,67.740,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.730 | Acc: 51.831,67.841,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 0.920 | Acc: 59.375,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.880 | Acc: 62.872,93.862,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.892 | Acc: 61.643,93.731,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.890 | Acc: 62.026,93.916,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.880 | Acc: 62.645,94.232,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.878 | Acc: 62.686,94.206,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.881 | Acc: 62.603,94.112,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.882 | Acc: 62.600,94.094,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.882 | Acc: 62.597,94.216,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.884 | Acc: 62.629,94.251,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.883 | Acc: 62.659,94.224,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.881 | Acc: 62.854,94.231,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.882 | Acc: 62.850,94.158,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.881 | Acc: 62.814,94.175,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.881 | Acc: 62.792,94.128,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.883 | Acc: 62.739,94.095,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.885 | Acc: 62.697,94.047,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.884 | Acc: 62.660,94.068,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.884 | Acc: 62.660,94.116,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.883 | Acc: 62.644,94.123,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.481 | Acc: 56.250,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.675 | Acc: 52.121,68.378,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.720 | Acc: 51.791,67.778,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 51.934,67.713,75.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 0.857 | Acc: 65.625,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.888 | Acc: 62.463,94.122,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.894 | Acc: 62.233,94.150,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.890 | Acc: 62.231,94.134,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.886 | Acc: 62.500,93.953,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.882 | Acc: 62.608,94.044,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.883 | Acc: 62.403,94.034,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.886 | Acc: 62.256,94.071,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.884 | Acc: 62.209,94.085,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.883 | Acc: 62.137,94.074,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.882 | Acc: 62.146,94.100,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.883 | Acc: 62.178,94.114,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.881 | Acc: 62.250,94.152,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.881 | Acc: 62.353,94.199,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.881 | Acc: 62.297,94.214,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.881 | Acc: 62.311,94.189,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.880 | Acc: 62.381,94.200,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.882 | Acc: 62.285,94.158,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.884 | Acc: 62.204,94.150,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.884 | Acc: 62.199,94.154,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.568 | Acc: 57.031,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.703 | Acc: 52.158,68.713,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.738 | Acc: 51.772,67.912,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.733 | Acc: 51.895,67.828,74.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 0.928 | Acc: 64.844,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.899 | Acc: 61.421,94.085,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.879 | Acc: 62.424,94.512,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.878 | Acc: 62.513,94.595,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.885 | Acc: 62.153,94.425,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.889 | Acc: 62.113,94.175,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.888 | Acc: 61.964,94.234,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.888 | Acc: 62.057,94.188,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.887 | Acc: 62.223,94.206,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.886 | Acc: 62.289,94.216,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.886 | Acc: 62.294,94.189,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.886 | Acc: 62.221,94.256,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.887 | Acc: 62.156,94.223,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.884 | Acc: 62.258,94.280,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.884 | Acc: 62.375,94.281,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.885 | Acc: 62.334,94.251,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.885 | Acc: 62.373,94.261,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.884 | Acc: 62.360,94.249,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.885 | Acc: 62.325,94.246,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.885 | Acc: 62.295,94.177,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.502 | Acc: 57.031,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.699 | Acc: 52.344,68.527,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 51.791,67.816,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 51.844,67.764,75.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 0.792 | Acc: 71.094,91.406,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.877 | Acc: 63.132,93.862,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.892 | Acc: 62.862,93.769,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.888 | Acc: 62.551,93.981,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.885 | Acc: 62.423,94.126,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.881 | Acc: 62.531,94.106,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.879 | Acc: 62.707,94.170,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.879 | Acc: 62.572,94.171,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.881 | Acc: 62.267,94.153,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.884 | Acc: 62.133,94.126,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.883 | Acc: 62.251,94.131,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.883 | Acc: 62.270,94.139,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.882 | Acc: 62.419,94.133,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.880 | Acc: 62.563,94.130,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.879 | Acc: 62.519,94.142,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.880 | Acc: 62.464,94.145,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.880 | Acc: 62.500,94.122,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.883 | Acc: 62.468,94.041,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.884 | Acc: 62.444,94.053,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.883 | Acc: 62.516,94.078,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.510 | Acc: 56.250,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.688 | Acc: 51.972,68.527,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.732 | Acc: 51.696,67.797,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.726 | Acc: 51.831,67.636,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 0.916 | Acc: 60.938,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.872 | Acc: 61.979,94.345,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.877 | Acc: 62.176,94.131,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.878 | Acc: 61.975,94.019,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.877 | Acc: 62.085,94.155,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.878 | Acc: 62.183,94.052,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.874 | Acc: 62.500,94.170,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 62.483,94.210,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.875 | Acc: 62.510,94.221,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.876 | Acc: 62.396,94.220,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.874 | Acc: 62.531,94.213,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.875 | Acc: 62.468,94.270,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.875 | Acc: 62.403,94.311,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.876 | Acc: 62.422,94.289,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.879 | Acc: 62.344,94.259,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.878 | Acc: 62.381,94.220,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.878 | Acc: 62.347,94.249,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.878 | Acc: 62.305,94.261,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.877 | Acc: 62.364,94.267,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.878 | Acc: 62.324,94.248,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.507 | Acc: 55.469,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 52.195,68.527,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.726 | Acc: 51.696,67.988,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.722 | Acc: 51.716,67.956,75.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 0.872 | Acc: 60.938,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.881 | Acc: 62.388,94.196,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.884 | Acc: 61.471,94.436,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.887 | Acc: 61.642,94.365,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.884 | Acc: 61.873,94.396,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.878 | Acc: 62.090,94.330,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.879 | Acc: 62.164,94.331,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.880 | Acc: 62.134,94.304,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.881 | Acc: 62.175,94.352,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.884 | Acc: 62.042,94.315,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.881 | Acc: 62.185,94.352,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.882 | Acc: 62.267,94.294,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.881 | Acc: 62.318,94.291,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.881 | Acc: 62.311,94.268,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.882 | Acc: 62.208,94.223,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.882 | Acc: 62.225,94.212,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.882 | Acc: 62.310,94.256,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.882 | Acc: 62.324,94.229,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.882 | Acc: 62.383,94.233,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.882 | Acc: 62.379,94.246,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.457 | Acc: 57.031,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.689 | Acc: 52.269,68.452,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 51.925,67.893,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.725 | Acc: 51.742,67.943,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 0.876 | Acc: 64.062,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.873 | Acc: 62.984,94.010,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.877 | Acc: 62.824,94.245,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.876 | Acc: 63.140,94.160,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.882 | Acc: 62.731,94.194,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.880 | Acc: 62.562,94.338,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.882 | Acc: 62.371,94.338,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.882 | Acc: 62.367,94.354,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.880 | Acc: 62.388,94.429,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.880 | Acc: 62.474,94.458,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.881 | Acc: 62.500,94.426,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.880 | Acc: 62.475,94.397,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.881 | Acc: 62.510,94.350,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.882 | Acc: 62.443,94.325,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.882 | Acc: 62.355,94.364,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.882 | Acc: 62.357,94.414,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.881 | Acc: 62.434,94.371,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.882 | Acc: 62.427,94.320,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.882 | Acc: 62.435,94.321,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.880 | Acc: 62.621,94.349,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.557 | Acc: 57.812,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.681 | Acc: 51.935,67.932,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.725 | Acc: 51.677,67.607,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.722 | Acc: 51.767,67.559,75.307,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 0.958 | Acc: 60.156,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.875 | Acc: 63.132,93.862,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.890 | Acc: 61.966,93.788,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.891 | Acc: 61.962,93.968,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.888 | Acc: 62.191,94.030,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.883 | Acc: 62.245,94.152,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.883 | Acc: 62.106,94.228,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.880 | Acc: 62.195,94.348,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.884 | Acc: 62.000,94.279,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.885 | Acc: 61.887,94.268,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.885 | Acc: 62.006,94.321,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.885 | Acc: 62.044,94.326,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.884 | Acc: 62.033,94.337,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.884 | Acc: 62.087,94.331,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.885 | Acc: 62.064,94.331,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.883 | Acc: 62.098,94.339,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.882 | Acc: 62.213,94.351,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.881 | Acc: 62.353,94.375,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.879 | Acc: 62.526,94.339,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.878 | Acc: 62.660,94.345,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.529 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 51.935,68.155,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 51.620,67.740,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.731 | Acc: 51.678,67.892,75.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 0.684 | Acc: 68.750,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.874 | Acc: 62.500,94.940,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.863 | Acc: 63.224,94.627,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.866 | Acc: 63.012,94.595,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.865 | Acc: 62.924,94.724,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 63.134,94.516,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.873 | Acc: 62.900,94.441,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.872 | Acc: 62.988,94.459,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.877 | Acc: 62.718,94.458,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.875 | Acc: 62.729,94.449,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.878 | Acc: 62.609,94.504,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.875 | Acc: 62.641,94.468,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.875 | Acc: 62.588,94.408,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.875 | Acc: 62.548,94.406,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.875 | Acc: 62.611,94.409,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.875 | Acc: 62.567,94.399,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.877 | Acc: 62.478,94.344,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.878 | Acc: 62.395,94.369,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.878 | Acc: 62.403,94.369,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.878 | Acc: 62.449,94.390,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.508 | Acc: 56.250,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.689 | Acc: 51.935,68.229,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 51.639,67.797,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.732 | Acc: 51.819,67.828,74.936,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 0.885 | Acc: 58.594,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.883 | Acc: 62.128,94.234,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.887 | Acc: 62.062,93.998,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.885 | Acc: 62.334,94.198,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.880 | Acc: 62.558,94.232,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.883 | Acc: 62.384,94.253,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.882 | Acc: 62.468,94.267,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.880 | Acc: 62.517,94.321,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.880 | Acc: 62.422,94.366,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.880 | Acc: 62.444,94.324,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.882 | Acc: 62.399,94.275,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.884 | Acc: 62.313,94.224,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.882 | Acc: 62.393,94.220,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.880 | Acc: 62.452,94.253,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.882 | Acc: 62.330,94.234,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.880 | Acc: 62.435,94.277,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.880 | Acc: 62.364,94.295,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.880 | Acc: 62.360,94.286,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.880 | Acc: 62.418,94.300,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.879 | Acc: 62.447,94.302,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.512 | Acc: 56.250,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.685 | Acc: 52.046,68.341,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 51.677,67.759,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.729 | Acc: 51.819,67.674,75.320,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 0.827 | Acc: 68.750,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.881 | Acc: 61.793,94.271,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.872 | Acc: 63.053,94.360,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.875 | Acc: 63.179,94.557,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.872 | Acc: 63.185,94.522,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.870 | Acc: 63.065,94.640,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.877 | Acc: 62.597,94.538,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 62.821,94.537,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.877 | Acc: 62.650,94.526,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.878 | Acc: 62.547,94.488,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.880 | Acc: 62.539,94.380,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.877 | Acc: 62.592,94.432,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.878 | Acc: 62.649,94.453,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.877 | Acc: 62.569,94.438,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.878 | Acc: 62.611,94.406,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.877 | Acc: 62.622,94.420,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.878 | Acc: 62.646,94.378,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.880 | Acc: 62.525,94.382,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.880 | Acc: 62.481,94.380,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.879 | Acc: 62.527,94.382,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.520 | Acc: 57.031,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.697 | Acc: 52.009,68.452,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 51.639,67.969,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 51.806,68.135,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 0.753 | Acc: 66.406,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.896 | Acc: 63.021,93.415,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.890 | Acc: 62.367,93.826,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.882 | Acc: 63.268,94.121,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.884 | Acc: 62.722,94.271,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.879 | Acc: 62.771,94.168,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.879 | Acc: 62.868,94.183,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.879 | Acc: 62.921,94.210,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.884 | Acc: 62.563,94.177,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.885 | Acc: 62.414,94.134,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.886 | Acc: 62.352,94.146,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.887 | Acc: 62.189,94.149,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.887 | Acc: 62.153,94.152,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.887 | Acc: 62.192,94.202,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.885 | Acc: 62.325,94.256,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.884 | Acc: 62.433,94.277,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.882 | Acc: 62.524,94.302,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.880 | Acc: 62.541,94.291,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.880 | Acc: 62.517,94.298,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.880 | Acc: 62.486,94.312,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.540 | Acc: 57.031,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.686 | Acc: 52.083,68.341,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.721 | Acc: 51.696,68.045,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.722 | Acc: 51.831,67.841,75.218,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 0.719 | Acc: 68.750,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.874 | Acc: 62.574,94.643,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.866 | Acc: 62.691,94.493,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.872 | Acc: 62.500,94.416,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.875 | Acc: 62.452,94.425,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.883 | Acc: 62.276,94.361,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.883 | Acc: 62.203,94.357,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.880 | Acc: 62.378,94.409,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.880 | Acc: 62.481,94.391,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.881 | Acc: 62.522,94.285,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.883 | Acc: 62.348,94.201,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.881 | Acc: 62.348,94.234,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.882 | Acc: 62.189,94.275,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.883 | Acc: 62.222,94.265,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.881 | Acc: 62.353,94.323,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.880 | Acc: 62.381,94.342,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.881 | Acc: 62.434,94.339,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.881 | Acc: 62.495,94.346,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.882 | Acc: 62.463,94.241,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.882 | Acc: 62.449,94.279,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.544 | Acc: 57.031,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 52.381,68.192,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 51.982,67.645,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 52.024,67.725,75.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 0.789 | Acc: 68.750,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.884 | Acc: 61.793,93.750,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.888 | Acc: 61.852,94.303,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.880 | Acc: 62.385,94.518,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.878 | Acc: 62.683,94.541,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.878 | Acc: 62.662,94.524,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.875 | Acc: 62.887,94.609,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.874 | Acc: 63.060,94.564,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.870 | Acc: 63.252,94.522,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.868 | Acc: 63.376,94.514,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.868 | Acc: 63.305,94.516,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.868 | Acc: 63.278,94.507,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 63.158,94.450,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.873 | Acc: 62.973,94.465,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.875 | Acc: 62.881,94.445,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.876 | Acc: 62.858,94.422,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.875 | Acc: 62.941,94.458,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.874 | Acc: 62.956,94.465,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.876 | Acc: 62.831,94.468,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.875 | Acc: 62.918,94.433,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.482 | Acc: 55.469,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.684 | Acc: 52.195,68.266,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.732 | Acc: 51.772,67.626,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.730 | Acc: 51.870,67.725,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 0.891 | Acc: 59.375,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 62.277,94.680,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.874 | Acc: 62.081,94.150,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.884 | Acc: 61.975,93.878,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.888 | Acc: 61.863,94.097,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.889 | Acc: 61.866,94.152,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.885 | Acc: 61.990,94.267,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.885 | Acc: 61.968,94.221,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.885 | Acc: 62.005,94.250,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.886 | Acc: 62.086,94.290,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.886 | Acc: 62.092,94.251,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.883 | Acc: 62.313,94.270,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.883 | Acc: 62.341,94.278,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.882 | Acc: 62.413,94.235,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.882 | Acc: 62.386,94.237,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.882 | Acc: 62.440,94.204,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.881 | Acc: 62.454,94.198,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.879 | Acc: 62.459,94.233,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.878 | Acc: 62.400,94.230,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.879 | Acc: 62.414,94.211,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.505 | Acc: 57.031,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.673 | Acc: 52.121,68.527,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.720 | Acc: 51.734,67.721,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.722 | Acc: 51.870,67.700,75.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 0.821 | Acc: 68.750,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.865 | Acc: 62.612,94.345,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 62.862,94.627,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.862 | Acc: 62.948,94.493,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.863 | Acc: 62.751,94.637,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 62.833,94.462,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.865 | Acc: 62.978,94.441,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.869 | Acc: 62.794,94.465,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.875 | Acc: 62.544,94.332,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.875 | Acc: 62.522,94.324,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.875 | Acc: 62.632,94.345,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.875 | Acc: 62.648,94.453,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.875 | Acc: 62.636,94.486,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.875 | Acc: 62.623,94.495,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.876 | Acc: 62.650,94.470,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.877 | Acc: 62.632,94.407,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.876 | Acc: 62.692,94.390,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.876 | Acc: 62.672,94.380,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.877 | Acc: 62.662,94.373,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.877 | Acc: 62.672,94.353,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.592 | Acc: 58.594,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 52.195,68.676,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 51.772,67.854,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.733 | Acc: 51.703,67.751,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 0.854 | Acc: 64.844,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.875 | Acc: 62.760,94.457,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.874 | Acc: 63.319,94.646,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.872 | Acc: 63.435,94.403,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.875 | Acc: 62.731,94.367,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.879 | Acc: 62.477,94.307,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.875 | Acc: 62.791,94.357,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.875 | Acc: 62.794,94.326,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.879 | Acc: 62.393,94.332,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.880 | Acc: 62.280,94.346,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.879 | Acc: 62.372,94.333,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.879 | Acc: 62.440,94.309,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.879 | Acc: 62.429,94.321,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.878 | Acc: 62.458,94.367,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.877 | Acc: 62.469,94.339,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.880 | Acc: 62.300,94.311,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.879 | Acc: 62.352,94.322,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.879 | Acc: 62.317,94.323,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.879 | Acc: 62.316,94.321,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.878 | Acc: 62.371,94.343,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.521 | Acc: 54.688,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.697 | Acc: 51.860,68.341,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 51.582,67.626,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.730 | Acc: 51.691,67.661,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 0.803 | Acc: 64.062,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.873 | Acc: 62.054,94.122,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.868 | Acc: 62.252,94.398,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.869 | Acc: 62.346,94.544,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.872 | Acc: 62.413,94.531,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.872 | Acc: 62.508,94.524,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.872 | Acc: 62.558,94.505,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 62.783,94.559,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.870 | Acc: 62.922,94.633,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.870 | Acc: 62.781,94.626,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.871 | Acc: 62.702,94.597,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.871 | Acc: 62.737,94.591,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.872 | Acc: 62.691,94.538,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.873 | Acc: 62.745,94.507,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.875 | Acc: 62.681,94.453,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.875 | Acc: 62.619,94.440,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.876 | Acc: 62.551,94.461,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.877 | Acc: 62.571,94.398,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.877 | Acc: 62.563,94.375,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.877 | Acc: 62.547,94.412,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.528 | Acc: 57.812,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.699 | Acc: 51.823,68.564,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.732 | Acc: 51.410,67.835,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 51.511,67.764,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 0.920 | Acc: 64.062,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.852 | Acc: 63.839,95.089,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.858 | Acc: 63.720,94.703,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 63.076,94.839,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 62.973,94.715,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.873 | Acc: 62.585,94.756,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.873 | Acc: 62.655,94.686,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 62.749,94.609,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.873 | Acc: 62.815,94.589,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.876 | Acc: 62.686,94.510,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.877 | Acc: 62.601,94.446,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.876 | Acc: 62.567,94.475,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.874 | Acc: 62.633,94.505,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.875 | Acc: 62.611,94.477,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.875 | Acc: 62.597,94.467,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.876 | Acc: 62.580,94.446,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.878 | Acc: 62.571,94.439,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.880 | Acc: 62.509,94.373,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.879 | Acc: 62.617,94.384,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.879 | Acc: 62.570,94.367,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.550 | Acc: 56.250,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 51.823,68.378,76.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 51.467,67.645,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.724 | Acc: 51.639,67.623,75.218,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 0.817 | Acc: 64.844,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.874 | Acc: 63.616,94.048,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.867 | Acc: 63.739,94.531,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 63.819,94.762,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.867 | Acc: 63.175,94.647,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.864 | Acc: 63.157,94.717,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.866 | Acc: 63.204,94.531,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 63.254,94.542,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 63.160,94.580,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.869 | Acc: 63.104,94.609,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.868 | Acc: 63.005,94.656,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.869 | Acc: 63.030,94.655,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.870 | Acc: 63.054,94.641,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 62.919,94.732,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.871 | Acc: 62.934,94.748,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 62.902,94.723,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.873 | Acc: 62.841,94.702,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.874 | Acc: 62.848,94.644,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.875 | Acc: 62.803,94.626,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.873 | Acc: 62.869,94.656,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.523 | Acc: 57.031,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.681 | Acc: 51.972,68.341,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 51.524,67.530,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.726 | Acc: 51.639,67.636,75.218,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 0.970 | Acc: 60.938,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.854 | Acc: 63.318,94.903,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.869 | Acc: 63.053,94.684,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.871 | Acc: 63.204,94.647,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.871 | Acc: 62.973,94.811,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 62.956,94.771,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.869 | Acc: 62.926,94.660,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.871 | Acc: 62.677,94.675,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.872 | Acc: 62.582,94.653,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.872 | Acc: 62.543,94.609,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.869 | Acc: 62.659,94.679,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 62.716,94.701,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.869 | Acc: 62.763,94.732,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.870 | Acc: 62.713,94.699,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.868 | Acc: 62.806,94.706,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 62.840,94.749,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 62.950,94.765,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 62.910,94.717,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 62.851,94.707,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.869 | Acc: 62.836,94.683,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.519 | Acc: 57.031,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.688 | Acc: 52.530,68.266,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 51.944,67.778,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.724 | Acc: 52.024,67.789,75.371,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 0.913 | Acc: 60.156,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 63.430,95.201,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.867 | Acc: 63.491,94.665,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 62.948,94.570,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.867 | Acc: 63.069,94.473,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.868 | Acc: 62.809,94.531,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.871 | Acc: 62.713,94.615,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 62.982,94.642,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.868 | Acc: 63.053,94.614,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.867 | Acc: 63.143,94.626,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.867 | Acc: 63.176,94.687,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 63.214,94.644,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.866 | Acc: 63.239,94.700,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.866 | Acc: 63.206,94.738,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.868 | Acc: 63.039,94.729,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.868 | Acc: 63.001,94.736,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.871 | Acc: 62.902,94.675,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.874 | Acc: 62.754,94.669,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.874 | Acc: 62.714,94.665,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.872 | Acc: 62.816,94.662,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.512 | Acc: 56.250,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.682 | Acc: 52.493,68.527,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 51.886,67.645,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.724 | Acc: 51.947,67.674,75.359,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 0.855 | Acc: 68.750,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.884 | Acc: 62.054,93.638,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.869 | Acc: 62.576,94.341,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.876 | Acc: 62.385,94.249,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.873 | Acc: 62.529,94.290,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.869 | Acc: 62.647,94.431,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.868 | Acc: 62.655,94.615,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 62.661,94.542,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.874 | Acc: 62.636,94.522,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.875 | Acc: 62.651,94.484,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.877 | Acc: 62.605,94.481,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.875 | Acc: 62.691,94.503,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.875 | Acc: 62.776,94.476,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.873 | Acc: 62.772,94.483,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.875 | Acc: 62.703,94.495,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.875 | Acc: 62.715,94.521,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.873 | Acc: 62.802,94.558,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.873 | Acc: 62.807,94.524,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.873 | Acc: 62.831,94.546,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.872 | Acc: 62.869,94.589,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.559 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.686 | Acc: 52.083,68.229,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.732 | Acc: 51.677,67.683,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.732 | Acc: 51.742,67.725,75.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 0.779 | Acc: 67.969,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.880 | Acc: 61.644,94.531,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.882 | Acc: 61.928,94.245,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.887 | Acc: 61.565,94.288,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.882 | Acc: 62.191,94.319,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.880 | Acc: 62.345,94.423,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.877 | Acc: 62.442,94.415,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.877 | Acc: 62.467,94.437,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.874 | Acc: 62.665,94.507,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.872 | Acc: 62.681,94.540,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.872 | Acc: 62.702,94.520,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.873 | Acc: 62.652,94.560,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 62.730,94.564,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.872 | Acc: 62.748,94.576,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.871 | Acc: 62.700,94.642,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 62.736,94.607,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.871 | Acc: 62.855,94.629,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.871 | Acc: 62.901,94.598,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.871 | Acc: 62.857,94.603,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.871 | Acc: 62.863,94.626,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.536 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.689 | Acc: 52.158,68.304,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 51.753,67.740,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.729 | Acc: 51.857,67.674,75.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 0.858 | Acc: 64.844,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.865 | Acc: 62.500,94.531,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.869 | Acc: 62.710,94.684,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.873 | Acc: 62.859,94.595,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 63.329,94.608,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.869 | Acc: 63.266,94.585,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 63.197,94.512,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 63.159,94.481,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.867 | Acc: 63.155,94.478,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.870 | Acc: 63.091,94.397,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.869 | Acc: 63.025,94.492,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.868 | Acc: 63.006,94.492,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.870 | Acc: 62.883,94.547,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.870 | Acc: 62.820,94.525,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 62.736,94.509,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.869 | Acc: 62.793,94.531,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 62.836,94.560,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.869 | Acc: 62.807,94.570,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.870 | Acc: 62.803,94.568,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 62.799,94.542,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.539 | Acc: 55.469,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.675 | Acc: 52.083,68.415,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 51.753,67.607,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.719 | Acc: 51.895,67.572,75.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 0.984 | Acc: 63.281,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.867 | Acc: 62.277,94.606,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.866 | Acc: 62.691,94.741,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.869 | Acc: 62.615,94.672,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 62.596,94.599,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.869 | Acc: 62.786,94.601,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.875 | Acc: 62.558,94.551,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.876 | Acc: 62.411,94.553,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.871 | Acc: 62.563,94.677,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.872 | Acc: 62.565,94.652,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.870 | Acc: 62.605,94.683,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.871 | Acc: 62.574,94.655,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 62.594,94.690,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.869 | Acc: 62.683,94.687,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.867 | Acc: 62.786,94.731,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 62.775,94.705,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.868 | Acc: 62.741,94.680,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.869 | Acc: 62.770,94.687,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.869 | Acc: 62.788,94.707,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 62.748,94.681,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.502 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.691 | Acc: 52.121,68.229,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.738 | Acc: 51.734,67.530,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.736 | Acc: 51.793,67.559,75.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 0.907 | Acc: 57.031,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.908 | Acc: 60.751,93.899,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.889 | Acc: 61.871,94.436,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.876 | Acc: 62.654,94.647,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.877 | Acc: 62.847,94.560,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.876 | Acc: 62.662,94.570,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 62.720,94.712,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.870 | Acc: 62.755,94.764,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.871 | Acc: 62.806,94.784,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.871 | Acc: 62.785,94.725,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.871 | Acc: 62.788,94.679,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.872 | Acc: 62.747,94.722,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 62.604,94.745,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 62.629,94.696,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.872 | Acc: 62.595,94.684,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.873 | Acc: 62.606,94.671,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.873 | Acc: 62.602,94.636,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.871 | Acc: 62.679,94.673,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.870 | Acc: 62.749,94.683,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 62.781,94.677,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.593 | Acc: 57.812,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.697 | Acc: 52.158,68.155,76.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 51.658,67.740,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.730 | Acc: 51.767,67.738,75.231,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 0.957 | Acc: 58.594,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.865 | Acc: 63.653,94.940,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.878 | Acc: 62.614,94.360,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.879 | Acc: 62.372,94.531,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.880 | Acc: 62.066,94.666,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.880 | Acc: 62.299,94.609,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.878 | Acc: 62.455,94.622,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.875 | Acc: 62.555,94.625,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.877 | Acc: 62.374,94.706,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.873 | Acc: 62.461,94.743,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.873 | Acc: 62.504,94.784,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 62.645,94.789,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.870 | Acc: 62.604,94.758,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 62.674,94.750,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 62.592,94.720,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.871 | Acc: 62.562,94.692,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.872 | Acc: 62.515,94.658,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.873 | Acc: 62.511,94.607,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.874 | Acc: 62.517,94.546,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.874 | Acc: 62.559,94.544,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.559 | Acc: 57.812,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.697 | Acc: 52.493,68.378,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.742 | Acc: 51.867,67.473,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.738 | Acc: 51.857,67.623,75.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 0.835 | Acc: 58.594,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.835 | Acc: 64.211,94.978,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.861 | Acc: 63.148,94.855,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.863 | Acc: 63.243,94.800,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 63.175,94.686,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 62.771,94.779,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.868 | Acc: 62.771,94.796,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.871 | Acc: 62.506,94.709,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.872 | Acc: 62.529,94.716,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.872 | Acc: 62.543,94.704,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.870 | Acc: 62.675,94.745,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.873 | Acc: 62.528,94.683,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.873 | Acc: 62.500,94.697,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.872 | Acc: 62.677,94.654,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.871 | Acc: 62.781,94.684,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.871 | Acc: 62.811,94.679,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.870 | Acc: 62.816,94.677,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 62.887,94.657,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.870 | Acc: 62.844,94.629,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 62.894,94.619,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.565 | Acc: 57.812,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.707 | Acc: 52.232,68.378,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.745 | Acc: 51.601,67.702,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.745 | Acc: 51.742,67.777,74.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 0.830 | Acc: 67.969,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.867 | Acc: 62.128,94.159,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.867 | Acc: 62.633,94.245,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.872 | Acc: 62.718,94.429,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.865 | Acc: 63.127,94.483,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 63.235,94.609,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.861 | Acc: 63.120,94.628,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.861 | Acc: 63.032,94.642,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.861 | Acc: 62.966,94.662,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.859 | Acc: 63.070,94.631,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.863 | Acc: 62.889,94.574,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.863 | Acc: 62.896,94.602,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.865 | Acc: 62.879,94.629,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.864 | Acc: 62.871,94.663,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.864 | Acc: 62.900,94.629,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.865 | Acc: 62.902,94.578,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 62.889,94.556,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 62.864,94.595,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 62.796,94.646,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 62.818,94.650,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.508 | Acc: 57.812,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 52.083,67.969,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.732 | Acc: 51.620,67.454,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.726 | Acc: 51.831,67.636,75.038,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 0.770 | Acc: 64.062,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.873 | Acc: 62.277,94.978,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.860 | Acc: 62.252,94.684,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.861 | Acc: 62.692,94.851,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.864 | Acc: 62.558,94.753,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.868 | Acc: 62.508,94.632,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.871 | Acc: 62.377,94.557,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.872 | Acc: 62.422,94.581,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.870 | Acc: 62.485,94.589,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.870 | Acc: 62.504,94.622,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.870 | Acc: 62.488,94.593,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.869 | Acc: 62.631,94.616,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.869 | Acc: 62.649,94.684,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 62.757,94.699,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.869 | Acc: 62.811,94.704,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.870 | Acc: 62.702,94.690,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.870 | Acc: 62.790,94.665,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.869 | Acc: 62.841,94.689,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.869 | Acc: 62.820,94.691,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 62.687,94.638,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.486 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.683 | Acc: 52.121,68.229,76.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.726 | Acc: 51.753,67.702,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.719 | Acc: 51.870,67.853,75.359,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 0.946 | Acc: 59.375,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.873 | Acc: 62.872,94.717,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 63.129,95.160,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.866 | Acc: 63.192,94.800,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.864 | Acc: 63.166,94.801,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.866 | Acc: 63.026,94.787,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.869 | Acc: 62.797,94.647,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.869 | Acc: 63.065,94.686,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.870 | Acc: 62.980,94.696,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.870 | Acc: 63.014,94.674,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.872 | Acc: 62.931,94.632,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.873 | Acc: 62.839,94.595,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.873 | Acc: 62.789,94.570,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.872 | Acc: 62.844,94.585,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.872 | Acc: 62.895,94.542,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.870 | Acc: 62.936,94.594,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.871 | Acc: 62.850,94.565,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.872 | Acc: 62.818,94.504,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.873 | Acc: 62.838,94.518,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.872 | Acc: 62.783,94.562,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.539 | Acc: 57.812,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.685 | Acc: 52.307,68.304,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 51.925,67.645,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.727 | Acc: 51.934,67.649,75.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 0.924 | Acc: 59.375,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.862 | Acc: 62.909,94.457,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.856 | Acc: 62.481,95.027,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.862 | Acc: 62.513,94.980,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 62.510,94.907,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.858 | Acc: 62.701,95.003,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 62.842,94.925,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.862 | Acc: 62.711,94.963,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.863 | Acc: 62.689,94.919,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 62.888,94.980,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.862 | Acc: 62.904,94.974,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 62.663,94.828,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 62.714,94.804,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 62.760,94.768,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.869 | Acc: 62.709,94.759,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.868 | Acc: 62.752,94.786,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 62.678,94.770,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.869 | Acc: 62.637,94.740,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.869 | Acc: 62.621,94.733,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 62.730,94.751,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.539 | Acc: 57.031,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.684 | Acc: 52.641,68.229,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.722 | Acc: 51.791,67.759,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.721 | Acc: 51.921,67.802,75.397,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 0.767 | Acc: 70.312,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.862 | Acc: 63.467,94.345,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.877 | Acc: 62.748,94.417,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 63.128,94.531,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 62.895,94.695,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.863 | Acc: 63.088,94.779,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 63.165,94.925,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.857 | Acc: 63.287,94.941,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.858 | Acc: 63.301,94.910,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.859 | Acc: 63.251,94.898,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.861 | Acc: 63.207,94.866,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.862 | Acc: 63.218,94.818,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.862 | Acc: 63.226,94.833,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.862 | Acc: 63.233,94.837,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.861 | Acc: 63.273,94.854,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.862 | Acc: 63.159,94.876,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.861 | Acc: 63.147,94.901,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.863 | Acc: 63.075,94.857,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.864 | Acc: 63.026,94.808,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.864 | Acc: 63.023,94.804,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.526 | Acc: 56.250,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.698 | Acc: 51.860,68.118,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 51.582,67.607,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.732 | Acc: 51.652,67.649,75.128,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 0.985 | Acc: 57.812,92.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 64.062,94.717,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.868 | Acc: 63.548,94.665,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 63.909,94.595,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.864 | Acc: 63.831,94.608,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.869 | Acc: 63.606,94.516,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.865 | Acc: 63.630,94.538,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.863 | Acc: 63.619,94.520,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.866 | Acc: 63.480,94.546,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.864 | Acc: 63.519,94.592,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.867 | Acc: 63.351,94.605,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.866 | Acc: 63.313,94.697,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.867 | Acc: 63.139,94.703,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 63.066,94.645,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.867 | Acc: 63.128,94.676,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 63.084,94.677,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 63.087,94.702,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 63.098,94.703,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 63.093,94.698,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 63.082,94.671,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.577 | Acc: 57.812,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 52.307,68.080,76.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 51.867,67.492,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.738 | Acc: 51.934,67.610,75.346,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 0.887 | Acc: 65.625,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.880 | Acc: 61.086,94.345,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.877 | Acc: 61.928,94.607,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.888 | Acc: 61.539,94.429,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.891 | Acc: 61.449,94.406,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.888 | Acc: 61.696,94.547,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.885 | Acc: 62.029,94.531,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.880 | Acc: 62.256,94.559,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.880 | Acc: 62.243,94.575,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.878 | Acc: 62.293,94.549,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.877 | Acc: 62.329,94.535,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.876 | Acc: 62.461,94.538,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.873 | Acc: 62.581,94.583,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.873 | Acc: 62.581,94.564,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.871 | Acc: 62.650,94.626,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 62.614,94.555,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.871 | Acc: 62.704,94.531,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 62.688,94.586,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.869 | Acc: 62.677,94.601,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 62.670,94.652,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.522 | Acc: 56.250,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.682 | Acc: 51.972,68.490,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 51.639,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.720 | Acc: 51.831,67.841,75.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 0.760 | Acc: 67.969,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 62.240,94.940,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.866 | Acc: 62.767,94.931,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.862 | Acc: 62.999,94.877,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 63.108,94.840,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.864 | Acc: 62.987,94.701,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.863 | Acc: 62.881,94.802,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.862 | Acc: 62.766,94.814,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.862 | Acc: 62.811,94.827,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.865 | Acc: 62.755,94.777,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.868 | Acc: 62.663,94.722,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.868 | Acc: 62.511,94.803,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.867 | Acc: 62.581,94.755,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 62.566,94.729,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.869 | Acc: 62.430,94.690,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.868 | Acc: 62.492,94.716,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 62.541,94.721,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.866 | Acc: 62.594,94.747,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 62.639,94.733,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.866 | Acc: 62.637,94.730,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.497 | Acc: 58.594,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.692 | Acc: 52.083,68.192,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.726 | Acc: 51.753,67.569,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.729 | Acc: 51.844,67.636,75.295,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 0.905 | Acc: 60.938,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.873 | Acc: 62.351,94.308,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.866 | Acc: 62.843,94.360,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.872 | Acc: 63.012,94.506,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.876 | Acc: 62.712,94.367,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.877 | Acc: 62.562,94.438,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.875 | Acc: 62.590,94.576,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 62.539,94.692,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.873 | Acc: 62.616,94.691,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.874 | Acc: 62.565,94.721,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.871 | Acc: 62.593,94.784,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 62.656,94.828,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 62.707,94.852,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 62.742,94.771,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 62.850,94.762,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.869 | Acc: 62.897,94.791,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.868 | Acc: 62.909,94.833,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.869 | Acc: 62.885,94.770,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.869 | Acc: 62.853,94.778,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.869 | Acc: 62.826,94.781,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.555 | Acc: 57.031,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.681 | Acc: 51.860,68.229,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.720 | Acc: 51.582,67.816,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 51.742,67.879,75.359,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.011 | Acc: 53.125,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.886 | Acc: 61.905,95.275,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.887 | Acc: 61.585,95.141,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.885 | Acc: 62.077,94.864,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.878 | Acc: 62.423,94.850,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.875 | Acc: 62.469,94.787,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.874 | Acc: 62.519,94.731,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 62.511,94.781,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.874 | Acc: 62.515,94.677,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.873 | Acc: 62.716,94.613,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.872 | Acc: 62.799,94.691,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.872 | Acc: 62.818,94.673,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 62.766,94.713,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.870 | Acc: 62.745,94.774,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.871 | Acc: 62.747,94.762,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.871 | Acc: 62.747,94.731,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.871 | Acc: 62.658,94.733,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.871 | Acc: 62.731,94.772,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.872 | Acc: 62.667,94.767,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.871 | Acc: 62.713,94.765,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.544 | Acc: 56.250,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.691 | Acc: 52.158,68.304,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 51.562,67.893,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.725 | Acc: 51.703,67.943,75.423,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 0.842 | Acc: 60.938,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.863 | Acc: 61.793,95.461,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.882 | Acc: 61.452,94.893,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.876 | Acc: 61.962,94.864,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.871 | Acc: 62.191,94.763,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.869 | Acc: 62.322,94.833,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 62.371,94.802,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.865 | Acc: 62.539,94.814,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.867 | Acc: 62.505,94.861,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.864 | Acc: 62.724,94.872,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 62.792,94.881,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.865 | Acc: 62.822,94.818,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.867 | Acc: 62.759,94.784,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.866 | Acc: 62.817,94.753,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.868 | Acc: 62.767,94.751,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.868 | Acc: 62.749,94.762,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 62.748,94.765,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.868 | Acc: 62.823,94.790,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 62.872,94.797,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 62.885,94.798,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.561 | Acc: 57.812,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 52.455,68.043,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.736 | Acc: 51.848,67.435,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.733 | Acc: 51.921,67.623,75.333,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 0.907 | Acc: 62.500,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 62.388,95.201,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.874 | Acc: 62.462,94.893,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 63.115,94.775,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.865 | Acc: 63.223,94.608,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.868 | Acc: 63.343,94.756,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.874 | Acc: 62.946,94.641,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.875 | Acc: 62.844,94.598,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.875 | Acc: 62.772,94.687,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.875 | Acc: 62.686,94.738,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.875 | Acc: 62.702,94.706,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.876 | Acc: 62.687,94.750,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.875 | Acc: 62.701,94.726,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.874 | Acc: 62.659,94.729,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.873 | Acc: 62.622,94.748,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 62.702,94.687,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.870 | Acc: 62.780,94.716,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.871 | Acc: 62.736,94.705,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.870 | Acc: 62.714,94.728,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.869 | Acc: 62.750,94.771,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.518 | Acc: 57.031,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.685 | Acc: 52.307,68.266,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 51.696,67.569,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.726 | Acc: 51.857,67.764,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 0.858 | Acc: 69.531,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.863 | Acc: 63.170,94.866,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.879 | Acc: 62.329,94.550,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.877 | Acc: 62.436,94.390,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 62.558,94.551,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 62.631,94.554,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.871 | Acc: 62.584,94.583,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.875 | Acc: 62.533,94.515,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.872 | Acc: 62.515,94.560,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.869 | Acc: 62.595,94.639,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.866 | Acc: 62.710,94.722,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.868 | Acc: 62.613,94.694,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 62.604,94.661,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 62.781,94.651,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.867 | Acc: 62.825,94.659,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.866 | Acc: 62.848,94.661,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 62.802,94.682,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 62.683,94.673,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.869 | Acc: 62.794,94.681,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 62.785,94.660,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.546 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 52.046,68.304,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.729 | Acc: 51.562,67.778,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.726 | Acc: 51.716,67.725,75.371,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 0.764 | Acc: 67.188,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.851 | Acc: 64.472,94.829,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.858 | Acc: 63.643,94.817,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.870 | Acc: 62.474,94.775,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.871 | Acc: 62.500,94.715,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 62.678,94.848,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.866 | Acc: 62.687,94.854,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.867 | Acc: 62.727,94.803,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.867 | Acc: 62.752,94.852,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.866 | Acc: 62.759,94.868,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.868 | Acc: 62.710,94.834,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.868 | Acc: 62.723,94.768,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 62.646,94.710,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 62.611,94.723,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.869 | Acc: 62.697,94.690,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.869 | Acc: 62.705,94.687,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 62.770,94.709,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.869 | Acc: 62.814,94.715,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 62.892,94.745,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 62.900,94.747,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.524 | Acc: 57.812,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 52.009,68.452,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 51.639,67.873,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.737 | Acc: 51.831,67.802,75.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 0.823 | Acc: 65.625,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.846 | Acc: 64.993,94.494,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.854 | Acc: 64.005,94.474,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.852 | Acc: 63.755,94.775,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.854 | Acc: 63.619,94.676,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.847 | Acc: 63.885,94.879,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 63.572,94.932,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.849 | Acc: 63.813,94.925,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.854 | Acc: 63.417,94.852,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.857 | Acc: 63.514,94.764,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.858 | Acc: 63.526,94.702,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.862 | Acc: 63.264,94.673,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.865 | Acc: 63.080,94.638,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.865 | Acc: 63.144,94.612,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.865 | Acc: 63.226,94.551,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.866 | Acc: 63.193,94.596,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 63.179,94.602,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 63.162,94.524,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 63.093,94.544,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 63.031,94.550,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.512 | Acc: 56.250,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.706 | Acc: 52.046,68.192,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.744 | Acc: 51.639,67.550,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.742 | Acc: 51.767,67.559,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 0.907 | Acc: 58.594,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.896 | Acc: 63.170,94.382,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.875 | Acc: 63.167,94.760,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.869 | Acc: 63.140,94.800,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 63.088,94.763,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 63.041,94.655,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.871 | Acc: 62.881,94.602,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.869 | Acc: 62.949,94.614,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.867 | Acc: 63.121,94.667,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.868 | Acc: 63.152,94.656,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.867 | Acc: 63.122,94.675,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.866 | Acc: 63.104,94.634,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 62.944,94.648,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 62.892,94.669,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.868 | Acc: 62.800,94.681,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 62.819,94.687,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 62.826,94.680,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.868 | Acc: 62.750,94.705,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 62.727,94.698,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 62.750,94.697,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.485 | Acc: 57.031,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.684 | Acc: 52.121,68.266,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.722 | Acc: 51.639,67.740,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.721 | Acc: 51.819,67.841,75.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 0.782 | Acc: 70.312,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.866 | Acc: 63.653,94.234,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.866 | Acc: 63.167,94.550,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.868 | Acc: 63.640,94.378,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.866 | Acc: 63.792,94.416,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 63.428,94.554,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.868 | Acc: 63.255,94.628,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 63.193,94.747,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.867 | Acc: 63.242,94.720,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.868 | Acc: 63.320,94.691,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.865 | Acc: 63.452,94.652,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.868 | Acc: 63.175,94.662,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.867 | Acc: 63.165,94.742,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.869 | Acc: 63.090,94.714,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.866 | Acc: 63.178,94.809,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 63.113,94.778,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 63.091,94.765,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 63.054,94.756,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 63.067,94.730,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 63.029,94.722,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.515 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.701 | Acc: 52.195,68.415,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.736 | Acc: 51.829,67.759,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.732 | Acc: 51.908,67.789,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 0.885 | Acc: 67.188,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.843 | Acc: 64.695,95.647,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.870 | Acc: 63.110,95.141,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.871 | Acc: 62.833,94.839,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.874 | Acc: 62.818,94.715,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 62.817,94.670,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.864 | Acc: 63.223,94.796,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.867 | Acc: 63.082,94.714,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 62.903,94.759,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.869 | Acc: 62.897,94.743,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.869 | Acc: 62.854,94.737,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.869 | Acc: 62.758,94.754,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 62.808,94.768,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 62.874,94.786,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.868 | Acc: 62.945,94.790,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.870 | Acc: 62.824,94.788,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 62.816,94.794,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.869 | Acc: 62.825,94.774,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 62.777,94.789,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 62.797,94.806,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.495 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 51.972,68.229,76.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 51.639,67.588,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.732 | Acc: 51.819,67.751,75.307,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 0.762 | Acc: 75.781,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.865 | Acc: 64.583,94.271,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.863 | Acc: 63.472,94.607,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 63.371,94.506,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.873 | Acc: 63.050,94.502,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.872 | Acc: 63.018,94.578,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.871 | Acc: 62.791,94.654,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 62.888,94.559,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.873 | Acc: 62.796,94.536,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.874 | Acc: 62.811,94.518,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.875 | Acc: 62.745,94.597,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.874 | Acc: 62.786,94.545,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.872 | Acc: 62.960,94.554,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 62.865,94.579,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 62.825,94.604,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 62.900,94.669,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.868 | Acc: 62.863,94.689,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.869 | Acc: 62.818,94.678,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.870 | Acc: 62.766,94.648,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 62.830,94.665,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.560 | Acc: 57.812,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.701 | Acc: 52.604,68.155,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.740 | Acc: 51.829,67.569,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.737 | Acc: 51.755,67.700,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 0.954 | Acc: 57.812,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.886 | Acc: 61.570,94.940,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.873 | Acc: 62.652,94.627,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.870 | Acc: 62.436,94.659,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 62.548,94.637,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.875 | Acc: 62.369,94.524,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.876 | Acc: 62.519,94.505,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.877 | Acc: 62.494,94.443,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.876 | Acc: 62.612,94.449,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.875 | Acc: 62.513,94.492,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.873 | Acc: 62.527,94.461,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.873 | Acc: 62.532,94.507,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 62.753,94.541,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.869 | Acc: 62.799,94.531,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.868 | Acc: 62.825,94.584,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.868 | Acc: 62.791,94.599,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 62.743,94.619,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 62.752,94.623,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 62.701,94.609,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.869 | Acc: 62.625,94.591,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.524 | Acc: 57.031,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.685 | Acc: 51.823,68.266,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.725 | Acc: 51.562,67.721,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.723 | Acc: 51.703,67.815,75.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 0.806 | Acc: 67.188,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 61.905,94.792,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.875 | Acc: 61.776,94.893,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.875 | Acc: 62.167,94.941,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.873 | Acc: 62.500,94.724,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.872 | Acc: 62.392,94.903,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 62.448,94.970,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.871 | Acc: 62.445,94.886,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 62.582,94.842,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.869 | Acc: 62.664,94.751,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.867 | Acc: 62.780,94.741,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 62.825,94.740,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.866 | Acc: 62.853,94.765,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.865 | Acc: 62.937,94.813,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.866 | Acc: 62.917,94.806,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 62.887,94.830,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.868 | Acc: 62.829,94.814,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.868 | Acc: 62.782,94.825,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 62.825,94.817,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.866 | Acc: 62.838,94.810,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.531 | Acc: 57.031,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 51.897,68.341,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.736 | Acc: 51.543,67.797,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.733 | Acc: 51.755,67.815,75.038,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 0.962 | Acc: 59.375,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.879 | Acc: 62.723,94.717,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 63.548,94.817,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.870 | Acc: 63.166,94.672,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 63.117,94.724,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.866 | Acc: 62.941,94.872,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.867 | Acc: 62.978,94.854,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 62.921,94.825,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.868 | Acc: 63.019,94.827,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.869 | Acc: 62.867,94.825,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.868 | Acc: 62.908,94.819,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.871 | Acc: 62.839,94.786,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.869 | Acc: 63.002,94.823,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 63.033,94.834,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.869 | Acc: 63.037,94.812,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.869 | Acc: 63.022,94.793,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 63.006,94.765,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 62.926,94.751,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.869 | Acc: 62.959,94.717,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 63.017,94.726,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.529 | Acc: 57.812,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 52.344,68.304,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 51.905,67.473,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.730 | Acc: 52.036,67.610,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 0.914 | Acc: 62.500,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.889 | Acc: 62.388,94.345,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.883 | Acc: 62.348,94.474,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.878 | Acc: 62.359,94.570,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.877 | Acc: 62.568,94.464,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.874 | Acc: 62.817,94.531,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.873 | Acc: 62.771,94.512,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.874 | Acc: 62.661,94.576,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.867 | Acc: 62.903,94.745,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.870 | Acc: 62.746,94.643,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.868 | Acc: 62.698,94.722,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.866 | Acc: 62.800,94.690,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 62.740,94.641,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 62.754,94.642,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.866 | Acc: 62.875,94.662,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 62.845,94.664,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 62.858,94.655,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.868 | Acc: 62.867,94.595,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.870 | Acc: 62.762,94.588,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 62.793,94.601,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.540 | Acc: 57.812,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.693 | Acc: 52.381,68.155,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 51.867,67.645,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.730 | Acc: 51.972,67.853,75.128,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 0.848 | Acc: 66.406,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.853 | Acc: 63.170,95.089,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.877 | Acc: 61.909,94.779,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.863 | Acc: 62.654,94.839,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.871 | Acc: 62.587,94.715,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 62.678,94.624,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 62.623,94.576,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.870 | Acc: 62.655,94.537,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 62.762,94.614,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.867 | Acc: 62.888,94.721,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.869 | Acc: 62.842,94.745,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 62.843,94.662,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.870 | Acc: 62.925,94.687,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 62.937,94.633,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.871 | Acc: 62.898,94.645,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.870 | Acc: 62.918,94.703,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 62.916,94.731,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.868 | Acc: 62.961,94.698,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 62.991,94.722,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 62.996,94.736,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.580 | Acc: 57.031,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.691 | Acc: 52.158,68.304,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 51.715,67.778,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.727 | Acc: 51.806,67.777,75.282,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 0.782 | Acc: 72.656,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.853 | Acc: 64.955,94.494,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.863 | Acc: 63.834,94.341,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.863 | Acc: 63.832,94.480,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 63.339,94.551,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.866 | Acc: 63.204,94.632,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.865 | Acc: 63.081,94.622,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.865 | Acc: 63.060,94.637,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.864 | Acc: 63.058,94.619,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.863 | Acc: 63.139,94.704,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 62.966,94.722,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.863 | Acc: 63.073,94.673,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.862 | Acc: 63.106,94.758,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.862 | Acc: 63.054,94.768,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.862 | Acc: 63.031,94.779,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.863 | Acc: 62.946,94.770,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.864 | Acc: 62.889,94.777,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.865 | Acc: 62.869,94.765,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.864 | Acc: 62.913,94.791,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.864 | Acc: 62.931,94.786,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.502 | Acc: 57.031,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 52.158,68.118,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 51.925,67.550,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.729 | Acc: 51.998,67.738,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 0.896 | Acc: 63.281,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.871 | Acc: 62.537,94.978,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.852 | Acc: 63.053,95.179,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.862 | Acc: 62.897,95.069,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 62.490,94.946,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.873 | Acc: 62.461,95.003,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 62.597,95.112,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.872 | Acc: 62.395,94.986,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.870 | Acc: 62.539,94.856,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.868 | Acc: 62.724,94.898,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.867 | Acc: 62.772,94.928,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.868 | Acc: 62.857,94.899,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.869 | Acc: 62.801,94.885,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.870 | Acc: 62.716,94.914,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 62.656,94.868,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.869 | Acc: 62.778,94.866,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 62.743,94.894,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.868 | Acc: 62.839,94.893,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 62.771,94.903,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 62.775,94.915,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.542 | Acc: 57.812,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 52.344,68.304,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.739 | Acc: 51.905,67.454,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.738 | Acc: 51.934,67.687,75.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 0.934 | Acc: 56.250,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.885 | Acc: 62.649,94.345,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.878 | Acc: 63.110,94.703,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.878 | Acc: 63.038,94.685,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.874 | Acc: 63.156,94.840,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.870 | Acc: 63.165,94.848,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.867 | Acc: 63.068,94.886,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.871 | Acc: 63.015,94.875,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.868 | Acc: 63.077,94.842,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.869 | Acc: 63.035,94.721,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.869 | Acc: 62.990,94.780,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 62.995,94.757,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.866 | Acc: 63.022,94.797,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.866 | Acc: 62.937,94.819,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.865 | Acc: 62.864,94.848,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.866 | Acc: 62.874,94.840,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.865 | Acc: 62.923,94.835,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.865 | Acc: 62.922,94.795,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 62.913,94.771,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 62.826,94.734,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.526 | Acc: 57.031,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.698 | Acc: 51.823,68.266,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.739 | Acc: 51.543,67.835,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.739 | Acc: 51.819,67.725,75.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 0.924 | Acc: 61.719,92.188,100.000,% | Adaptive Acc: 94.531% | clf_exit: 0.422 0.492 0.086
Batch: 20 | Loss: 0.884 | Acc: 62.314,94.271,99.888,% | Adaptive Acc: 92.857% | clf_exit: 0.440 0.487 0.072
Batch: 40 | Loss: 0.882 | Acc: 62.443,94.379,99.829,% | Adaptive Acc: 92.569% | clf_exit: 0.446 0.489 0.065
Batch: 60 | Loss: 0.876 | Acc: 62.257,94.647,99.834,% | Adaptive Acc: 92.687% | clf_exit: 0.445 0.492 0.063
Batch: 80 | Loss: 0.880 | Acc: 61.979,94.560,99.836,% | Adaptive Acc: 92.728% | clf_exit: 0.442 0.496 0.062
Batch: 100 | Loss: 0.879 | Acc: 62.075,94.531,99.845,% | Adaptive Acc: 92.752% | clf_exit: 0.442 0.496 0.062
Batch: 120 | Loss: 0.875 | Acc: 62.242,94.576,99.858,% | Adaptive Acc: 92.872% | clf_exit: 0.442 0.497 0.061
Batch: 140 | Loss: 0.877 | Acc: 62.195,94.553,99.861,% | Adaptive Acc: 92.963% | clf_exit: 0.441 0.498 0.061
Batch: 160 | Loss: 0.877 | Acc: 62.262,94.623,99.854,% | Adaptive Acc: 92.964% | clf_exit: 0.442 0.497 0.061
Batch: 180 | Loss: 0.874 | Acc: 62.371,94.738,99.853,% | Adaptive Acc: 93.012% | clf_exit: 0.442 0.498 0.060
Batch: 200 | Loss: 0.874 | Acc: 62.376,94.683,99.856,% | Adaptive Acc: 92.977% | clf_exit: 0.441 0.499 0.060
Batch: 220 | Loss: 0.874 | Acc: 62.532,94.666,99.834,% | Adaptive Acc: 93.061% | clf_exit: 0.441 0.498 0.061
Batch: 240 | Loss: 0.874 | Acc: 62.549,94.638,99.825,% | Adaptive Acc: 93.105% | clf_exit: 0.440 0.498 0.061
Batch: 260 | Loss: 0.871 | Acc: 62.739,94.693,99.820,% | Adaptive Acc: 93.118% | clf_exit: 0.441 0.498 0.061
Batch: 280 | Loss: 0.871 | Acc: 62.731,94.765,99.822,% | Adaptive Acc: 93.186% | clf_exit: 0.441 0.498 0.061
Batch: 300 | Loss: 0.872 | Acc: 62.721,94.757,99.829,% | Adaptive Acc: 93.213% | clf_exit: 0.441 0.498 0.061
Batch: 320 | Loss: 0.871 | Acc: 62.707,94.758,99.837,% | Adaptive Acc: 93.232% | clf_exit: 0.441 0.498 0.062
Batch: 340 | Loss: 0.870 | Acc: 62.697,94.776,99.826,% | Adaptive Acc: 93.253% | clf_exit: 0.441 0.498 0.061
Batch: 360 | Loss: 0.870 | Acc: 62.699,94.804,99.831,% | Adaptive Acc: 93.287% | clf_exit: 0.441 0.498 0.061
Batch: 380 | Loss: 0.871 | Acc: 62.609,94.792,99.838,% | Adaptive Acc: 93.241% | clf_exit: 0.442 0.497 0.062
Batch: 0 | Loss: 2.548 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 67.969% | clf_exit: 0.484 0.375 0.141
Batch: 20 | Loss: 2.694 | Acc: 51.860,68.155,75.707,% | Adaptive Acc: 68.304% | clf_exit: 0.472 0.367 0.161
Batch: 40 | Loss: 2.737 | Acc: 51.505,67.492,74.962,% | Adaptive Acc: 67.607% | clf_exit: 0.468 0.361 0.171
Batch: 60 | Loss: 2.730 | Acc: 51.755,67.738,75.128,% | Adaptive Acc: 68.058% | clf_exit: 0.470 0.358 0.172
model is save as models/modelG_2con3_cifar100_adaptive0_circles5_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 6.711 | Acc: 57.031,27.344,8.594,% | Adaptive Acc: 41.406% | clf_exit: 0.484 0.000 0.516
Batch: 20 | Loss: 6.665 | Acc: 51.860,27.083,7.180,% | Adaptive Acc: 39.174% | clf_exit: 0.472 0.001 0.528
Batch: 40 | Loss: 6.637 | Acc: 51.505,27.001,7.107,% | Adaptive Acc: 39.367% | clf_exit: 0.468 0.000 0.531
Batch: 60 | Loss: 6.656 | Acc: 51.755,26.934,7.108,% | Adaptive Acc: 39.588% | clf_exit: 0.470 0.000 0.529
Batch: 0 | Loss: 4.704 | Acc: 57.031,56.250,41.406,% | Adaptive Acc: 54.688% | clf_exit: 0.484 0.016 0.500
Batch: 20 | Loss: 4.810 | Acc: 51.860,52.679,39.174,% | Adaptive Acc: 50.856% | clf_exit: 0.472 0.019 0.510
Batch: 40 | Loss: 4.789 | Acc: 51.505,52.363,40.473,% | Adaptive Acc: 51.277% | clf_exit: 0.468 0.015 0.517
Batch: 60 | Loss: 4.811 | Acc: 51.755,52.766,40.113,% | Adaptive Acc: 51.306% | clf_exit: 0.470 0.015 0.514
Batch: 0 | Loss: 3.516 | Acc: 57.031,62.500,67.188,% | Adaptive Acc: 64.844% | clf_exit: 0.484 0.086 0.430
Batch: 20 | Loss: 3.662 | Acc: 51.860,62.723,64.658,% | Adaptive Acc: 63.021% | clf_exit: 0.472 0.071 0.457
Batch: 40 | Loss: 3.660 | Acc: 51.505,62.633,64.272,% | Adaptive Acc: 62.729% | clf_exit: 0.468 0.074 0.458
Batch: 60 | Loss: 3.677 | Acc: 51.755,62.871,63.870,% | Adaptive Acc: 62.743% | clf_exit: 0.470 0.075 0.455
Batch: 0 | Loss: 2.830 | Acc: 57.031,66.406,72.656,% | Adaptive Acc: 67.188% | clf_exit: 0.484 0.195 0.320
Batch: 20 | Loss: 2.965 | Acc: 51.860,66.295,73.400,% | Adaptive Acc: 68.304% | clf_exit: 0.472 0.180 0.349
Batch: 40 | Loss: 2.981 | Acc: 51.505,66.273,72.618,% | Adaptive Acc: 67.778% | clf_exit: 0.468 0.181 0.351
Batch: 60 | Loss: 2.990 | Acc: 51.755,66.483,72.605,% | Adaptive Acc: 68.058% | clf_exit: 0.470 0.178 0.351
Batch: 0 | Loss: 2.503 | Acc: 57.031,68.750,75.000,% | Adaptive Acc: 69.531% | clf_exit: 0.484 0.305 0.211
Batch: 20 | Loss: 2.645 | Acc: 51.860,67.634,75.818,% | Adaptive Acc: 69.420% | clf_exit: 0.472 0.289 0.239
Batch: 40 | Loss: 2.674 | Acc: 51.505,67.340,74.771,% | Adaptive Acc: 68.579% | clf_exit: 0.468 0.284 0.247
Batch: 60 | Loss: 2.675 | Acc: 51.755,67.533,74.782,% | Adaptive Acc: 68.814% | clf_exit: 0.470 0.280 0.249
Batch: 0 | Loss: 2.548 | Acc: 57.031,70.312,76.562,% | Adaptive Acc: 67.969% | clf_exit: 0.484 0.375 0.141
Batch: 20 | Loss: 2.694 | Acc: 51.860,68.155,75.707,% | Adaptive Acc: 68.304% | clf_exit: 0.472 0.367 0.161
Batch: 40 | Loss: 2.737 | Acc: 51.505,67.492,74.962,% | Adaptive Acc: 67.607% | clf_exit: 0.468 0.361 0.171
Batch: 60 | Loss: 2.730 | Acc: 51.755,67.738,75.128,% | Adaptive Acc: 68.058% | clf_exit: 0.470 0.358 0.172







Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 7.909 |  Acc: 5.182,8.218,15.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 7.419 |  Acc: 6.950,11.510,19.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 6.797 |  Acc: 9.126,15.582,28.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 6.429 |  Acc: 10.150,16.520,31.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 6.072 |  Acc: 12.522,20.764,36.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 5.873 |  Acc: 13.430,20.870,38.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 5.529 |  Acc: 16.290,24.568,42.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 5.528 |  Acc: 16.190,24.020,43.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 5.125 |  Acc: 18.830,27.740,47.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 5.065 |  Acc: 19.220,27.580,49.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 4.810 |  Acc: 21.294,30.044,51.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 4.871 |  Acc: 20.780,28.690,51.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 4.549 |  Acc: 23.452,32.894,54.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 4.666 |  Acc: 21.400,29.000,55.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 4.323 |  Acc: 25.116,35.192,57.746,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 4.520 |  Acc: 23.050,32.900,55.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 4.119 |  Acc: 26.856,37.288,60.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 4.323 |  Acc: 25.290,36.940,56.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 3.946 |  Acc: 27.980,39.056,62.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 4.215 |  Acc: 25.510,36.940,59.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 3.805 |  Acc: 28.990,41.032,64.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 4.064 |  Acc: 27.230,38.800,60.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 3.655 |  Acc: 30.386,42.750,66.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 3.960 |  Acc: 27.570,40.310,62.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 3.535 |  Acc: 31.336,44.144,68.270,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 3.930 |  Acc: 27.580,40.240,63.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 3.426 |  Acc: 32.250,45.556,69.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 3.918 |  Acc: 27.670,40.770,62.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 3.316 |  Acc: 32.948,46.692,71.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 3.808 |  Acc: 29.490,44.530,63.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 3.231 |  Acc: 33.614,48.054,72.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 3.727 |  Acc: 31.620,43.630,64.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 3.144 |  Acc: 34.448,48.620,73.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 3.729 |  Acc: 32.400,45.170,64.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 3.061 |  Acc: 34.980,50.118,75.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 3.662 |  Acc: 31.680,47.190,64.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 2.993 |  Acc: 35.714,51.106,76.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 3.668 |  Acc: 31.790,46.880,64.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 2.916 |  Acc: 36.066,52.060,77.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 3.686 |  Acc: 30.280,46.480,66.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 2.865 |  Acc: 36.822,52.934,78.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 3.636 |  Acc: 33.440,46.950,66.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 2.806 |  Acc: 37.282,53.610,78.998,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 3.601 |  Acc: 32.160,49.130,66.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 2.749 |  Acc: 37.744,54.546,79.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 3.512 |  Acc: 34.610,49.890,67.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 2.703 |  Acc: 38.038,55.048,80.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 3.713 |  Acc: 32.150,47.890,65.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 2.656 |  Acc: 38.466,55.966,81.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 3.461 |  Acc: 36.130,50.690,67.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 2.603 |  Acc: 38.992,56.348,82.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 3.552 |  Acc: 34.790,49.270,67.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 2.564 |  Acc: 39.248,56.934,82.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 3.476 |  Acc: 35.280,51.590,67.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 2.535 |  Acc: 39.464,57.350,83.308,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 3.617 |  Acc: 35.650,49.230,66.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 2.491 |  Acc: 39.916,58.156,83.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 3.490 |  Acc: 35.570,52.310,67.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 2.480 |  Acc: 40.378,58.326,83.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 3.560 |  Acc: 33.990,51.970,66.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 2.432 |  Acc: 40.514,59.118,84.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 3.394 |  Acc: 36.500,53.120,68.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 2.418 |  Acc: 40.764,59.398,84.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 3.451 |  Acc: 37.380,53.460,66.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 2.381 |  Acc: 40.840,59.470,85.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 3.557 |  Acc: 35.190,52.190,66.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 2.355 |  Acc: 41.486,60.260,85.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 3.636 |  Acc: 35.780,49.880,65.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 2.341 |  Acc: 41.460,60.310,85.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 3.587 |  Acc: 32.880,51.120,67.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 2.309 |  Acc: 41.766,60.634,86.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 3.474 |  Acc: 36.810,54.040,66.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 2.292 |  Acc: 42.052,61.190,86.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 3.430 |  Acc: 39.350,54.000,67.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 2.285 |  Acc: 42.292,61.366,86.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 3.373 |  Acc: 38.640,54.930,67.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 2.265 |  Acc: 42.536,61.490,86.884,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 3.621 |  Acc: 33.450,52.580,66.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 2.246 |  Acc: 42.742,61.984,87.140,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 3.419 |  Acc: 37.360,55.430,67.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 2.231 |  Acc: 42.930,62.224,87.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 3.511 |  Acc: 37.760,53.750,66.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 2.210 |  Acc: 42.932,62.452,87.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 3.480 |  Acc: 38.110,52.760,66.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 2.191 |  Acc: 43.354,63.140,88.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 3.437 |  Acc: 38.240,53.660,67.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 2.185 |  Acc: 43.344,62.974,87.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 3.569 |  Acc: 35.850,53.390,66.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 2.189 |  Acc: 43.764,63.162,87.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 3.423 |  Acc: 36.020,57.080,68.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 2.161 |  Acc: 43.688,63.206,88.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 3.488 |  Acc: 36.940,55.260,65.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 2.169 |  Acc: 43.784,63.318,88.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 3.446 |  Acc: 39.250,55.210,66.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 2.133 |  Acc: 44.250,63.830,88.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 3.416 |  Acc: 37.610,56.230,67.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 2.128 |  Acc: 44.236,64.232,88.588,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 3.367 |  Acc: 39.380,56.260,67.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 2.119 |  Acc: 44.268,64.314,88.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 3.442 |  Acc: 39.790,55.320,66.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 2.107 |  Acc: 44.520,64.294,88.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 3.426 |  Acc: 38.390,56.380,66.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 2.091 |  Acc: 44.796,64.642,89.060,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 3.679 |  Acc: 37.350,54.120,64.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 2.092 |  Acc: 44.796,64.840,88.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 3.413 |  Acc: 40.490,55.550,66.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 2.091 |  Acc: 44.760,64.696,88.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 3.360 |  Acc: 39.500,56.370,67.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 2.084 |  Acc: 44.924,65.066,89.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 3.468 |  Acc: 38.800,54.290,66.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 2.053 |  Acc: 45.218,65.374,89.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 3.477 |  Acc: 37.350,55.470,67.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 2.062 |  Acc: 45.232,65.594,89.114,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 3.381 |  Acc: 39.480,55.650,68.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 2.062 |  Acc: 45.116,65.488,89.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 3.365 |  Acc: 40.210,56.000,67.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 2.050 |  Acc: 45.546,65.620,89.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 3.449 |  Acc: 39.880,54.980,66.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 2.051 |  Acc: 45.512,65.856,89.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 3.504 |  Acc: 39.740,56.020,66.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 2.035 |  Acc: 45.706,66.058,89.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 3.352 |  Acc: 40.600,56.420,67.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 2.027 |  Acc: 45.476,66.440,89.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 3.446 |  Acc: 40.090,55.930,66.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 2.018 |  Acc: 45.914,66.182,89.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 3.502 |  Acc: 37.840,54.770,67.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 2.000 |  Acc: 46.144,66.526,89.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 3.384 |  Acc: 40.600,55.820,67.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 1.994 |  Acc: 46.142,66.832,89.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 3.524 |  Acc: 36.210,55.940,67.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 2.012 |  Acc: 46.270,66.340,89.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 3.447 |  Acc: 39.670,55.420,67.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 2.000 |  Acc: 46.272,66.500,89.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 3.423 |  Acc: 40.180,56.230,66.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 1.989 |  Acc: 46.322,66.648,90.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 3.692 |  Acc: 34.790,54.860,65.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 1.977 |  Acc: 46.364,67.150,89.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 3.560 |  Acc: 40.500,54.340,65.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 1.970 |  Acc: 46.718,67.060,90.114,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 3.469 |  Acc: 38.570,56.030,66.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 1.987 |  Acc: 46.496,66.966,89.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 3.454 |  Acc: 39.300,55.260,66.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 1.954 |  Acc: 46.758,67.588,90.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 3.394 |  Acc: 39.570,56.930,66.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 1.963 |  Acc: 46.792,67.406,90.050,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 3.502 |  Acc: 39.630,55.340,66.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 1.969 |  Acc: 46.508,67.352,89.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 3.631 |  Acc: 36.030,55.640,66.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 1.964 |  Acc: 46.882,67.382,89.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 3.423 |  Acc: 39.710,56.910,67.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 1.963 |  Acc: 47.080,67.420,89.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 3.363 |  Acc: 39.870,58.050,67.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 1.937 |  Acc: 47.232,68.134,90.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 3.551 |  Acc: 39.190,54.800,65.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 1.940 |  Acc: 47.134,67.742,90.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 3.435 |  Acc: 40.830,56.340,66.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 1.938 |  Acc: 47.596,67.790,90.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 3.497 |  Acc: 39.140,56.740,67.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 1.933 |  Acc: 47.232,67.940,90.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 3.408 |  Acc: 40.990,56.710,66.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 1.930 |  Acc: 46.950,68.010,90.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 3.547 |  Acc: 38.090,54.380,66.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 1.930 |  Acc: 47.184,67.862,90.474,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 3.517 |  Acc: 39.550,55.640,67.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 1.915 |  Acc: 47.530,68.158,90.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 3.246 |  Acc: 42.580,58.510,68.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 1.911 |  Acc: 47.558,68.678,90.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 3.358 |  Acc: 40.390,57.360,68.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 1.906 |  Acc: 47.800,68.766,90.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 3.483 |  Acc: 39.650,56.490,67.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 1.923 |  Acc: 47.612,68.330,90.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 3.378 |  Acc: 39.140,57.840,68.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 1.900 |  Acc: 47.558,68.612,90.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 3.288 |  Acc: 41.370,58.650,68.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 1.916 |  Acc: 47.708,68.360,90.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 3.438 |  Acc: 41.350,56.610,66.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 1.898 |  Acc: 47.742,68.820,90.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 3.403 |  Acc: 39.890,57.120,67.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 1.894 |  Acc: 47.998,68.826,90.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 3.405 |  Acc: 40.710,56.990,67.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 1.891 |  Acc: 47.892,69.052,90.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 3.406 |  Acc: 41.710,57.910,66.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 1.902 |  Acc: 47.852,68.764,90.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 3.477 |  Acc: 41.840,56.810,66.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 1.883 |  Acc: 48.108,69.358,90.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 3.247 |  Acc: 42.570,60.100,68.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 1.893 |  Acc: 47.834,68.940,90.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 3.484 |  Acc: 40.960,55.900,66.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 1.877 |  Acc: 48.084,69.336,90.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 3.361 |  Acc: 41.480,58.470,68.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 1.884 |  Acc: 48.226,69.222,90.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 3.445 |  Acc: 38.760,57.960,67.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 1.871 |  Acc: 48.496,69.348,90.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 3.359 |  Acc: 42.800,58.120,67.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 1.877 |  Acc: 48.276,69.142,90.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 3.356 |  Acc: 42.190,58.430,66.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 1.879 |  Acc: 48.018,69.430,90.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 3.468 |  Acc: 41.960,55.890,65.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 1.887 |  Acc: 48.118,69.258,90.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 3.489 |  Acc: 40.320,56.310,66.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 1.870 |  Acc: 48.202,69.614,90.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 3.331 |  Acc: 41.750,58.670,68.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 1.864 |  Acc: 48.522,69.330,90.942,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 3.304 |  Acc: 42.450,58.810,68.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 1.869 |  Acc: 48.298,69.650,90.736,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 3.344 |  Acc: 41.820,58.590,67.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 1.862 |  Acc: 48.540,69.552,90.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 3.429 |  Acc: 41.330,57.640,66.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 1.849 |  Acc: 48.808,69.764,90.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 3.551 |  Acc: 39.650,57.200,66.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 1.834 |  Acc: 48.896,70.068,91.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 3.391 |  Acc: 40.850,58.020,67.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 1.853 |  Acc: 48.544,69.740,90.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 3.371 |  Acc: 42.690,57.790,66.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 1.853 |  Acc: 48.714,69.880,90.988,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 3.530 |  Acc: 40.330,55.890,66.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 1.863 |  Acc: 48.746,69.664,90.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 3.467 |  Acc: 38.040,57.160,66.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 1.833 |  Acc: 48.910,70.040,91.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 3.328 |  Acc: 42.500,59.590,67.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 1.849 |  Acc: 48.704,70.096,90.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 3.321 |  Acc: 42.260,57.990,67.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 1.825 |  Acc: 49.136,70.148,91.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 3.450 |  Acc: 42.080,56.410,66.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 1.837 |  Acc: 48.890,70.074,91.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 3.469 |  Acc: 41.270,56.960,66.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 1.833 |  Acc: 48.848,70.138,91.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 3.332 |  Acc: 41.330,59.580,68.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 1.823 |  Acc: 48.968,70.356,91.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 3.376 |  Acc: 41.770,58.580,67.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 1.837 |  Acc: 49.136,70.036,90.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 3.639 |  Acc: 38.910,55.050,65.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 1.821 |  Acc: 49.256,70.372,91.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 3.520 |  Acc: 40.660,56.220,66.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 1.819 |  Acc: 49.080,70.532,91.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 3.367 |  Acc: 40.590,58.360,67.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 1.833 |  Acc: 49.170,70.328,90.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 3.334 |  Acc: 40.910,58.590,67.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 1.812 |  Acc: 49.350,70.466,91.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 3.512 |  Acc: 38.820,57.300,66.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 1.825 |  Acc: 49.240,70.490,91.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 3.408 |  Acc: 41.760,58.090,67.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 1.800 |  Acc: 49.534,70.804,91.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 3.528 |  Acc: 38.390,56.260,67.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 1.829 |  Acc: 49.222,70.424,91.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 3.400 |  Acc: 41.610,57.790,67.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 1.802 |  Acc: 49.526,71.014,91.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 3.397 |  Acc: 41.600,57.220,66.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 1.820 |  Acc: 49.338,70.394,91.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 3.237 |  Acc: 44.540,60.050,68.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 1.808 |  Acc: 49.660,70.730,91.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 3.315 |  Acc: 42.430,58.400,67.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 1.804 |  Acc: 49.750,70.930,91.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 3.466 |  Acc: 40.800,57.660,66.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 1.799 |  Acc: 49.712,70.716,91.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 3.325 |  Acc: 42.140,59.350,67.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 1.801 |  Acc: 49.566,70.878,91.274,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 3.381 |  Acc: 42.610,58.920,66.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 1.795 |  Acc: 49.644,70.978,91.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 3.541 |  Acc: 41.130,55.670,66.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 1.796 |  Acc: 49.880,71.152,91.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 3.486 |  Acc: 41.220,57.600,66.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 1.824 |  Acc: 49.342,70.472,91.008,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 3.397 |  Acc: 41.640,59.000,67.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 1.802 |  Acc: 49.796,71.134,91.186,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 3.428 |  Acc: 40.850,58.170,67.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 1.776 |  Acc: 49.738,71.256,91.774,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 3.264 |  Acc: 42.970,58.430,68.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 1.806 |  Acc: 49.608,70.886,90.976,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 3.642 |  Acc: 38.690,55.790,66.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 1.789 |  Acc: 49.644,71.032,91.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 3.344 |  Acc: 40.500,58.380,68.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 1.770 |  Acc: 49.974,71.356,91.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 3.332 |  Acc: 43.270,58.150,67.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 1.852 |  Acc: 49.094,70.214,90.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 3.507 |  Acc: 41.350,56.780,66.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 1.782 |  Acc: 49.892,71.228,91.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 3.336 |  Acc: 41.910,59.190,67.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 1.793 |  Acc: 49.702,71.322,91.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 3.391 |  Acc: 43.320,57.550,66.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 1.773 |  Acc: 49.964,71.402,91.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 3.412 |  Acc: 41.310,58.070,67.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 1.776 |  Acc: 50.036,71.344,91.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 3.290 |  Acc: 43.320,59.920,67.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 1.772 |  Acc: 49.944,71.592,91.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 3.362 |  Acc: 41.340,59.370,68.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 1.774 |  Acc: 50.176,71.448,91.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 3.461 |  Acc: 40.710,58.050,66.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 1.771 |  Acc: 49.876,71.604,91.596,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 3.379 |  Acc: 42.280,58.670,67.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 1.778 |  Acc: 50.476,71.430,91.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 3.503 |  Acc: 41.830,56.670,64.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 1.773 |  Acc: 50.026,71.296,91.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 3.365 |  Acc: 40.950,60.120,67.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 1.781 |  Acc: 49.964,71.532,91.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 3.434 |  Acc: 41.410,59.020,66.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 1.760 |  Acc: 50.148,71.790,91.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 3.432 |  Acc: 41.560,57.650,66.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 1.762 |  Acc: 50.084,71.278,91.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 3.434 |  Acc: 42.770,58.280,67.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 1.424 |  Acc: 53.966,78.914,96.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 2.693 |  Acc: 49.840,67.700,74.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 1.296 |  Acc: 55.582,81.644,98.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 2.653 |  Acc: 50.360,68.040,74.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.263 |  Acc: 55.820,82.376,98.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 2.657 |  Acc: 50.710,68.140,74.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.237 |  Acc: 56.228,83.004,98.884,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 2.636 |  Acc: 50.790,68.640,74.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.220 |  Acc: 56.512,83.396,99.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 2.649 |  Acc: 50.780,68.490,74.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.204 |  Acc: 56.546,83.846,99.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 2.642 |  Acc: 50.780,68.510,75.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.191 |  Acc: 56.648,84.234,99.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 2.632 |  Acc: 50.670,68.690,75.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.180 |  Acc: 56.764,84.554,99.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 2.642 |  Acc: 50.730,68.700,75.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.170 |  Acc: 56.924,84.750,99.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 2.648 |  Acc: 50.780,68.640,75.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.160 |  Acc: 57.156,85.028,99.432,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 2.662 |  Acc: 50.640,68.520,75.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 1.151 |  Acc: 57.200,85.388,99.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 2.643 |  Acc: 50.990,68.840,75.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.143 |  Acc: 57.336,85.492,99.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 2.644 |  Acc: 50.790,68.680,75.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.135 |  Acc: 57.632,85.812,99.500,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 2.649 |  Acc: 51.340,68.660,75.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.130 |  Acc: 57.428,85.782,99.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 2.652 |  Acc: 51.370,68.600,75.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.125 |  Acc: 57.886,85.940,99.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 2.649 |  Acc: 51.260,68.900,75.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.119 |  Acc: 57.828,85.958,99.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 2.663 |  Acc: 50.750,68.730,75.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.111 |  Acc: 57.932,86.316,99.544,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 2.660 |  Acc: 51.280,68.350,75.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.105 |  Acc: 57.838,86.644,99.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 2.655 |  Acc: 51.240,68.460,75.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.099 |  Acc: 58.070,86.712,99.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 2.668 |  Acc: 51.080,68.180,75.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.097 |  Acc: 57.930,86.970,99.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 2.658 |  Acc: 50.890,68.170,75.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.091 |  Acc: 58.120,87.102,99.586,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 2.664 |  Acc: 51.370,68.310,75.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.089 |  Acc: 57.948,87.016,99.626,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 2.667 |  Acc: 51.380,68.070,75.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.083 |  Acc: 58.422,87.382,99.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 2.654 |  Acc: 51.100,68.480,75.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.078 |  Acc: 58.382,87.460,99.614,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 2.670 |  Acc: 51.170,68.440,75.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.075 |  Acc: 58.398,87.492,99.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 2.679 |  Acc: 51.460,68.280,75.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.067 |  Acc: 58.522,87.766,99.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 2.677 |  Acc: 51.130,68.400,75.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.065 |  Acc: 58.742,87.820,99.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 2.674 |  Acc: 51.280,68.170,75.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.060 |  Acc: 58.832,87.880,99.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 2.671 |  Acc: 51.180,68.460,75.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.060 |  Acc: 58.604,88.058,99.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 2.674 |  Acc: 51.370,68.290,75.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.057 |  Acc: 58.598,88.078,99.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 2.676 |  Acc: 51.160,68.160,75.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.051 |  Acc: 58.908,88.138,99.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 2.666 |  Acc: 51.250,68.650,75.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.048 |  Acc: 58.724,88.244,99.668,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 2.683 |  Acc: 50.960,67.990,75.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.044 |  Acc: 58.896,88.494,99.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 2.666 |  Acc: 51.160,68.160,75.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.044 |  Acc: 58.936,88.432,99.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 2.679 |  Acc: 51.250,67.700,75.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.039 |  Acc: 58.820,88.668,99.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 2.685 |  Acc: 51.150,68.020,75.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.037 |  Acc: 59.014,88.708,99.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 2.683 |  Acc: 51.380,67.770,75.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.033 |  Acc: 58.884,88.906,99.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 2.669 |  Acc: 51.490,68.530,75.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.029 |  Acc: 59.100,88.976,99.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 2.673 |  Acc: 51.400,68.010,75.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.030 |  Acc: 59.194,88.964,99.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 2.695 |  Acc: 51.170,67.620,75.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.026 |  Acc: 59.372,89.092,99.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 2.709 |  Acc: 50.840,67.420,75.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.019 |  Acc: 59.456,89.244,99.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 2.700 |  Acc: 50.790,68.060,75.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.017 |  Acc: 59.510,89.240,99.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 2.691 |  Acc: 50.910,67.770,75.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.016 |  Acc: 59.436,89.484,99.684,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 2.682 |  Acc: 51.120,68.120,75.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.014 |  Acc: 59.700,89.318,99.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 2.704 |  Acc: 51.120,67.900,75.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.013 |  Acc: 59.650,89.590,99.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 2.703 |  Acc: 51.230,67.730,75.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.010 |  Acc: 59.642,89.512,99.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 2.714 |  Acc: 50.990,67.820,74.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.008 |  Acc: 59.518,89.672,99.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 2.709 |  Acc: 51.120,67.710,75.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.004 |  Acc: 59.472,89.852,99.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 2.720 |  Acc: 51.340,67.750,75.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.003 |  Acc: 59.596,89.872,99.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 2.724 |  Acc: 50.940,67.410,75.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.003 |  Acc: 59.900,89.834,99.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 2.722 |  Acc: 50.430,67.420,75.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.000 |  Acc: 59.894,89.784,99.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 2.707 |  Acc: 51.220,67.710,75.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 0.996 |  Acc: 59.894,90.090,99.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 2.709 |  Acc: 51.750,67.720,75.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 0.990 |  Acc: 60.052,90.152,99.764,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 2.713 |  Acc: 51.290,67.690,75.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 0.991 |  Acc: 59.634,90.266,99.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 2.726 |  Acc: 50.880,67.430,75.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 0.992 |  Acc: 60.202,90.112,99.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 2.711 |  Acc: 51.340,67.600,75.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 0.993 |  Acc: 59.892,90.002,99.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 2.715 |  Acc: 51.180,67.750,75.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 0.986 |  Acc: 60.212,90.366,99.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 2.715 |  Acc: 50.830,67.930,75.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 0.988 |  Acc: 59.848,90.246,99.764,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 2.724 |  Acc: 51.120,67.120,75.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 0.980 |  Acc: 60.010,90.524,99.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 2.742 |  Acc: 51.220,67.380,75.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 0.982 |  Acc: 60.254,90.616,99.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 2.714 |  Acc: 51.730,67.410,75.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 0.978 |  Acc: 60.196,90.604,99.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 2.734 |  Acc: 50.800,67.460,75.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 0.980 |  Acc: 60.272,90.556,99.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 2.741 |  Acc: 51.370,67.060,75.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 0.975 |  Acc: 60.484,90.784,99.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 2.722 |  Acc: 51.290,68.070,75.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 0.973 |  Acc: 60.410,90.712,99.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 2.728 |  Acc: 51.520,67.480,75.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 0.972 |  Acc: 60.434,90.786,99.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 2.748 |  Acc: 50.660,67.140,75.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 0.971 |  Acc: 60.590,90.762,99.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 2.754 |  Acc: 51.140,67.340,75.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 0.973 |  Acc: 60.138,90.964,99.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 2.743 |  Acc: 50.840,67.140,75.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 0.966 |  Acc: 60.522,90.948,99.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 2.768 |  Acc: 51.150,67.120,75.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 0.968 |  Acc: 60.458,90.848,99.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 2.746 |  Acc: 50.800,67.530,75.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 0.968 |  Acc: 60.434,90.938,99.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 2.731 |  Acc: 51.430,67.580,75.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 0.965 |  Acc: 60.512,91.048,99.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 2.770 |  Acc: 51.340,66.630,74.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 0.959 |  Acc: 60.498,91.296,99.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 2.734 |  Acc: 51.400,66.890,75.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 0.963 |  Acc: 60.554,91.026,99.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 2.760 |  Acc: 50.980,67.400,74.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 0.957 |  Acc: 60.888,91.346,99.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 2.741 |  Acc: 51.380,67.350,75.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 0.958 |  Acc: 60.656,91.340,99.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 2.753 |  Acc: 51.610,67.510,74.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 0.914 |  Acc: 61.718,93.052,99.766,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 2.697 |  Acc: 51.970,68.360,75.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 0.902 |  Acc: 62.080,93.636,99.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 2.690 |  Acc: 52.130,68.280,75.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 0.901 |  Acc: 62.030,93.524,99.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 2.685 |  Acc: 51.980,68.320,75.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 0.897 |  Acc: 62.384,93.618,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 2.695 |  Acc: 51.940,68.120,75.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 0.896 |  Acc: 62.316,93.826,99.784,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 2.692 |  Acc: 52.250,68.440,75.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 0.891 |  Acc: 62.386,93.756,99.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 2.684 |  Acc: 52.240,68.300,75.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 0.890 |  Acc: 62.192,93.834,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 2.683 |  Acc: 51.920,68.240,75.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 0.892 |  Acc: 62.392,93.824,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 2.690 |  Acc: 52.170,68.220,75.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 0.892 |  Acc: 62.312,93.922,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 2.689 |  Acc: 52.080,68.350,75.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 0.888 |  Acc: 62.380,93.928,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 2.690 |  Acc: 52.010,68.230,75.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 0.890 |  Acc: 62.450,93.952,99.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 2.689 |  Acc: 52.020,68.130,75.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 0.889 |  Acc: 62.314,94.016,99.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 2.685 |  Acc: 52.140,68.090,75.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 0.887 |  Acc: 62.294,94.034,99.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 2.694 |  Acc: 52.240,68.130,75.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 0.888 |  Acc: 62.292,94.006,99.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 2.690 |  Acc: 52.040,68.240,75.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 0.887 |  Acc: 62.490,94.148,99.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 2.685 |  Acc: 52.140,68.330,75.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 0.886 |  Acc: 62.460,94.088,99.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 2.684 |  Acc: 52.050,68.400,75.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 0.887 |  Acc: 62.254,94.050,99.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 2.688 |  Acc: 52.150,68.270,75.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 0.884 |  Acc: 62.472,94.188,99.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 2.698 |  Acc: 52.180,68.100,75.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 0.883 |  Acc: 62.630,94.122,99.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 2.691 |  Acc: 52.090,68.030,75.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 0.885 |  Acc: 62.206,94.154,99.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 2.707 |  Acc: 52.090,68.070,75.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 0.885 |  Acc: 62.272,94.174,99.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 2.698 |  Acc: 52.030,68.090,75.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 0.883 |  Acc: 62.538,94.082,99.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 2.700 |  Acc: 52.080,67.960,75.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 0.880 |  Acc: 62.246,94.230,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 2.692 |  Acc: 51.920,68.200,75.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 0.883 |  Acc: 62.360,94.208,99.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 2.696 |  Acc: 52.050,68.140,75.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 0.881 |  Acc: 62.614,94.350,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 2.693 |  Acc: 52.060,67.840,75.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 0.878 |  Acc: 62.624,94.344,99.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 2.699 |  Acc: 51.960,68.140,75.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 0.879 |  Acc: 62.420,94.384,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 2.703 |  Acc: 52.090,68.080,75.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 0.879 |  Acc: 62.514,94.312,99.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 2.700 |  Acc: 52.070,67.920,75.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 0.879 |  Acc: 62.514,94.372,99.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 2.697 |  Acc: 52.100,68.320,75.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 0.880 |  Acc: 62.516,94.320,99.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 2.695 |  Acc: 52.060,68.210,75.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 0.882 |  Acc: 62.442,94.286,99.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 2.701 |  Acc: 52.120,68.050,75.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 0.876 |  Acc: 62.920,94.422,99.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 2.702 |  Acc: 52.120,67.970,75.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 0.879 |  Acc: 62.420,94.240,99.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 2.694 |  Acc: 52.040,67.900,75.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 0.877 |  Acc: 62.636,94.346,99.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 2.704 |  Acc: 51.940,68.000,75.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 0.879 |  Acc: 62.354,94.338,99.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 2.700 |  Acc: 51.950,67.880,75.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 0.877 |  Acc: 62.500,94.410,99.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 2.707 |  Acc: 51.770,68.030,75.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 0.880 |  Acc: 62.570,94.362,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 2.696 |  Acc: 51.900,67.830,75.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 0.873 |  Acc: 62.848,94.658,99.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 2.698 |  Acc: 51.930,67.880,75.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 0.870 |  Acc: 62.832,94.678,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 2.697 |  Acc: 52.180,67.970,75.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 0.872 |  Acc: 62.796,94.666,99.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 2.698 |  Acc: 52.200,67.970,75.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 0.872 |  Acc: 62.894,94.594,99.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 2.702 |  Acc: 51.990,67.970,75.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 0.871 |  Acc: 62.814,94.620,99.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 2.702 |  Acc: 52.140,67.910,75.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 0.872 |  Acc: 62.760,94.528,99.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 2.694 |  Acc: 52.160,67.890,75.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 0.871 |  Acc: 62.696,94.682,99.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 2.706 |  Acc: 52.080,67.910,75.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 0.870 |  Acc: 62.778,94.696,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 2.700 |  Acc: 52.020,67.970,75.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 0.872 |  Acc: 62.604,94.546,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 2.711 |  Acc: 52.100,67.890,75.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 0.870 |  Acc: 62.876,94.624,99.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 2.714 |  Acc: 52.020,67.940,75.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 0.868 |  Acc: 62.790,94.640,99.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 2.699 |  Acc: 52.080,67.960,75.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 0.870 |  Acc: 62.714,94.640,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 2.692 |  Acc: 52.090,68.010,75.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 0.871 |  Acc: 62.810,94.586,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 2.700 |  Acc: 52.250,67.890,75.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 0.868 |  Acc: 62.754,94.726,99.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 2.694 |  Acc: 52.080,68.000,75.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 0.864 |  Acc: 63.042,94.806,99.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 2.702 |  Acc: 51.940,67.920,75.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 0.868 |  Acc: 63.074,94.704,99.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 2.710 |  Acc: 52.130,67.780,75.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 0.869 |  Acc: 62.694,94.652,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 2.691 |  Acc: 52.070,68.080,75.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 0.867 |  Acc: 62.610,94.708,99.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 2.701 |  Acc: 52.060,67.810,75.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 0.869 |  Acc: 62.846,94.788,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 2.693 |  Acc: 51.970,68.050,75.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 0.871 |  Acc: 62.734,94.740,99.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 2.694 |  Acc: 51.980,68.190,75.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 0.869 |  Acc: 62.814,94.764,99.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 2.701 |  Acc: 52.070,67.930,75.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 0.869 |  Acc: 62.770,94.762,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 2.699 |  Acc: 52.040,67.960,75.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 0.870 |  Acc: 62.776,94.654,99.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 2.698 |  Acc: 52.010,67.940,75.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 0.868 |  Acc: 62.912,94.746,99.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 2.705 |  Acc: 52.030,68.000,75.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 0.866 |  Acc: 63.030,94.576,99.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 2.715 |  Acc: 52.030,67.860,75.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 0.868 |  Acc: 62.782,94.692,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 2.695 |  Acc: 52.020,68.120,75.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 0.868 |  Acc: 63.024,94.722,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 2.702 |  Acc: 52.130,68.060,75.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 0.867 |  Acc: 62.848,94.796,99.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 2.701 |  Acc: 52.100,67.890,75.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 0.868 |  Acc: 62.796,94.664,99.892,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 2.708 |  Acc: 51.990,67.910,75.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 0.869 |  Acc: 62.610,94.580,99.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 2.697 |  Acc: 52.030,67.980,75.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 0.865 |  Acc: 62.872,94.812,99.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 2.703 |  Acc: 52.080,68.030,75.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 0.867 |  Acc: 63.044,94.736,99.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 2.701 |  Acc: 52.220,67.940,75.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 0.869 |  Acc: 62.866,94.616,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 2.700 |  Acc: 52.190,68.040,75.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 0.869 |  Acc: 62.916,94.722,99.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 2.700 |  Acc: 51.950,67.940,75.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 0.864 |  Acc: 62.982,94.784,99.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 2.699 |  Acc: 52.220,68.010,75.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 0.867 |  Acc: 62.806,94.918,99.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 2.707 |  Acc: 52.160,67.870,75.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 0.868 |  Acc: 62.792,94.720,99.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 2.708 |  Acc: 52.040,68.050,75.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 0.871 |  Acc: 62.594,94.776,99.840,% | Adaptive Acc:93.242% | clf_exit: 0.442 0.496 0.062
Testing: Epoch=299 | Loss: 2.701 |  Acc: 51.970,67.920,75.310,% | Adaptive Acc:68.140% | clf_exit: 0.469 0.360 0.170

circles: 0
Testing: Epoch=299 | Loss: 6.645 |  Acc: 51.970,27.190,7.040,% | Adaptive Acc:39.470% | clf_exit: 0.469 0.000 0.530
circles: 1
Testing: Epoch=299 | Loss: 4.794 |  Acc: 51.970,52.820,40.430,% | Adaptive Acc:51.420% | clf_exit: 0.469 0.015 0.516
circles: 2
Testing: Epoch=299 | Loss: 3.657 |  Acc: 51.970,63.150,64.350,% | Adaptive Acc:63.000% | clf_exit: 0.469 0.075 0.455
circles: 3
Testing: Epoch=299 | Loss: 2.970 |  Acc: 51.970,66.760,72.970,% | Adaptive Acc:68.360% | clf_exit: 0.469 0.177 0.353
circles: 4
Testing: Epoch=299 | Loss: 2.652 |  Acc: 51.970,67.880,74.930,% | Adaptive Acc:68.930% | clf_exit: 0.469 0.283 0.248
circles: 5
Testing: Epoch=299 | Loss: 2.701 |  Acc: 51.970,67.920,75.310,% | Adaptive Acc:68.140% | clf_exit: 0.469 0.360 0.170
