==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModuleFirst(
      (relu): ReLU()
      (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=128, out_features=32, bias=True)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModuleMiddle(
      (relu): ReLU()
      (BN): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear_h): Linear(in_features=288, out_features=72, bias=True)
      (linear): Linear(in_features=72, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x72])
      (linear_bw): Linear(in_features=72, out_features=288, bias=True)
      (BN1d): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModuleLast(
      (relu): ReLU()
      (BN): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=584, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear): Linear(in_features=584, out_features=100, bias=True)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU()
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 9.662 | Acc: 0.781,1.562,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.072 | Acc: 1.190,2.083,5.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.883 | Acc: 1.925,2.630,6.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.755 | Acc: 2.395,3.163,7.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.654 | Acc: 2.614,3.627,8.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.564 | Acc: 2.823,3.906,9.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.495 | Acc: 3.002,4.190,9.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.428 | Acc: 3.230,4.599,10.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.372 | Acc: 3.353,4.794,11.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.331 | Acc: 3.466,5.007,11.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.289 | Acc: 3.615,5.267,12.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.245 | Acc: 3.779,5.486,12.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.204 | Acc: 3.906,5.754,12.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.162 | Acc: 4.086,5.942,13.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.125 | Acc: 4.201,6.144,13.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.090 | Acc: 4.264,6.307,14.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.049 | Acc: 4.420,6.603,14.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.015 | Acc: 4.529,6.745,15.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.982 | Acc: 4.644,6.943,15.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.949 | Acc: 4.737,7.089,15.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.124 | Acc: 6.250,14.062,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.264 | Acc: 6.882,10.528,23.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.255 | Acc: 6.784,10.633,23.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.267 | Acc: 6.468,10.758,23.207,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 7.302 | Acc: 6.250,12.500,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.220 | Acc: 7.031,11.682,25.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.173 | Acc: 7.317,11.585,25.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.164 | Acc: 7.428,11.744,25.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.146 | Acc: 7.359,11.671,25.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.112 | Acc: 7.681,11.881,25.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.107 | Acc: 7.722,11.964,25.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.088 | Acc: 7.857,11.974,25.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.072 | Acc: 7.953,12.078,26.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.044 | Acc: 8.041,12.284,26.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.021 | Acc: 8.174,12.539,26.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.994 | Acc: 8.353,12.793,27.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.975 | Acc: 8.490,13.028,27.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.955 | Acc: 8.588,13.159,27.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.934 | Acc: 8.669,13.181,27.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.915 | Acc: 8.817,13.320,27.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.892 | Acc: 8.934,13.498,28.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.872 | Acc: 9.038,13.675,28.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.851 | Acc: 9.178,13.863,28.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.831 | Acc: 9.264,14.017,28.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.202 | Acc: 10.938,17.969,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.434 | Acc: 10.231,15.625,33.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.415 | Acc: 9.775,16.101,32.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.416 | Acc: 9.746,16.419,32.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 6.200 | Acc: 14.062,23.438,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.356 | Acc: 11.012,17.039,34.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.384 | Acc: 11.223,16.902,33.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.320 | Acc: 11.885,18.058,35.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.301 | Acc: 11.979,18.335,35.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.296 | Acc: 12.059,18.441,35.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.290 | Acc: 12.119,18.447,35.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.269 | Acc: 12.445,18.650,35.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.253 | Acc: 12.587,18.837,35.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.242 | Acc: 12.625,18.905,35.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.230 | Acc: 12.605,18.836,35.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.217 | Acc: 12.652,18.898,35.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.194 | Acc: 12.805,19.009,35.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.179 | Acc: 13.012,19.226,35.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.166 | Acc: 13.045,19.220,35.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.151 | Acc: 13.136,19.378,36.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.135 | Acc: 13.223,19.366,36.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.118 | Acc: 13.336,19.536,36.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.104 | Acc: 13.359,19.622,36.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.088 | Acc: 13.503,19.720,36.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.729 | Acc: 14.062,27.344,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.871 | Acc: 13.690,18.601,39.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.846 | Acc: 14.024,19.284,39.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.843 | Acc: 14.255,19.403,39.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 5.575 | Acc: 14.062,21.875,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.644 | Acc: 17.039,23.512,42.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.627 | Acc: 16.730,23.361,43.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.660 | Acc: 16.278,22.797,42.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.686 | Acc: 15.972,22.473,41.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.684 | Acc: 15.981,22.401,41.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.682 | Acc: 15.774,22.463,41.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.673 | Acc: 15.836,22.640,41.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.651 | Acc: 15.936,22.676,41.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.642 | Acc: 15.992,22.738,41.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.632 | Acc: 15.990,22.785,41.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.619 | Acc: 16.116,22.861,42.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.611 | Acc: 16.225,23.010,42.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.596 | Acc: 16.364,23.156,42.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.583 | Acc: 16.470,23.287,42.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.572 | Acc: 16.531,23.354,42.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.563 | Acc: 16.606,23.430,42.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.556 | Acc: 16.658,23.541,42.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.545 | Acc: 16.757,23.667,42.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.533 | Acc: 16.894,23.749,42.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.460 | Acc: 20.312,23.438,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.565 | Acc: 17.932,20.722,42.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.541 | Acc: 18.102,21.532,42.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.545 | Acc: 17.866,21.465,42.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 5.530 | Acc: 17.969,27.344,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.239 | Acc: 18.750,26.153,47.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.222 | Acc: 19.284,25.934,47.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.211 | Acc: 19.390,26.127,48.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.215 | Acc: 19.232,26.022,47.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.201 | Acc: 19.670,26.269,47.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.185 | Acc: 19.809,26.485,48.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.180 | Acc: 19.797,26.562,47.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.193 | Acc: 19.687,26.407,47.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.191 | Acc: 19.682,26.321,47.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.188 | Acc: 19.679,26.287,47.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.175 | Acc: 19.757,26.336,47.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.168 | Acc: 19.710,26.404,47.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.161 | Acc: 19.849,26.515,47.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.155 | Acc: 19.901,26.643,47.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.144 | Acc: 19.923,26.731,47.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.140 | Acc: 19.974,26.791,47.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.132 | Acc: 20.095,26.929,47.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.120 | Acc: 20.241,27.060,47.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.115 | Acc: 20.241,27.079,47.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.065 | Acc: 21.094,28.906,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.149 | Acc: 19.568,24.293,48.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.159 | Acc: 19.627,24.676,48.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.154 | Acc: 19.723,24.757,48.092,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 5.022 | Acc: 19.531,28.125,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.932 | Acc: 21.168,28.943,50.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.905 | Acc: 21.265,28.697,50.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.893 | Acc: 21.171,29.111,50.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.892 | Acc: 21.007,28.906,50.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.886 | Acc: 21.341,29.015,50.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.879 | Acc: 21.501,29.016,50.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.867 | Acc: 21.659,29.217,50.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.852 | Acc: 21.666,29.455,50.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.844 | Acc: 21.970,29.640,50.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.824 | Acc: 22.151,29.901,50.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.819 | Acc: 22.186,29.885,50.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.808 | Acc: 22.199,29.856,51.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.803 | Acc: 22.279,29.975,51.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.795 | Acc: 22.275,30.074,51.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.787 | Acc: 22.340,30.082,51.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.783 | Acc: 22.452,30.259,51.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.777 | Acc: 22.475,30.297,51.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.774 | Acc: 22.533,30.304,51.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.773 | Acc: 22.498,30.307,51.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.643 | Acc: 23.438,30.469,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.831 | Acc: 21.280,28.385,52.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.841 | Acc: 21.094,28.144,52.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.829 | Acc: 21.311,28.240,52.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 4.892 | Acc: 21.875,28.125,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.543 | Acc: 23.847,32.961,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.509 | Acc: 24.905,32.889,55.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.507 | Acc: 24.898,32.825,55.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.532 | Acc: 24.740,32.504,55.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.535 | Acc: 24.667,32.534,55.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.532 | Acc: 24.464,32.296,54.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.532 | Acc: 24.368,32.380,54.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.531 | Acc: 24.243,32.235,55.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.529 | Acc: 24.335,32.295,54.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.526 | Acc: 24.293,32.315,54.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.527 | Acc: 24.286,32.328,55.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.518 | Acc: 24.274,32.449,55.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.517 | Acc: 24.347,32.459,55.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.513 | Acc: 24.383,32.604,55.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.520 | Acc: 24.364,32.493,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.522 | Acc: 24.367,32.418,55.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.523 | Acc: 24.347,32.462,55.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.517 | Acc: 24.422,32.533,55.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.516 | Acc: 24.399,32.544,55.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.516 | Acc: 28.125,33.594,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.682 | Acc: 22.433,30.022,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.702 | Acc: 22.180,30.126,52.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.711 | Acc: 22.144,30.315,52.241,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 4.691 | Acc: 21.875,31.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.316 | Acc: 26.265,34.598,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.318 | Acc: 26.524,34.280,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.316 | Acc: 26.268,34.823,58.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.312 | Acc: 26.032,34.684,58.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.306 | Acc: 25.835,34.545,58.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.321 | Acc: 25.446,34.375,58.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.319 | Acc: 25.471,34.502,58.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.315 | Acc: 25.412,34.487,58.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.316 | Acc: 25.384,34.466,58.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.306 | Acc: 25.424,34.632,58.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.303 | Acc: 25.421,34.743,58.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.301 | Acc: 25.477,34.929,58.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.294 | Acc: 25.566,34.980,58.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.294 | Acc: 25.612,34.989,58.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.293 | Acc: 25.683,35.052,58.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.292 | Acc: 25.691,35.015,58.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.289 | Acc: 25.797,35.076,58.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.289 | Acc: 25.790,35.055,58.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.286 | Acc: 25.738,35.089,58.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.242 | Acc: 25.781,35.156,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.543 | Acc: 24.256,31.585,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.556 | Acc: 24.009,30.983,54.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.561 | Acc: 23.796,30.866,55.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 4.445 | Acc: 24.219,32.031,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.089 | Acc: 27.530,37.537,61.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.065 | Acc: 27.725,37.957,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.070 | Acc: 27.421,37.474,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.062 | Acc: 27.739,37.558,61.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.065 | Acc: 27.537,37.531,61.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.078 | Acc: 27.344,37.209,60.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.073 | Acc: 27.471,37.456,60.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.085 | Acc: 27.412,37.311,60.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.099 | Acc: 27.301,37.124,60.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.101 | Acc: 27.340,37.146,60.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.099 | Acc: 27.418,37.111,60.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.101 | Acc: 27.519,37.237,60.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.102 | Acc: 27.553,37.293,60.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.098 | Acc: 27.588,37.297,60.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.092 | Acc: 27.629,37.300,60.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.087 | Acc: 27.619,37.356,60.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.091 | Acc: 27.610,37.287,60.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.096 | Acc: 27.560,37.277,60.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.097 | Acc: 27.536,37.272,60.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.232 | Acc: 26.562,41.406,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.446 | Acc: 24.888,32.738,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.466 | Acc: 24.143,32.736,56.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.460 | Acc: 24.142,32.620,56.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 4.092 | Acc: 25.000,34.375,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.973 | Acc: 29.353,38.579,63.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.914 | Acc: 29.116,38.948,63.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.910 | Acc: 29.047,38.563,64.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.909 | Acc: 29.061,38.696,63.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.921 | Acc: 29.030,38.490,63.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.917 | Acc: 29.184,38.830,63.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.912 | Acc: 29.239,39.146,63.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.920 | Acc: 29.062,39.014,63.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.911 | Acc: 28.980,39.127,63.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.906 | Acc: 28.949,39.237,63.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.898 | Acc: 29.097,39.398,63.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.900 | Acc: 29.010,39.325,63.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.901 | Acc: 28.969,39.389,63.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.904 | Acc: 28.948,39.354,63.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.909 | Acc: 28.896,39.332,63.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.916 | Acc: 28.860,39.294,63.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.918 | Acc: 28.851,39.298,63.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.920 | Acc: 28.835,39.251,62.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.921 | Acc: 28.855,39.218,62.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.123 | Acc: 32.031,35.156,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.147 | Acc: 28.385,35.677,60.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.168 | Acc: 27.839,35.595,59.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.164 | Acc: 27.626,35.669,59.631,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 3.796 | Acc: 25.781,40.625,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.799 | Acc: 28.348,39.732,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.739 | Acc: 30.297,41.235,65.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.761 | Acc: 29.739,40.868,65.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.760 | Acc: 29.794,41.107,65.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.753 | Acc: 29.757,41.066,65.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.738 | Acc: 29.694,41.109,65.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.742 | Acc: 29.843,41.068,65.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.740 | Acc: 29.896,41.285,65.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.755 | Acc: 29.675,41.061,65.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.758 | Acc: 29.676,40.897,65.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.765 | Acc: 29.663,40.954,65.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.769 | Acc: 29.626,40.829,65.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.768 | Acc: 29.690,40.888,65.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.771 | Acc: 29.688,40.870,65.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.776 | Acc: 29.664,40.799,64.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.775 | Acc: 29.700,40.817,64.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.777 | Acc: 29.623,40.815,64.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.775 | Acc: 29.694,40.848,64.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.780 | Acc: 29.716,40.818,64.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.155 | Acc: 26.562,40.625,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 25.298,36.086,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.287 | Acc: 25.324,35.766,59.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.303 | Acc: 25.166,35.809,59.221,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 3.698 | Acc: 29.688,39.844,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.618 | Acc: 30.990,42.336,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.618 | Acc: 30.393,41.692,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.633 | Acc: 29.816,41.957,67.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.616 | Acc: 30.150,42.004,68.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.611 | Acc: 30.391,42.118,68.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.629 | Acc: 30.365,41.890,67.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.628 | Acc: 30.624,42.176,67.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.619 | Acc: 30.828,42.469,67.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.621 | Acc: 30.762,42.464,67.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.625 | Acc: 30.764,42.409,67.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.628 | Acc: 30.741,42.322,67.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.633 | Acc: 30.741,42.243,67.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.635 | Acc: 30.774,42.247,67.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.630 | Acc: 30.966,42.404,67.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.633 | Acc: 30.868,42.419,67.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.632 | Acc: 30.943,42.516,67.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.634 | Acc: 30.943,42.483,67.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.640 | Acc: 30.886,42.426,66.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.642 | Acc: 30.893,42.452,66.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.795 | Acc: 28.906,48.438,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.973 | Acc: 27.567,39.583,62.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.978 | Acc: 27.763,39.539,62.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.992 | Acc: 27.536,39.267,62.295,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 4.000 | Acc: 21.875,35.938,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.416 | Acc: 31.548,45.573,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.493 | Acc: 31.479,44.455,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.480 | Acc: 31.673,44.544,69.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.495 | Acc: 31.703,43.924,69.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.484 | Acc: 32.000,44.090,69.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.494 | Acc: 31.896,44.041,69.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.500 | Acc: 31.799,43.972,68.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.503 | Acc: 31.842,44.133,68.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.502 | Acc: 31.880,44.117,68.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.501 | Acc: 31.817,44.162,68.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.500 | Acc: 31.826,44.202,68.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.498 | Acc: 31.879,44.217,68.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.501 | Acc: 31.906,44.277,68.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.511 | Acc: 31.762,44.175,68.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.514 | Acc: 31.735,44.134,68.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.516 | Acc: 31.749,44.132,68.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.519 | Acc: 31.772,44.121,68.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.523 | Acc: 31.735,44.083,68.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.522 | Acc: 31.800,44.090,68.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.853 | Acc: 28.906,42.969,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.943 | Acc: 29.055,40.216,63.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.977 | Acc: 28.735,39.196,62.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.981 | Acc: 28.509,38.973,62.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 3.609 | Acc: 30.469,43.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.385 | Acc: 31.250,43.899,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.413 | Acc: 31.193,43.331,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.387 | Acc: 32.006,43.993,71.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.390 | Acc: 32.099,44.223,71.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.382 | Acc: 32.256,44.740,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.371 | Acc: 32.244,44.906,71.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.373 | Acc: 32.281,44.997,71.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.375 | Acc: 32.419,45.172,70.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.379 | Acc: 32.437,45.239,70.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.374 | Acc: 32.521,45.367,70.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.374 | Acc: 32.565,45.426,70.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.375 | Acc: 32.670,45.543,70.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.381 | Acc: 32.636,45.564,70.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.380 | Acc: 32.657,45.638,70.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.385 | Acc: 32.628,45.614,70.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.390 | Acc: 32.708,45.622,70.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.392 | Acc: 32.632,45.597,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.395 | Acc: 32.613,45.572,70.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.397 | Acc: 32.638,45.534,70.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.857 | Acc: 29.688,46.094,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.940 | Acc: 28.832,43.155,62.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.949 | Acc: 28.373,42.626,62.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.954 | Acc: 28.151,42.405,62.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 3.654 | Acc: 25.000,39.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.209 | Acc: 33.966,47.396,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.253 | Acc: 33.289,47.180,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.242 | Acc: 33.645,46.875,73.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.239 | Acc: 33.574,47.116,73.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.246 | Acc: 33.524,46.921,73.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.257 | Acc: 33.529,46.952,72.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.250 | Acc: 33.721,47.002,72.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.261 | Acc: 33.603,46.763,72.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.264 | Acc: 33.602,46.810,72.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.271 | Acc: 33.469,46.720,72.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.278 | Acc: 33.382,46.705,72.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.279 | Acc: 33.477,46.729,72.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.281 | Acc: 33.423,46.824,72.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.287 | Acc: 33.357,46.822,71.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.294 | Acc: 33.394,46.750,71.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.297 | Acc: 33.477,46.758,71.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.302 | Acc: 33.376,46.579,71.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.303 | Acc: 33.377,46.676,71.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.308 | Acc: 33.352,46.623,71.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.800 | Acc: 30.469,44.531,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.832 | Acc: 30.878,43.676,64.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.841 | Acc: 30.831,43.007,63.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.857 | Acc: 30.225,43.186,63.217,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 3.318 | Acc: 32.031,46.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.140 | Acc: 33.929,49.330,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.127 | Acc: 33.975,49.085,75.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.129 | Acc: 33.952,48.963,75.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.126 | Acc: 33.941,49.016,75.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.139 | Acc: 33.803,48.840,74.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.144 | Acc: 34.072,48.896,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.149 | Acc: 34.115,48.676,74.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.162 | Acc: 34.045,48.559,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.170 | Acc: 34.025,48.489,74.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.171 | Acc: 34.045,48.465,73.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.177 | Acc: 34.053,48.466,73.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.181 | Acc: 33.866,48.382,73.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.186 | Acc: 33.893,48.390,73.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.193 | Acc: 33.830,48.237,73.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.198 | Acc: 33.851,48.295,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.201 | Acc: 33.844,48.231,73.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.198 | Acc: 33.887,48.300,73.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.198 | Acc: 33.910,48.267,73.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.204 | Acc: 33.910,48.241,73.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.637 | Acc: 32.031,49.219,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.735 | Acc: 30.580,46.429,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.788 | Acc: 30.678,46.113,64.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.803 | Acc: 30.187,46.119,64.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 3.137 | Acc: 30.469,47.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.100 | Acc: 34.263,48.400,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.069 | Acc: 34.432,48.399,75.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.057 | Acc: 34.593,49.091,76.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.061 | Acc: 34.713,49.219,76.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.065 | Acc: 35.079,49.358,75.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.067 | Acc: 34.756,49.458,75.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.072 | Acc: 34.691,49.413,75.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.075 | Acc: 34.797,49.423,75.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.076 | Acc: 34.850,49.400,75.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.074 | Acc: 34.931,49.456,75.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.076 | Acc: 34.983,49.473,75.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.081 | Acc: 35.014,49.355,75.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.092 | Acc: 34.914,49.300,74.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.095 | Acc: 34.970,49.313,74.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.100 | Acc: 34.899,49.252,74.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.104 | Acc: 34.833,49.216,74.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.103 | Acc: 34.925,49.210,74.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.105 | Acc: 34.855,49.204,74.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.111 | Acc: 34.843,49.219,74.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.652 | Acc: 38.281,47.656,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.710 | Acc: 33.333,45.908,64.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.741 | Acc: 32.755,45.846,63.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.756 | Acc: 32.134,45.466,63.845,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 2.871 | Acc: 43.750,57.031,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.014 | Acc: 35.491,50.223,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.019 | Acc: 35.042,49.600,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.008 | Acc: 35.297,50.295,77.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.989 | Acc: 35.388,50.415,77.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.003 | Acc: 35.481,50.286,76.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.996 | Acc: 35.447,50.678,76.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.009 | Acc: 35.178,50.543,76.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.009 | Acc: 35.355,50.451,76.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.010 | Acc: 35.251,50.462,76.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.017 | Acc: 35.180,50.361,76.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.011 | Acc: 35.361,50.608,76.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.022 | Acc: 35.283,50.525,75.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.023 | Acc: 35.399,50.437,75.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.032 | Acc: 35.315,50.267,75.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.034 | Acc: 35.328,50.280,75.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.036 | Acc: 35.312,50.353,75.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.039 | Acc: 35.319,50.364,75.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.043 | Acc: 35.316,50.290,75.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.043 | Acc: 35.296,50.273,75.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.688 | Acc: 37.500,47.656,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.754 | Acc: 32.775,43.936,65.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.763 | Acc: 32.470,43.388,64.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.781 | Acc: 32.134,43.404,64.344,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 3.090 | Acc: 36.719,45.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 35.900,51.600,77.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.930 | Acc: 35.690,51.429,77.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.927 | Acc: 35.899,51.562,77.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.944 | Acc: 35.667,50.993,77.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.945 | Acc: 35.512,50.712,77.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.940 | Acc: 35.292,50.814,77.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.935 | Acc: 35.422,51.141,77.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.928 | Acc: 35.510,51.330,77.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.938 | Acc: 35.502,51.355,77.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.948 | Acc: 35.475,51.353,77.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.950 | Acc: 35.535,51.379,77.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.954 | Acc: 35.584,51.378,77.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.965 | Acc: 35.635,51.260,77.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.967 | Acc: 35.679,51.257,76.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.966 | Acc: 35.777,51.324,76.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.969 | Acc: 35.838,51.399,76.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.975 | Acc: 35.841,51.388,76.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.979 | Acc: 35.877,51.366,76.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.983 | Acc: 35.888,51.323,76.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.502 | Acc: 35.938,51.562,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.596 | Acc: 34.115,46.615,66.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.624 | Acc: 34.089,46.037,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.646 | Acc: 33.222,46.068,64.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 3.015 | Acc: 25.781,46.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.864 | Acc: 37.351,52.641,79.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.848 | Acc: 36.623,52.325,79.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.849 | Acc: 36.130,52.408,79.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.858 | Acc: 36.024,52.296,78.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.860 | Acc: 36.409,52.529,78.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.862 | Acc: 36.473,52.557,78.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.864 | Acc: 36.264,52.416,78.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.861 | Acc: 36.403,52.518,78.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.863 | Acc: 36.481,52.439,78.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.879 | Acc: 36.365,52.181,78.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.883 | Acc: 36.309,52.156,77.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.885 | Acc: 36.262,52.204,77.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.887 | Acc: 36.231,52.284,77.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.895 | Acc: 36.188,52.188,77.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.898 | Acc: 36.283,52.131,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.903 | Acc: 36.217,52.125,77.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.901 | Acc: 36.261,52.225,77.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.901 | Acc: 36.316,52.207,77.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.905 | Acc: 36.354,52.196,77.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.283 | Acc: 41.406,51.562,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.648 | Acc: 33.073,46.912,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.657 | Acc: 32.565,46.894,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.674 | Acc: 31.839,46.222,65.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 3.362 | Acc: 33.594,43.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.730 | Acc: 37.091,53.199,80.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.742 | Acc: 36.909,53.125,80.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.765 | Acc: 36.770,52.959,79.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.795 | Acc: 36.478,52.787,79.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.802 | Acc: 36.448,52.870,79.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.798 | Acc: 36.493,52.957,79.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.793 | Acc: 36.564,53.086,79.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.781 | Acc: 36.685,53.207,79.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.782 | Acc: 36.792,53.449,79.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.790 | Acc: 36.789,53.479,79.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.801 | Acc: 36.804,53.217,79.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.810 | Acc: 36.816,53.128,78.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.817 | Acc: 36.779,53.068,78.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.822 | Acc: 36.708,53.058,78.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.825 | Acc: 36.714,53.109,78.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.825 | Acc: 36.770,53.110,78.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.829 | Acc: 36.847,53.175,78.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.833 | Acc: 36.907,53.192,78.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.836 | Acc: 36.911,53.146,78.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.275 | Acc: 35.938,50.781,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.542 | Acc: 34.561,47.693,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.559 | Acc: 34.966,47.351,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.578 | Acc: 34.170,47.720,65.894,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 2.354 | Acc: 46.875,62.500,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.750 | Acc: 36.719,51.935,79.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 37.538,53.201,80.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 37.731,53.932,80.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.718 | Acc: 37.297,54.215,80.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.715 | Acc: 37.570,54.394,80.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.720 | Acc: 37.364,54.358,80.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.723 | Acc: 37.733,54.250,80.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.731 | Acc: 37.689,54.236,80.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.737 | Acc: 37.500,54.243,80.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.738 | Acc: 37.473,54.283,80.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.737 | Acc: 37.535,54.398,80.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.741 | Acc: 37.445,54.512,80.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.745 | Acc: 37.365,54.457,79.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.754 | Acc: 37.386,54.362,79.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.764 | Acc: 37.342,54.267,79.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.765 | Acc: 37.308,54.176,79.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.766 | Acc: 37.296,54.156,79.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.774 | Acc: 37.175,54.077,79.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.777 | Acc: 37.197,54.076,79.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.326 | Acc: 35.156,53.125,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.583 | Acc: 33.854,47.433,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.579 | Acc: 34.223,48.418,65.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.593 | Acc: 33.594,48.386,65.087,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 2.579 | Acc: 42.969,60.156,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 36.793,56.696,82.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.642 | Acc: 37.614,55.602,82.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.639 | Acc: 37.935,55.712,82.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.641 | Acc: 37.944,55.546,82.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.650 | Acc: 37.601,55.175,82.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.668 | Acc: 37.584,54.836,81.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.675 | Acc: 37.544,54.699,81.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.670 | Acc: 37.714,54.751,81.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.672 | Acc: 37.664,54.657,81.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.682 | Acc: 37.753,54.711,81.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.683 | Acc: 37.843,54.790,80.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.688 | Acc: 37.707,54.759,80.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.698 | Acc: 37.542,54.747,80.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.706 | Acc: 37.547,54.718,80.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.710 | Acc: 37.562,54.729,80.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.717 | Acc: 37.585,54.678,80.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.723 | Acc: 37.587,54.669,80.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.725 | Acc: 37.626,54.672,80.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.730 | Acc: 37.711,54.685,79.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.645 | Acc: 37.500,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.588 | Acc: 35.193,47.619,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.611 | Acc: 35.042,47.123,65.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.612 | Acc: 34.285,47.208,65.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 2.545 | Acc: 36.719,57.031,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.663 | Acc: 38.690,54.762,81.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.619 | Acc: 39.101,55.526,82.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.599 | Acc: 39.498,55.661,82.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.614 | Acc: 39.207,55.305,82.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.612 | Acc: 38.931,55.407,82.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.615 | Acc: 38.746,55.469,82.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.618 | Acc: 38.536,55.546,82.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.623 | Acc: 38.461,55.561,82.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.636 | Acc: 38.342,55.313,81.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.639 | Acc: 38.347,55.321,81.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.644 | Acc: 38.278,55.197,81.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.645 | Acc: 38.346,55.362,81.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.647 | Acc: 38.386,55.325,81.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.653 | Acc: 38.345,55.277,81.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.654 | Acc: 38.248,55.235,81.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.658 | Acc: 38.203,55.165,81.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.661 | Acc: 38.263,55.226,81.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.664 | Acc: 38.299,55.274,81.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.666 | Acc: 38.320,55.299,81.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.626 | Acc: 36.719,51.562,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.543 | Acc: 35.342,49.665,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.571 | Acc: 35.271,49.143,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.598 | Acc: 34.695,49.501,66.124,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 2.562 | Acc: 40.625,53.906,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.556 | Acc: 39.100,56.287,83.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.524 | Acc: 38.891,56.993,83.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 38.653,57.159,84.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.534 | Acc: 38.725,56.780,84.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.531 | Acc: 38.869,56.884,83.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.548 | Acc: 38.791,56.696,83.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.561 | Acc: 38.830,56.477,83.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.561 | Acc: 38.912,56.546,82.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.564 | Acc: 38.985,56.418,82.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.575 | Acc: 38.868,56.347,82.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.588 | Acc: 38.865,56.193,82.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.597 | Acc: 38.797,56.156,82.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.604 | Acc: 38.787,56.160,81.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.608 | Acc: 38.829,56.117,81.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.611 | Acc: 38.772,56.146,81.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.616 | Acc: 38.688,55.980,81.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.620 | Acc: 38.664,55.945,81.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.629 | Acc: 38.621,55.867,81.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.635 | Acc: 38.574,55.782,81.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.368 | Acc: 35.938,53.125,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.589 | Acc: 34.077,50.446,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.587 | Acc: 33.441,49.848,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.585 | Acc: 33.056,49.513,66.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 2.444 | Acc: 42.188,54.688,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.561 | Acc: 38.207,55.618,83.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.518 | Acc: 39.177,56.212,84.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.510 | Acc: 39.191,56.416,84.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 39.313,56.404,84.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 39.055,56.304,84.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.525 | Acc: 39.011,56.282,84.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.529 | Acc: 38.797,56.289,83.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.530 | Acc: 38.805,56.269,83.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.529 | Acc: 38.933,56.401,83.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.524 | Acc: 39.179,56.596,83.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.527 | Acc: 39.169,56.487,83.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.537 | Acc: 39.173,56.464,83.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.544 | Acc: 39.206,56.340,83.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.547 | Acc: 39.252,56.456,83.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.556 | Acc: 39.218,56.364,82.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.569 | Acc: 39.097,56.245,82.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.575 | Acc: 39.147,56.186,82.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.579 | Acc: 39.145,56.142,82.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.585 | Acc: 39.087,56.100,82.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.220 | Acc: 35.938,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.449 | Acc: 36.458,52.009,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.461 | Acc: 36.643,51.429,66.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.477 | Acc: 35.797,51.716,66.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 2.682 | Acc: 37.500,51.562,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.480 | Acc: 40.253,57.999,84.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 39.253,58.003,84.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.491 | Acc: 39.344,57.761,84.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.493 | Acc: 39.487,57.880,84.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.495 | Acc: 39.341,57.851,84.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.495 | Acc: 39.250,57.806,84.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 39.373,57.984,84.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.492 | Acc: 39.368,57.929,84.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 39.145,57.705,83.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.507 | Acc: 39.214,57.649,83.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.515 | Acc: 39.218,57.445,83.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.516 | Acc: 39.328,57.508,83.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.520 | Acc: 39.410,57.432,83.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.522 | Acc: 39.368,57.487,83.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.526 | Acc: 39.470,57.439,83.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.533 | Acc: 39.381,57.335,82.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.534 | Acc: 39.413,57.370,82.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.535 | Acc: 39.485,57.371,82.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.535 | Acc: 39.491,57.368,82.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.322 | Acc: 39.062,55.469,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.471 | Acc: 34.710,52.158,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.480 | Acc: 35.328,51.734,66.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.485 | Acc: 35.079,51.678,66.790,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 2.573 | Acc: 35.156,55.469,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.439 | Acc: 39.249,58.110,84.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.471 | Acc: 39.062,57.565,84.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.465 | Acc: 39.293,57.684,84.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.445 | Acc: 39.593,58.247,84.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.441 | Acc: 39.705,58.199,84.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.444 | Acc: 39.902,58.200,84.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.451 | Acc: 39.899,58.350,84.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.455 | Acc: 40.135,58.273,84.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.464 | Acc: 39.917,57.929,84.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.467 | Acc: 39.828,57.921,84.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.473 | Acc: 39.854,57.873,84.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.471 | Acc: 39.973,58.026,84.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.474 | Acc: 39.865,57.962,84.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.477 | Acc: 39.866,57.915,84.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.482 | Acc: 39.875,57.789,83.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 39.863,57.691,83.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.491 | Acc: 39.857,57.677,83.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.497 | Acc: 39.876,57.626,83.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.502 | Acc: 39.932,57.589,83.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.455 | Acc: 39.844,52.344,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.528 | Acc: 35.603,52.381,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.536 | Acc: 35.232,51.410,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.547 | Acc: 34.810,50.973,65.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 2.426 | Acc: 44.531,58.594,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.445 | Acc: 40.551,59.003,84.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.418 | Acc: 40.072,59.451,85.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.440 | Acc: 39.895,59.106,84.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.439 | Acc: 39.815,59.066,85.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.425 | Acc: 39.975,59.089,85.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.428 | Acc: 40.037,59.181,84.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.440 | Acc: 39.888,59.037,84.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.439 | Acc: 39.887,59.016,84.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.441 | Acc: 39.943,58.935,84.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.444 | Acc: 39.887,58.843,84.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.447 | Acc: 39.922,58.838,84.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.449 | Acc: 39.941,58.850,84.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.457 | Acc: 39.871,58.878,84.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.458 | Acc: 39.902,58.755,84.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.465 | Acc: 39.906,58.672,83.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.469 | Acc: 39.951,58.613,83.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.474 | Acc: 39.919,58.472,83.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.479 | Acc: 39.868,58.321,83.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 39.868,58.325,83.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.171 | Acc: 41.406,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.432 | Acc: 37.463,53.013,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.469 | Acc: 37.729,52.591,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.478 | Acc: 36.783,52.561,66.342,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 2.129 | Acc: 45.312,56.250,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.311 | Acc: 41.778,59.524,85.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.353 | Acc: 40.949,59.375,85.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.361 | Acc: 40.945,59.580,85.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.363 | Acc: 41.069,59.414,85.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.370 | Acc: 40.834,59.414,85.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.370 | Acc: 40.941,59.472,85.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.376 | Acc: 40.985,59.491,85.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.390 | Acc: 40.732,59.244,85.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.398 | Acc: 40.556,59.202,85.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.406 | Acc: 40.559,59.161,85.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.414 | Acc: 40.547,59.082,84.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.417 | Acc: 40.583,59.074,84.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.422 | Acc: 40.490,59.088,84.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.426 | Acc: 40.469,59.044,84.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.426 | Acc: 40.454,59.053,84.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.430 | Acc: 40.515,59.022,84.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.433 | Acc: 40.520,58.947,84.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.435 | Acc: 40.480,58.927,84.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.441 | Acc: 40.397,58.838,84.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.289 | Acc: 36.719,53.906,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.557 | Acc: 34.933,51.786,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.571 | Acc: 35.175,51.543,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.582 | Acc: 34.772,51.627,66.624,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 2.151 | Acc: 47.656,66.406,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.299 | Acc: 41.406,60.454,86.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.325 | Acc: 40.568,59.851,86.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.306 | Acc: 41.483,60.361,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.309 | Acc: 41.590,60.118,86.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.329 | Acc: 41.445,59.831,86.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.343 | Acc: 41.277,59.627,86.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.336 | Acc: 41.395,59.746,86.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.334 | Acc: 41.377,60.011,86.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.350 | Acc: 41.225,59.802,86.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.366 | Acc: 41.068,59.546,85.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.370 | Acc: 41.113,59.446,85.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.373 | Acc: 41.144,59.437,85.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.384 | Acc: 41.035,59.258,85.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.392 | Acc: 40.986,59.297,85.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.397 | Acc: 40.926,59.282,85.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.402 | Acc: 40.864,59.188,85.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.402 | Acc: 40.898,59.226,84.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.402 | Acc: 40.893,59.271,84.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.405 | Acc: 40.853,59.188,84.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.242 | Acc: 36.719,55.469,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.494 | Acc: 35.603,53.237,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.474 | Acc: 36.052,53.296,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.494 | Acc: 35.143,52.843,66.214,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 2.193 | Acc: 45.312,55.469,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.338 | Acc: 42.150,59.970,86.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.341 | Acc: 42.092,59.718,86.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.323 | Acc: 42.098,60.220,86.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.322 | Acc: 42.323,60.079,86.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.314 | Acc: 42.102,60.342,86.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.321 | Acc: 42.078,60.343,86.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.330 | Acc: 41.933,60.234,85.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.332 | Acc: 41.853,60.258,85.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.340 | Acc: 41.691,60.204,85.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.346 | Acc: 41.554,60.110,85.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.350 | Acc: 41.459,59.990,85.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.350 | Acc: 41.403,59.988,85.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.358 | Acc: 41.349,59.899,85.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.359 | Acc: 41.401,59.842,85.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.360 | Acc: 41.373,59.777,85.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.366 | Acc: 41.321,59.716,85.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.373 | Acc: 41.321,59.600,85.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.376 | Acc: 41.315,59.669,85.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.380 | Acc: 41.261,59.685,85.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.196 | Acc: 38.281,56.250,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.622 | Acc: 34.598,51.637,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.637 | Acc: 34.680,51.848,65.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.633 | Acc: 34.080,51.793,65.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 2.440 | Acc: 39.062,59.375,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.322 | Acc: 40.551,59.933,85.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.306 | Acc: 41.006,60.442,86.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.306 | Acc: 41.726,60.873,86.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.313 | Acc: 41.715,61.092,86.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.325 | Acc: 41.352,60.644,86.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.321 | Acc: 41.432,60.653,86.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.328 | Acc: 41.201,60.721,86.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.335 | Acc: 41.159,60.583,86.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.334 | Acc: 41.212,60.532,86.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.334 | Acc: 41.161,60.401,86.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.333 | Acc: 41.297,60.340,86.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.344 | Acc: 41.066,60.088,85.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.348 | Acc: 41.056,60.004,85.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.353 | Acc: 41.045,59.903,85.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.356 | Acc: 41.154,59.907,85.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.355 | Acc: 41.151,60.042,85.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.360 | Acc: 41.129,60.012,85.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.365 | Acc: 41.147,59.948,85.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.369 | Acc: 41.121,59.922,85.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.058 | Acc: 42.969,53.906,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.410 | Acc: 37.016,53.795,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.456 | Acc: 37.043,52.954,66.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.464 | Acc: 36.591,52.984,66.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 2.107 | Acc: 49.219,64.844,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.248 | Acc: 42.857,62.277,86.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.301 | Acc: 41.768,61.147,86.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.294 | Acc: 41.470,61.040,86.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.296 | Acc: 41.271,61.198,86.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.293 | Acc: 41.313,60.837,86.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.296 | Acc: 41.510,60.724,86.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.292 | Acc: 41.728,60.871,86.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.294 | Acc: 41.799,60.899,86.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.295 | Acc: 41.756,60.877,86.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.301 | Acc: 41.842,60.786,86.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.310 | Acc: 41.703,60.573,85.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.317 | Acc: 41.581,60.506,85.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.321 | Acc: 41.553,60.432,85.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.324 | Acc: 41.540,60.395,85.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.329 | Acc: 41.494,60.356,85.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.334 | Acc: 41.452,60.324,85.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.339 | Acc: 41.422,60.209,85.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.342 | Acc: 41.443,60.210,85.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.348 | Acc: 41.388,60.136,85.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.370 | Acc: 39.062,55.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.440 | Acc: 36.384,53.423,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.458 | Acc: 36.890,53.144,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.466 | Acc: 35.925,52.856,66.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 2.199 | Acc: 44.531,63.281,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.218 | Acc: 43.713,63.393,87.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.207 | Acc: 43.731,63.510,87.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.212 | Acc: 43.110,62.795,88.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.219 | Acc: 42.757,62.346,87.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.227 | Acc: 42.729,62.345,87.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.231 | Acc: 42.575,62.351,87.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.234 | Acc: 42.420,62.212,87.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.236 | Acc: 42.328,61.782,87.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.236 | Acc: 42.295,61.723,87.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.248 | Acc: 42.067,61.536,87.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.249 | Acc: 42.127,61.546,87.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.252 | Acc: 42.100,61.421,87.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.258 | Acc: 42.047,61.455,87.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.265 | Acc: 41.960,61.360,87.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.277 | Acc: 41.920,61.169,86.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.287 | Acc: 41.847,61.025,86.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.292 | Acc: 41.832,60.965,86.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.296 | Acc: 41.880,60.938,86.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.299 | Acc: 41.847,60.872,86.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.302 | Acc: 42.188,53.125,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.400 | Acc: 38.876,53.274,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.435 | Acc: 38.396,52.363,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.445 | Acc: 37.897,51.985,67.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 2.182 | Acc: 49.219,60.156,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.228 | Acc: 43.192,60.454,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.236 | Acc: 42.530,60.995,87.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.223 | Acc: 42.290,61.232,87.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.237 | Acc: 42.216,61.323,87.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.241 | Acc: 42.033,61.177,87.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.244 | Acc: 41.936,61.235,87.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.239 | Acc: 42.165,61.547,87.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.247 | Acc: 42.202,61.408,87.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.257 | Acc: 42.136,61.356,86.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.255 | Acc: 42.343,61.622,86.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.264 | Acc: 42.163,61.404,86.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.271 | Acc: 42.103,61.304,86.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.275 | Acc: 42.164,61.258,86.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.281 | Acc: 42.060,61.243,86.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.286 | Acc: 42.042,61.137,86.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.291 | Acc: 41.964,60.998,86.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.295 | Acc: 41.986,60.949,86.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.300 | Acc: 41.915,60.875,86.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.302 | Acc: 41.868,60.903,85.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.155 | Acc: 42.969,55.469,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.437 | Acc: 37.500,52.939,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.476 | Acc: 37.062,52.248,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.475 | Acc: 36.642,51.844,66.022,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 2.204 | Acc: 39.844,59.375,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.174 | Acc: 41.034,61.607,89.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.161 | Acc: 42.054,62.576,89.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.186 | Acc: 41.842,62.116,88.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.186 | Acc: 42.216,62.191,88.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.199 | Acc: 41.925,62.121,88.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.211 | Acc: 42.078,62.074,87.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.213 | Acc: 42.210,62.118,87.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.220 | Acc: 42.260,62.083,87.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.215 | Acc: 42.459,62.159,87.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.217 | Acc: 42.366,62.212,87.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.216 | Acc: 42.431,62.118,87.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.226 | Acc: 42.217,62.004,87.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.235 | Acc: 42.196,61.904,87.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.240 | Acc: 42.221,61.886,87.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.243 | Acc: 42.278,61.810,87.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.253 | Acc: 42.239,61.634,86.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.257 | Acc: 42.185,61.606,86.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.263 | Acc: 42.181,61.537,86.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.268 | Acc: 42.153,61.469,86.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.332 | Acc: 38.281,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.484 | Acc: 38.058,53.088,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.546 | Acc: 36.738,52.001,65.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.577 | Acc: 36.155,51.921,64.921,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 2.011 | Acc: 46.875,64.844,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.164 | Acc: 44.159,63.021,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.189 | Acc: 42.797,62.652,88.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.191 | Acc: 42.520,62.423,88.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.172 | Acc: 42.998,63.059,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.170 | Acc: 43.015,62.902,88.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.183 | Acc: 42.594,62.784,88.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.190 | Acc: 42.459,62.650,88.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.191 | Acc: 42.658,62.549,88.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.196 | Acc: 42.667,62.487,88.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.206 | Acc: 42.662,62.337,87.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.213 | Acc: 42.590,62.245,87.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.220 | Acc: 42.577,62.111,87.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.224 | Acc: 42.577,62.033,87.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.230 | Acc: 42.582,61.858,87.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.234 | Acc: 42.611,61.724,87.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.236 | Acc: 42.555,61.692,87.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.240 | Acc: 42.600,61.655,87.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.242 | Acc: 42.592,61.656,86.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.247 | Acc: 42.645,61.694,86.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.454 | Acc: 39.062,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.467 | Acc: 38.095,52.939,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.511 | Acc: 38.129,52.477,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.534 | Acc: 37.577,51.998,66.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 2.458 | Acc: 38.281,51.562,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.241 | Acc: 43.490,60.826,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.198 | Acc: 43.655,61.509,87.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.171 | Acc: 43.673,62.052,88.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.164 | Acc: 43.258,62.404,88.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.165 | Acc: 43.100,62.585,88.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.170 | Acc: 43.020,62.500,88.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.174 | Acc: 43.080,62.323,88.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.185 | Acc: 42.969,61.918,88.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.184 | Acc: 43.021,61.917,88.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.191 | Acc: 42.872,61.796,88.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.193 | Acc: 42.866,61.722,88.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.197 | Acc: 42.797,61.829,88.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.206 | Acc: 42.681,61.710,87.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.212 | Acc: 42.694,61.671,87.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.213 | Acc: 42.761,61.825,87.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.215 | Acc: 42.825,61.909,87.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.220 | Acc: 42.792,61.826,87.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.224 | Acc: 42.811,61.779,87.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.228 | Acc: 42.835,61.764,87.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.464 | Acc: 35.156,54.688,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.516 | Acc: 37.091,52.269,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.499 | Acc: 37.748,52.268,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.508 | Acc: 37.218,51.908,66.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 2.186 | Acc: 46.094,59.375,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.162 | Acc: 43.936,63.132,88.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.156 | Acc: 43.636,63.529,88.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.157 | Acc: 43.302,63.281,88.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.141 | Acc: 43.702,63.484,89.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.151 | Acc: 43.564,62.856,88.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.166 | Acc: 43.343,62.636,88.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.173 | Acc: 42.985,62.378,88.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.187 | Acc: 42.804,62.228,88.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.188 | Acc: 42.934,62.189,88.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.192 | Acc: 42.942,62.111,88.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.197 | Acc: 42.824,62.097,87.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.201 | Acc: 42.810,62.027,87.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.201 | Acc: 42.816,61.967,87.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.201 | Acc: 42.771,61.936,87.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.211 | Acc: 42.670,61.747,87.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.212 | Acc: 42.677,61.733,87.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.214 | Acc: 42.698,61.824,87.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.219 | Acc: 42.631,61.840,87.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.224 | Acc: 42.612,61.803,87.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.089 | Acc: 39.844,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.386 | Acc: 36.607,54.576,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.430 | Acc: 36.909,54.211,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.433 | Acc: 36.488,54.419,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 2.107 | Acc: 46.875,69.531,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.161 | Acc: 43.155,62.872,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.155 | Acc: 43.064,63.053,87.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.132 | Acc: 43.097,63.717,88.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.136 | Acc: 43.239,63.773,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.141 | Acc: 43.123,63.676,88.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.142 | Acc: 43.156,63.617,88.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.152 | Acc: 42.841,63.281,88.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.151 | Acc: 42.891,63.393,88.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.160 | Acc: 42.947,63.178,88.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.166 | Acc: 42.996,63.013,88.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.172 | Acc: 43.032,62.956,88.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.179 | Acc: 42.991,62.860,87.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.181 | Acc: 42.975,62.838,87.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.185 | Acc: 42.966,62.683,87.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.189 | Acc: 42.979,62.648,87.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.188 | Acc: 43.064,62.704,87.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.192 | Acc: 43.051,62.635,87.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.196 | Acc: 43.057,62.556,87.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.201 | Acc: 42.989,62.568,87.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.208 | Acc: 42.969,57.031,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.335 | Acc: 38.988,54.353,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.361 | Acc: 39.253,54.859,67.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.374 | Acc: 38.909,54.739,67.482,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 1.843 | Acc: 45.312,70.312,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.125 | Acc: 41.853,63.467,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.132 | Acc: 42.245,63.014,89.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.141 | Acc: 42.431,63.012,88.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.135 | Acc: 42.834,63.214,88.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.117 | Acc: 43.410,63.560,89.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.127 | Acc: 43.240,63.436,88.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.133 | Acc: 43.279,63.492,88.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.135 | Acc: 43.134,63.495,88.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.142 | Acc: 43.137,63.260,88.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.149 | Acc: 43.175,63.157,88.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.157 | Acc: 43.124,62.974,88.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.158 | Acc: 43.131,62.934,88.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.156 | Acc: 43.325,62.949,88.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.157 | Acc: 43.333,62.931,88.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.165 | Acc: 43.348,62.876,88.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.173 | Acc: 43.278,62.717,87.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.174 | Acc: 43.251,62.722,87.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.175 | Acc: 43.322,62.779,87.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.179 | Acc: 43.354,62.693,87.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.240 | Acc: 38.281,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.441 | Acc: 37.835,55.357,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.432 | Acc: 38.720,54.802,66.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.429 | Acc: 38.217,54.841,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 2.040 | Acc: 48.438,64.062,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.105 | Acc: 43.638,62.946,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.074 | Acc: 43.979,63.072,89.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.076 | Acc: 43.609,63.422,89.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.090 | Acc: 43.422,63.503,89.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.109 | Acc: 43.448,63.428,89.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.106 | Acc: 43.673,63.410,89.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.109 | Acc: 43.789,63.553,89.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.114 | Acc: 43.682,63.344,89.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.126 | Acc: 43.582,63.212,88.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.126 | Acc: 43.602,63.238,88.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.133 | Acc: 43.457,63.168,88.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.142 | Acc: 43.530,63.122,88.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.143 | Acc: 43.567,63.168,88.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.147 | Acc: 43.516,63.056,88.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.149 | Acc: 43.519,63.024,88.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.153 | Acc: 43.417,62.958,88.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.160 | Acc: 43.402,62.896,87.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.162 | Acc: 43.495,62.950,87.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.166 | Acc: 43.549,62.888,87.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.310 | Acc: 39.062,56.250,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.476 | Acc: 37.798,53.906,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.491 | Acc: 37.938,53.335,66.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.500 | Acc: 37.769,53.458,66.688,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 2.085 | Acc: 45.312,67.188,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.098 | Acc: 44.606,63.765,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.087 | Acc: 44.512,63.872,90.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.099 | Acc: 43.916,63.986,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.089 | Acc: 44.010,63.937,89.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.099 | Acc: 43.735,63.653,89.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.111 | Acc: 43.724,63.243,89.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.110 | Acc: 43.938,63.370,89.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.117 | Acc: 43.828,63.354,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.122 | Acc: 43.672,63.255,88.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.116 | Acc: 43.975,63.503,88.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.125 | Acc: 43.799,63.324,88.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.136 | Acc: 43.724,63.197,88.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.138 | Acc: 43.744,63.278,88.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.143 | Acc: 43.747,63.145,88.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.150 | Acc: 43.786,63.011,88.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.156 | Acc: 43.757,62.965,87.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.160 | Acc: 43.771,62.869,87.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.166 | Acc: 43.715,62.758,87.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.168 | Acc: 43.686,62.773,87.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.379 | Acc: 37.500,54.688,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.495 | Acc: 37.574,51.749,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.529 | Acc: 36.947,51.296,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.542 | Acc: 36.603,50.935,66.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 2.254 | Acc: 40.625,58.594,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.101 | Acc: 43.676,63.393,88.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.060 | Acc: 44.169,64.539,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.088 | Acc: 43.852,63.960,89.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.093 | Acc: 43.490,63.879,89.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.082 | Acc: 43.750,64.148,89.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.091 | Acc: 43.705,64.017,89.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.093 | Acc: 43.684,64.002,89.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.099 | Acc: 43.876,64.004,88.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.105 | Acc: 43.802,64.062,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.107 | Acc: 43.668,64.094,88.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.107 | Acc: 43.697,64.052,88.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.117 | Acc: 43.552,63.813,88.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.121 | Acc: 43.546,63.676,88.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.129 | Acc: 43.458,63.473,88.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.133 | Acc: 43.563,63.320,88.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.131 | Acc: 43.704,63.410,88.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.135 | Acc: 43.736,63.377,88.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.141 | Acc: 43.629,63.363,88.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.146 | Acc: 43.545,63.392,88.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.079 | Acc: 40.625,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.377 | Acc: 40.625,56.287,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.380 | Acc: 40.606,55.774,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.384 | Acc: 39.921,55.494,66.688,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 1.922 | Acc: 48.438,66.406,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.052 | Acc: 45.499,64.844,89.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.058 | Acc: 44.798,64.444,89.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.064 | Acc: 44.570,64.536,89.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.056 | Acc: 44.628,64.506,89.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.064 | Acc: 44.570,64.403,89.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.073 | Acc: 44.473,64.282,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.075 | Acc: 44.387,64.345,89.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.082 | Acc: 44.473,64.325,89.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.082 | Acc: 44.492,64.447,89.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.091 | Acc: 44.255,64.272,89.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.095 | Acc: 44.195,64.034,89.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.099 | Acc: 44.090,64.037,89.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.106 | Acc: 44.007,63.994,88.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.110 | Acc: 43.959,63.876,88.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.115 | Acc: 44.002,63.816,88.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.118 | Acc: 43.967,63.719,88.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.119 | Acc: 44.020,63.739,88.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.123 | Acc: 43.971,63.675,88.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.125 | Acc: 44.002,63.622,88.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.184 | Acc: 40.625,56.250,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.323 | Acc: 39.472,56.213,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.342 | Acc: 39.806,55.697,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.355 | Acc: 39.267,54.918,68.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 1.881 | Acc: 53.125,60.938,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.083 | Acc: 46.019,63.579,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.047 | Acc: 45.160,63.720,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.019 | Acc: 45.069,64.933,90.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.019 | Acc: 45.235,65.201,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.033 | Acc: 45.119,64.968,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.048 | Acc: 44.854,65.031,89.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.056 | Acc: 44.980,65.043,89.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.066 | Acc: 44.900,64.887,89.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.077 | Acc: 44.631,64.706,89.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.080 | Acc: 44.687,64.591,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.088 | Acc: 44.538,64.437,88.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.097 | Acc: 44.415,64.218,88.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.099 | Acc: 44.459,64.194,88.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.105 | Acc: 44.473,64.129,88.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.111 | Acc: 44.453,64.070,88.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.121 | Acc: 44.283,63.880,88.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.125 | Acc: 44.211,63.792,88.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.130 | Acc: 44.181,63.783,88.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.136 | Acc: 44.172,63.724,88.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.416 | Acc: 37.500,57.031,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.509 | Acc: 38.021,53.237,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.527 | Acc: 38.205,53.468,65.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.521 | Acc: 37.334,52.920,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 1.895 | Acc: 44.531,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.007 | Acc: 46.168,65.699,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 44.722,65.587,90.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.034 | Acc: 44.378,65.369,89.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.055 | Acc: 43.808,64.689,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.069 | Acc: 43.796,64.418,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.058 | Acc: 43.944,64.695,89.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.058 | Acc: 43.972,64.788,89.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.061 | Acc: 44.022,64.708,89.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.067 | Acc: 44.022,64.611,89.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.069 | Acc: 44.248,64.669,89.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.073 | Acc: 44.256,64.582,89.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.077 | Acc: 44.431,64.503,89.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.087 | Acc: 44.412,64.308,88.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.093 | Acc: 44.456,64.246,88.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.100 | Acc: 44.365,64.218,88.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.103 | Acc: 44.354,64.260,88.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.103 | Acc: 44.426,64.221,88.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.111 | Acc: 44.230,64.086,88.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.117 | Acc: 44.269,64.032,88.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.256 | Acc: 42.969,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.370 | Acc: 39.100,55.878,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.385 | Acc: 39.596,55.145,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.403 | Acc: 38.858,54.880,67.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 2.020 | Acc: 42.188,63.281,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.070 | Acc: 44.680,64.025,89.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.058 | Acc: 44.665,64.329,89.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.042 | Acc: 44.980,64.703,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.043 | Acc: 45.091,64.834,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.042 | Acc: 44.903,64.697,90.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.046 | Acc: 44.802,64.805,90.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.047 | Acc: 44.570,64.860,90.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.045 | Acc: 44.672,64.790,90.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.051 | Acc: 44.682,64.753,89.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.053 | Acc: 44.714,64.782,89.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.062 | Acc: 44.556,64.731,89.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.064 | Acc: 44.606,64.785,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.068 | Acc: 44.645,64.748,89.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.075 | Acc: 44.562,64.621,89.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.079 | Acc: 44.536,64.532,89.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.086 | Acc: 44.436,64.469,89.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.088 | Acc: 44.472,64.431,88.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.091 | Acc: 44.404,64.359,88.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.097 | Acc: 44.330,64.274,88.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.358 | Acc: 39.062,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.381 | Acc: 38.988,54.874,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.402 | Acc: 38.910,54.973,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.425 | Acc: 38.384,54.841,66.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 2.507 | Acc: 35.156,62.500,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.061 | Acc: 44.457,64.025,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.028 | Acc: 44.912,64.444,90.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.033 | Acc: 44.736,64.447,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.030 | Acc: 45.129,64.911,89.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.036 | Acc: 45.150,64.867,89.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.035 | Acc: 45.203,65.025,89.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.048 | Acc: 45.002,65.010,89.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.044 | Acc: 44.837,65.052,89.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.047 | Acc: 44.855,65.047,89.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.053 | Acc: 44.881,64.953,89.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.058 | Acc: 44.878,64.982,89.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.061 | Acc: 45.011,65.012,89.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.069 | Acc: 44.869,64.829,89.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.074 | Acc: 44.873,64.696,89.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.078 | Acc: 44.941,64.662,89.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.079 | Acc: 44.904,64.690,88.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.080 | Acc: 45.005,64.656,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.085 | Acc: 44.951,64.582,88.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.090 | Acc: 44.870,64.581,88.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.426 | Acc: 41.406,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.424 | Acc: 38.653,56.696,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.458 | Acc: 38.491,56.098,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.458 | Acc: 37.795,55.866,66.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 1.970 | Acc: 46.875,66.406,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.024 | Acc: 45.089,65.253,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.036 | Acc: 45.503,65.263,89.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.028 | Acc: 45.274,65.330,89.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.022 | Acc: 45.583,65.712,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.025 | Acc: 45.436,65.648,89.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.032 | Acc: 45.403,65.683,89.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.031 | Acc: 45.396,65.553,89.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.033 | Acc: 45.487,65.703,89.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.041 | Acc: 45.369,65.500,89.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.042 | Acc: 45.270,65.423,89.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.049 | Acc: 45.228,65.271,89.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.056 | Acc: 45.241,65.116,89.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.061 | Acc: 45.109,65.098,89.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.066 | Acc: 45.009,64.977,89.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.068 | Acc: 45.024,65.033,89.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.073 | Acc: 44.996,64.873,88.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.075 | Acc: 45.049,64.770,88.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.078 | Acc: 44.999,64.759,88.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.079 | Acc: 45.011,64.792,88.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.350 | Acc: 36.719,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.378 | Acc: 38.951,56.250,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.444 | Acc: 37.786,55.431,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.440 | Acc: 37.090,55.430,68.519,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 1.887 | Acc: 46.875,66.406,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.011 | Acc: 45.350,64.955,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 44.722,65.492,89.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.001 | Acc: 44.890,65.932,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.005 | Acc: 45.245,65.934,90.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.008 | Acc: 45.065,65.857,90.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.012 | Acc: 44.912,65.948,90.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.019 | Acc: 44.697,65.719,89.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.014 | Acc: 44.963,65.829,90.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.017 | Acc: 44.928,65.798,90.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.022 | Acc: 44.943,65.703,89.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.031 | Acc: 44.941,65.660,89.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.034 | Acc: 45.024,65.502,89.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.036 | Acc: 45.091,65.481,89.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.040 | Acc: 45.098,65.475,89.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.042 | Acc: 45.113,65.521,89.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.050 | Acc: 45.093,65.435,89.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.056 | Acc: 45.079,65.261,89.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.063 | Acc: 45.007,65.119,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.069 | Acc: 44.909,64.987,88.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.040 | Acc: 39.844,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.434 | Acc: 37.946,55.841,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.452 | Acc: 38.319,55.926,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.445 | Acc: 37.846,55.751,67.713,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 1.975 | Acc: 43.750,65.625,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.033 | Acc: 45.610,65.104,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.045 | Acc: 45.160,65.225,89.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.030 | Acc: 45.441,65.612,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.014 | Acc: 46.026,65.721,89.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.033 | Acc: 45.622,65.246,90.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.019 | Acc: 45.642,65.580,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.025 | Acc: 45.595,65.359,89.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.026 | Acc: 45.487,65.242,89.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.030 | Acc: 45.515,65.155,89.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.033 | Acc: 45.398,64.968,89.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.035 | Acc: 45.323,64.978,89.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.039 | Acc: 45.196,64.918,89.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.041 | Acc: 45.292,64.963,89.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.044 | Acc: 45.157,64.927,89.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.046 | Acc: 45.110,64.922,89.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.051 | Acc: 45.110,64.832,89.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.056 | Acc: 45.054,64.683,89.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.059 | Acc: 45.090,64.703,89.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.065 | Acc: 45.040,64.559,88.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.979 | Acc: 42.188,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.340 | Acc: 40.179,54.613,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.349 | Acc: 40.358,54.745,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.346 | Acc: 40.574,54.598,67.367,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 1.946 | Acc: 46.094,68.750,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.072 | Acc: 44.829,65.625,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.043 | Acc: 44.703,65.396,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 45.248,66.189,90.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.006 | Acc: 45.525,66.503,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.006 | Acc: 45.436,66.368,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.999 | Acc: 45.467,66.516,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.003 | Acc: 45.495,66.340,90.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.997 | Acc: 45.686,66.416,90.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.002 | Acc: 45.727,66.272,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.006 | Acc: 45.721,66.099,89.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.006 | Acc: 45.708,66.063,89.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.010 | Acc: 45.611,66.001,89.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.009 | Acc: 45.681,66.020,89.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.022 | Acc: 45.488,65.770,89.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.032 | Acc: 45.445,65.680,89.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.040 | Acc: 45.400,65.547,89.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.045 | Acc: 45.379,65.465,89.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.050 | Acc: 45.274,65.359,89.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.054 | Acc: 45.216,65.375,89.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.392 | Acc: 42.969,53.125,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.514 | Acc: 40.327,54.948,65.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.512 | Acc: 39.291,54.878,65.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.516 | Acc: 38.704,54.214,65.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 1.757 | Acc: 50.000,71.875,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.973 | Acc: 45.647,66.369,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.000 | Acc: 45.884,66.273,89.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.004 | Acc: 45.377,66.137,89.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.996 | Acc: 45.554,66.329,89.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.990 | Acc: 45.506,66.638,89.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.991 | Acc: 45.577,66.271,90.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.986 | Acc: 45.783,66.445,90.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.993 | Acc: 45.681,66.144,90.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.999 | Acc: 45.735,66.044,89.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.005 | Acc: 45.658,66.045,89.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.003 | Acc: 45.836,66.046,89.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.008 | Acc: 45.601,66.033,89.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.008 | Acc: 45.675,65.990,89.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.013 | Acc: 45.529,65.842,89.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.018 | Acc: 45.515,65.703,89.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.022 | Acc: 45.510,65.642,89.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.026 | Acc: 45.427,65.517,89.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.032 | Acc: 45.328,65.545,89.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.035 | Acc: 45.376,65.496,89.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.348 | Acc: 39.844,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.567 | Acc: 37.686,53.571,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.550 | Acc: 37.881,53.659,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.560 | Acc: 37.321,53.676,66.650,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 2.163 | Acc: 42.188,61.719,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.066 | Acc: 43.713,64.807,88.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.038 | Acc: 44.722,64.634,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.009 | Acc: 45.697,65.049,89.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.008 | Acc: 45.592,65.152,89.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.997 | Acc: 45.800,65.524,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.996 | Acc: 46.132,65.515,89.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.000 | Acc: 45.983,65.503,89.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.001 | Acc: 45.953,65.489,89.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.002 | Acc: 45.930,65.547,89.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.012 | Acc: 45.818,65.396,89.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.015 | Acc: 45.786,65.328,89.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.021 | Acc: 45.565,65.255,89.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.027 | Acc: 45.468,65.218,89.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.028 | Acc: 45.649,65.272,89.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.036 | Acc: 45.479,65.137,89.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.042 | Acc: 45.393,65.090,88.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.046 | Acc: 45.374,65.096,88.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.049 | Acc: 45.393,65.060,88.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.051 | Acc: 45.380,65.090,88.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.377 | Acc: 42.188,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.472 | Acc: 38.244,54.725,66.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.494 | Acc: 38.453,54.821,66.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.519 | Acc: 37.935,54.611,66.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 2.031 | Acc: 46.875,67.188,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.936 | Acc: 46.280,66.853,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.947 | Acc: 45.846,66.463,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.964 | Acc: 45.517,66.253,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.979 | Acc: 45.284,65.876,90.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.980 | Acc: 45.258,65.865,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.974 | Acc: 45.526,66.154,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.977 | Acc: 45.756,66.196,90.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.982 | Acc: 45.740,66.062,90.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.986 | Acc: 45.701,65.992,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.985 | Acc: 45.849,66.029,90.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.988 | Acc: 45.945,65.989,90.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.994 | Acc: 45.877,65.855,90.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.998 | Acc: 45.836,65.748,90.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.001 | Acc: 45.788,65.856,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.007 | Acc: 45.800,65.747,89.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.011 | Acc: 45.702,65.683,89.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.015 | Acc: 45.674,65.570,89.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.022 | Acc: 45.579,65.528,89.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.025 | Acc: 45.602,65.504,89.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.099 | Acc: 43.750,58.594,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.281 | Acc: 41.406,55.878,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.328 | Acc: 41.578,56.555,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.357 | Acc: 41.048,56.237,67.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 2.001 | Acc: 48.438,59.375,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.003 | Acc: 44.531,66.443,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.953 | Acc: 46.284,66.845,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.955 | Acc: 46.107,66.995,90.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.962 | Acc: 46.113,67.081,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.979 | Acc: 45.738,66.538,89.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.986 | Acc: 45.764,66.503,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.991 | Acc: 45.529,66.478,89.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.996 | Acc: 45.487,66.280,89.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.998 | Acc: 45.533,66.329,89.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.992 | Acc: 45.717,66.484,89.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.994 | Acc: 45.871,66.498,89.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.000 | Acc: 45.714,66.364,89.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.003 | Acc: 45.675,66.295,89.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.007 | Acc: 45.591,66.237,89.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.012 | Acc: 45.494,66.110,89.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.016 | Acc: 45.519,66.063,89.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.023 | Acc: 45.530,65.943,89.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.027 | Acc: 45.548,65.921,89.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.032 | Acc: 45.468,65.824,89.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.179 | Acc: 42.969,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.427 | Acc: 38.951,56.734,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.459 | Acc: 38.891,56.002,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.495 | Acc: 38.345,55.289,66.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 2.149 | Acc: 42.969,64.844,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.008 | Acc: 46.131,66.778,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.007 | Acc: 45.884,66.597,89.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.991 | Acc: 45.902,66.470,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.967 | Acc: 46.373,67.014,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.965 | Acc: 46.388,67.188,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.975 | Acc: 46.087,66.897,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.984 | Acc: 45.922,66.850,90.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.985 | Acc: 45.885,66.998,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.990 | Acc: 45.731,66.829,89.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.994 | Acc: 45.686,66.616,89.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.990 | Acc: 45.786,66.717,89.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.985 | Acc: 45.915,66.841,89.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.988 | Acc: 45.884,66.816,89.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.992 | Acc: 45.835,66.773,89.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.997 | Acc: 45.787,66.601,89.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.004 | Acc: 45.702,66.440,89.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.007 | Acc: 45.693,66.376,89.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.010 | Acc: 45.724,66.318,89.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.014 | Acc: 45.757,66.291,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.338 | Acc: 37.500,60.156,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.535 | Acc: 38.542,55.060,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.541 | Acc: 38.586,54.821,65.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.559 | Acc: 37.948,54.316,65.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 1.995 | Acc: 45.312,61.719,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 46.391,67.485,90.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.975 | Acc: 46.608,66.997,89.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.965 | Acc: 46.132,66.931,89.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.963 | Acc: 45.978,67.130,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.977 | Acc: 45.730,66.700,89.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.988 | Acc: 45.403,66.329,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.985 | Acc: 45.545,66.451,89.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.990 | Acc: 45.521,66.285,89.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.990 | Acc: 45.727,66.350,89.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.993 | Acc: 45.771,66.286,89.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.994 | Acc: 45.797,66.194,89.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.998 | Acc: 45.805,66.166,89.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.001 | Acc: 45.812,66.041,89.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.004 | Acc: 45.849,66.053,89.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.005 | Acc: 45.909,66.043,89.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.011 | Acc: 45.721,65.912,89.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.015 | Acc: 45.674,65.895,89.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.014 | Acc: 45.771,65.954,89.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.019 | Acc: 45.782,65.908,89.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.239 | Acc: 39.062,58.594,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.440 | Acc: 39.397,56.659,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.437 | Acc: 38.186,56.460,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.444 | Acc: 37.871,55.994,67.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 2.056 | Acc: 42.188,63.281,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.938 | Acc: 46.057,66.964,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.922 | Acc: 46.418,67.226,91.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.930 | Acc: 46.145,66.880,91.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.924 | Acc: 46.142,67.120,91.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.931 | Acc: 45.769,67.149,90.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.932 | Acc: 46.003,67.071,90.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.935 | Acc: 46.243,67.032,90.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.945 | Acc: 46.157,66.790,90.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.951 | Acc: 46.176,66.752,90.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.956 | Acc: 46.152,66.709,90.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.958 | Acc: 46.249,66.763,90.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.961 | Acc: 46.301,66.795,90.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.968 | Acc: 46.279,66.589,90.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.972 | Acc: 46.247,66.556,90.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.977 | Acc: 46.294,66.469,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.983 | Acc: 46.125,66.379,89.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.990 | Acc: 46.098,66.319,89.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.995 | Acc: 46.107,66.270,89.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.000 | Acc: 46.036,66.136,89.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.568 | Acc: 42.188,58.594,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.284 | Acc: 39.583,57.440,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.328 | Acc: 38.948,56.803,68.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.333 | Acc: 38.909,56.711,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 1.950 | Acc: 49.219,66.406,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 46.652,67.671,89.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 46.475,67.778,90.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.941 | Acc: 46.670,67.789,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.930 | Acc: 46.605,67.901,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.928 | Acc: 46.720,67.791,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.932 | Acc: 46.597,67.775,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.932 | Acc: 46.825,67.592,90.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.933 | Acc: 46.817,67.542,90.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.938 | Acc: 46.681,67.308,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.943 | Acc: 46.564,67.277,90.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.947 | Acc: 46.543,67.184,90.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.947 | Acc: 46.648,67.207,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.951 | Acc: 46.671,67.152,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.956 | Acc: 46.611,67.112,90.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.962 | Acc: 46.540,67.027,90.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.969 | Acc: 46.400,66.854,89.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.977 | Acc: 46.343,66.736,89.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.980 | Acc: 46.265,66.677,89.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.986 | Acc: 46.172,66.572,89.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.156 | Acc: 40.625,57.031,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.299 | Acc: 41.332,56.399,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.324 | Acc: 41.578,56.574,67.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.335 | Acc: 41.381,56.314,67.149,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 1.926 | Acc: 43.750,67.188,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.876 | Acc: 48.214,67.671,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.914 | Acc: 47.027,67.721,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.938 | Acc: 46.606,66.944,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.933 | Acc: 46.644,66.937,90.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.932 | Acc: 46.442,66.894,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.940 | Acc: 46.036,66.761,90.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.947 | Acc: 46.171,66.866,90.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.950 | Acc: 46.157,66.756,90.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.949 | Acc: 46.146,66.795,90.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.952 | Acc: 46.144,66.810,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.953 | Acc: 46.101,66.873,90.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.960 | Acc: 46.055,66.704,90.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.962 | Acc: 46.103,66.709,90.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.963 | Acc: 46.169,66.809,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.965 | Acc: 46.252,66.767,89.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.965 | Acc: 46.327,66.869,89.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.971 | Acc: 46.250,66.789,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.975 | Acc: 46.159,66.685,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.980 | Acc: 46.028,66.601,89.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.431 | Acc: 45.312,57.812,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.407 | Acc: 39.025,56.250,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.436 | Acc: 38.986,55.907,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.461 | Acc: 38.589,55.418,66.765,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 1.786 | Acc: 43.750,66.406,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.948 | Acc: 45.238,66.146,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.931 | Acc: 45.884,66.406,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.932 | Acc: 46.222,66.342,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.933 | Acc: 45.920,66.503,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.925 | Acc: 46.109,66.971,91.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.934 | Acc: 46.152,66.968,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.936 | Acc: 46.133,67.149,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.942 | Acc: 46.268,67.042,90.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.942 | Acc: 46.210,66.976,90.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.944 | Acc: 46.315,66.904,90.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.946 | Acc: 46.355,66.848,90.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.948 | Acc: 46.431,66.802,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.951 | Acc: 46.414,66.825,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.955 | Acc: 46.402,66.873,90.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.959 | Acc: 46.317,66.907,90.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.961 | Acc: 46.305,66.910,90.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.962 | Acc: 46.343,66.908,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.967 | Acc: 46.312,66.791,90.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.971 | Acc: 46.307,66.757,90.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.442 | Acc: 34.375,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.445 | Acc: 38.430,55.618,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.443 | Acc: 38.319,55.869,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.451 | Acc: 38.512,55.866,66.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 1.854 | Acc: 45.312,67.969,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.905 | Acc: 46.094,67.597,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.924 | Acc: 46.532,66.787,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.913 | Acc: 47.118,67.264,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.907 | Acc: 47.454,67.486,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.902 | Acc: 47.440,67.713,91.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.914 | Acc: 47.178,67.459,91.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.909 | Acc: 47.169,67.647,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.911 | Acc: 47.103,67.605,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.916 | Acc: 47.095,67.498,90.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.928 | Acc: 47.081,67.324,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.931 | Acc: 47.045,67.322,90.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.942 | Acc: 46.940,67.055,90.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.945 | Acc: 46.878,66.996,90.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.949 | Acc: 46.908,66.921,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.957 | Acc: 46.875,66.819,90.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.963 | Acc: 46.948,66.781,89.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.972 | Acc: 46.776,66.642,89.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.981 | Acc: 46.641,66.471,89.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.987 | Acc: 46.504,66.367,89.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.536 | Acc: 37.500,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.611 | Acc: 36.682,54.241,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.574 | Acc: 37.386,54.897,66.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.576 | Acc: 36.744,54.777,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 1.827 | Acc: 45.312,69.531,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.935 | Acc: 45.610,66.369,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.929 | Acc: 46.132,67.321,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.932 | Acc: 46.055,67.239,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.937 | Acc: 46.296,67.081,90.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.933 | Acc: 46.774,67.249,90.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.939 | Acc: 46.778,67.097,90.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.943 | Acc: 46.792,67.204,90.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.942 | Acc: 46.773,67.285,90.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.948 | Acc: 46.655,67.140,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.947 | Acc: 46.618,67.137,90.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.956 | Acc: 46.567,66.993,89.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.959 | Acc: 46.548,66.912,89.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.957 | Acc: 46.636,66.975,89.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.965 | Acc: 46.605,66.804,89.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.969 | Acc: 46.558,66.687,89.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.971 | Acc: 46.576,66.684,89.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.978 | Acc: 46.424,66.622,89.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.978 | Acc: 46.479,66.612,89.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.979 | Acc: 46.490,66.583,89.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.231 | Acc: 42.188,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.414 | Acc: 38.914,58.185,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.414 | Acc: 39.005,57.279,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.433 | Acc: 38.576,56.762,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 2.223 | Acc: 39.062,53.906,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.926 | Acc: 46.801,67.597,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.917 | Acc: 46.341,67.740,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.932 | Acc: 46.824,67.303,91.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.929 | Acc: 47.087,67.486,91.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.928 | Acc: 47.130,67.420,91.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.924 | Acc: 46.972,67.639,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.916 | Acc: 47.113,67.908,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.920 | Acc: 47.059,67.843,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.924 | Acc: 46.901,67.757,90.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.928 | Acc: 46.875,67.677,90.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.930 | Acc: 46.956,67.619,90.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.933 | Acc: 46.901,67.470,90.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.939 | Acc: 46.848,67.313,90.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.943 | Acc: 46.805,67.310,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.947 | Acc: 46.833,67.234,90.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.954 | Acc: 46.731,67.063,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.958 | Acc: 46.721,67.004,90.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.962 | Acc: 46.639,66.900,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.964 | Acc: 46.656,66.814,89.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.187 | Acc: 44.531,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.411 | Acc: 38.914,56.064,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.419 | Acc: 38.567,55.240,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.440 | Acc: 38.358,54.969,67.213,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 1.997 | Acc: 51.562,68.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.888 | Acc: 48.363,69.048,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.884 | Acc: 48.171,68.369,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.882 | Acc: 47.848,68.315,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.884 | Acc: 47.550,68.750,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.909 | Acc: 46.821,68.224,91.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.913 | Acc: 46.746,67.956,91.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.921 | Acc: 46.648,67.681,90.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.920 | Acc: 46.744,67.716,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.928 | Acc: 46.763,67.438,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.930 | Acc: 46.696,67.327,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.933 | Acc: 46.681,67.382,90.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.934 | Acc: 46.791,67.372,90.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.944 | Acc: 46.612,67.125,90.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.948 | Acc: 46.547,67.104,90.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.952 | Acc: 46.649,67.112,90.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.958 | Acc: 46.692,67.032,90.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.964 | Acc: 46.678,66.832,89.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.972 | Acc: 46.576,66.709,89.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.976 | Acc: 46.537,66.677,89.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.192 | Acc: 43.750,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.323 | Acc: 42.039,58.631,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.323 | Acc: 40.701,58.479,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.339 | Acc: 40.727,57.877,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 1.731 | Acc: 46.875,72.656,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.860 | Acc: 47.954,68.824,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.863 | Acc: 47.942,68.902,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.867 | Acc: 48.117,68.801,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.872 | Acc: 47.840,68.470,91.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.881 | Acc: 47.463,68.224,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.884 | Acc: 47.572,68.117,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.896 | Acc: 47.457,67.819,91.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.902 | Acc: 47.064,67.556,90.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.905 | Acc: 47.134,67.654,90.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.917 | Acc: 46.941,67.401,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.921 | Acc: 46.914,67.378,90.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.934 | Acc: 46.839,67.113,90.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.939 | Acc: 46.962,67.116,90.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.943 | Acc: 46.805,67.040,90.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.941 | Acc: 46.927,67.068,90.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.943 | Acc: 47.021,67.080,90.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.950 | Acc: 46.967,66.974,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.953 | Acc: 46.927,66.882,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.959 | Acc: 46.898,66.847,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.220 | Acc: 39.062,56.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.419 | Acc: 40.885,55.432,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.453 | Acc: 40.625,55.259,65.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.431 | Acc: 40.305,55.046,66.137,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 1.947 | Acc: 46.094,69.531,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.894 | Acc: 48.140,68.304,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.888 | Acc: 47.542,67.626,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.886 | Acc: 47.374,67.982,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.880 | Acc: 47.164,68.297,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.876 | Acc: 47.293,68.386,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.878 | Acc: 47.101,68.382,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.892 | Acc: 46.814,67.991,91.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.893 | Acc: 46.885,68.119,91.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.898 | Acc: 46.996,68.059,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.903 | Acc: 46.999,67.938,91.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.907 | Acc: 46.974,67.827,91.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.911 | Acc: 46.979,67.742,91.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.912 | Acc: 47.019,67.660,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.918 | Acc: 46.975,67.560,90.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.923 | Acc: 47.023,67.442,90.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.925 | Acc: 46.967,67.407,90.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.926 | Acc: 47.072,67.366,90.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.933 | Acc: 46.983,67.285,90.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.939 | Acc: 46.945,67.149,90.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.137 | Acc: 40.625,56.250,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.333 | Acc: 38.988,58.519,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.376 | Acc: 38.567,57.832,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.383 | Acc: 38.243,57.441,67.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 1.846 | Acc: 48.438,74.219,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.883 | Acc: 46.949,71.057,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.883 | Acc: 46.513,69.436,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.877 | Acc: 46.619,69.211,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.884 | Acc: 46.682,69.039,91.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.890 | Acc: 46.651,68.665,90.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.894 | Acc: 46.591,68.388,90.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.894 | Acc: 46.714,68.296,90.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.902 | Acc: 46.584,67.813,90.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.900 | Acc: 46.715,67.766,90.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.913 | Acc: 46.618,67.596,90.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.914 | Acc: 46.578,67.598,90.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.916 | Acc: 46.723,67.709,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.924 | Acc: 46.648,67.589,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.923 | Acc: 46.641,67.624,90.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.924 | Acc: 46.693,67.603,90.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.928 | Acc: 46.695,67.545,90.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.932 | Acc: 46.724,67.446,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.934 | Acc: 46.812,67.516,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.938 | Acc: 46.766,67.466,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.019 | Acc: 47.656,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.216 | Acc: 42.597,59.487,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.276 | Acc: 42.111,58.270,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.294 | Acc: 41.675,58.043,67.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 1.691 | Acc: 51.562,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.929 | Acc: 46.801,68.490,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.883 | Acc: 46.513,68.979,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.899 | Acc: 46.427,68.251,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.893 | Acc: 47.232,68.220,91.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.897 | Acc: 47.231,68.255,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.897 | Acc: 47.256,68.150,90.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.898 | Acc: 47.329,68.091,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.894 | Acc: 47.433,68.114,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.902 | Acc: 47.410,67.956,90.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.902 | Acc: 47.384,67.922,90.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.906 | Acc: 47.221,67.902,90.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.910 | Acc: 47.206,67.787,90.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.918 | Acc: 47.079,67.628,90.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.920 | Acc: 47.025,67.632,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.924 | Acc: 46.976,67.608,90.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.931 | Acc: 46.870,67.375,90.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.939 | Acc: 46.831,67.158,90.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.942 | Acc: 46.769,67.116,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.946 | Acc: 46.764,67.089,89.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.065 | Acc: 42.188,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.343 | Acc: 40.997,57.589,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.338 | Acc: 40.549,57.470,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.353 | Acc: 40.459,57.108,67.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 1.838 | Acc: 49.219,70.312,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.884 | Acc: 47.619,68.266,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.863 | Acc: 47.409,68.598,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.877 | Acc: 47.298,68.865,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.878 | Acc: 47.251,68.519,91.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.866 | Acc: 47.594,68.912,91.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.878 | Acc: 47.392,68.756,91.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.875 | Acc: 47.357,68.556,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.883 | Acc: 47.321,68.376,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.885 | Acc: 47.354,68.396,91.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.890 | Acc: 47.407,68.264,91.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.890 | Acc: 47.313,68.209,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.895 | Acc: 47.287,68.089,90.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.901 | Acc: 47.213,67.948,90.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.904 | Acc: 47.239,67.980,90.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.907 | Acc: 47.218,67.932,90.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.912 | Acc: 47.157,67.864,90.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.915 | Acc: 47.109,67.779,90.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.919 | Acc: 47.005,67.644,90.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.922 | Acc: 47.006,67.657,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.302 | Acc: 40.625,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.402 | Acc: 39.249,56.920,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.397 | Acc: 38.796,56.974,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.412 | Acc: 38.742,56.775,67.866,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 2.050 | Acc: 39.062,65.625,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.876 | Acc: 46.057,68.601,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.883 | Acc: 46.570,68.369,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.863 | Acc: 47.157,68.955,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.845 | Acc: 47.425,69.396,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.862 | Acc: 47.447,68.704,91.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.857 | Acc: 47.695,68.731,91.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.864 | Acc: 47.507,68.462,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.872 | Acc: 47.486,68.168,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.877 | Acc: 47.376,68.180,91.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.881 | Acc: 47.349,68.183,91.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.891 | Acc: 47.331,68.078,90.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.897 | Acc: 47.309,68.108,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.905 | Acc: 47.246,67.945,90.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.912 | Acc: 47.231,67.860,90.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.913 | Acc: 47.324,67.868,90.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.923 | Acc: 47.152,67.682,90.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.931 | Acc: 47.058,67.543,90.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.935 | Acc: 47.033,67.467,89.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.943 | Acc: 46.916,67.304,89.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.428 | Acc: 46.875,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.439 | Acc: 41.220,56.138,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.440 | Acc: 41.178,56.612,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.471 | Acc: 40.497,56.340,65.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 1.741 | Acc: 50.000,73.438,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.886 | Acc: 48.289,68.936,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.887 | Acc: 47.904,68.521,90.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.880 | Acc: 47.695,68.507,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.865 | Acc: 48.061,68.547,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.883 | Acc: 47.579,68.433,91.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.882 | Acc: 47.618,68.421,91.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.878 | Acc: 47.629,68.406,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.882 | Acc: 47.685,68.469,90.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.885 | Acc: 47.635,68.353,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.880 | Acc: 47.831,68.431,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.884 | Acc: 47.805,68.460,90.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.889 | Acc: 47.786,68.406,90.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.892 | Acc: 47.848,68.340,90.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.900 | Acc: 47.704,68.158,90.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.907 | Acc: 47.750,68.088,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.915 | Acc: 47.668,68.000,90.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.921 | Acc: 47.551,67.969,90.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.928 | Acc: 47.433,67.815,90.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.934 | Acc: 47.357,67.755,90.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.328 | Acc: 44.531,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.335 | Acc: 39.993,56.696,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.395 | Acc: 40.225,56.307,66.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.390 | Acc: 39.869,56.084,66.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 1.799 | Acc: 50.000,68.750,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.856 | Acc: 48.735,68.341,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.859 | Acc: 47.942,68.083,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.851 | Acc: 47.976,68.635,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.860 | Acc: 47.704,68.403,91.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.863 | Acc: 47.989,68.394,91.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.868 | Acc: 48.050,68.356,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.869 | Acc: 48.027,68.318,91.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.871 | Acc: 47.865,68.342,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.873 | Acc: 47.803,68.267,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.874 | Acc: 47.785,68.338,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.871 | Acc: 47.844,68.428,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.879 | Acc: 47.737,68.351,90.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.890 | Acc: 47.629,68.068,90.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.897 | Acc: 47.570,67.938,90.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.898 | Acc: 47.602,67.958,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.904 | Acc: 47.500,67.849,90.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.908 | Acc: 47.432,67.895,90.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.911 | Acc: 47.446,67.893,90.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.915 | Acc: 47.406,67.846,90.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.110 | Acc: 40.625,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.214 | Acc: 40.997,57.924,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.252 | Acc: 40.454,57.755,68.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.285 | Acc: 39.959,57.262,68.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 1.943 | Acc: 45.312,67.969,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.824 | Acc: 49.219,69.680,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.835 | Acc: 48.095,69.093,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.839 | Acc: 47.964,68.993,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.850 | Acc: 47.560,68.673,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.851 | Acc: 47.741,68.812,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.861 | Acc: 47.585,68.769,91.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.860 | Acc: 47.678,68.761,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.864 | Acc: 47.671,68.760,91.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.863 | Acc: 47.635,68.793,91.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.862 | Acc: 47.633,68.882,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.876 | Acc: 47.402,68.517,91.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.877 | Acc: 47.468,68.520,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.882 | Acc: 47.372,68.403,90.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.886 | Acc: 47.400,68.377,90.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.889 | Acc: 47.477,68.374,90.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.899 | Acc: 47.452,68.163,90.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.902 | Acc: 47.377,68.058,90.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.908 | Acc: 47.291,68.008,90.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.913 | Acc: 47.277,67.913,90.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.246 | Acc: 43.750,56.250,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.326 | Acc: 41.853,56.920,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.338 | Acc: 41.768,56.479,67.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.367 | Acc: 40.868,56.468,66.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 2.001 | Acc: 46.094,67.969,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.868 | Acc: 47.098,69.420,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.870 | Acc: 47.370,69.150,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.867 | Acc: 47.221,68.891,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.868 | Acc: 47.367,69.078,91.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.868 | Acc: 47.610,69.222,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.866 | Acc: 47.540,69.279,91.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.862 | Acc: 47.584,69.127,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.855 | Acc: 47.710,69.167,91.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.865 | Acc: 47.665,68.858,91.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.870 | Acc: 47.656,68.734,91.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.876 | Acc: 47.518,68.570,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.878 | Acc: 47.540,68.530,91.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.882 | Acc: 47.480,68.436,90.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.886 | Acc: 47.559,68.444,90.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.889 | Acc: 47.581,68.355,90.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.895 | Acc: 47.464,68.222,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.902 | Acc: 47.400,68.138,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.908 | Acc: 47.416,68.092,90.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.912 | Acc: 47.357,68.075,90.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.371 | Acc: 42.188,55.469,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.540 | Acc: 41.555,55.841,65.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.562 | Acc: 41.235,55.564,64.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.567 | Acc: 40.548,55.571,64.511,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 1.836 | Acc: 47.656,71.875,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.860 | Acc: 47.470,69.382,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.837 | Acc: 48.095,70.293,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.841 | Acc: 48.271,69.890,91.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.843 | Acc: 48.148,69.416,91.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.846 | Acc: 48.407,69.152,91.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.849 | Acc: 48.257,69.066,91.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.861 | Acc: 47.850,68.855,91.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.863 | Acc: 47.826,68.794,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.870 | Acc: 47.656,68.573,91.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.876 | Acc: 47.687,68.567,91.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.879 | Acc: 47.815,68.633,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.878 | Acc: 47.867,68.585,90.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.888 | Acc: 47.851,68.466,90.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.893 | Acc: 47.712,68.391,90.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.896 | Acc: 47.765,68.309,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.900 | Acc: 47.698,68.246,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.901 | Acc: 47.853,68.333,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.904 | Acc: 47.821,68.252,90.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.909 | Acc: 47.779,68.198,90.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.201 | Acc: 36.719,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.539 | Acc: 36.830,55.841,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.577 | Acc: 36.719,54.935,66.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.607 | Acc: 35.720,54.457,65.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 1.874 | Acc: 44.531,68.750,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.843 | Acc: 48.326,68.973,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.858 | Acc: 47.485,68.750,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.851 | Acc: 47.490,69.198,91.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.854 | Acc: 47.579,69.039,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.841 | Acc: 47.865,69.322,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.849 | Acc: 47.889,69.202,91.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.864 | Acc: 47.883,68.922,91.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.862 | Acc: 48.093,69.027,91.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.871 | Acc: 48.040,68.793,90.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.881 | Acc: 48.018,68.723,90.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.883 | Acc: 48.013,68.573,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.885 | Acc: 47.997,68.598,90.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.887 | Acc: 47.917,68.558,90.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.889 | Acc: 47.848,68.642,90.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.894 | Acc: 47.765,68.542,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.901 | Acc: 47.727,68.358,90.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.907 | Acc: 47.624,68.228,90.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.912 | Acc: 47.572,68.142,90.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.919 | Acc: 47.492,68.034,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.269 | Acc: 40.625,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.363 | Acc: 41.034,58.705,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.406 | Acc: 41.006,58.537,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.402 | Acc: 41.073,58.120,66.368,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 1.681 | Acc: 53.906,71.875,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.859 | Acc: 47.879,69.308,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.859 | Acc: 47.523,68.350,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.852 | Acc: 47.118,68.737,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.855 | Acc: 47.299,68.654,91.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.861 | Acc: 47.184,68.626,91.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.861 | Acc: 47.262,68.821,91.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.861 | Acc: 47.191,68.778,91.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.859 | Acc: 47.617,68.837,91.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.864 | Acc: 47.540,68.772,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.873 | Acc: 47.384,68.563,91.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.871 | Acc: 47.419,68.711,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.873 | Acc: 47.569,68.714,90.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.875 | Acc: 47.584,68.741,90.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.877 | Acc: 47.545,68.781,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.883 | Acc: 47.443,68.623,90.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.889 | Acc: 47.466,68.555,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.892 | Acc: 47.450,68.487,90.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.896 | Acc: 47.410,68.343,90.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.901 | Acc: 47.353,68.239,90.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.045 | Acc: 42.969,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.262 | Acc: 41.146,57.701,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.323 | Acc: 40.968,57.546,67.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.344 | Acc: 40.599,57.159,67.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 1.903 | Acc: 47.656,68.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.859 | Acc: 47.656,69.196,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.838 | Acc: 47.256,69.455,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.841 | Acc: 47.208,69.634,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.826 | Acc: 47.598,69.821,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.824 | Acc: 47.842,69.531,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.824 | Acc: 47.966,69.525,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.831 | Acc: 48.000,69.382,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.836 | Acc: 47.879,69.255,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.842 | Acc: 47.812,69.147,91.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.850 | Acc: 47.769,69.030,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.853 | Acc: 47.730,68.973,91.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.857 | Acc: 47.608,68.896,91.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.858 | Acc: 47.740,68.945,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.862 | Acc: 47.706,68.956,91.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.867 | Acc: 47.744,68.914,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.871 | Acc: 47.722,68.933,90.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.876 | Acc: 47.785,68.803,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.879 | Acc: 47.825,68.741,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.882 | Acc: 47.777,68.703,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.085 | Acc: 49.219,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.375 | Acc: 39.807,57.999,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.377 | Acc: 40.072,58.727,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.392 | Acc: 39.882,58.837,67.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 1.664 | Acc: 48.438,71.875,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.747 | Acc: 50.000,72.061,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.762 | Acc: 49.447,71.284,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.769 | Acc: 49.283,70.786,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.772 | Acc: 49.142,70.399,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.791 | Acc: 48.902,70.312,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.800 | Acc: 48.722,70.241,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.809 | Acc: 48.643,70.019,91.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.810 | Acc: 48.564,69.871,91.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.822 | Acc: 48.433,69.756,91.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.827 | Acc: 48.441,69.671,91.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.832 | Acc: 48.374,69.510,91.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.840 | Acc: 48.253,69.324,91.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.848 | Acc: 48.195,69.247,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.857 | Acc: 48.184,69.153,91.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.862 | Acc: 48.147,69.067,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.871 | Acc: 48.046,68.940,90.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.878 | Acc: 47.986,68.830,90.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.882 | Acc: 47.959,68.718,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.884 | Acc: 47.982,68.691,90.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.088 | Acc: 42.188,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.338 | Acc: 40.104,57.924,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.365 | Acc: 40.072,57.546,68.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.400 | Acc: 39.728,57.095,67.853,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 1.818 | Acc: 42.969,66.406,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.851 | Acc: 48.065,67.932,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.819 | Acc: 48.037,69.150,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.820 | Acc: 47.784,69.518,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.829 | Acc: 47.820,69.194,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.832 | Acc: 47.958,69.191,92.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.843 | Acc: 48.057,69.086,91.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.846 | Acc: 47.961,69.027,91.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.852 | Acc: 47.850,68.939,91.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.853 | Acc: 47.954,68.923,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.849 | Acc: 48.072,69.096,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.849 | Acc: 47.928,69.142,91.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.856 | Acc: 47.961,69.042,91.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.861 | Acc: 47.941,69.058,91.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.864 | Acc: 47.879,68.986,91.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.869 | Acc: 47.879,68.823,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.871 | Acc: 47.866,68.779,91.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.870 | Acc: 47.984,68.821,90.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.879 | Acc: 47.918,68.679,90.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.887 | Acc: 47.865,68.541,90.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.445 | Acc: 39.844,55.469,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.495 | Acc: 40.402,54.836,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.495 | Acc: 40.111,55.316,66.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.477 | Acc: 40.254,55.494,66.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 1.963 | Acc: 46.094,67.188,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.812 | Acc: 49.479,69.940,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.817 | Acc: 49.638,69.512,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.826 | Acc: 48.975,69.275,91.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.820 | Acc: 48.939,69.464,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.826 | Acc: 48.770,69.315,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.832 | Acc: 48.586,69.137,91.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.839 | Acc: 48.493,68.977,91.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.840 | Acc: 48.457,68.915,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.850 | Acc: 48.364,68.754,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.851 | Acc: 48.414,68.707,91.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.852 | Acc: 48.321,68.789,91.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.852 | Acc: 48.237,68.847,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.856 | Acc: 48.237,68.744,91.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.859 | Acc: 48.218,68.714,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.864 | Acc: 48.108,68.675,91.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.867 | Acc: 48.131,68.582,90.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.870 | Acc: 48.128,68.496,90.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.877 | Acc: 48.074,68.432,90.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.878 | Acc: 48.036,68.365,90.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.201 | Acc: 46.094,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.294 | Acc: 41.518,57.961,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 41.730,57.908,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.317 | Acc: 41.522,57.825,67.866,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 1.933 | Acc: 47.656,62.500,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.805 | Acc: 48.289,70.089,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.804 | Acc: 48.457,69.970,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.814 | Acc: 48.578,69.557,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.810 | Acc: 48.563,70.004,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.815 | Acc: 48.376,69.910,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.820 | Acc: 48.237,69.822,91.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.830 | Acc: 48.149,69.570,91.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.835 | Acc: 48.248,69.386,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.840 | Acc: 48.135,69.147,91.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.842 | Acc: 48.158,68.999,91.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.847 | Acc: 48.148,68.867,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.852 | Acc: 48.146,68.815,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.856 | Acc: 48.045,68.831,91.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.863 | Acc: 47.887,68.778,91.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.866 | Acc: 47.781,68.701,91.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.868 | Acc: 47.839,68.631,91.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.872 | Acc: 47.785,68.629,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.876 | Acc: 47.767,68.540,90.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.876 | Acc: 47.783,68.596,90.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.292 | Acc: 41.406,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.548 | Acc: 38.393,56.324,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.568 | Acc: 38.548,56.059,65.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.559 | Acc: 37.859,55.751,65.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 1.807 | Acc: 46.094,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.830 | Acc: 47.284,70.015,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.830 | Acc: 48.647,69.950,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.838 | Acc: 48.553,69.518,91.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.847 | Acc: 48.264,69.309,91.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.847 | Acc: 48.167,69.237,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.844 | Acc: 47.979,69.144,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.839 | Acc: 48.116,69.315,91.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.845 | Acc: 48.074,69.167,91.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.847 | Acc: 48.148,69.195,90.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.850 | Acc: 48.294,69.100,90.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.857 | Acc: 48.080,69.001,90.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.864 | Acc: 48.104,68.902,90.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.872 | Acc: 48.006,68.723,90.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.874 | Acc: 48.096,68.694,90.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.878 | Acc: 48.012,68.586,90.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.878 | Acc: 47.987,68.582,90.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.883 | Acc: 47.917,68.480,90.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.888 | Acc: 47.842,68.449,90.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.890 | Acc: 47.806,68.465,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.990 | Acc: 42.188,60.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.387 | Acc: 43.080,57.143,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.436 | Acc: 42.035,56.383,65.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.437 | Acc: 42.316,56.301,65.126,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 1.776 | Acc: 53.125,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.829 | Acc: 48.810,70.573,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.792 | Acc: 49.371,70.370,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.805 | Acc: 48.732,69.851,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.813 | Acc: 48.148,69.502,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.825 | Acc: 47.587,69.485,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.830 | Acc: 47.895,69.447,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.827 | Acc: 47.906,69.293,91.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.827 | Acc: 47.952,69.391,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.837 | Acc: 47.958,69.328,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.845 | Acc: 47.975,69.146,91.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.850 | Acc: 48.038,69.111,91.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.848 | Acc: 48.165,69.175,91.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.849 | Acc: 48.240,69.214,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.851 | Acc: 48.332,69.206,91.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.856 | Acc: 48.173,69.095,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.859 | Acc: 48.155,68.991,90.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.865 | Acc: 48.092,68.894,90.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.868 | Acc: 48.046,68.852,90.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.873 | Acc: 47.941,68.775,90.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.365 | Acc: 47.656,58.594,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.482 | Acc: 40.067,56.250,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.473 | Acc: 40.434,56.784,66.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.471 | Acc: 40.036,57.070,66.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 1.805 | Acc: 46.875,67.188,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.726 | Acc: 49.702,71.057,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.765 | Acc: 47.809,70.255,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.785 | Acc: 48.015,70.300,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.792 | Acc: 48.254,70.274,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.807 | Acc: 48.221,69.964,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.806 | Acc: 48.463,70.022,91.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.811 | Acc: 48.554,70.024,91.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.823 | Acc: 48.355,69.818,91.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.818 | Acc: 48.468,69.795,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.822 | Acc: 48.484,69.764,91.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.831 | Acc: 48.328,69.489,91.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.840 | Acc: 48.340,69.440,91.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.845 | Acc: 48.207,69.364,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.846 | Acc: 48.307,69.387,91.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.853 | Acc: 48.264,69.217,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.855 | Acc: 48.282,69.264,90.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.861 | Acc: 48.211,69.156,90.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.872 | Acc: 48.041,68.956,90.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.878 | Acc: 47.960,68.855,90.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.044 | Acc: 39.844,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.363 | Acc: 40.848,59.226,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.361 | Acc: 40.701,59.566,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.367 | Acc: 40.574,59.042,67.303,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 1.616 | Acc: 53.125,71.094,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.811 | Acc: 49.442,69.829,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.809 | Acc: 48.971,70.713,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.813 | Acc: 48.604,70.966,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.813 | Acc: 48.736,71.026,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.822 | Acc: 48.337,70.761,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.815 | Acc: 48.592,70.739,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.822 | Acc: 48.338,70.606,91.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.826 | Acc: 48.365,70.541,91.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.831 | Acc: 48.450,70.351,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.837 | Acc: 48.387,70.106,91.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.838 | Acc: 48.278,70.001,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.846 | Acc: 48.324,69.771,91.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.851 | Acc: 48.360,69.705,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.854 | Acc: 48.357,69.534,90.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.858 | Acc: 48.331,69.407,90.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.861 | Acc: 48.425,69.315,90.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.864 | Acc: 48.318,69.231,90.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.865 | Acc: 48.314,69.241,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.866 | Acc: 48.269,69.187,90.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.213 | Acc: 46.875,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.447 | Acc: 40.699,58.780,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.420 | Acc: 40.434,58.460,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.403 | Acc: 40.318,57.941,66.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 1.987 | Acc: 38.281,67.188,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.840 | Acc: 46.689,69.420,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.858 | Acc: 46.227,69.798,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.850 | Acc: 46.862,69.621,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.840 | Acc: 47.328,69.946,91.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.835 | Acc: 47.293,69.856,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.829 | Acc: 47.598,69.731,91.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.828 | Acc: 47.773,69.709,91.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.834 | Acc: 47.831,69.643,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.837 | Acc: 47.855,69.635,91.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.843 | Acc: 47.886,69.512,91.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.843 | Acc: 47.957,69.531,91.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.847 | Acc: 47.899,69.437,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.846 | Acc: 47.962,69.498,91.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.848 | Acc: 47.990,69.437,90.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.850 | Acc: 48.048,69.331,90.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.854 | Acc: 48.046,69.317,90.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.855 | Acc: 48.004,69.268,90.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.857 | Acc: 47.983,69.207,90.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.859 | Acc: 48.005,69.150,90.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.979 | Acc: 44.531,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.338 | Acc: 43.155,57.812,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.352 | Acc: 42.988,57.965,67.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.373 | Acc: 42.418,57.825,66.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 1.815 | Acc: 51.562,67.188,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.754 | Acc: 50.967,71.838,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.756 | Acc: 50.419,71.494,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.762 | Acc: 49.949,70.774,91.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.766 | Acc: 49.855,70.592,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.783 | Acc: 49.319,70.336,91.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.798 | Acc: 49.006,70.112,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.805 | Acc: 48.582,69.825,91.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.813 | Acc: 48.418,69.696,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.813 | Acc: 48.450,69.713,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.819 | Acc: 48.410,69.539,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.827 | Acc: 48.310,69.365,91.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.830 | Acc: 48.331,69.324,91.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.833 | Acc: 48.408,69.301,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.845 | Acc: 48.287,69.100,91.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.849 | Acc: 48.341,68.991,91.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.851 | Acc: 48.382,68.915,90.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.855 | Acc: 48.275,68.892,90.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.857 | Acc: 48.388,68.839,90.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.864 | Acc: 48.335,68.693,90.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.665 | Acc: 39.062,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.474 | Acc: 39.881,55.655,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.497 | Acc: 39.939,55.335,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.518 | Acc: 39.664,55.187,66.112,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 1.972 | Acc: 50.781,68.750,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.816 | Acc: 48.661,69.494,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.787 | Acc: 48.990,70.103,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.820 | Acc: 48.169,69.582,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.814 | Acc: 48.573,69.628,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.812 | Acc: 48.623,69.601,91.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.815 | Acc: 48.696,69.570,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.819 | Acc: 48.670,69.648,91.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.825 | Acc: 48.544,69.444,91.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.825 | Acc: 48.550,69.484,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.832 | Acc: 48.574,69.356,91.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.836 | Acc: 48.681,69.224,91.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.838 | Acc: 48.804,69.165,91.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.842 | Acc: 48.755,69.049,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.845 | Acc: 48.674,68.986,91.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.848 | Acc: 48.611,68.911,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.851 | Acc: 48.608,68.920,91.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.850 | Acc: 48.616,68.942,91.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.851 | Acc: 48.591,68.854,91.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.855 | Acc: 48.581,68.834,90.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.304 | Acc: 42.188,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.373 | Acc: 39.844,59.412,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.385 | Acc: 39.729,59.089,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.398 | Acc: 39.754,58.863,67.328,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 1.614 | Acc: 53.125,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.832 | Acc: 48.214,70.126,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.839 | Acc: 47.866,70.332,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.825 | Acc: 48.117,70.325,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.818 | Acc: 48.495,70.177,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.818 | Acc: 48.700,70.336,91.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.815 | Acc: 48.999,70.164,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.806 | Acc: 49.091,70.368,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.808 | Acc: 48.976,70.308,91.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.804 | Acc: 48.981,70.356,91.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.804 | Acc: 48.900,70.281,91.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.805 | Acc: 48.745,70.129,91.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.815 | Acc: 48.664,69.936,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.823 | Acc: 48.614,69.825,91.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.829 | Acc: 48.560,69.617,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.836 | Acc: 48.456,69.479,91.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.841 | Acc: 48.374,69.346,91.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.842 | Acc: 48.417,69.272,91.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.845 | Acc: 48.412,69.239,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.848 | Acc: 48.429,69.185,90.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.253 | Acc: 42.969,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.359 | Acc: 41.071,56.845,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.386 | Acc: 40.968,56.364,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.381 | Acc: 40.587,57.031,67.533,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 2.025 | Acc: 41.406,64.062,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.811 | Acc: 47.619,69.568,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.799 | Acc: 47.771,69.779,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.794 | Acc: 48.066,70.082,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.789 | Acc: 48.061,70.139,92.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.800 | Acc: 47.710,69.833,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.803 | Acc: 47.921,69.848,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.808 | Acc: 47.972,69.853,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.814 | Acc: 48.001,69.754,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.822 | Acc: 48.019,69.669,91.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.823 | Acc: 48.189,69.625,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.823 | Acc: 48.353,69.662,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.824 | Acc: 48.256,69.638,91.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.828 | Acc: 48.138,69.627,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.829 | Acc: 48.176,69.590,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.832 | Acc: 48.183,69.555,91.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.835 | Acc: 48.231,69.470,91.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.842 | Acc: 48.252,69.350,90.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.851 | Acc: 48.186,69.194,90.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.855 | Acc: 48.206,69.185,90.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.034 | Acc: 48.438,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.353 | Acc: 41.890,57.626,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.373 | Acc: 41.806,57.470,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.380 | Acc: 41.342,57.159,66.688,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 1.568 | Acc: 54.688,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.803 | Acc: 49.702,70.238,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.792 | Acc: 49.524,70.655,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.792 | Acc: 49.629,70.300,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.780 | Acc: 49.711,70.476,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.776 | Acc: 49.629,70.838,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.793 | Acc: 49.270,70.584,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.799 | Acc: 49.080,70.379,91.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.807 | Acc: 49.015,70.215,91.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.815 | Acc: 48.774,70.114,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.826 | Acc: 48.768,69.823,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.834 | Acc: 48.646,69.609,91.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.838 | Acc: 48.606,69.453,91.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.840 | Acc: 48.494,69.352,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.842 | Acc: 48.535,69.303,91.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.842 | Acc: 48.572,69.337,90.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.844 | Acc: 48.603,69.302,90.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.848 | Acc: 48.623,69.256,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.857 | Acc: 48.539,69.064,90.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.860 | Acc: 48.515,69.002,90.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.445 | Acc: 43.750,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.460 | Acc: 40.290,57.552,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.477 | Acc: 39.558,57.641,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.459 | Acc: 39.460,57.569,66.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 1.714 | Acc: 49.219,70.312,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.768 | Acc: 49.888,70.499,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.778 | Acc: 49.657,70.560,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.789 | Acc: 48.540,70.453,91.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.784 | Acc: 48.630,70.312,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.795 | Acc: 48.561,70.212,91.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.796 | Acc: 48.644,70.164,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.793 | Acc: 48.438,70.224,91.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.798 | Acc: 48.438,70.104,91.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.801 | Acc: 48.463,69.972,91.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.815 | Acc: 48.321,69.683,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.814 | Acc: 48.377,69.733,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.821 | Acc: 48.298,69.560,91.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.825 | Acc: 48.204,69.561,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.827 | Acc: 48.332,69.512,91.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.830 | Acc: 48.375,69.459,91.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.835 | Acc: 48.438,69.412,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.840 | Acc: 48.357,69.316,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.845 | Acc: 48.360,69.302,90.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.851 | Acc: 48.337,69.244,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.276 | Acc: 46.094,54.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.268 | Acc: 43.452,59.003,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.303 | Acc: 44.017,59.070,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.337 | Acc: 43.596,58.389,66.586,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 1.652 | Acc: 52.344,67.188,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.754 | Acc: 49.851,71.429,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.731 | Acc: 50.629,71.208,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.738 | Acc: 50.320,71.119,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.739 | Acc: 50.511,71.287,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.743 | Acc: 50.070,71.419,92.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.768 | Acc: 49.574,70.719,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.771 | Acc: 49.767,70.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.767 | Acc: 49.835,70.589,92.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.777 | Acc: 49.724,70.399,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.781 | Acc: 49.693,70.344,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.785 | Acc: 49.650,70.302,91.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.791 | Acc: 49.459,70.050,91.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.799 | Acc: 49.309,69.819,91.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.805 | Acc: 49.205,69.770,91.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.810 | Acc: 49.034,69.697,91.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.813 | Acc: 49.005,69.687,91.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.816 | Acc: 49.031,69.664,91.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.819 | Acc: 48.953,69.635,91.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.824 | Acc: 48.985,69.570,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.515 | Acc: 36.719,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.494 | Acc: 37.054,56.585,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.532 | Acc: 37.862,56.631,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.524 | Acc: 38.102,56.224,67.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 1.651 | Acc: 53.125,71.875,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.779 | Acc: 50.260,70.759,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.768 | Acc: 49.657,71.037,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.747 | Acc: 49.680,71.299,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.769 | Acc: 49.412,71.103,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.767 | Acc: 49.435,71.016,92.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.778 | Acc: 49.232,70.881,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.787 | Acc: 48.986,70.556,91.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.791 | Acc: 49.209,70.507,91.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.793 | Acc: 49.180,70.481,91.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.802 | Acc: 49.164,70.309,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.804 | Acc: 48.954,70.221,91.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.812 | Acc: 48.794,70.082,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.815 | Acc: 48.686,70.046,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.822 | Acc: 48.685,69.946,91.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.821 | Acc: 48.793,69.939,91.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.829 | Acc: 48.652,69.714,91.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.834 | Acc: 48.566,69.586,91.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.840 | Acc: 48.489,69.503,90.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.844 | Acc: 48.509,69.406,90.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.875 | Acc: 44.531,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.291 | Acc: 40.030,60.119,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.342 | Acc: 40.187,59.070,67.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.364 | Acc: 39.857,58.363,68.007,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 1.819 | Acc: 47.656,69.531,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.818 | Acc: 48.326,69.159,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.805 | Acc: 48.895,70.655,91.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.792 | Acc: 49.116,70.902,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.787 | Acc: 49.306,70.833,91.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.794 | Acc: 48.847,70.413,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.798 | Acc: 48.715,70.325,91.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.794 | Acc: 48.842,70.512,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.805 | Acc: 48.826,70.225,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.804 | Acc: 48.947,70.226,91.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.805 | Acc: 48.865,70.351,91.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.804 | Acc: 49.046,70.447,91.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.809 | Acc: 48.995,70.371,91.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.815 | Acc: 48.886,70.247,91.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.820 | Acc: 48.824,70.140,91.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.826 | Acc: 48.731,70.076,91.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.828 | Acc: 48.730,69.957,91.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.831 | Acc: 48.751,69.818,90.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.837 | Acc: 48.747,69.743,90.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.841 | Acc: 48.759,69.587,90.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.249 | Acc: 39.844,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.474 | Acc: 39.323,57.217,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.434 | Acc: 39.844,57.851,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.418 | Acc: 40.036,58.184,66.547,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.234 | Acc: 42.188,66.406,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.742 | Acc: 49.330,71.949,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.731 | Acc: 49.428,71.437,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.739 | Acc: 48.975,71.030,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.738 | Acc: 48.881,71.113,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.744 | Acc: 48.755,71.156,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.737 | Acc: 49.057,71.113,93.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.740 | Acc: 49.147,70.950,92.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.747 | Acc: 49.355,70.803,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.755 | Acc: 49.340,70.740,92.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.768 | Acc: 49.219,70.542,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.777 | Acc: 49.109,70.401,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.787 | Acc: 49.011,70.257,91.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.788 | Acc: 49.000,70.211,91.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.790 | Acc: 49.046,70.126,91.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.797 | Acc: 49.003,69.980,91.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.807 | Acc: 48.922,69.789,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.814 | Acc: 48.809,69.737,91.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.820 | Acc: 48.836,69.676,91.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.826 | Acc: 48.876,69.599,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.928 | Acc: 44.531,63.281,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.270 | Acc: 42.113,59.598,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.285 | Acc: 41.730,59.013,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.327 | Acc: 41.214,58.222,67.328,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.024 | Acc: 46.875,64.844,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.765 | Acc: 50.744,70.015,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.755 | Acc: 50.534,70.636,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.784 | Acc: 49.834,70.184,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.778 | Acc: 49.547,70.351,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.776 | Acc: 49.459,70.506,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.778 | Acc: 49.671,70.584,91.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.782 | Acc: 49.601,70.656,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.796 | Acc: 49.398,70.361,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.803 | Acc: 49.249,70.222,91.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.804 | Acc: 49.195,70.227,91.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.807 | Acc: 49.134,70.224,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.810 | Acc: 49.079,70.099,91.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.814 | Acc: 48.991,69.956,91.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.816 | Acc: 48.985,69.798,91.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.819 | Acc: 48.928,69.770,91.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.825 | Acc: 48.842,69.641,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.832 | Acc: 48.799,69.518,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.839 | Acc: 48.792,69.412,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.843 | Acc: 48.725,69.347,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.001 | Acc: 42.188,60.156,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.294 | Acc: 42.746,59.003,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.334 | Acc: 41.711,58.822,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.360 | Acc: 41.201,58.478,67.687,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 1.677 | Acc: 55.469,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.763 | Acc: 51.451,71.057,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.798 | Acc: 50.286,70.408,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.802 | Acc: 50.205,70.492,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.798 | Acc: 49.817,70.245,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.798 | Acc: 49.722,70.196,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.795 | Acc: 49.471,70.209,91.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.796 | Acc: 49.379,70.157,91.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.800 | Acc: 49.078,70.041,91.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.802 | Acc: 49.115,70.045,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.804 | Acc: 49.024,69.994,91.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.809 | Acc: 49.014,69.786,91.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.814 | Acc: 48.882,69.638,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.819 | Acc: 48.755,69.513,91.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.819 | Acc: 48.729,69.592,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.820 | Acc: 48.778,69.617,91.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.823 | Acc: 48.805,69.599,91.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.826 | Acc: 48.816,69.593,91.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.828 | Acc: 48.821,69.549,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.831 | Acc: 48.790,69.492,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.949 | Acc: 46.094,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.240 | Acc: 43.452,60.640,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.257 | Acc: 43.102,59.451,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.256 | Acc: 42.713,59.221,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 1.672 | Acc: 46.875,76.562,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.712 | Acc: 49.665,72.396,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.719 | Acc: 50.534,71.837,92.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.722 | Acc: 50.102,71.632,92.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.735 | Acc: 50.077,71.354,92.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.750 | Acc: 49.613,70.993,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.757 | Acc: 49.522,70.726,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.765 | Acc: 49.490,70.434,92.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.772 | Acc: 49.549,70.439,91.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.777 | Acc: 49.620,70.382,91.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.783 | Acc: 49.572,70.394,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.789 | Acc: 49.491,70.281,91.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.801 | Acc: 49.374,70.157,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.801 | Acc: 49.374,70.196,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.808 | Acc: 49.260,70.121,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.816 | Acc: 49.149,69.988,91.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.819 | Acc: 49.102,69.857,91.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.826 | Acc: 49.033,69.744,91.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.830 | Acc: 49.069,69.739,90.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.837 | Acc: 48.962,69.675,90.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.282 | Acc: 42.188,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.511 | Acc: 38.616,55.766,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.570 | Acc: 38.281,55.888,64.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.549 | Acc: 38.550,56.135,64.793,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 1.825 | Acc: 46.094,72.656,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.803 | Acc: 49.405,70.164,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.792 | Acc: 50.000,70.503,91.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.779 | Acc: 49.834,70.569,91.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.796 | Acc: 49.778,70.399,91.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.790 | Acc: 49.544,70.467,91.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.794 | Acc: 49.664,70.325,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.785 | Acc: 50.050,70.457,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.789 | Acc: 49.918,70.390,91.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.795 | Acc: 49.801,70.157,91.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.796 | Acc: 49.506,70.285,91.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.799 | Acc: 49.555,70.231,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.805 | Acc: 49.436,70.128,91.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.805 | Acc: 49.455,70.229,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.808 | Acc: 49.430,70.137,91.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.815 | Acc: 49.349,70.032,91.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.820 | Acc: 49.236,69.957,91.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.826 | Acc: 49.159,69.879,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.831 | Acc: 49.106,69.774,90.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.835 | Acc: 49.075,69.699,90.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.229 | Acc: 38.281,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.470 | Acc: 39.732,56.101,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.481 | Acc: 40.130,56.307,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.485 | Acc: 39.869,56.122,66.688,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 1.707 | Acc: 48.438,71.875,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.788 | Acc: 49.293,70.722,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.784 | Acc: 48.952,70.655,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.777 | Acc: 49.308,70.812,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.773 | Acc: 49.161,71.055,92.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.778 | Acc: 49.041,70.722,92.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.785 | Acc: 48.754,70.551,91.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.789 | Acc: 48.831,70.490,91.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.794 | Acc: 48.976,70.429,91.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.793 | Acc: 49.150,70.446,91.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.788 | Acc: 49.184,70.565,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.798 | Acc: 49.109,70.419,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.796 | Acc: 49.089,70.494,91.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.799 | Acc: 49.060,70.318,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.803 | Acc: 49.052,70.168,91.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.805 | Acc: 49.141,70.136,91.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.809 | Acc: 49.136,70.016,91.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.811 | Acc: 49.152,70.042,91.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.818 | Acc: 49.037,69.927,91.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.823 | Acc: 48.981,69.818,91.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.050 | Acc: 41.406,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.289 | Acc: 42.374,59.189,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.308 | Acc: 42.607,59.146,67.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.358 | Acc: 42.341,58.581,66.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 1.784 | Acc: 42.188,73.438,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.792 | Acc: 49.665,70.387,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.763 | Acc: 49.257,70.522,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.771 | Acc: 49.372,70.466,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.770 | Acc: 49.460,70.554,92.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.775 | Acc: 49.319,70.421,92.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.783 | Acc: 49.103,70.364,92.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.778 | Acc: 49.047,70.445,92.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.779 | Acc: 48.986,70.380,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.783 | Acc: 48.943,70.304,92.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.784 | Acc: 48.997,70.312,91.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.785 | Acc: 49.099,70.298,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.787 | Acc: 49.241,70.287,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.790 | Acc: 49.312,70.214,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.794 | Acc: 49.305,70.115,91.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.802 | Acc: 49.302,70.027,91.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.808 | Acc: 49.338,69.904,91.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.813 | Acc: 49.239,69.781,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.818 | Acc: 49.115,69.694,91.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.822 | Acc: 49.102,69.650,91.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.343 | Acc: 45.312,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.309 | Acc: 41.741,58.222,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.340 | Acc: 40.796,57.450,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.361 | Acc: 40.727,57.569,66.970,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 1.636 | Acc: 53.906,71.094,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.799 | Acc: 48.624,70.164,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.779 | Acc: 48.914,70.427,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.772 | Acc: 49.193,70.466,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.768 | Acc: 49.344,70.332,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.770 | Acc: 49.343,70.637,91.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.770 | Acc: 49.516,70.467,91.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.775 | Acc: 49.291,70.296,91.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.778 | Acc: 49.272,70.293,91.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.774 | Acc: 49.422,70.485,91.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.778 | Acc: 49.448,70.433,91.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.784 | Acc: 49.335,70.291,91.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.790 | Acc: 49.300,70.196,91.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.792 | Acc: 49.195,70.184,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.797 | Acc: 49.124,70.101,91.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.802 | Acc: 49.076,70.043,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.809 | Acc: 49.005,69.928,91.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.814 | Acc: 48.974,69.841,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.817 | Acc: 48.989,69.843,91.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.820 | Acc: 48.909,69.792,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.174 | Acc: 44.531,64.062,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.364 | Acc: 41.183,58.743,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.406 | Acc: 40.377,58.213,66.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.423 | Acc: 40.292,57.928,66.624,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 1.917 | Acc: 47.656,67.188,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.802 | Acc: 49.033,69.494,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.763 | Acc: 49.219,70.503,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.774 | Acc: 49.180,70.159,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.779 | Acc: 49.151,70.177,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.787 | Acc: 48.917,69.903,91.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.788 | Acc: 49.135,69.873,91.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.785 | Acc: 49.307,70.085,91.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.782 | Acc: 49.505,70.186,91.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.786 | Acc: 49.581,70.140,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.787 | Acc: 49.701,70.064,91.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.791 | Acc: 49.516,69.966,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.797 | Acc: 49.303,69.849,91.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.800 | Acc: 49.330,69.902,91.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.803 | Acc: 49.291,69.954,91.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.805 | Acc: 49.297,69.887,91.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.811 | Acc: 49.231,69.789,91.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.815 | Acc: 49.255,69.715,91.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.818 | Acc: 49.204,69.681,91.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.823 | Acc: 49.145,69.673,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.420 | Acc: 41.406,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.434 | Acc: 40.588,58.185,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.448 | Acc: 40.682,57.508,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.448 | Acc: 40.382,57.736,66.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 1.765 | Acc: 46.875,70.312,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.792 | Acc: 49.814,71.131,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.822 | Acc: 49.104,69.817,91.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.796 | Acc: 49.193,70.210,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.797 | Acc: 49.228,70.062,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.794 | Acc: 49.126,70.096,92.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.780 | Acc: 49.232,70.409,92.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.785 | Acc: 49.296,70.373,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.791 | Acc: 49.389,70.351,91.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.796 | Acc: 49.271,70.334,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.797 | Acc: 49.188,70.417,91.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.798 | Acc: 49.169,70.436,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.798 | Acc: 49.212,70.458,91.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.800 | Acc: 49.246,70.453,91.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.804 | Acc: 49.266,70.326,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.805 | Acc: 49.255,70.393,91.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.811 | Acc: 49.180,70.295,91.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.813 | Acc: 49.139,70.241,91.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.817 | Acc: 49.154,70.172,91.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.821 | Acc: 49.167,70.109,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.059 | Acc: 42.188,57.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.512 | Acc: 40.960,55.692,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.548 | Acc: 39.787,56.117,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.569 | Acc: 39.165,55.661,65.996,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 1.909 | Acc: 43.750,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.718 | Acc: 50.112,70.833,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.736 | Acc: 49.581,70.351,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.727 | Acc: 49.821,70.850,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.733 | Acc: 49.662,70.843,92.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.738 | Acc: 49.590,70.808,92.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.742 | Acc: 49.690,70.842,92.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.747 | Acc: 49.712,70.839,92.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.749 | Acc: 49.801,70.885,92.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.742 | Acc: 49.940,70.994,92.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.749 | Acc: 49.872,70.892,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.747 | Acc: 49.784,70.832,92.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.756 | Acc: 49.621,70.721,92.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.768 | Acc: 49.407,70.462,92.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.771 | Acc: 49.466,70.432,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.775 | Acc: 49.452,70.362,91.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.781 | Acc: 49.416,70.283,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.790 | Acc: 49.370,70.164,91.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.796 | Acc: 49.292,70.072,91.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.800 | Acc: 49.319,69.995,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.281 | Acc: 40.625,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.325 | Acc: 40.997,58.705,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.359 | Acc: 40.625,58.937,68.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.370 | Acc: 40.215,58.568,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 1.492 | Acc: 56.250,74.219,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.698 | Acc: 48.847,72.210,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.726 | Acc: 49.581,72.161,92.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.723 | Acc: 49.372,71.773,92.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.746 | Acc: 49.267,71.402,92.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.745 | Acc: 49.590,71.140,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.751 | Acc: 49.600,70.874,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.754 | Acc: 49.723,70.867,92.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.761 | Acc: 49.636,70.652,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.765 | Acc: 49.620,70.602,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.772 | Acc: 49.506,70.371,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.781 | Acc: 49.427,70.221,91.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.786 | Acc: 49.426,70.073,91.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.795 | Acc: 49.306,69.864,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.804 | Acc: 49.205,69.773,91.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.811 | Acc: 49.175,69.721,91.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.820 | Acc: 49.121,69.624,91.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.825 | Acc: 49.157,69.593,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.829 | Acc: 49.113,69.494,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.830 | Acc: 49.065,69.517,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.284 | Acc: 40.625,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.296 | Acc: 39.807,59.933,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.317 | Acc: 40.225,59.794,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.332 | Acc: 39.946,59.977,67.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 1.643 | Acc: 52.344,71.094,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.711 | Acc: 50.298,71.466,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.732 | Acc: 50.133,71.380,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.744 | Acc: 49.910,71.222,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.742 | Acc: 50.347,71.238,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.751 | Acc: 50.085,71.140,92.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.750 | Acc: 49.974,71.165,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.750 | Acc: 49.812,71.055,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.752 | Acc: 49.622,70.885,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.761 | Acc: 49.348,70.757,91.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.765 | Acc: 49.343,70.744,91.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.770 | Acc: 49.350,70.701,91.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.780 | Acc: 49.186,70.549,91.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.786 | Acc: 49.114,70.477,91.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.795 | Acc: 49.046,70.318,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.800 | Acc: 48.957,70.206,91.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.803 | Acc: 49.044,70.203,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.807 | Acc: 49.001,70.150,91.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.809 | Acc: 49.015,70.144,91.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.810 | Acc: 49.042,70.138,91.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.933 | Acc: 44.531,62.500,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.318 | Acc: 41.704,59.859,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.418 | Acc: 42.168,58.822,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.408 | Acc: 42.123,58.427,66.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 1.600 | Acc: 51.562,71.875,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.772 | Acc: 49.591,71.168,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.759 | Acc: 51.029,71.246,91.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.763 | Acc: 50.269,71.363,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.748 | Acc: 50.656,71.508,91.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.752 | Acc: 50.456,71.403,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.761 | Acc: 50.136,71.087,91.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.763 | Acc: 49.884,70.883,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.778 | Acc: 49.646,70.531,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.774 | Acc: 49.564,70.584,91.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.775 | Acc: 49.553,70.433,91.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.787 | Acc: 49.332,70.182,91.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.787 | Acc: 49.222,70.183,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.789 | Acc: 49.249,70.115,91.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.790 | Acc: 49.302,70.210,91.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.792 | Acc: 49.426,70.209,91.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.794 | Acc: 49.504,70.140,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.798 | Acc: 49.473,70.090,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.804 | Acc: 49.431,69.979,91.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.810 | Acc: 49.375,69.865,91.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.130 | Acc: 43.750,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.281 | Acc: 41.629,59.077,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.322 | Acc: 42.226,58.765,67.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.323 | Acc: 42.059,58.811,68.020,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 1.631 | Acc: 52.344,71.875,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.735 | Acc: 50.856,72.693,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.771 | Acc: 49.733,71.361,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.760 | Acc: 49.552,71.107,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.742 | Acc: 49.691,71.653,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.737 | Acc: 49.714,71.705,92.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.727 | Acc: 49.755,72.024,92.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.742 | Acc: 49.734,71.592,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.756 | Acc: 49.500,71.409,92.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.756 | Acc: 49.521,71.379,91.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.760 | Acc: 49.471,71.257,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.761 | Acc: 49.502,71.143,91.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.766 | Acc: 49.514,70.971,91.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.772 | Acc: 49.383,70.824,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.777 | Acc: 49.438,70.685,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.786 | Acc: 49.395,70.523,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.793 | Acc: 49.211,70.356,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.796 | Acc: 49.194,70.290,91.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.804 | Acc: 49.188,70.142,91.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.812 | Acc: 49.081,70.042,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.124 | Acc: 40.625,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.281 | Acc: 42.113,59.077,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.333 | Acc: 41.349,58.575,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.327 | Acc: 41.457,58.350,68.455,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 1.646 | Acc: 51.562,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.719 | Acc: 50.744,72.507,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 50.648,72.447,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.718 | Acc: 50.359,72.246,91.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.731 | Acc: 50.328,72.386,91.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.735 | Acc: 50.286,72.169,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.739 | Acc: 50.006,71.810,91.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.754 | Acc: 49.789,71.565,91.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.762 | Acc: 49.646,71.327,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.770 | Acc: 49.715,71.094,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.780 | Acc: 49.553,70.794,91.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.785 | Acc: 49.360,70.680,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.788 | Acc: 49.455,70.536,91.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.795 | Acc: 49.312,70.366,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.792 | Acc: 49.422,70.454,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.798 | Acc: 49.421,70.440,91.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.799 | Acc: 49.479,70.388,91.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.798 | Acc: 49.450,70.420,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.803 | Acc: 49.359,70.395,91.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.809 | Acc: 49.286,70.241,91.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.132 | Acc: 49.219,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.330 | Acc: 43.229,60.342,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.343 | Acc: 43.312,59.756,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.345 | Acc: 43.327,59.503,66.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 1.935 | Acc: 45.312,69.531,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.711 | Acc: 50.893,72.247,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.732 | Acc: 50.229,71.875,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.745 | Acc: 49.949,71.401,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.735 | Acc: 50.029,71.595,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.730 | Acc: 50.278,71.597,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.725 | Acc: 50.278,71.655,92.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.729 | Acc: 50.183,71.570,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.739 | Acc: 50.000,71.293,92.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.740 | Acc: 49.922,71.305,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.751 | Acc: 49.872,71.133,92.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.753 | Acc: 49.763,71.157,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.757 | Acc: 49.880,70.996,91.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.762 | Acc: 49.877,70.785,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.768 | Acc: 49.755,70.688,91.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.776 | Acc: 49.639,70.463,91.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.778 | Acc: 49.596,70.383,91.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.779 | Acc: 49.643,70.351,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.785 | Acc: 49.498,70.274,91.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.792 | Acc: 49.461,70.161,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.140 | Acc: 49.219,60.156,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.360 | Acc: 43.080,58.185,66.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.364 | Acc: 43.636,57.603,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.365 | Acc: 43.635,57.390,66.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 1.726 | Acc: 52.344,70.312,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.734 | Acc: 48.177,71.317,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.740 | Acc: 49.047,71.227,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.723 | Acc: 49.424,71.529,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.720 | Acc: 49.846,71.856,91.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.735 | Acc: 49.575,71.651,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.740 | Acc: 49.684,71.378,92.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.748 | Acc: 49.413,71.238,92.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.758 | Acc: 49.340,71.264,91.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.766 | Acc: 49.258,71.111,91.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.771 | Acc: 49.273,71.102,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.778 | Acc: 49.275,71.020,91.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.787 | Acc: 49.216,70.838,91.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.789 | Acc: 49.237,70.729,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.793 | Acc: 49.260,70.679,91.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.802 | Acc: 49.229,70.494,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.807 | Acc: 49.253,70.398,91.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.810 | Acc: 49.189,70.331,90.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.812 | Acc: 49.199,70.165,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.814 | Acc: 49.211,70.179,90.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.230 | Acc: 45.312,57.812,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.394 | Acc: 42.039,56.436,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.386 | Acc: 42.378,56.764,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.371 | Acc: 42.162,57.211,67.444,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 1.740 | Acc: 50.000,71.094,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.784 | Acc: 48.921,71.949,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.764 | Acc: 50.114,71.113,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.751 | Acc: 50.000,71.260,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.747 | Acc: 50.318,71.200,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.752 | Acc: 50.433,71.086,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.757 | Acc: 50.136,70.887,92.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.758 | Acc: 50.078,70.800,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.755 | Acc: 50.126,70.943,92.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.756 | Acc: 50.013,70.904,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.759 | Acc: 49.841,70.721,92.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.759 | Acc: 49.887,70.783,92.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.765 | Acc: 49.799,70.734,91.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.767 | Acc: 49.886,70.678,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.774 | Acc: 49.819,70.529,91.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.782 | Acc: 49.753,70.427,91.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.786 | Acc: 49.681,70.337,91.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.791 | Acc: 49.629,70.219,91.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.793 | Acc: 49.610,70.217,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.792 | Acc: 49.643,70.230,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.178 | Acc: 48.438,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.333 | Acc: 42.374,58.594,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.374 | Acc: 42.530,58.841,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.352 | Acc: 42.136,58.543,67.405,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 1.640 | Acc: 53.906,71.875,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.711 | Acc: 50.372,71.168,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.729 | Acc: 49.657,70.827,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.732 | Acc: 49.552,71.094,92.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.742 | Acc: 49.392,70.824,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.748 | Acc: 49.513,70.784,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.751 | Acc: 49.264,70.726,92.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.750 | Acc: 49.191,70.750,92.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.756 | Acc: 49.228,70.769,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.755 | Acc: 49.525,70.835,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.754 | Acc: 49.576,70.907,92.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.755 | Acc: 49.650,70.942,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.762 | Acc: 49.540,70.825,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.765 | Acc: 49.572,70.827,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.773 | Acc: 49.494,70.710,91.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.775 | Acc: 49.445,70.738,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.781 | Acc: 49.421,70.663,91.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.786 | Acc: 49.439,70.606,91.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.792 | Acc: 49.411,70.585,91.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.797 | Acc: 49.405,70.468,91.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.180 | Acc: 42.969,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.402 | Acc: 39.807,58.259,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.462 | Acc: 39.672,57.698,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.451 | Acc: 39.127,57.787,66.457,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 1.864 | Acc: 50.000,64.844,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.748 | Acc: 51.190,71.577,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.745 | Acc: 51.086,71.380,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.744 | Acc: 50.666,71.376,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.742 | Acc: 50.521,71.393,91.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.749 | Acc: 50.178,71.163,92.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.751 | Acc: 50.129,71.216,91.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.752 | Acc: 50.000,71.171,91.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.755 | Acc: 50.000,71.254,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.758 | Acc: 49.974,71.279,91.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.761 | Acc: 49.891,71.203,91.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.761 | Acc: 49.890,71.161,91.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.763 | Acc: 49.916,71.084,91.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.765 | Acc: 49.895,70.980,91.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.770 | Acc: 49.911,70.921,91.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.774 | Acc: 49.761,70.808,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.780 | Acc: 49.723,70.709,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.784 | Acc: 49.709,70.592,91.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.793 | Acc: 49.515,70.377,91.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.798 | Acc: 49.584,70.304,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.315 | Acc: 41.406,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.412 | Acc: 40.960,59.524,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.433 | Acc: 40.473,58.689,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.425 | Acc: 40.561,58.210,66.137,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 1.773 | Acc: 45.312,70.312,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.800 | Acc: 51.823,69.792,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.787 | Acc: 50.743,70.179,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.773 | Acc: 50.756,70.402,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.769 | Acc: 50.569,70.245,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.768 | Acc: 50.688,70.359,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.764 | Acc: 50.646,70.603,91.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.772 | Acc: 50.432,70.396,91.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.783 | Acc: 50.451,70.351,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.781 | Acc: 50.393,70.356,91.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.789 | Acc: 50.346,70.231,91.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.793 | Acc: 50.187,70.171,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.796 | Acc: 50.068,70.160,91.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.797 | Acc: 50.012,70.136,91.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.800 | Acc: 49.825,70.115,91.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.801 | Acc: 49.922,70.094,90.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.806 | Acc: 49.830,70.091,90.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.810 | Acc: 49.785,70.060,90.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.811 | Acc: 49.742,70.061,90.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.816 | Acc: 49.649,70.009,90.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.145 | Acc: 50.781,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.369 | Acc: 43.043,58.147,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.386 | Acc: 43.140,57.527,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.408 | Acc: 42.789,57.313,66.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 1.804 | Acc: 46.094,70.312,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.715 | Acc: 50.967,72.805,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.727 | Acc: 50.724,72.104,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.753 | Acc: 49.846,71.350,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.750 | Acc: 50.029,71.354,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.754 | Acc: 49.869,71.434,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.751 | Acc: 50.058,71.216,91.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.763 | Acc: 49.817,71.000,91.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.764 | Acc: 49.825,71.084,91.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.768 | Acc: 49.888,70.865,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.770 | Acc: 49.775,70.798,91.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.776 | Acc: 49.643,70.786,91.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.776 | Acc: 49.718,70.766,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.781 | Acc: 49.653,70.651,91.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.780 | Acc: 49.725,70.727,91.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.781 | Acc: 49.696,70.640,91.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.779 | Acc: 49.701,70.746,91.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.784 | Acc: 49.688,70.704,91.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.786 | Acc: 49.610,70.676,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.788 | Acc: 49.608,70.587,91.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.018 | Acc: 43.750,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.461 | Acc: 42.150,56.473,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.447 | Acc: 42.035,57.050,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.440 | Acc: 41.752,57.300,67.392,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 1.621 | Acc: 57.031,71.875,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.746 | Acc: 50.670,72.247,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.708 | Acc: 50.915,72.885,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.697 | Acc: 50.909,73.079,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.698 | Acc: 50.714,72.907,92.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.701 | Acc: 50.596,72.656,92.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.711 | Acc: 50.620,72.172,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.716 | Acc: 50.537,71.836,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.723 | Acc: 50.611,71.686,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.734 | Acc: 50.483,71.512,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.736 | Acc: 50.400,71.471,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.745 | Acc: 50.258,71.278,92.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.753 | Acc: 50.065,71.113,91.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.761 | Acc: 49.937,70.839,91.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.758 | Acc: 50.053,70.907,91.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.761 | Acc: 50.039,70.808,91.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.767 | Acc: 50.034,70.738,91.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.775 | Acc: 49.934,70.661,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.780 | Acc: 49.950,70.624,91.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.788 | Acc: 49.834,70.491,91.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.935 | Acc: 43.750,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.398 | Acc: 41.815,57.812,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.355 | Acc: 42.054,58.251,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.371 | Acc: 41.457,58.286,67.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 1.503 | Acc: 53.125,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.719 | Acc: 51.228,71.949,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 51.143,72.561,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.727 | Acc: 50.666,71.913,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.732 | Acc: 50.694,71.904,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.740 | Acc: 50.642,71.566,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.748 | Acc: 50.620,71.572,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.756 | Acc: 50.449,71.321,91.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.756 | Acc: 50.369,71.341,91.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.764 | Acc: 50.285,71.076,91.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.763 | Acc: 50.361,71.067,91.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.769 | Acc: 50.247,71.023,91.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.772 | Acc: 50.175,70.902,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.775 | Acc: 50.114,70.890,91.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.777 | Acc: 50.111,70.841,91.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.784 | Acc: 50.096,70.663,91.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.791 | Acc: 49.949,70.575,91.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.794 | Acc: 49.895,70.505,90.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.796 | Acc: 49.861,70.399,90.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.799 | Acc: 49.807,70.325,90.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.930 | Acc: 46.875,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.312 | Acc: 43.266,58.519,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.297 | Acc: 43.102,59.070,68.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.329 | Acc: 42.828,58.863,67.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 1.505 | Acc: 58.594,73.438,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.717 | Acc: 51.376,71.875,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 51.543,72.008,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.707 | Acc: 51.268,72.093,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.721 | Acc: 50.704,71.576,92.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.721 | Acc: 50.665,71.689,92.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.737 | Acc: 50.297,71.094,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.737 | Acc: 50.299,71.110,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.745 | Acc: 50.034,71.026,92.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.748 | Acc: 49.974,70.956,92.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.750 | Acc: 49.841,70.962,92.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.756 | Acc: 49.919,70.966,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.764 | Acc: 49.841,70.815,91.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.771 | Acc: 49.823,70.741,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.777 | Acc: 49.786,70.641,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.782 | Acc: 49.779,70.598,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.786 | Acc: 49.849,70.558,91.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.792 | Acc: 49.737,70.404,91.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.794 | Acc: 49.740,70.427,91.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.794 | Acc: 49.772,70.477,91.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.732 | Acc: 46.875,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.287 | Acc: 42.634,60.491,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.289 | Acc: 42.264,60.480,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.296 | Acc: 41.675,60.361,66.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 1.761 | Acc: 47.656,72.656,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.691 | Acc: 50.595,73.624,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.680 | Acc: 50.953,73.495,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.673 | Acc: 50.845,73.309,93.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.684 | Acc: 50.858,72.704,93.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.686 | Acc: 51.013,72.672,92.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.711 | Acc: 50.529,72.120,92.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.713 | Acc: 50.521,72.086,92.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.723 | Acc: 50.378,71.928,92.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.736 | Acc: 50.358,71.720,92.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.744 | Acc: 50.117,71.479,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.746 | Acc: 50.166,71.405,91.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.750 | Acc: 50.237,71.253,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.756 | Acc: 50.269,71.049,91.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.759 | Acc: 50.170,70.988,91.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.763 | Acc: 49.971,70.951,91.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.761 | Acc: 50.073,71.057,91.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.767 | Acc: 49.986,70.972,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.770 | Acc: 49.959,70.815,91.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.771 | Acc: 49.990,70.768,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.051 | Acc: 41.406,58.594,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.329 | Acc: 42.560,57.552,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.384 | Acc: 42.492,57.489,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.373 | Acc: 42.213,57.608,68.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 1.626 | Acc: 51.562,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.747 | Acc: 49.888,72.173,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.718 | Acc: 51.315,72.485,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.720 | Acc: 51.012,72.170,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.729 | Acc: 50.743,71.644,92.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.735 | Acc: 50.511,71.519,92.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.734 | Acc: 50.568,71.358,92.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.738 | Acc: 50.676,71.321,92.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.746 | Acc: 50.393,71.186,91.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.748 | Acc: 50.440,71.163,91.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.748 | Acc: 50.396,71.171,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.749 | Acc: 50.382,71.069,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.750 | Acc: 50.289,71.181,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.750 | Acc: 50.365,71.178,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.756 | Acc: 50.331,71.033,91.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.761 | Acc: 50.249,71.052,91.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.764 | Acc: 50.231,70.945,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.772 | Acc: 50.154,70.819,91.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.778 | Acc: 50.212,70.750,91.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.785 | Acc: 50.078,70.620,91.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.152 | Acc: 50.000,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.312 | Acc: 43.266,58.557,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.353 | Acc: 42.188,58.498,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.353 | Acc: 42.175,58.555,67.354,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 1.848 | Acc: 47.656,60.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.765 | Acc: 50.484,70.387,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.745 | Acc: 50.114,71.208,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.734 | Acc: 50.077,71.286,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.742 | Acc: 49.923,71.181,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.737 | Acc: 50.093,71.272,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.729 | Acc: 50.207,71.513,92.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.730 | Acc: 50.277,71.504,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.734 | Acc: 50.082,71.298,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.737 | Acc: 50.022,71.150,92.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.739 | Acc: 49.992,71.179,92.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.738 | Acc: 49.986,71.147,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.737 | Acc: 50.084,71.113,92.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.742 | Acc: 50.006,71.049,92.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.750 | Acc: 49.914,70.910,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.755 | Acc: 49.987,70.881,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.765 | Acc: 49.852,70.743,91.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.772 | Acc: 49.879,70.636,91.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.777 | Acc: 49.916,70.598,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.781 | Acc: 49.873,70.548,91.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.308 | Acc: 39.062,55.469,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.488 | Acc: 41.109,55.357,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.532 | Acc: 40.739,55.164,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.531 | Acc: 40.446,54.944,66.688,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 1.644 | Acc: 53.125,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.810 | Acc: 49.591,70.908,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.774 | Acc: 49.733,71.056,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.754 | Acc: 50.141,70.953,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.745 | Acc: 50.289,70.910,92.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.726 | Acc: 50.735,71.171,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.727 | Acc: 50.652,71.410,92.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.729 | Acc: 50.532,71.465,92.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.725 | Acc: 50.621,71.511,92.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.727 | Acc: 50.583,71.530,92.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.739 | Acc: 50.428,71.358,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.745 | Acc: 50.385,71.274,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.749 | Acc: 50.344,71.253,92.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.755 | Acc: 50.278,71.127,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.758 | Acc: 50.339,71.052,91.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.762 | Acc: 50.205,71.013,91.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.766 | Acc: 50.190,70.984,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.772 | Acc: 50.094,70.917,91.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.777 | Acc: 49.976,70.830,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.780 | Acc: 49.920,70.825,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.100 | Acc: 39.844,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.374 | Acc: 41.481,59.561,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.364 | Acc: 40.873,58.765,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.379 | Acc: 40.548,58.325,68.033,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 1.901 | Acc: 42.188,69.531,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.789 | Acc: 48.326,70.833,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.776 | Acc: 49.809,71.761,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.748 | Acc: 50.243,72.144,91.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.749 | Acc: 50.106,71.663,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.736 | Acc: 50.541,71.720,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.746 | Acc: 50.452,71.765,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.742 | Acc: 50.488,71.858,92.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.746 | Acc: 50.218,71.681,92.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.743 | Acc: 50.043,71.737,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.744 | Acc: 50.019,71.778,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.749 | Acc: 50.014,71.553,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.751 | Acc: 50.032,71.544,91.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.753 | Acc: 50.051,71.486,91.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.759 | Acc: 50.047,71.402,91.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.765 | Acc: 49.925,71.255,91.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.767 | Acc: 49.963,71.218,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.771 | Acc: 49.989,71.133,91.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.778 | Acc: 49.877,70.977,91.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.782 | Acc: 49.856,70.975,91.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.096 | Acc: 49.219,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.353 | Acc: 42.969,57.701,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.336 | Acc: 43.255,57.812,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.351 | Acc: 42.969,57.966,67.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 1.515 | Acc: 51.562,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.692 | Acc: 50.446,71.131,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.686 | Acc: 50.305,72.008,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.706 | Acc: 50.141,71.926,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.705 | Acc: 50.058,71.991,92.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.701 | Acc: 50.108,72.146,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.705 | Acc: 50.232,72.140,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.719 | Acc: 50.066,71.886,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.720 | Acc: 50.180,71.681,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.719 | Acc: 50.194,71.672,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.728 | Acc: 50.144,71.498,92.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.732 | Acc: 50.018,71.377,92.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.731 | Acc: 50.133,71.379,92.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.733 | Acc: 50.102,71.396,92.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.738 | Acc: 50.150,71.366,92.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.741 | Acc: 50.156,71.327,92.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.747 | Acc: 50.041,71.213,92.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.750 | Acc: 49.998,71.135,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.753 | Acc: 49.976,71.100,91.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.755 | Acc: 49.947,71.042,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.242 | Acc: 45.312,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.371 | Acc: 41.406,56.994,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.463 | Acc: 41.311,56.917,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.460 | Acc: 41.278,56.685,66.765,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 1.796 | Acc: 51.562,68.750,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.742 | Acc: 49.851,71.205,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.751 | Acc: 49.829,71.208,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.744 | Acc: 49.936,71.619,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.742 | Acc: 50.386,71.393,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.732 | Acc: 50.511,71.713,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.735 | Acc: 50.381,71.578,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.735 | Acc: 50.305,71.493,91.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.745 | Acc: 50.228,71.283,91.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.747 | Acc: 50.017,71.323,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.743 | Acc: 50.140,71.339,91.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.737 | Acc: 50.315,71.408,91.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.741 | Acc: 50.366,71.295,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.747 | Acc: 50.317,71.207,91.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.752 | Acc: 50.278,71.085,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.755 | Acc: 50.254,70.987,91.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.765 | Acc: 50.129,70.816,91.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.773 | Acc: 50.041,70.713,91.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.778 | Acc: 49.933,70.663,91.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.783 | Acc: 49.918,70.604,91.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.248 | Acc: 45.312,57.812,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.289 | Acc: 44.122,58.817,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.353 | Acc: 44.207,58.079,66.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.359 | Acc: 43.379,58.030,66.368,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 1.721 | Acc: 48.438,71.094,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.737 | Acc: 50.856,71.615,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.728 | Acc: 51.334,72.123,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.709 | Acc: 51.089,72.157,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.704 | Acc: 51.196,72.367,92.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.707 | Acc: 50.967,72.169,92.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.706 | Acc: 51.027,72.024,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.713 | Acc: 50.892,71.947,92.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.715 | Acc: 50.878,71.953,92.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.723 | Acc: 50.712,71.651,92.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.728 | Acc: 50.637,71.603,92.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.731 | Acc: 50.608,71.461,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.740 | Acc: 50.480,71.262,91.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.746 | Acc: 50.332,70.992,91.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.750 | Acc: 50.289,70.871,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.758 | Acc: 50.244,70.689,91.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.762 | Acc: 50.234,70.612,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.768 | Acc: 50.199,70.562,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.777 | Acc: 50.197,70.501,91.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.785 | Acc: 50.045,70.440,91.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.250 | Acc: 46.094,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.330 | Acc: 41.815,58.891,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.334 | Acc: 42.092,58.975,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.330 | Acc: 41.765,59.144,67.354,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 1.785 | Acc: 48.438,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.727 | Acc: 49.665,71.243,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.697 | Acc: 50.514,71.913,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.695 | Acc: 51.076,72.272,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.683 | Acc: 50.965,72.531,92.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.693 | Acc: 51.075,72.509,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.705 | Acc: 50.923,72.243,92.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.710 | Acc: 50.837,72.235,92.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.719 | Acc: 50.568,71.812,92.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.721 | Acc: 50.432,71.819,92.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.731 | Acc: 50.354,71.521,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.734 | Acc: 50.311,71.518,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.737 | Acc: 50.344,71.499,92.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.737 | Acc: 50.422,71.507,92.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.740 | Acc: 50.439,71.419,91.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.749 | Acc: 50.309,71.255,91.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.748 | Acc: 50.343,71.186,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.753 | Acc: 50.369,71.121,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.757 | Acc: 50.299,71.059,91.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.761 | Acc: 50.285,70.999,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.124 | Acc: 42.188,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.321 | Acc: 42.857,59.859,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.358 | Acc: 42.416,59.204,67.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.384 | Acc: 42.123,58.696,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 2.012 | Acc: 40.625,65.625,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.713 | Acc: 51.562,71.503,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.665 | Acc: 51.810,72.732,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.678 | Acc: 51.614,72.618,92.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 51.032,72.261,92.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.692 | Acc: 51.098,72.254,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.696 | Acc: 50.904,72.133,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.696 | Acc: 50.792,72.086,92.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.696 | Acc: 50.864,71.996,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.710 | Acc: 50.591,71.633,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.718 | Acc: 50.455,71.463,92.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.728 | Acc: 50.332,71.306,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.742 | Acc: 50.201,71.168,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.747 | Acc: 50.189,71.121,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.751 | Acc: 50.122,71.052,91.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.752 | Acc: 50.151,71.016,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.758 | Acc: 50.032,70.904,91.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.760 | Acc: 50.034,70.862,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.765 | Acc: 50.017,70.765,91.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.769 | Acc: 49.967,70.682,91.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.316 | Acc: 44.531,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.364 | Acc: 42.188,57.626,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.366 | Acc: 42.835,57.851,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.359 | Acc: 42.431,58.325,66.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 1.458 | Acc: 62.500,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.703 | Acc: 51.265,72.098,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.698 | Acc: 50.877,72.199,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.712 | Acc: 50.589,71.388,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.714 | Acc: 50.849,71.499,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.718 | Acc: 50.495,71.481,92.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.720 | Acc: 50.588,71.333,92.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.720 | Acc: 50.504,71.543,92.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.723 | Acc: 50.505,71.550,92.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.728 | Acc: 50.419,71.478,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.733 | Acc: 50.253,71.393,92.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.741 | Acc: 50.230,71.327,92.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.745 | Acc: 50.292,71.236,91.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.754 | Acc: 50.314,71.103,91.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.757 | Acc: 50.303,71.055,91.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.759 | Acc: 50.397,71.029,91.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.764 | Acc: 50.350,71.013,91.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.770 | Acc: 50.156,70.897,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.776 | Acc: 50.084,70.765,91.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.778 | Acc: 50.039,70.770,91.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.325 | Acc: 47.656,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.407 | Acc: 41.220,57.738,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.429 | Acc: 40.987,58.194,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.425 | Acc: 41.086,57.595,66.406,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 1.923 | Acc: 57.812,67.969,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.750 | Acc: 48.810,70.908,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.722 | Acc: 50.076,71.551,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.726 | Acc: 50.000,71.644,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.725 | Acc: 49.942,71.779,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.721 | Acc: 50.085,71.937,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.721 | Acc: 50.052,71.991,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.720 | Acc: 50.127,72.008,92.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.726 | Acc: 50.112,71.841,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.727 | Acc: 50.380,71.793,92.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.727 | Acc: 50.466,71.894,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.735 | Acc: 50.399,71.705,91.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.739 | Acc: 50.350,71.635,91.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.749 | Acc: 50.239,71.468,91.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.757 | Acc: 50.100,71.213,91.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.757 | Acc: 50.174,71.231,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.760 | Acc: 50.119,71.133,91.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.763 | Acc: 50.099,71.050,91.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.767 | Acc: 50.052,70.968,91.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.769 | Acc: 50.062,70.946,91.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.841 | Acc: 46.094,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.231 | Acc: 42.411,60.342,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.195 | Acc: 42.626,60.556,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.220 | Acc: 42.149,60.233,68.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 1.646 | Acc: 48.438,77.344,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.736 | Acc: 50.521,71.949,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.716 | Acc: 50.819,72.008,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.704 | Acc: 50.973,72.131,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.703 | Acc: 50.801,72.290,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.708 | Acc: 51.044,72.239,91.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.723 | Acc: 50.910,71.978,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.734 | Acc: 50.576,71.709,91.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.746 | Acc: 50.451,71.409,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.748 | Acc: 50.255,71.452,91.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.742 | Acc: 50.420,71.545,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.750 | Acc: 50.346,71.504,91.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.755 | Acc: 50.379,71.327,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.760 | Acc: 50.305,71.163,91.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.767 | Acc: 50.197,70.932,91.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.774 | Acc: 50.179,70.793,91.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.775 | Acc: 50.187,70.828,91.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.776 | Acc: 50.296,70.853,91.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.780 | Acc: 50.268,70.821,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.785 | Acc: 50.113,70.757,90.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.367 | Acc: 41.406,60.938,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.482 | Acc: 42.597,56.920,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.473 | Acc: 41.806,57.374,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.480 | Acc: 41.342,57.198,66.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 1.635 | Acc: 52.344,71.875,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.754 | Acc: 49.963,72.173,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.753 | Acc: 49.676,71.361,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.730 | Acc: 50.205,71.644,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.732 | Acc: 50.203,71.740,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.736 | Acc: 50.224,71.890,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.732 | Acc: 50.265,71.746,92.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.737 | Acc: 50.283,71.653,91.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.734 | Acc: 50.306,71.725,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.736 | Acc: 50.285,71.711,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.744 | Acc: 50.288,71.560,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.750 | Acc: 50.198,71.366,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.750 | Acc: 50.230,71.301,91.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.750 | Acc: 50.236,71.297,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.760 | Acc: 50.017,71.110,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.760 | Acc: 50.101,71.156,91.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.767 | Acc: 50.071,70.945,91.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.771 | Acc: 49.989,70.853,91.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.775 | Acc: 49.933,70.782,91.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.781 | Acc: 49.895,70.729,91.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.249 | Acc: 48.438,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.387 | Acc: 41.146,58.705,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.401 | Acc: 41.635,58.060,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.398 | Acc: 41.752,58.235,67.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 1.874 | Acc: 43.750,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.773 | Acc: 49.256,71.317,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.728 | Acc: 49.809,72.027,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.725 | Acc: 49.693,71.683,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.715 | Acc: 50.174,71.769,92.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.716 | Acc: 50.449,71.890,92.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.715 | Acc: 50.194,71.739,92.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.711 | Acc: 50.410,71.659,92.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.714 | Acc: 50.277,71.623,92.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.715 | Acc: 50.440,71.672,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.716 | Acc: 50.610,71.696,92.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.724 | Acc: 50.530,71.645,92.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.727 | Acc: 50.425,71.645,92.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.738 | Acc: 50.353,71.459,92.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.742 | Acc: 50.336,71.386,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.745 | Acc: 50.335,71.301,92.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.747 | Acc: 50.294,71.323,91.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.747 | Acc: 50.378,71.318,91.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.751 | Acc: 50.340,71.258,91.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.754 | Acc: 50.334,71.190,91.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.969 | Acc: 42.969,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.329 | Acc: 40.365,59.487,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.348 | Acc: 40.511,59.566,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.352 | Acc: 40.561,59.106,67.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 1.587 | Acc: 52.344,72.656,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.709 | Acc: 50.967,72.991,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.703 | Acc: 50.724,72.580,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.691 | Acc: 50.832,72.592,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 50.868,72.396,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.698 | Acc: 50.789,72.169,92.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.700 | Acc: 50.910,72.101,92.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.706 | Acc: 50.798,72.041,92.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.713 | Acc: 50.636,71.870,92.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.719 | Acc: 50.449,71.741,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.721 | Acc: 50.307,71.716,92.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.725 | Acc: 50.364,71.553,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.727 | Acc: 50.379,71.512,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.727 | Acc: 50.605,71.468,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.724 | Acc: 50.573,71.447,92.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.731 | Acc: 50.433,71.296,92.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.738 | Acc: 50.350,71.147,91.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.745 | Acc: 50.344,71.085,91.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.753 | Acc: 50.290,70.966,91.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.757 | Acc: 50.252,70.934,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.038 | Acc: 40.625,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.285 | Acc: 44.420,59.821,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.308 | Acc: 43.674,58.613,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.310 | Acc: 43.584,58.478,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 1.666 | Acc: 46.875,71.094,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.743 | Acc: 50.484,71.429,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.724 | Acc: 50.857,72.104,92.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.714 | Acc: 51.101,72.503,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.699 | Acc: 51.283,72.521,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.704 | Acc: 51.098,72.200,92.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.707 | Acc: 51.014,72.075,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.706 | Acc: 50.798,72.135,92.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.709 | Acc: 50.820,71.894,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.710 | Acc: 50.820,71.905,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.714 | Acc: 50.886,71.891,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.719 | Acc: 50.852,71.748,92.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.728 | Acc: 50.674,71.625,92.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.732 | Acc: 50.590,71.570,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.735 | Acc: 50.559,71.494,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.741 | Acc: 50.542,71.452,91.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.748 | Acc: 50.489,71.315,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.752 | Acc: 50.481,71.325,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.755 | Acc: 50.361,71.258,91.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.758 | Acc: 50.371,71.227,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.298 | Acc: 48.438,64.062,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.410 | Acc: 43.378,58.445,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.408 | Acc: 42.912,58.060,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.404 | Acc: 42.853,58.491,66.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 1.837 | Acc: 52.344,68.750,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.726 | Acc: 51.265,71.801,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.718 | Acc: 51.220,71.532,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.723 | Acc: 50.884,71.516,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.715 | Acc: 50.723,71.711,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.717 | Acc: 50.743,71.674,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.718 | Acc: 50.736,71.572,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.723 | Acc: 50.443,71.293,92.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.722 | Acc: 50.568,71.293,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.725 | Acc: 50.557,71.206,92.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.728 | Acc: 50.525,71.222,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.733 | Acc: 50.452,71.267,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.736 | Acc: 50.470,71.233,91.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.745 | Acc: 50.368,71.166,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.751 | Acc: 50.361,71.052,91.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.755 | Acc: 50.309,70.951,91.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.759 | Acc: 50.316,70.931,91.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.763 | Acc: 50.218,70.899,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.764 | Acc: 50.249,70.936,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.767 | Acc: 50.293,70.842,91.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.108 | Acc: 45.312,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.235 | Acc: 44.457,58.891,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.234 | Acc: 43.426,59.299,68.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.238 | Acc: 43.276,59.516,68.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 1.736 | Acc: 46.094,72.656,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.619 | Acc: 53.199,74.702,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.660 | Acc: 52.248,73.399,92.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.671 | Acc: 51.806,73.092,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.680 | Acc: 51.235,72.704,92.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.696 | Acc: 51.338,72.409,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.698 | Acc: 51.143,72.295,92.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.704 | Acc: 51.014,72.069,92.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.716 | Acc: 50.772,71.865,92.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.718 | Acc: 50.889,71.905,92.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.718 | Acc: 51.057,71.824,92.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.719 | Acc: 50.933,71.847,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.722 | Acc: 50.875,71.830,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.726 | Acc: 50.781,71.686,92.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.734 | Acc: 50.581,71.541,91.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.734 | Acc: 50.620,71.462,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.741 | Acc: 50.582,71.327,91.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.746 | Acc: 50.605,71.245,91.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.749 | Acc: 50.524,71.172,91.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.752 | Acc: 50.570,71.163,91.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.589 | Acc: 42.188,60.156,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.595 | Acc: 38.988,57.366,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.602 | Acc: 38.739,56.631,65.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.582 | Acc: 38.973,56.609,65.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 1.627 | Acc: 53.125,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.759 | Acc: 49.628,71.354,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.748 | Acc: 50.076,71.704,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.724 | Acc: 50.717,71.734,92.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.726 | Acc: 50.463,71.730,92.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.726 | Acc: 50.441,71.960,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.729 | Acc: 50.342,71.920,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.729 | Acc: 50.460,71.881,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.728 | Acc: 50.568,71.924,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.734 | Acc: 50.401,71.832,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.735 | Acc: 50.249,71.828,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.734 | Acc: 50.421,71.801,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.736 | Acc: 50.428,71.736,91.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.740 | Acc: 50.458,71.594,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.746 | Acc: 50.348,71.469,91.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.751 | Acc: 50.298,71.333,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.756 | Acc: 50.282,71.245,91.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.761 | Acc: 50.261,71.137,91.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.765 | Acc: 50.249,71.079,91.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.767 | Acc: 50.260,71.006,91.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.001 | Acc: 48.438,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.320 | Acc: 43.080,58.296,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.295 | Acc: 42.416,58.727,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.297 | Acc: 42.431,58.594,68.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 1.714 | Acc: 51.562,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.657 | Acc: 51.376,72.917,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.671 | Acc: 51.048,73.323,92.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.692 | Acc: 50.948,72.567,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.701 | Acc: 50.791,72.348,92.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.704 | Acc: 50.920,72.231,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.697 | Acc: 51.046,72.340,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.703 | Acc: 51.058,72.019,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.709 | Acc: 50.946,71.822,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.718 | Acc: 50.924,71.689,92.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.728 | Acc: 50.661,71.510,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.734 | Acc: 50.506,71.415,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.739 | Acc: 50.480,71.492,91.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.743 | Acc: 50.431,71.393,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.748 | Acc: 50.353,71.311,91.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.752 | Acc: 50.324,71.224,91.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.756 | Acc: 50.282,71.176,91.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.758 | Acc: 50.332,71.185,91.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.757 | Acc: 50.416,71.161,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.759 | Acc: 50.412,71.090,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.168 | Acc: 50.781,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.341 | Acc: 43.936,59.003,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.352 | Acc: 42.530,58.022,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.341 | Acc: 42.559,57.953,66.931,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 1.770 | Acc: 49.219,66.406,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.722 | Acc: 50.856,71.094,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.723 | Acc: 51.086,71.475,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.686 | Acc: 52.049,72.259,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.699 | Acc: 51.640,72.135,92.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.693 | Acc: 51.709,72.200,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.694 | Acc: 51.517,72.475,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.695 | Acc: 51.485,72.401,92.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.696 | Acc: 51.310,72.482,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.705 | Acc: 51.083,72.186,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.708 | Acc: 51.201,72.042,92.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.715 | Acc: 51.018,71.886,91.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.724 | Acc: 50.924,71.693,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.730 | Acc: 50.850,71.633,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.739 | Acc: 50.812,71.644,91.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.742 | Acc: 50.729,71.561,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.749 | Acc: 50.686,71.556,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.755 | Acc: 50.632,71.453,91.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.754 | Acc: 50.669,71.453,91.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.757 | Acc: 50.658,71.371,91.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.357 | Acc: 38.281,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.636 | Acc: 39.844,57.552,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.587 | Acc: 40.758,57.165,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.574 | Acc: 40.702,57.172,66.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 1.784 | Acc: 46.094,71.875,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.745 | Acc: 50.856,71.131,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.737 | Acc: 51.658,71.932,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.732 | Acc: 51.524,71.798,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.740 | Acc: 50.598,71.586,91.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.736 | Acc: 50.565,71.836,91.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.737 | Acc: 50.794,71.791,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.740 | Acc: 50.759,71.703,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.740 | Acc: 50.757,71.710,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.745 | Acc: 50.678,71.551,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.743 | Acc: 50.727,71.549,91.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.751 | Acc: 50.516,71.405,91.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.754 | Acc: 50.327,71.304,91.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.751 | Acc: 50.329,71.378,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.754 | Acc: 50.242,71.297,91.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.757 | Acc: 50.327,71.252,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.765 | Acc: 50.287,71.101,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.766 | Acc: 50.302,71.080,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.771 | Acc: 50.288,70.970,91.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.770 | Acc: 50.285,71.040,91.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.905 | Acc: 46.094,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.284 | Acc: 43.676,60.045,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.259 | Acc: 44.474,59.909,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.249 | Acc: 43.852,59.631,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 1.425 | Acc: 53.906,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.650 | Acc: 53.199,73.140,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.684 | Acc: 52.096,72.485,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.708 | Acc: 51.306,71.965,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.721 | Acc: 50.839,71.730,92.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.712 | Acc: 51.176,71.798,92.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.710 | Acc: 51.136,71.849,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.715 | Acc: 51.003,71.714,92.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.722 | Acc: 50.941,71.642,92.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.729 | Acc: 50.803,71.465,92.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.736 | Acc: 50.789,71.381,92.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.737 | Acc: 50.831,71.412,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.741 | Acc: 50.888,71.360,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.742 | Acc: 50.835,71.190,91.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.744 | Acc: 50.778,71.155,91.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.746 | Acc: 50.680,71.169,91.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.750 | Acc: 50.684,71.145,91.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.755 | Acc: 50.623,71.091,91.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.758 | Acc: 50.530,71.063,91.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.759 | Acc: 50.607,71.061,91.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.209 | Acc: 41.406,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.396 | Acc: 43.043,59.412,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.399 | Acc: 42.664,58.822,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.384 | Acc: 42.546,58.402,66.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 1.629 | Acc: 56.250,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.621 | Acc: 53.051,73.884,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.563 | Acc: 52.744,74.771,94.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.551 | Acc: 52.830,74.898,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.527 | Acc: 53.135,75.444,94.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.513 | Acc: 53.287,75.758,95.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.498 | Acc: 53.299,76.156,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 53.280,76.424,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.475 | Acc: 53.489,76.781,95.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.465 | Acc: 53.699,77.076,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.460 | Acc: 53.801,77.149,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.449 | Acc: 54.026,77.414,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.442 | Acc: 54.104,77.561,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.435 | Acc: 54.155,77.676,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.429 | Acc: 54.204,77.866,96.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.425 | Acc: 54.327,77.961,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.422 | Acc: 54.378,77.950,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.416 | Acc: 54.477,78.077,96.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.411 | Acc: 54.616,78.214,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.405 | Acc: 54.628,78.338,96.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.518 | Acc: 53.906,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.670 | Acc: 49.554,67.634,73.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.680 | Acc: 49.505,67.397,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.673 | Acc: 49.180,66.995,73.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 1.144 | Acc: 64.062,85.938,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.293 | Acc: 57.329,81.176,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.277 | Acc: 56.669,81.326,98.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.275 | Acc: 56.749,81.237,98.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.287 | Acc: 56.366,81.047,98.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.277 | Acc: 56.691,81.505,98.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.279 | Acc: 56.437,81.386,98.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.285 | Acc: 56.261,81.172,98.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.287 | Acc: 56.201,81.129,98.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.285 | Acc: 56.220,81.073,98.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.282 | Acc: 56.328,81.137,98.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.279 | Acc: 56.363,81.250,98.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.277 | Acc: 56.467,81.334,98.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.280 | Acc: 56.477,81.277,98.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.282 | Acc: 56.378,81.231,98.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.284 | Acc: 56.268,81.167,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.284 | Acc: 56.172,81.111,98.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.284 | Acc: 56.053,81.076,98.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.283 | Acc: 56.075,81.077,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.282 | Acc: 56.031,81.127,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.441 | Acc: 50.781,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.641 | Acc: 50.856,67.560,73.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.651 | Acc: 50.457,67.683,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.641 | Acc: 50.064,67.687,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.551 | Acc: 48.438,77.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.239 | Acc: 57.180,82.515,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.236 | Acc: 57.279,82.698,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.252 | Acc: 56.442,82.031,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.242 | Acc: 56.732,82.118,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.234 | Acc: 56.776,82.248,98.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.233 | Acc: 56.612,82.341,98.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.236 | Acc: 56.582,82.236,98.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.244 | Acc: 56.347,81.852,98.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.247 | Acc: 56.358,81.824,98.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.247 | Acc: 56.328,81.767,98.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.248 | Acc: 56.360,81.717,98.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.250 | Acc: 56.256,81.636,98.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.250 | Acc: 56.244,81.648,98.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.248 | Acc: 56.294,81.681,98.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.248 | Acc: 56.284,81.709,98.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.247 | Acc: 56.335,81.802,98.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.245 | Acc: 56.353,81.850,98.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.244 | Acc: 56.397,81.865,98.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.244 | Acc: 56.385,81.873,98.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.358 | Acc: 53.906,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.610 | Acc: 51.376,68.080,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.620 | Acc: 50.534,68.102,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.611 | Acc: 50.141,67.930,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.185 | Acc: 55.469,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.223 | Acc: 55.915,81.771,98.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.232 | Acc: 55.621,82.069,99.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.233 | Acc: 55.494,82.377,99.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.232 | Acc: 55.777,82.542,99.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.236 | Acc: 55.933,82.449,98.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.228 | Acc: 56.192,82.619,98.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.223 | Acc: 56.117,82.807,98.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.221 | Acc: 56.134,82.745,98.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.222 | Acc: 56.207,82.623,98.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.218 | Acc: 56.273,82.653,98.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.222 | Acc: 56.140,82.473,98.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.224 | Acc: 56.133,82.456,98.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.221 | Acc: 56.307,82.507,98.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.221 | Acc: 56.392,82.484,98.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.222 | Acc: 56.414,82.483,98.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.221 | Acc: 56.474,82.520,98.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.220 | Acc: 56.468,82.467,98.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.221 | Acc: 56.451,82.475,98.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.220 | Acc: 56.455,82.462,98.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.345 | Acc: 52.344,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.620 | Acc: 50.930,68.787,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.625 | Acc: 50.514,68.941,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.616 | Acc: 50.256,68.571,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.230 | Acc: 55.469,82.031,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.191 | Acc: 57.701,82.961,98.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.219 | Acc: 57.203,82.336,98.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.209 | Acc: 57.031,82.441,98.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.204 | Acc: 56.838,82.639,98.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.208 | Acc: 56.559,82.503,99.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.206 | Acc: 56.702,82.632,99.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.207 | Acc: 56.638,82.685,99.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.212 | Acc: 56.454,82.502,99.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.208 | Acc: 56.656,82.648,99.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.205 | Acc: 56.786,82.766,99.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.206 | Acc: 56.784,82.728,99.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.202 | Acc: 56.905,82.884,99.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.203 | Acc: 56.849,82.869,99.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.201 | Acc: 56.848,82.932,99.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.202 | Acc: 56.772,82.916,99.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.201 | Acc: 56.829,82.946,99.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.199 | Acc: 56.896,82.957,99.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.200 | Acc: 56.806,82.953,99.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.199 | Acc: 56.775,82.985,99.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.339 | Acc: 53.125,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.614 | Acc: 51.302,68.676,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.629 | Acc: 50.724,68.407,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.622 | Acc: 50.371,68.225,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.147 | Acc: 58.594,82.812,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.172 | Acc: 56.882,83.743,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.174 | Acc: 57.431,83.975,99.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.178 | Acc: 57.556,83.530,99.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.183 | Acc: 57.407,83.372,99.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.177 | Acc: 57.596,83.439,99.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.178 | Acc: 57.645,83.342,99.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.173 | Acc: 57.812,83.577,99.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.174 | Acc: 57.701,83.545,99.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.179 | Acc: 57.523,83.417,99.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.181 | Acc: 57.459,83.349,99.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.180 | Acc: 57.342,83.399,99.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.183 | Acc: 57.213,83.412,99.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.182 | Acc: 57.157,83.369,99.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.181 | Acc: 57.159,83.449,99.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.184 | Acc: 57.070,83.345,99.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.186 | Acc: 57.068,83.326,99.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.185 | Acc: 57.125,83.317,99.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.185 | Acc: 57.109,83.319,99.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.185 | Acc: 57.142,83.301,99.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.352 | Acc: 53.906,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.595 | Acc: 51.079,68.564,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.612 | Acc: 50.648,68.350,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.607 | Acc: 50.320,68.225,75.218,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.079 | Acc: 60.938,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.133 | Acc: 58.259,85.045,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.140 | Acc: 57.603,84.794,99.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.161 | Acc: 57.006,84.298,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.160 | Acc: 57.504,84.288,99.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.161 | Acc: 57.519,84.267,99.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.166 | Acc: 57.348,84.168,99.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.163 | Acc: 57.281,84.142,99.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.160 | Acc: 57.162,84.132,99.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.159 | Acc: 57.355,84.077,99.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.160 | Acc: 57.323,84.083,99.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.160 | Acc: 57.431,83.983,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.162 | Acc: 57.300,83.908,99.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.162 | Acc: 57.268,83.872,99.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.163 | Acc: 57.240,83.869,99.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.164 | Acc: 57.231,83.838,99.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.169 | Acc: 57.082,83.625,99.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.166 | Acc: 57.194,83.688,99.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.168 | Acc: 57.137,83.657,99.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.169 | Acc: 57.117,83.594,99.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.329 | Acc: 50.781,68.750,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.605 | Acc: 51.079,68.415,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.619 | Acc: 50.629,68.178,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.608 | Acc: 50.231,68.186,75.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.153 | Acc: 57.812,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.134 | Acc: 58.296,85.379,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.137 | Acc: 58.575,85.118,99.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.139 | Acc: 58.235,84.862,99.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.139 | Acc: 58.083,84.549,99.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.142 | Acc: 58.045,84.460,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.148 | Acc: 57.690,84.214,99.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.153 | Acc: 57.447,84.092,99.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.153 | Acc: 57.332,84.147,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.152 | Acc: 57.398,84.133,99.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.155 | Acc: 57.334,84.033,99.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.155 | Acc: 57.491,84.046,99.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.154 | Acc: 57.495,84.044,99.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.154 | Acc: 57.453,84.061,99.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.154 | Acc: 57.318,84.116,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.156 | Acc: 57.304,83.999,99.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.156 | Acc: 57.362,83.971,99.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.156 | Acc: 57.350,83.921,99.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.156 | Acc: 57.358,83.890,99.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.156 | Acc: 57.349,83.895,99.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.314 | Acc: 50.781,71.094,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.605 | Acc: 51.265,68.415,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.614 | Acc: 50.877,68.216,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.610 | Acc: 50.307,68.212,75.295,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.148 | Acc: 54.688,83.594,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.155 | Acc: 56.659,84.189,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.152 | Acc: 56.898,84.242,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.160 | Acc: 57.070,83.978,99.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.150 | Acc: 57.186,84.250,99.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.149 | Acc: 57.356,84.174,99.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.150 | Acc: 57.315,84.052,99.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.147 | Acc: 57.458,84.148,99.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.144 | Acc: 57.604,84.225,99.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.144 | Acc: 57.683,84.168,99.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.148 | Acc: 57.591,84.099,99.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.149 | Acc: 57.508,84.131,99.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.147 | Acc: 57.537,84.226,99.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.148 | Acc: 57.393,84.133,99.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.152 | Acc: 57.254,84.052,99.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.151 | Acc: 57.267,84.134,99.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.150 | Acc: 57.404,84.144,99.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.150 | Acc: 57.361,84.144,99.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.150 | Acc: 57.419,84.152,99.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.151 | Acc: 57.333,84.176,99.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.334 | Acc: 55.469,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.604 | Acc: 51.674,68.341,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.616 | Acc: 51.086,68.369,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.613 | Acc: 50.679,68.186,75.269,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 0.918 | Acc: 59.375,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.107 | Acc: 57.924,85.565,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.117 | Acc: 57.622,85.385,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.120 | Acc: 57.710,85.156,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.116 | Acc: 57.938,85.301,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.121 | Acc: 57.983,85.032,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.126 | Acc: 57.935,85.014,99.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.133 | Acc: 57.790,84.746,99.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.132 | Acc: 57.997,84.739,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.133 | Acc: 57.942,84.694,99.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.136 | Acc: 57.859,84.519,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.133 | Acc: 57.880,84.580,99.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.137 | Acc: 57.741,84.453,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.136 | Acc: 57.720,84.486,99.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.138 | Acc: 57.671,84.450,99.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.138 | Acc: 57.665,84.359,99.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.140 | Acc: 57.581,84.297,99.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.140 | Acc: 57.519,84.293,99.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.141 | Acc: 57.540,84.271,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.141 | Acc: 57.566,84.297,99.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.288 | Acc: 53.125,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.601 | Acc: 50.967,68.341,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.621 | Acc: 50.667,68.197,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.614 | Acc: 50.269,68.186,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.050 | Acc: 58.594,83.594,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.099 | Acc: 58.966,85.751,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.113 | Acc: 58.308,85.213,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.119 | Acc: 58.017,84.682,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.119 | Acc: 58.102,84.462,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.119 | Acc: 58.184,84.708,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.126 | Acc: 57.903,84.607,99.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.128 | Acc: 57.901,84.624,99.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.124 | Acc: 58.031,84.715,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.121 | Acc: 58.054,84.845,99.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.124 | Acc: 57.937,84.736,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.124 | Acc: 57.965,84.750,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.125 | Acc: 57.968,84.800,99.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.125 | Acc: 58.010,84.782,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.128 | Acc: 57.910,84.792,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.127 | Acc: 57.934,84.868,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.126 | Acc: 57.993,84.886,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.126 | Acc: 58.014,84.836,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.128 | Acc: 57.938,84.760,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.130 | Acc: 57.880,84.715,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.244 | Acc: 51.562,71.875,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.586 | Acc: 51.562,68.973,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.610 | Acc: 50.991,68.807,75.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.610 | Acc: 50.410,68.327,75.640,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 0.951 | Acc: 64.844,85.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.130 | Acc: 57.738,84.970,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.112 | Acc: 58.613,85.271,99.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.119 | Acc: 58.402,84.900,99.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.118 | Acc: 58.372,84.857,99.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.112 | Acc: 58.687,84.963,99.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.114 | Acc: 58.704,85.027,99.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.119 | Acc: 58.505,84.929,99.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.115 | Acc: 58.400,85.011,99.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.115 | Acc: 58.564,85.083,99.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.117 | Acc: 58.396,84.939,99.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.118 | Acc: 58.360,85.001,99.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.118 | Acc: 58.292,85.001,99.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.119 | Acc: 58.172,84.968,99.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.122 | Acc: 58.071,84.939,99.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.124 | Acc: 58.002,84.894,99.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.124 | Acc: 57.961,84.837,99.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.124 | Acc: 57.906,84.815,99.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.124 | Acc: 57.903,84.849,99.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.124 | Acc: 57.907,84.804,99.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.275 | Acc: 50.781,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.610 | Acc: 51.042,68.899,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.616 | Acc: 50.800,68.502,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.604 | Acc: 50.435,68.327,75.410,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 0.969 | Acc: 57.031,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.096 | Acc: 59.449,85.603,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.100 | Acc: 58.727,85.423,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.106 | Acc: 58.145,85.451,99.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.110 | Acc: 58.015,85.455,99.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.113 | Acc: 58.029,85.311,99.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.120 | Acc: 57.948,85.066,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.118 | Acc: 58.123,85.051,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.113 | Acc: 58.089,85.137,99.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.113 | Acc: 58.076,85.204,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.111 | Acc: 58.026,85.215,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.113 | Acc: 57.901,85.167,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.109 | Acc: 57.984,85.208,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.110 | Acc: 58.067,85.165,99.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.111 | Acc: 58.038,85.103,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.110 | Acc: 58.054,85.110,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.110 | Acc: 57.971,85.105,99.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.112 | Acc: 57.925,85.115,99.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.111 | Acc: 57.999,85.143,99.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.111 | Acc: 57.991,85.142,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.342 | Acc: 53.906,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.622 | Acc: 51.004,68.452,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.637 | Acc: 50.686,68.407,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.627 | Acc: 50.512,68.545,75.653,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.119 | Acc: 59.375,81.250,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.101 | Acc: 59.115,85.528,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.106 | Acc: 58.365,85.309,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.095 | Acc: 58.466,85.489,99.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.099 | Acc: 58.459,85.532,99.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.104 | Acc: 58.230,85.473,99.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.108 | Acc: 58.064,85.402,99.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.104 | Acc: 58.167,85.467,99.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.107 | Acc: 57.992,85.481,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.107 | Acc: 57.851,85.398,99.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.106 | Acc: 57.871,85.316,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.109 | Acc: 57.834,85.354,99.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.109 | Acc: 57.777,85.351,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.107 | Acc: 57.923,85.423,99.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.108 | Acc: 57.913,85.351,99.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.108 | Acc: 57.875,85.379,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.107 | Acc: 57.978,85.314,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.105 | Acc: 58.012,85.353,99.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.105 | Acc: 58.020,85.316,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.107 | Acc: 57.958,85.255,99.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.371 | Acc: 52.344,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.606 | Acc: 51.004,68.601,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.624 | Acc: 50.705,68.579,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.622 | Acc: 50.384,68.263,75.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.107 | Acc: 59.375,82.031,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.092 | Acc: 59.040,85.640,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.101 | Acc: 58.594,85.023,99.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.088 | Acc: 58.927,85.348,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.092 | Acc: 58.613,85.571,99.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.099 | Acc: 58.532,85.667,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.096 | Acc: 58.632,85.653,99.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.100 | Acc: 58.306,85.660,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.102 | Acc: 58.220,85.583,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.103 | Acc: 58.218,85.480,99.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.102 | Acc: 58.170,85.467,99.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.103 | Acc: 58.039,85.446,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.102 | Acc: 58.069,85.497,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.099 | Acc: 58.130,85.548,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.103 | Acc: 58.096,85.484,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.103 | Acc: 58.056,85.426,99.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.103 | Acc: 58.141,85.414,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.102 | Acc: 58.131,85.456,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.103 | Acc: 58.102,85.422,99.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.103 | Acc: 58.091,85.425,99.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.335 | Acc: 51.562,73.438,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.619 | Acc: 51.823,68.638,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.633 | Acc: 51.353,68.636,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.627 | Acc: 50.832,68.609,75.359,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.227 | Acc: 53.906,82.812,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.103 | Acc: 57.589,85.603,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.096 | Acc: 58.155,86.071,99.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.105 | Acc: 57.966,85.592,99.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.108 | Acc: 57.870,85.330,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.108 | Acc: 57.843,85.319,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.107 | Acc: 57.851,85.415,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.111 | Acc: 57.907,85.256,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.105 | Acc: 58.210,85.423,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.101 | Acc: 58.192,85.540,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.100 | Acc: 58.131,85.452,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.100 | Acc: 58.148,85.428,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.101 | Acc: 58.166,85.438,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.104 | Acc: 58.031,85.369,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.100 | Acc: 58.149,85.465,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.098 | Acc: 58.199,85.525,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.096 | Acc: 58.265,85.609,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.096 | Acc: 58.268,85.601,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.095 | Acc: 58.317,85.663,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.094 | Acc: 58.372,85.669,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.320 | Acc: 54.688,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.618 | Acc: 51.823,68.936,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.627 | Acc: 51.010,68.750,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.616 | Acc: 50.602,68.468,75.346,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 0.960 | Acc: 61.719,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.055 | Acc: 59.784,86.793,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.069 | Acc: 59.127,86.395,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.072 | Acc: 59.170,86.539,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.076 | Acc: 58.700,86.516,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.081 | Acc: 58.485,86.317,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.087 | Acc: 58.226,86.247,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.092 | Acc: 58.228,86.082,99.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.096 | Acc: 57.890,85.923,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.097 | Acc: 57.726,85.795,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.097 | Acc: 57.921,85.759,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.096 | Acc: 58.046,85.711,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.095 | Acc: 58.104,85.792,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.093 | Acc: 58.229,85.749,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.094 | Acc: 58.224,85.723,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.093 | Acc: 58.272,85.732,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.092 | Acc: 58.299,85.772,99.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.094 | Acc: 58.195,85.763,99.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.092 | Acc: 58.224,85.786,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.092 | Acc: 58.262,85.790,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.288 | Acc: 54.688,71.875,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.607 | Acc: 51.562,68.601,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.624 | Acc: 51.162,68.274,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.614 | Acc: 50.743,68.058,75.666,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.113 | Acc: 57.031,84.375,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.088 | Acc: 57.664,85.565,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.068 | Acc: 58.308,86.261,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.064 | Acc: 58.747,86.142,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.066 | Acc: 58.690,86.208,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.073 | Acc: 58.455,86.131,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.070 | Acc: 58.587,86.099,99.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.069 | Acc: 58.688,86.165,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.071 | Acc: 58.662,86.073,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.071 | Acc: 58.646,86.054,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.073 | Acc: 58.586,86.062,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.075 | Acc: 58.622,86.040,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.077 | Acc: 58.587,86.035,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.080 | Acc: 58.537,86.042,99.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.080 | Acc: 58.505,86.021,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.079 | Acc: 58.518,86.062,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.080 | Acc: 58.557,86.013,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.082 | Acc: 58.470,85.940,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.082 | Acc: 58.466,85.953,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.085 | Acc: 58.370,85.860,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.278 | Acc: 53.125,72.656,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.623 | Acc: 51.339,68.006,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.637 | Acc: 50.819,67.969,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.625 | Acc: 50.615,67.969,75.359,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.081 | Acc: 58.594,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.062 | Acc: 59.115,87.091,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.060 | Acc: 58.803,87.176,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.060 | Acc: 58.876,87.334,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.060 | Acc: 58.816,87.037,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.055 | Acc: 59.089,87.121,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.055 | Acc: 58.942,87.067,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.061 | Acc: 58.766,86.758,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.066 | Acc: 58.618,86.573,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.068 | Acc: 58.438,86.568,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.070 | Acc: 58.497,86.454,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.070 | Acc: 58.512,86.447,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.070 | Acc: 58.626,86.362,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.071 | Acc: 58.630,86.330,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.071 | Acc: 58.574,86.335,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.072 | Acc: 58.508,86.301,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.072 | Acc: 58.440,86.295,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.075 | Acc: 58.392,86.212,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.076 | Acc: 58.390,86.184,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.076 | Acc: 58.403,86.151,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.301 | Acc: 52.344,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.629 | Acc: 51.525,68.118,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.640 | Acc: 51.010,68.178,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.627 | Acc: 50.666,68.161,75.423,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.022 | Acc: 51.562,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.070 | Acc: 58.296,87.165,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.062 | Acc: 58.899,87.119,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.075 | Acc: 58.568,86.949,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.082 | Acc: 58.391,86.593,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.082 | Acc: 58.416,86.417,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.076 | Acc: 58.542,86.596,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.078 | Acc: 58.494,86.547,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.076 | Acc: 58.565,86.534,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.075 | Acc: 58.581,86.494,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.073 | Acc: 58.706,86.478,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.073 | Acc: 58.732,86.411,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.073 | Acc: 58.759,86.450,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.073 | Acc: 58.767,86.464,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.072 | Acc: 58.680,86.469,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.073 | Acc: 58.666,86.358,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.073 | Acc: 58.720,86.329,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.073 | Acc: 58.717,86.338,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.073 | Acc: 58.661,86.340,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.072 | Acc: 58.622,86.325,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.290 | Acc: 53.906,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.622 | Acc: 52.158,68.192,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.640 | Acc: 51.334,68.064,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.633 | Acc: 50.871,67.853,75.333,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 1.104 | Acc: 59.375,85.938,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.044 | Acc: 59.673,87.537,99.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.044 | Acc: 59.299,87.005,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.054 | Acc: 58.978,86.885,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.052 | Acc: 59.008,86.757,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.054 | Acc: 58.694,86.827,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.060 | Acc: 58.549,86.648,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.064 | Acc: 58.439,86.469,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.064 | Acc: 58.356,86.442,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.067 | Acc: 58.240,86.386,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.065 | Acc: 58.197,86.427,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.062 | Acc: 58.339,86.546,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.061 | Acc: 58.406,86.544,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.063 | Acc: 58.378,86.467,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.060 | Acc: 58.483,86.482,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.063 | Acc: 58.396,86.444,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.065 | Acc: 58.380,86.376,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.064 | Acc: 58.543,86.375,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.066 | Acc: 58.444,86.357,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.065 | Acc: 58.512,86.411,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.310 | Acc: 53.125,71.875,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.636 | Acc: 51.935,68.713,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.649 | Acc: 51.486,68.331,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.641 | Acc: 51.101,68.148,75.589,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.063 | Acc: 61.719,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.031 | Acc: 60.789,88.021,99.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.039 | Acc: 59.737,87.919,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.040 | Acc: 59.311,87.615,99.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.047 | Acc: 59.057,87.269,99.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.052 | Acc: 58.841,87.090,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.049 | Acc: 59.233,87.235,99.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.052 | Acc: 59.087,87.051,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.055 | Acc: 58.924,86.869,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.053 | Acc: 58.948,86.870,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.052 | Acc: 59.037,86.940,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.051 | Acc: 59.021,86.952,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.053 | Acc: 58.950,86.868,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.056 | Acc: 58.857,86.779,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.058 | Acc: 58.747,86.727,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.059 | Acc: 58.796,86.662,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.059 | Acc: 58.784,86.673,99.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.060 | Acc: 58.807,86.659,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.061 | Acc: 58.808,86.639,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.062 | Acc: 58.754,86.643,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.381 | Acc: 51.562,68.750,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 51.414,68.304,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.637 | Acc: 50.991,68.216,75.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.631 | Acc: 50.487,68.007,75.551,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 1.200 | Acc: 58.594,83.594,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.068 | Acc: 58.036,86.347,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.054 | Acc: 58.251,86.890,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.047 | Acc: 59.042,86.962,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.054 | Acc: 58.912,86.912,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.049 | Acc: 59.011,87.036,99.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.045 | Acc: 59.155,87.184,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.042 | Acc: 59.231,87.223,99.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.044 | Acc: 59.356,87.136,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.046 | Acc: 59.284,87.150,99.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.049 | Acc: 59.181,87.049,99.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.052 | Acc: 58.919,86.991,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.054 | Acc: 58.837,86.881,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.054 | Acc: 58.821,86.895,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.052 | Acc: 58.830,86.913,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.055 | Acc: 58.765,86.846,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.056 | Acc: 58.732,86.814,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.055 | Acc: 58.736,86.810,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.057 | Acc: 58.693,86.790,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.059 | Acc: 58.645,86.729,99.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.363 | Acc: 53.125,71.875,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.646 | Acc: 51.897,68.229,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.642 | Acc: 51.181,68.388,75.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.636 | Acc: 50.897,68.161,75.487,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.069 | Acc: 55.469,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.031 | Acc: 60.379,87.463,99.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.028 | Acc: 60.595,87.957,99.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.037 | Acc: 59.849,87.615,99.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.044 | Acc: 59.462,87.201,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.042 | Acc: 59.731,87.322,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.043 | Acc: 59.659,87.216,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.045 | Acc: 59.552,87.151,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.039 | Acc: 59.763,87.180,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.044 | Acc: 59.591,86.969,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.042 | Acc: 59.694,87.014,99.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.044 | Acc: 59.513,86.864,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.047 | Acc: 59.333,86.806,99.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.049 | Acc: 59.174,86.818,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.053 | Acc: 58.997,86.733,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.053 | Acc: 58.991,86.776,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.052 | Acc: 59.059,86.777,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.053 | Acc: 59.139,86.696,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.054 | Acc: 59.066,86.667,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.054 | Acc: 58.940,86.678,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.449 | Acc: 50.781,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.655 | Acc: 51.451,68.043,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.650 | Acc: 51.143,68.274,75.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.649 | Acc: 50.961,68.199,75.781,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.000 | Acc: 56.250,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.035 | Acc: 59.524,87.612,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.030 | Acc: 59.394,87.919,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.038 | Acc: 58.747,87.590,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.045 | Acc: 58.613,87.220,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.047 | Acc: 58.756,86.951,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.045 | Acc: 58.865,87.054,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.041 | Acc: 59.159,87.162,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.046 | Acc: 58.992,87.068,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.050 | Acc: 58.741,87.086,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.054 | Acc: 58.648,86.960,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.050 | Acc: 58.799,87.016,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.048 | Acc: 58.928,87.121,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.048 | Acc: 58.908,87.006,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.047 | Acc: 59.019,86.966,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.044 | Acc: 59.051,87.038,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.045 | Acc: 59.007,86.960,99.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.045 | Acc: 59.041,86.934,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.047 | Acc: 58.977,86.885,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.048 | Acc: 59.045,86.885,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.260 | Acc: 53.125,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.615 | Acc: 51.860,68.824,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.624 | Acc: 51.200,68.807,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.625 | Acc: 50.679,68.404,75.845,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 0.987 | Acc: 60.156,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.051 | Acc: 58.296,87.612,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.042 | Acc: 59.032,87.500,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.026 | Acc: 59.477,87.782,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.030 | Acc: 59.385,87.683,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.038 | Acc: 58.926,87.570,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.041 | Acc: 58.755,87.416,99.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.044 | Acc: 58.771,87.339,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.046 | Acc: 58.671,87.354,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.043 | Acc: 58.784,87.362,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.044 | Acc: 58.722,87.236,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.043 | Acc: 58.778,87.150,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.044 | Acc: 58.733,87.085,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.043 | Acc: 58.770,87.123,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.044 | Acc: 58.763,87.089,99.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.044 | Acc: 58.856,87.072,99.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.045 | Acc: 58.896,87.077,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.044 | Acc: 58.914,87.085,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.045 | Acc: 58.918,87.043,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.044 | Acc: 58.961,87.067,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.330 | Acc: 52.344,71.094,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.640 | Acc: 51.935,68.601,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.650 | Acc: 51.315,68.445,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.636 | Acc: 50.986,68.391,75.576,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.066 | Acc: 55.469,85.938,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.024 | Acc: 60.193,87.128,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.032 | Acc: 60.118,87.081,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.038 | Acc: 59.964,87.001,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.045 | Acc: 59.346,87.085,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.042 | Acc: 59.004,87.299,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.040 | Acc: 59.039,87.377,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.038 | Acc: 59.076,87.395,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.039 | Acc: 59.142,87.359,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.037 | Acc: 59.133,87.444,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.039 | Acc: 59.021,87.383,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.039 | Acc: 58.983,87.334,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.037 | Acc: 59.067,87.383,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.036 | Acc: 59.070,87.425,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.036 | Acc: 59.036,87.472,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.036 | Acc: 59.022,87.373,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.035 | Acc: 59.037,87.386,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.036 | Acc: 59.045,87.374,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.038 | Acc: 58.962,87.320,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.039 | Acc: 58.971,87.311,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.353 | Acc: 50.781,70.312,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.633 | Acc: 52.009,68.899,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.643 | Acc: 51.505,68.426,75.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.637 | Acc: 51.114,68.315,75.602,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 0.782 | Acc: 68.750,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.012 | Acc: 59.970,87.798,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.027 | Acc: 59.642,87.729,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.030 | Acc: 59.785,87.577,99.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.035 | Acc: 59.587,87.529,99.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.035 | Acc: 59.274,87.469,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.034 | Acc: 59.220,87.545,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.040 | Acc: 58.932,87.361,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.037 | Acc: 59.011,87.408,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.038 | Acc: 58.974,87.392,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.040 | Acc: 59.076,87.310,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.038 | Acc: 59.251,87.344,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.037 | Acc: 59.326,87.338,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.040 | Acc: 59.228,87.293,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.040 | Acc: 59.255,87.300,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.040 | Acc: 59.193,87.230,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.042 | Acc: 59.010,87.213,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.042 | Acc: 59.077,87.202,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.042 | Acc: 58.988,87.173,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.044 | Acc: 58.955,87.086,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.351 | Acc: 51.562,71.875,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.672 | Acc: 51.190,67.932,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.680 | Acc: 50.896,67.854,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.666 | Acc: 50.717,67.777,75.269,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 0.943 | Acc: 66.406,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.006 | Acc: 60.342,88.021,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.008 | Acc: 60.252,88.053,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.014 | Acc: 59.862,88.153,99.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.014 | Acc: 60.002,88.040,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.022 | Acc: 59.537,87.887,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.020 | Acc: 59.892,87.791,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.019 | Acc: 59.807,87.799,99.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.022 | Acc: 59.720,87.704,99.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.020 | Acc: 59.681,87.794,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.021 | Acc: 59.585,87.745,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.025 | Acc: 59.432,87.709,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.027 | Acc: 59.453,87.617,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.030 | Acc: 59.345,87.593,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.031 | Acc: 59.308,87.575,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.031 | Acc: 59.282,87.570,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.033 | Acc: 59.258,87.573,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.034 | Acc: 59.176,87.505,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.034 | Acc: 59.228,87.442,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.034 | Acc: 59.227,87.379,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.406 | Acc: 51.562,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.662 | Acc: 51.860,68.713,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.673 | Acc: 51.734,68.159,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.662 | Acc: 51.370,67.943,75.359,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 0.865 | Acc: 68.750,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.015 | Acc: 60.193,87.835,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.023 | Acc: 59.737,87.214,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.024 | Acc: 59.298,87.513,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.020 | Acc: 59.269,87.722,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.029 | Acc: 58.911,87.446,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.029 | Acc: 59.175,87.468,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.027 | Acc: 59.198,87.472,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.024 | Acc: 59.152,87.684,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.022 | Acc: 59.293,87.690,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.021 | Acc: 59.091,87.830,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.019 | Acc: 59.322,87.832,99.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.020 | Acc: 59.404,87.772,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.021 | Acc: 59.351,87.787,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.024 | Acc: 59.186,87.706,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.023 | Acc: 59.271,87.721,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.023 | Acc: 59.273,87.636,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.027 | Acc: 59.139,87.571,99.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.028 | Acc: 59.117,87.530,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.029 | Acc: 59.086,87.512,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.329 | Acc: 53.906,69.531,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.644 | Acc: 51.637,67.708,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.664 | Acc: 51.200,67.245,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.653 | Acc: 50.986,67.098,75.333,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.054 | Acc: 58.594,84.375,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.018 | Acc: 58.854,87.574,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.021 | Acc: 58.994,87.481,99.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.025 | Acc: 58.876,87.423,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.018 | Acc: 59.221,87.703,99.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.017 | Acc: 59.166,87.825,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.015 | Acc: 59.381,87.849,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.018 | Acc: 59.558,87.760,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.020 | Acc: 59.525,87.796,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.020 | Acc: 59.526,87.664,99.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.023 | Acc: 59.476,87.706,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.023 | Acc: 59.428,87.730,99.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.023 | Acc: 59.599,87.750,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.021 | Acc: 59.710,87.739,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.023 | Acc: 59.611,87.645,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.023 | Acc: 59.663,87.588,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.024 | Acc: 59.572,87.624,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.026 | Acc: 59.405,87.601,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.028 | Acc: 59.336,87.528,99.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.028 | Acc: 59.361,87.564,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.394 | Acc: 50.781,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.667 | Acc: 51.451,68.601,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.677 | Acc: 51.372,68.274,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.664 | Acc: 51.140,68.097,75.461,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.028 | Acc: 54.688,86.719,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.981 | Acc: 61.086,89.137,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.001 | Acc: 60.423,88.034,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.017 | Acc: 59.810,87.923,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.019 | Acc: 59.510,87.645,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.018 | Acc: 59.568,87.693,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.018 | Acc: 59.420,87.649,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.019 | Acc: 59.148,87.699,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.017 | Acc: 59.356,87.650,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.017 | Acc: 59.427,87.642,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.019 | Acc: 59.317,87.562,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.019 | Acc: 59.269,87.610,99.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.023 | Acc: 59.119,87.643,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.024 | Acc: 59.204,87.704,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.024 | Acc: 59.158,87.753,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.024 | Acc: 59.227,87.705,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.024 | Acc: 59.248,87.704,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.025 | Acc: 59.212,87.665,99.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.026 | Acc: 59.245,87.645,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.027 | Acc: 59.242,87.535,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.442 | Acc: 51.562,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.647 | Acc: 50.372,68.043,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.659 | Acc: 50.743,67.854,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.652 | Acc: 50.564,67.802,75.346,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 1.140 | Acc: 54.688,83.594,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.047 | Acc: 58.705,88.132,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.034 | Acc: 59.604,87.900,99.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.035 | Acc: 59.183,87.948,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.022 | Acc: 59.491,88.223,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.020 | Acc: 59.700,88.127,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.028 | Acc: 59.317,87.836,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.027 | Acc: 59.314,87.877,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.026 | Acc: 59.166,87.878,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.023 | Acc: 59.211,87.923,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.024 | Acc: 59.227,87.955,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.023 | Acc: 59.251,87.903,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.021 | Acc: 59.268,87.967,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.024 | Acc: 59.189,87.886,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.023 | Acc: 59.286,87.814,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.022 | Acc: 59.240,87.806,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.021 | Acc: 59.300,87.848,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.020 | Acc: 59.311,87.848,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.021 | Acc: 59.314,87.825,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.021 | Acc: 59.340,87.781,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.434 | Acc: 50.000,68.750,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.642 | Acc: 51.414,68.304,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.659 | Acc: 51.296,68.464,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.647 | Acc: 51.101,68.263,75.602,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.051 | Acc: 55.469,84.375,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.009 | Acc: 60.007,87.984,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.012 | Acc: 59.794,88.034,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.004 | Acc: 59.874,88.358,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.002 | Acc: 60.224,88.291,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.008 | Acc: 59.576,88.181,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.010 | Acc: 59.491,88.249,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.014 | Acc: 59.220,88.209,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.011 | Acc: 59.448,88.189,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.010 | Acc: 59.548,88.229,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.015 | Acc: 59.336,88.145,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.017 | Acc: 59.202,88.104,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.018 | Acc: 59.236,88.002,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.017 | Acc: 59.414,88.030,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.016 | Acc: 59.378,88.031,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.016 | Acc: 59.414,88.009,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.016 | Acc: 59.460,87.948,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.015 | Acc: 59.476,87.924,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.014 | Acc: 59.492,87.948,99.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.014 | Acc: 59.463,87.953,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.470 | Acc: 51.562,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.652 | Acc: 51.600,68.043,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.657 | Acc: 51.391,67.950,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.646 | Acc: 51.242,67.815,75.371,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.024 | Acc: 62.500,85.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.001 | Acc: 61.272,88.653,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.014 | Acc: 60.309,88.243,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.014 | Acc: 59.939,88.371,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.017 | Acc: 60.127,88.233,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.017 | Acc: 59.847,88.351,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.010 | Acc: 59.814,88.481,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.011 | Acc: 59.807,88.353,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.010 | Acc: 59.778,88.359,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.010 | Acc: 59.845,88.324,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.014 | Acc: 59.740,88.227,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.013 | Acc: 59.725,88.221,99.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.014 | Acc: 59.586,88.210,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.014 | Acc: 59.602,88.108,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.014 | Acc: 59.620,88.073,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.013 | Acc: 59.679,88.094,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.013 | Acc: 59.708,88.084,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.015 | Acc: 59.636,88.087,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.017 | Acc: 59.581,88.052,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.017 | Acc: 59.529,88.072,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.489 | Acc: 52.344,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.650 | Acc: 51.525,68.155,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.668 | Acc: 51.258,68.064,75.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.663 | Acc: 51.025,67.982,75.282,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 0.864 | Acc: 61.719,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.948 | Acc: 61.942,88.728,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.964 | Acc: 61.033,88.910,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.981 | Acc: 60.566,88.614,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.988 | Acc: 60.253,88.445,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.986 | Acc: 60.226,88.622,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.995 | Acc: 60.195,88.346,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.998 | Acc: 60.189,88.209,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.003 | Acc: 59.904,88.077,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.001 | Acc: 59.738,88.109,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.005 | Acc: 59.701,88.099,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.004 | Acc: 59.817,88.143,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.007 | Acc: 59.683,88.080,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.009 | Acc: 59.522,88.075,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.011 | Acc: 59.386,88.012,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.011 | Acc: 59.372,88.027,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.013 | Acc: 59.329,88.006,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.012 | Acc: 59.478,87.999,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.012 | Acc: 59.462,88.043,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.013 | Acc: 59.459,88.058,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.442 | Acc: 51.562,67.188,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.654 | Acc: 51.749,68.638,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.676 | Acc: 51.372,68.293,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.668 | Acc: 51.255,68.046,75.448,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 0.933 | Acc: 58.594,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.988 | Acc: 60.305,88.765,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.979 | Acc: 60.347,88.777,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.988 | Acc: 60.156,88.486,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.987 | Acc: 59.992,88.619,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.987 | Acc: 59.769,88.846,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.990 | Acc: 59.724,88.765,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.993 | Acc: 59.907,88.569,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.995 | Acc: 59.885,88.524,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.999 | Acc: 59.712,88.432,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.999 | Acc: 59.729,88.495,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.998 | Acc: 59.743,88.617,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.997 | Acc: 59.864,88.628,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.998 | Acc: 59.758,88.581,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.000 | Acc: 59.725,88.520,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.000 | Acc: 59.712,88.440,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.003 | Acc: 59.565,88.401,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.005 | Acc: 59.579,88.380,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.006 | Acc: 59.646,88.361,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.007 | Acc: 59.521,88.292,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.437 | Acc: 52.344,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.674 | Acc: 51.711,67.932,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.677 | Acc: 51.239,68.083,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.674 | Acc: 51.037,67.841,75.269,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 0.929 | Acc: 59.375,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.987 | Acc: 61.310,89.174,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.974 | Acc: 61.471,89.253,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.982 | Acc: 60.861,89.011,99.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.999 | Acc: 60.012,88.378,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.993 | Acc: 59.963,88.606,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.994 | Acc: 60.072,88.559,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.996 | Acc: 60.129,88.641,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.995 | Acc: 60.147,88.504,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.000 | Acc: 59.932,88.402,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.003 | Acc: 59.923,88.375,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.004 | Acc: 59.820,88.334,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.003 | Acc: 59.884,88.382,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.006 | Acc: 59.743,88.281,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.006 | Acc: 59.703,88.240,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.007 | Acc: 59.715,88.211,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.008 | Acc: 59.713,88.208,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.006 | Acc: 59.684,88.247,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.004 | Acc: 59.773,88.279,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.006 | Acc: 59.689,88.214,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.432 | Acc: 53.906,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.648 | Acc: 52.567,67.783,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.657 | Acc: 51.734,67.873,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.655 | Acc: 51.460,67.879,75.435,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 0.935 | Acc: 61.719,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.983 | Acc: 59.970,87.984,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.988 | Acc: 59.718,88.415,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.996 | Acc: 59.618,88.576,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.997 | Acc: 59.462,88.368,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.996 | Acc: 59.460,88.312,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.993 | Acc: 59.775,88.572,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.988 | Acc: 60.029,88.702,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.989 | Acc: 59.996,88.718,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.988 | Acc: 59.988,88.743,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.986 | Acc: 60.090,88.755,99.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.989 | Acc: 60.029,88.638,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.992 | Acc: 59.923,88.563,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.993 | Acc: 59.818,88.572,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.998 | Acc: 59.742,88.484,99.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.004 | Acc: 59.588,88.323,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.003 | Acc: 59.645,88.286,99.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.004 | Acc: 59.668,88.274,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.005 | Acc: 59.604,88.283,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.005 | Acc: 59.574,88.248,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.469 | Acc: 52.344,67.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.674 | Acc: 51.637,68.118,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.682 | Acc: 51.372,67.988,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.680 | Acc: 51.332,67.853,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 0.886 | Acc: 63.281,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.979 | Acc: 59.338,90.104,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.978 | Acc: 60.080,89.844,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.985 | Acc: 59.708,89.421,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.995 | Acc: 59.414,89.198,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.982 | Acc: 60.071,89.558,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.983 | Acc: 60.182,89.392,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.986 | Acc: 60.090,89.373,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.988 | Acc: 60.103,89.242,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.989 | Acc: 60.057,89.170,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.990 | Acc: 60.012,89.047,99.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.988 | Acc: 60.089,88.978,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.987 | Acc: 59.975,89.017,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.990 | Acc: 59.953,88.976,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.992 | Acc: 59.942,88.926,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.993 | Acc: 59.868,88.899,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.996 | Acc: 59.747,88.802,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.997 | Acc: 59.709,88.776,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.997 | Acc: 59.773,88.831,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.998 | Acc: 59.719,88.823,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.419 | Acc: 54.688,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.674 | Acc: 50.930,68.006,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.686 | Acc: 51.353,68.140,75.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.679 | Acc: 51.178,67.994,75.435,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.033 | Acc: 53.906,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.980 | Acc: 60.342,89.174,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.973 | Acc: 60.118,89.215,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.974 | Acc: 60.105,89.178,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.977 | Acc: 60.156,89.226,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.983 | Acc: 59.963,89.271,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.979 | Acc: 60.227,89.082,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.983 | Acc: 60.167,88.974,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.985 | Acc: 60.079,88.854,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.987 | Acc: 59.979,88.821,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.988 | Acc: 60.005,88.709,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.987 | Acc: 59.958,88.758,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.990 | Acc: 59.839,88.699,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.990 | Acc: 59.860,88.670,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.992 | Acc: 59.748,88.679,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.992 | Acc: 59.808,88.598,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.992 | Acc: 59.857,88.573,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.990 | Acc: 59.939,88.586,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.992 | Acc: 59.897,88.547,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.993 | Acc: 59.908,88.519,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.491 | Acc: 52.344,67.188,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.702 | Acc: 51.637,67.299,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.712 | Acc: 51.200,67.359,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.700 | Acc: 51.050,67.405,75.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.212 | Acc: 47.656,82.812,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.982 | Acc: 60.193,89.100,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.986 | Acc: 60.156,89.120,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.988 | Acc: 60.092,88.960,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.983 | Acc: 59.954,88.850,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.991 | Acc: 59.530,88.676,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.989 | Acc: 59.762,88.849,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.988 | Acc: 59.863,88.780,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.992 | Acc: 59.749,88.621,99.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.994 | Acc: 59.673,88.583,99.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.992 | Acc: 59.907,88.565,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.993 | Acc: 59.852,88.529,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.993 | Acc: 59.890,88.550,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.994 | Acc: 59.821,88.572,99.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.993 | Acc: 59.806,88.579,99.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.993 | Acc: 59.782,88.632,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.993 | Acc: 59.779,88.627,99.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.994 | Acc: 59.785,88.607,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.995 | Acc: 59.758,88.565,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.996 | Acc: 59.668,88.558,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.490 | Acc: 54.688,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.668 | Acc: 51.414,68.155,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.674 | Acc: 51.829,68.064,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.676 | Acc: 51.511,67.982,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 0.917 | Acc: 59.375,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.931 | Acc: 62.537,90.104,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.952 | Acc: 61.300,89.596,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.967 | Acc: 60.694,89.460,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.970 | Acc: 60.475,89.381,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.967 | Acc: 60.334,89.511,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.966 | Acc: 60.557,89.463,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.968 | Acc: 60.472,89.439,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.970 | Acc: 60.413,89.402,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.974 | Acc: 60.212,89.278,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.977 | Acc: 60.148,89.132,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.981 | Acc: 60.103,89.062,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.980 | Acc: 60.127,89.105,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.981 | Acc: 60.069,89.137,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.983 | Acc: 60.017,89.107,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.984 | Acc: 59.972,89.073,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.986 | Acc: 59.927,89.021,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.989 | Acc: 59.838,88.943,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.988 | Acc: 59.862,88.913,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.989 | Acc: 59.830,88.917,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.453 | Acc: 53.125,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.659 | Acc: 51.376,67.783,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.684 | Acc: 51.258,67.550,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.674 | Acc: 51.191,67.713,75.282,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 0.883 | Acc: 67.969,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.961 | Acc: 61.979,89.360,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.974 | Acc: 60.709,89.101,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.974 | Acc: 60.348,89.370,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.969 | Acc: 60.745,89.294,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.970 | Acc: 60.698,89.426,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.974 | Acc: 60.440,89.379,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.972 | Acc: 60.550,89.450,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.973 | Acc: 60.651,89.286,99.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.975 | Acc: 60.562,89.235,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.975 | Acc: 60.522,89.191,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.979 | Acc: 60.354,89.073,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.978 | Acc: 60.237,89.030,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.981 | Acc: 60.192,88.970,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.980 | Acc: 60.226,88.949,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.983 | Acc: 60.068,88.876,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.983 | Acc: 60.039,88.853,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.985 | Acc: 60.021,88.829,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.987 | Acc: 59.972,88.760,99.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.987 | Acc: 60.021,88.759,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.403 | Acc: 52.344,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.679 | Acc: 51.525,68.006,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.692 | Acc: 51.639,67.778,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.683 | Acc: 51.537,67.405,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.035 | Acc: 61.719,88.281,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.979 | Acc: 60.193,89.360,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.969 | Acc: 60.042,89.558,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.978 | Acc: 59.926,89.127,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.977 | Acc: 59.857,89.304,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.982 | Acc: 59.808,89.086,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.984 | Acc: 59.846,89.017,99.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.983 | Acc: 60.012,89.035,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.978 | Acc: 60.297,89.198,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.980 | Acc: 60.217,89.235,99.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.982 | Acc: 60.098,89.249,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.984 | Acc: 60.040,89.158,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.983 | Acc: 60.065,89.098,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.984 | Acc: 59.977,89.071,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.985 | Acc: 59.942,89.001,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.985 | Acc: 59.920,89.024,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.983 | Acc: 59.964,89.106,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.984 | Acc: 59.964,89.079,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.983 | Acc: 60.024,89.093,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.984 | Acc: 59.964,89.081,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.429 | Acc: 53.906,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.675 | Acc: 51.414,67.299,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.693 | Acc: 50.991,67.435,75.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.685 | Acc: 50.948,67.431,75.576,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 0.823 | Acc: 64.844,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.969 | Acc: 61.124,89.286,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.960 | Acc: 60.747,89.405,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.975 | Acc: 60.143,89.011,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.975 | Acc: 60.069,89.188,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.979 | Acc: 60.149,89.341,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.985 | Acc: 59.821,89.185,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.987 | Acc: 59.735,89.218,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.985 | Acc: 59.880,89.300,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.982 | Acc: 60.009,89.352,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.981 | Acc: 60.133,89.346,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.984 | Acc: 60.110,89.211,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.984 | Acc: 60.082,89.157,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.984 | Acc: 60.105,89.125,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.983 | Acc: 60.131,89.140,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.983 | Acc: 60.112,89.130,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.982 | Acc: 60.108,89.053,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.983 | Acc: 60.092,89.083,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.983 | Acc: 60.046,89.054,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.984 | Acc: 59.988,89.030,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.463 | Acc: 52.344,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.678 | Acc: 52.046,68.229,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.696 | Acc: 51.734,68.045,75.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.691 | Acc: 51.588,67.969,75.423,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 0.982 | Acc: 58.594,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.970 | Acc: 60.379,89.546,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.970 | Acc: 60.404,89.463,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.970 | Acc: 60.297,89.562,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.973 | Acc: 59.963,89.342,99.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.976 | Acc: 59.994,89.287,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.977 | Acc: 60.189,89.250,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.986 | Acc: 59.802,89.007,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.985 | Acc: 59.729,88.980,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.981 | Acc: 59.975,89.015,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.984 | Acc: 59.989,88.958,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.981 | Acc: 60.011,88.939,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.982 | Acc: 59.949,88.959,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.981 | Acc: 60.043,88.940,99.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.983 | Acc: 59.931,88.898,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.985 | Acc: 59.920,88.876,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.986 | Acc: 59.959,88.878,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.986 | Acc: 59.900,88.863,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.986 | Acc: 59.927,88.879,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.985 | Acc: 59.984,88.888,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.495 | Acc: 52.344,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.663 | Acc: 51.525,68.415,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.680 | Acc: 51.334,68.083,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.675 | Acc: 51.345,67.853,75.333,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 0.945 | Acc: 58.594,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.987 | Acc: 59.449,88.988,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.972 | Acc: 59.870,89.577,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.977 | Acc: 59.836,89.511,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.976 | Acc: 60.012,89.410,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.978 | Acc: 59.862,89.295,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.979 | Acc: 59.885,89.217,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.975 | Acc: 60.007,89.351,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.974 | Acc: 60.142,89.378,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.978 | Acc: 59.988,89.252,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.977 | Acc: 59.946,89.276,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.977 | Acc: 59.994,89.275,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.979 | Acc: 59.942,89.189,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.978 | Acc: 60.057,89.197,99.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.980 | Acc: 59.945,89.157,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.980 | Acc: 60.006,89.197,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.979 | Acc: 60.056,89.226,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.977 | Acc: 60.078,89.266,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.978 | Acc: 60.081,89.266,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.980 | Acc: 60.037,89.204,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.440 | Acc: 52.344,67.188,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.676 | Acc: 51.153,67.560,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.687 | Acc: 50.934,67.835,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.680 | Acc: 50.961,67.520,75.487,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 0.874 | Acc: 64.844,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.958 | Acc: 60.454,89.174,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.954 | Acc: 60.499,89.120,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.960 | Acc: 60.438,89.191,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.964 | Acc: 60.561,89.246,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.965 | Acc: 60.512,89.325,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.967 | Acc: 60.466,89.392,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.963 | Acc: 60.616,89.450,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.964 | Acc: 60.632,89.431,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.969 | Acc: 60.489,89.330,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.968 | Acc: 60.533,89.338,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.967 | Acc: 60.651,89.328,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.967 | Acc: 60.620,89.400,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.966 | Acc: 60.635,89.422,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.967 | Acc: 60.573,89.416,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.968 | Acc: 60.499,89.314,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.970 | Acc: 60.463,89.301,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.973 | Acc: 60.399,89.225,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.973 | Acc: 60.383,89.233,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.975 | Acc: 60.298,89.188,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.479 | Acc: 52.344,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.690 | Acc: 52.344,66.815,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.714 | Acc: 51.372,67.188,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.704 | Acc: 51.127,67.188,75.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 0.962 | Acc: 64.062,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.964 | Acc: 59.375,89.993,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.948 | Acc: 60.957,90.282,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.950 | Acc: 60.105,90.228,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.951 | Acc: 60.330,90.210,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.958 | Acc: 60.079,90.045,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.960 | Acc: 60.137,89.973,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.956 | Acc: 60.483,90.110,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.960 | Acc: 60.452,89.936,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.962 | Acc: 60.385,89.814,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.965 | Acc: 60.168,89.704,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.965 | Acc: 60.227,89.692,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.966 | Acc: 60.185,89.643,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.967 | Acc: 60.321,89.607,99.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.968 | Acc: 60.384,89.546,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.970 | Acc: 60.315,89.543,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.970 | Acc: 60.351,89.486,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.972 | Acc: 60.214,89.427,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.971 | Acc: 60.245,89.446,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.971 | Acc: 60.283,89.397,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.533 | Acc: 48.438,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 51.525,67.857,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.713 | Acc: 50.819,67.702,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.694 | Acc: 51.037,67.380,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.062 | Acc: 55.469,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.995 | Acc: 60.193,88.021,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.966 | Acc: 61.204,88.948,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.973 | Acc: 61.002,89.024,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.974 | Acc: 60.446,89.178,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.973 | Acc: 60.381,89.372,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.971 | Acc: 60.518,89.398,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.973 | Acc: 60.539,89.256,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.974 | Acc: 60.540,89.417,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.973 | Acc: 60.609,89.403,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.973 | Acc: 60.669,89.342,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.971 | Acc: 60.736,89.388,99.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.971 | Acc: 60.749,89.406,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.971 | Acc: 60.701,89.422,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.972 | Acc: 60.601,89.404,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.973 | Acc: 60.509,89.345,99.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.974 | Acc: 60.470,89.299,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.974 | Acc: 60.431,89.351,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.974 | Acc: 60.433,89.342,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.973 | Acc: 60.452,89.374,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.502 | Acc: 53.125,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.681 | Acc: 51.935,68.155,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.703 | Acc: 51.829,67.893,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.690 | Acc: 51.562,67.777,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 0.972 | Acc: 54.688,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.961 | Acc: 60.417,89.807,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.953 | Acc: 60.671,89.691,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.955 | Acc: 60.733,89.652,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.950 | Acc: 60.774,90.027,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.955 | Acc: 60.736,89.890,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.956 | Acc: 60.634,89.799,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.958 | Acc: 60.727,89.711,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.966 | Acc: 60.413,89.548,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.968 | Acc: 60.359,89.494,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.968 | Acc: 60.378,89.490,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.965 | Acc: 60.591,89.596,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.964 | Acc: 60.510,89.562,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.966 | Acc: 60.381,89.497,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.967 | Acc: 60.345,89.491,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.969 | Acc: 60.317,89.382,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.968 | Acc: 60.317,89.389,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.969 | Acc: 60.319,89.388,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.969 | Acc: 60.325,89.318,99.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.970 | Acc: 60.228,89.294,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.537 | Acc: 52.344,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.693 | Acc: 51.339,67.746,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.719 | Acc: 51.448,67.816,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.706 | Acc: 50.999,67.572,75.295,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 0.914 | Acc: 62.500,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.945 | Acc: 60.342,90.476,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.948 | Acc: 60.537,90.072,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.943 | Acc: 61.155,90.241,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.950 | Acc: 60.687,90.249,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.949 | Acc: 60.860,90.246,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.955 | Acc: 60.557,90.070,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.961 | Acc: 60.372,89.866,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.962 | Acc: 60.384,89.839,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.963 | Acc: 60.394,89.757,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.965 | Acc: 60.405,89.708,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.965 | Acc: 60.340,89.660,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.964 | Acc: 60.510,89.620,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.966 | Acc: 60.405,89.538,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.968 | Acc: 60.384,89.427,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.970 | Acc: 60.294,89.374,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.971 | Acc: 60.312,89.335,99.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.969 | Acc: 60.378,89.363,99.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.967 | Acc: 60.392,89.439,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.968 | Acc: 60.353,89.419,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.442 | Acc: 53.906,67.188,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.706 | Acc: 52.455,67.262,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.729 | Acc: 51.982,67.149,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 51.742,67.341,75.346,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.018 | Acc: 60.156,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.920 | Acc: 61.682,90.997,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.935 | Acc: 61.357,91.025,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.938 | Acc: 61.014,90.471,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.938 | Acc: 61.005,90.297,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.942 | Acc: 60.876,90.176,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.948 | Acc: 60.737,90.018,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.950 | Acc: 60.660,89.993,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.948 | Acc: 60.671,90.028,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.952 | Acc: 60.644,89.891,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.956 | Acc: 60.413,89.848,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.957 | Acc: 60.496,89.784,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.957 | Acc: 60.503,89.756,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.956 | Acc: 60.402,89.769,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.958 | Acc: 60.362,89.713,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.956 | Acc: 60.392,89.709,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.959 | Acc: 60.305,89.671,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.963 | Acc: 60.179,89.583,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.964 | Acc: 60.152,89.528,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.964 | Acc: 60.171,89.491,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.412 | Acc: 52.344,67.969,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.679 | Acc: 51.525,67.932,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.721 | Acc: 51.543,67.664,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.702 | Acc: 51.255,67.738,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 0.999 | Acc: 57.812,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.913 | Acc: 62.351,90.141,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.941 | Acc: 60.595,90.072,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.942 | Acc: 61.002,90.151,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.955 | Acc: 60.610,89.796,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.951 | Acc: 60.582,89.983,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.954 | Acc: 60.653,89.908,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.958 | Acc: 60.455,89.960,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.957 | Acc: 60.477,89.994,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.958 | Acc: 60.536,89.913,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.959 | Acc: 60.615,89.875,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.961 | Acc: 60.566,89.854,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.961 | Acc: 60.497,89.818,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.961 | Acc: 60.560,89.820,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.963 | Acc: 60.434,89.799,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.963 | Acc: 60.416,89.766,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.964 | Acc: 60.436,89.695,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.964 | Acc: 60.459,89.677,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.963 | Acc: 60.427,89.671,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.965 | Acc: 60.433,89.604,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.622 | Acc: 50.781,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.697 | Acc: 51.600,67.336,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.716 | Acc: 51.448,67.359,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.707 | Acc: 51.306,67.405,75.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.078 | Acc: 51.562,87.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.943 | Acc: 61.086,89.993,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.939 | Acc: 61.185,90.511,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.949 | Acc: 60.784,90.241,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.946 | Acc: 60.851,90.316,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.954 | Acc: 60.481,89.983,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.956 | Acc: 60.621,89.928,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.960 | Acc: 60.439,89.777,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.958 | Acc: 60.457,89.795,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.959 | Acc: 60.381,89.783,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.957 | Acc: 60.323,89.820,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.957 | Acc: 60.220,89.861,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.959 | Acc: 60.237,89.850,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.959 | Acc: 60.294,89.865,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.959 | Acc: 60.315,89.838,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.959 | Acc: 60.281,89.763,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.959 | Acc: 60.319,89.744,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.959 | Acc: 60.383,89.667,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.961 | Acc: 60.301,89.567,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.960 | Acc: 60.396,89.596,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.552 | Acc: 51.562,69.531,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.691 | Acc: 51.339,67.001,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.717 | Acc: 51.010,67.054,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.706 | Acc: 50.973,67.085,75.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 0.840 | Acc: 66.406,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.952 | Acc: 60.603,90.141,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.945 | Acc: 60.785,89.958,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.948 | Acc: 61.040,89.972,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.958 | Acc: 60.764,89.699,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.957 | Acc: 60.821,89.790,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.956 | Acc: 60.628,89.876,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.954 | Acc: 60.732,89.783,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.953 | Acc: 60.709,89.747,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.955 | Acc: 60.597,89.732,99.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.956 | Acc: 60.572,89.677,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.955 | Acc: 60.545,89.674,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.957 | Acc: 60.591,89.682,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.956 | Acc: 60.662,89.709,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.955 | Acc: 60.684,89.730,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.955 | Acc: 60.623,89.748,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.955 | Acc: 60.621,89.776,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.957 | Acc: 60.637,89.713,99.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.959 | Acc: 60.589,89.645,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.959 | Acc: 60.671,89.639,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.545 | Acc: 53.125,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.699 | Acc: 51.637,68.378,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.727 | Acc: 51.524,67.873,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 51.178,67.661,75.448,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 0.903 | Acc: 60.938,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.953 | Acc: 60.826,90.588,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.946 | Acc: 61.033,90.339,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.946 | Acc: 60.938,90.407,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.946 | Acc: 60.677,90.413,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.937 | Acc: 60.930,90.764,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.938 | Acc: 60.705,90.502,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.940 | Acc: 60.827,90.359,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.939 | Acc: 60.908,90.387,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.941 | Acc: 60.791,90.366,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.946 | Acc: 60.720,90.225,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.946 | Acc: 60.771,90.190,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.949 | Acc: 60.740,90.139,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.951 | Acc: 60.611,90.119,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.952 | Acc: 60.554,89.977,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.952 | Acc: 60.600,89.961,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.956 | Acc: 60.439,89.868,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.956 | Acc: 60.431,89.853,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.957 | Acc: 60.448,89.751,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.957 | Acc: 60.523,89.743,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.529 | Acc: 52.344,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 51.972,67.560,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.727 | Acc: 51.639,67.378,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.715 | Acc: 51.755,67.226,75.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 0.996 | Acc: 56.250,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.946 | Acc: 61.384,90.253,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.940 | Acc: 61.261,90.625,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.932 | Acc: 61.898,90.471,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.930 | Acc: 61.786,90.664,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.936 | Acc: 61.317,90.408,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.936 | Acc: 61.247,90.528,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.936 | Acc: 61.231,90.475,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.938 | Acc: 61.161,90.378,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.943 | Acc: 60.920,90.198,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.943 | Acc: 60.934,90.260,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.944 | Acc: 60.927,90.176,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.946 | Acc: 60.869,90.116,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.948 | Acc: 60.746,90.038,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.952 | Acc: 60.540,89.977,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.953 | Acc: 60.481,89.945,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.953 | Acc: 60.577,89.892,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.957 | Acc: 60.450,89.853,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.957 | Acc: 60.472,89.829,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.958 | Acc: 60.433,89.844,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.518 | Acc: 51.562,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.720 | Acc: 51.153,68.266,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 50.781,67.607,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.717 | Acc: 50.935,67.444,75.397,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.079 | Acc: 53.906,87.500,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.934 | Acc: 60.677,90.216,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.931 | Acc: 60.633,90.644,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.933 | Acc: 61.373,90.446,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.937 | Acc: 61.092,90.355,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.936 | Acc: 61.255,90.285,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.941 | Acc: 61.080,90.199,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.943 | Acc: 60.915,90.248,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.943 | Acc: 60.942,90.213,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.943 | Acc: 61.050,90.098,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.944 | Acc: 60.945,90.069,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.947 | Acc: 60.870,90.013,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.947 | Acc: 60.934,90.025,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.949 | Acc: 60.797,89.975,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.948 | Acc: 60.893,89.927,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.951 | Acc: 60.784,89.872,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.955 | Acc: 60.680,89.795,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.957 | Acc: 60.624,89.754,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.957 | Acc: 60.632,89.759,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.958 | Acc: 60.605,89.706,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.530 | Acc: 53.125,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 50.409,67.225,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.720 | Acc: 51.010,67.664,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 50.858,67.431,74.962,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 0.847 | Acc: 64.844,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.940 | Acc: 61.644,90.960,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.948 | Acc: 60.861,90.072,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.939 | Acc: 61.219,90.292,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.940 | Acc: 61.169,90.336,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.940 | Acc: 61.177,90.300,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.935 | Acc: 61.538,90.322,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.938 | Acc: 61.226,90.287,99.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.939 | Acc: 61.292,90.276,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.940 | Acc: 61.145,90.258,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.943 | Acc: 60.906,90.221,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.944 | Acc: 60.831,90.187,99.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.943 | Acc: 60.931,90.152,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.943 | Acc: 60.863,90.119,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.943 | Acc: 60.773,90.113,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.947 | Acc: 60.670,90.018,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.947 | Acc: 60.648,90.002,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.950 | Acc: 60.601,89.935,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.951 | Acc: 60.593,89.887,99.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.952 | Acc: 60.573,89.864,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.553 | Acc: 50.000,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.747 | Acc: 51.562,67.411,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.764 | Acc: 51.067,67.111,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.739 | Acc: 50.858,67.149,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 0.953 | Acc: 59.375,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.943 | Acc: 61.793,90.476,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.935 | Acc: 61.147,90.682,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.935 | Acc: 60.886,90.702,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.941 | Acc: 60.417,90.432,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.945 | Acc: 60.365,90.393,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.944 | Acc: 60.408,90.360,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.948 | Acc: 60.206,90.298,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.947 | Acc: 60.491,90.276,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.944 | Acc: 60.752,90.275,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.944 | Acc: 60.743,90.299,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.945 | Acc: 60.764,90.233,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.947 | Acc: 60.821,90.181,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.952 | Acc: 60.602,90.077,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.951 | Acc: 60.601,90.147,99.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.952 | Acc: 60.522,90.171,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.951 | Acc: 60.614,90.204,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.951 | Acc: 60.612,90.190,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.951 | Acc: 60.563,90.209,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.950 | Acc: 60.634,90.252,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.499 | Acc: 53.906,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.714 | Acc: 51.823,67.448,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 51.448,67.435,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 51.434,67.444,75.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 0.889 | Acc: 63.281,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.956 | Acc: 60.900,90.365,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.947 | Acc: 61.452,90.187,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.953 | Acc: 61.386,90.138,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.955 | Acc: 61.130,89.931,99.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.955 | Acc: 60.883,89.991,99.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.953 | Acc: 60.808,90.121,99.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.951 | Acc: 60.938,90.209,99.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.952 | Acc: 60.840,90.159,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.947 | Acc: 60.916,90.284,99.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.947 | Acc: 60.887,90.299,99.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.946 | Acc: 60.874,90.307,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.946 | Acc: 60.938,90.301,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.947 | Acc: 60.905,90.290,99.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.947 | Acc: 60.796,90.302,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.947 | Acc: 60.769,90.264,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.947 | Acc: 60.770,90.272,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.948 | Acc: 60.800,90.215,99.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.949 | Acc: 60.782,90.140,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.951 | Acc: 60.683,90.102,99.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.480 | Acc: 52.344,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.699 | Acc: 52.232,67.969,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.736 | Acc: 52.020,67.340,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 51.678,67.405,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.064 | Acc: 57.812,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.931 | Acc: 61.124,90.439,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.928 | Acc: 61.528,90.454,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.920 | Acc: 61.514,90.856,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.922 | Acc: 61.526,90.799,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.931 | Acc: 60.938,90.579,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.935 | Acc: 60.750,90.535,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.933 | Acc: 60.877,90.675,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.938 | Acc: 60.782,90.606,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.939 | Acc: 60.821,90.565,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.939 | Acc: 60.945,90.520,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.939 | Acc: 60.952,90.519,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.939 | Acc: 61.048,90.537,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.942 | Acc: 60.899,90.401,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.942 | Acc: 60.901,90.403,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.941 | Acc: 61.052,90.337,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.943 | Acc: 60.925,90.333,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.942 | Acc: 60.938,90.341,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.944 | Acc: 60.883,90.287,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.945 | Acc: 60.759,90.305,99.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.483 | Acc: 53.125,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.698 | Acc: 51.525,68.192,76.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.717 | Acc: 51.543,67.969,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 51.409,67.751,75.423,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 0.994 | Acc: 60.156,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.927 | Acc: 60.640,91.220,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.930 | Acc: 60.537,90.968,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.928 | Acc: 60.733,90.856,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.934 | Acc: 60.417,90.731,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.935 | Acc: 60.551,90.687,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.929 | Acc: 60.938,90.741,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.934 | Acc: 60.816,90.542,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.934 | Acc: 60.923,90.426,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.938 | Acc: 60.717,90.306,99.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.938 | Acc: 60.875,90.306,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.940 | Acc: 60.839,90.289,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.942 | Acc: 60.775,90.288,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.946 | Acc: 60.662,90.242,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.947 | Acc: 60.648,90.189,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.948 | Acc: 60.634,90.173,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.949 | Acc: 60.543,90.138,99.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.948 | Acc: 60.541,90.128,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.948 | Acc: 60.526,90.145,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.949 | Acc: 60.538,90.102,99.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.464 | Acc: 55.469,67.188,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.752 | Acc: 51.190,66.555,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.763 | Acc: 50.915,66.883,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.745 | Acc: 50.922,66.726,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 0.915 | Acc: 60.156,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.914 | Acc: 61.682,90.923,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.925 | Acc: 60.938,90.873,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.929 | Acc: 60.989,90.779,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.927 | Acc: 61.111,90.837,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.932 | Acc: 60.938,90.702,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.934 | Acc: 60.795,90.644,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.936 | Acc: 60.832,90.559,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.938 | Acc: 60.918,90.494,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.940 | Acc: 60.868,90.461,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.939 | Acc: 60.887,90.450,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.940 | Acc: 60.839,90.441,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.937 | Acc: 61.012,90.450,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.936 | Acc: 61.150,90.421,99.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.939 | Acc: 61.079,90.302,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.939 | Acc: 61.065,90.324,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.941 | Acc: 60.991,90.255,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.941 | Acc: 60.999,90.261,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.944 | Acc: 60.881,90.160,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.945 | Acc: 60.860,90.114,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.484 | Acc: 53.906,68.750,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.737 | Acc: 51.972,66.927,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.747 | Acc: 51.505,67.054,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.731 | Acc: 51.076,66.970,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 0.859 | Acc: 61.719,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.963 | Acc: 59.561,90.588,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.958 | Acc: 60.442,90.015,99.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.947 | Acc: 60.592,90.292,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.945 | Acc: 60.802,90.490,99.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.940 | Acc: 61.123,90.470,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.944 | Acc: 60.989,90.309,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.946 | Acc: 60.782,90.281,99.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.945 | Acc: 60.671,90.217,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.944 | Acc: 60.657,90.344,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.942 | Acc: 60.825,90.392,99.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.943 | Acc: 60.708,90.363,99.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.942 | Acc: 60.805,90.437,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.941 | Acc: 60.905,90.472,99.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.941 | Acc: 60.879,90.425,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.940 | Acc: 60.803,90.355,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.941 | Acc: 60.816,90.260,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.940 | Acc: 60.828,90.219,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.940 | Acc: 60.866,90.218,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.940 | Acc: 60.864,90.188,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.495 | Acc: 52.344,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.730 | Acc: 52.344,67.560,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.753 | Acc: 52.001,66.940,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.738 | Acc: 51.767,66.880,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 0.833 | Acc: 63.281,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.895 | Acc: 61.905,91.406,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.910 | Acc: 62.081,90.777,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.922 | Acc: 61.680,90.894,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.919 | Acc: 61.661,91.107,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.916 | Acc: 61.696,91.074,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.919 | Acc: 61.757,90.922,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.927 | Acc: 61.325,90.741,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.929 | Acc: 61.272,90.640,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.931 | Acc: 61.171,90.634,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.934 | Acc: 61.140,90.563,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.931 | Acc: 61.234,90.671,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.931 | Acc: 61.294,90.641,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.933 | Acc: 61.216,90.661,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.934 | Acc: 61.216,90.581,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.936 | Acc: 61.104,90.449,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.937 | Acc: 61.137,90.433,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.939 | Acc: 61.061,90.407,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.938 | Acc: 61.095,90.389,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.940 | Acc: 61.052,90.348,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.516 | Acc: 50.781,69.531,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.722 | Acc: 51.228,66.704,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.750 | Acc: 51.143,66.425,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.735 | Acc: 50.871,66.624,75.218,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 0.778 | Acc: 67.188,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.915 | Acc: 61.644,90.848,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.925 | Acc: 61.071,90.625,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.921 | Acc: 61.066,90.881,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.918 | Acc: 61.198,91.088,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.918 | Acc: 61.471,90.973,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.920 | Acc: 61.267,90.980,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.922 | Acc: 61.093,90.896,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.927 | Acc: 60.884,90.800,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.925 | Acc: 60.981,90.815,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.924 | Acc: 61.046,90.815,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.925 | Acc: 61.065,90.795,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.928 | Acc: 61.025,90.657,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.928 | Acc: 61.042,90.643,99.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.932 | Acc: 60.907,90.561,99.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.933 | Acc: 60.852,90.524,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.934 | Acc: 60.852,90.472,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.936 | Acc: 60.869,90.462,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.937 | Acc: 60.836,90.458,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.938 | Acc: 60.851,90.459,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.458 | Acc: 53.906,69.531,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.721 | Acc: 51.897,67.894,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.747 | Acc: 51.658,67.511,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 51.486,67.456,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 0.938 | Acc: 58.594,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.934 | Acc: 59.970,90.997,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.935 | Acc: 60.880,91.349,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.927 | Acc: 61.309,91.253,99.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.927 | Acc: 60.851,91.175,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.926 | Acc: 60.922,91.035,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.925 | Acc: 61.125,90.993,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.929 | Acc: 60.960,90.874,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.928 | Acc: 61.136,90.809,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.930 | Acc: 61.149,90.711,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.934 | Acc: 60.922,90.551,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.935 | Acc: 60.930,90.547,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.936 | Acc: 60.967,90.619,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.937 | Acc: 60.940,90.547,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.937 | Acc: 61.035,90.497,99.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.937 | Acc: 60.971,90.490,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.939 | Acc: 60.903,90.462,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.938 | Acc: 60.954,90.506,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.937 | Acc: 61.026,90.512,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.937 | Acc: 60.985,90.488,99.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.368 | Acc: 53.906,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.739 | Acc: 51.860,67.969,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.761 | Acc: 51.448,67.321,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.740 | Acc: 51.281,67.188,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 0.948 | Acc: 60.156,85.938,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.910 | Acc: 60.938,91.443,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.911 | Acc: 61.223,91.502,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.910 | Acc: 61.232,91.381,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.918 | Acc: 60.947,91.242,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.926 | Acc: 60.667,90.965,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.927 | Acc: 60.828,90.909,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.924 | Acc: 61.187,90.969,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.925 | Acc: 61.331,90.829,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.927 | Acc: 61.192,90.754,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.927 | Acc: 61.357,90.742,99.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.930 | Acc: 61.185,90.632,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.931 | Acc: 61.051,90.619,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.932 | Acc: 61.051,90.550,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.935 | Acc: 60.938,90.467,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.937 | Acc: 60.940,90.436,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.937 | Acc: 60.896,90.447,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.939 | Acc: 60.802,90.396,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.940 | Acc: 60.795,90.350,99.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.941 | Acc: 60.819,90.356,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.430 | Acc: 50.781,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.753 | Acc: 51.897,67.783,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 51.010,67.569,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.754 | Acc: 50.832,67.559,74.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 0.937 | Acc: 60.156,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.933 | Acc: 60.231,90.699,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.946 | Acc: 60.042,90.777,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.941 | Acc: 60.656,90.766,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.936 | Acc: 60.938,90.856,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.929 | Acc: 61.293,90.942,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.929 | Acc: 61.176,90.890,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.928 | Acc: 61.253,90.896,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.929 | Acc: 61.175,90.829,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.931 | Acc: 61.089,90.746,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.929 | Acc: 61.136,90.827,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.930 | Acc: 61.139,90.777,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.930 | Acc: 61.184,90.790,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.929 | Acc: 61.219,90.742,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.928 | Acc: 61.293,90.811,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.930 | Acc: 61.197,90.763,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.931 | Acc: 61.178,90.698,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.931 | Acc: 61.116,90.675,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.932 | Acc: 61.128,90.575,99.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.933 | Acc: 61.122,90.486,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.391 | Acc: 54.688,69.531,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.724 | Acc: 51.823,67.969,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 51.715,67.321,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.730 | Acc: 51.524,67.482,74.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 0.864 | Acc: 62.500,89.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.911 | Acc: 60.900,90.811,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.912 | Acc: 60.976,90.682,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.917 | Acc: 61.066,90.932,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.909 | Acc: 61.526,90.953,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.914 | Acc: 61.394,90.950,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.919 | Acc: 61.273,90.967,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.920 | Acc: 61.181,90.913,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.920 | Acc: 61.331,90.834,99.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.922 | Acc: 61.520,90.763,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.923 | Acc: 61.427,90.753,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.928 | Acc: 61.196,90.713,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.928 | Acc: 61.177,90.716,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.926 | Acc: 61.291,90.718,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.926 | Acc: 61.279,90.728,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.926 | Acc: 61.280,90.721,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.929 | Acc: 61.222,90.613,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.928 | Acc: 61.226,90.627,99.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.928 | Acc: 61.178,90.608,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.931 | Acc: 61.058,90.537,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.425 | Acc: 53.906,69.531,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.756 | Acc: 51.116,67.001,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.767 | Acc: 50.953,66.787,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.746 | Acc: 50.922,66.893,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 0.906 | Acc: 57.031,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.909 | Acc: 61.719,92.039,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.915 | Acc: 61.738,91.559,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.913 | Acc: 61.834,91.598,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.916 | Acc: 61.526,91.503,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.920 | Acc: 61.409,91.391,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.917 | Acc: 61.615,91.303,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.918 | Acc: 61.602,91.301,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.917 | Acc: 61.665,91.270,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.916 | Acc: 61.615,91.320,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.920 | Acc: 61.443,91.177,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.922 | Acc: 61.323,91.138,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.924 | Acc: 61.271,91.108,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.923 | Acc: 61.330,91.065,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.925 | Acc: 61.316,90.967,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.927 | Acc: 61.311,90.929,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.928 | Acc: 61.295,90.895,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.928 | Acc: 61.377,90.888,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.929 | Acc: 61.418,90.876,99.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.931 | Acc: 61.313,90.816,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.485 | Acc: 57.031,71.875,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.727 | Acc: 52.455,67.225,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 52.268,66.978,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.743 | Acc: 51.806,66.778,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 0.728 | Acc: 68.750,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.914 | Acc: 62.314,90.960,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.910 | Acc: 62.062,91.178,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.919 | Acc: 61.450,91.060,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.922 | Acc: 61.410,91.445,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.922 | Acc: 61.355,91.344,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.924 | Acc: 61.183,91.161,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.924 | Acc: 61.287,91.074,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.925 | Acc: 61.321,90.979,99.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.920 | Acc: 61.503,91.022,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.921 | Acc: 61.598,91.060,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.921 | Acc: 61.560,91.032,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.924 | Acc: 61.450,90.975,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.923 | Acc: 61.491,91.008,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.925 | Acc: 61.391,90.978,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.925 | Acc: 61.366,90.952,99.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.925 | Acc: 61.468,90.902,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.926 | Acc: 61.375,90.907,99.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.928 | Acc: 61.312,90.876,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.927 | Acc: 61.309,90.869,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.459 | Acc: 55.469,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.715 | Acc: 51.972,67.448,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.745 | Acc: 51.429,66.825,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 51.140,66.662,74.782,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 0.930 | Acc: 57.812,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.890 | Acc: 63.504,91.295,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.898 | Acc: 62.386,91.616,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.894 | Acc: 62.180,91.919,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.896 | Acc: 62.066,92.159,99.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.891 | Acc: 62.245,92.249,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.888 | Acc: 62.235,92.407,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.892 | Acc: 62.140,92.409,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.893 | Acc: 62.073,92.377,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.895 | Acc: 61.874,92.347,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.894 | Acc: 61.870,92.401,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.893 | Acc: 61.896,92.368,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.890 | Acc: 61.994,92.427,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.889 | Acc: 62.057,92.457,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.890 | Acc: 62.005,92.432,99.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.887 | Acc: 62.121,92.517,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.887 | Acc: 62.125,92.497,99.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.885 | Acc: 62.211,92.515,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.885 | Acc: 62.234,92.521,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.884 | Acc: 62.276,92.536,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.430 | Acc: 54.688,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.688 | Acc: 52.381,68.638,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.711 | Acc: 52.363,68.312,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.689 | Acc: 52.190,68.212,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.087 | Acc: 53.906,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.885 | Acc: 61.347,93.118,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.873 | Acc: 62.519,93.064,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.871 | Acc: 62.666,92.841,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 63.011,92.872,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.875 | Acc: 62.577,92.721,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.875 | Acc: 62.700,92.846,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 62.583,92.869,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.872 | Acc: 62.738,92.780,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.874 | Acc: 62.556,92.714,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.875 | Acc: 62.442,92.767,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.874 | Acc: 62.468,92.796,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.875 | Acc: 62.487,92.722,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.873 | Acc: 62.461,92.708,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 62.672,92.777,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.871 | Acc: 62.617,92.738,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.870 | Acc: 62.673,92.738,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.871 | Acc: 62.681,92.769,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.871 | Acc: 62.703,92.763,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.871 | Acc: 62.656,92.788,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.468 | Acc: 54.688,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.692 | Acc: 52.902,68.601,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.717 | Acc: 52.706,68.216,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.694 | Acc: 52.485,68.007,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 0.947 | Acc: 69.531,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.916 | Acc: 60.975,92.448,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.881 | Acc: 62.309,93.007,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.872 | Acc: 62.999,93.391,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.865 | Acc: 63.310,93.326,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 63.320,93.317,99.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.862 | Acc: 63.307,93.279,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.869 | Acc: 63.010,93.257,99.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 62.840,93.197,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.869 | Acc: 62.690,93.189,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.866 | Acc: 62.760,93.210,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 62.779,93.206,99.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.866 | Acc: 62.847,93.205,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.864 | Acc: 62.943,93.241,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.867 | Acc: 62.859,93.238,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.866 | Acc: 62.848,93.283,99.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 62.933,93.217,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 62.908,93.198,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 62.857,93.177,99.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.869 | Acc: 62.822,93.170,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.440 | Acc: 54.688,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.680 | Acc: 52.493,68.601,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.709 | Acc: 52.287,68.102,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.690 | Acc: 52.190,68.020,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 0.919 | Acc: 54.688,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.889 | Acc: 61.012,93.378,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.875 | Acc: 61.947,93.045,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.878 | Acc: 61.578,93.263,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 62.143,93.200,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.876 | Acc: 61.873,93.139,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 61.925,93.292,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 62.068,93.285,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.866 | Acc: 62.189,93.260,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.864 | Acc: 62.362,93.383,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.865 | Acc: 62.418,93.311,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.865 | Acc: 62.451,93.287,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.865 | Acc: 62.513,93.257,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.866 | Acc: 62.485,93.298,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.867 | Acc: 62.492,93.258,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 62.529,93.275,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 62.493,93.273,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.869 | Acc: 62.459,93.271,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 62.528,93.276,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 62.588,93.266,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.462 | Acc: 54.688,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.690 | Acc: 52.716,68.266,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.715 | Acc: 52.553,68.045,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.695 | Acc: 52.344,67.905,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 0.904 | Acc: 58.594,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.874 | Acc: 61.198,93.304,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.867 | Acc: 62.062,93.331,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.875 | Acc: 61.834,92.956,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.874 | Acc: 62.047,92.921,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 62.515,93.007,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.864 | Acc: 62.694,93.091,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.864 | Acc: 62.550,93.102,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.865 | Acc: 62.422,93.124,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 62.647,93.210,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.860 | Acc: 62.601,93.249,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.861 | Acc: 62.542,93.287,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.862 | Acc: 62.630,93.235,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.862 | Acc: 62.596,93.259,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.862 | Acc: 62.617,93.269,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.862 | Acc: 62.625,93.228,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.861 | Acc: 62.585,93.202,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.863 | Acc: 62.553,93.200,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.862 | Acc: 62.628,93.233,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.864 | Acc: 62.525,93.233,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.477 | Acc: 54.688,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.704 | Acc: 52.418,68.155,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 52.344,67.969,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 52.113,67.879,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 0.927 | Acc: 55.469,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 63.579,93.192,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.851 | Acc: 63.338,93.159,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.857 | Acc: 63.307,92.866,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.860 | Acc: 63.137,92.949,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.854 | Acc: 63.374,93.147,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.853 | Acc: 63.333,93.266,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 63.580,93.418,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.849 | Acc: 63.553,93.352,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.851 | Acc: 63.493,93.357,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.852 | Acc: 63.328,93.451,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.853 | Acc: 63.186,93.517,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.858 | Acc: 63.002,93.452,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 63.087,93.427,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.856 | Acc: 63.126,93.408,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.859 | Acc: 62.954,93.327,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.859 | Acc: 62.987,93.322,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.860 | Acc: 62.908,93.319,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.863 | Acc: 62.794,93.293,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.862 | Acc: 62.832,93.297,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.483 | Acc: 54.688,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.692 | Acc: 53.125,68.378,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.715 | Acc: 52.363,67.988,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.697 | Acc: 52.152,67.879,75.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 0.958 | Acc: 53.906,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.855 | Acc: 62.091,93.415,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.869 | Acc: 62.176,93.369,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.865 | Acc: 63.012,93.379,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 63.339,93.412,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 63.096,93.193,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.865 | Acc: 63.230,93.208,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.864 | Acc: 63.176,93.257,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.863 | Acc: 63.111,93.260,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.866 | Acc: 62.901,93.241,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.865 | Acc: 62.928,93.194,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.865 | Acc: 62.850,93.227,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 62.756,93.124,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 62.719,93.109,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.866 | Acc: 62.789,93.177,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.865 | Acc: 62.884,93.231,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.865 | Acc: 62.824,93.254,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.864 | Acc: 62.848,93.267,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.864 | Acc: 62.742,93.311,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.864 | Acc: 62.795,93.313,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.526 | Acc: 54.688,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.679 | Acc: 52.195,68.490,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.705 | Acc: 52.287,67.950,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.692 | Acc: 52.164,67.866,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 0.858 | Acc: 64.844,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.871 | Acc: 61.793,93.527,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.875 | Acc: 62.157,92.969,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.876 | Acc: 62.141,93.084,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.874 | Acc: 62.297,93.258,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.877 | Acc: 62.546,93.154,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.877 | Acc: 62.519,93.169,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.870 | Acc: 62.733,93.357,99.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.865 | Acc: 62.801,93.391,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.864 | Acc: 62.837,93.418,99.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.867 | Acc: 62.652,93.404,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.866 | Acc: 62.857,93.425,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.865 | Acc: 62.876,93.449,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.864 | Acc: 62.898,93.376,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.866 | Acc: 62.767,93.330,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.866 | Acc: 62.780,93.330,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.865 | Acc: 62.797,93.327,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.865 | Acc: 62.800,93.294,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 62.667,93.270,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.866 | Acc: 62.658,93.270,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.528 | Acc: 54.688,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.702 | Acc: 52.269,68.080,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.720 | Acc: 52.153,67.759,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.700 | Acc: 52.139,67.764,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 0.837 | Acc: 60.938,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.816 | Acc: 64.323,93.601,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.845 | Acc: 63.281,93.540,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.851 | Acc: 62.615,93.596,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.858 | Acc: 62.365,93.692,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 62.322,93.696,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.855 | Acc: 62.494,93.698,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.856 | Acc: 62.733,93.634,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 62.898,93.536,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.856 | Acc: 62.815,93.551,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 62.819,93.544,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.856 | Acc: 62.822,93.559,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 62.857,93.530,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.856 | Acc: 62.811,93.526,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.857 | Acc: 62.848,93.522,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.857 | Acc: 62.900,93.509,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.859 | Acc: 62.829,93.477,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.858 | Acc: 62.834,93.493,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.860 | Acc: 62.799,93.469,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.861 | Acc: 62.806,93.418,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.475 | Acc: 53.906,68.750,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.691 | Acc: 52.790,68.192,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.719 | Acc: 52.515,67.797,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.699 | Acc: 52.433,67.738,75.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 0.835 | Acc: 62.500,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.877 | Acc: 62.612,92.113,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.858 | Acc: 63.281,92.835,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.861 | Acc: 62.769,92.789,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 62.635,92.872,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.864 | Acc: 62.570,92.822,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.861 | Acc: 62.758,92.891,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 62.794,93.013,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.861 | Acc: 62.728,93.051,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 62.629,93.038,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.863 | Acc: 62.554,93.035,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.863 | Acc: 62.592,93.089,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.862 | Acc: 62.646,93.095,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.864 | Acc: 62.581,93.124,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.861 | Acc: 62.633,93.133,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.863 | Acc: 62.560,93.119,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.864 | Acc: 62.558,93.086,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.863 | Acc: 62.580,93.143,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.862 | Acc: 62.582,93.148,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.863 | Acc: 62.527,93.164,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.458 | Acc: 54.688,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.692 | Acc: 52.344,68.564,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 52.134,68.255,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.700 | Acc: 52.049,68.007,75.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 0.827 | Acc: 58.594,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.862 | Acc: 63.244,93.601,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 62.595,93.693,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 62.423,93.404,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.860 | Acc: 62.625,93.634,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.861 | Acc: 62.585,93.495,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.867 | Acc: 62.416,93.543,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.866 | Acc: 62.267,93.556,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.865 | Acc: 62.320,93.512,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 62.453,93.543,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.860 | Acc: 62.659,93.579,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.858 | Acc: 62.776,93.626,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.858 | Acc: 62.840,93.513,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.856 | Acc: 62.907,93.505,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 62.839,93.500,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.857 | Acc: 62.866,93.535,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.858 | Acc: 62.790,93.529,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.858 | Acc: 62.780,93.493,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.860 | Acc: 62.749,93.423,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.860 | Acc: 62.767,93.420,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.441 | Acc: 54.688,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.700 | Acc: 52.418,68.527,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 52.191,68.197,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 52.177,67.892,75.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 0.945 | Acc: 54.688,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 62.054,93.527,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.855 | Acc: 61.966,93.826,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.857 | Acc: 62.257,93.635,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 62.230,93.557,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.858 | Acc: 62.670,93.626,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.856 | Acc: 62.816,93.634,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.858 | Acc: 62.838,93.611,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.858 | Acc: 62.937,93.672,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.857 | Acc: 62.992,93.629,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.860 | Acc: 62.877,93.544,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.860 | Acc: 62.885,93.495,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.859 | Acc: 62.860,93.500,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.859 | Acc: 62.844,93.546,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.860 | Acc: 62.809,93.533,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.859 | Acc: 62.827,93.545,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.861 | Acc: 62.702,93.473,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.859 | Acc: 62.773,93.496,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.858 | Acc: 62.788,93.505,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.859 | Acc: 62.758,93.483,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.548 | Acc: 53.906,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.720 | Acc: 52.381,68.155,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.743 | Acc: 52.115,67.950,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.716 | Acc: 52.139,67.828,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 0.670 | Acc: 71.094,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.841 | Acc: 62.612,93.452,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.831 | Acc: 63.796,93.750,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.841 | Acc: 63.563,93.878,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.850 | Acc: 63.243,93.528,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 63.150,93.588,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.852 | Acc: 63.055,93.472,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.854 | Acc: 63.098,93.346,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.852 | Acc: 63.058,93.372,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.854 | Acc: 62.966,93.297,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 62.955,93.276,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.856 | Acc: 62.942,93.283,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 62.886,93.264,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.856 | Acc: 63.060,93.286,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.856 | Acc: 63.034,93.336,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 62.993,93.340,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.858 | Acc: 62.948,93.312,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 63.128,93.367,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 63.095,93.367,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.856 | Acc: 63.080,93.383,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.485 | Acc: 54.688,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.691 | Acc: 52.939,68.601,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.719 | Acc: 52.515,68.026,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.693 | Acc: 52.344,67.956,74.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 0.964 | Acc: 62.500,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.845 | Acc: 64.286,93.862,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.849 | Acc: 64.024,93.064,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.842 | Acc: 63.640,93.481,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.845 | Acc: 63.349,93.625,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.843 | Acc: 63.328,93.719,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.845 | Acc: 63.146,93.718,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.852 | Acc: 62.716,93.678,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.851 | Acc: 62.684,93.750,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.850 | Acc: 62.733,93.806,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.852 | Acc: 62.710,93.808,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.851 | Acc: 62.800,93.789,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.851 | Acc: 62.941,93.766,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.852 | Acc: 62.880,93.738,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.855 | Acc: 62.784,93.669,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 62.957,93.706,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.852 | Acc: 62.916,93.723,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 62.896,93.688,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 62.807,93.655,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 62.881,93.652,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.513 | Acc: 53.906,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.697 | Acc: 52.641,68.080,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.726 | Acc: 52.325,67.759,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.701 | Acc: 51.998,67.777,75.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 0.907 | Acc: 57.812,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.866 | Acc: 62.128,93.490,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.854 | Acc: 62.957,93.540,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.863 | Acc: 62.538,93.558,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.867 | Acc: 62.558,93.576,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.863 | Acc: 62.647,93.696,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.861 | Acc: 62.681,93.627,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.862 | Acc: 62.428,93.617,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.859 | Acc: 62.616,93.701,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.861 | Acc: 62.720,93.659,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.859 | Acc: 62.757,93.618,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.860 | Acc: 62.712,93.587,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.860 | Acc: 62.805,93.659,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.860 | Acc: 62.722,93.666,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.859 | Acc: 62.722,93.658,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.858 | Acc: 62.749,93.636,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.855 | Acc: 62.921,93.667,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.856 | Acc: 62.871,93.638,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 62.939,93.635,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.855 | Acc: 62.927,93.615,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.516 | Acc: 53.125,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 52.493,68.006,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 52.306,67.797,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.702 | Acc: 52.152,67.751,75.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 0.908 | Acc: 61.719,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.846 | Acc: 64.509,94.085,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 62.824,93.388,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.869 | Acc: 62.359,93.327,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 62.510,93.239,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.869 | Acc: 62.299,93.325,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.871 | Acc: 62.216,93.246,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.866 | Acc: 62.428,93.390,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.862 | Acc: 62.612,93.483,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.858 | Acc: 62.837,93.573,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 62.916,93.509,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.854 | Acc: 62.974,93.577,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.855 | Acc: 62.866,93.578,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.853 | Acc: 63.012,93.624,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 62.945,93.619,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.855 | Acc: 62.871,93.571,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.856 | Acc: 62.846,93.572,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 62.883,93.587,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 62.868,93.624,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 62.916,93.676,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.497 | Acc: 53.906,72.656,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.705 | Acc: 52.641,68.043,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 52.344,67.854,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 52.190,67.994,74.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 0.734 | Acc: 70.312,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.857 | Acc: 62.574,92.932,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.847 | Acc: 62.938,93.559,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.857 | Acc: 62.833,93.686,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.855 | Acc: 63.185,93.721,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.858 | Acc: 63.119,93.564,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.857 | Acc: 62.881,93.698,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.854 | Acc: 63.165,93.672,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.853 | Acc: 63.058,93.682,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.855 | Acc: 62.871,93.595,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 62.912,93.532,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.854 | Acc: 62.984,93.545,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.854 | Acc: 63.116,93.517,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.854 | Acc: 63.093,93.531,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.855 | Acc: 63.017,93.511,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.854 | Acc: 63.050,93.529,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.855 | Acc: 62.945,93.507,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.857 | Acc: 62.873,93.484,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.858 | Acc: 62.779,93.449,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.858 | Acc: 62.816,93.463,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.529 | Acc: 53.125,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.700 | Acc: 52.344,68.341,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.722 | Acc: 52.363,67.969,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.698 | Acc: 52.075,67.866,75.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 0.831 | Acc: 64.844,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.868 | Acc: 62.351,94.122,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.863 | Acc: 62.614,93.902,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.866 | Acc: 62.513,93.635,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.864 | Acc: 62.838,93.480,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 62.933,93.634,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.856 | Acc: 63.081,93.692,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 62.899,93.573,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.856 | Acc: 62.883,93.556,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.855 | Acc: 62.932,93.621,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.854 | Acc: 63.032,93.552,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.854 | Acc: 63.041,93.503,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.855 | Acc: 62.892,93.572,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.855 | Acc: 62.901,93.624,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.855 | Acc: 62.848,93.633,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.853 | Acc: 62.946,93.657,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.855 | Acc: 62.921,93.631,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.854 | Acc: 63.022,93.619,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 62.926,93.601,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.856 | Acc: 62.828,93.572,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.497 | Acc: 53.906,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 52.530,68.155,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.716 | Acc: 52.401,67.740,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.698 | Acc: 52.203,67.815,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 0.925 | Acc: 59.375,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.858 | Acc: 62.314,93.527,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.858 | Acc: 62.576,93.483,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.857 | Acc: 62.731,93.571,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.854 | Acc: 62.731,93.663,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.852 | Acc: 62.848,93.727,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.853 | Acc: 62.758,93.647,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.852 | Acc: 63.026,93.639,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.849 | Acc: 63.145,93.740,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.849 | Acc: 63.052,93.802,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.848 | Acc: 63.067,93.824,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.848 | Acc: 63.023,93.824,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.849 | Acc: 63.009,93.815,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.849 | Acc: 63.015,93.813,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.849 | Acc: 62.989,93.836,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.851 | Acc: 62.972,93.721,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 62.992,93.684,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.850 | Acc: 63.045,93.725,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 63.019,93.698,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.851 | Acc: 62.996,93.693,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.504 | Acc: 54.688,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.706 | Acc: 52.753,68.006,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 52.210,67.759,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 52.126,67.969,75.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 0.833 | Acc: 60.938,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.843 | Acc: 63.356,94.234,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.841 | Acc: 63.205,93.941,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.848 | Acc: 62.846,93.852,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.852 | Acc: 62.674,93.760,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.849 | Acc: 62.771,93.866,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.847 | Acc: 62.836,93.892,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.849 | Acc: 62.755,93.911,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 62.621,93.968,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.853 | Acc: 62.504,93.914,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.851 | Acc: 62.795,93.921,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.851 | Acc: 62.850,93.867,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.852 | Acc: 62.876,93.802,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.852 | Acc: 62.850,93.861,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 62.903,93.825,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.851 | Acc: 62.923,93.856,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 62.965,93.801,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 62.912,93.796,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.852 | Acc: 62.963,93.782,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 62.978,93.752,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.477 | Acc: 53.906,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 52.493,68.304,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.722 | Acc: 52.229,67.912,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 52.113,67.892,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 0.779 | Acc: 64.844,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.836 | Acc: 63.244,94.531,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.844 | Acc: 62.729,93.921,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.848 | Acc: 62.756,93.827,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.845 | Acc: 62.905,94.010,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.843 | Acc: 62.964,94.090,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.843 | Acc: 63.010,94.079,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 62.738,93.961,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.847 | Acc: 62.752,93.954,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 62.772,93.957,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.851 | Acc: 62.745,93.839,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.851 | Acc: 62.747,93.810,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.851 | Acc: 62.879,93.776,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 62.853,93.744,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.849 | Acc: 62.987,93.694,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.850 | Acc: 63.019,93.664,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.852 | Acc: 62.926,93.604,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 62.816,93.585,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 62.864,93.627,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.851 | Acc: 62.924,93.606,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.518 | Acc: 53.906,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 52.307,68.155,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 52.191,67.950,75.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 52.203,67.905,75.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 0.867 | Acc: 60.156,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.870 | Acc: 63.132,92.746,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.847 | Acc: 63.319,93.464,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.838 | Acc: 63.806,93.840,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.843 | Acc: 63.551,93.740,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.847 | Acc: 63.157,93.827,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.848 | Acc: 63.171,93.821,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 63.098,93.944,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 62.980,93.886,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.851 | Acc: 62.876,93.823,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.852 | Acc: 62.819,93.828,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.854 | Acc: 62.719,93.814,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.854 | Acc: 62.733,93.873,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.854 | Acc: 62.713,93.840,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.855 | Acc: 62.692,93.811,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.855 | Acc: 62.713,93.781,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.854 | Acc: 62.802,93.755,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 62.789,93.697,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 62.755,93.731,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 62.789,93.748,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.445 | Acc: 53.906,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.705 | Acc: 52.381,67.746,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 51.963,67.607,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 52.036,67.661,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 0.889 | Acc: 60.938,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.844 | Acc: 63.281,94.085,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.852 | Acc: 62.919,93.559,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.844 | Acc: 63.589,93.673,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.843 | Acc: 63.542,93.818,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.843 | Acc: 63.467,93.951,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.839 | Acc: 63.585,94.028,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.843 | Acc: 63.459,93.977,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.844 | Acc: 63.456,93.905,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.846 | Acc: 63.342,93.854,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.846 | Acc: 63.242,93.878,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.847 | Acc: 63.324,93.835,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.847 | Acc: 63.353,93.860,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.844 | Acc: 63.398,93.888,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.845 | Acc: 63.392,93.897,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.846 | Acc: 63.388,93.890,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.848 | Acc: 63.332,93.806,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.848 | Acc: 63.279,93.812,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.850 | Acc: 63.180,93.813,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.850 | Acc: 63.238,93.795,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.477 | Acc: 54.688,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.689 | Acc: 52.716,67.671,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.720 | Acc: 52.172,67.378,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.703 | Acc: 52.139,67.572,75.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 0.761 | Acc: 64.062,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.834 | Acc: 64.397,93.452,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.832 | Acc: 64.310,93.598,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.842 | Acc: 64.127,93.596,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.838 | Acc: 63.744,93.875,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.841 | Acc: 63.482,93.804,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 63.468,93.892,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.840 | Acc: 63.442,93.894,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.844 | Acc: 63.310,93.823,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.846 | Acc: 63.212,93.854,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.845 | Acc: 63.262,93.874,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.845 | Acc: 63.398,93.842,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.844 | Acc: 63.359,93.860,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.846 | Acc: 63.266,93.831,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 63.242,93.872,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.846 | Acc: 63.284,93.872,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.848 | Acc: 63.162,93.828,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.849 | Acc: 63.125,93.821,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.850 | Acc: 63.086,93.767,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.850 | Acc: 63.033,93.775,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.509 | Acc: 53.906,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.690 | Acc: 52.493,68.155,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.720 | Acc: 52.287,67.893,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.703 | Acc: 52.164,67.700,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 0.936 | Acc: 60.156,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.834 | Acc: 64.249,94.234,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.830 | Acc: 64.405,94.207,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.836 | Acc: 64.139,94.096,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.839 | Acc: 64.005,94.252,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.843 | Acc: 63.707,94.059,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.845 | Acc: 63.662,94.073,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.843 | Acc: 63.713,94.105,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.844 | Acc: 63.437,94.119,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.841 | Acc: 63.536,94.048,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.846 | Acc: 63.456,93.960,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.845 | Acc: 63.462,93.987,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.842 | Acc: 63.625,93.974,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 63.455,93.986,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.845 | Acc: 63.420,93.950,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.847 | Acc: 63.367,93.890,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.848 | Acc: 63.286,93.864,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.849 | Acc: 63.247,93.832,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.850 | Acc: 63.141,93.830,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.851 | Acc: 63.101,93.814,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.489 | Acc: 54.688,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.702 | Acc: 53.125,68.266,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.729 | Acc: 52.496,67.683,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 52.241,67.777,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 0.829 | Acc: 64.062,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.833 | Acc: 62.760,93.936,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.833 | Acc: 63.300,94.112,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.834 | Acc: 63.204,94.160,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.841 | Acc: 62.818,93.924,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.837 | Acc: 63.018,94.098,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.839 | Acc: 63.094,94.079,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.845 | Acc: 62.965,93.933,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.842 | Acc: 63.053,93.954,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.844 | Acc: 62.988,93.970,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.845 | Acc: 62.990,93.925,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.847 | Acc: 63.027,93.849,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.846 | Acc: 62.912,93.873,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.848 | Acc: 62.850,93.867,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.849 | Acc: 62.861,93.817,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.850 | Acc: 62.879,93.773,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.853 | Acc: 62.768,93.716,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 62.834,93.732,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 62.926,93.726,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.851 | Acc: 62.920,93.703,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.485 | Acc: 53.906,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 52.455,68.304,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 52.287,67.664,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.699 | Acc: 52.126,67.738,75.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 0.878 | Acc: 60.156,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.819 | Acc: 64.286,95.312,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.821 | Acc: 64.348,94.588,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.834 | Acc: 63.512,94.109,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.840 | Acc: 63.166,94.010,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 63.204,94.052,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.842 | Acc: 63.210,94.008,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.845 | Acc: 63.104,93.983,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.846 | Acc: 63.043,93.939,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.843 | Acc: 63.286,93.949,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.843 | Acc: 63.328,93.874,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.844 | Acc: 63.239,93.831,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.847 | Acc: 63.119,93.805,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.850 | Acc: 63.024,93.789,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.849 | Acc: 63.025,93.831,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.850 | Acc: 62.907,93.817,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.849 | Acc: 63.011,93.804,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.849 | Acc: 63.098,93.798,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.848 | Acc: 63.089,93.821,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.848 | Acc: 63.072,93.809,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.469 | Acc: 55.469,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.705 | Acc: 52.604,68.043,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 52.572,67.759,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 52.357,67.802,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 0.769 | Acc: 63.281,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.809 | Acc: 64.583,95.052,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.819 | Acc: 63.415,94.703,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.829 | Acc: 63.256,94.365,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.832 | Acc: 63.156,94.396,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.835 | Acc: 63.204,94.307,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.843 | Acc: 63.042,94.157,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 62.971,93.933,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.847 | Acc: 62.990,93.930,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.845 | Acc: 63.195,93.940,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.844 | Acc: 63.099,93.921,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.845 | Acc: 63.172,93.923,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 63.148,93.886,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.845 | Acc: 63.141,93.873,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.846 | Acc: 63.067,93.875,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.846 | Acc: 63.048,93.914,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.847 | Acc: 63.089,93.886,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.847 | Acc: 63.029,93.871,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.846 | Acc: 63.030,93.863,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.847 | Acc: 63.043,93.816,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.545 | Acc: 54.688,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.715 | Acc: 52.753,67.820,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 52.306,67.530,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 52.190,67.597,75.000,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 0.886 | Acc: 58.594,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.838 | Acc: 63.281,94.196,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.861 | Acc: 62.824,93.636,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.855 | Acc: 63.166,93.635,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.851 | Acc: 63.079,93.692,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 63.026,93.827,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.850 | Acc: 63.094,93.866,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.854 | Acc: 63.043,93.850,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.852 | Acc: 63.223,93.862,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.849 | Acc: 63.281,93.862,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.850 | Acc: 63.176,93.933,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.851 | Acc: 63.133,93.923,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.851 | Acc: 63.139,93.945,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 63.138,93.897,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.851 | Acc: 63.101,93.892,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.849 | Acc: 63.183,93.919,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.849 | Acc: 63.179,93.942,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.848 | Acc: 63.208,93.926,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.848 | Acc: 63.208,93.906,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.848 | Acc: 63.226,93.898,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.488 | Acc: 54.688,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.701 | Acc: 52.939,68.155,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 52.611,67.778,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.713 | Acc: 52.421,67.700,74.962,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 0.695 | Acc: 71.875,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.841 | Acc: 62.760,92.932,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.837 | Acc: 62.976,93.464,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.842 | Acc: 62.820,93.622,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.845 | Acc: 62.905,93.682,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.850 | Acc: 62.771,93.711,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 62.758,93.640,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.849 | Acc: 62.827,93.767,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 62.806,93.789,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.851 | Acc: 62.815,93.832,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.851 | Acc: 62.737,93.832,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.850 | Acc: 62.857,93.870,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.850 | Acc: 62.928,93.795,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.850 | Acc: 63.042,93.792,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.848 | Acc: 63.109,93.831,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.849 | Acc: 63.058,93.792,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.848 | Acc: 63.089,93.842,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.847 | Acc: 63.098,93.851,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.847 | Acc: 63.123,93.845,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.847 | Acc: 63.127,93.826,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.488 | Acc: 56.250,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 52.753,67.783,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 52.458,67.645,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.702 | Acc: 52.318,67.559,75.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 0.810 | Acc: 59.375,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.841 | Acc: 63.542,94.308,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.841 | Acc: 63.243,93.998,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.845 | Acc: 63.192,93.865,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.846 | Acc: 63.339,93.953,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.845 | Acc: 63.250,94.005,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.846 | Acc: 63.165,94.086,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.842 | Acc: 63.414,94.099,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.842 | Acc: 63.519,93.978,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.844 | Acc: 63.363,93.905,99.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.845 | Acc: 63.277,93.905,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.845 | Acc: 63.299,93.895,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.846 | Acc: 63.249,93.850,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.846 | Acc: 63.323,93.861,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 63.265,93.853,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.845 | Acc: 63.372,93.872,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.846 | Acc: 63.345,93.835,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.847 | Acc: 63.279,93.830,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.847 | Acc: 63.244,93.854,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.848 | Acc: 63.246,93.828,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.524 | Acc: 53.906,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 52.753,68.043,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.725 | Acc: 52.344,67.740,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.704 | Acc: 52.305,67.661,75.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 0.781 | Acc: 63.281,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.848 | Acc: 63.467,94.196,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.832 | Acc: 63.910,94.341,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.832 | Acc: 63.345,94.442,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.837 | Acc: 63.291,94.493,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.836 | Acc: 63.304,94.493,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.836 | Acc: 63.365,94.312,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.836 | Acc: 63.486,94.232,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.841 | Acc: 63.233,94.075,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.840 | Acc: 63.264,94.100,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.841 | Acc: 63.347,94.045,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.841 | Acc: 63.302,94.100,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.839 | Acc: 63.430,94.188,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.839 | Acc: 63.383,94.136,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 63.270,94.145,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.842 | Acc: 63.302,94.142,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.844 | Acc: 63.272,94.118,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.844 | Acc: 63.229,94.142,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.845 | Acc: 63.173,94.072,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.846 | Acc: 63.189,94.002,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.553 | Acc: 53.906,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.707 | Acc: 52.530,67.894,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.732 | Acc: 52.401,67.626,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 52.152,67.559,74.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 0.787 | Acc: 72.656,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.839 | Acc: 63.914,94.345,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.834 | Acc: 63.872,94.455,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.833 | Acc: 63.896,94.314,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.839 | Acc: 63.580,94.213,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.841 | Acc: 63.498,94.021,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 63.552,94.150,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.842 | Acc: 63.436,94.071,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.843 | Acc: 63.417,94.109,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.844 | Acc: 63.324,94.000,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.844 | Acc: 63.273,93.972,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.843 | Acc: 63.278,93.923,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.843 | Acc: 63.181,93.912,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.841 | Acc: 63.260,93.986,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 63.278,94.011,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.839 | Acc: 63.307,94.004,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.840 | Acc: 63.281,93.996,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.841 | Acc: 63.288,93.958,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.842 | Acc: 63.227,93.936,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.844 | Acc: 63.173,93.914,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.517 | Acc: 53.906,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.700 | Acc: 52.679,67.894,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.726 | Acc: 52.172,67.740,75.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.707 | Acc: 52.267,67.789,75.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 0.924 | Acc: 60.938,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.822 | Acc: 64.137,93.973,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.826 | Acc: 64.158,93.902,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.828 | Acc: 64.075,93.878,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.838 | Acc: 63.686,93.731,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.835 | Acc: 63.498,93.982,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.835 | Acc: 63.636,94.047,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.837 | Acc: 63.514,94.088,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 63.369,94.022,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.840 | Acc: 63.238,94.087,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.843 | Acc: 63.122,93.968,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.845 | Acc: 63.062,93.941,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.848 | Acc: 62.983,93.889,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.847 | Acc: 63.003,93.951,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 62.920,93.972,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.848 | Acc: 62.959,93.965,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.847 | Acc: 63.023,93.950,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.846 | Acc: 63.089,93.915,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.845 | Acc: 63.130,93.904,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.846 | Acc: 63.070,93.881,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.518 | Acc: 55.469,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.702 | Acc: 52.530,68.080,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.729 | Acc: 52.210,67.702,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 52.203,67.841,75.282,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 0.767 | Acc: 65.625,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.843 | Acc: 63.504,94.978,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.845 | Acc: 63.624,94.303,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.843 | Acc: 63.550,94.301,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.840 | Acc: 63.802,94.145,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.836 | Acc: 63.575,94.168,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 63.378,93.944,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.839 | Acc: 63.403,94.027,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.841 | Acc: 63.184,94.007,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.843 | Acc: 63.040,93.940,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.845 | Acc: 63.040,93.867,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.842 | Acc: 63.186,93.902,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.844 | Acc: 63.080,93.935,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 63.147,93.986,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.845 | Acc: 63.123,93.939,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.845 | Acc: 63.167,93.932,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.844 | Acc: 63.235,93.986,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.842 | Acc: 63.272,94.009,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.843 | Acc: 63.216,93.973,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.846 | Acc: 63.080,93.918,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.490 | Acc: 53.906,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.692 | Acc: 52.195,68.229,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.722 | Acc: 51.982,67.873,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.704 | Acc: 52.011,67.879,75.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 0.759 | Acc: 63.281,96.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.825 | Acc: 64.360,94.494,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.825 | Acc: 64.539,94.512,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.826 | Acc: 64.434,94.365,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.836 | Acc: 64.188,94.097,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.837 | Acc: 64.186,94.083,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 64.114,93.892,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.842 | Acc: 63.863,93.866,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.841 | Acc: 63.839,94.007,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.836 | Acc: 63.825,94.061,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.837 | Acc: 63.724,94.065,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.837 | Acc: 63.642,94.068,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.836 | Acc: 63.625,94.103,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.838 | Acc: 63.575,94.088,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.837 | Acc: 63.587,94.106,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.836 | Acc: 63.694,94.108,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.838 | Acc: 63.661,94.091,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 63.501,94.018,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.841 | Acc: 63.448,93.999,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.844 | Acc: 63.263,93.949,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.499 | Acc: 53.906,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.710 | Acc: 52.790,67.894,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 52.287,67.454,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.714 | Acc: 52.280,67.520,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 0.830 | Acc: 58.594,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.868 | Acc: 61.682,93.564,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.855 | Acc: 62.957,93.693,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.851 | Acc: 63.409,93.673,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.845 | Acc: 63.407,93.731,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.848 | Acc: 63.235,93.789,99.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.848 | Acc: 63.075,93.705,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.845 | Acc: 63.093,93.800,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.847 | Acc: 62.966,93.808,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.847 | Acc: 62.897,93.832,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.848 | Acc: 62.912,93.960,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.849 | Acc: 62.899,93.955,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.850 | Acc: 62.928,93.886,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.850 | Acc: 62.979,93.861,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.850 | Acc: 62.973,93.836,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.851 | Acc: 62.895,93.843,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 62.909,93.838,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.851 | Acc: 62.876,93.867,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.850 | Acc: 62.883,93.878,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.850 | Acc: 62.916,93.865,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.536 | Acc: 55.469,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.716 | Acc: 52.530,68.266,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.738 | Acc: 52.210,67.854,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 52.113,67.905,75.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 0.834 | Acc: 58.594,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.831 | Acc: 63.393,94.085,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.842 | Acc: 63.110,94.093,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.845 | Acc: 62.910,93.942,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.848 | Acc: 62.963,93.924,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 62.848,93.920,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.852 | Acc: 62.823,93.879,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.850 | Acc: 62.766,93.922,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.843 | Acc: 63.107,94.061,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.847 | Acc: 63.027,93.953,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.846 | Acc: 62.943,94.100,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.845 | Acc: 62.995,94.107,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.843 | Acc: 63.109,94.168,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 63.072,94.139,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 63.039,94.184,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 63.087,94.212,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.841 | Acc: 63.077,94.193,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.842 | Acc: 63.109,94.181,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.841 | Acc: 63.177,94.187,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.841 | Acc: 63.220,94.146,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.496 | Acc: 54.688,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.703 | Acc: 52.641,67.857,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 52.191,67.607,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 52.164,67.751,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 0.781 | Acc: 64.062,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.821 | Acc: 64.472,94.085,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.826 | Acc: 63.853,93.845,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.829 | Acc: 64.165,94.019,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 64.101,94.252,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.836 | Acc: 63.707,94.059,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.836 | Acc: 63.572,94.073,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.836 | Acc: 63.486,94.110,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.837 | Acc: 63.437,94.109,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.838 | Acc: 63.372,94.113,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.841 | Acc: 63.235,94.061,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.843 | Acc: 63.165,93.941,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 63.223,93.987,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.840 | Acc: 63.203,93.989,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 63.209,94.011,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.841 | Acc: 63.138,94.015,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.841 | Acc: 63.116,93.984,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.842 | Acc: 63.043,93.965,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.841 | Acc: 63.151,94.003,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.841 | Acc: 63.160,94.021,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.501 | Acc: 56.250,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.700 | Acc: 52.865,68.229,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 52.306,67.759,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 52.421,67.853,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 0.853 | Acc: 58.594,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.841 | Acc: 62.649,94.308,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.830 | Acc: 63.300,94.398,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.839 | Acc: 63.422,94.262,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.837 | Acc: 63.600,94.242,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.840 | Acc: 63.359,94.245,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.838 | Acc: 63.126,94.299,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.839 | Acc: 63.087,94.310,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.838 | Acc: 63.145,94.371,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.836 | Acc: 63.268,94.363,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.835 | Acc: 63.254,94.333,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.833 | Acc: 63.373,94.333,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.835 | Acc: 63.301,94.301,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.835 | Acc: 63.335,94.331,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.837 | Acc: 63.315,94.328,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.838 | Acc: 63.245,94.321,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.838 | Acc: 63.220,94.327,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.839 | Acc: 63.297,94.288,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.839 | Acc: 63.338,94.259,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.837 | Acc: 63.425,94.267,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.523 | Acc: 53.906,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.699 | Acc: 52.753,67.820,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 52.229,67.683,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.714 | Acc: 52.254,67.751,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 0.847 | Acc: 63.281,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.827 | Acc: 63.430,94.085,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.843 | Acc: 63.415,93.807,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.842 | Acc: 63.768,93.916,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.839 | Acc: 63.619,93.962,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 63.428,93.943,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.837 | Acc: 63.514,93.995,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 63.514,94.033,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.837 | Acc: 63.597,94.114,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.834 | Acc: 63.661,94.117,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.834 | Acc: 63.608,94.034,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.837 | Acc: 63.430,93.944,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.837 | Acc: 63.398,93.980,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.838 | Acc: 63.281,94.010,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.838 | Acc: 63.278,94.020,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.839 | Acc: 63.172,94.098,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.838 | Acc: 63.218,94.074,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.838 | Acc: 63.279,94.123,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.838 | Acc: 63.327,94.137,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.839 | Acc: 63.228,94.142,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.542 | Acc: 54.688,68.750,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.699 | Acc: 52.902,67.783,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 52.477,67.588,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 52.382,67.738,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 0.834 | Acc: 67.969,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.850 | Acc: 62.277,94.643,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.852 | Acc: 62.386,94.055,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.852 | Acc: 62.026,94.019,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.842 | Acc: 62.780,94.039,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 62.740,93.998,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.844 | Acc: 62.565,94.041,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.846 | Acc: 62.727,94.016,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.844 | Acc: 62.854,94.056,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.843 | Acc: 62.811,94.121,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.841 | Acc: 62.881,94.131,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.841 | Acc: 62.928,94.135,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 62.795,94.097,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 62.850,94.106,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.842 | Acc: 62.973,94.114,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.842 | Acc: 63.048,94.043,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.842 | Acc: 63.065,94.059,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 63.109,94.110,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.840 | Acc: 63.080,94.109,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.840 | Acc: 63.062,94.121,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.522 | Acc: 56.250,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.713 | Acc: 52.976,67.857,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 52.401,67.607,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 52.318,67.738,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 0.790 | Acc: 70.312,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.833 | Acc: 64.174,93.638,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.834 | Acc: 64.177,93.845,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.829 | Acc: 64.050,94.160,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.835 | Acc: 63.744,94.030,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.834 | Acc: 63.714,94.013,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.836 | Acc: 63.604,93.860,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.834 | Acc: 63.625,93.872,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.835 | Acc: 63.626,93.900,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.835 | Acc: 63.614,93.914,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.839 | Acc: 63.305,93.847,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.841 | Acc: 63.317,93.831,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 63.304,93.909,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.840 | Acc: 63.329,93.921,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.839 | Acc: 63.445,93.975,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 63.341,93.945,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.839 | Acc: 63.362,93.957,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 63.293,93.954,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.840 | Acc: 63.312,93.990,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.839 | Acc: 63.257,94.041,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.511 | Acc: 54.688,67.188,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.705 | Acc: 52.865,67.671,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 52.344,67.397,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 52.344,67.610,75.064,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 0.923 | Acc: 55.469,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.839 | Acc: 62.984,94.568,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.824 | Acc: 63.777,94.607,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.824 | Acc: 63.870,94.659,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.823 | Acc: 63.908,94.589,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.826 | Acc: 64.008,94.469,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.829 | Acc: 63.791,94.564,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.834 | Acc: 63.686,94.348,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.833 | Acc: 63.742,94.303,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.831 | Acc: 63.950,94.281,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 63.814,94.209,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.832 | Acc: 63.780,94.234,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.834 | Acc: 63.716,94.239,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.837 | Acc: 63.619,94.115,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.838 | Acc: 63.534,94.153,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 63.468,94.132,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.840 | Acc: 63.435,94.152,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.841 | Acc: 63.460,94.117,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.840 | Acc: 63.463,94.120,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.840 | Acc: 63.458,94.111,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.519 | Acc: 54.688,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.705 | Acc: 52.753,68.155,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 52.268,67.835,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 52.254,67.853,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 0.789 | Acc: 67.969,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.830 | Acc: 63.839,94.420,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.827 | Acc: 63.796,94.798,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.818 | Acc: 64.062,94.839,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.819 | Acc: 63.908,94.647,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.822 | Acc: 64.055,94.508,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.829 | Acc: 63.946,94.370,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.830 | Acc: 63.830,94.443,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.829 | Acc: 63.825,94.405,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.831 | Acc: 63.713,94.428,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.833 | Acc: 63.592,94.407,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.835 | Acc: 63.582,94.323,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.835 | Acc: 63.644,94.317,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.833 | Acc: 63.706,94.376,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.835 | Acc: 63.623,94.348,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.837 | Acc: 63.497,94.331,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.837 | Acc: 63.459,94.312,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.836 | Acc: 63.513,94.318,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.838 | Acc: 63.424,94.295,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 63.421,94.269,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.571 | Acc: 55.469,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.708 | Acc: 52.716,67.820,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 52.363,67.645,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.714 | Acc: 52.190,67.764,74.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 0.851 | Acc: 63.281,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.845 | Acc: 62.835,93.564,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.832 | Acc: 63.072,94.150,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.827 | Acc: 63.358,94.403,99.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.834 | Acc: 63.098,94.300,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.832 | Acc: 63.111,94.407,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.830 | Acc: 63.410,94.421,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.829 | Acc: 63.647,94.371,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.831 | Acc: 63.582,94.235,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.831 | Acc: 63.726,94.164,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.831 | Acc: 63.728,94.123,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.831 | Acc: 63.691,94.227,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.831 | Acc: 63.729,94.252,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.834 | Acc: 63.634,94.235,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.833 | Acc: 63.618,94.220,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.835 | Acc: 63.585,94.183,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.836 | Acc: 63.527,94.186,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.837 | Acc: 63.531,94.158,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.838 | Acc: 63.474,94.185,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 63.482,94.234,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.503 | Acc: 53.906,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.700 | Acc: 52.753,68.080,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.729 | Acc: 52.344,67.664,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.715 | Acc: 52.344,67.725,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 0.768 | Acc: 63.281,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.838 | Acc: 64.174,94.568,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.845 | Acc: 63.700,94.188,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.845 | Acc: 63.704,94.237,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.848 | Acc: 63.358,94.213,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.841 | Acc: 63.428,94.291,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 63.307,94.183,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.839 | Acc: 63.470,94.243,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 63.407,94.211,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.840 | Acc: 63.437,94.151,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.842 | Acc: 63.406,94.162,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.841 | Acc: 63.447,94.114,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 63.417,94.133,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.840 | Acc: 63.485,94.184,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.839 | Acc: 63.548,94.175,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.838 | Acc: 63.569,94.199,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.838 | Acc: 63.581,94.188,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.837 | Acc: 63.616,94.197,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.838 | Acc: 63.534,94.235,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 63.548,94.254,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.529 | Acc: 55.469,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.703 | Acc: 52.827,68.192,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 52.363,67.835,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 52.421,67.841,75.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 0.708 | Acc: 70.312,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.848 | Acc: 63.616,94.196,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.838 | Acc: 63.300,94.417,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.836 | Acc: 63.409,94.224,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 63.609,94.252,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.835 | Acc: 63.436,94.160,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.834 | Acc: 63.326,94.241,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 63.121,94.265,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 63.010,94.264,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.840 | Acc: 63.001,94.307,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.840 | Acc: 63.001,94.325,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.840 | Acc: 63.073,94.326,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.841 | Acc: 62.821,94.334,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.839 | Acc: 62.913,94.370,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.839 | Acc: 62.975,94.328,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.838 | Acc: 63.011,94.337,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.840 | Acc: 62.958,94.283,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.839 | Acc: 63.029,94.295,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.838 | Acc: 63.145,94.282,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 63.173,94.285,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.548 | Acc: 53.906,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.719 | Acc: 52.641,67.857,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 52.287,67.835,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.716 | Acc: 52.216,67.789,75.218,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 0.913 | Acc: 57.812,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.834 | Acc: 63.356,94.457,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.832 | Acc: 63.205,94.607,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.839 | Acc: 63.320,94.326,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.845 | Acc: 63.079,94.126,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.844 | Acc: 62.956,94.106,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.840 | Acc: 63.062,94.105,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.841 | Acc: 62.943,94.010,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 63.048,94.051,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.841 | Acc: 62.988,94.056,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.842 | Acc: 62.963,94.065,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.843 | Acc: 62.914,94.093,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 62.840,94.081,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 62.925,94.076,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.843 | Acc: 62.987,94.084,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.843 | Acc: 62.936,94.082,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.844 | Acc: 62.960,94.054,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.843 | Acc: 62.983,94.087,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.843 | Acc: 62.913,94.070,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.842 | Acc: 62.959,94.105,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.517 | Acc: 54.688,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 52.567,67.597,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 52.115,67.588,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.716 | Acc: 52.113,67.725,75.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 0.809 | Acc: 64.844,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.818 | Acc: 64.844,94.382,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.836 | Acc: 63.967,94.017,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.837 | Acc: 63.730,93.929,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.841 | Acc: 63.378,93.933,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 63.150,93.959,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.842 | Acc: 63.075,94.066,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.844 | Acc: 63.115,93.972,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.842 | Acc: 63.087,93.964,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.846 | Acc: 62.945,93.879,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.845 | Acc: 63.048,93.909,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.845 | Acc: 63.087,94.012,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.844 | Acc: 63.058,94.090,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.844 | Acc: 63.126,94.139,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.843 | Acc: 63.106,94.175,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.844 | Acc: 63.084,94.142,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.844 | Acc: 63.087,94.142,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.843 | Acc: 63.107,94.158,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.842 | Acc: 63.132,94.209,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.841 | Acc: 63.207,94.193,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.503 | Acc: 53.906,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.709 | Acc: 52.976,68.043,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 52.534,67.969,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 52.395,67.918,75.231,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 0.815 | Acc: 60.938,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.838 | Acc: 63.095,94.196,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.835 | Acc: 63.186,94.360,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.829 | Acc: 63.345,94.480,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.821 | Acc: 63.985,94.473,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.830 | Acc: 63.730,94.152,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.836 | Acc: 63.514,94.021,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.835 | Acc: 63.575,93.944,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 63.213,93.910,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.839 | Acc: 63.173,94.005,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.839 | Acc: 63.242,93.991,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.843 | Acc: 63.122,93.941,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.843 | Acc: 63.158,93.983,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.841 | Acc: 63.188,94.031,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.839 | Acc: 63.226,94.100,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.839 | Acc: 63.346,94.051,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.839 | Acc: 63.354,94.027,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 63.290,94.064,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.839 | Acc: 63.244,94.064,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.839 | Acc: 63.277,94.080,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.482 | Acc: 54.688,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.704 | Acc: 53.051,67.932,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 52.534,67.721,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 52.408,67.764,75.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 0.771 | Acc: 69.531,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.835 | Acc: 64.621,93.936,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.820 | Acc: 64.539,94.398,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.832 | Acc: 63.550,94.378,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.834 | Acc: 63.378,94.348,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.833 | Acc: 63.312,94.353,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.833 | Acc: 63.404,94.234,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.832 | Acc: 63.348,94.215,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.833 | Acc: 63.369,94.192,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.834 | Acc: 63.368,94.190,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.833 | Acc: 63.406,94.193,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.834 | Acc: 63.320,94.238,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.834 | Acc: 63.401,94.227,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.834 | Acc: 63.479,94.241,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.834 | Acc: 63.456,94.200,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.836 | Acc: 63.315,94.152,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.835 | Acc: 63.366,94.125,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.836 | Acc: 63.345,94.089,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.836 | Acc: 63.407,94.092,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.837 | Acc: 63.394,94.109,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.548 | Acc: 53.906,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.704 | Acc: 52.790,67.932,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.729 | Acc: 52.344,67.797,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 52.228,67.853,75.038,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 0.813 | Acc: 57.812,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.846 | Acc: 62.760,93.862,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.842 | Acc: 63.262,94.074,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.840 | Acc: 63.166,94.211,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.838 | Acc: 62.992,94.261,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.840 | Acc: 62.910,94.346,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.840 | Acc: 62.745,94.196,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.840 | Acc: 62.816,94.088,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 62.951,94.090,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.843 | Acc: 62.953,94.065,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.841 | Acc: 62.998,94.022,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.842 | Acc: 62.998,94.036,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.839 | Acc: 63.116,94.110,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.838 | Acc: 63.197,94.151,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.838 | Acc: 63.212,94.120,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.836 | Acc: 63.367,94.165,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.837 | Acc: 63.415,94.173,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.834 | Acc: 63.538,94.222,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.836 | Acc: 63.441,94.259,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.835 | Acc: 63.435,94.267,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.553 | Acc: 53.906,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.701 | Acc: 52.790,68.006,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 52.382,67.664,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 52.267,67.623,75.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 0.821 | Acc: 61.719,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.851 | Acc: 63.728,93.527,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.844 | Acc: 63.815,93.864,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.843 | Acc: 63.537,93.929,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.841 | Acc: 63.455,94.010,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 63.359,94.129,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 63.430,94.208,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.844 | Acc: 63.259,94.221,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 63.514,94.303,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.839 | Acc: 63.398,94.328,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.835 | Acc: 63.526,94.352,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.836 | Acc: 63.490,94.347,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.837 | Acc: 63.489,94.304,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.839 | Acc: 63.365,94.328,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 63.306,94.328,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.841 | Acc: 63.266,94.355,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.841 | Acc: 63.184,94.341,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 63.300,94.346,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.839 | Acc: 63.331,94.386,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 63.415,94.341,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.507 | Acc: 54.688,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.705 | Acc: 53.088,68.229,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 52.572,67.950,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 52.382,67.930,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 0.884 | Acc: 62.500,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.847 | Acc: 64.062,93.527,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.827 | Acc: 64.596,94.417,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.828 | Acc: 64.408,94.454,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.834 | Acc: 64.217,94.213,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.831 | Acc: 64.302,94.253,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.829 | Acc: 64.398,94.312,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.834 | Acc: 64.112,94.227,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.834 | Acc: 64.130,94.226,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.833 | Acc: 64.123,94.212,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.836 | Acc: 64.004,94.104,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.837 | Acc: 63.780,94.100,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.836 | Acc: 63.771,94.087,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.838 | Acc: 63.781,94.079,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.838 | Acc: 63.648,94.111,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.838 | Acc: 63.582,94.145,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.840 | Acc: 63.410,94.137,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.837 | Acc: 63.515,94.183,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.837 | Acc: 63.537,94.148,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.836 | Acc: 63.527,94.179,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.506 | Acc: 53.125,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.707 | Acc: 52.641,68.155,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 52.229,67.683,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 52.228,67.674,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 0.792 | Acc: 67.969,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.841 | Acc: 62.649,94.568,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.843 | Acc: 62.671,94.493,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.848 | Acc: 62.807,94.275,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.842 | Acc: 63.194,94.232,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.840 | Acc: 63.111,94.276,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 63.236,94.228,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.841 | Acc: 63.215,94.177,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.843 | Acc: 63.063,94.090,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.846 | Acc: 62.893,94.087,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.846 | Acc: 62.920,94.119,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.847 | Acc: 63.101,94.072,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 63.142,94.139,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 63.209,94.196,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 63.220,94.225,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 63.248,94.251,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.839 | Acc: 63.242,94.237,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.839 | Acc: 63.304,94.229,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.839 | Acc: 63.264,94.189,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 63.300,94.222,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.548 | Acc: 56.250,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.714 | Acc: 52.827,68.043,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.738 | Acc: 52.572,67.778,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.716 | Acc: 52.408,67.879,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 0.830 | Acc: 66.406,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.826 | Acc: 63.690,94.308,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.818 | Acc: 63.948,94.493,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.830 | Acc: 64.127,94.493,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.824 | Acc: 64.053,94.599,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.822 | Acc: 63.885,94.678,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.828 | Acc: 63.494,94.609,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.828 | Acc: 63.575,94.570,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.829 | Acc: 63.635,94.522,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.831 | Acc: 63.579,94.432,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 63.616,94.485,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.833 | Acc: 63.578,94.418,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.833 | Acc: 63.498,94.428,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.833 | Acc: 63.569,94.459,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.835 | Acc: 63.431,94.426,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.833 | Acc: 63.528,94.464,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.835 | Acc: 63.435,94.431,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.836 | Acc: 63.439,94.440,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.836 | Acc: 63.407,94.397,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.836 | Acc: 63.423,94.390,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.534 | Acc: 54.688,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.708 | Acc: 52.753,68.043,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.736 | Acc: 52.534,67.721,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 52.344,67.700,74.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 0.882 | Acc: 66.406,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.846 | Acc: 62.277,94.234,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.844 | Acc: 62.633,94.341,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.844 | Acc: 62.859,94.390,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.839 | Acc: 62.982,94.319,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.840 | Acc: 63.127,94.214,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.839 | Acc: 62.920,94.350,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.836 | Acc: 63.049,94.415,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 62.743,94.434,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.838 | Acc: 62.863,94.445,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.837 | Acc: 63.013,94.446,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.838 | Acc: 63.044,94.450,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.837 | Acc: 63.122,94.453,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.837 | Acc: 63.126,94.465,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.836 | Acc: 63.153,94.445,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.836 | Acc: 63.279,94.438,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.835 | Acc: 63.281,94.458,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.836 | Acc: 63.238,94.437,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.837 | Acc: 63.225,94.410,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.836 | Acc: 63.287,94.414,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.540 | Acc: 54.688,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 52.902,68.006,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.739 | Acc: 52.325,67.797,75.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.715 | Acc: 52.241,67.866,75.423,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.069 | Acc: 53.125,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.871 | Acc: 62.351,93.378,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.855 | Acc: 62.500,93.712,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.854 | Acc: 62.615,93.750,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.853 | Acc: 62.857,93.991,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.848 | Acc: 63.111,94.106,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.842 | Acc: 63.423,94.215,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.843 | Acc: 63.331,94.304,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.843 | Acc: 63.422,94.250,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.844 | Acc: 63.359,94.203,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.843 | Acc: 63.332,94.236,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.843 | Acc: 63.306,94.210,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.844 | Acc: 63.239,94.217,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 63.323,94.190,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.843 | Acc: 63.303,94.175,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.842 | Acc: 63.325,94.191,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.839 | Acc: 63.405,94.193,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.839 | Acc: 63.410,94.190,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.837 | Acc: 63.467,94.235,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 63.466,94.222,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.545 | Acc: 55.469,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.710 | Acc: 52.455,68.043,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 52.153,67.797,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.713 | Acc: 52.177,67.879,74.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 0.710 | Acc: 68.750,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.803 | Acc: 66.406,94.940,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.817 | Acc: 64.558,94.989,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.826 | Acc: 64.293,94.954,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.828 | Acc: 64.024,94.782,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.832 | Acc: 63.753,94.640,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.836 | Acc: 63.494,94.512,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.837 | Acc: 63.569,94.498,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.837 | Acc: 63.563,94.488,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.833 | Acc: 63.873,94.523,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.834 | Acc: 63.724,94.465,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.833 | Acc: 63.773,94.492,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.833 | Acc: 63.755,94.515,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.834 | Acc: 63.748,94.516,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.834 | Acc: 63.696,94.501,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.835 | Acc: 63.658,94.451,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.837 | Acc: 63.566,94.397,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.838 | Acc: 63.451,94.355,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.837 | Acc: 63.448,94.380,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 63.412,94.380,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.514 | Acc: 53.906,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.707 | Acc: 52.865,67.820,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.727 | Acc: 52.382,67.816,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 52.331,67.905,74.923,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 0.655 | Acc: 72.656,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.832 | Acc: 62.984,94.606,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.828 | Acc: 63.453,94.588,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.829 | Acc: 63.435,94.698,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.830 | Acc: 63.522,94.541,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.825 | Acc: 63.683,94.701,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.825 | Acc: 63.740,94.706,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.827 | Acc: 63.708,94.587,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.835 | Acc: 63.417,94.517,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.835 | Acc: 63.475,94.501,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.833 | Acc: 63.581,94.496,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.834 | Acc: 63.550,94.471,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.834 | Acc: 63.531,94.437,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.836 | Acc: 63.455,94.406,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.836 | Acc: 63.462,94.440,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.836 | Acc: 63.504,94.373,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.835 | Acc: 63.593,94.324,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.835 | Acc: 63.538,94.265,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.834 | Acc: 63.571,94.254,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.835 | Acc: 63.474,94.242,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.542 | Acc: 53.906,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 52.716,67.969,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 52.287,67.626,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.709 | Acc: 52.062,67.687,75.231,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 0.980 | Acc: 57.812,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.848 | Acc: 62.909,94.308,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.838 | Acc: 63.758,94.398,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.843 | Acc: 63.550,94.429,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.840 | Acc: 63.561,94.290,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.841 | Acc: 63.475,94.175,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.844 | Acc: 63.404,93.976,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.842 | Acc: 63.314,94.038,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.842 | Acc: 63.427,94.128,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.842 | Acc: 63.277,94.100,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.840 | Acc: 63.394,94.119,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.841 | Acc: 63.327,94.146,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.842 | Acc: 63.340,94.165,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.842 | Acc: 63.245,94.163,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.842 | Acc: 63.348,94.148,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 63.333,94.178,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.840 | Acc: 63.320,94.212,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 63.268,94.222,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.839 | Acc: 63.359,94.243,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 63.316,94.236,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.488 | Acc: 55.469,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.705 | Acc: 52.827,68.378,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 52.420,67.873,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 52.382,67.918,75.115,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 0.875 | Acc: 64.844,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.819 | Acc: 65.588,93.936,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.831 | Acc: 64.787,93.883,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.828 | Acc: 64.434,94.070,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.834 | Acc: 63.927,93.933,99.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.834 | Acc: 63.869,94.090,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.832 | Acc: 63.908,94.208,99.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.833 | Acc: 63.691,94.260,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.831 | Acc: 63.791,94.206,99.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.830 | Acc: 63.825,94.229,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 63.685,94.197,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.835 | Acc: 63.642,94.167,99.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.835 | Acc: 63.615,94.201,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.836 | Acc: 63.578,94.166,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.838 | Acc: 63.554,94.150,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.837 | Acc: 63.551,94.157,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.838 | Acc: 63.503,94.161,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.839 | Acc: 63.439,94.160,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.838 | Acc: 63.500,94.159,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.839 | Acc: 63.410,94.170,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.533 | Acc: 53.906,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 52.753,68.080,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 52.248,67.721,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.706 | Acc: 52.267,67.828,75.051,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 0.795 | Acc: 58.594,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.837 | Acc: 62.723,94.271,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.841 | Acc: 62.595,94.284,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.846 | Acc: 62.641,94.211,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.844 | Acc: 62.828,94.290,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.840 | Acc: 63.266,94.384,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 63.243,94.318,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 63.237,94.354,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 63.150,94.361,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.840 | Acc: 63.229,94.251,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.842 | Acc: 63.188,94.228,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.838 | Acc: 63.338,94.291,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.835 | Acc: 63.541,94.295,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.834 | Acc: 63.536,94.343,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.835 | Acc: 63.529,94.309,99.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.835 | Acc: 63.564,94.308,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.834 | Acc: 63.688,94.317,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.834 | Acc: 63.710,94.323,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.834 | Acc: 63.669,94.345,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.837 | Acc: 63.581,94.310,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.500 | Acc: 54.688,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.701 | Acc: 52.493,68.192,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.732 | Acc: 52.115,67.912,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.714 | Acc: 52.075,67.802,75.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 0.867 | Acc: 61.719,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.836 | Acc: 63.281,94.122,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.834 | Acc: 63.662,94.379,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.850 | Acc: 63.038,94.134,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.841 | Acc: 63.590,94.184,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.838 | Acc: 63.436,94.284,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.834 | Acc: 63.488,94.473,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.837 | Acc: 63.381,94.348,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.835 | Acc: 63.315,94.449,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.834 | Acc: 63.445,94.458,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.835 | Acc: 63.336,94.434,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.834 | Acc: 63.274,94.432,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.833 | Acc: 63.291,94.450,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.833 | Acc: 63.311,94.426,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.833 | Acc: 63.320,94.414,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.833 | Acc: 63.390,94.365,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.833 | Acc: 63.466,94.390,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.835 | Acc: 63.384,94.330,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.835 | Acc: 63.387,94.345,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.835 | Acc: 63.355,94.332,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.490 | Acc: 53.906,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.700 | Acc: 52.716,68.043,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 52.344,67.835,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 52.177,67.956,75.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 0.880 | Acc: 55.469,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.887 | Acc: 61.830,93.452,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.857 | Acc: 62.214,93.921,99.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.851 | Acc: 62.641,93.942,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.856 | Acc: 62.404,93.798,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.854 | Acc: 62.562,93.843,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.854 | Acc: 62.577,93.905,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.852 | Acc: 62.489,93.905,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.848 | Acc: 62.665,93.973,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.846 | Acc: 62.755,94.026,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.839 | Acc: 63.172,94.135,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.838 | Acc: 63.200,94.202,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.837 | Acc: 63.294,94.175,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.838 | Acc: 63.341,94.184,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.838 | Acc: 63.426,94.161,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.839 | Acc: 63.364,94.168,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.839 | Acc: 63.340,94.135,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.839 | Acc: 63.334,94.133,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.839 | Acc: 63.338,94.207,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.840 | Acc: 63.244,94.181,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.473 | Acc: 53.906,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.712 | Acc: 52.418,68.043,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.740 | Acc: 52.153,67.912,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.715 | Acc: 52.100,67.956,75.141,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 0.780 | Acc: 63.281,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.811 | Acc: 63.728,94.457,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.824 | Acc: 63.758,94.531,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.833 | Acc: 63.678,94.314,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.832 | Acc: 63.850,94.358,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.833 | Acc: 63.753,94.400,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.833 | Acc: 63.798,94.389,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.836 | Acc: 63.680,94.249,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.832 | Acc: 63.796,94.245,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.832 | Acc: 63.799,94.290,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.835 | Acc: 63.701,94.139,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.835 | Acc: 63.670,94.118,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.834 | Acc: 63.612,94.149,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.834 | Acc: 63.616,94.208,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.835 | Acc: 63.598,94.195,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.834 | Acc: 63.533,94.202,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.834 | Acc: 63.564,94.225,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.835 | Acc: 63.490,94.236,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.835 | Acc: 63.552,94.233,99.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.834 | Acc: 63.572,94.263,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.509 | Acc: 54.688,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.701 | Acc: 52.902,68.118,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.730 | Acc: 52.477,68.026,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.711 | Acc: 52.318,67.969,75.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 0.640 | Acc: 75.000,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.847 | Acc: 62.984,93.973,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.843 | Acc: 63.110,94.150,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.841 | Acc: 63.486,94.121,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.836 | Acc: 63.638,94.348,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.841 | Acc: 63.529,94.315,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.844 | Acc: 63.307,94.215,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 63.154,94.127,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.849 | Acc: 63.126,94.167,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 63.087,94.134,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.849 | Acc: 63.056,94.143,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.844 | Acc: 63.189,94.234,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.842 | Acc: 63.262,94.285,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.841 | Acc: 63.299,94.319,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.839 | Acc: 63.323,94.339,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 63.377,94.313,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.839 | Acc: 63.432,94.332,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.839 | Acc: 63.382,94.334,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.838 | Acc: 63.411,94.360,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.839 | Acc: 63.427,94.363,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.479 | Acc: 52.344,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.707 | Acc: 52.381,67.783,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 52.115,67.569,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 52.126,67.751,75.320,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 0.919 | Acc: 59.375,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.830 | Acc: 64.472,94.903,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.836 | Acc: 64.272,94.474,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.835 | Acc: 63.998,94.365,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.838 | Acc: 63.628,94.309,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.833 | Acc: 63.606,94.392,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.834 | Acc: 63.540,94.467,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.829 | Acc: 63.647,94.609,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.830 | Acc: 63.694,94.560,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.829 | Acc: 63.704,94.587,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.829 | Acc: 63.794,94.527,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.834 | Acc: 63.575,94.397,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.835 | Acc: 63.489,94.411,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.835 | Acc: 63.512,94.352,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.836 | Acc: 63.570,94.317,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.837 | Acc: 63.541,94.274,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.835 | Acc: 63.547,94.332,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.835 | Acc: 63.533,94.348,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.836 | Acc: 63.545,94.311,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.836 | Acc: 63.488,94.314,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.511 | Acc: 53.906,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.709 | Acc: 52.641,67.894,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.736 | Acc: 52.210,67.835,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 52.177,67.930,74.962,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 0.932 | Acc: 54.688,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.850 | Acc: 62.351,93.378,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.834 | Acc: 63.014,94.131,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.841 | Acc: 62.974,94.198,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.845 | Acc: 62.944,93.953,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.841 | Acc: 63.258,94.083,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.842 | Acc: 63.243,94.066,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.840 | Acc: 63.198,94.143,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.836 | Acc: 63.286,94.114,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.833 | Acc: 63.445,94.190,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.836 | Acc: 63.273,94.240,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.835 | Acc: 63.345,94.199,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.836 | Acc: 63.278,94.184,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.837 | Acc: 63.314,94.127,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.838 | Acc: 63.306,94.098,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.837 | Acc: 63.338,94.087,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.836 | Acc: 63.352,94.139,99.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.836 | Acc: 63.352,94.144,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.836 | Acc: 63.392,94.148,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 63.347,94.101,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.472 | Acc: 54.688,68.750,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 52.493,67.969,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 52.210,67.664,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 52.113,67.674,75.102,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 0.863 | Acc: 61.719,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.847 | Acc: 62.351,94.754,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.837 | Acc: 62.671,94.779,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.839 | Acc: 62.999,94.698,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.829 | Acc: 63.329,94.657,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.835 | Acc: 63.304,94.516,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.839 | Acc: 63.010,94.305,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.841 | Acc: 62.810,94.276,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.841 | Acc: 62.718,94.255,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.840 | Acc: 62.711,94.238,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.838 | Acc: 62.850,94.267,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.840 | Acc: 62.751,94.284,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 62.821,94.259,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.841 | Acc: 62.850,94.220,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.842 | Acc: 62.842,94.209,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 62.879,94.204,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.840 | Acc: 62.955,94.178,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 62.993,94.144,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.838 | Acc: 63.095,94.153,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.839 | Acc: 63.113,94.162,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.490 | Acc: 54.688,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.701 | Acc: 52.641,68.080,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.729 | Acc: 52.191,67.702,75.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.704 | Acc: 52.203,67.789,75.448,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 0.906 | Acc: 57.812,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.867 | Acc: 60.975,93.824,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.854 | Acc: 62.157,94.169,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.844 | Acc: 62.718,94.096,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.839 | Acc: 63.079,94.280,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.835 | Acc: 63.366,94.330,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.837 | Acc: 63.494,94.137,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 63.470,94.071,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.836 | Acc: 63.548,94.133,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.834 | Acc: 63.570,94.177,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 63.678,94.251,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.834 | Acc: 63.649,94.245,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.835 | Acc: 63.664,94.155,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.835 | Acc: 63.622,94.118,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.836 | Acc: 63.484,94.109,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.837 | Acc: 63.437,94.139,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.837 | Acc: 63.456,94.096,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.837 | Acc: 63.526,94.117,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.837 | Acc: 63.452,94.148,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.839 | Acc: 63.335,94.154,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.470 | Acc: 55.469,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 52.865,67.485,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.725 | Acc: 52.344,67.340,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.701 | Acc: 52.254,67.495,75.435,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 0.771 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.806 | Acc: 64.100,94.717,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.823 | Acc: 63.910,94.684,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.827 | Acc: 63.665,94.775,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 63.339,94.743,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.836 | Acc: 63.250,94.562,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.836 | Acc: 63.281,94.441,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.832 | Acc: 63.531,94.465,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.832 | Acc: 63.500,94.473,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.832 | Acc: 63.614,94.423,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 63.678,94.368,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.835 | Acc: 63.465,94.280,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.835 | Acc: 63.398,94.288,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.836 | Acc: 63.449,94.295,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.836 | Acc: 63.434,94.281,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.836 | Acc: 63.429,94.261,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.835 | Acc: 63.447,94.293,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.835 | Acc: 63.476,94.314,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.835 | Acc: 63.476,94.276,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.835 | Acc: 63.501,94.289,99.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.538 | Acc: 53.906,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.714 | Acc: 52.493,67.783,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.741 | Acc: 52.344,67.435,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.713 | Acc: 52.267,67.508,74.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 0.782 | Acc: 70.312,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.831 | Acc: 64.807,94.606,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.832 | Acc: 64.520,94.722,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.837 | Acc: 63.947,94.518,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.835 | Acc: 63.985,94.493,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.837 | Acc: 63.800,94.346,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.839 | Acc: 63.882,94.176,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 63.680,94.166,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.841 | Acc: 63.514,94.172,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.836 | Acc: 63.691,94.277,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.836 | Acc: 63.728,94.205,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.835 | Acc: 63.705,94.256,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.834 | Acc: 63.690,94.223,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.835 | Acc: 63.682,94.241,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.835 | Acc: 63.707,94.281,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.835 | Acc: 63.793,94.264,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.837 | Acc: 63.668,94.256,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.837 | Acc: 63.591,94.270,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.836 | Acc: 63.653,94.256,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.837 | Acc: 63.585,94.269,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.526 | Acc: 54.688,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.714 | Acc: 52.753,68.155,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.742 | Acc: 52.363,67.816,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.719 | Acc: 52.318,67.841,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 0.975 | Acc: 53.125,89.844,100.000,% | Adaptive Acc: 90.625% | clf_exit: 0.406 0.492 0.102
Batch: 20 | Loss: 0.835 | Acc: 64.211,93.824,99.851,% | Adaptive Acc: 93.266% | clf_exit: 0.460 0.466 0.074
Batch: 40 | Loss: 0.847 | Acc: 63.415,93.864,99.809,% | Adaptive Acc: 92.873% | clf_exit: 0.456 0.474 0.070
Batch: 60 | Loss: 0.844 | Acc: 63.512,93.929,99.808,% | Adaptive Acc: 92.943% | clf_exit: 0.456 0.474 0.069
Batch: 80 | Loss: 0.839 | Acc: 63.619,93.895,99.836,% | Adaptive Acc: 92.814% | clf_exit: 0.460 0.473 0.067
Batch: 100 | Loss: 0.838 | Acc: 63.560,93.881,99.814,% | Adaptive Acc: 92.636% | clf_exit: 0.461 0.473 0.066
Batch: 120 | Loss: 0.836 | Acc: 63.662,93.873,99.839,% | Adaptive Acc: 92.659% | clf_exit: 0.464 0.470 0.067
Batch: 140 | Loss: 0.833 | Acc: 63.863,93.933,99.839,% | Adaptive Acc: 92.642% | clf_exit: 0.466 0.469 0.065
Batch: 160 | Loss: 0.833 | Acc: 63.752,94.085,99.830,% | Adaptive Acc: 92.809% | clf_exit: 0.463 0.472 0.064
Batch: 180 | Loss: 0.832 | Acc: 63.683,94.095,99.827,% | Adaptive Acc: 92.826% | clf_exit: 0.464 0.472 0.064
Batch: 200 | Loss: 0.833 | Acc: 63.507,94.108,99.833,% | Adaptive Acc: 92.774% | clf_exit: 0.462 0.475 0.063
Batch: 220 | Loss: 0.830 | Acc: 63.744,94.149,99.834,% | Adaptive Acc: 92.799% | clf_exit: 0.462 0.475 0.063
Batch: 240 | Loss: 0.832 | Acc: 63.654,94.120,99.828,% | Adaptive Acc: 92.709% | clf_exit: 0.461 0.476 0.063
Batch: 260 | Loss: 0.834 | Acc: 63.473,94.085,99.823,% | Adaptive Acc: 92.663% | clf_exit: 0.460 0.476 0.064
Batch: 280 | Loss: 0.836 | Acc: 63.406,94.103,99.830,% | Adaptive Acc: 92.646% | clf_exit: 0.459 0.478 0.063
Batch: 300 | Loss: 0.834 | Acc: 63.421,94.183,99.839,% | Adaptive Acc: 92.691% | clf_exit: 0.459 0.479 0.063
Batch: 320 | Loss: 0.834 | Acc: 63.437,94.159,99.842,% | Adaptive Acc: 92.694% | clf_exit: 0.459 0.479 0.063
Batch: 340 | Loss: 0.835 | Acc: 63.373,94.172,99.840,% | Adaptive Acc: 92.696% | clf_exit: 0.459 0.479 0.063
Batch: 360 | Loss: 0.835 | Acc: 63.331,94.178,99.840,% | Adaptive Acc: 92.718% | clf_exit: 0.458 0.479 0.063
Batch: 380 | Loss: 0.836 | Acc: 63.322,94.119,99.844,% | Adaptive Acc: 92.735% | clf_exit: 0.458 0.479 0.063
Batch: 0 | Loss: 2.463 | Acc: 54.688,69.531,78.906,% | Adaptive Acc: 71.875% | clf_exit: 0.461 0.391 0.148
Batch: 20 | Loss: 2.698 | Acc: 52.827,67.969,75.595,% | Adaptive Acc: 68.266% | clf_exit: 0.479 0.361 0.160
Batch: 40 | Loss: 2.723 | Acc: 52.477,67.816,75.095,% | Adaptive Acc: 68.064% | clf_exit: 0.481 0.357 0.162
Batch: 60 | Loss: 2.702 | Acc: 52.485,67.892,75.256,% | Adaptive Acc: 68.122% | clf_exit: 0.478 0.358 0.163
model is save as models/modelG_2con3_cifar100_adaptive0_circles5_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 6.410 | Acc: 54.688,21.875,21.875,% | Adaptive Acc: 48.438% | clf_exit: 0.461 0.000 0.539
Batch: 20 | Loss: 6.482 | Acc: 52.827,21.838,17.522,% | Adaptive Acc: 45.089% | clf_exit: 0.479 0.000 0.520
Batch: 40 | Loss: 6.468 | Acc: 52.477,23.304,18.540,% | Adaptive Acc: 45.560% | clf_exit: 0.481 0.001 0.518
Batch: 60 | Loss: 6.456 | Acc: 52.485,23.066,18.199,% | Adaptive Acc: 44.980% | clf_exit: 0.478 0.001 0.521
Batch: 0 | Loss: 4.372 | Acc: 54.688,48.438,52.344,% | Adaptive Acc: 58.594% | clf_exit: 0.461 0.008 0.531
Batch: 20 | Loss: 4.632 | Acc: 52.827,50.372,49.182,% | Adaptive Acc: 56.808% | clf_exit: 0.479 0.020 0.500
Batch: 40 | Loss: 4.634 | Acc: 52.477,50.915,49.028,% | Adaptive Acc: 56.402% | clf_exit: 0.481 0.020 0.499
Batch: 60 | Loss: 4.627 | Acc: 52.485,51.076,49.155,% | Adaptive Acc: 56.071% | clf_exit: 0.478 0.020 0.502
Batch: 0 | Loss: 3.246 | Acc: 54.688,63.281,66.406,% | Adaptive Acc: 67.188% | clf_exit: 0.461 0.109 0.430
Batch: 20 | Loss: 3.522 | Acc: 52.827,62.612,65.699,% | Adaptive Acc: 65.104% | clf_exit: 0.479 0.100 0.421
Batch: 40 | Loss: 3.533 | Acc: 52.477,62.367,65.244,% | Adaptive Acc: 64.653% | clf_exit: 0.481 0.094 0.425
Batch: 60 | Loss: 3.526 | Acc: 52.485,62.372,65.523,% | Adaptive Acc: 64.575% | clf_exit: 0.478 0.093 0.428
Batch: 0 | Loss: 2.682 | Acc: 54.688,64.844,77.344,% | Adaptive Acc: 74.219% | clf_exit: 0.461 0.266 0.273
Batch: 20 | Loss: 2.908 | Acc: 52.827,66.518,72.991,% | Adaptive Acc: 68.936% | clf_exit: 0.479 0.205 0.316
Batch: 40 | Loss: 2.923 | Acc: 52.477,66.178,72.790,% | Adaptive Acc: 68.274% | clf_exit: 0.481 0.199 0.320
Batch: 60 | Loss: 2.916 | Acc: 52.485,66.137,72.900,% | Adaptive Acc: 68.263% | clf_exit: 0.478 0.197 0.324
Batch: 0 | Loss: 2.444 | Acc: 54.688,67.188,79.688,% | Adaptive Acc: 75.000% | clf_exit: 0.461 0.312 0.227
Batch: 20 | Loss: 2.646 | Acc: 52.827,67.485,74.963,% | Adaptive Acc: 69.382% | clf_exit: 0.479 0.288 0.233
Batch: 40 | Loss: 2.663 | Acc: 52.477,67.511,74.676,% | Adaptive Acc: 68.807% | clf_exit: 0.481 0.286 0.233
Batch: 60 | Loss: 2.651 | Acc: 52.485,67.585,74.834,% | Adaptive Acc: 68.929% | clf_exit: 0.478 0.288 0.234
Batch: 0 | Loss: 2.463 | Acc: 54.688,69.531,78.906,% | Adaptive Acc: 71.875% | clf_exit: 0.461 0.391 0.148
Batch: 20 | Loss: 2.698 | Acc: 52.827,67.969,75.595,% | Adaptive Acc: 68.266% | clf_exit: 0.479 0.361 0.160
Batch: 40 | Loss: 2.723 | Acc: 52.477,67.816,75.095,% | Adaptive Acc: 68.064% | clf_exit: 0.481 0.357 0.162
Batch: 60 | Loss: 2.702 | Acc: 52.485,67.892,75.256,% | Adaptive Acc: 68.122% | clf_exit: 0.478 0.358 0.163







Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 7.932 |  Acc: 4.802,7.216,15.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 7.256 |  Acc: 6.620,10.830,22.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 6.823 |  Acc: 9.346,14.076,28.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 6.412 |  Acc: 9.890,16.190,32.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 6.080 |  Acc: 13.574,19.826,36.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 5.821 |  Acc: 14.240,19.310,39.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 5.531 |  Acc: 16.918,23.732,42.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 5.531 |  Acc: 17.700,21.560,42.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 5.113 |  Acc: 20.234,27.108,47.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 5.137 |  Acc: 19.670,24.970,48.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 4.768 |  Acc: 22.562,30.370,51.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 4.809 |  Acc: 21.360,28.190,52.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 4.514 |  Acc: 24.406,32.572,55.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 4.691 |  Acc: 22.080,30.450,52.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 4.283 |  Acc: 25.808,35.146,58.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 4.547 |  Acc: 23.610,30.620,55.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 4.096 |  Acc: 27.534,37.334,60.304,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 4.444 |  Acc: 24.090,32.610,57.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 3.924 |  Acc: 28.820,39.192,62.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 4.145 |  Acc: 27.280,35.600,59.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 3.777 |  Acc: 29.748,40.848,64.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 4.287 |  Acc: 24.950,35.990,59.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 3.640 |  Acc: 30.926,42.464,66.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 3.979 |  Acc: 27.270,39.400,62.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 3.520 |  Acc: 31.866,44.094,68.140,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 3.956 |  Acc: 28.670,39.240,62.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 3.399 |  Acc: 32.596,45.536,70.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 3.922 |  Acc: 28.180,42.320,62.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 3.309 |  Acc: 33.340,46.594,71.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 3.834 |  Acc: 30.300,43.200,63.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 3.200 |  Acc: 33.940,48.348,73.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 3.783 |  Acc: 30.210,45.900,64.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 3.114 |  Acc: 34.840,49.210,74.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 3.715 |  Acc: 32.130,45.660,64.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 3.046 |  Acc: 35.268,50.320,75.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 3.756 |  Acc: 32.160,43.460,64.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 2.985 |  Acc: 35.904,51.354,76.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 3.616 |  Acc: 33.040,46.250,65.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 2.907 |  Acc: 36.350,52.162,77.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 3.662 |  Acc: 31.950,46.170,65.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 2.840 |  Acc: 36.900,53.132,78.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 3.558 |  Acc: 33.870,47.840,66.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 2.779 |  Acc: 37.202,54.072,79.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 3.571 |  Acc: 33.920,48.250,65.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 2.731 |  Acc: 37.726,54.744,79.884,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 3.583 |  Acc: 34.360,47.880,66.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 2.670 |  Acc: 38.290,55.228,80.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 3.575 |  Acc: 34.610,49.580,66.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 2.637 |  Acc: 38.550,55.776,81.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 3.558 |  Acc: 33.190,49.860,67.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 2.587 |  Acc: 39.048,56.102,82.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 3.453 |  Acc: 35.780,51.590,66.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 2.536 |  Acc: 39.470,57.376,82.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 3.471 |  Acc: 34.940,51.530,67.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 2.505 |  Acc: 39.920,57.576,83.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 3.525 |  Acc: 34.900,51.080,66.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 2.483 |  Acc: 39.956,58.336,83.506,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 3.456 |  Acc: 36.890,52.750,66.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 2.444 |  Acc: 40.340,58.820,84.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 3.543 |  Acc: 35.130,52.000,67.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 2.407 |  Acc: 40.838,59.208,84.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 3.473 |  Acc: 34.940,52.830,66.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 2.382 |  Acc: 41.224,59.668,85.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 3.615 |  Acc: 34.270,51.860,65.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 2.370 |  Acc: 41.150,59.914,85.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 3.441 |  Acc: 36.880,53.130,66.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 2.348 |  Acc: 41.390,60.138,85.348,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 3.440 |  Acc: 36.250,53.080,67.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 2.303 |  Acc: 41.808,60.886,86.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 3.426 |  Acc: 38.050,52.290,67.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 2.301 |  Acc: 41.944,60.902,85.976,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 3.448 |  Acc: 36.860,52.170,66.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 2.271 |  Acc: 42.174,61.434,86.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 3.558 |  Acc: 36.300,51.970,65.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 2.252 |  Acc: 42.582,61.672,86.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 3.509 |  Acc: 37.750,52.500,67.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 2.231 |  Acc: 42.788,61.716,87.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 3.473 |  Acc: 37.670,52.000,66.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 2.227 |  Acc: 42.610,61.794,87.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 3.399 |  Acc: 36.640,54.490,67.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 2.202 |  Acc: 43.054,62.570,87.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 3.346 |  Acc: 38.860,54.920,67.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 2.182 |  Acc: 43.360,62.630,87.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 3.408 |  Acc: 38.300,55.060,67.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 2.171 |  Acc: 43.494,62.808,87.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 3.473 |  Acc: 38.240,53.640,66.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 2.170 |  Acc: 43.656,62.792,87.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 3.504 |  Acc: 36.590,51.380,66.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 2.149 |  Acc: 43.540,63.378,88.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 3.355 |  Acc: 39.930,55.300,67.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 2.130 |  Acc: 43.956,63.586,88.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 3.328 |  Acc: 39.540,55.180,68.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 2.138 |  Acc: 44.154,63.650,88.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 3.492 |  Acc: 37.440,53.080,66.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 2.119 |  Acc: 44.264,64.018,88.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 3.368 |  Acc: 38.990,55.220,67.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 2.101 |  Acc: 44.248,64.194,88.662,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 3.421 |  Acc: 38.330,54.750,67.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 2.092 |  Acc: 44.878,64.576,88.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 3.443 |  Acc: 37.990,55.930,66.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 2.080 |  Acc: 45.030,64.824,88.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 3.419 |  Acc: 37.530,55.600,68.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 2.071 |  Acc: 44.876,64.922,88.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 3.406 |  Acc: 38.030,56.190,68.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 2.066 |  Acc: 45.066,64.600,88.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 3.321 |  Acc: 40.580,54.850,67.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 2.057 |  Acc: 45.192,65.348,88.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 3.509 |  Acc: 38.890,54.290,65.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 2.039 |  Acc: 45.348,65.422,89.192,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 3.527 |  Acc: 37.360,54.010,67.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 2.055 |  Acc: 45.328,65.060,88.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 3.484 |  Acc: 38.220,54.710,66.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 2.031 |  Acc: 45.584,65.432,89.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 3.325 |  Acc: 41.100,56.570,67.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 2.033 |  Acc: 45.536,65.792,88.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 3.468 |  Acc: 38.440,55.410,66.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 2.016 |  Acc: 45.728,66.242,89.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 3.534 |  Acc: 38.030,54.490,65.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 2.022 |  Acc: 45.738,65.834,88.976,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 3.414 |  Acc: 38.080,56.220,67.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 2.003 |  Acc: 46.016,66.096,89.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 3.308 |  Acc: 39.260,57.240,68.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 1.989 |  Acc: 46.168,66.550,89.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 3.294 |  Acc: 41.400,56.630,67.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 1.981 |  Acc: 46.016,66.572,89.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 3.418 |  Acc: 38.800,55.790,67.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 1.974 |  Acc: 46.298,66.720,90.008,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 3.428 |  Acc: 38.600,56.200,67.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 1.990 |  Acc: 46.464,66.320,89.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 3.552 |  Acc: 36.680,54.940,66.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 1.981 |  Acc: 46.484,66.584,89.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 3.415 |  Acc: 38.340,56.900,67.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 1.966 |  Acc: 46.676,66.766,89.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 3.413 |  Acc: 38.470,55.220,67.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 1.979 |  Acc: 46.486,66.636,89.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 3.305 |  Acc: 40.910,58.150,67.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 1.961 |  Acc: 46.812,66.746,89.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 3.422 |  Acc: 40.490,55.140,66.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 1.942 |  Acc: 46.874,67.104,90.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 3.354 |  Acc: 38.380,57.750,68.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 1.941 |  Acc: 46.712,67.374,90.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 3.264 |  Acc: 41.920,58.580,67.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 1.948 |  Acc: 46.772,67.096,89.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 3.332 |  Acc: 40.380,57.330,67.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 1.925 |  Acc: 46.948,67.620,90.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 3.392 |  Acc: 39.170,57.440,68.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 1.943 |  Acc: 46.934,67.288,89.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 3.449 |  Acc: 40.440,56.760,66.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 1.937 |  Acc: 47.268,67.746,89.954,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 3.373 |  Acc: 40.040,56.280,66.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 1.918 |  Acc: 47.392,67.840,90.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 3.257 |  Acc: 40.480,57.910,68.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 1.916 |  Acc: 47.216,67.846,90.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 3.346 |  Acc: 41.080,56.580,66.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 1.916 |  Acc: 47.274,67.984,90.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 3.522 |  Acc: 40.960,55.950,65.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 1.910 |  Acc: 47.740,68.190,90.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 3.579 |  Acc: 36.110,54.650,66.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 1.920 |  Acc: 47.518,67.964,90.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 3.348 |  Acc: 41.230,58.550,66.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 1.900 |  Acc: 47.428,68.260,90.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 3.316 |  Acc: 41.140,57.500,67.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 1.886 |  Acc: 47.770,68.686,90.612,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 3.376 |  Acc: 40.010,58.930,67.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 1.888 |  Acc: 47.952,68.598,90.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 3.369 |  Acc: 39.600,57.660,68.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 1.887 |  Acc: 47.884,68.522,90.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 3.449 |  Acc: 40.480,55.970,67.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 1.880 |  Acc: 48.024,68.314,90.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 3.287 |  Acc: 41.760,58.280,68.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 1.881 |  Acc: 47.762,68.526,90.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 3.503 |  Acc: 38.440,56.260,65.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 1.893 |  Acc: 47.804,68.454,90.252,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 3.414 |  Acc: 42.740,56.550,65.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 1.876 |  Acc: 47.906,68.712,90.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 3.458 |  Acc: 40.280,57.260,66.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 1.879 |  Acc: 47.958,68.826,90.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 3.342 |  Acc: 40.770,59.260,67.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 1.869 |  Acc: 48.292,69.170,90.512,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 3.375 |  Acc: 40.620,58.240,67.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 1.862 |  Acc: 47.968,69.106,90.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 3.333 |  Acc: 42.730,58.430,67.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 1.867 |  Acc: 48.258,68.636,90.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 3.490 |  Acc: 40.190,55.720,66.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 1.858 |  Acc: 48.540,68.770,90.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 3.374 |  Acc: 40.200,59.130,67.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 1.850 |  Acc: 48.478,69.152,90.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 3.351 |  Acc: 40.930,57.320,67.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 1.855 |  Acc: 48.264,69.190,90.746,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 3.375 |  Acc: 41.210,57.200,66.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 1.862 |  Acc: 48.488,69.016,90.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 3.425 |  Acc: 39.750,57.760,67.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 1.852 |  Acc: 48.338,69.174,90.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 3.321 |  Acc: 43.700,58.680,66.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 1.830 |  Acc: 48.896,69.526,91.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 3.493 |  Acc: 38.100,56.400,67.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 1.846 |  Acc: 48.538,69.358,90.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 3.361 |  Acc: 40.140,58.800,68.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 1.842 |  Acc: 48.724,69.544,90.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 3.367 |  Acc: 40.290,58.630,67.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 1.830 |  Acc: 48.818,69.564,91.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 3.321 |  Acc: 41.290,58.420,67.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 1.846 |  Acc: 48.650,69.286,90.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 3.351 |  Acc: 41.440,58.710,67.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 1.832 |  Acc: 48.768,69.482,91.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 3.256 |  Acc: 42.900,59.450,67.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 1.839 |  Acc: 48.960,69.640,90.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 3.519 |  Acc: 39.070,56.560,65.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 1.839 |  Acc: 49.008,69.626,90.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 3.462 |  Acc: 40.040,56.840,67.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 1.826 |  Acc: 48.912,69.786,90.976,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 3.339 |  Acc: 42.950,59.210,67.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 1.824 |  Acc: 49.120,69.632,90.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 3.336 |  Acc: 41.190,57.430,67.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 1.824 |  Acc: 48.834,69.744,90.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 3.401 |  Acc: 40.390,58.260,67.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 1.824 |  Acc: 49.120,69.634,91.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 3.418 |  Acc: 40.580,57.870,67.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 1.823 |  Acc: 49.154,70.034,91.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 3.534 |  Acc: 39.430,55.920,66.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 1.802 |  Acc: 49.338,69.978,91.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 3.341 |  Acc: 40.510,59.050,68.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 1.832 |  Acc: 49.068,69.506,90.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 3.315 |  Acc: 40.120,60.210,67.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 1.813 |  Acc: 49.130,70.092,91.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 3.390 |  Acc: 42.240,58.570,66.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 1.811 |  Acc: 49.392,69.816,91.008,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 3.305 |  Acc: 42.430,59.200,68.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 1.813 |  Acc: 49.090,70.046,91.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 3.293 |  Acc: 41.650,58.770,68.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 1.809 |  Acc: 49.300,70.220,90.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 3.328 |  Acc: 43.580,59.970,67.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 1.795 |  Acc: 49.404,70.142,91.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 3.340 |  Acc: 43.500,57.690,66.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 1.815 |  Acc: 49.194,70.150,90.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 3.358 |  Acc: 42.280,57.680,67.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 1.793 |  Acc: 49.638,70.262,91.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 3.333 |  Acc: 42.270,58.880,67.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 1.801 |  Acc: 49.376,70.390,91.146,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 3.422 |  Acc: 39.500,57.970,66.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 1.801 |  Acc: 49.558,70.282,91.174,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 3.403 |  Acc: 40.660,58.330,66.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 1.818 |  Acc: 49.638,70.030,90.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 3.397 |  Acc: 42.980,57.730,67.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 1.791 |  Acc: 49.612,70.546,91.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 3.397 |  Acc: 41.930,57.640,67.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 1.790 |  Acc: 49.800,70.438,91.250,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 3.358 |  Acc: 41.660,58.590,67.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 1.802 |  Acc: 49.784,70.280,90.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 3.296 |  Acc: 43.300,58.960,68.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 1.796 |  Acc: 49.762,70.460,91.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 3.263 |  Acc: 41.990,60.700,67.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 1.773 |  Acc: 49.982,70.752,91.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 3.355 |  Acc: 42.420,57.600,68.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 1.788 |  Acc: 50.042,70.596,91.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 3.316 |  Acc: 42.260,58.880,67.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 1.784 |  Acc: 49.810,70.512,91.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 3.510 |  Acc: 40.900,55.330,66.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 1.780 |  Acc: 49.950,70.804,91.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 3.358 |  Acc: 40.510,58.530,68.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 1.784 |  Acc: 49.916,70.916,91.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 3.329 |  Acc: 43.630,58.370,67.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 1.756 |  Acc: 49.956,71.010,91.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 3.432 |  Acc: 41.710,57.070,67.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 1.788 |  Acc: 49.900,70.570,91.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 3.325 |  Acc: 43.570,58.530,66.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 1.789 |  Acc: 50.010,70.380,91.158,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 3.302 |  Acc: 41.740,59.550,67.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 1.763 |  Acc: 50.248,70.994,91.608,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 3.356 |  Acc: 42.090,59.140,67.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 1.771 |  Acc: 49.918,70.656,91.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 3.334 |  Acc: 42.550,58.430,67.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 1.780 |  Acc: 50.048,70.754,91.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 3.382 |  Acc: 41.460,58.440,66.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 1.771 |  Acc: 50.062,70.874,91.394,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 3.203 |  Acc: 42.250,60.530,68.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 1.789 |  Acc: 50.080,70.706,90.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 3.467 |  Acc: 41.470,57.610,66.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 1.784 |  Acc: 49.872,70.682,91.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 3.377 |  Acc: 41.850,58.140,67.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 1.754 |  Acc: 50.346,71.174,91.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 3.345 |  Acc: 40.660,59.470,68.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 1.760 |  Acc: 50.190,70.914,91.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 3.285 |  Acc: 43.910,58.750,68.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 1.760 |  Acc: 50.372,71.150,91.450,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 3.356 |  Acc: 43.320,59.300,67.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 1.769 |  Acc: 50.286,70.822,91.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 3.219 |  Acc: 43.700,59.990,68.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 1.755 |  Acc: 50.574,71.146,91.544,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 3.545 |  Acc: 39.780,57.040,65.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 1.768 |  Acc: 50.274,71.016,91.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 3.279 |  Acc: 42.590,58.820,68.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 1.765 |  Acc: 50.318,70.964,91.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 3.303 |  Acc: 42.910,58.370,67.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 1.759 |  Acc: 50.638,71.342,91.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 3.524 |  Acc: 40.970,57.580,67.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 1.772 |  Acc: 50.258,71.010,91.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 3.214 |  Acc: 44.110,60.200,68.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 1.761 |  Acc: 50.540,71.054,91.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 3.347 |  Acc: 42.800,58.890,67.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 1.406 |  Acc: 54.578,78.302,96.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 2.651 |  Acc: 49.740,67.410,74.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 1.282 |  Acc: 55.994,81.136,98.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 2.617 |  Acc: 50.530,68.180,74.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.244 |  Acc: 56.356,81.866,98.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 2.592 |  Acc: 50.480,68.310,75.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.220 |  Acc: 56.408,82.446,98.874,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 2.592 |  Acc: 50.710,68.880,75.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.199 |  Acc: 56.828,82.944,99.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 2.599 |  Acc: 50.890,68.730,75.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.185 |  Acc: 57.158,83.306,99.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 2.589 |  Acc: 50.650,68.670,75.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.171 |  Acc: 57.058,83.558,99.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 2.592 |  Acc: 50.750,68.520,75.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.157 |  Acc: 57.356,83.854,99.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 2.587 |  Acc: 50.740,68.690,75.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.152 |  Acc: 57.328,84.172,99.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 2.589 |  Acc: 51.060,68.440,75.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.144 |  Acc: 57.494,84.214,99.434,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 2.595 |  Acc: 50.950,68.670,75.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 1.131 |  Acc: 57.864,84.682,99.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 2.589 |  Acc: 50.970,68.730,75.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.124 |  Acc: 57.922,84.810,99.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 2.584 |  Acc: 51.050,68.730,75.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.112 |  Acc: 57.960,85.132,99.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 2.600 |  Acc: 51.000,68.940,76.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.107 |  Acc: 57.990,85.236,99.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 2.597 |  Acc: 50.790,68.700,75.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.102 |  Acc: 58.130,85.442,99.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 2.606 |  Acc: 51.280,68.970,75.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.094 |  Acc: 58.368,85.660,99.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 2.594 |  Acc: 51.260,68.820,75.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.092 |  Acc: 58.248,85.784,99.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 2.593 |  Acc: 51.060,68.520,75.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.084 |  Acc: 58.370,85.862,99.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 2.599 |  Acc: 51.030,68.510,75.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.076 |  Acc: 58.346,86.158,99.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 2.600 |  Acc: 51.110,68.530,75.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.071 |  Acc: 58.632,86.330,99.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 2.607 |  Acc: 51.310,68.370,75.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.065 |  Acc: 58.544,86.420,99.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 2.620 |  Acc: 51.570,68.420,75.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.062 |  Acc: 58.752,86.616,99.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 2.610 |  Acc: 50.820,68.480,75.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.059 |  Acc: 58.610,86.732,99.608,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 2.613 |  Acc: 51.290,68.630,75.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.054 |  Acc: 58.958,86.688,99.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 2.623 |  Acc: 51.360,68.640,76.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.048 |  Acc: 59.038,86.886,99.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 2.603 |  Acc: 51.200,68.910,76.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.044 |  Acc: 58.962,87.054,99.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 2.611 |  Acc: 51.510,68.820,75.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.040 |  Acc: 58.960,87.278,99.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 2.617 |  Acc: 51.520,68.750,75.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.044 |  Acc: 58.922,87.082,99.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 2.641 |  Acc: 51.000,68.280,75.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.034 |  Acc: 59.260,87.356,99.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 2.634 |  Acc: 51.770,68.320,75.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.030 |  Acc: 59.092,87.508,99.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 2.627 |  Acc: 51.380,67.570,75.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.028 |  Acc: 59.338,87.562,99.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 2.634 |  Acc: 51.580,68.480,75.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.026 |  Acc: 59.248,87.540,99.642,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 2.632 |  Acc: 51.070,68.140,75.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.022 |  Acc: 59.312,87.760,99.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 2.623 |  Acc: 51.500,68.680,75.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.016 |  Acc: 59.470,87.896,99.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 2.621 |  Acc: 51.520,68.430,75.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.017 |  Acc: 59.500,88.076,99.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 2.642 |  Acc: 51.280,68.360,75.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.014 |  Acc: 59.506,88.006,99.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 2.643 |  Acc: 51.700,68.580,75.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.008 |  Acc: 59.504,88.238,99.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 2.645 |  Acc: 51.590,68.260,75.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.006 |  Acc: 59.688,88.210,99.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 2.629 |  Acc: 51.970,68.520,75.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.005 |  Acc: 59.632,88.252,99.662,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 2.653 |  Acc: 51.610,68.350,75.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 0.998 |  Acc: 59.740,88.788,99.662,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 2.648 |  Acc: 51.510,68.600,75.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 0.994 |  Acc: 59.900,88.476,99.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 2.668 |  Acc: 51.400,68.070,75.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 0.997 |  Acc: 59.662,88.540,99.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 2.649 |  Acc: 51.940,68.330,75.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 0.990 |  Acc: 59.904,88.886,99.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 2.646 |  Acc: 51.580,68.230,75.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 0.985 |  Acc: 60.092,88.794,99.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 2.654 |  Acc: 51.670,67.890,75.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 0.985 |  Acc: 59.936,89.046,99.684,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 2.656 |  Acc: 51.460,67.970,75.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 0.985 |  Acc: 59.966,89.046,99.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 2.662 |  Acc: 51.790,68.500,75.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 0.985 |  Acc: 59.980,88.916,99.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 2.648 |  Acc: 51.650,68.390,75.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 0.980 |  Acc: 60.052,89.188,99.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 2.656 |  Acc: 51.260,68.050,75.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 0.978 |  Acc: 60.212,89.152,99.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 2.677 |  Acc: 51.500,67.680,75.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 0.972 |  Acc: 60.284,89.378,99.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 2.672 |  Acc: 51.240,67.870,75.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 0.974 |  Acc: 60.386,89.344,99.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 2.660 |  Acc: 51.890,68.310,75.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 0.971 |  Acc: 60.240,89.292,99.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 2.673 |  Acc: 51.420,68.110,75.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 0.969 |  Acc: 60.320,89.412,99.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 2.679 |  Acc: 52.150,67.910,75.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 0.964 |  Acc: 60.190,89.508,99.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 2.673 |  Acc: 51.660,68.290,75.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 0.966 |  Acc: 60.420,89.580,99.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 2.676 |  Acc: 51.660,67.990,75.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 0.961 |  Acc: 60.376,89.572,99.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 2.678 |  Acc: 51.280,67.730,75.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 0.959 |  Acc: 60.658,89.614,99.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 2.680 |  Acc: 51.540,68.070,75.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 0.957 |  Acc: 60.542,89.732,99.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 2.690 |  Acc: 52.110,67.600,75.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 0.958 |  Acc: 60.422,89.868,99.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 2.685 |  Acc: 51.520,68.050,75.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 0.958 |  Acc: 60.566,89.730,99.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 2.686 |  Acc: 51.120,67.940,75.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 0.953 |  Acc: 60.566,89.818,99.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 2.708 |  Acc: 51.090,67.410,75.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 0.950 |  Acc: 60.640,90.252,99.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 2.686 |  Acc: 51.760,67.900,75.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 0.951 |  Acc: 60.664,90.106,99.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 2.686 |  Acc: 51.890,67.950,75.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 0.945 |  Acc: 60.738,90.296,99.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 2.692 |  Acc: 51.700,68.230,75.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 0.949 |  Acc: 60.540,90.070,99.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 2.705 |  Acc: 51.360,67.440,75.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 0.945 |  Acc: 60.840,90.114,99.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 2.700 |  Acc: 51.330,67.540,75.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 0.941 |  Acc: 60.840,90.158,99.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 2.704 |  Acc: 52.030,67.430,75.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 0.939 |  Acc: 61.070,90.362,99.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 2.706 |  Acc: 51.240,67.230,75.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 0.938 |  Acc: 60.876,90.452,99.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 2.706 |  Acc: 51.840,68.030,75.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 0.938 |  Acc: 60.986,90.446,99.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 2.706 |  Acc: 51.650,67.700,75.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 0.941 |  Acc: 60.868,90.354,99.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 2.718 |  Acc: 51.220,68.110,75.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 0.933 |  Acc: 61.102,90.518,99.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 2.698 |  Acc: 51.820,67.790,75.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 0.933 |  Acc: 61.026,90.500,99.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 2.714 |  Acc: 51.260,67.360,75.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 0.933 |  Acc: 61.214,90.790,99.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 2.708 |  Acc: 52.140,67.500,75.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 0.928 |  Acc: 61.240,90.862,99.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 2.696 |  Acc: 51.580,67.260,75.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 0.883 |  Acc: 62.280,92.526,99.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 2.659 |  Acc: 52.590,68.620,75.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 0.871 |  Acc: 62.638,92.780,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 2.658 |  Acc: 52.870,68.580,75.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 0.871 |  Acc: 62.734,93.104,99.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 2.657 |  Acc: 52.720,68.590,75.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 0.868 |  Acc: 62.616,93.254,99.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 2.661 |  Acc: 52.810,68.570,75.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 0.865 |  Acc: 62.436,93.226,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 2.675 |  Acc: 52.610,68.510,75.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 0.861 |  Acc: 62.872,93.298,99.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 2.662 |  Acc: 52.600,68.510,75.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 0.864 |  Acc: 62.840,93.304,99.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 2.657 |  Acc: 52.650,68.490,75.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 0.865 |  Acc: 62.682,93.272,99.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 2.667 |  Acc: 52.690,68.360,75.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 0.861 |  Acc: 62.802,93.452,99.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 2.664 |  Acc: 52.890,68.360,75.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 0.864 |  Acc: 62.530,93.158,99.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 2.667 |  Acc: 52.580,68.480,75.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 0.861 |  Acc: 62.750,93.428,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 2.675 |  Acc: 52.700,68.540,75.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 0.858 |  Acc: 62.778,93.486,99.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 2.682 |  Acc: 52.660,68.430,75.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 0.857 |  Acc: 63.018,93.356,99.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 2.663 |  Acc: 52.810,68.560,75.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 0.854 |  Acc: 62.906,93.648,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 2.669 |  Acc: 52.490,68.370,75.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 0.855 |  Acc: 62.928,93.618,99.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 2.669 |  Acc: 52.720,68.360,75.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 0.855 |  Acc: 62.892,93.674,99.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 2.677 |  Acc: 52.650,68.530,75.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 0.858 |  Acc: 62.810,93.492,99.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 2.662 |  Acc: 52.560,68.450,75.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 0.855 |  Acc: 62.858,93.580,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 2.664 |  Acc: 52.700,68.430,75.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 0.851 |  Acc: 63.016,93.694,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 2.672 |  Acc: 52.540,68.530,75.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 0.853 |  Acc: 62.974,93.742,99.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 2.671 |  Acc: 52.520,68.500,75.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 0.852 |  Acc: 62.924,93.592,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 2.678 |  Acc: 52.640,68.520,75.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 0.854 |  Acc: 62.814,93.718,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 2.675 |  Acc: 52.490,68.220,75.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 0.851 |  Acc: 63.220,93.796,99.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 2.669 |  Acc: 52.640,68.310,75.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 0.850 |  Acc: 63.036,93.796,99.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 2.669 |  Acc: 52.490,68.300,75.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 0.852 |  Acc: 63.058,93.814,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 2.673 |  Acc: 52.630,68.350,75.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 0.851 |  Acc: 62.930,93.684,99.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 2.663 |  Acc: 52.510,68.320,75.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 0.849 |  Acc: 63.008,93.820,99.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 2.675 |  Acc: 52.700,68.390,75.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 0.848 |  Acc: 62.956,93.808,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 2.678 |  Acc: 52.650,68.300,75.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 0.848 |  Acc: 63.214,93.902,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 2.677 |  Acc: 52.740,68.360,75.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 0.847 |  Acc: 63.150,93.844,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 2.667 |  Acc: 52.670,68.180,75.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 0.847 |  Acc: 63.302,93.850,99.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 2.669 |  Acc: 52.640,68.260,75.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 0.846 |  Acc: 63.182,93.994,99.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 2.677 |  Acc: 52.570,68.270,75.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 0.844 |  Acc: 63.160,93.902,99.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 2.673 |  Acc: 52.670,68.390,75.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 0.846 |  Acc: 63.102,93.880,99.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 2.672 |  Acc: 52.550,68.290,75.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 0.846 |  Acc: 63.096,93.928,99.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 2.668 |  Acc: 52.440,68.460,75.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 0.844 |  Acc: 63.236,93.944,99.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 2.678 |  Acc: 52.690,68.150,75.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 0.850 |  Acc: 62.902,93.868,99.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 2.678 |  Acc: 52.600,68.440,75.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 0.842 |  Acc: 63.244,94.144,99.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 2.676 |  Acc: 52.590,68.310,75.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 0.842 |  Acc: 63.170,94.016,99.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 2.676 |  Acc: 52.840,68.370,75.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 0.838 |  Acc: 63.396,94.272,99.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 2.679 |  Acc: 52.710,68.320,75.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 0.838 |  Acc: 63.258,94.168,99.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 2.669 |  Acc: 52.800,68.270,75.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 0.839 |  Acc: 63.144,94.154,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 2.675 |  Acc: 52.730,68.290,75.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 0.839 |  Acc: 63.272,94.066,99.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 2.673 |  Acc: 52.710,68.140,75.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 0.840 |  Acc: 63.410,94.122,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 2.678 |  Acc: 52.630,68.390,75.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 0.839 |  Acc: 63.362,94.248,99.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 2.681 |  Acc: 52.670,68.320,75.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 0.837 |  Acc: 63.482,94.244,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 2.682 |  Acc: 52.790,68.300,75.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 0.838 |  Acc: 63.542,94.244,99.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 2.677 |  Acc: 52.770,68.380,75.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 0.837 |  Acc: 63.238,94.302,99.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 2.680 |  Acc: 52.690,68.230,75.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 0.841 |  Acc: 63.010,94.122,99.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 2.680 |  Acc: 52.580,68.220,75.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 0.841 |  Acc: 63.230,94.202,99.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 2.674 |  Acc: 52.800,68.550,75.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 0.839 |  Acc: 63.270,94.070,99.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 2.673 |  Acc: 52.820,68.330,75.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 0.837 |  Acc: 63.392,94.118,99.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 2.675 |  Acc: 52.670,68.360,75.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 0.836 |  Acc: 63.428,94.260,99.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 2.676 |  Acc: 52.720,68.130,75.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 0.838 |  Acc: 63.458,94.308,99.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 2.676 |  Acc: 52.770,68.460,75.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 0.837 |  Acc: 63.524,94.160,99.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 2.674 |  Acc: 52.590,68.240,75.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 0.838 |  Acc: 63.288,94.208,99.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 2.679 |  Acc: 52.750,68.420,75.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 0.836 |  Acc: 63.388,94.394,99.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 2.684 |  Acc: 52.690,68.300,75.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 0.837 |  Acc: 63.308,94.394,99.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 2.681 |  Acc: 52.580,68.440,75.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 0.838 |  Acc: 63.474,94.244,99.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 2.677 |  Acc: 52.650,68.400,75.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 0.837 |  Acc: 63.444,94.394,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 2.673 |  Acc: 52.720,68.480,75.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 0.836 |  Acc: 63.444,94.264,99.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 2.676 |  Acc: 52.500,68.280,75.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 0.838 |  Acc: 63.322,94.216,99.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 2.678 |  Acc: 52.760,68.530,75.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 0.840 |  Acc: 63.380,94.150,99.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 2.671 |  Acc: 52.680,68.380,75.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 0.837 |  Acc: 63.532,94.328,99.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 2.675 |  Acc: 52.520,68.340,75.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 0.835 |  Acc: 63.340,94.346,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 2.674 |  Acc: 52.590,68.500,75.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 0.841 |  Acc: 63.246,94.182,99.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 2.682 |  Acc: 52.610,68.450,75.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 0.834 |  Acc: 63.552,94.290,99.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 2.675 |  Acc: 52.770,68.510,75.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 0.839 |  Acc: 63.414,94.364,99.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 2.677 |  Acc: 52.500,68.260,75.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 0.838 |  Acc: 63.416,94.286,99.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 2.684 |  Acc: 52.610,68.410,75.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 0.838 |  Acc: 63.318,94.092,99.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 2.675 |  Acc: 52.450,68.270,75.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 0.839 |  Acc: 63.114,94.148,99.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 2.669 |  Acc: 52.720,68.310,75.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 0.838 |  Acc: 63.336,94.150,99.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 2.667 |  Acc: 52.630,68.080,75.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 0.835 |  Acc: 63.482,94.290,99.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 2.677 |  Acc: 52.620,68.000,75.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 0.838 |  Acc: 63.534,94.276,99.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 2.685 |  Acc: 52.720,68.340,75.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=1.0, adaptive=0, backend='modelG_2con3', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', flops_str='', gamma=0.5, ge=1, lmbda=0.0, lmbda_e=0.9, loss_type='knowledge_distillation', max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 0.836 |  Acc: 63.350,94.122,99.842,% | Adaptive Acc:92.750% | clf_exit: 0.458 0.478 0.064
Testing: Epoch=299 | Loss: 2.666 |  Acc: 52.860,68.410,75.610,% | Adaptive Acc:68.630% | clf_exit: 0.480 0.359 0.161

circles: 0
Testing: Epoch=299 | Loss: 6.435 |  Acc: 52.860,23.330,18.250,% | Adaptive Acc:45.220% | clf_exit: 0.480 0.001 0.519
circles: 1
Testing: Epoch=299 | Loss: 4.600 |  Acc: 52.860,51.410,49.410,% | Adaptive Acc:56.360% | clf_exit: 0.480 0.020 0.500
circles: 2
Testing: Epoch=299 | Loss: 3.496 |  Acc: 52.860,62.650,65.970,% | Adaptive Acc:64.790% | clf_exit: 0.480 0.092 0.428
circles: 3
Testing: Epoch=299 | Loss: 2.884 |  Acc: 52.860,66.660,73.120,% | Adaptive Acc:68.550% | clf_exit: 0.480 0.197 0.323
circles: 4
Testing: Epoch=299 | Loss: 2.619 |  Acc: 52.860,68.090,75.180,% | Adaptive Acc:69.300% | clf_exit: 0.480 0.288 0.232
circles: 5
Testing: Epoch=299 | Loss: 2.666 |  Acc: 52.860,68.410,75.610,% | Adaptive Acc:68.630% | clf_exit: 0.480 0.359 0.161
