
Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 12.077 |  Acc: 6.754,10.068,13.040,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=0 | Loss: 11.206 |  Acc: 9.070,13.940,18.830,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 10.476 |  Acc: 11.478,18.316,24.334,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=1 | Loss: 9.883 |  Acc: 12.940,21.040,28.060,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 9.357 |  Acc: 15.304,24.690,33.172,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=2 | Loss: 8.970 |  Acc: 16.380,26.140,35.540,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 8.542 |  Acc: 19.100,29.928,39.850,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=3 | Loss: 8.365 |  Acc: 19.450,30.280,40.290,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 7.915 |  Acc: 22.384,33.958,44.724,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=4 | Loss: 7.770 |  Acc: 21.950,33.520,46.800,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 7.418 |  Acc: 24.830,37.390,49.128,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=5 | Loss: 7.501 |  Acc: 22.950,35.550,48.530,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 7.032 |  Acc: 26.796,40.344,52.468,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=6 | Loss: 7.120 |  Acc: 25.390,37.730,51.630,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 6.682 |  Acc: 28.638,43.122,55.550,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=7 | Loss: 6.912 |  Acc: 25.260,39.850,53.210,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 6.404 |  Acc: 29.914,45.228,57.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=8 | Loss: 6.749 |  Acc: 26.030,41.960,54.710,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 6.143 |  Acc: 31.122,47.382,60.508,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=9 | Loss: 6.407 |  Acc: 27.710,44.970,57.720,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 5.919 |  Acc: 32.312,49.132,62.412,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=10 | Loss: 6.427 |  Acc: 26.810,45.190,58.620,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 5.731 |  Acc: 33.698,50.480,64.292,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=11 | Loss: 6.184 |  Acc: 30.630,46.440,58.930,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 5.561 |  Acc: 34.632,52.128,66.224,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=12 | Loss: 5.982 |  Acc: 31.860,48.430,60.410,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 5.389 |  Acc: 35.474,53.468,67.826,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=13 | Loss: 5.884 |  Acc: 31.980,49.420,61.420,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 5.259 |  Acc: 36.172,54.376,69.278,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=14 | Loss: 5.941 |  Acc: 31.230,49.870,62.030,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 5.124 |  Acc: 37.172,55.812,70.616,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=15 | Loss: 5.822 |  Acc: 32.750,50.050,61.240,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 5.008 |  Acc: 37.748,56.634,71.776,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=16 | Loss: 5.656 |  Acc: 34.520,50.580,63.370,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 4.897 |  Acc: 38.462,57.346,73.250,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=17 | Loss: 5.721 |  Acc: 33.800,51.980,62.920,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.797 |  Acc: 38.828,58.374,74.088,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=18 | Loss: 5.529 |  Acc: 34.390,53.030,63.830,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.711 |  Acc: 39.510,58.712,75.016,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=19 | Loss: 5.521 |  Acc: 35.660,53.340,64.430,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.619 |  Acc: 40.018,59.674,76.142,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=20 | Loss: 5.567 |  Acc: 33.960,53.400,64.440,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.541 |  Acc: 40.524,60.324,77.052,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=21 | Loss: 5.673 |  Acc: 34.800,51.530,63.310,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 4.449 |  Acc: 40.884,61.176,78.236,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=22 | Loss: 5.388 |  Acc: 36.300,54.470,65.550,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 4.386 |  Acc: 41.206,61.464,78.816,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=23 | Loss: 5.405 |  Acc: 34.190,54.830,66.170,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 4.334 |  Acc: 41.544,62.020,79.240,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=24 | Loss: 5.215 |  Acc: 37.320,56.220,66.910,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 4.238 |  Acc: 41.966,62.814,80.624,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=25 | Loss: 5.321 |  Acc: 36.400,55.380,66.820,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 4.199 |  Acc: 42.296,63.418,81.018,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=26 | Loss: 5.248 |  Acc: 38.190,56.340,65.470,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 4.159 |  Acc: 42.536,63.402,81.664,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=27 | Loss: 5.163 |  Acc: 37.920,57.410,66.830,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 4.087 |  Acc: 42.786,64.054,82.492,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=28 | Loss: 5.098 |  Acc: 38.630,57.830,67.340,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 4.032 |  Acc: 43.024,64.796,83.180,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=29 | Loss: 5.243 |  Acc: 37.290,56.630,65.700,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 3.985 |  Acc: 43.586,65.042,83.610,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=30 | Loss: 5.389 |  Acc: 36.190,55.100,65.260,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 3.970 |  Acc: 43.796,65.228,83.826,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=31 | Loss: 5.345 |  Acc: 36.900,56.080,66.670,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 3.913 |  Acc: 44.034,65.582,84.484,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=32 | Loss: 5.258 |  Acc: 38.480,56.570,65.500,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 3.882 |  Acc: 44.398,65.714,84.950,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=33 | Loss: 5.200 |  Acc: 38.450,57.370,66.800,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 3.839 |  Acc: 44.394,66.542,85.468,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=34 | Loss: 5.204 |  Acc: 37.700,57.230,67.070,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 3.809 |  Acc: 44.876,66.808,85.984,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=35 | Loss: 5.198 |  Acc: 38.240,57.360,66.860,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.763 |  Acc: 45.022,66.918,86.480,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=36 | Loss: 5.037 |  Acc: 38.580,59.230,68.510,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.738 |  Acc: 45.014,67.312,86.662,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=37 | Loss: 5.357 |  Acc: 37.550,56.190,66.430,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.711 |  Acc: 45.506,67.828,87.014,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=38 | Loss: 5.131 |  Acc: 38.720,58.130,66.730,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.682 |  Acc: 45.612,67.754,87.436,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=39 | Loss: 5.131 |  Acc: 38.190,58.280,66.960,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.638 |  Acc: 45.748,68.164,88.072,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=40 | Loss: 5.265 |  Acc: 36.340,58.480,66.360,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.634 |  Acc: 45.662,68.148,88.132,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=41 | Loss: 5.237 |  Acc: 37.590,57.500,66.520,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.584 |  Acc: 45.954,69.024,88.530,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=42 | Loss: 5.024 |  Acc: 40.260,59.310,67.270,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.572 |  Acc: 46.134,68.540,88.734,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=43 | Loss: 5.140 |  Acc: 37.790,58.740,67.540,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.530 |  Acc: 46.470,69.124,89.164,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=44 | Loss: 5.249 |  Acc: 38.070,58.380,66.170,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.529 |  Acc: 46.590,69.316,89.080,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=45 | Loss: 5.081 |  Acc: 40.310,59.210,67.000,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.507 |  Acc: 46.572,69.270,89.278,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=46 | Loss: 5.037 |  Acc: 39.200,59.860,66.950,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.484 |  Acc: 46.826,69.622,89.608,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=47 | Loss: 5.052 |  Acc: 39.700,59.780,67.580,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.465 |  Acc: 46.836,69.782,89.934,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=48 | Loss: 5.309 |  Acc: 36.570,57.780,66.310,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.452 |  Acc: 46.990,70.224,89.838,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=49 | Loss: 5.118 |  Acc: 38.640,58.740,66.860,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.431 |  Acc: 47.064,70.286,90.136,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=50 | Loss: 5.066 |  Acc: 40.230,59.550,67.030,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.407 |  Acc: 47.288,70.384,90.516,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=51 | Loss: 5.170 |  Acc: 39.450,58.850,67.190,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.390 |  Acc: 47.280,70.652,90.538,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=52 | Loss: 4.995 |  Acc: 40.030,59.770,68.520,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.380 |  Acc: 47.580,70.838,90.658,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=53 | Loss: 4.989 |  Acc: 39.110,59.800,68.470,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.367 |  Acc: 47.780,70.614,90.944,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=54 | Loss: 5.034 |  Acc: 39.370,60.540,68.420,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.348 |  Acc: 47.598,71.172,90.930,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=55 | Loss: 5.186 |  Acc: 38.390,59.330,66.880,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.336 |  Acc: 47.836,71.326,91.000,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=56 | Loss: 4.904 |  Acc: 42.110,60.600,67.410,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.318 |  Acc: 47.992,71.710,91.252,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=57 | Loss: 4.990 |  Acc: 40.280,60.620,67.380,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.312 |  Acc: 47.914,71.734,91.320,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=58 | Loss: 5.073 |  Acc: 40.310,59.590,66.950,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.299 |  Acc: 48.030,71.598,91.434,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=59 | Loss: 4.914 |  Acc: 42.150,59.960,67.490,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.282 |  Acc: 48.462,71.988,91.412,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=60 | Loss: 5.136 |  Acc: 38.330,59.600,67.780,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.286 |  Acc: 48.046,72.154,91.582,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=61 | Loss: 4.897 |  Acc: 41.660,60.960,68.840,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.274 |  Acc: 48.412,71.978,91.436,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=62 | Loss: 5.064 |  Acc: 40.470,59.980,66.610,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.257 |  Acc: 48.408,72.214,91.904,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=63 | Loss: 5.116 |  Acc: 40.160,59.860,66.890,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 3.254 |  Acc: 48.480,72.150,91.668,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=64 | Loss: 5.021 |  Acc: 40.040,60.080,67.520,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 3.241 |  Acc: 48.508,72.346,91.984,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=65 | Loss: 5.049 |  Acc: 39.270,60.150,67.350,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 3.205 |  Acc: 48.792,72.752,92.214,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=66 | Loss: 5.101 |  Acc: 39.900,60.150,66.800,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 3.216 |  Acc: 48.804,72.604,92.102,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=67 | Loss: 5.050 |  Acc: 40.530,60.810,66.860,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 3.195 |  Acc: 48.952,73.080,92.074,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=68 | Loss: 5.093 |  Acc: 38.550,60.400,68.680,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 3.198 |  Acc: 48.790,73.026,92.298,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=69 | Loss: 5.042 |  Acc: 40.470,61.000,67.580,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 3.189 |  Acc: 49.058,72.800,92.260,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=70 | Loss: 4.784 |  Acc: 44.170,62.160,68.890,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 3.164 |  Acc: 49.070,73.342,92.578,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=71 | Loss: 4.845 |  Acc: 42.430,61.410,67.940,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 3.161 |  Acc: 48.994,73.406,92.402,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=72 | Loss: 5.128 |  Acc: 38.760,59.480,67.290,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 3.160 |  Acc: 49.242,73.530,92.292,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=73 | Loss: 5.065 |  Acc: 39.210,60.270,67.800,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 3.152 |  Acc: 49.542,73.350,92.574,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=74 | Loss: 4.884 |  Acc: 42.450,61.810,68.400,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 3.132 |  Acc: 49.636,73.540,92.588,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=75 | Loss: 4.846 |  Acc: 42.340,61.530,67.880,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 3.133 |  Acc: 49.496,73.864,92.662,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=76 | Loss: 4.860 |  Acc: 42.960,60.900,68.590,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 3.136 |  Acc: 49.314,73.572,92.482,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=77 | Loss: 5.053 |  Acc: 40.300,60.080,67.040,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 3.119 |  Acc: 49.632,73.822,92.896,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=78 | Loss: 4.948 |  Acc: 41.980,61.070,67.440,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 3.098 |  Acc: 49.742,74.098,93.122,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=79 | Loss: 4.919 |  Acc: 43.130,61.830,68.210,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 3.104 |  Acc: 49.772,73.920,92.720,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=80 | Loss: 4.835 |  Acc: 42.740,61.480,67.880,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 3.096 |  Acc: 49.758,74.326,93.024,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=81 | Loss: 4.869 |  Acc: 42.240,62.070,68.240,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 3.091 |  Acc: 50.036,74.270,92.730,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=82 | Loss: 4.750 |  Acc: 43.940,61.610,68.310,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 3.083 |  Acc: 49.954,74.384,92.880,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=83 | Loss: 4.914 |  Acc: 42.350,60.820,67.700,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 3.081 |  Acc: 49.894,74.022,92.932,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=84 | Loss: 4.922 |  Acc: 42.060,60.900,67.910,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 3.062 |  Acc: 49.950,74.676,93.300,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=85 | Loss: 4.820 |  Acc: 43.930,61.490,67.830,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 3.053 |  Acc: 50.078,74.580,93.466,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=86 | Loss: 4.919 |  Acc: 42.170,61.300,67.630,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 3.068 |  Acc: 50.036,74.768,93.004,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=87 | Loss: 4.908 |  Acc: 42.460,61.190,67.410,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 3.064 |  Acc: 50.038,74.688,92.950,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=88 | Loss: 4.855 |  Acc: 43.380,60.910,68.650,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 3.021 |  Acc: 50.536,74.966,93.402,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=89 | Loss: 4.738 |  Acc: 43.240,62.450,68.940,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 3.038 |  Acc: 50.130,74.772,93.148,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=90 | Loss: 4.888 |  Acc: 41.400,61.390,68.010,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 3.019 |  Acc: 50.536,75.004,93.412,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=91 | Loss: 4.921 |  Acc: 42.590,61.610,67.810,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 3.019 |  Acc: 50.516,75.002,93.398,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=92 | Loss: 4.943 |  Acc: 41.730,61.670,67.380,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 3.022 |  Acc: 50.916,75.294,93.082,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=93 | Loss: 4.846 |  Acc: 43.580,61.920,67.920,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 3.023 |  Acc: 50.584,75.012,93.316,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=94 | Loss: 4.840 |  Acc: 43.430,62.040,67.330,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 3.012 |  Acc: 50.464,75.292,93.558,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=95 | Loss: 4.769 |  Acc: 43.310,61.850,67.950,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 3.007 |  Acc: 50.794,75.304,93.252,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=96 | Loss: 4.796 |  Acc: 42.740,62.120,68.670,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 2.998 |  Acc: 50.492,75.390,93.720,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=97 | Loss: 4.817 |  Acc: 43.080,62.460,68.050,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 3.000 |  Acc: 50.666,75.516,93.432,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=98 | Loss: 4.754 |  Acc: 43.660,62.190,68.840,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 2.990 |  Acc: 50.596,75.380,93.638,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=99 | Loss: 4.927 |  Acc: 41.900,61.730,68.070,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 2.971 |  Acc: 51.094,75.598,93.600,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=100 | Loss: 4.807 |  Acc: 43.230,62.360,68.030,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 2.983 |  Acc: 50.928,75.818,93.486,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=101 | Loss: 4.929 |  Acc: 42.860,61.560,67.050,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 3.001 |  Acc: 50.926,75.464,93.126,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=102 | Loss: 4.741 |  Acc: 44.710,62.680,68.520,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 2.982 |  Acc: 50.818,76.064,93.538,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=103 | Loss: 4.782 |  Acc: 43.330,62.440,68.670,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 2.969 |  Acc: 51.086,75.858,93.598,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=104 | Loss: 4.923 |  Acc: 42.660,61.720,66.880,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 2.963 |  Acc: 50.856,75.702,93.614,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=105 | Loss: 4.888 |  Acc: 42.320,61.330,67.660,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 2.951 |  Acc: 51.052,75.960,93.754,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=106 | Loss: 4.809 |  Acc: 43.140,61.840,68.240,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 2.955 |  Acc: 51.054,76.118,93.724,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=107 | Loss: 4.955 |  Acc: 43.140,61.040,66.280,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 2.944 |  Acc: 51.218,76.282,93.738,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=108 | Loss: 4.879 |  Acc: 42.420,62.100,68.540,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 2.930 |  Acc: 51.416,76.218,93.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=109 | Loss: 4.887 |  Acc: 41.670,61.720,67.640,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 2.944 |  Acc: 51.254,76.216,93.838,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=110 | Loss: 4.985 |  Acc: 42.380,61.240,67.330,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 2.931 |  Acc: 51.546,76.502,93.786,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=111 | Loss: 4.869 |  Acc: 42.730,62.070,67.660,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 2.938 |  Acc: 51.098,76.176,93.914,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=112 | Loss: 4.876 |  Acc: 42.340,61.270,67.760,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 2.935 |  Acc: 51.530,76.200,93.790,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=113 | Loss: 4.815 |  Acc: 42.970,62.370,68.350,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 2.909 |  Acc: 51.370,76.618,93.884,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=114 | Loss: 4.830 |  Acc: 43.410,61.990,66.550,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 2.935 |  Acc: 51.558,76.522,93.484,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=115 | Loss: 4.971 |  Acc: 40.030,62.100,68.520,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 2.915 |  Acc: 51.640,76.290,93.884,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=116 | Loss: 4.819 |  Acc: 43.300,61.890,68.420,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 2.928 |  Acc: 51.252,76.398,93.902,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=117 | Loss: 4.920 |  Acc: 41.620,61.350,68.220,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 2.908 |  Acc: 51.640,76.560,93.978,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=118 | Loss: 4.793 |  Acc: 43.140,62.420,68.380,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 2.921 |  Acc: 51.302,76.596,93.658,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=119 | Loss: 4.895 |  Acc: 42.900,61.090,68.300,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 2.909 |  Acc: 51.470,76.670,93.836,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=120 | Loss: 4.904 |  Acc: 41.490,61.710,68.190,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 2.896 |  Acc: 51.476,77.000,93.978,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=121 | Loss: 4.835 |  Acc: 42.230,62.110,68.080,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 2.896 |  Acc: 51.376,76.846,94.058,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=122 | Loss: 4.805 |  Acc: 44.170,62.340,68.010,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 2.907 |  Acc: 51.828,76.770,93.762,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=123 | Loss: 4.819 |  Acc: 44.370,62.030,68.160,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 2.907 |  Acc: 51.648,76.586,93.746,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=124 | Loss: 4.702 |  Acc: 44.540,62.900,68.990,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 2.894 |  Acc: 51.570,76.940,94.056,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=125 | Loss: 4.779 |  Acc: 44.680,62.440,66.840,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 2.882 |  Acc: 51.856,76.950,94.222,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=126 | Loss: 4.783 |  Acc: 42.960,62.640,68.730,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 2.877 |  Acc: 51.776,77.026,94.118,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=127 | Loss: 4.889 |  Acc: 43.980,61.800,67.400,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 2.876 |  Acc: 51.754,77.162,94.124,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=128 | Loss: 4.868 |  Acc: 42.450,61.290,68.220,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 2.874 |  Acc: 51.894,77.200,94.086,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=129 | Loss: 4.855 |  Acc: 44.530,61.530,67.740,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 2.882 |  Acc: 51.770,77.044,93.830,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=130 | Loss: 4.833 |  Acc: 43.380,62.150,67.680,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 2.867 |  Acc: 51.948,77.134,94.176,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=131 | Loss: 4.859 |  Acc: 43.330,62.760,67.260,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 2.860 |  Acc: 52.008,77.350,94.200,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=132 | Loss: 4.801 |  Acc: 44.240,62.510,67.600,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 2.860 |  Acc: 51.976,77.098,94.156,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=133 | Loss: 4.738 |  Acc: 44.100,63.490,68.470,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 2.872 |  Acc: 51.990,77.186,93.866,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=134 | Loss: 4.847 |  Acc: 44.830,61.890,67.170,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 2.873 |  Acc: 51.740,77.018,93.970,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=135 | Loss: 4.757 |  Acc: 44.310,61.920,67.940,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 2.866 |  Acc: 52.092,77.142,94.058,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=136 | Loss: 4.735 |  Acc: 44.810,62.690,67.970,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 2.867 |  Acc: 52.008,77.402,93.824,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=137 | Loss: 4.840 |  Acc: 42.380,62.710,68.510,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 2.854 |  Acc: 52.338,77.444,94.024,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=138 | Loss: 4.750 |  Acc: 44.620,62.490,67.860,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 2.865 |  Acc: 51.904,77.214,93.908,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=139 | Loss: 5.001 |  Acc: 41.290,62.010,67.250,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 2.848 |  Acc: 52.136,77.438,94.114,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=140 | Loss: 4.938 |  Acc: 42.690,60.190,68.060,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 2.816 |  Acc: 52.360,77.880,94.358,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=141 | Loss: 4.828 |  Acc: 43.310,62.370,68.190,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 2.817 |  Acc: 52.444,77.954,94.406,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=142 | Loss: 4.889 |  Acc: 44.110,62.460,66.830,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 2.841 |  Acc: 52.368,77.654,94.070,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=143 | Loss: 5.068 |  Acc: 41.220,59.980,65.910,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 2.839 |  Acc: 52.402,77.784,94.128,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=144 | Loss: 4.766 |  Acc: 45.270,62.280,67.720,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 2.843 |  Acc: 52.482,77.810,93.960,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=145 | Loss: 4.753 |  Acc: 43.880,62.590,67.910,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 2.830 |  Acc: 52.422,78.020,94.390,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=146 | Loss: 4.754 |  Acc: 44.250,62.360,68.010,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 2.848 |  Acc: 52.384,77.544,93.990,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=147 | Loss: 4.780 |  Acc: 44.140,62.810,68.210,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 2.817 |  Acc: 52.362,77.884,94.442,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=148 | Loss: 4.922 |  Acc: 41.970,61.990,67.400,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 2.819 |  Acc: 52.422,77.908,94.222,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=149 | Loss: 4.747 |  Acc: 45.330,62.310,67.920,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.351 |  Acc: 56.234,84.700,98.560,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=150 | Loss: 4.029 |  Acc: 50.010,69.080,74.340,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 2.209 |  Acc: 57.348,86.934,99.540,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=151 | Loss: 4.061 |  Acc: 49.460,69.110,74.480,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 2.160 |  Acc: 57.896,87.716,99.736,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=152 | Loss: 4.017 |  Acc: 50.170,69.360,74.710,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 2.143 |  Acc: 58.084,87.990,99.714,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=153 | Loss: 4.046 |  Acc: 49.740,69.290,74.730,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 2.115 |  Acc: 58.100,88.204,99.806,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=154 | Loss: 4.032 |  Acc: 49.780,69.100,74.820,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 2.102 |  Acc: 58.254,88.670,99.816,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=155 | Loss: 3.990 |  Acc: 50.570,69.100,74.790,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 2.098 |  Acc: 58.124,88.628,99.830,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=156 | Loss: 3.990 |  Acc: 50.110,69.490,74.710,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 2.076 |  Acc: 58.056,89.152,99.866,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=157 | Loss: 3.971 |  Acc: 50.360,69.390,74.860,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 2.071 |  Acc: 58.400,89.216,99.890,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=158 | Loss: 4.020 |  Acc: 50.000,69.210,74.570,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 2.067 |  Acc: 58.106,89.382,99.876,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=159 | Loss: 3.978 |  Acc: 50.450,69.190,75.040,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 2.056 |  Acc: 58.408,89.416,99.908,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=160 | Loss: 3.947 |  Acc: 51.050,69.570,74.580,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 2.043 |  Acc: 58.494,89.610,99.896,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=161 | Loss: 3.992 |  Acc: 50.740,69.120,74.810,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 2.027 |  Acc: 58.810,89.632,99.890,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=162 | Loss: 4.038 |  Acc: 50.120,69.070,74.770,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 2.021 |  Acc: 58.916,89.830,99.894,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=163 | Loss: 4.006 |  Acc: 50.300,69.310,74.770,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 2.016 |  Acc: 58.814,89.938,99.910,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=164 | Loss: 4.029 |  Acc: 50.090,69.590,74.520,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 2.008 |  Acc: 59.102,90.036,99.910,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=165 | Loss: 4.025 |  Acc: 50.630,68.980,74.840,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 2.001 |  Acc: 59.224,90.058,99.928,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=166 | Loss: 3.983 |  Acc: 50.690,69.390,74.820,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.999 |  Acc: 58.920,90.144,99.914,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=167 | Loss: 4.003 |  Acc: 50.350,69.580,74.800,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.985 |  Acc: 59.242,90.422,99.922,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=168 | Loss: 4.018 |  Acc: 50.310,69.320,74.720,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.992 |  Acc: 58.914,90.370,99.922,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=169 | Loss: 4.003 |  Acc: 50.090,69.270,74.770,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.982 |  Acc: 59.304,90.356,99.912,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=170 | Loss: 3.980 |  Acc: 50.920,69.370,74.590,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.964 |  Acc: 59.476,90.590,99.918,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=171 | Loss: 3.974 |  Acc: 50.900,69.060,74.930,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.970 |  Acc: 59.338,90.606,99.924,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=172 | Loss: 4.001 |  Acc: 50.620,69.220,74.910,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.970 |  Acc: 59.072,90.746,99.926,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=173 | Loss: 4.016 |  Acc: 50.710,69.100,74.390,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.965 |  Acc: 59.380,90.808,99.934,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=174 | Loss: 4.012 |  Acc: 50.310,69.270,75.020,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.958 |  Acc: 59.670,90.702,99.922,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=175 | Loss: 4.001 |  Acc: 50.690,69.080,74.490,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.944 |  Acc: 59.694,90.954,99.918,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=176 | Loss: 3.989 |  Acc: 50.500,69.300,75.100,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.954 |  Acc: 59.440,91.176,99.928,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=177 | Loss: 3.995 |  Acc: 50.890,68.940,74.690,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.943 |  Acc: 59.746,91.108,99.944,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=178 | Loss: 3.964 |  Acc: 51.350,69.030,74.730,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.939 |  Acc: 59.710,90.974,99.930,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=179 | Loss: 3.984 |  Acc: 51.090,69.050,74.530,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.939 |  Acc: 59.584,91.150,99.938,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=180 | Loss: 3.957 |  Acc: 51.260,69.130,74.820,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.924 |  Acc: 59.964,91.258,99.938,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=181 | Loss: 4.015 |  Acc: 50.950,69.040,74.540,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.929 |  Acc: 59.536,91.300,99.930,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=182 | Loss: 4.026 |  Acc: 50.460,68.830,74.530,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.932 |  Acc: 59.610,91.276,99.934,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=183 | Loss: 4.022 |  Acc: 50.380,68.900,74.580,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.918 |  Acc: 59.932,91.348,99.920,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=184 | Loss: 3.970 |  Acc: 51.350,69.220,74.460,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.920 |  Acc: 59.958,91.368,99.946,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=185 | Loss: 4.005 |  Acc: 50.700,68.740,74.600,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.916 |  Acc: 59.954,91.358,99.934,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=186 | Loss: 3.984 |  Acc: 51.160,69.270,74.410,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.910 |  Acc: 59.872,91.558,99.942,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=187 | Loss: 3.973 |  Acc: 51.350,68.570,74.430,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.902 |  Acc: 60.164,91.664,99.940,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=188 | Loss: 4.014 |  Acc: 50.430,69.080,74.530,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.896 |  Acc: 60.086,91.598,99.936,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=189 | Loss: 4.022 |  Acc: 50.290,68.900,74.720,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.896 |  Acc: 60.176,91.748,99.946,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=190 | Loss: 4.000 |  Acc: 51.070,68.610,74.790,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.896 |  Acc: 60.268,91.500,99.950,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=191 | Loss: 3.990 |  Acc: 50.930,68.780,74.830,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.906 |  Acc: 60.016,91.482,99.944,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=192 | Loss: 3.979 |  Acc: 51.280,68.680,74.700,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.899 |  Acc: 60.148,91.710,99.944,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=193 | Loss: 4.021 |  Acc: 50.890,68.740,74.330,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.883 |  Acc: 60.380,91.762,99.938,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=194 | Loss: 3.986 |  Acc: 51.570,68.710,74.670,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.886 |  Acc: 60.432,91.674,99.952,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=195 | Loss: 3.980 |  Acc: 51.390,69.140,74.490,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.884 |  Acc: 60.416,92.058,99.954,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=196 | Loss: 4.006 |  Acc: 51.250,68.490,74.340,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.887 |  Acc: 60.202,91.842,99.952,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=197 | Loss: 3.976 |  Acc: 51.090,69.050,74.660,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.888 |  Acc: 60.200,91.830,99.952,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=198 | Loss: 4.041 |  Acc: 50.740,68.580,74.660,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.883 |  Acc: 60.454,92.006,99.936,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=199 | Loss: 4.018 |  Acc: 51.010,68.660,74.540,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.877 |  Acc: 60.336,91.990,99.940,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=200 | Loss: 3.986 |  Acc: 51.160,68.640,74.530,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.879 |  Acc: 60.430,91.968,99.940,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=201 | Loss: 3.997 |  Acc: 51.350,68.440,74.420,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.871 |  Acc: 60.410,92.012,99.940,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=202 | Loss: 4.069 |  Acc: 49.950,68.190,74.360,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.869 |  Acc: 60.476,92.184,99.934,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=203 | Loss: 4.023 |  Acc: 50.910,68.450,74.640,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.863 |  Acc: 60.530,92.026,99.948,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=204 | Loss: 4.049 |  Acc: 50.550,68.360,74.800,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.862 |  Acc: 60.504,92.198,99.946,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=205 | Loss: 3.990 |  Acc: 51.440,68.690,74.330,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.871 |  Acc: 60.390,91.856,99.926,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=206 | Loss: 4.054 |  Acc: 50.220,68.310,74.480,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.867 |  Acc: 60.530,91.978,99.956,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=207 | Loss: 4.046 |  Acc: 50.770,68.780,74.310,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.865 |  Acc: 60.610,92.078,99.946,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=208 | Loss: 4.008 |  Acc: 51.270,68.820,74.300,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.852 |  Acc: 60.844,92.198,99.952,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=209 | Loss: 4.028 |  Acc: 51.250,68.350,74.520,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.857 |  Acc: 60.686,92.238,99.948,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=210 | Loss: 4.054 |  Acc: 50.590,68.540,74.450,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.860 |  Acc: 60.586,92.074,99.948,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=211 | Loss: 4.021 |  Acc: 51.630,67.860,74.140,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.851 |  Acc: 60.606,92.330,99.934,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=212 | Loss: 4.040 |  Acc: 51.570,68.080,74.230,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.847 |  Acc: 60.782,92.294,99.938,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=213 | Loss: 4.046 |  Acc: 51.040,67.880,74.330,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.856 |  Acc: 60.714,92.144,99.954,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=214 | Loss: 3.981 |  Acc: 51.730,68.750,74.460,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.853 |  Acc: 60.894,92.232,99.934,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=215 | Loss: 4.057 |  Acc: 51.080,68.190,74.300,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.851 |  Acc: 60.550,92.166,99.950,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=216 | Loss: 4.076 |  Acc: 50.640,68.020,74.300,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.845 |  Acc: 60.994,92.376,99.942,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=217 | Loss: 4.094 |  Acc: 49.880,68.060,74.290,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.846 |  Acc: 60.806,92.248,99.914,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=218 | Loss: 4.015 |  Acc: 51.590,67.970,74.150,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.840 |  Acc: 60.914,92.290,99.940,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=219 | Loss: 4.065 |  Acc: 50.960,67.540,74.320,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.839 |  Acc: 61.042,92.454,99.942,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=220 | Loss: 3.987 |  Acc: 51.780,68.430,74.230,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.843 |  Acc: 60.964,92.500,99.942,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=221 | Loss: 4.081 |  Acc: 50.190,67.820,74.330,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.842 |  Acc: 60.780,92.194,99.962,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=222 | Loss: 4.040 |  Acc: 50.980,68.040,74.140,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.836 |  Acc: 60.988,92.340,99.940,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=223 | Loss: 4.064 |  Acc: 50.970,67.230,74.270,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.845 |  Acc: 60.706,92.334,99.946,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=224 | Loss: 4.015 |  Acc: 51.460,68.280,74.350,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.742 |  Acc: 62.262,94.376,99.960,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=225 | Loss: 3.966 |  Acc: 52.000,68.960,74.750,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.732 |  Acc: 62.194,94.750,99.958,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=226 | Loss: 3.964 |  Acc: 52.150,68.990,74.330,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.719 |  Acc: 62.368,94.868,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=227 | Loss: 3.969 |  Acc: 52.050,68.980,74.660,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.720 |  Acc: 62.340,95.094,99.974,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=228 | Loss: 3.920 |  Acc: 52.520,69.260,74.430,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.719 |  Acc: 62.354,95.140,99.974,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=229 | Loss: 3.934 |  Acc: 52.340,69.240,74.660,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.714 |  Acc: 62.402,95.064,99.956,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=230 | Loss: 3.934 |  Acc: 52.110,69.230,74.520,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.717 |  Acc: 62.346,95.050,99.976,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=231 | Loss: 3.981 |  Acc: 51.630,69.100,74.570,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.716 |  Acc: 62.224,95.172,99.958,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=232 | Loss: 3.951 |  Acc: 52.330,69.060,74.400,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.722 |  Acc: 62.194,95.098,99.970,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=233 | Loss: 3.960 |  Acc: 52.210,69.150,74.570,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.723 |  Acc: 61.988,95.132,99.966,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=234 | Loss: 3.957 |  Acc: 52.150,69.130,74.380,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.722 |  Acc: 62.150,95.086,99.984,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=235 | Loss: 3.951 |  Acc: 52.140,69.080,74.430,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.712 |  Acc: 62.462,95.110,99.966,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=236 | Loss: 3.927 |  Acc: 52.410,69.000,74.470,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.710 |  Acc: 62.246,95.360,99.972,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=237 | Loss: 4.020 |  Acc: 51.150,68.870,74.450,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.709 |  Acc: 62.454,95.296,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=238 | Loss: 3.957 |  Acc: 52.140,68.930,74.360,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.710 |  Acc: 62.402,95.294,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=239 | Loss: 3.946 |  Acc: 52.370,69.160,74.600,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.711 |  Acc: 62.250,95.144,99.964,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=240 | Loss: 3.973 |  Acc: 52.050,68.920,74.430,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.710 |  Acc: 62.090,95.334,99.964,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=241 | Loss: 3.925 |  Acc: 52.340,68.870,74.490,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.713 |  Acc: 62.130,95.290,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=242 | Loss: 3.992 |  Acc: 51.750,68.990,74.440,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.712 |  Acc: 62.062,95.296,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=243 | Loss: 3.931 |  Acc: 52.330,69.110,74.480,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.712 |  Acc: 62.320,95.392,99.970,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=244 | Loss: 3.966 |  Acc: 51.920,68.880,74.530,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.704 |  Acc: 62.468,95.378,99.974,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=245 | Loss: 3.927 |  Acc: 52.320,68.970,74.230,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.706 |  Acc: 62.436,95.378,99.964,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=246 | Loss: 3.931 |  Acc: 52.630,69.210,74.460,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.701 |  Acc: 62.542,95.450,99.966,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=247 | Loss: 3.974 |  Acc: 51.800,68.860,74.190,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.694 |  Acc: 62.728,95.436,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=248 | Loss: 3.963 |  Acc: 52.130,68.840,74.390,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.707 |  Acc: 62.416,95.324,99.966,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=249 | Loss: 3.956 |  Acc: 52.070,68.790,74.500,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.710 |  Acc: 62.204,95.458,99.960,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=250 | Loss: 3.965 |  Acc: 52.260,68.770,74.400,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.710 |  Acc: 62.140,95.236,99.970,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=251 | Loss: 3.960 |  Acc: 52.210,68.810,74.600,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.708 |  Acc: 62.296,95.338,99.966,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=252 | Loss: 3.951 |  Acc: 52.440,68.820,74.520,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.706 |  Acc: 62.388,95.370,99.976,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=253 | Loss: 3.911 |  Acc: 52.680,69.000,74.380,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.705 |  Acc: 62.416,95.432,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=254 | Loss: 3.926 |  Acc: 52.610,69.020,74.560,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.700 |  Acc: 62.346,95.472,99.956,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=255 | Loss: 3.960 |  Acc: 52.210,69.170,74.380,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.702 |  Acc: 62.412,95.366,99.978,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=256 | Loss: 3.976 |  Acc: 51.930,68.880,74.530,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.705 |  Acc: 62.348,95.512,99.964,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=257 | Loss: 3.937 |  Acc: 52.400,69.030,74.490,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.696 |  Acc: 62.464,95.538,99.974,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=258 | Loss: 3.990 |  Acc: 51.720,69.050,74.540,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.699 |  Acc: 62.486,95.646,99.960,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=259 | Loss: 3.962 |  Acc: 52.070,68.870,74.550,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.698 |  Acc: 62.620,95.424,99.974,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=260 | Loss: 4.015 |  Acc: 51.510,68.960,74.350,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.696 |  Acc: 62.468,95.584,99.972,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=261 | Loss: 3.968 |  Acc: 52.190,69.030,74.530,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.699 |  Acc: 62.398,95.636,99.966,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=262 | Loss: 3.958 |  Acc: 52.270,69.240,74.540,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.693 |  Acc: 62.516,95.680,99.990,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=263 | Loss: 4.007 |  Acc: 51.490,69.030,74.510,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.681 |  Acc: 62.770,95.772,99.976,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=264 | Loss: 3.960 |  Acc: 52.280,69.210,74.540,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.680 |  Acc: 62.748,95.776,99.978,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=265 | Loss: 3.962 |  Acc: 52.190,69.090,74.450,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.692 |  Acc: 62.406,95.674,99.982,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=266 | Loss: 3.964 |  Acc: 52.130,69.210,74.550,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.682 |  Acc: 62.796,95.812,99.972,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=267 | Loss: 3.932 |  Acc: 52.650,68.920,74.390,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.695 |  Acc: 62.542,95.688,99.974,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=268 | Loss: 3.959 |  Acc: 52.280,69.100,74.340,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.691 |  Acc: 62.358,95.640,99.972,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=269 | Loss: 3.952 |  Acc: 52.490,68.950,74.410,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.684 |  Acc: 62.758,95.808,99.970,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=270 | Loss: 3.996 |  Acc: 51.500,68.980,74.450,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.689 |  Acc: 62.418,95.778,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=271 | Loss: 3.941 |  Acc: 52.470,68.980,74.570,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.678 |  Acc: 62.904,95.714,99.960,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=272 | Loss: 3.993 |  Acc: 51.670,68.920,74.500,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.682 |  Acc: 62.594,95.854,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=273 | Loss: 3.990 |  Acc: 51.800,68.930,74.500,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.684 |  Acc: 62.764,95.972,99.982,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=274 | Loss: 3.952 |  Acc: 52.250,68.920,74.350,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.686 |  Acc: 62.904,95.610,99.966,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=275 | Loss: 4.005 |  Acc: 51.520,68.820,74.370,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.685 |  Acc: 62.720,95.794,99.966,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=276 | Loss: 3.917 |  Acc: 52.810,69.240,74.570,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.681 |  Acc: 62.796,95.872,99.972,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=277 | Loss: 3.976 |  Acc: 52.040,69.070,74.490,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.679 |  Acc: 62.822,95.844,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=278 | Loss: 3.980 |  Acc: 51.930,69.020,74.570,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.689 |  Acc: 62.554,95.942,99.978,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=279 | Loss: 3.924 |  Acc: 52.640,69.030,74.560,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.675 |  Acc: 62.840,95.790,99.978,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=280 | Loss: 3.965 |  Acc: 52.200,69.080,74.370,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.683 |  Acc: 62.684,95.768,99.980,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=281 | Loss: 4.001 |  Acc: 51.560,68.740,74.350,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.685 |  Acc: 62.720,95.708,99.976,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=282 | Loss: 3.993 |  Acc: 51.880,68.930,74.550,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.683 |  Acc: 62.720,95.880,99.972,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=283 | Loss: 3.975 |  Acc: 51.990,68.850,74.480,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.675 |  Acc: 62.720,95.756,99.960,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=284 | Loss: 3.990 |  Acc: 51.750,69.040,74.450,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.689 |  Acc: 62.380,95.710,99.978,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=285 | Loss: 4.009 |  Acc: 51.340,68.950,74.510,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.678 |  Acc: 62.816,95.880,99.978,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=286 | Loss: 4.001 |  Acc: 51.490,68.950,74.450,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.683 |  Acc: 62.606,95.796,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=287 | Loss: 3.978 |  Acc: 52.070,68.980,74.470,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.683 |  Acc: 62.644,95.890,99.974,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=288 | Loss: 3.966 |  Acc: 52.140,68.920,74.360,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.684 |  Acc: 62.674,95.750,99.976,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=289 | Loss: 3.935 |  Acc: 52.530,69.020,74.550,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.678 |  Acc: 62.940,95.756,99.976,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=290 | Loss: 4.021 |  Acc: 51.330,68.850,74.380,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.676 |  Acc: 62.884,95.860,99.970,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=291 | Loss: 3.974 |  Acc: 52.200,68.920,74.410,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.683 |  Acc: 62.742,95.860,99.978,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=292 | Loss: 3.989 |  Acc: 51.720,69.010,74.450,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.678 |  Acc: 62.668,95.830,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=293 | Loss: 3.935 |  Acc: 52.620,68.920,74.510,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.686 |  Acc: 62.634,95.844,99.970,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=294 | Loss: 3.941 |  Acc: 52.350,69.110,74.440,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.682 |  Acc: 62.656,95.786,99.976,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=295 | Loss: 3.974 |  Acc: 52.010,69.060,74.610,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.691 |  Acc: 62.552,95.786,99.968,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=296 | Loss: 3.995 |  Acc: 51.730,68.990,74.380,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.683 |  Acc: 62.604,95.660,99.970,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=297 | Loss: 3.979 |  Acc: 52.100,68.820,74.560,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.689 |  Acc: 62.498,95.742,99.976,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 
Testing: Epoch=298 | Loss: 3.948 |  Acc: 52.250,69.170,74.550,% | Adaptive Acc:0.000% | clf_exit: nan nan nan 

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=1, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.681 |  Acc: 62.690,95.846,99.980,% | Adaptive Acc:94.496% | clf_exit: 0.428 0.486 0.087 
Testing: Epoch=299 | Loss: 3.977 |  Acc: 51.960,69.170,74.450,% | Adaptive Acc:71.170% | clf_exit: 0.339 0.429 0.232 

==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32x1x1])
      (FBconv): ConvTranspose2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(288, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=64, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=64, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 13.961 | Acc: 2.344,1.562,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.604 | Acc: 1.935,3.051,4.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.412 | Acc: 2.591,3.982,5.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.258 | Acc: 3.202,4.790,6.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.128 | Acc: 3.559,5.228,7.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.017 | Acc: 4.022,5.763,7.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.918 | Acc: 4.197,6.082,8.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.828 | Acc: 4.405,6.427,8.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.744 | Acc: 4.726,6.750,9.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.676 | Acc: 4.908,6.984,9.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.601 | Acc: 5.146,7.416,9.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.527 | Acc: 5.345,7.876,10.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.475 | Acc: 5.491,8.107,10.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.412 | Acc: 5.621,8.405,11.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.360 | Acc: 5.769,8.605,11.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.304 | Acc: 6.009,8.879,11.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.248 | Acc: 6.150,9.124,11.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.193 | Acc: 6.369,9.467,12.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.148 | Acc: 6.521,9.700,12.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.101 | Acc: 6.654,9.929,12.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.047 | Acc: 9.375,14.062,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.224 | Acc: 9.859,13.951,19.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.208 | Acc: 9.527,13.929,19.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.223 | Acc: 9.080,13.781,19.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 11.521 | Acc: 7.031,14.844,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.133 | Acc: 9.115,14.583,19.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.021 | Acc: 10.080,15.587,20.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.986 | Acc: 9.887,15.702,20.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.944 | Acc: 9.983,15.557,20.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.938 | Acc: 9.878,15.486,20.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.912 | Acc: 10.046,15.470,21.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.871 | Acc: 10.156,15.769,21.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.825 | Acc: 10.321,15.916,21.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.791 | Acc: 10.519,16.285,21.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.756 | Acc: 10.514,16.523,22.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.728 | Acc: 10.460,16.537,22.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.693 | Acc: 10.685,16.688,22.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.660 | Acc: 10.863,17.053,22.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.632 | Acc: 10.968,17.293,23.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.606 | Acc: 11.044,17.452,23.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.574 | Acc: 11.164,17.645,23.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.549 | Acc: 11.281,17.820,23.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.518 | Acc: 11.355,18.016,24.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.488 | Acc: 11.436,18.217,24.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.106 | Acc: 14.844,21.875,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.945 | Acc: 13.914,21.540,27.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.917 | Acc: 13.072,21.075,27.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.909 | Acc: 12.999,21.299,27.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 9.618 | Acc: 12.500,23.438,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.868 | Acc: 13.728,22.470,29.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.806 | Acc: 14.196,22.485,29.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.727 | Acc: 14.536,23.028,30.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.682 | Acc: 14.361,23.042,30.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.655 | Acc: 14.202,23.182,30.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.633 | Acc: 14.372,23.295,30.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.609 | Acc: 14.439,23.316,31.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.597 | Acc: 14.359,23.287,31.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.570 | Acc: 14.593,23.520,31.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.555 | Acc: 14.661,23.612,31.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.529 | Acc: 14.773,23.773,31.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.495 | Acc: 14.828,24.018,32.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.487 | Acc: 14.766,24.009,32.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.472 | Acc: 14.872,24.105,32.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.445 | Acc: 14.989,24.221,32.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.422 | Acc: 15.097,24.355,32.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.398 | Acc: 15.114,24.510,32.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.380 | Acc: 15.274,24.587,33.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.364 | Acc: 15.328,24.670,33.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.154 | Acc: 18.750,28.125,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.027 | Acc: 17.039,26.376,35.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.005 | Acc: 16.502,26.143,35.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.012 | Acc: 16.457,26.140,35.182,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 8.664 | Acc: 18.750,32.812,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.778 | Acc: 16.592,28.274,37.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.773 | Acc: 17.245,28.163,38.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.757 | Acc: 17.623,28.458,38.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.761 | Acc: 17.718,28.221,38.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.783 | Acc: 17.830,28.295,38.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.742 | Acc: 18.104,28.583,38.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.740 | Acc: 17.991,28.496,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.718 | Acc: 18.163,28.620,38.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.710 | Acc: 18.288,28.591,38.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.685 | Acc: 18.365,28.778,38.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.674 | Acc: 18.396,28.871,38.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.660 | Acc: 18.500,29.062,38.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.644 | Acc: 18.636,29.197,38.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.632 | Acc: 18.669,29.209,39.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.615 | Acc: 18.714,29.345,39.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.599 | Acc: 18.789,29.473,39.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.574 | Acc: 18.908,29.662,39.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.563 | Acc: 18.973,29.781,39.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.545 | Acc: 19.090,29.893,39.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.369 | Acc: 25.781,32.812,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.415 | Acc: 20.275,31.027,39.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.369 | Acc: 19.931,31.250,40.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.395 | Acc: 19.954,30.507,39.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 8.281 | Acc: 16.406,24.219,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.217 | Acc: 20.759,31.808,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.137 | Acc: 20.751,32.241,42.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.129 | Acc: 21.055,32.300,42.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.147 | Acc: 20.901,32.147,42.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.131 | Acc: 21.148,32.580,43.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.131 | Acc: 21.178,32.328,43.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.095 | Acc: 21.454,32.668,43.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.080 | Acc: 21.584,32.667,43.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.063 | Acc: 21.763,32.739,43.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.033 | Acc: 21.918,33.081,43.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.020 | Acc: 21.790,33.088,43.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.006 | Acc: 21.959,33.159,44.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.005 | Acc: 21.875,33.133,44.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.991 | Acc: 21.908,33.243,44.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.971 | Acc: 21.984,33.319,44.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.948 | Acc: 22.177,33.543,44.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.939 | Acc: 22.239,33.637,44.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.926 | Acc: 22.297,33.773,44.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.917 | Acc: 22.377,33.916,44.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.637 | Acc: 26.562,36.719,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.782 | Acc: 22.135,33.743,46.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.783 | Acc: 22.142,33.575,46.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.801 | Acc: 21.901,33.389,46.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 7.727 | Acc: 18.750,31.250,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.530 | Acc: 24.405,36.347,48.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.488 | Acc: 24.486,36.776,48.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.520 | Acc: 23.847,36.578,48.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.525 | Acc: 24.228,36.507,48.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.497 | Acc: 24.513,36.897,48.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.524 | Acc: 24.309,36.415,48.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.531 | Acc: 24.280,36.253,48.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.516 | Acc: 24.335,36.335,48.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.512 | Acc: 24.460,36.451,48.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.502 | Acc: 24.522,36.660,48.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.490 | Acc: 24.608,36.828,48.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.481 | Acc: 24.614,36.900,48.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.455 | Acc: 24.737,37.066,48.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.449 | Acc: 24.686,37.055,48.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.449 | Acc: 24.668,37.105,48.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.443 | Acc: 24.769,37.140,49.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.439 | Acc: 24.645,37.149,49.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.426 | Acc: 24.788,37.316,49.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.426 | Acc: 24.789,37.322,49.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.358 | Acc: 29.688,36.719,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.536 | Acc: 23.103,36.086,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.516 | Acc: 22.923,36.185,48.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.525 | Acc: 22.989,35.630,48.297,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 7.842 | Acc: 19.531,32.031,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.312 | Acc: 23.958,37.165,50.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.232 | Acc: 25.076,38.148,50.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.152 | Acc: 25.922,39.127,51.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.142 | Acc: 25.791,39.361,51.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.126 | Acc: 26.083,39.302,52.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.109 | Acc: 26.169,39.585,52.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.101 | Acc: 26.097,39.772,52.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.103 | Acc: 26.063,39.635,52.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.104 | Acc: 26.083,39.593,52.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.092 | Acc: 26.112,39.630,52.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.081 | Acc: 26.290,39.734,52.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.075 | Acc: 26.300,39.772,52.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.072 | Acc: 26.371,39.802,52.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.069 | Acc: 26.426,39.852,52.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.063 | Acc: 26.498,39.935,52.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.058 | Acc: 26.611,40.094,52.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.046 | Acc: 26.734,40.261,52.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.044 | Acc: 26.738,40.246,52.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.037 | Acc: 26.749,40.287,52.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.847 | Acc: 32.031,45.312,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.161 | Acc: 25.595,37.760,51.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.146 | Acc: 25.534,37.557,51.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.150 | Acc: 25.205,37.615,51.345,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 6.844 | Acc: 25.000,41.406,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.686 | Acc: 28.274,42.039,56.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.649 | Acc: 28.430,43.445,56.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.663 | Acc: 28.586,43.443,56.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.693 | Acc: 28.318,42.959,55.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.700 | Acc: 28.233,42.984,55.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.720 | Acc: 28.138,42.898,55.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.715 | Acc: 28.230,43.085,55.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.712 | Acc: 28.251,42.983,55.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.712 | Acc: 28.311,42.900,55.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.710 | Acc: 28.358,42.914,55.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.706 | Acc: 28.369,42.940,55.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.703 | Acc: 28.371,42.991,55.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.690 | Acc: 28.496,42.990,55.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.694 | Acc: 28.511,43.013,55.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.693 | Acc: 28.558,43.010,55.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.690 | Acc: 28.612,42.993,55.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.694 | Acc: 28.636,42.976,55.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.687 | Acc: 28.634,43.014,55.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.683 | Acc: 28.662,43.067,55.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.684 | Acc: 30.469,43.750,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.980 | Acc: 25.484,39.881,53.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.950 | Acc: 25.572,39.615,52.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.951 | Acc: 25.282,39.536,52.882,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 6.607 | Acc: 28.906,41.406,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.430 | Acc: 28.795,44.792,58.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.384 | Acc: 29.668,45.427,58.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.390 | Acc: 29.662,45.466,58.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.413 | Acc: 29.909,45.322,58.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.422 | Acc: 29.657,44.872,58.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.406 | Acc: 29.965,45.054,58.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.423 | Acc: 29.848,45.047,58.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.409 | Acc: 29.891,45.303,58.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.411 | Acc: 29.873,45.161,58.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.415 | Acc: 29.792,45.068,57.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.411 | Acc: 29.840,45.065,57.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.414 | Acc: 29.859,45.163,57.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.416 | Acc: 29.882,45.130,57.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.412 | Acc: 29.882,45.146,57.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.406 | Acc: 29.908,45.235,57.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.406 | Acc: 29.875,45.215,57.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.405 | Acc: 29.866,45.216,57.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.403 | Acc: 29.856,45.235,57.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.404 | Acc: 29.897,45.198,57.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.700 | Acc: 29.688,46.094,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.827 | Acc: 25.260,41.555,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.815 | Acc: 25.991,41.197,54.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.810 | Acc: 25.858,41.560,54.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 6.272 | Acc: 28.125,44.531,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.171 | Acc: 31.027,47.098,60.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.142 | Acc: 30.945,47.523,61.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.183 | Acc: 30.674,47.067,60.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.161 | Acc: 30.768,47.531,61.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.167 | Acc: 30.886,47.416,60.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.171 | Acc: 30.985,47.411,60.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.163 | Acc: 30.918,47.257,60.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.153 | Acc: 30.852,47.389,60.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.139 | Acc: 30.939,47.402,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.135 | Acc: 30.990,47.341,60.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.148 | Acc: 30.914,47.211,60.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.140 | Acc: 30.949,47.364,60.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.141 | Acc: 31.023,47.288,60.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.146 | Acc: 31.022,47.278,60.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.152 | Acc: 31.029,47.233,60.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.146 | Acc: 31.104,47.296,60.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.150 | Acc: 31.074,47.292,60.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.142 | Acc: 31.131,47.364,60.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.143 | Acc: 31.139,47.398,60.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.879 | Acc: 34.375,54.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.412 | Acc: 27.976,46.019,58.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.415 | Acc: 28.296,45.255,57.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.433 | Acc: 27.741,44.877,57.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 6.175 | Acc: 32.031,46.094,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.853 | Acc: 32.478,48.624,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.924 | Acc: 31.898,48.571,62.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.932 | Acc: 31.596,48.732,62.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.938 | Acc: 31.665,48.630,62.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.941 | Acc: 31.598,48.646,62.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.937 | Acc: 31.702,48.851,62.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.927 | Acc: 31.981,49.058,62.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.932 | Acc: 31.837,49.005,62.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.936 | Acc: 31.945,48.994,62.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.929 | Acc: 32.062,48.986,62.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.929 | Acc: 32.113,49.063,62.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.934 | Acc: 32.161,48.940,62.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.932 | Acc: 32.145,48.988,62.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.936 | Acc: 32.206,48.927,62.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.932 | Acc: 32.213,48.980,62.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.933 | Acc: 32.189,49.024,62.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.925 | Acc: 32.249,49.148,62.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.925 | Acc: 32.271,49.141,62.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.918 | Acc: 32.339,49.131,62.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.916 | Acc: 32.812,50.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.461 | Acc: 26.042,45.833,59.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.416 | Acc: 26.905,45.255,58.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.451 | Acc: 26.703,45.159,58.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 6.035 | Acc: 32.031,46.875,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.668 | Acc: 34.040,51.153,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.577 | Acc: 35.404,52.172,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.658 | Acc: 34.618,51.294,65.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.672 | Acc: 34.423,51.273,65.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.691 | Acc: 34.050,51.067,64.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.690 | Acc: 34.013,50.943,64.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.689 | Acc: 34.015,51.036,64.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.698 | Acc: 33.967,50.951,65.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.689 | Acc: 34.159,51.049,65.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.703 | Acc: 33.940,50.871,64.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.711 | Acc: 33.816,50.608,64.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.710 | Acc: 33.853,50.574,64.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.712 | Acc: 33.857,50.593,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.714 | Acc: 33.847,50.614,64.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.719 | Acc: 33.791,50.633,64.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.721 | Acc: 33.769,50.574,64.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.719 | Acc: 33.809,50.648,64.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.719 | Acc: 33.797,50.606,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.729 | Acc: 33.727,50.521,64.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.891 | Acc: 35.156,50.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.199 | Acc: 31.027,47.024,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.216 | Acc: 31.079,46.208,58.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.216 | Acc: 30.520,46.414,58.350,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 5.404 | Acc: 32.031,50.781,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.522 | Acc: 34.003,51.265,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.486 | Acc: 34.737,52.268,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.467 | Acc: 34.746,52.203,68.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.463 | Acc: 34.713,52.392,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.485 | Acc: 34.537,52.413,67.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.495 | Acc: 34.582,52.382,67.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.512 | Acc: 34.475,52.166,67.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.535 | Acc: 34.336,52.004,66.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.542 | Acc: 34.297,52.072,66.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.539 | Acc: 34.418,52.111,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.546 | Acc: 34.453,52.026,66.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.547 | Acc: 34.514,52.078,66.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.545 | Acc: 34.597,52.167,66.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.541 | Acc: 34.709,52.199,66.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.542 | Acc: 34.686,52.144,66.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.541 | Acc: 34.777,52.198,66.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.539 | Acc: 34.753,52.215,66.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.550 | Acc: 34.613,52.112,66.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.558 | Acc: 34.644,52.120,66.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.721 | Acc: 33.594,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.020 | Acc: 31.399,49.144,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.028 | Acc: 32.069,48.476,60.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.031 | Acc: 31.609,48.079,59.810,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 5.571 | Acc: 35.156,57.812,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.376 | Acc: 36.198,52.865,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.411 | Acc: 35.328,53.030,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.376 | Acc: 35.579,52.882,68.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.386 | Acc: 35.523,53.067,68.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.391 | Acc: 35.535,53.017,68.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.383 | Acc: 35.569,53.209,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.367 | Acc: 35.688,53.385,68.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.376 | Acc: 35.540,53.212,68.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.365 | Acc: 35.575,53.211,68.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.354 | Acc: 35.693,53.409,68.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.371 | Acc: 35.510,53.288,68.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.382 | Acc: 35.464,53.255,68.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.377 | Acc: 35.509,53.436,68.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.386 | Acc: 35.340,53.420,68.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.385 | Acc: 35.392,53.442,68.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.384 | Acc: 35.473,53.475,68.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.381 | Acc: 35.514,53.464,67.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.385 | Acc: 35.461,53.452,67.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.389 | Acc: 35.452,53.457,67.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.525 | Acc: 37.500,57.031,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.919 | Acc: 31.027,49.814,61.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.908 | Acc: 31.936,49.276,61.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.920 | Acc: 31.839,49.488,61.245,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 4.957 | Acc: 34.375,57.031,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.113 | Acc: 37.314,55.878,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.183 | Acc: 35.861,55.088,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.225 | Acc: 35.515,55.149,70.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.237 | Acc: 35.455,54.851,70.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.248 | Acc: 35.636,54.780,70.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.229 | Acc: 35.808,54.739,70.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.239 | Acc: 35.827,54.660,70.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.257 | Acc: 35.578,54.411,69.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.245 | Acc: 35.855,54.662,69.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.239 | Acc: 35.984,54.703,69.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.235 | Acc: 36.061,54.666,69.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.240 | Acc: 36.090,54.506,69.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.248 | Acc: 36.120,54.385,69.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.250 | Acc: 36.077,54.454,69.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.248 | Acc: 36.080,54.498,69.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.245 | Acc: 36.071,54.532,69.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.253 | Acc: 36.105,54.490,69.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.253 | Acc: 36.137,54.458,69.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.261 | Acc: 36.128,54.349,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.648 | Acc: 35.938,56.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.959 | Acc: 30.320,49.851,62.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.987 | Acc: 30.983,49.790,61.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.995 | Acc: 30.930,49.744,61.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 5.220 | Acc: 32.812,52.344,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.031 | Acc: 37.463,56.622,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.067 | Acc: 36.566,56.079,73.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.156 | Acc: 35.873,55.200,72.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.115 | Acc: 36.381,55.633,72.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.116 | Acc: 36.402,55.500,71.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.103 | Acc: 36.448,55.727,71.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.121 | Acc: 36.486,55.613,71.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.125 | Acc: 36.500,55.794,71.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.114 | Acc: 36.792,55.883,71.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.113 | Acc: 36.820,55.885,71.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.115 | Acc: 36.860,55.904,71.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.127 | Acc: 36.858,55.751,70.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.119 | Acc: 36.907,55.726,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.114 | Acc: 37.025,55.827,70.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.118 | Acc: 36.955,55.796,70.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.116 | Acc: 37.040,55.834,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.120 | Acc: 36.998,55.863,70.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.123 | Acc: 37.056,55.796,70.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.122 | Acc: 37.147,55.819,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.345 | Acc: 32.031,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.817 | Acc: 32.292,50.893,61.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.818 | Acc: 32.793,50.286,61.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.839 | Acc: 32.633,50.154,61.040,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 5.063 | Acc: 38.281,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.962 | Acc: 37.574,57.366,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.026 | Acc: 36.528,56.402,72.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.989 | Acc: 36.847,57.044,72.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.975 | Acc: 36.863,57.263,72.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.980 | Acc: 37.098,57.140,72.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.994 | Acc: 37.268,56.883,72.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.997 | Acc: 37.389,56.760,72.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.986 | Acc: 37.447,56.861,72.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.980 | Acc: 37.629,56.949,72.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.989 | Acc: 37.671,56.876,72.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.983 | Acc: 37.808,56.851,72.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.990 | Acc: 37.811,56.730,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.999 | Acc: 37.766,56.564,72.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.001 | Acc: 37.756,56.600,72.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.002 | Acc: 37.817,56.611,72.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.003 | Acc: 37.758,56.622,71.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.003 | Acc: 37.745,56.623,71.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.002 | Acc: 37.753,56.666,71.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.008 | Acc: 37.721,56.582,71.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.270 | Acc: 35.156,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.662 | Acc: 34.040,51.637,64.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.683 | Acc: 34.489,50.438,62.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.693 | Acc: 34.516,50.384,63.281,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 4.785 | Acc: 36.719,57.812,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.717 | Acc: 40.141,58.631,76.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.807 | Acc: 39.120,58.117,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.819 | Acc: 38.332,58.030,75.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.819 | Acc: 38.522,58.054,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.826 | Acc: 38.506,58.014,74.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.845 | Acc: 38.230,57.709,74.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.829 | Acc: 38.531,57.873,74.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.849 | Acc: 38.446,57.662,74.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.857 | Acc: 38.398,57.588,74.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.863 | Acc: 38.460,57.424,74.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.876 | Acc: 38.281,57.335,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.865 | Acc: 38.379,57.436,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.867 | Acc: 38.350,57.552,73.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.877 | Acc: 38.367,57.457,73.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.883 | Acc: 38.294,57.491,73.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.887 | Acc: 38.330,57.406,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.889 | Acc: 38.394,57.441,73.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.892 | Acc: 38.431,57.438,73.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.897 | Acc: 38.445,57.357,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.437 | Acc: 35.156,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.812 | Acc: 33.817,52.344,62.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.763 | Acc: 33.861,52.115,62.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.761 | Acc: 33.722,52.049,62.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 4.622 | Acc: 39.062,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.777 | Acc: 38.616,57.664,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.817 | Acc: 38.053,57.222,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.794 | Acc: 38.281,57.454,74.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.795 | Acc: 38.079,57.562,74.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.808 | Acc: 38.320,57.611,74.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.783 | Acc: 38.630,58.252,74.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.777 | Acc: 38.719,58.333,74.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.791 | Acc: 38.524,58.089,74.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.795 | Acc: 38.583,58.076,74.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.792 | Acc: 38.456,58.120,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.794 | Acc: 38.578,58.194,74.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.791 | Acc: 38.625,58.182,74.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.788 | Acc: 38.691,58.348,74.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.792 | Acc: 38.670,58.305,74.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.789 | Acc: 38.676,58.358,74.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.790 | Acc: 38.714,58.358,74.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.795 | Acc: 38.753,58.319,74.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.796 | Acc: 38.775,58.377,74.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.796 | Acc: 38.812,58.376,74.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.069 | Acc: 39.844,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.568 | Acc: 33.594,53.906,63.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.577 | Acc: 34.261,52.954,62.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.565 | Acc: 34.234,52.882,63.397,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 4.261 | Acc: 44.531,64.844,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.656 | Acc: 39.137,58.445,76.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.702 | Acc: 39.024,58.403,75.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.672 | Acc: 39.267,58.632,76.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.677 | Acc: 39.313,58.796,76.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.677 | Acc: 39.356,58.609,75.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.691 | Acc: 39.243,58.484,75.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.686 | Acc: 39.511,58.660,75.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.670 | Acc: 39.756,58.899,76.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.678 | Acc: 39.762,58.857,76.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.683 | Acc: 39.681,58.761,75.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.679 | Acc: 39.731,58.781,75.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.687 | Acc: 39.640,58.766,75.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.696 | Acc: 39.535,58.710,75.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.699 | Acc: 39.527,58.694,75.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.696 | Acc: 39.631,58.664,75.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.702 | Acc: 39.564,58.625,75.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.705 | Acc: 39.507,58.690,75.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.708 | Acc: 39.497,58.678,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.710 | Acc: 39.512,58.707,75.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.936 | Acc: 35.938,62.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.562 | Acc: 35.528,54.092,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.570 | Acc: 35.995,53.678,63.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.571 | Acc: 35.425,53.099,63.896,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 4.510 | Acc: 42.188,57.812,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.606 | Acc: 40.811,58.259,76.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 40.091,58.670,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.563 | Acc: 40.241,59.349,77.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.572 | Acc: 39.911,59.635,77.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.577 | Acc: 40.169,59.561,77.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.582 | Acc: 40.134,59.607,77.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.598 | Acc: 39.855,59.480,77.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.593 | Acc: 40.086,59.564,76.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.605 | Acc: 39.934,59.414,76.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.611 | Acc: 39.754,59.542,76.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.607 | Acc: 39.794,59.718,76.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.611 | Acc: 39.831,59.676,76.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.609 | Acc: 39.877,59.620,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.605 | Acc: 39.969,59.659,76.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.622 | Acc: 39.802,59.409,76.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.619 | Acc: 39.871,59.458,76.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.621 | Acc: 39.876,59.565,76.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.623 | Acc: 39.902,59.615,76.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.619 | Acc: 40.020,59.637,76.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.176 | Acc: 41.406,60.156,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.513 | Acc: 34.189,53.906,65.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.574 | Acc: 34.299,53.144,64.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.598 | Acc: 33.760,53.343,64.101,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 4.492 | Acc: 34.375,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.474 | Acc: 39.732,60.007,78.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.474 | Acc: 40.873,60.423,78.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.489 | Acc: 40.753,60.272,78.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.457 | Acc: 40.760,60.619,78.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.450 | Acc: 41.081,60.705,78.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.455 | Acc: 41.006,60.492,78.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.458 | Acc: 41.102,60.550,78.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.468 | Acc: 40.916,60.520,78.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.482 | Acc: 40.668,60.441,78.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.483 | Acc: 40.594,60.549,78.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.497 | Acc: 40.593,60.549,77.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.504 | Acc: 40.593,60.552,77.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.502 | Acc: 40.646,60.596,77.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.506 | Acc: 40.614,60.568,77.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.510 | Acc: 40.656,60.514,77.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.512 | Acc: 40.708,60.548,77.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.519 | Acc: 40.669,60.463,77.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.530 | Acc: 40.614,60.405,77.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.537 | Acc: 40.549,60.361,77.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.474 | Acc: 40.625,54.688,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.754 | Acc: 36.161,51.302,63.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.715 | Acc: 35.595,51.239,63.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.719 | Acc: 35.028,51.486,63.128,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 4.055 | Acc: 46.875,64.062,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.450 | Acc: 40.476,61.421,79.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.328 | Acc: 41.902,62.576,80.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.356 | Acc: 41.304,62.692,80.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.370 | Acc: 41.165,62.568,80.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.384 | Acc: 40.996,62.338,80.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.388 | Acc: 41.096,62.287,79.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.416 | Acc: 40.769,61.902,79.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.420 | Acc: 40.834,61.908,79.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.412 | Acc: 40.901,61.775,79.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.416 | Acc: 40.924,61.668,79.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.423 | Acc: 40.975,61.556,78.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.427 | Acc: 40.917,61.485,78.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.421 | Acc: 40.891,61.518,78.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.420 | Acc: 40.900,61.432,78.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.425 | Acc: 40.879,61.374,78.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.427 | Acc: 40.924,61.351,78.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.427 | Acc: 41.037,61.341,78.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.435 | Acc: 41.006,61.342,78.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.444 | Acc: 40.967,61.208,78.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.191 | Acc: 34.375,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.421 | Acc: 36.198,54.762,65.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.419 | Acc: 36.776,53.906,64.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.435 | Acc: 36.232,54.022,65.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 5.121 | Acc: 42.969,49.219,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.347 | Acc: 41.629,60.714,79.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.339 | Acc: 41.368,61.471,79.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.358 | Acc: 40.907,61.719,79.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.353 | Acc: 40.847,61.767,80.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.355 | Acc: 40.989,61.804,80.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.359 | Acc: 41.025,61.757,80.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.358 | Acc: 41.057,61.780,79.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.354 | Acc: 41.193,61.748,79.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.363 | Acc: 41.104,61.719,79.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.366 | Acc: 41.076,61.548,79.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.370 | Acc: 41.088,61.429,79.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.377 | Acc: 41.137,61.446,79.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.383 | Acc: 41.080,61.419,79.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.382 | Acc: 41.092,61.438,79.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.389 | Acc: 41.095,61.319,78.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.381 | Acc: 41.165,61.436,78.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.389 | Acc: 41.134,61.396,78.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.386 | Acc: 41.196,61.409,78.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.386 | Acc: 41.195,61.421,78.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.000 | Acc: 44.531,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.404 | Acc: 33.185,55.246,65.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.434 | Acc: 34.223,54.954,65.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.437 | Acc: 34.029,54.675,65.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 3.937 | Acc: 42.188,64.062,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.172 | Acc: 42.746,63.467,81.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.196 | Acc: 42.035,63.491,81.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.197 | Acc: 42.162,63.601,81.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.232 | Acc: 41.975,63.214,80.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.233 | Acc: 41.870,62.894,80.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.252 | Acc: 41.432,62.881,80.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.277 | Acc: 41.290,62.594,80.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.284 | Acc: 41.246,62.505,80.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.288 | Acc: 41.393,62.535,80.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.309 | Acc: 41.259,62.255,79.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.310 | Acc: 41.286,62.221,79.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.311 | Acc: 41.468,62.218,79.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.302 | Acc: 41.586,62.374,79.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.308 | Acc: 41.615,62.275,79.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.315 | Acc: 41.539,62.207,79.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.319 | Acc: 41.511,62.242,79.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.335 | Acc: 41.390,62.115,79.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.333 | Acc: 41.495,62.115,79.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.336 | Acc: 41.472,62.035,79.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.909 | Acc: 45.312,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.253 | Acc: 36.570,56.548,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.249 | Acc: 37.443,56.364,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.252 | Acc: 37.244,56.250,66.342,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 4.254 | Acc: 45.312,57.812,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.193 | Acc: 43.452,61.644,81.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.088 | Acc: 44.436,63.262,82.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.106 | Acc: 43.571,63.473,82.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.129 | Acc: 42.882,63.407,82.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.124 | Acc: 42.744,63.513,82.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.121 | Acc: 42.943,63.636,82.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.136 | Acc: 42.747,63.558,82.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.143 | Acc: 42.508,63.568,82.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.172 | Acc: 42.278,63.320,81.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.181 | Acc: 42.191,63.157,81.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.187 | Acc: 42.195,63.030,81.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.198 | Acc: 42.097,62.941,81.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.204 | Acc: 41.966,62.943,81.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.209 | Acc: 41.934,62.934,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.216 | Acc: 41.873,62.905,81.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.220 | Acc: 41.947,62.948,80.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.224 | Acc: 41.974,62.938,80.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.230 | Acc: 41.956,62.881,80.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.232 | Acc: 41.976,62.877,80.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.824 | Acc: 44.531,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.377 | Acc: 35.565,55.915,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.378 | Acc: 36.280,55.164,66.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.373 | Acc: 36.168,55.085,66.586,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 3.768 | Acc: 47.656,64.844,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.038 | Acc: 43.824,64.025,83.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.061 | Acc: 43.388,64.234,83.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.055 | Acc: 43.161,64.293,83.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.070 | Acc: 43.084,64.178,82.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.092 | Acc: 43.062,64.001,82.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.119 | Acc: 42.769,63.527,82.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.147 | Acc: 42.481,63.342,82.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.157 | Acc: 42.430,63.466,82.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.151 | Acc: 42.429,63.644,82.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.150 | Acc: 42.510,63.748,82.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.148 | Acc: 42.594,63.766,82.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.164 | Acc: 42.492,63.609,81.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.172 | Acc: 42.556,63.599,81.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.173 | Acc: 42.624,63.662,81.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.181 | Acc: 42.512,63.572,81.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.184 | Acc: 42.526,63.478,81.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.193 | Acc: 42.403,63.410,81.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.189 | Acc: 42.410,63.498,81.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.194 | Acc: 42.393,63.453,81.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.137 | Acc: 42.188,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.280 | Acc: 38.393,56.399,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.302 | Acc: 38.415,55.812,64.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.285 | Acc: 38.435,55.904,65.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 3.749 | Acc: 49.219,71.875,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.029 | Acc: 43.266,65.141,83.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.041 | Acc: 42.873,64.329,83.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.025 | Acc: 43.033,64.319,84.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.024 | Acc: 42.949,64.304,83.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.056 | Acc: 42.698,64.117,83.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.074 | Acc: 42.594,64.011,83.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.085 | Acc: 42.775,64.029,83.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.099 | Acc: 42.765,63.961,82.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.102 | Acc: 42.705,64.088,82.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.099 | Acc: 42.790,63.993,82.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.110 | Acc: 42.725,63.797,82.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.116 | Acc: 42.696,63.667,82.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.123 | Acc: 42.577,63.637,82.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.127 | Acc: 42.607,63.609,82.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.131 | Acc: 42.657,63.582,82.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.140 | Acc: 42.604,63.459,81.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.152 | Acc: 42.561,63.419,81.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.157 | Acc: 42.564,63.396,81.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.158 | Acc: 42.552,63.419,81.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.810 | Acc: 39.062,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.185 | Acc: 37.686,58.259,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.196 | Acc: 37.995,57.241,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.206 | Acc: 37.846,57.262,66.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 4.283 | Acc: 39.062,60.156,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.961 | Acc: 43.192,65.179,84.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.910 | Acc: 44.074,65.796,84.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.917 | Acc: 44.045,65.663,84.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.943 | Acc: 43.837,65.577,84.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.966 | Acc: 43.541,65.231,84.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.979 | Acc: 43.434,64.934,84.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.999 | Acc: 43.168,64.750,84.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.001 | Acc: 43.265,64.752,84.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.008 | Acc: 43.124,64.714,83.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.030 | Acc: 42.961,64.525,83.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.036 | Acc: 43.085,64.480,83.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.043 | Acc: 42.972,64.520,83.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.049 | Acc: 42.873,64.440,83.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.062 | Acc: 42.885,64.235,83.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.063 | Acc: 42.945,64.187,82.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.066 | Acc: 42.974,64.226,82.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.077 | Acc: 42.799,64.161,82.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.081 | Acc: 42.757,64.136,82.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.085 | Acc: 42.751,64.067,82.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.828 | Acc: 39.844,60.938,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.075 | Acc: 37.760,59.375,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.091 | Acc: 38.586,57.774,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.120 | Acc: 38.525,57.697,67.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 4.450 | Acc: 31.250,58.594,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.894 | Acc: 42.857,66.109,84.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.927 | Acc: 43.140,65.816,85.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.962 | Acc: 42.636,65.587,84.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.953 | Acc: 42.602,65.606,84.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.965 | Acc: 42.760,65.548,84.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.959 | Acc: 42.859,65.444,84.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.950 | Acc: 43.235,65.531,84.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.970 | Acc: 43.134,65.285,84.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.977 | Acc: 43.120,65.150,83.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.971 | Acc: 43.233,65.186,84.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.982 | Acc: 43.054,65.088,83.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.989 | Acc: 43.121,64.993,83.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.992 | Acc: 43.082,64.931,83.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.998 | Acc: 43.019,64.913,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.002 | Acc: 43.150,64.885,83.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.007 | Acc: 43.205,64.924,83.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.011 | Acc: 43.168,64.938,83.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.020 | Acc: 43.118,64.861,83.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.028 | Acc: 43.030,64.790,83.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.857 | Acc: 37.500,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.278 | Acc: 36.793,57.143,64.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.268 | Acc: 37.252,56.479,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.267 | Acc: 37.218,56.557,65.599,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 3.983 | Acc: 42.188,64.062,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.883 | Acc: 43.490,66.406,85.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.872 | Acc: 44.474,66.978,86.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.882 | Acc: 44.493,66.637,85.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.905 | Acc: 43.827,66.291,85.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.889 | Acc: 44.028,66.267,85.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.914 | Acc: 43.892,66.122,85.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.930 | Acc: 43.944,65.736,84.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.934 | Acc: 43.896,65.732,84.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.944 | Acc: 43.806,65.616,84.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.932 | Acc: 43.909,65.691,84.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.940 | Acc: 43.842,65.565,84.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.941 | Acc: 43.867,65.547,84.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.945 | Acc: 43.849,65.511,84.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.950 | Acc: 43.722,65.302,84.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.958 | Acc: 43.646,65.220,84.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.968 | Acc: 43.633,65.124,83.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.974 | Acc: 43.619,65.091,83.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.973 | Acc: 43.650,65.099,83.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.982 | Acc: 43.606,65.049,83.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.120 | Acc: 42.969,57.812,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.396 | Acc: 36.496,55.432,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.428 | Acc: 36.166,54.402,64.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.423 | Acc: 36.002,54.982,64.972,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 4.079 | Acc: 39.844,59.375,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.917 | Acc: 42.783,65.923,84.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.903 | Acc: 42.435,65.644,85.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.916 | Acc: 42.585,65.510,85.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.904 | Acc: 42.998,65.741,85.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.900 | Acc: 43.131,65.873,85.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.882 | Acc: 43.550,65.748,85.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.888 | Acc: 43.595,65.874,85.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.901 | Acc: 43.570,65.834,85.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.898 | Acc: 43.815,65.832,85.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.915 | Acc: 43.789,65.644,85.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.921 | Acc: 43.792,65.699,84.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.925 | Acc: 43.915,65.755,84.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.935 | Acc: 43.921,65.628,84.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.939 | Acc: 43.881,65.586,84.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.939 | Acc: 43.867,65.628,84.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.949 | Acc: 43.818,65.559,84.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.957 | Acc: 43.764,65.345,84.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.966 | Acc: 43.674,65.246,83.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.970 | Acc: 43.709,65.194,83.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.883 | Acc: 39.844,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.371 | Acc: 36.533,57.254,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.376 | Acc: 36.966,55.964,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.395 | Acc: 36.693,55.456,66.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 3.818 | Acc: 44.531,64.062,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.794 | Acc: 44.271,66.592,86.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.754 | Acc: 44.760,67.035,86.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.763 | Acc: 44.595,66.726,86.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.820 | Acc: 44.387,66.098,86.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.837 | Acc: 44.129,66.050,86.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.842 | Acc: 44.073,65.987,86.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.844 | Acc: 44.038,66.135,86.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.847 | Acc: 44.128,66.125,86.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.844 | Acc: 44.039,66.182,85.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.856 | Acc: 43.855,65.951,85.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.866 | Acc: 43.881,65.865,85.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.878 | Acc: 43.844,65.735,85.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.875 | Acc: 43.927,65.832,85.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.878 | Acc: 44.011,65.728,85.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.889 | Acc: 43.924,65.648,85.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.901 | Acc: 43.933,65.603,84.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.900 | Acc: 43.981,65.678,84.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.903 | Acc: 44.081,65.696,84.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.912 | Acc: 44.066,65.592,84.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.179 | Acc: 35.156,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.331 | Acc: 38.170,56.994,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.299 | Acc: 38.681,56.460,65.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.302 | Acc: 38.371,56.481,65.343,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 4.355 | Acc: 39.844,52.344,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.948 | Acc: 43.601,63.170,86.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.877 | Acc: 44.455,64.729,86.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.865 | Acc: 44.685,65.484,86.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.862 | Acc: 44.425,65.480,86.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.872 | Acc: 44.098,65.207,85.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.860 | Acc: 44.137,65.438,86.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.843 | Acc: 44.420,65.808,86.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.831 | Acc: 44.483,65.979,86.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.830 | Acc: 44.488,66.078,86.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.829 | Acc: 44.609,66.196,86.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.829 | Acc: 44.531,66.201,86.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.831 | Acc: 44.483,66.186,85.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.833 | Acc: 44.525,66.248,85.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.838 | Acc: 44.478,66.189,85.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.849 | Acc: 44.394,66.087,85.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.860 | Acc: 44.332,65.881,85.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.863 | Acc: 44.435,65.911,85.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.871 | Acc: 44.419,65.757,85.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.878 | Acc: 44.398,65.758,85.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.874 | Acc: 45.312,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.229 | Acc: 38.802,58.371,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.237 | Acc: 38.834,57.546,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.249 | Acc: 38.525,57.211,66.368,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 3.526 | Acc: 42.188,69.531,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.908 | Acc: 42.857,64.769,86.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.830 | Acc: 43.178,65.415,86.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.826 | Acc: 43.327,65.612,86.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.797 | Acc: 43.576,66.107,87.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.806 | Acc: 43.526,66.043,87.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.790 | Acc: 43.840,66.277,87.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.790 | Acc: 44.188,66.307,86.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.784 | Acc: 44.211,66.489,86.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.781 | Acc: 44.372,66.674,86.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.792 | Acc: 44.555,66.581,86.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.802 | Acc: 44.538,66.640,86.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.806 | Acc: 44.538,66.737,86.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.821 | Acc: 44.406,66.496,85.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.831 | Acc: 44.356,66.395,85.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.839 | Acc: 44.321,66.424,85.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.839 | Acc: 44.332,66.487,85.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.837 | Acc: 44.391,66.535,85.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.838 | Acc: 44.404,66.530,85.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.835 | Acc: 44.443,66.578,85.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.643 | Acc: 45.312,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.210 | Acc: 38.021,58.110,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.251 | Acc: 38.014,56.879,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.235 | Acc: 37.705,57.006,66.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 3.636 | Acc: 49.219,65.625,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.655 | Acc: 45.796,68.452,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.739 | Acc: 44.950,67.683,88.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.738 | Acc: 45.338,67.815,87.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.736 | Acc: 44.975,67.679,87.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.735 | Acc: 44.933,67.644,87.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.738 | Acc: 44.996,67.646,87.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.759 | Acc: 44.764,67.293,87.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.766 | Acc: 44.740,67.124,87.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.776 | Acc: 44.635,66.989,87.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.782 | Acc: 44.691,66.931,87.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.776 | Acc: 44.750,66.979,87.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.776 | Acc: 44.820,67.051,86.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.778 | Acc: 44.843,66.996,86.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.788 | Acc: 44.784,66.921,86.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.792 | Acc: 44.861,67.016,86.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.798 | Acc: 44.811,66.932,86.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.805 | Acc: 44.854,66.915,86.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.808 | Acc: 44.828,66.820,86.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.807 | Acc: 44.888,66.837,86.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.746 | Acc: 44.531,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.174 | Acc: 37.984,58.519,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.225 | Acc: 38.700,57.774,66.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.249 | Acc: 38.243,57.275,66.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 3.155 | Acc: 49.219,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.740 | Acc: 44.234,67.522,88.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.727 | Acc: 45.598,67.149,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.699 | Acc: 45.505,67.687,88.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.681 | Acc: 45.679,68.210,88.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.681 | Acc: 45.970,68.000,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.680 | Acc: 45.926,67.995,88.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.684 | Acc: 45.850,67.963,88.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.692 | Acc: 45.609,67.813,87.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.704 | Acc: 45.606,67.693,87.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.700 | Acc: 45.670,67.600,87.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.705 | Acc: 45.708,67.527,87.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.712 | Acc: 45.588,67.418,87.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.723 | Acc: 45.390,67.298,87.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.730 | Acc: 45.326,67.238,87.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.729 | Acc: 45.266,67.250,87.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.739 | Acc: 45.198,67.090,86.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.742 | Acc: 45.193,67.073,86.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.752 | Acc: 45.109,67.014,86.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.757 | Acc: 45.077,66.948,86.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.108 | Acc: 39.062,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.050 | Acc: 38.728,59.784,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.060 | Acc: 39.062,58.956,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.083 | Acc: 38.371,58.671,68.186,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 4.007 | Acc: 39.844,60.938,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.630 | Acc: 44.234,69.122,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.647 | Acc: 44.207,68.540,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.631 | Acc: 44.723,68.699,88.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.645 | Acc: 45.149,68.210,88.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.651 | Acc: 45.088,68.417,88.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.653 | Acc: 45.312,68.324,87.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.665 | Acc: 45.235,68.329,87.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.684 | Acc: 45.148,68.109,87.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.692 | Acc: 45.045,68.072,87.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.695 | Acc: 45.013,67.984,87.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.702 | Acc: 44.920,67.873,87.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.708 | Acc: 44.949,67.739,87.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.709 | Acc: 45.040,67.810,87.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.711 | Acc: 45.132,67.821,87.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.720 | Acc: 45.074,67.660,87.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.722 | Acc: 45.089,67.570,86.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.732 | Acc: 45.028,67.437,86.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.739 | Acc: 44.966,67.358,86.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.738 | Acc: 45.003,67.356,86.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.987 | Acc: 42.188,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.412 | Acc: 36.793,56.808,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.404 | Acc: 37.443,56.040,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.398 | Acc: 37.334,55.827,66.227,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.303 | Acc: 42.969,75.781,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.639 | Acc: 46.503,68.564,87.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.614 | Acc: 46.322,68.598,88.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.656 | Acc: 45.556,68.148,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.640 | Acc: 45.573,68.528,88.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.653 | Acc: 45.529,68.711,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.639 | Acc: 45.597,68.653,88.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.634 | Acc: 45.756,68.728,88.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.632 | Acc: 45.905,68.837,88.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.632 | Acc: 45.826,68.737,88.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.637 | Acc: 45.915,68.575,88.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.642 | Acc: 45.811,68.570,88.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.647 | Acc: 45.737,68.380,88.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.664 | Acc: 45.630,68.226,87.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.675 | Acc: 45.629,68.141,87.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.677 | Acc: 45.606,68.091,87.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.684 | Acc: 45.597,68.025,87.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.695 | Acc: 45.530,67.992,87.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.698 | Acc: 45.602,67.949,87.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.708 | Acc: 45.532,67.829,87.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.750 | Acc: 45.312,61.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.133 | Acc: 39.844,58.445,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.156 | Acc: 39.615,58.060,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.165 | Acc: 38.998,57.774,66.406,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 3.702 | Acc: 41.406,71.875,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.530 | Acc: 46.243,68.824,88.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.563 | Acc: 45.446,68.464,89.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.558 | Acc: 45.722,68.763,89.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.562 | Acc: 45.988,68.586,89.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.584 | Acc: 45.916,68.448,89.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.603 | Acc: 45.655,68.195,88.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.606 | Acc: 45.567,68.074,88.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.618 | Acc: 45.521,68.114,88.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.628 | Acc: 45.528,68.038,88.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.641 | Acc: 45.363,67.910,88.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.645 | Acc: 45.489,67.976,88.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.649 | Acc: 45.497,67.966,88.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.659 | Acc: 45.492,67.852,88.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.654 | Acc: 45.668,67.933,88.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.661 | Acc: 45.590,67.914,87.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.664 | Acc: 45.673,67.913,87.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.671 | Acc: 45.686,67.831,87.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.676 | Acc: 45.628,67.787,87.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.678 | Acc: 45.643,67.764,87.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.865 | Acc: 39.844,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.136 | Acc: 38.542,59.077,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.132 | Acc: 38.491,58.365,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.164 | Acc: 38.025,57.928,66.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.557 | Acc: 46.094,67.969,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.574 | Acc: 45.796,69.271,88.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.560 | Acc: 45.484,68.864,89.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.537 | Acc: 45.710,69.416,89.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.533 | Acc: 45.901,69.252,89.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.534 | Acc: 46.241,69.423,89.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.532 | Acc: 46.184,69.421,89.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.536 | Acc: 46.144,69.154,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.538 | Acc: 46.254,69.162,89.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.546 | Acc: 46.158,68.983,89.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.560 | Acc: 45.942,68.894,89.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.567 | Acc: 45.921,68.930,89.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.576 | Acc: 45.867,68.883,89.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.594 | Acc: 45.782,68.714,89.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.604 | Acc: 45.766,68.564,88.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.609 | Acc: 45.813,68.488,88.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.620 | Acc: 45.770,68.407,88.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.624 | Acc: 45.807,68.312,88.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.628 | Acc: 45.771,68.287,88.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.632 | Acc: 45.784,68.248,88.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.058 | Acc: 35.938,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.304 | Acc: 35.045,58.817,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.317 | Acc: 35.652,58.136,66.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.318 | Acc: 35.784,58.402,66.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 3.666 | Acc: 46.875,66.406,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.505 | Acc: 46.987,70.126,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.487 | Acc: 46.608,70.179,89.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.523 | Acc: 46.568,69.980,89.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.534 | Acc: 46.181,69.319,89.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.525 | Acc: 46.295,69.446,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.525 | Acc: 46.455,69.551,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.532 | Acc: 46.426,69.526,89.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.541 | Acc: 46.361,69.327,89.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.542 | Acc: 46.387,69.121,89.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.550 | Acc: 46.265,68.995,89.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.563 | Acc: 46.122,68.792,89.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.577 | Acc: 45.951,68.675,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.588 | Acc: 45.866,68.540,88.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.604 | Acc: 45.749,68.350,88.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.603 | Acc: 45.808,68.293,88.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.607 | Acc: 45.804,68.283,88.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.615 | Acc: 45.773,68.287,88.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.620 | Acc: 45.765,68.196,88.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.629 | Acc: 45.702,68.198,88.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.551 | Acc: 39.844,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.283 | Acc: 37.351,57.664,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.266 | Acc: 38.167,57.107,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.266 | Acc: 37.654,57.198,66.611,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.148 | Acc: 49.219,73.438,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.488 | Acc: 46.912,70.052,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.495 | Acc: 45.979,70.236,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.515 | Acc: 45.594,69.621,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.525 | Acc: 45.785,69.724,89.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.520 | Acc: 46.009,69.493,89.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.526 | Acc: 46.132,69.499,89.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.523 | Acc: 46.271,69.487,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.540 | Acc: 46.036,69.386,89.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.545 | Acc: 46.081,69.311,89.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.541 | Acc: 46.171,69.450,89.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.542 | Acc: 46.232,69.446,89.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.542 | Acc: 46.249,69.509,89.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.548 | Acc: 46.172,69.412,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.551 | Acc: 46.166,69.339,89.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.558 | Acc: 46.182,69.313,88.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.562 | Acc: 46.103,69.232,88.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.563 | Acc: 46.089,69.249,88.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.573 | Acc: 46.063,69.105,88.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.578 | Acc: 45.987,69.021,88.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.644 | Acc: 41.406,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.029 | Acc: 39.881,59.710,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.052 | Acc: 40.244,59.223,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.057 | Acc: 40.138,59.298,67.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 3.346 | Acc: 47.656,75.000,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.500 | Acc: 46.540,69.382,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.480 | Acc: 46.246,70.217,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.473 | Acc: 46.209,69.890,90.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.491 | Acc: 45.775,69.821,90.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.488 | Acc: 45.970,69.585,90.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.502 | Acc: 45.887,69.531,90.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.503 | Acc: 46.033,69.315,90.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.507 | Acc: 46.118,69.177,90.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.518 | Acc: 46.102,69.117,90.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.519 | Acc: 46.024,69.018,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.529 | Acc: 46.073,68.941,89.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.536 | Acc: 46.168,68.880,89.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.544 | Acc: 46.097,68.813,89.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.552 | Acc: 46.060,68.736,89.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.553 | Acc: 46.026,68.693,89.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.560 | Acc: 46.077,68.628,89.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.567 | Acc: 46.082,68.514,88.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.567 | Acc: 46.144,68.527,88.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.566 | Acc: 46.163,68.578,88.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.095 | Acc: 41.406,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.250 | Acc: 36.793,60.045,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.199 | Acc: 37.900,58.975,67.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.203 | Acc: 37.462,58.658,67.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 3.192 | Acc: 47.656,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.433 | Acc: 48.214,72.247,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.425 | Acc: 47.275,70.846,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.398 | Acc: 47.682,71.043,91.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.392 | Acc: 47.772,71.026,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.405 | Acc: 47.509,70.854,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.430 | Acc: 47.178,70.280,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.452 | Acc: 46.825,70.085,90.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.455 | Acc: 46.744,69.934,90.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.456 | Acc: 46.733,69.946,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.467 | Acc: 46.599,69.854,90.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.477 | Acc: 46.529,69.719,90.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.482 | Acc: 46.463,69.518,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.486 | Acc: 46.567,69.486,89.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.490 | Acc: 46.516,69.459,89.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.495 | Acc: 46.613,69.425,89.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.503 | Acc: 46.734,69.327,89.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.511 | Acc: 46.639,69.245,89.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.522 | Acc: 46.533,69.204,89.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.525 | Acc: 46.496,69.174,89.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.919 | Acc: 44.531,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.359 | Acc: 37.649,58.557,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.290 | Acc: 38.681,58.441,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.286 | Acc: 37.987,58.235,65.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 3.278 | Acc: 51.562,72.656,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.499 | Acc: 46.615,70.499,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.419 | Acc: 47.561,70.884,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.433 | Acc: 46.926,70.607,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.443 | Acc: 46.971,70.370,90.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.440 | Acc: 46.798,70.243,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.447 | Acc: 46.668,70.099,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.445 | Acc: 46.703,70.008,90.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.453 | Acc: 46.652,69.958,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.452 | Acc: 46.927,69.859,90.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.464 | Acc: 46.852,69.694,90.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.470 | Acc: 46.893,69.757,90.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.479 | Acc: 46.775,69.700,90.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.492 | Acc: 46.648,69.570,89.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.498 | Acc: 46.597,69.473,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.500 | Acc: 46.665,69.456,89.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.501 | Acc: 46.741,69.463,89.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.516 | Acc: 46.598,69.332,89.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.521 | Acc: 46.613,69.302,89.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.525 | Acc: 46.641,69.347,89.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.597 | Acc: 46.094,60.156,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.021 | Acc: 40.216,60.751,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.110 | Acc: 40.111,58.918,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.119 | Acc: 40.356,58.991,66.790,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 3.436 | Acc: 41.406,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.529 | Acc: 45.275,68.676,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.467 | Acc: 45.370,69.531,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.460 | Acc: 45.645,69.685,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.439 | Acc: 46.345,70.033,90.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.432 | Acc: 46.511,69.926,90.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.449 | Acc: 46.333,69.886,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.450 | Acc: 46.398,69.781,90.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.458 | Acc: 46.574,69.682,90.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.462 | Acc: 46.668,69.669,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.467 | Acc: 46.704,69.729,89.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.468 | Acc: 46.688,69.704,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.472 | Acc: 46.625,69.612,89.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.476 | Acc: 46.597,69.612,89.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.479 | Acc: 46.636,69.656,89.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.484 | Acc: 46.628,69.542,89.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.489 | Acc: 46.675,69.478,89.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.493 | Acc: 46.678,69.442,89.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.500 | Acc: 46.622,69.328,89.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.506 | Acc: 46.567,69.279,89.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.837 | Acc: 40.625,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.049 | Acc: 38.616,60.603,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.080 | Acc: 38.872,59.394,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.065 | Acc: 38.922,59.670,66.509,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 3.523 | Acc: 49.219,68.750,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.336 | Acc: 48.624,71.057,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.393 | Acc: 47.561,70.484,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.428 | Acc: 47.093,69.903,90.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.442 | Acc: 46.605,69.936,90.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.421 | Acc: 47.045,70.235,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.415 | Acc: 47.107,70.448,90.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.418 | Acc: 47.052,70.318,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.411 | Acc: 47.210,70.395,90.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.420 | Acc: 47.091,70.209,90.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.413 | Acc: 47.236,70.231,90.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.434 | Acc: 47.038,70.115,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.446 | Acc: 47.040,69.923,90.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.454 | Acc: 46.974,69.768,90.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.462 | Acc: 46.847,69.765,90.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.462 | Acc: 46.922,69.767,90.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.466 | Acc: 46.933,69.714,90.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.471 | Acc: 46.868,69.666,89.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.477 | Acc: 46.834,69.644,89.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.482 | Acc: 46.842,69.634,89.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.651 | Acc: 46.875,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.072 | Acc: 40.104,61.124,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.097 | Acc: 39.615,60.232,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.101 | Acc: 39.588,59.580,67.303,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.117 | Acc: 52.344,75.000,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.435 | Acc: 47.024,70.908,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.421 | Acc: 46.227,70.960,91.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.437 | Acc: 46.055,70.761,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.394 | Acc: 46.624,71.123,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.405 | Acc: 46.898,70.916,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.407 | Acc: 46.959,70.706,91.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.413 | Acc: 46.842,70.628,91.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.412 | Acc: 46.933,70.584,91.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.426 | Acc: 46.676,70.455,91.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.439 | Acc: 46.611,70.200,90.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.434 | Acc: 46.702,70.295,90.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.442 | Acc: 46.671,70.225,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.440 | Acc: 46.728,70.169,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.441 | Acc: 46.828,70.123,90.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.446 | Acc: 46.776,70.009,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.446 | Acc: 46.887,69.964,90.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.456 | Acc: 46.825,69.884,90.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.460 | Acc: 46.847,69.867,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.464 | Acc: 46.877,69.794,89.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.998 | Acc: 42.969,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.338 | Acc: 36.272,57.589,66.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.353 | Acc: 36.623,57.184,65.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.352 | Acc: 36.655,57.454,65.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 3.416 | Acc: 47.656,66.406,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.400 | Acc: 47.024,70.685,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.367 | Acc: 47.351,71.799,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.368 | Acc: 47.029,71.452,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.360 | Acc: 47.116,71.354,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.363 | Acc: 47.262,71.040,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.387 | Acc: 47.062,70.616,91.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.384 | Acc: 47.279,70.689,91.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.380 | Acc: 47.355,70.827,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.384 | Acc: 47.462,70.757,91.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.387 | Acc: 47.439,70.725,90.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.392 | Acc: 47.370,70.723,90.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.401 | Acc: 47.390,70.617,90.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.409 | Acc: 47.279,70.612,90.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.417 | Acc: 47.170,70.577,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.433 | Acc: 47.000,70.367,90.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.441 | Acc: 46.907,70.230,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.446 | Acc: 46.941,70.191,89.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.452 | Acc: 46.949,70.163,89.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.453 | Acc: 46.975,70.214,89.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.517 | Acc: 45.312,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.117 | Acc: 39.955,58.519,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.130 | Acc: 39.539,58.479,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.136 | Acc: 38.768,58.184,66.650,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 3.093 | Acc: 48.438,75.781,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.347 | Acc: 48.512,70.685,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.289 | Acc: 48.285,71.856,92.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 48.028,71.913,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.302 | Acc: 47.811,71.663,91.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.324 | Acc: 47.416,71.434,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.342 | Acc: 47.321,71.391,91.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.348 | Acc: 47.623,71.155,91.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.359 | Acc: 47.714,71.002,91.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.355 | Acc: 47.704,71.081,91.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.361 | Acc: 47.544,70.907,91.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.367 | Acc: 47.494,70.807,91.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.361 | Acc: 47.656,70.906,91.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.371 | Acc: 47.545,70.833,90.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.378 | Acc: 47.556,70.741,90.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.398 | Acc: 47.332,70.447,90.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.406 | Acc: 47.289,70.354,90.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.418 | Acc: 47.216,70.308,90.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.424 | Acc: 47.180,70.308,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.425 | Acc: 47.125,70.347,90.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.532 | Acc: 47.656,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.075 | Acc: 40.551,59.970,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.097 | Acc: 40.511,59.432,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.104 | Acc: 40.164,59.260,66.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 3.696 | Acc: 40.625,69.531,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.475 | Acc: 45.722,69.457,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.379 | Acc: 47.199,70.427,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.333 | Acc: 47.951,70.697,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.352 | Acc: 47.666,70.563,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.358 | Acc: 47.432,70.637,92.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.346 | Acc: 47.669,70.842,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.342 | Acc: 47.717,70.911,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.341 | Acc: 47.739,70.793,92.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.344 | Acc: 47.561,70.960,92.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.336 | Acc: 47.699,71.113,91.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.356 | Acc: 47.571,70.822,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.354 | Acc: 47.663,70.896,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.356 | Acc: 47.710,70.890,91.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.362 | Acc: 47.676,70.869,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.366 | Acc: 47.695,70.865,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.373 | Acc: 47.639,70.785,90.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.376 | Acc: 47.647,70.700,90.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.391 | Acc: 47.483,70.520,90.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.403 | Acc: 47.297,70.421,90.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.670 | Acc: 46.094,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.179 | Acc: 38.430,59.524,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.189 | Acc: 39.291,58.975,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.209 | Acc: 39.178,58.709,66.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.339 | Acc: 53.125,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.423 | Acc: 46.987,71.317,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.346 | Acc: 47.180,71.551,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.337 | Acc: 47.426,71.529,91.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.346 | Acc: 47.328,71.402,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.341 | Acc: 47.223,71.573,91.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.332 | Acc: 47.417,71.584,91.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.331 | Acc: 47.562,71.365,91.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.344 | Acc: 47.389,71.220,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.349 | Acc: 47.354,71.150,91.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.361 | Acc: 47.264,70.989,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.368 | Acc: 47.299,70.910,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.370 | Acc: 47.326,70.928,91.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.371 | Acc: 47.414,70.863,91.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.373 | Acc: 47.476,70.846,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.376 | Acc: 47.456,70.790,90.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.382 | Acc: 47.435,70.726,90.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.387 | Acc: 47.347,70.695,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.389 | Acc: 47.303,70.672,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.388 | Acc: 47.320,70.643,90.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.855 | Acc: 47.656,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.038 | Acc: 40.365,59.970,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.038 | Acc: 40.492,59.032,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.047 | Acc: 40.202,59.362,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 3.345 | Acc: 46.875,69.531,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.326 | Acc: 46.875,71.615,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.326 | Acc: 46.894,71.532,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.323 | Acc: 47.131,71.696,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.327 | Acc: 46.730,71.576,91.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.319 | Acc: 46.991,71.481,91.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.329 | Acc: 47.159,71.378,91.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.350 | Acc: 46.858,71.127,91.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.351 | Acc: 47.152,71.021,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.338 | Acc: 47.427,71.184,91.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.338 | Acc: 47.384,71.113,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.339 | Acc: 47.359,71.101,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.352 | Acc: 47.293,70.902,91.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.358 | Acc: 47.411,70.950,91.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.365 | Acc: 47.370,70.905,91.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.370 | Acc: 47.420,70.881,90.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.375 | Acc: 47.488,70.826,90.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.376 | Acc: 47.516,70.853,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.379 | Acc: 47.498,70.847,90.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.378 | Acc: 47.554,70.837,90.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.379 | Acc: 45.312,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.991 | Acc: 38.914,59.970,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.995 | Acc: 39.158,59.851,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.022 | Acc: 38.678,59.618,68.020,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 3.492 | Acc: 45.312,70.312,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.352 | Acc: 47.061,71.540,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.316 | Acc: 47.790,71.399,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.305 | Acc: 47.938,71.171,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.268 | Acc: 48.322,71.914,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.287 | Acc: 48.105,71.535,92.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.278 | Acc: 48.257,71.649,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.269 | Acc: 48.365,71.792,92.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.286 | Acc: 48.175,71.545,92.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.296 | Acc: 48.170,71.465,92.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.305 | Acc: 48.138,71.374,91.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.307 | Acc: 48.141,71.391,91.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.312 | Acc: 48.146,71.304,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.318 | Acc: 48.105,71.202,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.330 | Acc: 48.034,71.133,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.333 | Acc: 48.043,71.109,91.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.338 | Acc: 48.043,71.023,91.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.348 | Acc: 47.950,70.872,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.359 | Acc: 47.842,70.706,91.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.366 | Acc: 47.794,70.602,90.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.824 | Acc: 45.312,60.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.074 | Acc: 39.062,61.272,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.075 | Acc: 39.367,60.347,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.081 | Acc: 39.293,60.195,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 3.280 | Acc: 53.125,69.531,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.241 | Acc: 48.065,72.098,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.238 | Acc: 48.418,72.713,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.252 | Acc: 48.079,72.579,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.259 | Acc: 48.032,72.328,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.253 | Acc: 48.151,72.285,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.273 | Acc: 47.695,72.075,92.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.290 | Acc: 47.667,71.864,92.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.293 | Acc: 47.782,71.754,92.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.298 | Acc: 47.643,71.646,91.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.306 | Acc: 47.575,71.669,91.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.305 | Acc: 47.639,71.624,91.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.314 | Acc: 47.520,71.505,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.323 | Acc: 47.441,71.438,91.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.327 | Acc: 47.412,71.475,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.336 | Acc: 47.347,71.299,91.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.343 | Acc: 47.379,71.220,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.348 | Acc: 47.457,71.140,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.350 | Acc: 47.531,71.107,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.346 | Acc: 47.605,71.217,90.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.819 | Acc: 41.406,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.178 | Acc: 38.914,61.570,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.193 | Acc: 39.139,60.042,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.213 | Acc: 38.550,59.234,66.675,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 2.992 | Acc: 56.250,73.438,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.311 | Acc: 48.810,72.842,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.264 | Acc: 48.609,73.247,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.280 | Acc: 48.694,72.567,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.283 | Acc: 48.090,72.454,91.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.286 | Acc: 48.159,72.447,92.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.288 | Acc: 47.992,72.185,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.280 | Acc: 48.122,72.174,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.277 | Acc: 48.161,72.181,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.283 | Acc: 48.002,72.164,91.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.284 | Acc: 48.041,72.054,91.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.285 | Acc: 47.996,71.935,91.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.298 | Acc: 47.919,71.742,91.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.309 | Acc: 47.914,71.615,91.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.306 | Acc: 48.054,71.614,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.307 | Acc: 48.030,71.569,91.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.313 | Acc: 48.029,71.522,91.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.314 | Acc: 48.034,71.504,91.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.319 | Acc: 47.996,71.453,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.328 | Acc: 47.923,71.348,91.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.470 | Acc: 46.094,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.948 | Acc: 41.704,61.644,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.936 | Acc: 42.054,60.252,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.952 | Acc: 41.880,60.400,66.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 3.622 | Acc: 47.656,69.531,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.232 | Acc: 49.144,73.847,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.224 | Acc: 49.257,73.285,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.234 | Acc: 48.655,73.284,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.218 | Acc: 48.573,73.187,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.245 | Acc: 48.291,72.896,92.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.240 | Acc: 48.605,72.546,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.239 | Acc: 48.576,72.568,92.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.240 | Acc: 48.384,72.545,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.245 | Acc: 48.308,72.384,92.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.268 | Acc: 48.025,72.128,92.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.270 | Acc: 48.155,72.055,92.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.271 | Acc: 48.188,72.066,92.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.281 | Acc: 48.051,71.959,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.280 | Acc: 48.134,71.947,91.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.289 | Acc: 48.139,71.966,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.300 | Acc: 48.051,71.880,91.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.306 | Acc: 47.975,71.834,91.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.310 | Acc: 47.966,71.743,91.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.314 | Acc: 47.982,71.705,91.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.699 | Acc: 50.000,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.009 | Acc: 40.588,61.347,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.013 | Acc: 40.434,60.328,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.030 | Acc: 40.036,60.156,66.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 2.760 | Acc: 55.469,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.257 | Acc: 47.954,73.624,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.196 | Acc: 48.552,74.009,92.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.213 | Acc: 48.450,73.463,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.218 | Acc: 48.225,73.486,92.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.222 | Acc: 48.445,73.074,92.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.233 | Acc: 48.283,72.927,92.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.243 | Acc: 48.172,72.678,92.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.249 | Acc: 48.316,72.642,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.253 | Acc: 48.235,72.613,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.263 | Acc: 48.084,72.431,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.270 | Acc: 47.932,72.303,92.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.276 | Acc: 47.883,72.293,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.279 | Acc: 47.899,72.267,91.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.289 | Acc: 47.815,72.120,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.297 | Acc: 47.729,72.106,91.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.298 | Acc: 47.780,72.077,91.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.299 | Acc: 47.920,72.026,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.307 | Acc: 47.868,71.853,91.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.310 | Acc: 47.911,71.760,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.452 | Acc: 42.969,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.060 | Acc: 40.513,61.161,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.086 | Acc: 41.044,59.870,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.120 | Acc: 40.318,59.183,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 3.304 | Acc: 46.094,72.656,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.265 | Acc: 48.065,72.731,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.206 | Acc: 49.333,72.694,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.223 | Acc: 48.642,72.823,92.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.232 | Acc: 48.042,72.762,92.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.232 | Acc: 48.020,72.819,92.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.229 | Acc: 48.347,72.682,92.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.231 | Acc: 48.482,72.429,92.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.237 | Acc: 48.486,72.399,92.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.239 | Acc: 48.563,72.354,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.251 | Acc: 48.278,72.198,92.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.263 | Acc: 48.232,72.172,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.262 | Acc: 48.340,72.141,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.268 | Acc: 48.258,71.986,91.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.271 | Acc: 48.254,71.986,91.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.273 | Acc: 48.328,71.870,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.279 | Acc: 48.253,71.829,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.288 | Acc: 48.188,71.689,91.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.286 | Acc: 48.217,71.734,91.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.295 | Acc: 48.073,71.610,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.552 | Acc: 42.188,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.887 | Acc: 42.299,60.900,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.924 | Acc: 42.378,60.290,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.926 | Acc: 42.034,59.926,67.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 3.458 | Acc: 42.188,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.280 | Acc: 47.656,71.875,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.228 | Acc: 48.609,72.942,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.208 | Acc: 48.450,73.373,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.219 | Acc: 48.640,72.878,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.196 | Acc: 48.963,73.260,92.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.191 | Acc: 49.174,73.347,92.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.207 | Acc: 49.097,73.011,92.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.222 | Acc: 48.748,72.831,92.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.228 | Acc: 48.804,72.721,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.237 | Acc: 48.745,72.687,92.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.243 | Acc: 48.650,72.649,92.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.238 | Acc: 48.697,72.689,92.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.240 | Acc: 48.782,72.641,92.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.250 | Acc: 48.652,72.437,92.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.255 | Acc: 48.596,72.324,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.261 | Acc: 48.549,72.225,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.268 | Acc: 48.483,72.086,91.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.271 | Acc: 48.531,72.091,91.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.282 | Acc: 48.444,71.982,91.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.686 | Acc: 41.406,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.115 | Acc: 37.909,60.789,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.154 | Acc: 38.091,59.299,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.170 | Acc: 38.102,59.093,67.636,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 3.272 | Acc: 50.781,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.222 | Acc: 49.219,72.842,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.215 | Acc: 48.666,73.075,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.230 | Acc: 47.951,72.784,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.242 | Acc: 47.888,72.811,92.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.235 | Acc: 48.128,72.765,92.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.222 | Acc: 48.283,72.727,93.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.227 | Acc: 48.260,72.645,92.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.233 | Acc: 48.229,72.685,92.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.245 | Acc: 48.079,72.579,92.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.242 | Acc: 48.177,72.571,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.240 | Acc: 48.176,72.586,92.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.242 | Acc: 48.243,72.514,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.246 | Acc: 48.273,72.456,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.260 | Acc: 48.159,72.373,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.265 | Acc: 48.079,72.347,92.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.268 | Acc: 48.068,72.308,91.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.274 | Acc: 48.032,72.262,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.280 | Acc: 48.050,72.184,91.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.285 | Acc: 48.013,72.127,91.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.670 | Acc: 42.969,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.941 | Acc: 41.183,60.975,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.927 | Acc: 41.864,60.633,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.933 | Acc: 41.432,60.528,68.519,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 2.980 | Acc: 52.344,71.094,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.153 | Acc: 48.810,73.475,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.188 | Acc: 48.723,73.018,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.200 | Acc: 48.553,72.836,92.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.194 | Acc: 48.872,72.772,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.205 | Acc: 48.793,72.548,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.211 | Acc: 48.773,72.495,92.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.213 | Acc: 49.003,72.457,92.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.219 | Acc: 48.928,72.355,92.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.217 | Acc: 48.960,72.276,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.230 | Acc: 48.838,72.244,92.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.229 | Acc: 48.798,72.306,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.233 | Acc: 48.736,72.267,92.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.248 | Acc: 48.581,72.213,91.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.250 | Acc: 48.585,72.273,91.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.254 | Acc: 48.528,72.197,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.258 | Acc: 48.493,72.131,91.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.268 | Acc: 48.378,72.024,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.268 | Acc: 48.394,71.988,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.270 | Acc: 48.433,71.992,91.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.033 | Acc: 44.531,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.078 | Acc: 40.588,60.193,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.108 | Acc: 40.434,59.661,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.114 | Acc: 40.190,59.516,66.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 3.208 | Acc: 54.688,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.154 | Acc: 47.954,75.186,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.155 | Acc: 48.361,74.200,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.151 | Acc: 48.642,74.347,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.156 | Acc: 48.698,74.122,92.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.151 | Acc: 48.639,74.025,92.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.173 | Acc: 48.502,73.747,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.184 | Acc: 48.415,73.515,92.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.195 | Acc: 48.423,73.277,92.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.196 | Acc: 48.541,73.230,92.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.208 | Acc: 48.496,72.936,92.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.214 | Acc: 48.512,72.730,92.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.228 | Acc: 48.467,72.572,92.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.224 | Acc: 48.647,72.632,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.228 | Acc: 48.660,72.656,92.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.232 | Acc: 48.611,72.560,92.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.242 | Acc: 48.532,72.403,92.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.246 | Acc: 48.538,72.363,92.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.254 | Acc: 48.438,72.295,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.256 | Acc: 48.384,72.252,91.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.779 | Acc: 44.531,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.087 | Acc: 40.476,60.714,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.132 | Acc: 40.835,59.661,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.162 | Acc: 40.126,59.247,66.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 3.311 | Acc: 48.438,70.312,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.160 | Acc: 49.479,74.814,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.152 | Acc: 48.723,74.200,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.168 | Acc: 48.860,73.604,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.177 | Acc: 48.804,73.669,93.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.185 | Acc: 48.863,73.523,92.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.182 | Acc: 48.889,73.547,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.185 | Acc: 49.102,73.332,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.182 | Acc: 48.986,73.273,92.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.185 | Acc: 49.029,73.273,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.196 | Acc: 48.947,73.041,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.202 | Acc: 48.901,72.967,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.205 | Acc: 48.875,72.809,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.218 | Acc: 48.821,72.596,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.226 | Acc: 48.707,72.523,92.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.234 | Acc: 48.643,72.490,92.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.245 | Acc: 48.515,72.325,91.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.249 | Acc: 48.481,72.251,91.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.251 | Acc: 48.476,72.260,91.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.253 | Acc: 48.454,72.172,91.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.475 | Acc: 44.531,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.031 | Acc: 40.030,60.417,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.051 | Acc: 40.130,60.156,67.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.069 | Acc: 39.933,59.618,66.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 2.906 | Acc: 55.469,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.146 | Acc: 49.665,74.516,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.203 | Acc: 48.723,73.228,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.217 | Acc: 48.489,72.759,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.225 | Acc: 48.322,72.541,92.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.218 | Acc: 48.360,72.517,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.192 | Acc: 48.618,72.579,93.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.190 | Acc: 48.737,72.623,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.193 | Acc: 48.763,72.579,93.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.202 | Acc: 48.640,72.656,93.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.209 | Acc: 48.535,72.586,92.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.216 | Acc: 48.466,72.504,92.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.226 | Acc: 48.275,72.348,92.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.228 | Acc: 48.309,72.288,92.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.221 | Acc: 48.404,72.392,92.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.224 | Acc: 48.425,72.376,92.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.225 | Acc: 48.476,72.430,92.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.230 | Acc: 48.483,72.462,92.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.232 | Acc: 48.548,72.459,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.238 | Acc: 48.505,72.381,92.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.769 | Acc: 47.656,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.097 | Acc: 38.876,60.640,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.080 | Acc: 39.863,60.404,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.081 | Acc: 39.460,59.926,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 3.381 | Acc: 47.656,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.181 | Acc: 48.847,74.144,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.139 | Acc: 49.562,74.028,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.155 | Acc: 49.244,73.642,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.126 | Acc: 49.662,73.640,93.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.155 | Acc: 49.188,73.391,93.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.176 | Acc: 48.702,72.915,93.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.184 | Acc: 48.703,72.883,93.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.174 | Acc: 48.801,72.778,93.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.169 | Acc: 48.843,72.920,93.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.172 | Acc: 48.756,72.909,93.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.170 | Acc: 48.968,72.932,93.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.170 | Acc: 49.031,73.000,92.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.171 | Acc: 49.108,72.929,92.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.181 | Acc: 48.960,72.790,92.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.190 | Acc: 48.876,72.783,92.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.194 | Acc: 48.900,72.824,92.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.195 | Acc: 48.919,72.812,92.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.197 | Acc: 48.885,72.827,92.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.206 | Acc: 48.790,72.757,92.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.841 | Acc: 44.531,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.085 | Acc: 40.402,60.900,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.129 | Acc: 40.053,60.461,66.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.138 | Acc: 39.933,59.823,66.278,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 3.188 | Acc: 48.438,74.219,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.231 | Acc: 49.442,73.140,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.219 | Acc: 48.914,73.209,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.186 | Acc: 49.065,73.258,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.169 | Acc: 49.286,73.621,93.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.160 | Acc: 49.327,73.700,93.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.154 | Acc: 49.186,73.709,93.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.149 | Acc: 49.241,73.537,93.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.154 | Acc: 49.272,73.505,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.149 | Acc: 49.353,73.520,93.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.160 | Acc: 49.258,73.348,93.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.173 | Acc: 49.134,73.229,93.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.169 | Acc: 49.147,73.279,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.176 | Acc: 49.021,73.159,92.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.186 | Acc: 48.930,73.004,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.186 | Acc: 48.954,73.051,92.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.197 | Acc: 48.859,72.870,92.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.200 | Acc: 48.914,72.812,92.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.204 | Acc: 48.898,72.762,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.207 | Acc: 48.887,72.685,92.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.415 | Acc: 46.875,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.055 | Acc: 40.625,61.793,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.088 | Acc: 40.701,60.728,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.094 | Acc: 40.318,60.451,66.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 3.174 | Acc: 49.219,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.080 | Acc: 49.070,74.554,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.053 | Acc: 49.524,74.181,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.072 | Acc: 49.718,73.706,93.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.077 | Acc: 49.817,73.987,93.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.089 | Acc: 49.791,73.948,93.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.091 | Acc: 49.755,74.090,93.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.114 | Acc: 49.318,73.820,93.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.116 | Acc: 49.398,73.894,93.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.128 | Acc: 49.227,73.800,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.126 | Acc: 49.339,73.787,93.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.135 | Acc: 49.392,73.685,92.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.139 | Acc: 49.358,73.590,92.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.152 | Acc: 49.252,73.503,92.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.167 | Acc: 49.180,73.293,92.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.172 | Acc: 49.167,73.256,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.181 | Acc: 49.031,73.189,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.185 | Acc: 49.015,73.144,92.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.191 | Acc: 48.979,73.067,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.192 | Acc: 48.983,73.101,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.724 | Acc: 42.969,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.106 | Acc: 37.984,61.942,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.117 | Acc: 39.253,60.575,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.119 | Acc: 38.883,60.246,68.276,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 3.206 | Acc: 39.062,75.781,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 50.781,75.856,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.001 | Acc: 51.048,75.267,94.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.039 | Acc: 50.102,74.641,94.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.074 | Acc: 49.383,74.257,94.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.101 | Acc: 48.940,73.933,93.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.121 | Acc: 48.657,73.521,93.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.132 | Acc: 48.814,73.415,93.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.134 | Acc: 48.738,73.365,93.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.131 | Acc: 48.843,73.420,93.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.124 | Acc: 49.028,73.706,93.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.128 | Acc: 49.024,73.667,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.144 | Acc: 48.862,73.554,93.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.155 | Acc: 48.892,73.458,92.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.164 | Acc: 48.791,73.318,92.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.172 | Acc: 48.806,73.175,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.176 | Acc: 48.859,73.221,92.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.180 | Acc: 48.857,73.206,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.187 | Acc: 48.818,73.130,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.192 | Acc: 48.798,73.073,92.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.575 | Acc: 44.531,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.041 | Acc: 40.513,60.900,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.066 | Acc: 40.473,60.671,67.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.074 | Acc: 40.254,60.630,67.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 3.369 | Acc: 40.625,71.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.061 | Acc: 49.665,74.591,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.131 | Acc: 49.333,73.209,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.123 | Acc: 49.283,73.553,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.100 | Acc: 49.392,73.708,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.089 | Acc: 49.830,73.793,93.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.117 | Acc: 49.296,73.392,93.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.140 | Acc: 49.086,73.260,93.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.142 | Acc: 49.228,73.258,93.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.148 | Acc: 49.232,73.269,93.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.153 | Acc: 49.102,73.103,93.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.163 | Acc: 49.067,73.063,92.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.171 | Acc: 48.959,72.954,92.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.165 | Acc: 49.120,72.991,92.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.165 | Acc: 49.035,73.004,92.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.174 | Acc: 48.975,72.913,92.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.170 | Acc: 49.070,72.951,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.175 | Acc: 49.136,72.943,92.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.185 | Acc: 49.078,72.864,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.187 | Acc: 49.040,72.843,92.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.654 | Acc: 53.125,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.799 | Acc: 44.085,62.054,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.797 | Acc: 44.341,61.643,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.815 | Acc: 43.865,61.847,68.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 3.171 | Acc: 53.125,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.071 | Acc: 51.116,73.847,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.073 | Acc: 49.638,74.867,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.052 | Acc: 49.539,75.013,93.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.083 | Acc: 49.026,74.392,93.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.098 | Acc: 49.041,74.226,93.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.093 | Acc: 49.154,74.103,93.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.105 | Acc: 49.174,73.775,93.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.118 | Acc: 49.199,73.806,93.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.133 | Acc: 49.020,73.684,93.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.128 | Acc: 49.164,73.640,93.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.126 | Acc: 49.166,73.653,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.132 | Acc: 49.112,73.587,93.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.137 | Acc: 49.180,73.500,93.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.137 | Acc: 49.249,73.454,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.141 | Acc: 49.323,73.427,92.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.145 | Acc: 49.275,73.433,92.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.149 | Acc: 49.207,73.387,92.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.151 | Acc: 49.221,73.412,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.159 | Acc: 49.108,73.405,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.535 | Acc: 42.188,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.858 | Acc: 42.374,62.277,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.868 | Acc: 42.473,61.338,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.877 | Acc: 42.341,61.142,67.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 3.050 | Acc: 51.562,77.344,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.095 | Acc: 49.665,75.074,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.092 | Acc: 49.352,74.905,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.092 | Acc: 49.168,74.795,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.045 | Acc: 49.691,74.923,93.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.064 | Acc: 49.211,74.714,93.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.074 | Acc: 49.154,74.419,93.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.088 | Acc: 49.130,74.213,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.097 | Acc: 49.117,74.219,93.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.097 | Acc: 49.007,74.219,93.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.109 | Acc: 48.865,73.966,93.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.118 | Acc: 48.816,73.805,93.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.120 | Acc: 48.875,73.843,93.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.121 | Acc: 48.991,73.803,93.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.126 | Acc: 48.974,73.665,93.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.131 | Acc: 49.011,73.606,92.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.140 | Acc: 49.014,73.593,92.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.147 | Acc: 48.960,73.543,92.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.154 | Acc: 48.916,73.485,92.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.163 | Acc: 48.923,73.388,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.874 | Acc: 40.625,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.159 | Acc: 39.323,60.714,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.158 | Acc: 39.482,59.870,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.164 | Acc: 38.563,59.324,66.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 2.717 | Acc: 57.031,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.139 | Acc: 49.628,73.996,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.076 | Acc: 50.743,74.581,93.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.088 | Acc: 50.320,74.308,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.086 | Acc: 49.952,74.306,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.108 | Acc: 49.513,73.940,93.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.118 | Acc: 49.329,73.702,93.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.125 | Acc: 49.529,73.753,93.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.126 | Acc: 49.505,73.811,93.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.131 | Acc: 49.469,73.822,93.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.147 | Acc: 49.246,73.632,92.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.147 | Acc: 49.293,73.717,92.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.149 | Acc: 49.384,73.703,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.146 | Acc: 49.434,73.746,92.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.145 | Acc: 49.394,73.791,92.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.145 | Acc: 49.346,73.796,92.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.148 | Acc: 49.319,73.659,92.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.146 | Acc: 49.356,73.625,92.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.150 | Acc: 49.297,73.600,92.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.156 | Acc: 49.272,73.575,92.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.038 | Acc: 46.875,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.145 | Acc: 38.876,60.565,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.113 | Acc: 39.062,60.137,66.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.108 | Acc: 39.191,60.041,66.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 2.753 | Acc: 48.438,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.078 | Acc: 49.814,74.330,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.088 | Acc: 49.790,75.133,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.076 | Acc: 50.474,74.859,93.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.101 | Acc: 49.826,74.219,93.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.090 | Acc: 49.845,74.025,93.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.099 | Acc: 49.684,73.825,93.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.105 | Acc: 49.540,73.870,93.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.100 | Acc: 49.549,73.966,93.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.107 | Acc: 49.547,73.964,93.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.116 | Acc: 49.557,73.745,93.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.123 | Acc: 49.558,73.628,93.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.122 | Acc: 49.611,73.626,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.121 | Acc: 49.605,73.635,93.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.127 | Acc: 49.680,73.613,92.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.131 | Acc: 49.676,73.552,92.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.138 | Acc: 49.706,73.438,92.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.144 | Acc: 49.638,73.460,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.150 | Acc: 49.591,73.383,92.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.150 | Acc: 49.588,73.396,92.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.484 | Acc: 46.875,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.881 | Acc: 43.229,62.054,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.903 | Acc: 42.702,61.719,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.916 | Acc: 42.392,61.424,67.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 2.661 | Acc: 51.562,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.040 | Acc: 49.777,74.814,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.048 | Acc: 49.428,74.657,93.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.071 | Acc: 48.937,74.449,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.054 | Acc: 49.460,74.817,93.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.068 | Acc: 49.520,74.544,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.072 | Acc: 49.490,74.464,93.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.079 | Acc: 49.679,74.291,93.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.086 | Acc: 49.515,74.228,93.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.076 | Acc: 49.789,74.271,93.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.072 | Acc: 49.949,74.293,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.084 | Acc: 49.823,74.056,93.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.097 | Acc: 49.750,73.992,93.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.103 | Acc: 49.725,73.943,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.104 | Acc: 49.761,73.941,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.113 | Acc: 49.590,73.848,92.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.115 | Acc: 49.620,73.824,92.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.124 | Acc: 49.608,73.664,92.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.126 | Acc: 49.591,73.613,92.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.129 | Acc: 49.658,73.538,92.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.483 | Acc: 47.656,64.844,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.848 | Acc: 42.634,62.091,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.858 | Acc: 42.854,61.547,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.877 | Acc: 42.533,61.373,67.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 3.127 | Acc: 43.750,72.656,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.170 | Acc: 49.070,73.065,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.100 | Acc: 49.524,74.581,93.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.063 | Acc: 49.898,75.038,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.069 | Acc: 49.277,74.894,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.062 | Acc: 49.327,74.923,94.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.058 | Acc: 49.554,74.768,94.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.067 | Acc: 49.512,74.618,93.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.064 | Acc: 49.636,74.651,93.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.065 | Acc: 49.810,74.568,93.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.069 | Acc: 49.790,74.487,93.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.080 | Acc: 49.738,74.413,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.093 | Acc: 49.608,74.254,93.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.098 | Acc: 49.632,74.213,93.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.103 | Acc: 49.630,74.074,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.107 | Acc: 49.574,73.983,93.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.113 | Acc: 49.550,73.975,93.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.116 | Acc: 49.583,73.932,92.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.122 | Acc: 49.582,73.903,92.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.127 | Acc: 49.555,73.921,92.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.454 | Acc: 44.531,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.878 | Acc: 43.118,61.049,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.895 | Acc: 42.988,60.861,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.906 | Acc: 42.777,60.438,68.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 2.872 | Acc: 47.656,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.183 | Acc: 50.186,73.326,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.102 | Acc: 50.038,74.295,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.110 | Acc: 49.257,74.244,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.083 | Acc: 49.643,74.344,93.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.059 | Acc: 50.070,74.575,93.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.067 | Acc: 49.877,74.509,93.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.083 | Acc: 49.873,74.208,93.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.088 | Acc: 49.670,74.093,93.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.095 | Acc: 49.482,74.046,93.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.105 | Acc: 49.331,74.036,93.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.097 | Acc: 49.342,74.007,93.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.106 | Acc: 49.384,73.982,93.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.110 | Acc: 49.410,73.857,93.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.114 | Acc: 49.427,73.816,92.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.116 | Acc: 49.502,73.780,92.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.118 | Acc: 49.496,73.742,92.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.126 | Acc: 49.436,73.630,92.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.134 | Acc: 49.284,73.570,92.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.138 | Acc: 49.291,73.511,92.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.681 | Acc: 46.875,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.028 | Acc: 40.513,60.417,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.082 | Acc: 40.454,59.851,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.099 | Acc: 40.126,59.746,66.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 2.857 | Acc: 56.250,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.089 | Acc: 49.740,74.888,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.027 | Acc: 50.972,75.286,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.022 | Acc: 50.666,75.346,93.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.048 | Acc: 50.068,74.932,93.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.058 | Acc: 49.876,74.544,93.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.037 | Acc: 50.181,74.574,93.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.051 | Acc: 49.967,74.463,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.058 | Acc: 49.884,74.243,93.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.067 | Acc: 49.948,74.145,93.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.060 | Acc: 50.113,74.223,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.060 | Acc: 50.173,74.265,93.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.068 | Acc: 50.175,74.173,93.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.067 | Acc: 50.144,74.165,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.071 | Acc: 50.136,74.166,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.082 | Acc: 49.940,74.175,93.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.095 | Acc: 49.825,74.090,93.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.102 | Acc: 49.812,73.994,93.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.106 | Acc: 49.792,73.937,93.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.112 | Acc: 49.690,73.897,92.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.799 | Acc: 43.750,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.961 | Acc: 41.443,61.942,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.957 | Acc: 42.264,61.223,67.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.972 | Acc: 41.970,60.835,67.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 3.433 | Acc: 42.188,70.312,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.077 | Acc: 50.818,75.670,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.027 | Acc: 51.143,75.629,94.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.037 | Acc: 50.461,75.384,93.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.026 | Acc: 50.318,75.530,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.023 | Acc: 50.526,75.224,93.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.027 | Acc: 50.297,75.039,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.036 | Acc: 50.122,74.839,93.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.033 | Acc: 50.029,74.942,93.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.040 | Acc: 49.944,74.871,93.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.041 | Acc: 50.031,74.841,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.051 | Acc: 49.961,74.622,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.065 | Acc: 49.900,74.404,93.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.071 | Acc: 49.898,74.327,93.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.077 | Acc: 49.780,74.299,93.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.084 | Acc: 49.746,74.146,93.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.088 | Acc: 49.730,74.146,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.092 | Acc: 49.684,74.081,93.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.092 | Acc: 49.682,74.132,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.096 | Acc: 49.705,74.085,93.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.551 | Acc: 42.969,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.988 | Acc: 43.564,61.235,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.986 | Acc: 43.312,61.490,67.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.966 | Acc: 42.969,61.475,67.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 3.083 | Acc: 52.344,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.064 | Acc: 49.405,75.037,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.014 | Acc: 50.419,75.267,93.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.013 | Acc: 50.102,75.256,93.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.020 | Acc: 50.029,74.961,93.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.013 | Acc: 50.317,75.077,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.004 | Acc: 50.458,75.129,93.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.025 | Acc: 50.139,74.850,93.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.033 | Acc: 50.082,74.714,93.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.037 | Acc: 50.190,74.633,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.050 | Acc: 49.992,74.475,93.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.052 | Acc: 50.067,74.463,93.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.051 | Acc: 50.120,74.400,93.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.061 | Acc: 49.967,74.353,93.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.069 | Acc: 49.878,74.324,93.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.081 | Acc: 49.829,74.188,93.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.085 | Acc: 49.764,74.121,92.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.090 | Acc: 49.812,74.088,92.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.093 | Acc: 49.942,74.076,92.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.102 | Acc: 49.834,73.901,92.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.458 | Acc: 46.875,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.824 | Acc: 41.927,61.570,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.839 | Acc: 42.797,61.261,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.870 | Acc: 42.585,61.130,67.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 3.157 | Acc: 46.094,71.094,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.011 | Acc: 49.888,75.186,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.985 | Acc: 50.514,75.438,94.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.003 | Acc: 50.359,75.768,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.990 | Acc: 50.318,75.810,94.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.004 | Acc: 50.371,75.549,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.007 | Acc: 50.433,75.394,94.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.007 | Acc: 50.549,75.316,94.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.022 | Acc: 50.378,75.228,94.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.034 | Acc: 50.194,75.073,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.041 | Acc: 50.288,75.066,94.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.045 | Acc: 50.226,74.919,94.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.044 | Acc: 50.207,74.964,93.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.056 | Acc: 50.159,74.773,93.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.063 | Acc: 50.025,74.722,93.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.074 | Acc: 49.914,74.580,93.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.079 | Acc: 49.883,74.521,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.081 | Acc: 49.803,74.514,93.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.087 | Acc: 49.872,74.394,93.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.096 | Acc: 49.766,74.278,93.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.582 | Acc: 42.969,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.893 | Acc: 42.262,63.207,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.843 | Acc: 42.645,62.976,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.892 | Acc: 42.303,61.924,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 3.055 | Acc: 47.656,75.781,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.976 | Acc: 49.963,76.488,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.018 | Acc: 49.143,75.686,93.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.036 | Acc: 49.501,75.461,93.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.016 | Acc: 49.855,75.666,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.011 | Acc: 50.000,75.541,93.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.020 | Acc: 49.955,75.342,93.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.020 | Acc: 50.061,75.299,93.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.020 | Acc: 50.082,75.194,93.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.030 | Acc: 50.000,75.035,93.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.039 | Acc: 50.062,74.953,93.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.052 | Acc: 49.975,74.809,93.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.054 | Acc: 50.019,74.737,93.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.057 | Acc: 50.090,74.793,93.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.063 | Acc: 50.131,74.711,93.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.064 | Acc: 50.184,74.647,93.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.075 | Acc: 50.122,74.525,92.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.078 | Acc: 50.119,74.430,92.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.083 | Acc: 50.095,74.292,92.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.091 | Acc: 50.016,74.229,92.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.352 | Acc: 50.781,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.812 | Acc: 44.048,62.388,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.813 | Acc: 43.750,61.738,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.801 | Acc: 43.891,61.335,67.789,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 2.873 | Acc: 50.000,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.001 | Acc: 50.893,76.079,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.992 | Acc: 50.877,76.067,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 50.051,75.628,94.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.007 | Acc: 50.338,75.772,94.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.027 | Acc: 50.217,75.789,94.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.028 | Acc: 50.252,75.665,94.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.030 | Acc: 50.338,75.460,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.022 | Acc: 50.383,75.398,93.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.023 | Acc: 50.376,75.255,93.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.042 | Acc: 50.187,75.031,93.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.044 | Acc: 50.170,74.965,93.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.040 | Acc: 50.204,75.062,93.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.043 | Acc: 50.242,74.952,93.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.052 | Acc: 50.178,74.844,93.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.063 | Acc: 50.049,74.727,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.068 | Acc: 50.000,74.632,93.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.079 | Acc: 49.929,74.528,93.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.079 | Acc: 49.974,74.478,93.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.082 | Acc: 49.988,74.397,92.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.752 | Acc: 41.406,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.908 | Acc: 42.485,61.384,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.923 | Acc: 42.359,60.938,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.952 | Acc: 42.149,60.592,67.277,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 2.861 | Acc: 47.656,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.977 | Acc: 51.451,75.149,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.979 | Acc: 50.934,75.476,94.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.952 | Acc: 50.948,75.602,94.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.969 | Acc: 50.897,75.424,94.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.974 | Acc: 50.959,75.039,94.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.983 | Acc: 50.988,74.929,94.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.996 | Acc: 50.742,74.917,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.004 | Acc: 50.597,74.908,94.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.016 | Acc: 50.376,74.711,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.018 | Acc: 50.373,74.670,93.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.019 | Acc: 50.368,74.664,93.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.021 | Acc: 50.337,74.595,93.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.029 | Acc: 50.248,74.452,93.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.035 | Acc: 50.178,74.444,93.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.040 | Acc: 50.122,74.432,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.053 | Acc: 50.029,74.294,93.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.063 | Acc: 50.007,74.175,93.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.068 | Acc: 50.004,74.113,93.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.077 | Acc: 49.951,74.053,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.736 | Acc: 44.531,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.949 | Acc: 41.443,60.565,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.955 | Acc: 41.673,60.747,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.946 | Acc: 41.714,60.681,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 3.220 | Acc: 47.656,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.068 | Acc: 50.000,75.484,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.017 | Acc: 50.686,75.133,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.019 | Acc: 50.384,75.397,93.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.008 | Acc: 50.280,75.569,93.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.016 | Acc: 50.178,75.611,93.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.997 | Acc: 50.271,75.743,94.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.004 | Acc: 50.249,75.687,94.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.005 | Acc: 50.257,75.529,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.009 | Acc: 50.203,75.483,93.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.009 | Acc: 50.163,75.490,93.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.013 | Acc: 50.244,75.435,93.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.022 | Acc: 50.091,75.272,93.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.029 | Acc: 50.129,75.099,93.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.032 | Acc: 50.211,75.100,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.033 | Acc: 50.096,75.127,93.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.033 | Acc: 50.124,75.102,93.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.042 | Acc: 50.005,74.943,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.050 | Acc: 49.983,74.885,93.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.061 | Acc: 49.918,74.690,93.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.500 | Acc: 47.656,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.779 | Acc: 44.829,62.835,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.822 | Acc: 44.093,61.966,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.837 | Acc: 43.763,61.655,67.508,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 3.196 | Acc: 48.438,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.032 | Acc: 50.372,75.372,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.017 | Acc: 50.629,75.743,93.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.003 | Acc: 50.231,75.794,94.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.011 | Acc: 49.913,75.781,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.991 | Acc: 50.340,75.696,94.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.006 | Acc: 50.084,75.491,94.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.004 | Acc: 50.144,75.377,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.012 | Acc: 50.000,75.252,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.006 | Acc: 50.160,75.285,94.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.008 | Acc: 50.105,75.257,94.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.006 | Acc: 50.265,75.194,94.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.006 | Acc: 50.259,75.178,94.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.018 | Acc: 50.204,75.153,93.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.023 | Acc: 50.195,74.972,93.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.028 | Acc: 50.210,74.938,93.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.032 | Acc: 50.219,74.888,93.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.040 | Acc: 50.179,74.828,93.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.048 | Acc: 50.087,74.673,93.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.049 | Acc: 50.082,74.645,93.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.305 | Acc: 49.219,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.944 | Acc: 42.336,62.240,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.932 | Acc: 42.645,61.033,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.940 | Acc: 42.252,61.168,67.175,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.469 | Acc: 44.531,71.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.002 | Acc: 51.302,76.190,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.999 | Acc: 50.610,75.057,93.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.025 | Acc: 49.859,75.615,93.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.040 | Acc: 49.441,75.415,93.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.035 | Acc: 49.613,75.503,93.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.031 | Acc: 49.619,75.639,93.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.022 | Acc: 49.900,75.626,93.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.019 | Acc: 50.112,75.577,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.030 | Acc: 50.147,75.401,93.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.027 | Acc: 50.214,75.393,93.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.023 | Acc: 50.318,75.375,93.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.024 | Acc: 50.331,75.402,93.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.028 | Acc: 50.213,75.338,93.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.035 | Acc: 50.214,75.183,93.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.043 | Acc: 50.158,75.029,93.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.045 | Acc: 50.221,74.990,93.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.052 | Acc: 50.158,74.963,93.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.064 | Acc: 50.037,74.823,93.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.068 | Acc: 50.012,74.781,93.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.690 | Acc: 50.781,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.951 | Acc: 42.001,61.384,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.954 | Acc: 42.569,60.861,67.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.950 | Acc: 42.623,60.963,66.842,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 2.608 | Acc: 52.344,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 51.339,77.195,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.963 | Acc: 50.838,76.715,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.950 | Acc: 51.101,76.434,93.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.965 | Acc: 50.646,76.071,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.978 | Acc: 50.449,75.851,93.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.985 | Acc: 50.213,75.659,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.991 | Acc: 50.083,75.499,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.989 | Acc: 50.131,75.524,94.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.994 | Acc: 50.207,75.535,93.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.006 | Acc: 50.074,75.494,93.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.008 | Acc: 50.060,75.414,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.013 | Acc: 50.130,75.360,93.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.024 | Acc: 50.099,75.296,93.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.029 | Acc: 50.047,75.239,93.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.034 | Acc: 50.086,75.169,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.039 | Acc: 50.124,75.044,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.043 | Acc: 50.076,75.011,93.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.055 | Acc: 50.022,74.803,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.061 | Acc: 50.043,74.703,93.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.727 | Acc: 43.750,57.812,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.827 | Acc: 43.936,61.719,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.867 | Acc: 43.788,61.014,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.881 | Acc: 43.289,60.733,68.558,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 2.966 | Acc: 53.906,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.947 | Acc: 51.786,75.818,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.969 | Acc: 51.239,75.724,94.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.976 | Acc: 50.768,75.922,94.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.954 | Acc: 50.829,75.801,94.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.945 | Acc: 51.006,75.804,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.950 | Acc: 50.768,75.814,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.958 | Acc: 50.776,75.676,94.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.970 | Acc: 50.713,75.597,94.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.971 | Acc: 50.583,75.505,94.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.978 | Acc: 50.583,75.354,94.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.976 | Acc: 50.693,75.329,94.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.981 | Acc: 50.742,75.207,94.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.988 | Acc: 50.694,75.162,94.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.987 | Acc: 50.664,75.183,94.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.994 | Acc: 50.623,75.148,93.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.999 | Acc: 50.555,75.092,93.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.009 | Acc: 50.527,75.037,93.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.018 | Acc: 50.483,74.948,93.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.022 | Acc: 50.529,74.953,93.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.379 | Acc: 50.000,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.773 | Acc: 42.894,62.835,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.759 | Acc: 43.274,62.348,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.773 | Acc: 42.956,61.949,68.609,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 2.746 | Acc: 50.781,77.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.980 | Acc: 50.112,74.665,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.916 | Acc: 51.239,76.220,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.920 | Acc: 51.012,76.486,94.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.894 | Acc: 51.148,76.726,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.904 | Acc: 50.982,76.532,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.915 | Acc: 50.794,76.575,94.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.908 | Acc: 51.042,76.551,94.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.930 | Acc: 50.791,76.266,94.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.940 | Acc: 50.729,76.045,94.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.950 | Acc: 50.591,75.929,94.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.968 | Acc: 50.498,75.778,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.979 | Acc: 50.292,75.694,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.987 | Acc: 50.233,75.623,93.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.997 | Acc: 50.164,75.467,93.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.999 | Acc: 50.262,75.387,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.008 | Acc: 50.207,75.239,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.022 | Acc: 50.112,75.032,93.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.033 | Acc: 50.095,74.870,93.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.037 | Acc: 50.152,74.776,93.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.589 | Acc: 42.969,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.874 | Acc: 41.592,62.091,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.892 | Acc: 41.482,61.433,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.917 | Acc: 41.086,61.104,67.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 2.820 | Acc: 43.750,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.032 | Acc: 49.368,75.260,93.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.028 | Acc: 49.409,75.781,93.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.981 | Acc: 50.512,76.140,93.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.980 | Acc: 50.772,75.752,94.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.971 | Acc: 50.874,75.650,94.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.967 | Acc: 50.923,75.562,94.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.972 | Acc: 50.931,75.659,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.974 | Acc: 50.820,75.500,94.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.987 | Acc: 50.652,75.449,94.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.989 | Acc: 50.567,75.330,94.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.987 | Acc: 50.576,75.396,94.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.990 | Acc: 50.707,75.327,93.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.994 | Acc: 50.697,75.290,93.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.994 | Acc: 50.781,75.295,93.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.001 | Acc: 50.724,75.239,93.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.010 | Acc: 50.628,75.127,93.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.012 | Acc: 50.628,75.126,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.008 | Acc: 50.623,75.128,93.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.016 | Acc: 50.564,75.012,93.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.624 | Acc: 44.531,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.909 | Acc: 43.043,62.165,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.931 | Acc: 42.454,61.643,67.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.934 | Acc: 42.264,61.258,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 2.919 | Acc: 50.000,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.989 | Acc: 50.707,75.372,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.994 | Acc: 50.400,75.648,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.968 | Acc: 50.871,75.781,94.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.968 | Acc: 50.704,75.829,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.941 | Acc: 51.346,76.106,94.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.944 | Acc: 51.311,75.904,94.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.947 | Acc: 51.247,75.826,94.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.950 | Acc: 51.048,75.849,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.951 | Acc: 51.200,75.790,94.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.956 | Acc: 51.046,75.746,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.959 | Acc: 51.064,75.643,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.969 | Acc: 50.901,75.558,94.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.974 | Acc: 50.814,75.431,93.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.980 | Acc: 50.831,75.334,93.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.986 | Acc: 50.768,75.350,93.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.993 | Acc: 50.657,75.343,93.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.004 | Acc: 50.499,75.158,93.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.012 | Acc: 50.491,75.045,93.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.018 | Acc: 50.476,74.988,93.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.635 | Acc: 49.219,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.992 | Acc: 41.629,61.682,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.993 | Acc: 42.016,61.414,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.978 | Acc: 41.867,61.245,66.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 3.230 | Acc: 57.031,73.438,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 51.414,76.749,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.953 | Acc: 51.658,76.067,93.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.958 | Acc: 51.319,75.909,93.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.953 | Acc: 51.427,75.878,93.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.968 | Acc: 51.060,75.804,93.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.978 | Acc: 51.046,75.568,93.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.967 | Acc: 51.092,75.632,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.972 | Acc: 51.063,75.718,93.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.961 | Acc: 51.157,75.837,93.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.969 | Acc: 50.944,75.742,93.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.965 | Acc: 50.983,75.746,93.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.976 | Acc: 50.914,75.619,93.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.990 | Acc: 50.745,75.629,93.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.997 | Acc: 50.920,75.542,93.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.999 | Acc: 50.940,75.478,93.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.010 | Acc: 50.883,75.382,93.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.015 | Acc: 50.861,75.341,93.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.018 | Acc: 50.874,75.329,93.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.022 | Acc: 50.878,75.310,93.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.683 | Acc: 47.656,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.964 | Acc: 43.229,60.900,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.905 | Acc: 43.712,61.280,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.880 | Acc: 43.251,61.680,67.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 2.813 | Acc: 53.125,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.960 | Acc: 51.451,76.265,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.951 | Acc: 51.353,76.105,94.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.937 | Acc: 51.691,75.832,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.924 | Acc: 51.620,76.119,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.935 | Acc: 51.300,75.882,94.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.928 | Acc: 51.401,76.130,94.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.929 | Acc: 51.441,76.053,94.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.942 | Acc: 51.208,75.907,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.947 | Acc: 51.265,75.824,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.950 | Acc: 51.279,75.840,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.950 | Acc: 51.315,75.834,94.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.953 | Acc: 51.355,75.729,93.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.963 | Acc: 51.206,75.641,93.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.970 | Acc: 51.176,75.517,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.972 | Acc: 51.106,75.423,93.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.988 | Acc: 50.910,75.268,93.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.999 | Acc: 50.749,75.236,93.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.007 | Acc: 50.621,75.238,93.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.016 | Acc: 50.609,75.115,93.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.484 | Acc: 48.438,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.853 | Acc: 43.415,62.202,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.875 | Acc: 43.293,61.700,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.872 | Acc: 43.135,61.501,67.136,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 2.441 | Acc: 55.469,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.913 | Acc: 51.302,76.749,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.926 | Acc: 51.220,76.562,94.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.928 | Acc: 51.550,76.947,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.954 | Acc: 51.244,76.659,94.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.947 | Acc: 51.323,76.454,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.941 | Acc: 51.227,76.472,94.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.943 | Acc: 51.152,76.263,94.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.954 | Acc: 50.917,76.116,94.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.954 | Acc: 51.161,76.101,94.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.951 | Acc: 50.941,76.228,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.959 | Acc: 50.866,76.007,94.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.958 | Acc: 50.953,75.866,94.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.962 | Acc: 50.940,75.769,94.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.976 | Acc: 50.848,75.576,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.981 | Acc: 50.763,75.542,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.988 | Acc: 50.725,75.496,93.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.995 | Acc: 50.635,75.461,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.001 | Acc: 50.554,75.424,93.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.011 | Acc: 50.459,75.322,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.520 | Acc: 44.531,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.788 | Acc: 43.006,61.905,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.792 | Acc: 43.369,61.623,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.804 | Acc: 43.276,61.527,67.713,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 2.946 | Acc: 47.656,78.125,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.944 | Acc: 49.442,77.344,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.936 | Acc: 51.124,76.925,94.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.916 | Acc: 51.844,76.857,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.904 | Acc: 52.064,76.591,94.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.927 | Acc: 51.856,76.292,94.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.937 | Acc: 51.517,76.214,94.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.944 | Acc: 51.596,76.114,94.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.957 | Acc: 51.490,75.995,94.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.964 | Acc: 51.308,75.803,93.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.971 | Acc: 51.232,75.727,93.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.976 | Acc: 51.061,75.647,93.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.982 | Acc: 51.005,75.489,93.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.983 | Acc: 50.979,75.551,93.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.983 | Acc: 50.956,75.537,93.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.990 | Acc: 50.877,75.431,93.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.992 | Acc: 50.876,75.458,93.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.994 | Acc: 50.937,75.481,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.996 | Acc: 50.902,75.416,93.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.002 | Acc: 50.845,75.373,93.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.307 | Acc: 48.438,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.824 | Acc: 43.266,62.388,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.830 | Acc: 42.950,61.986,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.831 | Acc: 42.661,61.770,68.558,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.618 | Acc: 59.375,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.994 | Acc: 50.260,75.707,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.967 | Acc: 50.686,76.944,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.997 | Acc: 50.512,76.639,93.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.982 | Acc: 51.167,76.157,93.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.962 | Acc: 51.400,76.276,94.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.958 | Acc: 51.265,76.046,94.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.957 | Acc: 51.208,75.964,94.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.943 | Acc: 51.092,76.359,94.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.941 | Acc: 51.070,76.446,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.949 | Acc: 50.867,76.271,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.954 | Acc: 50.813,76.209,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.953 | Acc: 50.810,76.144,94.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.957 | Acc: 50.757,76.030,94.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.967 | Acc: 50.589,75.923,94.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.977 | Acc: 50.488,75.745,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.982 | Acc: 50.533,75.740,93.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.991 | Acc: 50.403,75.598,93.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.993 | Acc: 50.364,75.515,93.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.997 | Acc: 50.463,75.402,93.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.564 | Acc: 48.438,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.844 | Acc: 43.006,62.909,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.828 | Acc: 43.159,62.576,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.846 | Acc: 42.841,62.141,67.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 2.882 | Acc: 53.906,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.972 | Acc: 50.037,76.786,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.949 | Acc: 51.010,76.925,94.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.930 | Acc: 51.101,76.780,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.935 | Acc: 50.829,76.620,94.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.935 | Acc: 50.944,76.655,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.940 | Acc: 51.136,76.517,94.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.949 | Acc: 51.230,76.302,94.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.963 | Acc: 50.970,76.131,94.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.964 | Acc: 50.799,75.967,94.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.979 | Acc: 50.556,75.637,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.980 | Acc: 50.619,75.675,93.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.984 | Acc: 50.642,75.652,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.986 | Acc: 50.566,75.721,93.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.986 | Acc: 50.589,75.715,93.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.992 | Acc: 50.649,75.651,93.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.995 | Acc: 50.669,75.596,93.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.995 | Acc: 50.719,75.593,93.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.999 | Acc: 50.673,75.472,93.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.000 | Acc: 50.662,75.511,93.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.563 | Acc: 46.875,61.719,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.805 | Acc: 43.787,62.054,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.773 | Acc: 43.426,61.833,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.773 | Acc: 43.558,61.872,68.289,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 2.866 | Acc: 50.781,77.344,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.832 | Acc: 52.604,77.790,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.885 | Acc: 51.048,77.668,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.905 | Acc: 50.897,77.126,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.893 | Acc: 50.926,76.852,95.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.875 | Acc: 51.245,76.825,95.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.874 | Acc: 51.504,76.614,94.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.891 | Acc: 51.285,76.485,94.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.889 | Acc: 51.344,76.499,94.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.900 | Acc: 51.127,76.347,94.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.920 | Acc: 50.855,76.026,94.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.932 | Acc: 50.757,75.930,94.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.945 | Acc: 50.606,75.755,94.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.955 | Acc: 50.587,75.736,94.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.965 | Acc: 50.489,75.659,94.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.968 | Acc: 50.485,75.571,94.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.977 | Acc: 50.533,75.501,94.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.978 | Acc: 50.625,75.506,93.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.984 | Acc: 50.593,75.409,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.990 | Acc: 50.554,75.377,93.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.590 | Acc: 45.312,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.899 | Acc: 41.481,62.388,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.949 | Acc: 42.035,61.509,67.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.970 | Acc: 41.867,61.168,67.636,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.888 | Acc: 49.219,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.015 | Acc: 48.958,75.260,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 50.705,77.058,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.912 | Acc: 51.242,76.844,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.916 | Acc: 51.302,76.543,94.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.901 | Acc: 51.586,76.524,94.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.910 | Acc: 51.343,76.634,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.904 | Acc: 51.490,76.568,94.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.920 | Acc: 51.121,76.165,94.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.927 | Acc: 50.997,76.148,94.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.938 | Acc: 50.999,75.933,94.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.946 | Acc: 50.937,75.799,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.956 | Acc: 50.872,75.616,94.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.952 | Acc: 50.958,75.721,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.958 | Acc: 50.909,75.639,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.962 | Acc: 50.976,75.607,93.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.962 | Acc: 51.015,75.616,93.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.968 | Acc: 51.070,75.596,93.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.969 | Acc: 51.156,75.569,93.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.971 | Acc: 51.134,75.591,93.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.482 | Acc: 46.875,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.845 | Acc: 43.638,62.426,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.831 | Acc: 43.312,62.138,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.843 | Acc: 43.186,62.116,67.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.354 | Acc: 60.156,85.938,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.948 | Acc: 49.554,75.595,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.913 | Acc: 50.781,76.315,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.900 | Acc: 50.858,77.024,94.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.893 | Acc: 51.148,77.054,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.900 | Acc: 51.238,76.833,94.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.912 | Acc: 51.001,76.653,94.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.903 | Acc: 50.986,76.734,94.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.908 | Acc: 51.237,76.727,94.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.910 | Acc: 51.291,76.649,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.921 | Acc: 51.077,76.512,94.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.927 | Acc: 51.007,76.460,94.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.936 | Acc: 50.973,76.362,94.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.945 | Acc: 50.898,76.185,94.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.945 | Acc: 50.934,76.221,94.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.956 | Acc: 50.960,76.108,93.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.967 | Acc: 50.908,75.998,93.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.973 | Acc: 50.887,75.985,93.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.978 | Acc: 50.885,75.905,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.981 | Acc: 50.949,75.865,93.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.769 | Acc: 45.312,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.954 | Acc: 42.746,61.235,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.947 | Acc: 42.550,61.280,66.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.966 | Acc: 42.546,61.014,66.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 3.316 | Acc: 42.188,69.531,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.913 | Acc: 52.232,75.707,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.907 | Acc: 52.001,76.315,94.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.884 | Acc: 52.100,76.831,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.914 | Acc: 51.726,76.630,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.907 | Acc: 51.655,76.516,94.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.911 | Acc: 51.666,76.601,94.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.920 | Acc: 51.823,76.507,93.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.929 | Acc: 51.621,76.422,93.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.935 | Acc: 51.588,76.260,93.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.942 | Acc: 51.477,76.240,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.951 | Acc: 51.449,76.156,93.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.967 | Acc: 51.284,75.927,93.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.977 | Acc: 51.161,75.811,93.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.985 | Acc: 51.101,75.712,93.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.992 | Acc: 51.033,75.574,93.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.991 | Acc: 51.061,75.565,93.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.990 | Acc: 51.026,75.552,93.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.992 | Acc: 51.013,75.541,93.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.996 | Acc: 50.990,75.484,93.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 46.094,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.731 | Acc: 44.903,63.318,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.748 | Acc: 45.065,62.957,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.775 | Acc: 44.493,62.423,67.994,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 2.796 | Acc: 53.125,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.952 | Acc: 50.707,77.753,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.949 | Acc: 50.419,76.867,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.947 | Acc: 50.564,76.921,94.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.948 | Acc: 50.926,76.649,94.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.937 | Acc: 50.766,76.818,94.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.941 | Acc: 50.794,76.814,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.945 | Acc: 50.809,76.546,94.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.942 | Acc: 50.713,76.747,94.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.944 | Acc: 50.807,76.701,94.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.942 | Acc: 50.898,76.671,94.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.948 | Acc: 50.863,76.400,94.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.951 | Acc: 50.985,76.374,94.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.954 | Acc: 51.003,76.365,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.962 | Acc: 50.937,76.340,93.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.971 | Acc: 50.862,76.186,93.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.974 | Acc: 50.862,76.166,93.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.977 | Acc: 50.884,76.104,93.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.977 | Acc: 50.857,76.125,93.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.981 | Acc: 50.808,76.087,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.489 | Acc: 47.656,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.830 | Acc: 43.787,61.905,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.831 | Acc: 43.178,61.928,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.811 | Acc: 43.212,62.116,68.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 2.801 | Acc: 56.250,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.864 | Acc: 51.749,77.121,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.854 | Acc: 51.734,77.077,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.887 | Acc: 51.230,77.177,94.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.865 | Acc: 51.543,77.527,94.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.867 | Acc: 51.655,77.498,94.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.873 | Acc: 51.666,77.311,94.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.883 | Acc: 51.607,77.072,94.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.885 | Acc: 51.698,77.004,94.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.895 | Acc: 51.519,76.860,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.904 | Acc: 51.539,76.667,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.926 | Acc: 51.347,76.502,94.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.929 | Acc: 51.384,76.436,94.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.934 | Acc: 51.305,76.389,94.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.935 | Acc: 51.318,76.373,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.938 | Acc: 51.215,76.331,94.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.940 | Acc: 51.266,76.300,93.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.950 | Acc: 51.166,76.180,93.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.956 | Acc: 51.169,76.041,93.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.964 | Acc: 51.118,75.912,93.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.548 | Acc: 45.312,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.925 | Acc: 42.746,61.793,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.972 | Acc: 42.778,61.128,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.980 | Acc: 42.380,60.976,66.419,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 2.805 | Acc: 55.469,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.798 | Acc: 53.646,77.790,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.829 | Acc: 52.649,77.687,94.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.830 | Acc: 52.459,77.664,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.851 | Acc: 51.977,77.180,94.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.853 | Acc: 52.042,77.220,94.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.857 | Acc: 51.892,77.228,94.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.867 | Acc: 51.773,77.022,94.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.874 | Acc: 51.495,76.844,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.881 | Acc: 51.398,76.752,94.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.893 | Acc: 51.193,76.566,94.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.909 | Acc: 50.997,76.471,94.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.917 | Acc: 51.018,76.371,94.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.932 | Acc: 51.030,76.179,94.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.937 | Acc: 50.962,76.065,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.936 | Acc: 50.955,76.108,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.935 | Acc: 51.010,76.112,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.944 | Acc: 50.912,75.974,93.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.954 | Acc: 50.894,75.807,93.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.961 | Acc: 50.837,75.712,93.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.491 | Acc: 50.000,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.913 | Acc: 42.299,62.016,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.907 | Acc: 42.607,61.757,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.905 | Acc: 42.341,61.399,67.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 2.964 | Acc: 52.344,75.781,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.878 | Acc: 52.121,76.897,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.912 | Acc: 51.010,76.239,94.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.904 | Acc: 50.999,76.473,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.892 | Acc: 51.013,76.456,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.889 | Acc: 51.439,76.369,94.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.880 | Acc: 51.246,76.530,94.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.890 | Acc: 51.042,76.430,94.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.882 | Acc: 51.373,76.558,94.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.879 | Acc: 51.360,76.666,94.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.890 | Acc: 51.341,76.632,94.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.904 | Acc: 51.244,76.456,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.914 | Acc: 51.173,76.400,94.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.914 | Acc: 51.329,76.464,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.919 | Acc: 51.348,76.387,94.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.925 | Acc: 51.298,76.272,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.935 | Acc: 51.180,76.156,94.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.933 | Acc: 51.129,76.136,93.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.945 | Acc: 51.026,76.024,93.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.951 | Acc: 51.001,75.960,93.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.437 | Acc: 41.406,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.731 | Acc: 42.857,62.946,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.771 | Acc: 43.407,62.024,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.819 | Acc: 43.084,61.616,68.097,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.765 | Acc: 54.688,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.941 | Acc: 50.707,76.860,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.954 | Acc: 50.610,76.601,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.923 | Acc: 50.820,77.049,94.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.899 | Acc: 51.061,77.035,94.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.889 | Acc: 51.300,77.189,94.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.885 | Acc: 51.724,77.021,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.874 | Acc: 51.657,76.889,94.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.883 | Acc: 51.650,76.926,94.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.889 | Acc: 51.493,76.873,94.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.894 | Acc: 51.461,76.850,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.908 | Acc: 51.205,76.669,94.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.910 | Acc: 51.229,76.682,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.916 | Acc: 51.221,76.625,94.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.921 | Acc: 51.179,76.638,94.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.927 | Acc: 51.191,76.560,94.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.935 | Acc: 51.132,76.429,93.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.943 | Acc: 51.086,76.267,93.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.946 | Acc: 51.069,76.234,93.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.952 | Acc: 51.103,76.130,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.582 | Acc: 46.094,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.919 | Acc: 43.973,62.909,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.959 | Acc: 43.274,61.376,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.965 | Acc: 43.007,61.181,65.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 3.184 | Acc: 44.531,72.656,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.884 | Acc: 51.711,78.385,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.889 | Acc: 51.753,77.649,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.909 | Acc: 51.255,77.395,94.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.893 | Acc: 51.206,77.488,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.878 | Acc: 51.377,77.630,95.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.866 | Acc: 51.769,77.550,94.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.866 | Acc: 51.651,77.554,94.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.879 | Acc: 51.436,77.344,94.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.886 | Acc: 51.351,77.236,94.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.900 | Acc: 51.154,77.025,94.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.898 | Acc: 51.354,76.973,94.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.905 | Acc: 51.404,76.929,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.909 | Acc: 51.458,76.844,94.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.918 | Acc: 51.335,76.685,94.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.930 | Acc: 51.238,76.542,93.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.928 | Acc: 51.307,76.482,93.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.928 | Acc: 51.372,76.480,93.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.931 | Acc: 51.324,76.459,93.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.942 | Acc: 51.185,76.312,93.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.441 | Acc: 48.438,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.892 | Acc: 41.555,62.165,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.918 | Acc: 42.130,62.176,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.920 | Acc: 42.098,61.783,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 2.905 | Acc: 43.750,78.125,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.854 | Acc: 52.716,77.790,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.812 | Acc: 52.782,78.011,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.831 | Acc: 52.497,77.587,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.821 | Acc: 52.633,77.652,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.828 | Acc: 52.529,77.429,95.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.856 | Acc: 52.002,77.169,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.863 | Acc: 51.762,77.045,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.880 | Acc: 51.465,76.800,94.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.885 | Acc: 51.416,76.787,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.895 | Acc: 51.403,76.734,94.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 51.393,76.669,94.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.901 | Acc: 51.319,76.533,94.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.909 | Acc: 51.362,76.398,94.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.915 | Acc: 51.343,76.360,94.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.918 | Acc: 51.363,76.321,94.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.917 | Acc: 51.309,76.351,94.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.921 | Acc: 51.379,76.269,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.927 | Acc: 51.392,76.249,94.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.926 | Acc: 51.437,76.236,94.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.750 | Acc: 41.406,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.884 | Acc: 41.443,61.942,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.884 | Acc: 41.997,61.414,67.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.919 | Acc: 41.855,60.963,67.469,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 2.803 | Acc: 49.219,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.025 | Acc: 50.930,75.818,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.954 | Acc: 51.867,76.543,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.916 | Acc: 51.934,77.395,94.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.907 | Acc: 51.698,77.045,94.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.903 | Acc: 51.694,77.065,94.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.896 | Acc: 51.582,77.169,94.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.890 | Acc: 51.612,77.277,94.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.894 | Acc: 51.538,77.213,94.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.895 | Acc: 51.688,77.020,94.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.904 | Acc: 51.648,76.908,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.912 | Acc: 51.478,76.792,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.915 | Acc: 51.582,76.760,94.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.916 | Acc: 51.586,76.775,94.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.918 | Acc: 51.532,76.674,94.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.919 | Acc: 51.539,76.625,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.925 | Acc: 51.441,76.548,94.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.926 | Acc: 51.409,76.457,94.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.932 | Acc: 51.446,76.385,93.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.943 | Acc: 51.247,76.226,93.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.646 | Acc: 46.094,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.950 | Acc: 42.225,61.012,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.986 | Acc: 42.550,60.861,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.008 | Acc: 42.226,60.925,67.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 2.595 | Acc: 53.125,78.125,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.825 | Acc: 52.195,77.716,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.859 | Acc: 51.925,76.905,94.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.876 | Acc: 51.562,77.164,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.855 | Acc: 52.074,77.324,94.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.868 | Acc: 51.733,77.452,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.856 | Acc: 52.008,77.615,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.863 | Acc: 51.801,77.477,94.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.874 | Acc: 51.660,77.300,94.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.878 | Acc: 51.727,77.244,94.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.888 | Acc: 51.531,77.169,94.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.890 | Acc: 51.573,77.160,94.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.899 | Acc: 51.488,77.007,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.907 | Acc: 51.383,76.889,94.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.919 | Acc: 51.298,76.802,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.919 | Acc: 51.407,76.726,94.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.921 | Acc: 51.455,76.738,94.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.923 | Acc: 51.462,76.668,93.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.927 | Acc: 51.513,76.543,93.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.928 | Acc: 51.575,76.530,93.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.435 | Acc: 40.625,64.062,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.926 | Acc: 42.522,61.979,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.920 | Acc: 42.740,61.528,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.901 | Acc: 42.777,61.693,67.495,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 3.285 | Acc: 49.219,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.869 | Acc: 52.307,77.530,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.894 | Acc: 51.696,76.886,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.870 | Acc: 52.088,76.729,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.865 | Acc: 51.977,76.775,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.864 | Acc: 51.648,76.787,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.879 | Acc: 51.343,76.582,94.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.887 | Acc: 51.285,76.485,94.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.889 | Acc: 51.344,76.475,94.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.892 | Acc: 51.347,76.506,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.897 | Acc: 51.415,76.508,94.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.896 | Acc: 51.513,76.520,94.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.901 | Acc: 51.394,76.520,94.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.916 | Acc: 51.161,76.428,94.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.916 | Acc: 51.198,76.415,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.920 | Acc: 51.147,76.370,94.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.922 | Acc: 51.154,76.385,94.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.929 | Acc: 51.075,76.255,94.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.932 | Acc: 51.140,76.240,94.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.935 | Acc: 51.122,76.222,93.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.857 | Acc: 43.750,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.894 | Acc: 42.188,60.491,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.909 | Acc: 42.073,60.499,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.908 | Acc: 42.213,60.758,67.764,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.818 | Acc: 54.688,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.883 | Acc: 51.637,77.307,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.845 | Acc: 52.210,78.163,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.852 | Acc: 51.665,78.074,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.873 | Acc: 51.466,77.604,94.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.866 | Acc: 51.856,77.429,94.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.863 | Acc: 51.943,77.415,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.874 | Acc: 51.745,77.128,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.877 | Acc: 51.694,77.116,94.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.876 | Acc: 51.886,77.046,94.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.878 | Acc: 51.889,76.889,94.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.887 | Acc: 51.771,76.672,94.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.903 | Acc: 51.601,76.423,94.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.906 | Acc: 51.509,76.440,94.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.909 | Acc: 51.596,76.412,94.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.918 | Acc: 51.617,76.324,94.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.921 | Acc: 51.511,76.341,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.929 | Acc: 51.420,76.239,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.930 | Acc: 51.491,76.184,93.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.934 | Acc: 51.491,76.208,93.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.407 | Acc: 45.312,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.852 | Acc: 43.266,63.058,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.846 | Acc: 42.912,62.309,67.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.837 | Acc: 42.892,62.129,67.892,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 2.686 | Acc: 57.812,76.562,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.877 | Acc: 51.116,78.534,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.851 | Acc: 51.391,77.934,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.843 | Acc: 51.588,77.920,94.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.834 | Acc: 52.035,78.067,94.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.849 | Acc: 51.717,77.870,94.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.855 | Acc: 51.672,77.893,94.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.851 | Acc: 51.707,77.931,94.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 51.577,77.776,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.864 | Acc: 51.588,77.663,94.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.860 | Acc: 51.586,77.534,94.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.861 | Acc: 51.651,77.404,94.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.868 | Acc: 51.543,77.324,94.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.872 | Acc: 51.506,77.242,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.877 | Acc: 51.504,77.113,94.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.881 | Acc: 51.441,77.066,94.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.883 | Acc: 51.414,76.981,94.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.895 | Acc: 51.338,76.819,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.898 | Acc: 51.400,76.729,94.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.908 | Acc: 51.351,76.616,93.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.533 | Acc: 45.312,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.842 | Acc: 43.155,62.537,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.876 | Acc: 43.102,61.757,66.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.876 | Acc: 43.238,61.565,65.894,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 2.784 | Acc: 50.000,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.894 | Acc: 52.269,78.795,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.852 | Acc: 52.725,78.201,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.881 | Acc: 52.100,77.702,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.876 | Acc: 52.141,77.566,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.882 | Acc: 51.841,77.344,94.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.902 | Acc: 51.595,77.202,93.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.900 | Acc: 51.485,77.183,93.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.896 | Acc: 51.611,77.188,93.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.894 | Acc: 51.765,77.219,93.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.892 | Acc: 51.908,77.118,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 51.930,77.068,93.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.899 | Acc: 51.780,76.964,93.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.912 | Acc: 51.616,76.838,93.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.916 | Acc: 51.521,76.782,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.924 | Acc: 51.441,76.768,93.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.925 | Acc: 51.446,76.667,93.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.926 | Acc: 51.457,76.643,93.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.932 | Acc: 51.482,76.593,93.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.937 | Acc: 51.503,76.526,93.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.800 | Acc: 43.750,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.032 | Acc: 39.881,62.314,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.001 | Acc: 40.282,62.024,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.007 | Acc: 40.061,61.655,68.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 2.638 | Acc: 57.812,81.250,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.908 | Acc: 50.744,77.455,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.877 | Acc: 51.734,77.439,94.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.894 | Acc: 51.742,76.665,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.887 | Acc: 51.717,76.833,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.866 | Acc: 51.926,76.988,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.858 | Acc: 52.131,77.092,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.868 | Acc: 52.056,77.061,94.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.876 | Acc: 52.009,76.931,94.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.878 | Acc: 51.977,76.804,94.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.883 | Acc: 51.920,76.601,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.893 | Acc: 51.849,76.570,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.889 | Acc: 51.832,76.611,94.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.893 | Acc: 51.808,76.542,94.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.895 | Acc: 51.829,76.521,94.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.896 | Acc: 51.866,76.508,94.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.903 | Acc: 51.752,76.441,94.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.904 | Acc: 51.750,76.388,94.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.908 | Acc: 51.677,76.346,93.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.914 | Acc: 51.634,76.300,93.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.552 | Acc: 43.750,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.853 | Acc: 42.597,61.272,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.855 | Acc: 42.969,61.490,68.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.850 | Acc: 42.828,61.514,68.238,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 3.528 | Acc: 42.969,67.969,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.907 | Acc: 51.302,77.269,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.889 | Acc: 51.734,77.611,94.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.869 | Acc: 51.716,77.830,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.884 | Acc: 51.331,77.141,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.893 | Acc: 51.044,77.027,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.893 | Acc: 51.169,76.956,94.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.891 | Acc: 51.369,76.823,94.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.898 | Acc: 51.373,76.757,94.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.901 | Acc: 51.282,76.670,94.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.903 | Acc: 51.294,76.605,94.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.901 | Acc: 51.389,76.594,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.906 | Acc: 51.349,76.520,94.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.904 | Acc: 51.410,76.530,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.907 | Acc: 51.421,76.479,94.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.912 | Acc: 51.381,76.479,94.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.923 | Acc: 51.278,76.319,94.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.926 | Acc: 51.191,76.310,94.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.926 | Acc: 51.214,76.372,94.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.929 | Acc: 51.171,76.384,93.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.501 | Acc: 43.750,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.942 | Acc: 41.592,61.310,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.960 | Acc: 41.387,60.880,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.960 | Acc: 41.317,60.989,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.786 | Acc: 52.344,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.773 | Acc: 52.195,78.013,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.786 | Acc: 52.325,78.563,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.786 | Acc: 52.267,78.522,95.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.785 | Acc: 52.469,78.540,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.802 | Acc: 52.382,78.102,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.817 | Acc: 52.305,77.815,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.835 | Acc: 52.050,77.698,95.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.843 | Acc: 51.926,77.548,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.839 | Acc: 51.977,77.430,94.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.841 | Acc: 51.978,77.441,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.849 | Acc: 51.962,77.298,94.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.847 | Acc: 52.013,77.234,94.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.860 | Acc: 51.916,77.032,94.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.863 | Acc: 51.891,76.980,94.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.871 | Acc: 51.786,76.939,94.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.883 | Acc: 51.670,76.823,94.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.887 | Acc: 51.714,76.826,94.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.893 | Acc: 51.733,76.729,94.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.904 | Acc: 51.669,76.581,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 47.656,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.793 | Acc: 43.750,62.277,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.777 | Acc: 43.464,62.271,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.800 | Acc: 43.276,62.039,68.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 2.868 | Acc: 50.781,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.911 | Acc: 50.298,77.232,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.853 | Acc: 51.162,77.973,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.841 | Acc: 51.434,77.600,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.845 | Acc: 51.418,77.537,95.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.868 | Acc: 51.029,77.406,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.876 | Acc: 50.962,77.395,94.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.872 | Acc: 51.230,77.477,94.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.873 | Acc: 51.218,77.324,94.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.875 | Acc: 51.411,77.275,94.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.877 | Acc: 51.423,77.227,94.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.884 | Acc: 51.396,77.008,94.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.901 | Acc: 51.131,76.845,94.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.900 | Acc: 51.221,76.763,94.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.898 | Acc: 51.298,76.877,94.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.906 | Acc: 51.241,76.765,94.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.910 | Acc: 51.317,76.721,93.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.909 | Acc: 51.368,76.670,93.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.910 | Acc: 51.348,76.640,93.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.919 | Acc: 51.263,76.610,93.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.589 | Acc: 48.438,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.873 | Acc: 43.192,62.165,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.915 | Acc: 42.969,61.052,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.909 | Acc: 42.969,61.040,67.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 2.912 | Acc: 48.438,73.438,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.814 | Acc: 51.079,77.493,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.786 | Acc: 51.562,77.553,94.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.792 | Acc: 52.075,77.485,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 52.257,77.758,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.813 | Acc: 51.957,77.522,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.817 | Acc: 52.234,77.421,94.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.824 | Acc: 52.255,77.399,94.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.835 | Acc: 52.062,77.349,94.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.847 | Acc: 51.886,77.292,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.859 | Acc: 51.765,77.223,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.873 | Acc: 51.630,77.047,94.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 51.702,77.110,94.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.872 | Acc: 51.760,77.095,94.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.873 | Acc: 51.732,77.027,94.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.880 | Acc: 51.648,77.004,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.887 | Acc: 51.643,76.932,94.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.894 | Acc: 51.622,76.867,93.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.900 | Acc: 51.526,76.766,93.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.908 | Acc: 51.423,76.675,93.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.752 | Acc: 43.750,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.958 | Acc: 41.146,61.830,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.930 | Acc: 41.502,61.738,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.934 | Acc: 41.240,61.501,67.956,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.957 | Acc: 40.625,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.940 | Acc: 50.707,76.637,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.911 | Acc: 51.486,77.306,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.886 | Acc: 51.844,77.536,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.866 | Acc: 51.823,77.951,94.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.855 | Acc: 51.818,78.164,95.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.841 | Acc: 52.098,78.048,95.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.849 | Acc: 52.000,77.848,94.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.861 | Acc: 51.820,77.649,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.867 | Acc: 51.550,77.542,94.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.862 | Acc: 51.621,77.480,94.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.860 | Acc: 51.665,77.528,94.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.868 | Acc: 51.644,77.396,94.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.874 | Acc: 51.667,77.299,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.878 | Acc: 51.551,77.219,94.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.879 | Acc: 51.638,77.206,94.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.888 | Acc: 51.492,77.113,94.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.885 | Acc: 51.487,77.163,94.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.888 | Acc: 51.482,77.136,94.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.892 | Acc: 51.444,77.044,94.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.623 | Acc: 48.438,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.858 | Acc: 41.853,62.500,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.860 | Acc: 41.749,61.566,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.863 | Acc: 42.136,61.770,68.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 3.148 | Acc: 46.094,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.889 | Acc: 50.781,77.493,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.853 | Acc: 50.915,77.191,95.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.853 | Acc: 50.909,77.421,95.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.837 | Acc: 51.177,77.797,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.831 | Acc: 51.346,78.009,95.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.838 | Acc: 51.395,77.912,94.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.839 | Acc: 51.585,77.865,94.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.834 | Acc: 51.645,77.805,95.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.850 | Acc: 51.355,77.642,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.855 | Acc: 51.454,77.526,94.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.866 | Acc: 51.301,77.312,94.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.868 | Acc: 51.439,77.256,94.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.865 | Acc: 51.473,77.302,94.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.866 | Acc: 51.510,77.335,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.872 | Acc: 51.389,77.188,94.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.880 | Acc: 51.426,77.047,94.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.880 | Acc: 51.457,77.053,94.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.885 | Acc: 51.474,77.023,94.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.889 | Acc: 51.450,76.921,94.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.778 | Acc: 48.438,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.851 | Acc: 44.680,62.054,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.844 | Acc: 44.074,62.062,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.841 | Acc: 44.070,61.770,67.495,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 2.605 | Acc: 55.469,78.125,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.778 | Acc: 53.199,79.167,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.810 | Acc: 52.725,78.601,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.827 | Acc: 52.395,78.253,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.846 | Acc: 51.842,78.096,94.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.843 | Acc: 52.088,78.001,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.825 | Acc: 52.370,78.060,94.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.845 | Acc: 52.033,77.737,94.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.860 | Acc: 51.795,77.523,94.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.845 | Acc: 51.973,77.680,94.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.858 | Acc: 51.897,77.530,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.858 | Acc: 51.994,77.510,94.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.861 | Acc: 52.062,77.302,94.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.870 | Acc: 52.110,77.134,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.872 | Acc: 52.163,77.055,94.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.880 | Acc: 52.139,77.050,94.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.886 | Acc: 52.078,76.984,94.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.892 | Acc: 52.037,76.883,94.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.900 | Acc: 51.891,76.842,93.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.905 | Acc: 51.835,76.784,93.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.638 | Acc: 48.438,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.867 | Acc: 44.159,61.384,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.851 | Acc: 44.341,61.795,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.866 | Acc: 44.121,61.629,67.725,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 2.634 | Acc: 59.375,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.927 | Acc: 50.186,76.339,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.849 | Acc: 52.191,77.877,94.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.846 | Acc: 52.318,77.715,94.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.832 | Acc: 52.778,77.758,94.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.833 | Acc: 52.584,77.870,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.833 | Acc: 52.370,77.725,94.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.831 | Acc: 52.438,77.715,94.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.839 | Acc: 52.121,77.451,94.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.838 | Acc: 52.244,77.426,94.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.842 | Acc: 52.352,77.336,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.857 | Acc: 52.132,77.167,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.870 | Acc: 51.948,77.062,94.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.874 | Acc: 51.928,76.979,94.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.882 | Acc: 51.879,76.902,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.888 | Acc: 51.830,76.822,94.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.889 | Acc: 51.835,76.816,93.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.893 | Acc: 51.853,76.727,93.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.901 | Acc: 51.742,76.636,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.902 | Acc: 51.716,76.624,93.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.435 | Acc: 45.312,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.766 | Acc: 44.754,63.058,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.739 | Acc: 44.512,62.538,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.726 | Acc: 44.211,62.321,68.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 2.747 | Acc: 50.000,80.469,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.824 | Acc: 52.418,78.162,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.802 | Acc: 53.163,78.106,94.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.789 | Acc: 52.920,78.714,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.783 | Acc: 52.942,78.511,95.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.777 | Acc: 52.676,78.736,95.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.790 | Acc: 52.382,78.622,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.802 | Acc: 52.028,78.552,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.808 | Acc: 51.931,78.421,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.825 | Acc: 51.891,78.160,94.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.830 | Acc: 51.885,78.039,94.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.845 | Acc: 51.654,77.807,94.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.853 | Acc: 51.501,77.697,94.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.860 | Acc: 51.536,77.613,94.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.862 | Acc: 51.440,77.611,94.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.872 | Acc: 51.446,77.346,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.872 | Acc: 51.485,77.353,94.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.877 | Acc: 51.558,77.270,94.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.883 | Acc: 51.528,77.151,94.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.889 | Acc: 51.585,77.007,94.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.395 | Acc: 50.000,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.717 | Acc: 44.010,64.211,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.768 | Acc: 44.207,62.843,66.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.797 | Acc: 44.454,62.180,66.662,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.601 | Acc: 58.594,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.813 | Acc: 54.092,78.088,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.803 | Acc: 53.277,78.144,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.815 | Acc: 52.741,78.048,94.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.830 | Acc: 52.199,77.826,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.818 | Acc: 52.197,77.877,94.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.820 | Acc: 52.299,77.886,94.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.812 | Acc: 52.338,77.914,94.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.815 | Acc: 52.324,77.732,94.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.825 | Acc: 52.150,77.728,94.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.832 | Acc: 52.087,77.577,94.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.840 | Acc: 52.050,77.446,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.846 | Acc: 52.133,77.370,94.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.851 | Acc: 52.155,77.311,94.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.855 | Acc: 52.105,77.144,94.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.862 | Acc: 52.045,77.074,94.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.866 | Acc: 52.018,77.005,94.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.874 | Acc: 52.002,76.936,94.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.883 | Acc: 51.852,76.894,94.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.880 | Acc: 51.882,76.975,94.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.511 | Acc: 44.531,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.789 | Acc: 42.708,63.132,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.769 | Acc: 43.274,62.538,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.783 | Acc: 42.661,62.103,68.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 2.866 | Acc: 51.562,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.800 | Acc: 53.795,78.906,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.801 | Acc: 53.144,77.934,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.815 | Acc: 52.728,77.933,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.819 | Acc: 52.623,77.826,94.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.806 | Acc: 52.522,77.738,94.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.817 | Acc: 52.344,77.408,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.818 | Acc: 52.371,77.493,94.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.816 | Acc: 52.344,77.509,94.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.817 | Acc: 52.352,77.516,94.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.820 | Acc: 52.317,77.526,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.821 | Acc: 52.277,77.641,94.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.826 | Acc: 52.302,77.541,94.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.828 | Acc: 52.209,77.428,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.834 | Acc: 52.099,77.372,94.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.838 | Acc: 52.071,77.339,94.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.845 | Acc: 51.935,77.414,94.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.857 | Acc: 51.872,77.323,94.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.863 | Acc: 51.835,77.210,94.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.870 | Acc: 51.817,77.126,94.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.539 | Acc: 45.312,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.930 | Acc: 43.266,61.496,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.930 | Acc: 43.769,61.623,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.916 | Acc: 43.763,61.360,67.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 3.265 | Acc: 46.094,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.910 | Acc: 51.451,76.749,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.852 | Acc: 52.229,77.725,94.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.852 | Acc: 51.908,77.792,94.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.839 | Acc: 52.228,77.922,94.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.834 | Acc: 52.143,77.746,94.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.840 | Acc: 52.040,77.589,94.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.832 | Acc: 52.144,77.870,94.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.839 | Acc: 52.048,77.727,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.861 | Acc: 51.718,77.417,94.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.866 | Acc: 51.691,77.375,94.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.863 | Acc: 51.729,77.411,94.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.868 | Acc: 51.569,77.321,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.865 | Acc: 51.706,77.335,94.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.864 | Acc: 51.771,77.305,94.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.862 | Acc: 51.832,77.294,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.863 | Acc: 51.801,77.324,94.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.865 | Acc: 51.732,77.321,94.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.871 | Acc: 51.692,77.249,94.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.874 | Acc: 51.735,77.213,94.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.615 | Acc: 46.094,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.870 | Acc: 42.113,61.719,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.881 | Acc: 42.473,61.376,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.895 | Acc: 42.533,60.899,67.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 2.977 | Acc: 49.219,78.125,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.766 | Acc: 52.753,79.688,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.795 | Acc: 52.306,79.040,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.796 | Acc: 52.421,78.445,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.801 | Acc: 52.296,78.289,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.809 | Acc: 52.104,78.024,95.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.813 | Acc: 51.918,78.125,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.813 | Acc: 52.128,78.042,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.812 | Acc: 52.184,78.047,95.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.821 | Acc: 52.050,77.987,95.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.828 | Acc: 51.951,77.795,94.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.830 | Acc: 52.050,77.740,94.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.834 | Acc: 52.078,77.733,94.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.845 | Acc: 52.059,77.625,94.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.854 | Acc: 52.024,77.480,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.857 | Acc: 51.988,77.414,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.863 | Acc: 51.947,77.351,94.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.863 | Acc: 51.943,77.296,94.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.869 | Acc: 51.874,77.281,94.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.872 | Acc: 51.872,77.245,94.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.774 | Acc: 50.000,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.911 | Acc: 43.787,60.714,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.893 | Acc: 44.284,60.804,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.898 | Acc: 44.211,60.873,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 2.707 | Acc: 50.781,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.843 | Acc: 52.567,78.534,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.837 | Acc: 52.611,78.182,94.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.838 | Acc: 52.062,78.074,94.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.832 | Acc: 52.151,78.231,94.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.843 | Acc: 52.150,78.117,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.848 | Acc: 52.092,77.860,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.850 | Acc: 52.006,77.804,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.846 | Acc: 52.121,77.756,94.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.850 | Acc: 52.080,77.650,94.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.850 | Acc: 52.130,77.503,94.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.853 | Acc: 51.955,77.429,94.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.855 | Acc: 51.984,77.399,94.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.857 | Acc: 51.868,77.374,94.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.858 | Acc: 51.863,77.408,94.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.864 | Acc: 51.804,77.326,94.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.873 | Acc: 51.757,77.276,94.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.877 | Acc: 51.727,77.225,93.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.880 | Acc: 51.785,77.160,93.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.881 | Acc: 51.766,77.100,93.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.773 | Acc: 43.750,64.062,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.845 | Acc: 43.080,63.988,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.839 | Acc: 43.407,62.900,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.849 | Acc: 43.327,62.513,67.444,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 2.327 | Acc: 60.156,85.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.748 | Acc: 55.506,78.795,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.751 | Acc: 53.582,79.173,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.746 | Acc: 53.061,79.009,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.743 | Acc: 52.894,78.723,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.757 | Acc: 52.676,78.759,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.768 | Acc: 52.621,78.499,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.764 | Acc: 52.743,78.396,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.770 | Acc: 52.698,78.314,95.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.777 | Acc: 52.728,78.229,95.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.794 | Acc: 52.519,77.888,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.802 | Acc: 52.460,77.779,94.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 52.347,77.639,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.823 | Acc: 52.233,77.550,94.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.831 | Acc: 52.085,77.494,94.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.842 | Acc: 51.913,77.326,94.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.847 | Acc: 51.957,77.302,94.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.856 | Acc: 51.874,77.254,94.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.862 | Acc: 51.885,77.212,94.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.866 | Acc: 51.930,77.180,94.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.346 | Acc: 44.531,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.832 | Acc: 43.192,64.286,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.867 | Acc: 43.483,63.034,66.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.887 | Acc: 43.161,62.641,66.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 3.005 | Acc: 48.438,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.831 | Acc: 51.414,79.278,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.763 | Acc: 53.201,78.773,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.785 | Acc: 52.792,78.676,95.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.810 | Acc: 52.392,78.318,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.808 | Acc: 52.351,78.489,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.805 | Acc: 52.370,78.499,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.806 | Acc: 52.443,78.396,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.809 | Acc: 52.310,78.382,95.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.814 | Acc: 52.223,78.254,95.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.814 | Acc: 52.359,78.172,94.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.819 | Acc: 52.280,78.044,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.820 | Acc: 52.282,77.969,94.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.824 | Acc: 52.200,77.862,94.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.838 | Acc: 52.035,77.647,94.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.847 | Acc: 51.988,77.440,94.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.853 | Acc: 51.923,77.434,94.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.855 | Acc: 51.973,77.387,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.859 | Acc: 51.991,77.313,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.863 | Acc: 51.956,77.299,94.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.965 | Acc: 39.062,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.860 | Acc: 44.010,62.984,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.822 | Acc: 44.627,62.519,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.832 | Acc: 44.109,62.129,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 2.872 | Acc: 49.219,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.737 | Acc: 52.567,79.576,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.736 | Acc: 52.954,79.345,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.762 | Acc: 52.677,78.624,94.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.752 | Acc: 52.730,78.511,94.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.751 | Acc: 53.210,78.519,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.775 | Acc: 52.905,78.325,94.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.781 | Acc: 52.926,78.358,94.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.791 | Acc: 52.761,78.115,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.795 | Acc: 52.659,78.155,94.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.802 | Acc: 52.666,77.966,94.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.810 | Acc: 52.535,77.821,94.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.817 | Acc: 52.467,77.781,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.827 | Acc: 52.350,77.580,94.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.837 | Acc: 52.285,77.302,94.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.839 | Acc: 52.232,77.333,94.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 52.207,77.305,94.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 52.138,77.289,94.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.850 | Acc: 52.106,77.207,94.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.857 | Acc: 52.044,77.098,94.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.486 | Acc: 46.094,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.822 | Acc: 43.564,63.728,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.770 | Acc: 44.131,63.567,67.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.761 | Acc: 44.057,63.115,67.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 2.736 | Acc: 49.219,76.562,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.729 | Acc: 53.534,78.460,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.780 | Acc: 52.992,78.601,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.788 | Acc: 52.715,78.522,95.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.783 | Acc: 52.710,78.482,95.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.780 | Acc: 52.754,78.403,95.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.782 | Acc: 52.834,78.428,95.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.789 | Acc: 52.887,78.286,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.803 | Acc: 52.577,77.975,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.824 | Acc: 52.344,77.577,94.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.826 | Acc: 52.243,77.429,94.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.835 | Acc: 52.220,77.393,94.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.840 | Acc: 52.133,77.405,94.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.844 | Acc: 52.137,77.407,94.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.848 | Acc: 52.135,77.377,94.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.856 | Acc: 52.113,77.300,94.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.859 | Acc: 52.110,77.298,94.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.861 | Acc: 52.126,77.284,93.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.871 | Acc: 52.034,77.186,93.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.868 | Acc: 52.030,77.254,93.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.686 | Acc: 48.438,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.815 | Acc: 45.685,62.835,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.846 | Acc: 45.141,62.405,67.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.862 | Acc: 44.775,61.732,67.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 3.021 | Acc: 46.875,74.219,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.792 | Acc: 52.009,78.274,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.832 | Acc: 52.001,77.572,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.831 | Acc: 52.062,77.856,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.814 | Acc: 51.929,77.990,94.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.804 | Acc: 52.166,77.877,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.804 | Acc: 52.118,78.144,94.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.800 | Acc: 52.105,78.313,95.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.787 | Acc: 52.310,78.363,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.790 | Acc: 52.275,78.293,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.799 | Acc: 52.297,78.109,94.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 52.156,77.902,94.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.812 | Acc: 52.178,77.866,94.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.821 | Acc: 52.146,77.703,94.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.830 | Acc: 52.124,77.544,94.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 52.025,77.445,94.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.844 | Acc: 52.013,77.329,94.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.856 | Acc: 51.906,77.181,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.864 | Acc: 51.850,77.067,94.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.870 | Acc: 51.763,77.020,94.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.491 | Acc: 47.656,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.803 | Acc: 44.196,62.612,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.781 | Acc: 44.531,62.252,67.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.785 | Acc: 44.249,61.796,67.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 2.940 | Acc: 58.594,74.219,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.819 | Acc: 52.716,77.679,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.799 | Acc: 52.553,77.687,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.771 | Acc: 52.766,78.215,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.786 | Acc: 52.469,78.173,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.800 | Acc: 52.367,77.847,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.796 | Acc: 52.460,77.918,94.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.783 | Acc: 52.626,78.031,94.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.792 | Acc: 52.562,78.023,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.800 | Acc: 52.460,77.870,94.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.808 | Acc: 52.390,77.830,94.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.816 | Acc: 52.422,77.715,94.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.822 | Acc: 52.396,77.671,94.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.832 | Acc: 52.299,77.613,94.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.846 | Acc: 52.046,77.497,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.848 | Acc: 51.993,77.435,94.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.854 | Acc: 51.940,77.353,94.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.852 | Acc: 52.025,77.422,94.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.858 | Acc: 51.997,77.287,94.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.862 | Acc: 52.065,77.198,94.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.543 | Acc: 44.531,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.780 | Acc: 45.164,62.165,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.749 | Acc: 45.198,62.195,67.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.771 | Acc: 44.429,62.193,67.469,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 2.933 | Acc: 47.656,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.885 | Acc: 51.711,77.307,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.832 | Acc: 51.810,78.316,94.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.851 | Acc: 51.780,77.933,94.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.829 | Acc: 52.093,77.932,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.831 | Acc: 51.787,78.001,94.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.830 | Acc: 51.717,78.041,94.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.820 | Acc: 52.000,78.230,94.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.827 | Acc: 52.125,78.013,94.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.836 | Acc: 51.942,78.043,94.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.841 | Acc: 51.963,77.962,94.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.846 | Acc: 51.973,77.888,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.845 | Acc: 52.023,77.862,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.852 | Acc: 51.940,77.661,94.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.847 | Acc: 51.999,77.663,94.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 52.079,77.533,94.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.856 | Acc: 52.074,77.468,94.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.858 | Acc: 51.998,77.486,93.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.863 | Acc: 52.002,77.454,93.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.867 | Acc: 52.014,77.407,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.802 | Acc: 43.750,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.896 | Acc: 42.113,61.012,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.876 | Acc: 42.378,61.986,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.883 | Acc: 42.034,62.052,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 2.493 | Acc: 60.156,75.000,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.766 | Acc: 51.897,78.423,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.786 | Acc: 53.335,77.801,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.805 | Acc: 52.779,77.946,94.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.810 | Acc: 52.807,78.202,94.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.804 | Acc: 52.939,78.156,94.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.806 | Acc: 52.718,78.125,94.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.801 | Acc: 52.765,78.103,94.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.807 | Acc: 52.747,78.047,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.810 | Acc: 52.724,78.086,94.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.812 | Acc: 52.600,78.086,94.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.817 | Acc: 52.598,78.051,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.822 | Acc: 52.538,77.937,94.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.832 | Acc: 52.380,77.757,94.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.836 | Acc: 52.374,77.722,94.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.833 | Acc: 52.427,77.715,94.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.838 | Acc: 52.434,77.672,94.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.838 | Acc: 52.440,77.676,94.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.844 | Acc: 52.404,77.532,94.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.852 | Acc: 52.313,77.491,94.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.767 | Acc: 44.531,61.719,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.792 | Acc: 44.234,62.835,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.750 | Acc: 44.474,62.157,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.771 | Acc: 44.429,61.962,67.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 2.455 | Acc: 61.719,86.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.764 | Acc: 53.906,79.613,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.779 | Acc: 52.820,79.249,94.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.763 | Acc: 52.651,78.945,94.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.764 | Acc: 52.537,79.090,94.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.783 | Acc: 52.545,78.674,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.795 | Acc: 52.402,78.351,94.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.797 | Acc: 52.238,78.330,94.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.804 | Acc: 52.281,78.140,94.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.814 | Acc: 52.223,77.926,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.814 | Acc: 52.367,77.833,94.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.816 | Acc: 52.252,77.789,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.825 | Acc: 52.094,77.697,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.828 | Acc: 52.134,77.637,94.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 52.080,77.538,94.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.837 | Acc: 52.097,77.567,94.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.842 | Acc: 52.076,77.502,94.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.851 | Acc: 51.989,77.383,94.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.853 | Acc: 51.982,77.378,94.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.860 | Acc: 51.882,77.282,93.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.745 | Acc: 48.438,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.041 | Acc: 40.327,62.612,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.059 | Acc: 41.159,61.795,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.052 | Acc: 41.086,61.642,67.021,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 2.701 | Acc: 56.250,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.788 | Acc: 53.088,78.832,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.788 | Acc: 53.258,78.487,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.781 | Acc: 53.176,78.458,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.769 | Acc: 53.115,78.617,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.765 | Acc: 53.094,78.666,94.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.769 | Acc: 52.983,78.461,95.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.773 | Acc: 53.059,78.319,95.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.786 | Acc: 52.722,77.926,95.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.798 | Acc: 52.590,77.775,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.799 | Acc: 52.624,77.830,94.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.806 | Acc: 52.584,77.708,94.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.813 | Acc: 52.535,77.639,94.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.813 | Acc: 52.589,77.640,94.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.816 | Acc: 52.491,77.652,94.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.827 | Acc: 52.411,77.512,94.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.833 | Acc: 52.327,77.534,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.840 | Acc: 52.245,77.463,94.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.846 | Acc: 52.164,77.454,94.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.848 | Acc: 52.149,77.459,94.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.542 | Acc: 50.781,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.955 | Acc: 43.862,60.603,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.964 | Acc: 43.331,59.870,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.962 | Acc: 42.738,59.798,67.892,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 3.203 | Acc: 50.000,71.875,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.788 | Acc: 53.497,78.125,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.767 | Acc: 53.506,79.211,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.755 | Acc: 53.176,79.470,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.749 | Acc: 53.231,79.610,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.729 | Acc: 53.334,79.649,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.736 | Acc: 53.086,79.416,95.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.747 | Acc: 52.809,79.399,95.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.757 | Acc: 52.742,79.212,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.768 | Acc: 52.663,79.001,95.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.771 | Acc: 52.721,78.801,95.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.770 | Acc: 52.800,78.712,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.779 | Acc: 52.801,78.495,94.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.789 | Acc: 52.655,78.379,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.792 | Acc: 52.658,78.367,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.792 | Acc: 52.697,78.335,94.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.798 | Acc: 52.643,78.196,94.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.798 | Acc: 52.598,78.150,94.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.806 | Acc: 52.465,78.025,94.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.813 | Acc: 52.428,77.959,94.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.586 | Acc: 47.656,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.866 | Acc: 42.299,62.314,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.841 | Acc: 42.950,62.081,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.855 | Acc: 43.110,61.911,67.777,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 3.034 | Acc: 42.969,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.739 | Acc: 52.865,79.799,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 53.220,78.754,95.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 53.458,79.521,95.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.719 | Acc: 53.511,79.369,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.729 | Acc: 53.233,79.239,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.743 | Acc: 53.409,78.919,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.751 | Acc: 53.302,78.845,95.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.758 | Acc: 53.004,78.625,95.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.762 | Acc: 52.991,78.600,95.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.769 | Acc: 52.884,78.533,95.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.771 | Acc: 52.793,78.510,95.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.767 | Acc: 52.862,78.436,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.768 | Acc: 52.844,78.445,94.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.771 | Acc: 52.858,78.431,94.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.776 | Acc: 52.821,78.364,94.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.785 | Acc: 52.733,78.252,94.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.795 | Acc: 52.664,78.196,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.805 | Acc: 52.569,78.084,94.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.814 | Acc: 52.446,78.012,94.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.828 | Acc: 45.312,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.952 | Acc: 44.345,62.016,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.929 | Acc: 44.303,62.195,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.931 | Acc: 43.737,61.949,66.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.708 | Acc: 51.562,75.781,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.650 | Acc: 53.757,79.204,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.691 | Acc: 53.544,79.097,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 53.176,78.509,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.742 | Acc: 53.173,78.231,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.753 | Acc: 52.785,78.434,94.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.754 | Acc: 52.822,78.493,95.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.762 | Acc: 52.560,78.408,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.779 | Acc: 52.489,78.246,94.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.776 | Acc: 52.577,78.280,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.784 | Acc: 52.600,78.245,94.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 52.535,78.298,94.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.807 | Acc: 52.357,78.034,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.813 | Acc: 52.365,77.948,94.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.817 | Acc: 52.377,77.897,94.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.823 | Acc: 52.333,77.865,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.822 | Acc: 52.368,77.911,94.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.822 | Acc: 52.415,77.921,94.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.828 | Acc: 52.435,77.790,94.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.836 | Acc: 52.375,77.737,94.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.992 | Acc: 42.188,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.109 | Acc: 40.885,60.379,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.101 | Acc: 40.930,59.546,65.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.116 | Acc: 40.791,59.413,65.484,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.774 | Acc: 56.250,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.794 | Acc: 52.493,79.576,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.796 | Acc: 51.925,79.135,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.783 | Acc: 52.241,79.009,95.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.805 | Acc: 51.775,78.675,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.776 | Acc: 52.421,78.682,95.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.780 | Acc: 52.337,78.771,95.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.770 | Acc: 52.521,78.851,95.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.765 | Acc: 52.635,78.717,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.776 | Acc: 52.568,78.561,94.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.777 | Acc: 52.682,78.626,94.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.782 | Acc: 52.673,78.517,94.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.793 | Acc: 52.551,78.371,94.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.797 | Acc: 52.565,78.373,94.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.798 | Acc: 52.561,78.297,94.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.806 | Acc: 52.489,78.141,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.812 | Acc: 52.521,78.106,94.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.823 | Acc: 52.458,77.944,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.830 | Acc: 52.417,77.909,94.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.834 | Acc: 52.438,77.836,94.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.702 | Acc: 48.438,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.831 | Acc: 46.168,61.979,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.788 | Acc: 45.312,61.566,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.816 | Acc: 45.082,61.373,67.136,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 2.992 | Acc: 50.000,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.750 | Acc: 52.790,79.018,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.759 | Acc: 53.335,78.773,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.727 | Acc: 53.368,79.150,95.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.736 | Acc: 53.636,78.916,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.747 | Acc: 53.465,78.782,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.748 | Acc: 53.409,78.997,94.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.747 | Acc: 53.452,78.934,94.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.753 | Acc: 53.426,78.790,94.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.770 | Acc: 53.172,78.686,94.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.785 | Acc: 52.935,78.630,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.794 | Acc: 52.920,78.482,94.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.798 | Acc: 52.833,78.433,94.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.809 | Acc: 52.700,78.275,94.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.817 | Acc: 52.586,78.250,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 52.562,78.070,94.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.822 | Acc: 52.621,78.115,94.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.832 | Acc: 52.470,77.994,94.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 52.415,77.880,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.839 | Acc: 52.516,77.852,94.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.402 | Acc: 47.656,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.813 | Acc: 44.159,62.277,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.805 | Acc: 44.074,62.290,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.798 | Acc: 43.532,62.282,67.777,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 2.520 | Acc: 54.688,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.767 | Acc: 53.981,78.534,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.757 | Acc: 53.544,79.078,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.784 | Acc: 52.485,78.765,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.780 | Acc: 52.411,78.819,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.770 | Acc: 52.692,78.937,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.767 | Acc: 52.751,78.868,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.770 | Acc: 52.787,78.890,95.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.773 | Acc: 52.596,78.945,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.777 | Acc: 52.499,78.876,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.784 | Acc: 52.480,78.774,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.788 | Acc: 52.566,78.712,95.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.794 | Acc: 52.587,78.595,95.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.794 | Acc: 52.463,78.601,95.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.800 | Acc: 52.419,78.503,94.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.805 | Acc: 52.375,78.426,94.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.810 | Acc: 52.375,78.373,94.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.816 | Acc: 52.392,78.253,94.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.822 | Acc: 52.333,78.203,94.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.828 | Acc: 52.395,78.096,94.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.441 | Acc: 47.656,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.794 | Acc: 44.010,61.458,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.786 | Acc: 44.093,61.795,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.782 | Acc: 44.288,62.039,67.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 2.549 | Acc: 62.500,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.752 | Acc: 54.464,79.539,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 54.230,79.421,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.755 | Acc: 53.432,79.073,95.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.747 | Acc: 53.356,79.138,94.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.754 | Acc: 53.179,79.208,94.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.766 | Acc: 52.744,79.010,94.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.778 | Acc: 52.532,78.934,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.792 | Acc: 52.368,78.673,94.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.803 | Acc: 52.348,78.488,94.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.801 | Acc: 52.390,78.471,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 52.407,78.298,94.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.815 | Acc: 52.289,78.307,94.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.821 | Acc: 52.254,78.116,94.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.824 | Acc: 52.302,78.025,94.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.829 | Acc: 52.346,77.990,94.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.836 | Acc: 52.356,77.811,94.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.835 | Acc: 52.488,77.797,94.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 52.476,77.699,94.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.846 | Acc: 52.368,77.569,94.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.572 | Acc: 45.312,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.762 | Acc: 44.271,63.765,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.784 | Acc: 44.169,62.824,67.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.814 | Acc: 43.916,62.308,67.789,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 3.302 | Acc: 49.219,73.438,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.752 | Acc: 53.423,80.283,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.787 | Acc: 53.296,79.745,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.774 | Acc: 53.612,79.611,94.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.793 | Acc: 52.961,79.147,94.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.807 | Acc: 52.847,78.937,94.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.815 | Acc: 52.531,78.512,94.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.801 | Acc: 52.427,78.596,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.792 | Acc: 52.480,78.688,94.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.803 | Acc: 52.344,78.539,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.797 | Acc: 52.491,78.572,94.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.800 | Acc: 52.425,78.482,94.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.804 | Acc: 52.334,78.378,94.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.806 | Acc: 52.335,78.305,94.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.800 | Acc: 52.519,78.253,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.806 | Acc: 52.476,78.161,94.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.803 | Acc: 52.582,78.149,94.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.807 | Acc: 52.587,78.065,94.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.809 | Acc: 52.526,77.989,94.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.813 | Acc: 52.424,77.928,94.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.965 | Acc: 42.969,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.033 | Acc: 41.890,62.202,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.997 | Acc: 42.054,61.662,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.976 | Acc: 41.470,61.514,66.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.847 | Acc: 52.344,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.706 | Acc: 52.009,79.315,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.695 | Acc: 52.420,79.745,94.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.696 | Acc: 52.626,79.739,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.704 | Acc: 52.932,79.668,95.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.712 | Acc: 53.133,79.633,94.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.734 | Acc: 52.931,79.281,94.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.767 | Acc: 52.715,78.762,94.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.763 | Acc: 52.882,78.712,94.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.773 | Acc: 52.836,78.509,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.777 | Acc: 52.717,78.393,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.781 | Acc: 52.680,78.266,94.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.783 | Acc: 52.616,78.209,94.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.786 | Acc: 52.625,78.146,94.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.794 | Acc: 52.602,78.125,94.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.795 | Acc: 52.614,78.104,94.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.802 | Acc: 52.602,78.064,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.805 | Acc: 52.573,78.086,94.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.804 | Acc: 52.580,78.090,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.814 | Acc: 52.498,77.943,94.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.221 | Acc: 53.125,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.779 | Acc: 45.201,62.128,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.761 | Acc: 45.370,61.909,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.764 | Acc: 45.248,62.282,67.725,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 3.133 | Acc: 46.875,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.641 | Acc: 54.018,80.320,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.590 | Acc: 53.868,81.364,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.554 | Acc: 54.265,81.711,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.534 | Acc: 54.408,81.877,97.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.504 | Acc: 54.749,82.201,97.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.477 | Acc: 55.088,82.645,97.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.462 | Acc: 55.136,83.001,97.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.445 | Acc: 55.532,83.259,97.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.433 | Acc: 55.598,83.391,97.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.422 | Acc: 55.667,83.652,98.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.413 | Acc: 55.624,83.816,98.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.403 | Acc: 55.728,84.028,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.396 | Acc: 55.741,84.180,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.385 | Acc: 55.902,84.350,98.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.378 | Acc: 55.970,84.424,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.370 | Acc: 56.043,84.514,98.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.361 | Acc: 56.202,84.563,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.356 | Acc: 56.185,84.630,98.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.354 | Acc: 56.197,84.666,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.759 | Acc: 53.906,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.052 | Acc: 50.558,69.717,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.057 | Acc: 50.229,68.941,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.056 | Acc: 49.859,68.712,73.847,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 2.279 | Acc: 60.156,85.938,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.275 | Acc: 55.990,86.086,98.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.242 | Acc: 56.898,86.757,99.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.225 | Acc: 57.275,87.474,99.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.230 | Acc: 57.157,87.105,99.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.218 | Acc: 57.341,86.951,99.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.208 | Acc: 57.541,87.229,99.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.205 | Acc: 57.480,87.151,99.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.205 | Acc: 57.560,87.034,99.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.213 | Acc: 57.441,86.861,99.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.213 | Acc: 57.463,86.831,99.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.207 | Acc: 57.565,86.811,99.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.210 | Acc: 57.446,86.835,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.212 | Acc: 57.459,86.809,99.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.215 | Acc: 57.390,86.785,99.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.210 | Acc: 57.454,86.898,99.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.206 | Acc: 57.450,86.938,99.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.209 | Acc: 57.370,86.939,99.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.209 | Acc: 57.302,86.918,99.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.211 | Acc: 57.318,86.934,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.742 | Acc: 53.906,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.093 | Acc: 49.777,69.531,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.091 | Acc: 49.581,68.941,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.088 | Acc: 49.257,68.660,74.129,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 2.180 | Acc: 56.250,89.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.126 | Acc: 58.743,87.016,99.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.129 | Acc: 58.594,87.824,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.138 | Acc: 58.671,87.897,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.141 | Acc: 58.237,88.030,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.146 | Acc: 58.045,88.096,99.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.149 | Acc: 58.090,88.023,99.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.158 | Acc: 57.829,87.877,99.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.152 | Acc: 57.871,87.903,99.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.160 | Acc: 57.735,87.772,99.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.159 | Acc: 57.727,87.687,99.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.159 | Acc: 57.823,87.698,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.160 | Acc: 57.783,87.659,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.163 | Acc: 57.851,87.620,99.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.165 | Acc: 57.785,87.631,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.165 | Acc: 57.831,87.604,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.165 | Acc: 57.817,87.588,99.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.160 | Acc: 57.948,87.594,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.160 | Acc: 57.901,87.654,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.158 | Acc: 57.931,87.711,99.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.795 | Acc: 55.469,71.094,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.045 | Acc: 50.744,70.126,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.050 | Acc: 50.343,69.150,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.045 | Acc: 50.038,68.981,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.765 | Acc: 64.844,90.625,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.205 | Acc: 57.961,87.574,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.146 | Acc: 58.460,87.748,99.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.147 | Acc: 58.427,87.897,99.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.139 | Acc: 58.574,88.194,99.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.141 | Acc: 58.439,87.956,99.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.138 | Acc: 58.555,87.971,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.143 | Acc: 58.594,87.844,99.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.148 | Acc: 58.569,87.888,99.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.147 | Acc: 58.533,87.871,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.148 | Acc: 58.376,87.900,99.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.146 | Acc: 58.300,87.945,99.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.148 | Acc: 58.253,87.960,99.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.147 | Acc: 58.235,87.976,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.148 | Acc: 58.149,87.984,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.145 | Acc: 58.212,87.993,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.143 | Acc: 58.226,87.996,99.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.146 | Acc: 58.129,87.951,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.145 | Acc: 58.131,87.978,99.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.144 | Acc: 58.093,87.968,99.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.694 | Acc: 53.125,71.875,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.073 | Acc: 50.335,69.643,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.079 | Acc: 50.114,68.769,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.069 | Acc: 49.693,68.904,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 2.329 | Acc: 55.469,85.156,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.085 | Acc: 57.478,89.435,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.098 | Acc: 57.908,88.529,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.119 | Acc: 57.339,88.409,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.109 | Acc: 57.822,88.233,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.092 | Acc: 58.222,88.281,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.102 | Acc: 58.006,88.307,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.101 | Acc: 58.134,88.303,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.108 | Acc: 58.215,88.247,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.111 | Acc: 58.261,88.199,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.105 | Acc: 58.388,88.204,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.107 | Acc: 58.159,88.207,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.107 | Acc: 58.214,88.174,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.114 | Acc: 58.061,88.257,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.112 | Acc: 58.149,88.284,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.116 | Acc: 58.082,88.242,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.120 | Acc: 58.002,88.147,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.122 | Acc: 57.957,88.213,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.118 | Acc: 57.977,88.208,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.119 | Acc: 57.995,88.203,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.801 | Acc: 55.469,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.060 | Acc: 50.112,69.457,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.063 | Acc: 50.038,68.769,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.055 | Acc: 49.718,68.648,74.475,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 2.123 | Acc: 57.812,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.053 | Acc: 59.673,89.062,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.066 | Acc: 59.394,88.681,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.067 | Acc: 59.106,88.640,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.076 | Acc: 59.086,88.706,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.075 | Acc: 59.104,88.892,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.068 | Acc: 59.084,88.856,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.059 | Acc: 59.098,88.941,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.074 | Acc: 58.725,88.956,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.082 | Acc: 58.525,88.752,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.083 | Acc: 58.512,88.713,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.092 | Acc: 58.286,88.667,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.096 | Acc: 58.299,88.625,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.102 | Acc: 58.285,88.539,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.101 | Acc: 58.280,88.604,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.101 | Acc: 58.204,88.689,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.099 | Acc: 58.292,88.744,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.101 | Acc: 58.250,88.666,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.102 | Acc: 58.232,88.688,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.102 | Acc: 58.249,88.679,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.696 | Acc: 55.469,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.014 | Acc: 50.521,69.866,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.022 | Acc: 50.781,68.864,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.018 | Acc: 50.435,68.660,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.962 | Acc: 62.500,85.156,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.075 | Acc: 58.668,87.314,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.092 | Acc: 58.136,87.900,99.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.116 | Acc: 57.710,87.923,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.112 | Acc: 57.706,88.069,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.095 | Acc: 58.176,88.150,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.094 | Acc: 57.980,88.191,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.098 | Acc: 57.779,88.281,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.102 | Acc: 57.774,88.373,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.107 | Acc: 57.618,88.346,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.109 | Acc: 57.715,88.433,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.108 | Acc: 57.738,88.500,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.103 | Acc: 57.890,88.528,99.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.108 | Acc: 57.836,88.482,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.107 | Acc: 57.832,88.484,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.106 | Acc: 57.890,88.530,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.106 | Acc: 57.907,88.559,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.100 | Acc: 58.044,88.563,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.097 | Acc: 58.107,88.640,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.098 | Acc: 58.102,88.642,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.655 | Acc: 56.250,72.656,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.999 | Acc: 50.670,70.126,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.014 | Acc: 50.495,69.322,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.011 | Acc: 50.064,69.134,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 2.127 | Acc: 58.594,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.021 | Acc: 59.449,89.323,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.078 | Acc: 58.136,89.386,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.057 | Acc: 58.350,89.639,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.071 | Acc: 57.870,89.564,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.076 | Acc: 57.913,89.442,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.088 | Acc: 57.683,89.424,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.074 | Acc: 57.829,89.428,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.075 | Acc: 57.788,89.475,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.080 | Acc: 57.812,89.334,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.077 | Acc: 57.816,89.323,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.081 | Acc: 57.745,89.257,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.083 | Acc: 57.741,89.221,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.081 | Acc: 57.830,89.287,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.082 | Acc: 57.907,89.324,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.083 | Acc: 57.857,89.296,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.078 | Acc: 57.924,89.308,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.077 | Acc: 57.998,89.310,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.080 | Acc: 58.009,89.190,99.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.077 | Acc: 58.054,89.196,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.705 | Acc: 53.125,70.312,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.000 | Acc: 50.781,70.275,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.005 | Acc: 50.553,69.188,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.997 | Acc: 50.307,68.993,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.930 | Acc: 63.281,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.982 | Acc: 59.747,90.923,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.037 | Acc: 59.223,90.187,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.044 | Acc: 58.991,90.061,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.057 | Acc: 58.845,89.718,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.056 | Acc: 58.911,89.426,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.063 | Acc: 58.871,89.450,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.064 | Acc: 58.788,89.439,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.066 | Acc: 58.623,89.475,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.070 | Acc: 58.620,89.408,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.072 | Acc: 58.504,89.389,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.079 | Acc: 58.385,89.321,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.080 | Acc: 58.253,89.312,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.078 | Acc: 58.306,89.335,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.079 | Acc: 58.252,89.310,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.078 | Acc: 58.277,89.273,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.072 | Acc: 58.404,89.299,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.073 | Acc: 58.390,89.237,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.073 | Acc: 58.405,89.199,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.074 | Acc: 58.374,89.206,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.777 | Acc: 56.250,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.048 | Acc: 50.558,69.420,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.053 | Acc: 50.457,68.750,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.047 | Acc: 49.936,68.801,74.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 1.676 | Acc: 67.969,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.015 | Acc: 59.077,90.141,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.033 | Acc: 58.346,90.034,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.031 | Acc: 58.504,90.138,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.047 | Acc: 57.948,89.786,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.068 | Acc: 57.720,89.596,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.079 | Acc: 57.528,89.469,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.073 | Acc: 57.763,89.467,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.064 | Acc: 57.929,89.587,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.065 | Acc: 57.886,89.568,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.061 | Acc: 58.053,89.521,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.056 | Acc: 58.215,89.476,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.058 | Acc: 58.234,89.458,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.059 | Acc: 58.193,89.464,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.056 | Acc: 58.341,89.560,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.059 | Acc: 58.269,89.561,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.056 | Acc: 58.241,89.547,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.059 | Acc: 58.211,89.532,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.066 | Acc: 58.077,89.404,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.067 | Acc: 58.106,89.372,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.760 | Acc: 55.469,72.656,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.000 | Acc: 50.632,69.754,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.009 | Acc: 50.591,68.864,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.004 | Acc: 50.179,68.814,74.936,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.889 | Acc: 59.375,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.059 | Acc: 59.077,90.141,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.043 | Acc: 58.556,89.996,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.053 | Acc: 58.530,89.985,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.047 | Acc: 58.603,89.969,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.050 | Acc: 58.346,89.705,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.050 | Acc: 58.277,89.631,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.042 | Acc: 58.488,89.799,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.049 | Acc: 58.477,89.718,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.054 | Acc: 58.369,89.650,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.056 | Acc: 58.240,89.556,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.049 | Acc: 58.389,89.596,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.047 | Acc: 58.464,89.588,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.050 | Acc: 58.414,89.511,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.051 | Acc: 58.435,89.480,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.051 | Acc: 58.417,89.512,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.053 | Acc: 58.380,89.464,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.053 | Acc: 58.335,89.489,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.052 | Acc: 58.423,89.480,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.052 | Acc: 58.436,89.479,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.703 | Acc: 56.250,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.973 | Acc: 51.488,70.015,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.978 | Acc: 51.467,69.398,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.974 | Acc: 50.884,69.096,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.788 | Acc: 62.500,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.923 | Acc: 60.603,90.997,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.003 | Acc: 59.470,90.320,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.029 | Acc: 58.914,89.921,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.015 | Acc: 59.288,89.882,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.016 | Acc: 59.259,89.821,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.014 | Acc: 59.117,90.044,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.026 | Acc: 58.876,89.916,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.031 | Acc: 58.836,89.824,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.025 | Acc: 58.999,89.822,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.027 | Acc: 58.990,89.681,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.029 | Acc: 58.891,89.692,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.031 | Acc: 58.869,89.695,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.033 | Acc: 58.875,89.742,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.035 | Acc: 58.694,89.724,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.036 | Acc: 58.609,89.717,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.039 | Acc: 58.533,89.637,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.042 | Acc: 58.479,89.608,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.041 | Acc: 58.503,89.634,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.041 | Acc: 58.512,89.639,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.730 | Acc: 53.906,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.014 | Acc: 50.744,70.052,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.023 | Acc: 50.857,69.226,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.022 | Acc: 50.576,68.814,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.801 | Acc: 63.281,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 59.338,90.067,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.038 | Acc: 57.927,90.034,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.009 | Acc: 58.991,90.100,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.010 | Acc: 59.076,89.950,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.003 | Acc: 59.305,90.114,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.010 | Acc: 59.039,90.173,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.017 | Acc: 58.887,90.099,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.009 | Acc: 59.050,90.149,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.014 | Acc: 58.978,90.073,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.015 | Acc: 58.920,90.011,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.021 | Acc: 58.749,89.975,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.015 | Acc: 58.814,89.990,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.015 | Acc: 58.893,89.931,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.018 | Acc: 58.880,89.894,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.020 | Acc: 58.835,89.865,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.021 | Acc: 58.915,89.788,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.023 | Acc: 58.873,89.738,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.026 | Acc: 58.830,89.716,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.026 | Acc: 58.830,89.663,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.757 | Acc: 54.688,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.069 | Acc: 50.298,69.606,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.073 | Acc: 50.400,68.674,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.068 | Acc: 49.923,68.596,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 2.275 | Acc: 58.594,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.042 | Acc: 57.254,89.509,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.021 | Acc: 58.155,90.168,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.018 | Acc: 58.363,90.215,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.014 | Acc: 58.410,90.239,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.012 | Acc: 58.756,90.153,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.012 | Acc: 58.787,90.225,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.009 | Acc: 58.932,90.248,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.007 | Acc: 59.030,90.222,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.009 | Acc: 58.892,90.142,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.009 | Acc: 58.932,90.151,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.010 | Acc: 59.004,90.091,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.011 | Acc: 59.096,90.012,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.012 | Acc: 59.097,89.990,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.017 | Acc: 58.989,89.908,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.018 | Acc: 58.999,89.906,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.019 | Acc: 58.986,89.892,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.020 | Acc: 58.937,89.821,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.020 | Acc: 58.942,89.811,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.022 | Acc: 58.899,89.825,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.779 | Acc: 53.906,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.049 | Acc: 50.260,69.680,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.044 | Acc: 50.495,68.921,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.036 | Acc: 50.051,68.776,74.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.826 | Acc: 63.281,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.976 | Acc: 59.784,91.518,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 59.947,91.025,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.984 | Acc: 59.132,90.433,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.992 | Acc: 59.201,90.095,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.998 | Acc: 59.282,89.906,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.001 | Acc: 59.394,89.792,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.000 | Acc: 59.292,89.988,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.007 | Acc: 59.152,89.975,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.007 | Acc: 59.237,89.947,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.002 | Acc: 59.289,89.964,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.010 | Acc: 59.287,89.950,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.012 | Acc: 59.213,89.931,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.013 | Acc: 59.148,89.990,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.013 | Acc: 59.158,89.933,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.014 | Acc: 59.022,89.953,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.014 | Acc: 58.971,89.948,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.014 | Acc: 58.914,89.984,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.013 | Acc: 58.947,90.004,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.016 | Acc: 58.830,89.926,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.789 | Acc: 54.688,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.062 | Acc: 50.409,70.015,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.064 | Acc: 50.210,69.207,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.060 | Acc: 49.898,69.019,74.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.780 | Acc: 64.062,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 59.710,90.923,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.969 | Acc: 59.928,90.625,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 60.156,90.433,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.970 | Acc: 59.790,90.442,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.974 | Acc: 59.677,90.354,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.985 | Acc: 59.427,90.315,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.996 | Acc: 59.408,90.182,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.992 | Acc: 59.618,90.203,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.991 | Acc: 59.638,90.215,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.995 | Acc: 59.488,90.248,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.000 | Acc: 59.382,90.169,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.999 | Acc: 59.304,90.220,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.001 | Acc: 59.216,90.179,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.008 | Acc: 59.119,90.136,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.010 | Acc: 59.056,90.129,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.008 | Acc: 59.081,90.102,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.012 | Acc: 59.018,90.066,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.011 | Acc: 59.059,90.060,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.008 | Acc: 59.137,90.071,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.721 | Acc: 55.469,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.042 | Acc: 51.451,69.420,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.052 | Acc: 51.162,68.559,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.049 | Acc: 50.653,68.481,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 2.095 | Acc: 53.125,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.991 | Acc: 59.301,90.327,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.981 | Acc: 59.870,90.339,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 60.041,90.394,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.966 | Acc: 60.079,90.345,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.973 | Acc: 60.017,90.316,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.968 | Acc: 60.008,90.444,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.982 | Acc: 59.730,90.420,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.988 | Acc: 59.385,90.450,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.987 | Acc: 59.315,90.448,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.988 | Acc: 59.472,90.271,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.986 | Acc: 59.538,90.275,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.990 | Acc: 59.495,90.145,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.997 | Acc: 59.333,90.059,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.000 | Acc: 59.339,90.041,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.996 | Acc: 59.375,90.098,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.994 | Acc: 59.385,90.119,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.992 | Acc: 59.428,90.148,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.997 | Acc: 59.381,90.077,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.999 | Acc: 59.272,90.098,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.713 | Acc: 55.469,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.010 | Acc: 50.856,69.717,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.012 | Acc: 51.010,68.921,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.006 | Acc: 50.628,68.840,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 2.129 | Acc: 56.250,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.906 | Acc: 61.384,91.146,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.960 | Acc: 60.099,90.377,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.974 | Acc: 59.541,90.497,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.974 | Acc: 59.471,90.442,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.980 | Acc: 59.274,90.424,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.977 | Acc: 59.465,90.393,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.983 | Acc: 59.392,90.392,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.990 | Acc: 59.166,90.339,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.991 | Acc: 59.258,90.336,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.990 | Acc: 59.317,90.349,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.996 | Acc: 59.191,90.289,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.999 | Acc: 59.171,90.281,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.002 | Acc: 59.070,90.203,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.998 | Acc: 59.105,90.197,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.994 | Acc: 59.134,90.189,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.993 | Acc: 59.115,90.189,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.998 | Acc: 58.988,90.181,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.996 | Acc: 58.966,90.238,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.998 | Acc: 58.901,90.190,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.807 | Acc: 54.688,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.034 | Acc: 50.372,69.978,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.035 | Acc: 50.495,69.131,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.024 | Acc: 50.192,69.019,74.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.278 | Acc: 53.906,85.156,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.930 | Acc: 61.086,90.885,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 60.232,90.911,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.952 | Acc: 59.951,90.830,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.955 | Acc: 59.925,90.953,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.954 | Acc: 59.955,90.803,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.956 | Acc: 59.853,90.748,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.959 | Acc: 59.813,90.725,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.962 | Acc: 59.734,90.785,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.967 | Acc: 59.768,90.716,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.974 | Acc: 59.538,90.602,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.975 | Acc: 59.478,90.621,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.978 | Acc: 59.537,90.502,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.983 | Acc: 59.408,90.481,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.981 | Acc: 59.400,90.539,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.979 | Acc: 59.422,90.529,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.977 | Acc: 59.409,90.537,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.977 | Acc: 59.421,90.526,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.982 | Acc: 59.330,90.463,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.983 | Acc: 59.297,90.465,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.737 | Acc: 53.906,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.038 | Acc: 50.744,69.159,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.044 | Acc: 50.648,68.864,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.044 | Acc: 50.295,68.827,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.663 | Acc: 65.625,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.922 | Acc: 60.751,90.774,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.958 | Acc: 59.813,90.511,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.979 | Acc: 59.465,90.292,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.975 | Acc: 59.578,90.268,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.973 | Acc: 59.592,90.238,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.980 | Acc: 59.259,90.231,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.977 | Acc: 59.353,90.392,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.967 | Acc: 59.516,90.567,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.970 | Acc: 59.319,90.496,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.971 | Acc: 59.356,90.466,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.973 | Acc: 59.255,90.431,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.976 | Acc: 59.203,90.440,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.979 | Acc: 59.076,90.460,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.980 | Acc: 59.033,90.422,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.987 | Acc: 58.921,90.391,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.991 | Acc: 58.861,90.384,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.989 | Acc: 58.857,90.435,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.989 | Acc: 58.936,90.411,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.991 | Acc: 58.918,90.377,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.758 | Acc: 55.469,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.034 | Acc: 50.335,69.048,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.035 | Acc: 50.095,68.960,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.030 | Acc: 49.757,68.712,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 2.163 | Acc: 50.000,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.942 | Acc: 60.938,90.997,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.965 | Acc: 60.252,90.587,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.981 | Acc: 59.644,90.523,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.975 | Acc: 59.394,90.606,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.966 | Acc: 59.623,90.702,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.971 | Acc: 59.388,90.580,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.970 | Acc: 59.297,90.697,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.965 | Acc: 59.341,90.727,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.967 | Acc: 59.388,90.668,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.973 | Acc: 59.255,90.578,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.975 | Acc: 59.248,90.565,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.972 | Acc: 59.407,90.593,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.975 | Acc: 59.462,90.466,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.977 | Acc: 59.406,90.411,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.978 | Acc: 59.352,90.386,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.979 | Acc: 59.329,90.348,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.981 | Acc: 59.306,90.311,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.983 | Acc: 59.249,90.294,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.981 | Acc: 59.305,90.360,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.780 | Acc: 57.031,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.017 | Acc: 51.414,69.606,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.018 | Acc: 50.838,69.150,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.012 | Acc: 50.679,68.904,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.556 | Acc: 71.094,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.904 | Acc: 61.086,91.332,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.899 | Acc: 61.319,91.482,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.907 | Acc: 60.809,91.393,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.932 | Acc: 60.571,90.885,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.935 | Acc: 60.342,90.857,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.942 | Acc: 60.053,90.670,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.945 | Acc: 60.212,90.559,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.947 | Acc: 60.200,90.499,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.956 | Acc: 59.863,90.487,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.952 | Acc: 59.818,90.555,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.957 | Acc: 59.665,90.590,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.965 | Acc: 59.469,90.528,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.966 | Acc: 59.420,90.589,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.964 | Acc: 59.431,90.517,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.963 | Acc: 59.427,90.524,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.965 | Acc: 59.426,90.481,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.961 | Acc: 59.535,90.526,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.959 | Acc: 59.537,90.571,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.963 | Acc: 59.484,90.592,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.689 | Acc: 53.906,71.094,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.014 | Acc: 51.414,69.196,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.007 | Acc: 51.372,68.750,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.000 | Acc: 50.884,68.801,74.769,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 1.994 | Acc: 55.469,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 59.598,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.942 | Acc: 59.985,91.559,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.935 | Acc: 59.990,91.624,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.942 | Acc: 59.819,91.426,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.964 | Acc: 59.352,91.375,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.957 | Acc: 59.317,91.322,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.970 | Acc: 59.170,91.068,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.963 | Acc: 59.390,91.101,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.960 | Acc: 59.466,91.044,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.966 | Acc: 59.208,90.944,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.960 | Acc: 59.276,90.957,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.957 | Acc: 59.459,90.952,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.959 | Acc: 59.372,90.891,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.958 | Acc: 59.419,90.847,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.963 | Acc: 59.354,90.812,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.970 | Acc: 59.185,90.783,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.976 | Acc: 59.079,90.714,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.975 | Acc: 59.143,90.640,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.973 | Acc: 59.256,90.602,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.838 | Acc: 56.250,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.049 | Acc: 50.930,69.754,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.045 | Acc: 50.648,69.017,74.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.037 | Acc: 50.320,68.788,74.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 2.083 | Acc: 59.375,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.883 | Acc: 61.086,91.555,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.913 | Acc: 60.709,91.502,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.953 | Acc: 59.823,91.099,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.940 | Acc: 59.934,91.184,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.944 | Acc: 59.746,91.166,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.954 | Acc: 59.730,90.967,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.957 | Acc: 59.779,91.013,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.960 | Acc: 59.550,90.989,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.963 | Acc: 59.548,90.849,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.959 | Acc: 59.581,90.905,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.965 | Acc: 59.403,90.897,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.969 | Acc: 59.300,90.742,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.971 | Acc: 59.210,90.700,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.968 | Acc: 59.247,90.750,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.970 | Acc: 59.157,90.744,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.972 | Acc: 59.129,90.752,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.971 | Acc: 59.116,90.762,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.968 | Acc: 59.152,90.798,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.971 | Acc: 59.033,90.746,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.786 | Acc: 53.906,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.053 | Acc: 50.298,69.196,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.055 | Acc: 50.572,68.540,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.047 | Acc: 50.551,68.468,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 2.157 | Acc: 56.250,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.940 | Acc: 59.487,91.220,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.965 | Acc: 59.756,91.025,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.948 | Acc: 59.849,91.176,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.949 | Acc: 59.973,91.107,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.956 | Acc: 59.746,91.190,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.953 | Acc: 59.640,91.290,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.953 | Acc: 59.508,91.345,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.963 | Acc: 59.268,91.154,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.957 | Acc: 59.410,91.195,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.955 | Acc: 59.488,91.165,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.955 | Acc: 59.463,91.166,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.953 | Acc: 59.495,91.183,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.953 | Acc: 59.435,91.164,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.959 | Acc: 59.328,91.123,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.963 | Acc: 59.256,91.066,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.965 | Acc: 59.270,90.917,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.965 | Acc: 59.336,90.829,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.964 | Acc: 59.349,90.854,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.966 | Acc: 59.332,90.844,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.769 | Acc: 56.250,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.053 | Acc: 50.223,69.048,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 50.629,68.617,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.037 | Acc: 50.154,68.788,74.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 1.846 | Acc: 64.062,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.977 | Acc: 59.487,91.146,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.949 | Acc: 59.699,91.578,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.962 | Acc: 59.490,90.984,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.954 | Acc: 59.520,91.020,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.961 | Acc: 59.777,90.726,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.957 | Acc: 59.749,90.890,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.948 | Acc: 59.996,91.013,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.955 | Acc: 59.851,90.839,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.957 | Acc: 59.863,90.862,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.960 | Acc: 59.888,90.901,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.955 | Acc: 59.994,90.933,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.960 | Acc: 59.719,90.774,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.958 | Acc: 59.794,90.742,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.955 | Acc: 59.837,90.761,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.959 | Acc: 59.738,90.734,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.960 | Acc: 59.626,90.700,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.960 | Acc: 59.604,90.703,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.958 | Acc: 59.682,90.692,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.959 | Acc: 59.613,90.687,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.824 | Acc: 53.125,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.024 | Acc: 51.376,69.457,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.033 | Acc: 50.953,68.788,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.026 | Acc: 50.551,68.571,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.707 | Acc: 57.812,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.902 | Acc: 59.784,92.262,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.903 | Acc: 59.489,92.207,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.922 | Acc: 59.183,91.790,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.914 | Acc: 59.481,91.647,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.925 | Acc: 59.460,91.692,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.910 | Acc: 59.898,91.697,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.920 | Acc: 59.719,91.456,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.927 | Acc: 59.690,91.367,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.933 | Acc: 59.604,91.281,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.929 | Acc: 59.814,91.352,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.932 | Acc: 59.870,91.226,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.931 | Acc: 59.903,91.189,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.933 | Acc: 59.728,91.113,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.930 | Acc: 59.878,91.073,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.931 | Acc: 59.746,91.118,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.935 | Acc: 59.638,91.063,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.937 | Acc: 59.716,91.021,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.940 | Acc: 59.713,91.002,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.943 | Acc: 59.668,90.969,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.723 | Acc: 55.469,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.012 | Acc: 50.558,70.238,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.019 | Acc: 50.648,68.960,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.013 | Acc: 50.384,68.737,74.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.433 | Acc: 50.781,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.964 | Acc: 59.226,90.551,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.968 | Acc: 58.537,91.425,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.945 | Acc: 59.234,91.688,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.942 | Acc: 59.443,91.753,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.947 | Acc: 59.406,91.747,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.940 | Acc: 59.627,91.781,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.942 | Acc: 59.635,91.512,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.953 | Acc: 59.521,91.411,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.957 | Acc: 59.474,91.372,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.956 | Acc: 59.597,91.348,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.956 | Acc: 59.516,91.332,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.956 | Acc: 59.407,91.306,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.956 | Acc: 59.378,91.328,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.951 | Acc: 59.489,91.301,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.950 | Acc: 59.455,91.310,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.951 | Acc: 59.402,91.343,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.952 | Acc: 59.430,91.299,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.952 | Acc: 59.518,91.281,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.951 | Acc: 59.506,91.222,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.695 | Acc: 55.469,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.022 | Acc: 51.042,69.308,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.031 | Acc: 50.896,68.540,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.021 | Acc: 50.679,68.379,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 2.120 | Acc: 52.344,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.914 | Acc: 59.821,91.964,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.889 | Acc: 60.633,91.845,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.905 | Acc: 60.323,91.701,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.915 | Acc: 60.195,91.397,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.919 | Acc: 60.125,91.399,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.924 | Acc: 60.040,91.451,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.918 | Acc: 60.189,91.379,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.925 | Acc: 60.137,91.173,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.932 | Acc: 60.092,91.113,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.935 | Acc: 59.974,91.123,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.940 | Acc: 59.912,91.152,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.941 | Acc: 59.988,91.140,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.935 | Acc: 60.060,91.263,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.939 | Acc: 59.962,91.253,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.941 | Acc: 59.889,91.165,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.936 | Acc: 59.893,91.177,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.938 | Acc: 59.920,91.152,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.940 | Acc: 59.858,91.134,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.940 | Acc: 59.822,91.142,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.771 | Acc: 54.688,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.992 | Acc: 52.232,69.494,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.990 | Acc: 51.886,69.036,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.990 | Acc: 51.230,68.609,74.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.813 | Acc: 63.281,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.904 | Acc: 60.342,91.295,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.901 | Acc: 59.699,91.692,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.900 | Acc: 60.336,91.406,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.891 | Acc: 60.465,91.184,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.906 | Acc: 60.149,91.166,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.909 | Acc: 60.201,91.225,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.926 | Acc: 60.068,91.218,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.924 | Acc: 60.059,91.329,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.920 | Acc: 60.109,91.251,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.920 | Acc: 59.974,91.239,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.925 | Acc: 60.068,91.088,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.929 | Acc: 59.959,91.059,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.932 | Acc: 59.851,91.062,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.927 | Acc: 59.920,91.034,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.933 | Acc: 59.777,91.066,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.930 | Acc: 59.845,91.027,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.933 | Acc: 59.797,91.019,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.933 | Acc: 59.860,91.047,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.938 | Acc: 59.719,90.986,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.776 | Acc: 55.469,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.021 | Acc: 51.265,69.122,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.015 | Acc: 51.239,68.674,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.013 | Acc: 50.986,68.366,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.554 | Acc: 62.500,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.932 | Acc: 58.668,91.257,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.906 | Acc: 59.832,91.902,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.914 | Acc: 59.682,91.547,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.913 | Acc: 60.002,91.454,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.921 | Acc: 59.769,91.538,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.918 | Acc: 59.711,91.574,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.921 | Acc: 59.741,91.528,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.926 | Acc: 59.686,91.460,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.935 | Acc: 59.487,91.380,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.934 | Acc: 59.550,91.301,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.935 | Acc: 59.516,91.272,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.932 | Acc: 59.631,91.309,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.933 | Acc: 59.659,91.290,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.935 | Acc: 59.698,91.262,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.940 | Acc: 59.546,91.152,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.937 | Acc: 59.633,91.139,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.936 | Acc: 59.650,91.150,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.941 | Acc: 59.548,91.108,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.940 | Acc: 59.588,91.115,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.762 | Acc: 56.250,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.995 | Acc: 51.562,69.122,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.993 | Acc: 51.410,68.864,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.986 | Acc: 51.191,68.584,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 1.743 | Acc: 64.062,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.828 | Acc: 61.310,92.560,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.818 | Acc: 61.928,92.988,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.850 | Acc: 61.527,92.392,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.865 | Acc: 60.957,92.303,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.874 | Acc: 60.767,92.226,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.887 | Acc: 60.524,92.033,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.888 | Acc: 60.455,91.977,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.895 | Acc: 60.491,91.760,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.898 | Acc: 60.532,91.652,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.903 | Acc: 60.323,91.573,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.902 | Acc: 60.365,91.558,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.902 | Acc: 60.292,91.594,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.903 | Acc: 60.309,91.628,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.905 | Acc: 60.251,91.554,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.912 | Acc: 60.169,91.445,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.913 | Acc: 60.064,91.418,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.917 | Acc: 60.053,91.338,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.920 | Acc: 59.957,91.346,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.924 | Acc: 59.943,91.255,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.792 | Acc: 54.688,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.026 | Acc: 51.153,69.382,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.045 | Acc: 51.010,68.636,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.044 | Acc: 50.871,68.507,74.475,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.026 | Acc: 61.719,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.847 | Acc: 62.351,91.667,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.843 | Acc: 61.986,91.883,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.875 | Acc: 61.104,91.906,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.880 | Acc: 60.706,91.966,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.903 | Acc: 60.164,91.801,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.910 | Acc: 59.956,91.774,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.905 | Acc: 60.007,91.694,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.904 | Acc: 59.952,91.760,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.905 | Acc: 59.958,91.773,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.909 | Acc: 59.795,91.717,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.911 | Acc: 59.782,91.657,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.911 | Acc: 59.832,91.610,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.917 | Acc: 59.815,91.532,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.918 | Acc: 59.725,91.481,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.923 | Acc: 59.661,91.471,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.926 | Acc: 59.579,91.455,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.925 | Acc: 59.625,91.427,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.926 | Acc: 59.574,91.395,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.931 | Acc: 59.486,91.318,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.832 | Acc: 50.781,71.094,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.063 | Acc: 50.967,68.936,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.063 | Acc: 50.572,68.312,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.051 | Acc: 50.384,68.238,74.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.760 | Acc: 61.719,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.860 | Acc: 60.045,92.113,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.924 | Acc: 59.223,91.883,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.916 | Acc: 59.631,91.688,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.923 | Acc: 59.770,91.454,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.921 | Acc: 59.916,91.538,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.923 | Acc: 60.008,91.419,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.915 | Acc: 60.334,91.439,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.914 | Acc: 60.345,91.479,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.917 | Acc: 60.338,91.376,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.923 | Acc: 60.133,91.309,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.920 | Acc: 60.132,91.364,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.920 | Acc: 60.143,91.351,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.917 | Acc: 60.120,91.343,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.923 | Acc: 59.964,91.365,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.922 | Acc: 59.995,91.341,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.922 | Acc: 59.988,91.353,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.927 | Acc: 59.838,91.301,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.929 | Acc: 59.736,91.311,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.932 | Acc: 59.617,91.265,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.858 | Acc: 53.906,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.080 | Acc: 50.670,68.973,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.065 | Acc: 50.343,68.331,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.051 | Acc: 50.218,68.276,74.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.835 | Acc: 62.500,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.851 | Acc: 60.900,93.043,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.878 | Acc: 60.709,92.645,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.885 | Acc: 60.374,92.072,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.891 | Acc: 60.195,92.226,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.892 | Acc: 60.164,92.056,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.891 | Acc: 60.072,91.897,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.892 | Acc: 60.101,91.977,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.904 | Acc: 59.967,91.765,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.903 | Acc: 60.031,91.721,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.901 | Acc: 60.137,91.674,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.902 | Acc: 60.100,91.590,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.908 | Acc: 59.959,91.491,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.909 | Acc: 59.980,91.478,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.910 | Acc: 59.959,91.481,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.911 | Acc: 59.954,91.469,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.909 | Acc: 60.027,91.438,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.914 | Acc: 59.955,91.349,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.917 | Acc: 59.858,91.380,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.916 | Acc: 59.980,91.357,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.747 | Acc: 54.688,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.989 | Acc: 51.339,69.606,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.998 | Acc: 51.524,68.826,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.993 | Acc: 51.358,68.686,74.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 1.641 | Acc: 64.844,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.876 | Acc: 60.454,92.597,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.889 | Acc: 60.766,92.092,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.883 | Acc: 60.989,91.983,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.893 | Acc: 60.677,91.696,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.900 | Acc: 60.365,91.808,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.894 | Acc: 60.447,91.865,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.892 | Acc: 60.422,91.850,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.902 | Acc: 60.224,91.838,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.902 | Acc: 60.212,91.674,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.906 | Acc: 60.117,91.651,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.911 | Acc: 60.096,91.579,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.917 | Acc: 59.984,91.458,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.913 | Acc: 60.120,91.478,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.914 | Acc: 60.173,91.465,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.920 | Acc: 59.972,91.461,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.920 | Acc: 59.947,91.465,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.919 | Acc: 59.966,91.473,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.919 | Acc: 59.985,91.428,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.919 | Acc: 59.970,91.396,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.828 | Acc: 54.688,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.045 | Acc: 51.190,68.378,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.041 | Acc: 51.010,67.988,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.036 | Acc: 50.384,68.058,74.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.049 | Acc: 57.812,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.915 | Acc: 59.152,91.443,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.913 | Acc: 59.394,91.616,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.912 | Acc: 59.721,91.560,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.919 | Acc: 59.587,91.590,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.904 | Acc: 59.924,91.662,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.906 | Acc: 59.846,91.742,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.914 | Acc: 59.674,91.783,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.910 | Acc: 59.627,91.853,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.915 | Acc: 59.599,91.812,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.911 | Acc: 59.721,91.826,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.903 | Acc: 59.845,91.823,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.903 | Acc: 59.949,91.740,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.906 | Acc: 59.920,91.610,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.904 | Acc: 60.095,91.526,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.908 | Acc: 60.063,91.518,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.908 | Acc: 60.154,91.470,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.913 | Acc: 60.067,91.411,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.915 | Acc: 59.977,91.398,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.917 | Acc: 59.953,91.359,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.755 | Acc: 56.250,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.026 | Acc: 51.935,69.196,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.014 | Acc: 51.543,68.807,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.010 | Acc: 50.897,68.776,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.675 | Acc: 66.406,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.902 | Acc: 60.268,91.629,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.887 | Acc: 59.489,92.302,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.898 | Acc: 59.810,91.995,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.912 | Acc: 59.954,92.004,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.926 | Acc: 59.568,91.731,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.922 | Acc: 59.556,91.761,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.913 | Acc: 59.768,91.816,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.905 | Acc: 59.918,91.916,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.904 | Acc: 60.001,91.743,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.903 | Acc: 60.016,91.775,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.906 | Acc: 59.965,91.785,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.905 | Acc: 60.023,91.688,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.906 | Acc: 60.063,91.673,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.907 | Acc: 60.078,91.637,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.906 | Acc: 60.042,91.687,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.909 | Acc: 59.947,91.637,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.911 | Acc: 59.932,91.617,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.911 | Acc: 59.884,91.620,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.911 | Acc: 59.877,91.576,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.814 | Acc: 53.125,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.003 | Acc: 52.046,68.601,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.999 | Acc: 51.715,67.931,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.994 | Acc: 51.332,67.866,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.877 | Acc: 54.688,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.874 | Acc: 61.310,92.522,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.877 | Acc: 60.480,92.092,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.864 | Acc: 60.515,92.277,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.863 | Acc: 60.629,92.236,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.874 | Acc: 60.404,92.180,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.877 | Acc: 60.408,92.175,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.876 | Acc: 60.500,92.193,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.877 | Acc: 60.549,92.037,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.877 | Acc: 60.683,91.980,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.877 | Acc: 60.755,91.993,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.883 | Acc: 60.616,91.894,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.890 | Acc: 60.461,91.756,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.893 | Acc: 60.453,91.792,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.895 | Acc: 60.390,91.779,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.894 | Acc: 60.416,91.775,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.894 | Acc: 60.397,91.735,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.897 | Acc: 60.291,91.711,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.898 | Acc: 60.197,91.718,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.901 | Acc: 60.156,91.697,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.825 | Acc: 53.125,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.059 | Acc: 50.781,69.457,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.051 | Acc: 50.438,68.902,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.042 | Acc: 50.384,68.507,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.803 | Acc: 63.281,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.873 | Acc: 60.900,91.815,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.856 | Acc: 60.556,92.302,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.843 | Acc: 61.130,92.405,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.850 | Acc: 60.725,92.313,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.869 | Acc: 60.427,92.025,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.871 | Acc: 60.647,92.065,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.876 | Acc: 60.605,91.960,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.885 | Acc: 60.433,91.906,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.887 | Acc: 60.372,91.859,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.890 | Acc: 60.312,91.760,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.889 | Acc: 60.216,91.749,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.892 | Acc: 60.202,91.763,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.897 | Acc: 60.096,91.652,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.895 | Acc: 60.076,91.629,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.898 | Acc: 60.019,91.645,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.898 | Acc: 60.020,91.601,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.898 | Acc: 60.016,91.592,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.894 | Acc: 60.078,91.649,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.895 | Acc: 60.078,91.620,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.795 | Acc: 52.344,71.875,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.057 | Acc: 50.186,68.787,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.063 | Acc: 50.267,68.445,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.052 | Acc: 50.128,68.327,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.905 | Acc: 60.156,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.863 | Acc: 60.751,91.815,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.869 | Acc: 60.404,92.168,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.866 | Acc: 60.630,92.008,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.874 | Acc: 60.262,92.178,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.880 | Acc: 60.234,92.041,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.885 | Acc: 60.053,92.033,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.888 | Acc: 60.145,91.966,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.882 | Acc: 60.336,91.993,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.872 | Acc: 60.454,92.058,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.869 | Acc: 60.525,92.083,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.874 | Acc: 60.446,92.039,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.870 | Acc: 60.600,92.068,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.875 | Acc: 60.524,91.996,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.876 | Acc: 60.543,91.943,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.881 | Acc: 60.457,91.907,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.887 | Acc: 60.346,91.839,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.893 | Acc: 60.214,91.814,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.896 | Acc: 60.109,91.789,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.896 | Acc: 60.154,91.757,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.761 | Acc: 57.812,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.032 | Acc: 51.265,68.527,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.036 | Acc: 51.105,68.102,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.027 | Acc: 50.973,68.033,74.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.837 | Acc: 61.719,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.862 | Acc: 60.714,91.481,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.890 | Acc: 60.347,91.730,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.871 | Acc: 60.822,92.008,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.865 | Acc: 60.851,91.879,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.868 | Acc: 60.775,91.832,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.865 | Acc: 60.783,91.949,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.872 | Acc: 60.727,91.894,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.875 | Acc: 60.709,91.828,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.877 | Acc: 60.687,91.765,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.877 | Acc: 60.615,91.779,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.885 | Acc: 60.439,91.731,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.884 | Acc: 60.464,91.776,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.885 | Acc: 60.402,91.762,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.885 | Acc: 60.462,91.698,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.887 | Acc: 60.385,91.640,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.892 | Acc: 60.322,91.567,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.892 | Acc: 60.328,91.537,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.891 | Acc: 60.364,91.530,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.894 | Acc: 60.310,91.499,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.732 | Acc: 55.469,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.024 | Acc: 50.744,68.787,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.027 | Acc: 50.762,68.140,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.018 | Acc: 50.704,68.174,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 2.020 | Acc: 59.375,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.877 | Acc: 61.496,91.109,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.877 | Acc: 61.242,91.673,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.876 | Acc: 60.797,91.816,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.868 | Acc: 60.880,91.753,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.881 | Acc: 60.821,91.716,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.878 | Acc: 60.905,91.813,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.893 | Acc: 60.527,91.805,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.891 | Acc: 60.646,91.678,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.889 | Acc: 60.458,91.721,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.891 | Acc: 60.432,91.647,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.889 | Acc: 60.471,91.629,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.892 | Acc: 60.373,91.604,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.894 | Acc: 60.390,91.553,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.892 | Acc: 60.379,91.559,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.891 | Acc: 60.418,91.557,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.895 | Acc: 60.314,91.550,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.895 | Acc: 60.280,91.537,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.898 | Acc: 60.238,91.536,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.904 | Acc: 60.048,91.476,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.684 | Acc: 53.125,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.993 | Acc: 51.972,69.308,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.006 | Acc: 51.429,68.216,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.001 | Acc: 51.114,68.084,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 2.068 | Acc: 57.031,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.910 | Acc: 60.677,92.001,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.866 | Acc: 61.166,92.454,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.878 | Acc: 60.733,92.200,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.876 | Acc: 60.716,92.294,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.890 | Acc: 60.156,92.234,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.882 | Acc: 60.182,92.239,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.881 | Acc: 60.328,92.099,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.880 | Acc: 60.273,92.134,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.873 | Acc: 60.424,92.105,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.878 | Acc: 60.421,92.024,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.888 | Acc: 60.245,91.891,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.890 | Acc: 60.159,91.886,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.892 | Acc: 60.150,91.801,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.889 | Acc: 60.301,91.851,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.892 | Acc: 60.244,91.835,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.891 | Acc: 60.251,91.825,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.896 | Acc: 60.200,91.736,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.897 | Acc: 60.210,91.692,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.900 | Acc: 60.136,91.712,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.792 | Acc: 54.688,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.045 | Acc: 51.079,69.420,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.050 | Acc: 51.010,68.540,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.045 | Acc: 50.640,68.276,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.667 | Acc: 62.500,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.868 | Acc: 61.421,91.778,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.878 | Acc: 60.423,91.959,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.863 | Acc: 60.925,92.188,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.873 | Acc: 60.571,92.004,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.866 | Acc: 60.705,92.079,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.866 | Acc: 60.550,92.110,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.869 | Acc: 60.455,91.994,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.870 | Acc: 60.394,92.047,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.875 | Acc: 60.290,91.972,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.876 | Acc: 60.362,91.943,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.875 | Acc: 60.489,91.922,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.875 | Acc: 60.513,91.850,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.882 | Acc: 60.441,91.721,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.882 | Acc: 60.373,91.670,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.883 | Acc: 60.369,91.653,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.885 | Acc: 60.285,91.652,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.883 | Acc: 60.362,91.711,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.883 | Acc: 60.323,91.722,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.883 | Acc: 60.390,91.728,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.782 | Acc: 57.812,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.030 | Acc: 52.009,68.304,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.020 | Acc: 51.829,68.598,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.012 | Acc: 51.409,68.122,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.794 | Acc: 63.281,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.846 | Acc: 60.751,92.969,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.898 | Acc: 60.156,92.111,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.891 | Acc: 60.220,92.136,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.873 | Acc: 60.870,92.313,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.869 | Acc: 60.775,92.443,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.878 | Acc: 60.511,92.213,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.881 | Acc: 60.328,92.221,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.884 | Acc: 60.326,92.056,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.885 | Acc: 60.320,92.023,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.888 | Acc: 60.316,91.993,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.890 | Acc: 60.206,91.940,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.889 | Acc: 60.185,91.922,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.891 | Acc: 60.279,91.840,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.889 | Acc: 60.290,91.823,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.888 | Acc: 60.374,91.790,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.885 | Acc: 60.334,91.815,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.884 | Acc: 60.424,91.793,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.884 | Acc: 60.427,91.731,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.883 | Acc: 60.476,91.683,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.882 | Acc: 54.688,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.047 | Acc: 51.488,69.457,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.025 | Acc: 51.562,68.521,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.012 | Acc: 51.217,68.532,74.296,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 2.092 | Acc: 55.469,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.871 | Acc: 61.310,92.820,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.859 | Acc: 60.995,92.397,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.862 | Acc: 60.400,92.380,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.874 | Acc: 60.282,92.351,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.869 | Acc: 60.357,92.296,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.861 | Acc: 60.557,92.278,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.855 | Acc: 60.705,92.276,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.860 | Acc: 60.714,92.158,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.864 | Acc: 60.687,92.071,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.868 | Acc: 60.560,92.110,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.868 | Acc: 60.573,92.156,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.876 | Acc: 60.399,92.064,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.879 | Acc: 60.384,92.086,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.876 | Acc: 60.484,92.157,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.881 | Acc: 60.468,92.066,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.878 | Acc: 60.538,92.088,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.881 | Acc: 60.454,92.057,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.884 | Acc: 60.399,92.036,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.885 | Acc: 60.408,92.021,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.807 | Acc: 56.250,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.046 | Acc: 51.562,69.494,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.041 | Acc: 51.334,68.312,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.029 | Acc: 51.217,67.943,74.206,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.173 | Acc: 49.219,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.867 | Acc: 59.077,92.932,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.858 | Acc: 59.546,92.550,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.854 | Acc: 60.003,92.316,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.849 | Acc: 60.079,92.371,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.851 | Acc: 60.234,92.273,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.852 | Acc: 60.066,92.226,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.863 | Acc: 60.007,92.254,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.869 | Acc: 59.967,92.260,99.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.867 | Acc: 60.165,92.136,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.874 | Acc: 60.176,92.063,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.871 | Acc: 60.287,92.103,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.875 | Acc: 60.211,92.058,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.878 | Acc: 60.207,92.017,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.878 | Acc: 60.245,92.090,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.880 | Acc: 60.239,92.021,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.881 | Acc: 60.261,91.968,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.882 | Acc: 60.287,91.853,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.883 | Acc: 60.247,91.837,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.886 | Acc: 60.271,91.835,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.768 | Acc: 53.125,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.015 | Acc: 51.190,69.345,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.010 | Acc: 51.296,68.807,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.000 | Acc: 51.050,68.712,74.705,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.960 | Acc: 58.594,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.858 | Acc: 61.310,93.006,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.857 | Acc: 60.957,92.645,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.845 | Acc: 61.091,92.905,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.845 | Acc: 61.015,92.728,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.867 | Acc: 60.566,92.628,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.858 | Acc: 60.789,92.775,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.870 | Acc: 60.616,92.603,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.873 | Acc: 60.690,92.416,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.875 | Acc: 60.648,92.330,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.878 | Acc: 60.459,92.242,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.877 | Acc: 60.478,92.248,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.882 | Acc: 60.380,92.149,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.878 | Acc: 60.491,92.098,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.880 | Acc: 60.431,92.065,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.879 | Acc: 60.457,92.037,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.880 | Acc: 60.402,91.985,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.883 | Acc: 60.349,91.880,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.885 | Acc: 60.273,91.887,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.887 | Acc: 60.177,91.866,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.889 | Acc: 53.125,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.076 | Acc: 51.302,69.122,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.078 | Acc: 51.010,68.559,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.068 | Acc: 50.666,67.982,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.893 | Acc: 60.938,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.901 | Acc: 59.673,92.001,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.901 | Acc: 60.156,92.149,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.902 | Acc: 59.951,92.162,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.897 | Acc: 59.992,92.265,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.890 | Acc: 60.210,92.327,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.886 | Acc: 60.382,92.388,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.885 | Acc: 60.361,92.487,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.882 | Acc: 60.248,92.498,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.881 | Acc: 60.260,92.356,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.888 | Acc: 60.218,92.296,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.885 | Acc: 60.287,92.226,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.884 | Acc: 60.318,92.155,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.889 | Acc: 60.210,92.113,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.891 | Acc: 60.234,92.087,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.890 | Acc: 60.307,92.099,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.884 | Acc: 60.349,92.127,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.883 | Acc: 60.395,92.110,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.882 | Acc: 60.448,92.043,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.885 | Acc: 60.408,91.978,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.853 | Acc: 54.688,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.054 | Acc: 51.562,68.899,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.052 | Acc: 51.181,68.140,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.045 | Acc: 51.025,68.148,74.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.770 | Acc: 64.062,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.832 | Acc: 60.714,93.043,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.853 | Acc: 60.023,92.511,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.847 | Acc: 60.643,92.303,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.833 | Acc: 60.966,92.467,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.831 | Acc: 60.914,92.327,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.838 | Acc: 60.879,92.368,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.847 | Acc: 60.810,92.221,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.852 | Acc: 60.797,92.386,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.857 | Acc: 60.735,92.339,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.856 | Acc: 60.638,92.265,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.864 | Acc: 60.393,92.198,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.866 | Acc: 60.425,92.116,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.871 | Acc: 60.258,92.062,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.868 | Acc: 60.326,92.107,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.870 | Acc: 60.307,92.037,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.871 | Acc: 60.385,92.039,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.877 | Acc: 60.243,92.016,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.880 | Acc: 60.215,91.978,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.877 | Acc: 60.314,91.993,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.758 | Acc: 55.469,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.029 | Acc: 51.376,68.490,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.024 | Acc: 51.105,68.064,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.010 | Acc: 50.999,67.994,74.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.542 | Acc: 68.750,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.866 | Acc: 60.156,92.485,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.866 | Acc: 60.404,92.550,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.873 | Acc: 60.374,92.482,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.877 | Acc: 60.137,92.535,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.882 | Acc: 60.079,92.396,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.882 | Acc: 60.111,92.304,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.870 | Acc: 60.472,92.459,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.870 | Acc: 60.525,92.323,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.873 | Acc: 60.338,92.326,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.873 | Acc: 60.308,92.296,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.873 | Acc: 60.234,92.212,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.878 | Acc: 60.202,92.136,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.879 | Acc: 60.180,92.083,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.880 | Acc: 60.217,92.071,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.878 | Acc: 60.302,92.019,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.873 | Acc: 60.487,92.015,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.875 | Acc: 60.443,92.018,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.877 | Acc: 60.457,92.004,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.879 | Acc: 60.449,91.974,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.787 | Acc: 56.250,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.036 | Acc: 51.600,68.564,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.036 | Acc: 51.353,67.912,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.024 | Acc: 51.268,67.892,74.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.969 | Acc: 53.125,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.821 | Acc: 60.379,93.415,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.842 | Acc: 60.080,92.778,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.832 | Acc: 60.784,92.738,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.834 | Acc: 60.899,92.776,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.841 | Acc: 60.930,92.721,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.842 | Acc: 60.847,92.730,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.849 | Acc: 60.721,92.537,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.852 | Acc: 60.588,92.537,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.853 | Acc: 60.540,92.498,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.858 | Acc: 60.467,92.409,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.857 | Acc: 60.580,92.424,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.862 | Acc: 60.480,92.327,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.872 | Acc: 60.321,92.268,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.872 | Acc: 60.348,92.271,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.867 | Acc: 60.431,92.258,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.870 | Acc: 60.397,92.139,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.870 | Acc: 60.406,92.087,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.871 | Acc: 60.379,92.058,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.872 | Acc: 60.365,92.038,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.864 | Acc: 53.125,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.106 | Acc: 49.740,68.713,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.101 | Acc: 49.981,67.950,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.093 | Acc: 49.693,67.725,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.073 | Acc: 54.688,85.938,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.861 | Acc: 60.640,92.188,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.846 | Acc: 60.995,92.340,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.838 | Acc: 61.168,92.533,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.853 | Acc: 60.764,92.438,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.848 | Acc: 61.054,92.404,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.847 | Acc: 61.215,92.252,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.853 | Acc: 61.159,92.243,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.860 | Acc: 60.942,92.241,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.856 | Acc: 60.903,92.274,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.859 | Acc: 60.871,92.261,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.858 | Acc: 60.860,92.230,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.863 | Acc: 60.733,92.178,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.860 | Acc: 60.788,92.167,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.861 | Acc: 60.718,92.246,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.863 | Acc: 60.719,92.195,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.862 | Acc: 60.689,92.243,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.865 | Acc: 60.644,92.194,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.865 | Acc: 60.593,92.216,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.869 | Acc: 60.495,92.196,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.818 | Acc: 51.562,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.055 | Acc: 51.228,68.750,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 50.877,68.197,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.041 | Acc: 50.615,68.058,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.823 | Acc: 58.594,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.824 | Acc: 60.938,92.485,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.846 | Acc: 60.861,92.416,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.848 | Acc: 60.592,92.341,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.841 | Acc: 60.783,92.429,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.843 | Acc: 60.783,92.520,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.838 | Acc: 60.866,92.588,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.844 | Acc: 60.721,92.509,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.843 | Acc: 60.709,92.450,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.847 | Acc: 60.691,92.421,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.850 | Acc: 60.615,92.339,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.848 | Acc: 60.580,92.364,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.847 | Acc: 60.597,92.320,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.851 | Acc: 60.584,92.223,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.851 | Acc: 60.698,92.226,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.856 | Acc: 60.629,92.180,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.857 | Acc: 60.631,92.134,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.860 | Acc: 60.557,92.105,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.867 | Acc: 60.425,92.049,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.864 | Acc: 60.513,92.056,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.841 | Acc: 53.906,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.096 | Acc: 50.558,68.490,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.085 | Acc: 50.514,67.816,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.077 | Acc: 50.320,67.713,74.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 1.724 | Acc: 61.719,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.810 | Acc: 61.347,92.671,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.860 | Acc: 60.004,92.416,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.832 | Acc: 60.553,92.623,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.833 | Acc: 60.764,92.593,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.822 | Acc: 61.054,92.574,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.830 | Acc: 60.989,92.575,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.837 | Acc: 60.782,92.520,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.839 | Acc: 60.758,92.430,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.839 | Acc: 60.886,92.485,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.840 | Acc: 60.809,92.460,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.847 | Acc: 60.672,92.456,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.847 | Acc: 60.623,92.434,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.850 | Acc: 60.635,92.397,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.851 | Acc: 60.676,92.310,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.854 | Acc: 60.595,92.234,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.855 | Acc: 60.492,92.297,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.856 | Acc: 60.486,92.286,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.856 | Acc: 60.565,92.237,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.860 | Acc: 60.534,92.200,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.732 | Acc: 54.688,69.531,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.019 | Acc: 51.897,69.196,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.029 | Acc: 51.486,68.350,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.018 | Acc: 51.178,68.263,74.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.864 | Acc: 54.688,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.819 | Acc: 60.454,93.564,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.852 | Acc: 60.213,92.473,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.827 | Acc: 61.270,92.482,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.840 | Acc: 60.860,92.216,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.846 | Acc: 60.597,92.296,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.854 | Acc: 60.408,92.330,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.859 | Acc: 60.239,92.304,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.862 | Acc: 60.239,92.221,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.866 | Acc: 60.156,92.170,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.865 | Acc: 60.215,92.133,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.864 | Acc: 60.248,92.120,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.865 | Acc: 60.318,92.055,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.868 | Acc: 60.312,92.008,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.865 | Acc: 60.495,91.971,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.871 | Acc: 60.333,91.905,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.868 | Acc: 60.470,91.934,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.871 | Acc: 60.438,91.908,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.872 | Acc: 60.366,91.878,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.872 | Acc: 60.357,91.861,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.769 | Acc: 53.906,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.096 | Acc: 50.781,68.378,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.097 | Acc: 50.400,67.816,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.083 | Acc: 50.026,67.764,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.903 | Acc: 58.594,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.848 | Acc: 60.305,92.485,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.841 | Acc: 60.404,92.302,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.852 | Acc: 60.656,92.200,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.862 | Acc: 60.349,92.168,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.865 | Acc: 60.280,92.164,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.867 | Acc: 60.285,92.200,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.861 | Acc: 60.450,92.271,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.862 | Acc: 60.379,92.343,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.858 | Acc: 60.523,92.313,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.858 | Acc: 60.479,92.331,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.859 | Acc: 60.545,92.244,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.859 | Acc: 60.552,92.226,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.859 | Acc: 60.560,92.256,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.862 | Acc: 60.615,92.224,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.862 | Acc: 60.592,92.200,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.860 | Acc: 60.636,92.195,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.860 | Acc: 60.626,92.162,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.863 | Acc: 60.580,92.099,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.866 | Acc: 60.581,92.060,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.873 | Acc: 53.125,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.095 | Acc: 51.339,68.564,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.084 | Acc: 51.143,68.216,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.076 | Acc: 50.653,68.122,74.206,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.755 | Acc: 65.625,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.871 | Acc: 60.305,92.969,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.862 | Acc: 60.690,93.293,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.868 | Acc: 60.528,93.571,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.870 | Acc: 60.552,93.133,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.857 | Acc: 60.930,92.930,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.858 | Acc: 61.054,92.646,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.858 | Acc: 61.059,92.509,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.856 | Acc: 61.035,92.566,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.862 | Acc: 60.989,92.412,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.860 | Acc: 60.922,92.401,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.862 | Acc: 60.778,92.361,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.859 | Acc: 60.808,92.363,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.864 | Acc: 60.698,92.274,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.861 | Acc: 60.746,92.310,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.863 | Acc: 60.699,92.208,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.863 | Acc: 60.677,92.153,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.863 | Acc: 60.724,92.121,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.861 | Acc: 60.773,92.120,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.865 | Acc: 60.628,92.105,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.764 | Acc: 56.250,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.069 | Acc: 51.823,69.196,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 51.181,68.293,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.036 | Acc: 51.050,68.289,74.296,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.757 | Acc: 64.062,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.815 | Acc: 61.458,93.266,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.822 | Acc: 61.509,92.873,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.807 | Acc: 61.501,92.828,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.823 | Acc: 61.410,92.622,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.830 | Acc: 61.564,92.505,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.826 | Acc: 61.609,92.504,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.822 | Acc: 61.630,92.525,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.833 | Acc: 61.335,92.343,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.834 | Acc: 61.322,92.412,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.839 | Acc: 61.175,92.355,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.841 | Acc: 61.086,92.347,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.841 | Acc: 60.980,92.324,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.841 | Acc: 60.988,92.298,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.843 | Acc: 60.907,92.315,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.844 | Acc: 60.925,92.297,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.845 | Acc: 60.911,92.273,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.851 | Acc: 60.775,92.233,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.851 | Acc: 60.780,92.229,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.850 | Acc: 60.880,92.200,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.834 | Acc: 57.031,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.061 | Acc: 51.637,68.192,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.071 | Acc: 51.029,67.721,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.054 | Acc: 51.037,67.649,74.436,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.731 | Acc: 60.156,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.827 | Acc: 60.640,91.853,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.838 | Acc: 60.537,92.130,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.832 | Acc: 61.168,92.136,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.835 | Acc: 61.217,92.448,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.828 | Acc: 61.448,92.481,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.838 | Acc: 61.235,92.446,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.839 | Acc: 61.148,92.409,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.843 | Acc: 61.102,92.270,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.860 | Acc: 60.717,92.261,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.861 | Acc: 60.665,92.254,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.854 | Acc: 60.679,92.393,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.850 | Acc: 60.769,92.392,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.849 | Acc: 60.749,92.364,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.850 | Acc: 60.796,92.415,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.853 | Acc: 60.777,92.411,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.850 | Acc: 60.843,92.399,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.854 | Acc: 60.713,92.357,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.855 | Acc: 60.704,92.313,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.857 | Acc: 60.655,92.270,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.896 | Acc: 53.906,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.095 | Acc: 51.265,68.452,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.102 | Acc: 50.800,67.931,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.085 | Acc: 50.371,67.853,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 1.610 | Acc: 64.844,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.858 | Acc: 58.557,92.894,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.829 | Acc: 59.775,93.026,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.835 | Acc: 60.464,92.866,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.829 | Acc: 60.774,92.814,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.827 | Acc: 61.162,92.729,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.821 | Acc: 61.280,92.717,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.819 | Acc: 61.370,92.636,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.830 | Acc: 61.136,92.542,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.836 | Acc: 61.097,92.451,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.840 | Acc: 61.062,92.359,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.845 | Acc: 60.955,92.297,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.845 | Acc: 60.970,92.220,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.847 | Acc: 60.812,92.196,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.847 | Acc: 60.801,92.196,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.850 | Acc: 60.774,92.133,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.854 | Acc: 60.687,92.085,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.855 | Acc: 60.669,92.084,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.856 | Acc: 60.671,92.120,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.858 | Acc: 60.648,92.097,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.832 | Acc: 56.250,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.054 | Acc: 52.046,68.006,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.055 | Acc: 51.658,67.550,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.046 | Acc: 51.498,67.290,74.129,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 2.041 | Acc: 60.938,91.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.892 | Acc: 60.193,92.336,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.876 | Acc: 60.709,92.245,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.866 | Acc: 61.078,92.123,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.860 | Acc: 61.073,92.130,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.864 | Acc: 60.760,92.226,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.856 | Acc: 60.705,92.394,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.864 | Acc: 60.594,92.304,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.865 | Acc: 60.530,92.425,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.864 | Acc: 60.597,92.472,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.861 | Acc: 60.576,92.467,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.862 | Acc: 60.478,92.357,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.855 | Acc: 60.633,92.343,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.850 | Acc: 60.650,92.442,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.852 | Acc: 60.565,92.402,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.853 | Acc: 60.514,92.369,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.852 | Acc: 60.524,92.353,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.851 | Acc: 60.511,92.339,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.852 | Acc: 60.583,92.343,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.852 | Acc: 60.570,92.327,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.806 | Acc: 55.469,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.056 | Acc: 52.344,68.824,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.080 | Acc: 51.715,67.873,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.067 | Acc: 51.345,67.623,74.155,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.858 | Acc: 61.719,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.851 | Acc: 61.086,93.192,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.849 | Acc: 60.537,92.835,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.848 | Acc: 60.797,92.777,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.848 | Acc: 60.976,92.544,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.843 | Acc: 60.814,92.536,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.849 | Acc: 60.647,92.413,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.849 | Acc: 60.627,92.476,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.853 | Acc: 60.705,92.391,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.839 | Acc: 60.929,92.438,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.839 | Acc: 60.883,92.506,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.838 | Acc: 60.920,92.453,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.842 | Acc: 60.818,92.392,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.841 | Acc: 60.911,92.385,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.845 | Acc: 60.793,92.346,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.845 | Acc: 60.862,92.312,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.848 | Acc: 60.813,92.263,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.849 | Acc: 60.718,92.291,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.848 | Acc: 60.723,92.278,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.846 | Acc: 60.769,92.288,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.808 | Acc: 52.344,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.099 | Acc: 50.930,68.080,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.090 | Acc: 50.800,67.473,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.076 | Acc: 50.884,67.341,74.193,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 2.007 | Acc: 57.812,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.864 | Acc: 60.305,92.150,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.832 | Acc: 60.385,92.397,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.822 | Acc: 61.014,92.418,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.829 | Acc: 60.899,92.361,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.830 | Acc: 60.783,92.381,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.840 | Acc: 60.660,92.310,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.830 | Acc: 60.843,92.293,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.834 | Acc: 60.700,92.328,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.843 | Acc: 60.558,92.364,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.842 | Acc: 60.572,92.347,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.840 | Acc: 60.747,92.325,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.849 | Acc: 60.698,92.191,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.844 | Acc: 60.791,92.196,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.848 | Acc: 60.771,92.143,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.847 | Acc: 60.792,92.141,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.847 | Acc: 60.743,92.209,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.848 | Acc: 60.779,92.217,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.849 | Acc: 60.795,92.200,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.851 | Acc: 60.796,92.181,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.765 | Acc: 55.469,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.013 | Acc: 51.786,68.787,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.015 | Acc: 51.925,67.797,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.005 | Acc: 51.665,68.135,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 2.043 | Acc: 51.562,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.844 | Acc: 59.524,92.894,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.822 | Acc: 60.423,93.083,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.813 | Acc: 61.206,93.097,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.812 | Acc: 61.179,93.152,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.822 | Acc: 60.922,93.093,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.828 | Acc: 60.918,92.962,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.834 | Acc: 60.760,92.863,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.842 | Acc: 60.666,92.653,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.840 | Acc: 60.653,92.610,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.838 | Acc: 60.868,92.576,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.833 | Acc: 61.029,92.626,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.836 | Acc: 61.067,92.551,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.838 | Acc: 61.048,92.532,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.843 | Acc: 60.954,92.452,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.842 | Acc: 60.909,92.470,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.846 | Acc: 60.947,92.372,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.842 | Acc: 61.061,92.366,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.850 | Acc: 60.942,92.328,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.852 | Acc: 60.886,92.257,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.842 | Acc: 56.250,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.103 | Acc: 51.265,68.043,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.099 | Acc: 51.086,67.835,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.091 | Acc: 50.807,67.674,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 1.772 | Acc: 54.688,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.818 | Acc: 60.900,92.448,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.809 | Acc: 60.938,92.435,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.824 | Acc: 60.540,92.546,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.828 | Acc: 60.426,92.419,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.848 | Acc: 60.094,92.311,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.850 | Acc: 60.479,92.252,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.844 | Acc: 60.660,92.420,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.844 | Acc: 60.797,92.333,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.847 | Acc: 60.739,92.369,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.853 | Acc: 60.627,92.222,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.859 | Acc: 60.474,92.166,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.858 | Acc: 60.513,92.097,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.854 | Acc: 60.647,92.131,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.851 | Acc: 60.682,92.115,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.852 | Acc: 60.605,92.102,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.852 | Acc: 60.568,92.144,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.848 | Acc: 60.656,92.199,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.850 | Acc: 60.613,92.164,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.852 | Acc: 60.552,92.157,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.871 | Acc: 52.344,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.115 | Acc: 51.153,68.341,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.113 | Acc: 50.934,67.740,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.109 | Acc: 50.487,67.546,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.877 | Acc: 60.156,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.858 | Acc: 60.193,93.006,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.852 | Acc: 60.042,93.026,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.823 | Acc: 60.861,92.982,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.832 | Acc: 60.899,93.027,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.820 | Acc: 61.255,93.139,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.815 | Acc: 61.512,93.150,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.814 | Acc: 61.641,93.135,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.822 | Acc: 61.554,93.071,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.821 | Acc: 61.455,92.995,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.825 | Acc: 61.307,92.829,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.829 | Acc: 61.217,92.689,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.828 | Acc: 61.382,92.661,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.833 | Acc: 61.186,92.595,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.836 | Acc: 61.102,92.529,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.840 | Acc: 61.093,92.504,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.840 | Acc: 61.040,92.489,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.841 | Acc: 61.027,92.520,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.845 | Acc: 61.009,92.415,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.844 | Acc: 61.036,92.384,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.922 | Acc: 54.688,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.145 | Acc: 49.554,68.713,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.136 | Acc: 49.524,67.797,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.122 | Acc: 49.616,67.572,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.988 | Acc: 59.375,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.779 | Acc: 62.946,93.452,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.774 | Acc: 62.538,93.197,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.798 | Acc: 62.001,93.046,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.787 | Acc: 62.249,92.911,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.800 | Acc: 61.750,92.830,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.808 | Acc: 61.661,92.756,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.806 | Acc: 61.691,92.681,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.817 | Acc: 61.510,92.585,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.827 | Acc: 61.339,92.498,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.831 | Acc: 61.105,92.456,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.827 | Acc: 61.213,92.431,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.833 | Acc: 61.048,92.340,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.836 | Acc: 61.048,92.334,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.839 | Acc: 61.035,92.268,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.840 | Acc: 61.047,92.258,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.840 | Acc: 61.013,92.261,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.841 | Acc: 60.892,92.272,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.845 | Acc: 60.812,92.285,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.845 | Acc: 60.845,92.243,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.808 | Acc: 56.250,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.072 | Acc: 52.083,67.634,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.051 | Acc: 51.543,67.283,73.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.041 | Acc: 51.306,67.354,74.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.637 | Acc: 65.625,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.828 | Acc: 61.458,92.708,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.826 | Acc: 60.976,92.797,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.826 | Acc: 61.322,92.533,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.831 | Acc: 61.400,92.573,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.822 | Acc: 61.672,92.760,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.825 | Acc: 61.564,92.762,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.828 | Acc: 61.420,92.730,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.833 | Acc: 61.136,92.721,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.831 | Acc: 61.291,92.671,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.825 | Acc: 61.303,92.693,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.827 | Acc: 61.242,92.615,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.827 | Acc: 61.197,92.525,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.833 | Acc: 61.135,92.427,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.833 | Acc: 61.174,92.402,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.832 | Acc: 61.215,92.322,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.835 | Acc: 61.071,92.312,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.836 | Acc: 60.990,92.339,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.841 | Acc: 60.899,92.296,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.842 | Acc: 60.909,92.253,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.950 | Acc: 56.250,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.096 | Acc: 51.749,67.336,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.102 | Acc: 50.953,66.806,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.097 | Acc: 50.781,66.688,74.078,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.880 | Acc: 63.281,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.799 | Acc: 61.905,92.932,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.825 | Acc: 61.566,92.912,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.811 | Acc: 61.603,92.956,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.823 | Acc: 61.343,92.795,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.820 | Acc: 61.262,92.884,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.820 | Acc: 61.196,92.794,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.820 | Acc: 61.287,92.742,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.824 | Acc: 61.112,92.716,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.827 | Acc: 61.114,92.649,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.828 | Acc: 61.144,92.584,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.828 | Acc: 61.139,92.559,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.827 | Acc: 61.116,92.593,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.828 | Acc: 61.102,92.595,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.832 | Acc: 61.085,92.538,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.834 | Acc: 61.054,92.551,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.835 | Acc: 61.074,92.514,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.836 | Acc: 61.068,92.472,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.837 | Acc: 61.098,92.443,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.840 | Acc: 61.028,92.411,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.827 | Acc: 54.688,67.969,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.017 | Acc: 51.897,68.862,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.027 | Acc: 51.791,68.026,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.013 | Acc: 51.575,67.802,74.168,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 2.139 | Acc: 56.250,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.852 | Acc: 60.714,92.746,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.864 | Acc: 60.785,92.645,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.868 | Acc: 60.669,92.687,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.855 | Acc: 60.831,92.824,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.845 | Acc: 60.821,92.891,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.843 | Acc: 60.931,92.904,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.844 | Acc: 60.832,92.852,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.845 | Acc: 60.831,92.847,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.845 | Acc: 60.877,92.792,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.844 | Acc: 60.848,92.732,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.844 | Acc: 60.803,92.760,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.844 | Acc: 60.840,92.777,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.838 | Acc: 60.940,92.801,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.834 | Acc: 61.035,92.799,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.838 | Acc: 60.982,92.686,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.842 | Acc: 60.920,92.633,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.843 | Acc: 60.899,92.572,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.845 | Acc: 60.886,92.514,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.844 | Acc: 60.921,92.520,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.900 | Acc: 51.562,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.122 | Acc: 50.074,67.969,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.122 | Acc: 49.886,67.454,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.108 | Acc: 50.000,67.316,74.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.441 | Acc: 69.531,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.813 | Acc: 60.863,92.485,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.784 | Acc: 61.719,92.854,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.790 | Acc: 61.514,92.930,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.808 | Acc: 61.478,92.554,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.800 | Acc: 61.487,92.706,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.812 | Acc: 61.318,92.723,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.811 | Acc: 61.397,92.586,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.818 | Acc: 61.331,92.600,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.822 | Acc: 61.132,92.567,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.820 | Acc: 61.206,92.561,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.820 | Acc: 61.238,92.537,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.825 | Acc: 61.171,92.440,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.832 | Acc: 60.976,92.409,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.835 | Acc: 60.907,92.321,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.838 | Acc: 60.865,92.320,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.838 | Acc: 60.862,92.248,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.839 | Acc: 60.834,92.263,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.840 | Acc: 60.827,92.263,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.841 | Acc: 60.806,92.241,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.791 | Acc: 56.250,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.067 | Acc: 51.153,67.932,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.074 | Acc: 51.105,67.511,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.073 | Acc: 50.717,67.418,74.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.637 | Acc: 65.625,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.792 | Acc: 61.384,93.266,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.784 | Acc: 61.662,93.598,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.800 | Acc: 61.296,93.353,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.802 | Acc: 61.622,93.133,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.814 | Acc: 61.278,92.930,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.823 | Acc: 61.176,92.917,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.821 | Acc: 61.192,92.847,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.825 | Acc: 61.083,92.692,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.828 | Acc: 61.020,92.615,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.833 | Acc: 61.042,92.522,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.832 | Acc: 61.157,92.467,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.829 | Acc: 61.242,92.482,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.830 | Acc: 61.219,92.454,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.830 | Acc: 61.213,92.413,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.831 | Acc: 61.189,92.442,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.828 | Acc: 61.195,92.489,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.830 | Acc: 61.123,92.472,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.830 | Acc: 61.147,92.374,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.834 | Acc: 61.015,92.352,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.892 | Acc: 55.469,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.079 | Acc: 50.781,68.006,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.105 | Acc: 50.991,66.940,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.098 | Acc: 50.679,66.534,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.734 | Acc: 56.250,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.801 | Acc: 60.900,92.708,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.824 | Acc: 60.880,92.550,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.800 | Acc: 61.565,92.559,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.810 | Acc: 61.535,92.564,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.806 | Acc: 61.487,92.667,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.813 | Acc: 61.228,92.523,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.816 | Acc: 61.087,92.514,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.824 | Acc: 60.889,92.401,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.828 | Acc: 60.877,92.425,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.833 | Acc: 60.809,92.483,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.832 | Acc: 60.902,92.499,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.833 | Acc: 60.934,92.499,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.835 | Acc: 60.845,92.436,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.834 | Acc: 60.904,92.371,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.840 | Acc: 60.792,92.315,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.839 | Acc: 60.857,92.341,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.842 | Acc: 60.782,92.332,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.844 | Acc: 60.745,92.335,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.845 | Acc: 60.726,92.356,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.775 | Acc: 53.906,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.041 | Acc: 51.860,68.713,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 51.448,67.912,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.048 | Acc: 51.217,67.636,74.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.818 | Acc: 61.719,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.730 | Acc: 63.281,93.601,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.743 | Acc: 62.843,93.769,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.739 | Acc: 62.615,94.006,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.730 | Acc: 62.770,94.329,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.731 | Acc: 62.539,94.284,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.738 | Acc: 62.177,94.234,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.753 | Acc: 61.857,94.210,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.756 | Acc: 61.864,94.196,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.754 | Acc: 62.064,94.199,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.750 | Acc: 62.154,94.158,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.748 | Acc: 62.189,94.195,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.747 | Acc: 62.309,94.217,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.746 | Acc: 62.320,94.205,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.744 | Acc: 62.397,94.234,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.746 | Acc: 62.272,94.261,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.743 | Acc: 62.383,94.298,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.744 | Acc: 62.351,94.268,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.746 | Acc: 62.301,94.285,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.743 | Acc: 62.272,94.341,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.770 | Acc: 56.250,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.998 | Acc: 52.195,69.606,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.005 | Acc: 52.115,68.636,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.995 | Acc: 51.806,68.404,74.757,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.616 | Acc: 69.531,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.784 | Acc: 63.021,94.457,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.755 | Acc: 62.710,94.188,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.722 | Acc: 63.294,94.378,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.730 | Acc: 62.895,94.599,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.740 | Acc: 62.523,94.570,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.728 | Acc: 62.642,94.796,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.722 | Acc: 62.827,94.764,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.721 | Acc: 62.680,94.808,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.730 | Acc: 62.440,94.795,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.734 | Acc: 62.329,94.745,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.730 | Acc: 62.267,94.849,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.730 | Acc: 62.293,94.842,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.735 | Acc: 62.234,94.810,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.736 | Acc: 62.269,94.801,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.735 | Acc: 62.209,94.788,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.732 | Acc: 62.296,94.826,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.731 | Acc: 62.278,94.822,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.732 | Acc: 62.262,94.800,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.732 | Acc: 62.201,94.763,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.758 | Acc: 57.031,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.992 | Acc: 52.493,69.345,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.001 | Acc: 52.344,68.502,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.993 | Acc: 52.011,68.327,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.819 | Acc: 58.594,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.707 | Acc: 62.574,94.457,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.704 | Acc: 62.462,94.684,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.718 | Acc: 62.218,94.839,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.725 | Acc: 62.076,94.907,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.716 | Acc: 62.175,94.926,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.716 | Acc: 62.164,94.886,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.719 | Acc: 62.151,94.891,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.720 | Acc: 62.151,94.842,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.722 | Acc: 62.168,94.877,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.727 | Acc: 62.185,94.928,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.729 | Acc: 62.154,94.987,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.732 | Acc: 62.088,94.946,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.728 | Acc: 62.171,94.956,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.723 | Acc: 62.297,94.959,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.717 | Acc: 62.440,94.918,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.716 | Acc: 62.449,94.906,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.719 | Acc: 62.358,94.889,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.720 | Acc: 62.301,94.895,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.719 | Acc: 62.361,94.886,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.802 | Acc: 57.031,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.009 | Acc: 52.344,69.196,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.010 | Acc: 52.191,68.483,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.998 | Acc: 51.947,68.404,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.552 | Acc: 67.969,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.661 | Acc: 63.467,95.573,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.717 | Acc: 62.081,95.370,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.739 | Acc: 61.885,95.095,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.722 | Acc: 62.047,95.110,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.721 | Acc: 62.167,95.073,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.715 | Acc: 62.519,95.048,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.714 | Acc: 62.589,95.074,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.720 | Acc: 62.403,95.002,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.724 | Acc: 62.496,94.959,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.721 | Acc: 62.543,95.002,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.719 | Acc: 62.571,94.984,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.713 | Acc: 62.707,95.005,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.713 | Acc: 62.680,95.034,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.715 | Acc: 62.633,95.029,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.716 | Acc: 62.586,95.076,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.719 | Acc: 62.502,95.091,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.723 | Acc: 62.349,95.065,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.721 | Acc: 62.316,95.064,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.720 | Acc: 62.336,95.056,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.725 | Acc: 57.031,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.949 | Acc: 53.460,69.754,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.957 | Acc: 52.611,68.883,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.948 | Acc: 52.267,68.622,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.590 | Acc: 66.406,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.712 | Acc: 61.756,95.238,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.684 | Acc: 63.014,95.503,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.697 | Acc: 62.795,95.466,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.706 | Acc: 62.741,95.187,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.705 | Acc: 62.461,95.227,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.714 | Acc: 62.235,95.241,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.721 | Acc: 62.140,95.229,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.722 | Acc: 62.146,95.109,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.720 | Acc: 62.340,95.015,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.717 | Acc: 62.461,95.017,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.713 | Acc: 62.542,95.093,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.717 | Acc: 62.526,95.105,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.716 | Acc: 62.518,95.115,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.721 | Acc: 62.358,95.071,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.723 | Acc: 62.251,95.035,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.722 | Acc: 62.342,95.035,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.724 | Acc: 62.317,95.072,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.722 | Acc: 62.327,95.111,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.719 | Acc: 62.348,95.134,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.723 | Acc: 56.250,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.970 | Acc: 53.088,69.420,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.973 | Acc: 52.401,68.502,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.962 | Acc: 52.100,68.494,74.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.681 | Acc: 61.719,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.671 | Acc: 63.244,95.275,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.672 | Acc: 63.700,95.160,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.671 | Acc: 63.717,95.325,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.695 | Acc: 62.905,95.332,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.685 | Acc: 63.057,95.320,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.692 | Acc: 62.765,95.261,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.694 | Acc: 62.904,95.185,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.692 | Acc: 63.000,95.215,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.692 | Acc: 63.031,95.235,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.693 | Acc: 62.865,95.211,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.702 | Acc: 62.652,95.178,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.708 | Acc: 62.539,95.137,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.706 | Acc: 62.569,95.124,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.710 | Acc: 62.531,95.090,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.712 | Acc: 62.508,95.063,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.710 | Acc: 62.556,95.076,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.714 | Acc: 62.438,95.017,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.713 | Acc: 62.450,95.059,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.713 | Acc: 62.432,95.077,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.744 | Acc: 55.469,75.000,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.971 | Acc: 52.567,69.568,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.976 | Acc: 52.096,68.807,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.962 | Acc: 51.883,68.609,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.463 | Acc: 71.875,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.672 | Acc: 64.100,95.685,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.692 | Acc: 63.110,95.522,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.724 | Acc: 62.423,95.159,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.720 | Acc: 62.375,95.071,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.724 | Acc: 62.283,95.104,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.706 | Acc: 62.539,95.229,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.712 | Acc: 62.428,95.191,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.707 | Acc: 62.413,95.191,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.707 | Acc: 62.444,95.205,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.710 | Acc: 62.414,95.215,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.712 | Acc: 62.436,95.086,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.713 | Acc: 62.396,95.112,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.711 | Acc: 62.500,95.100,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.709 | Acc: 62.503,95.082,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.711 | Acc: 62.427,95.066,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.708 | Acc: 62.451,95.125,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.714 | Acc: 62.344,95.081,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.715 | Acc: 62.331,95.079,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.717 | Acc: 62.320,95.066,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.773 | Acc: 56.250,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.012 | Acc: 52.009,69.643,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.020 | Acc: 51.562,68.845,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.011 | Acc: 51.498,68.507,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.524 | Acc: 66.406,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.695 | Acc: 62.351,95.424,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.715 | Acc: 62.290,95.179,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.719 | Acc: 62.154,95.172,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.726 | Acc: 61.998,95.168,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.729 | Acc: 61.850,95.227,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.710 | Acc: 62.519,95.280,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.714 | Acc: 62.229,95.396,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.717 | Acc: 62.189,95.410,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.721 | Acc: 62.137,95.300,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.726 | Acc: 61.843,95.324,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.725 | Acc: 61.941,95.323,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.719 | Acc: 62.150,95.374,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.720 | Acc: 62.138,95.271,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.718 | Acc: 62.072,95.260,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.715 | Acc: 62.048,95.281,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.716 | Acc: 62.084,95.232,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.715 | Acc: 62.156,95.248,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.716 | Acc: 62.154,95.200,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.715 | Acc: 62.240,95.198,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.744 | Acc: 56.250,74.219,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.987 | Acc: 52.865,69.345,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.989 | Acc: 52.515,68.674,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.979 | Acc: 52.241,68.481,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.777 | Acc: 58.594,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.646 | Acc: 64.025,95.499,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.693 | Acc: 62.691,95.027,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.704 | Acc: 62.500,94.903,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.698 | Acc: 62.751,95.139,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.701 | Acc: 62.678,95.011,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.703 | Acc: 62.616,95.015,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.706 | Acc: 62.589,95.052,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.710 | Acc: 62.612,95.012,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.718 | Acc: 62.379,94.967,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.719 | Acc: 62.247,95.021,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.721 | Acc: 62.203,94.994,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.723 | Acc: 62.211,94.956,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.725 | Acc: 62.210,94.986,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.725 | Acc: 62.216,95.057,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.724 | Acc: 62.287,95.040,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.722 | Acc: 62.274,95.079,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.718 | Acc: 62.319,95.109,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.720 | Acc: 62.186,95.118,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.723 | Acc: 62.158,95.097,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.770 | Acc: 56.250,75.000,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.995 | Acc: 52.679,69.754,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.998 | Acc: 52.287,68.921,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.988 | Acc: 52.049,68.712,74.629,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.906 | Acc: 60.156,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.719 | Acc: 62.277,95.089,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 62.043,95.160,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.710 | Acc: 61.808,95.377,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.711 | Acc: 61.815,95.419,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.719 | Acc: 61.680,95.212,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.727 | Acc: 61.867,95.009,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.721 | Acc: 61.891,95.058,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.716 | Acc: 62.092,95.075,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.707 | Acc: 62.314,95.114,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.708 | Acc: 62.232,95.091,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.716 | Acc: 62.189,95.037,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.714 | Acc: 62.234,95.030,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.713 | Acc: 62.323,95.091,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.714 | Acc: 62.200,95.110,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.713 | Acc: 62.253,95.149,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.717 | Acc: 62.171,95.152,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.719 | Acc: 62.081,95.145,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.721 | Acc: 62.046,95.124,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.722 | Acc: 61.996,95.132,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.767 | Acc: 54.688,75.781,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.997 | Acc: 52.716,69.494,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.996 | Acc: 52.229,68.845,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.985 | Acc: 52.062,68.532,74.398,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.820 | Acc: 61.719,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.790 | Acc: 61.979,95.052,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.758 | Acc: 61.947,95.198,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.749 | Acc: 61.821,95.248,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.738 | Acc: 61.748,95.293,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.737 | Acc: 61.703,95.142,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.733 | Acc: 61.848,95.138,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.729 | Acc: 61.896,95.096,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.721 | Acc: 62.122,95.099,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.728 | Acc: 61.995,94.972,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.729 | Acc: 61.936,95.005,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.731 | Acc: 61.980,95.030,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.734 | Acc: 61.916,95.040,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.734 | Acc: 61.940,94.983,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.733 | Acc: 61.908,95.007,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.730 | Acc: 61.947,94.980,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.728 | Acc: 61.984,95.001,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.722 | Acc: 62.120,95.060,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.722 | Acc: 62.154,95.053,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.721 | Acc: 62.201,95.085,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.751 | Acc: 56.250,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.981 | Acc: 52.865,69.494,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.986 | Acc: 52.325,68.693,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.977 | Acc: 51.972,68.519,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.714 | Acc: 60.156,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.694 | Acc: 64.137,95.871,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.717 | Acc: 62.652,95.351,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.702 | Acc: 62.705,95.517,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.691 | Acc: 63.021,95.486,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.690 | Acc: 63.134,95.490,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.701 | Acc: 62.797,95.390,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.707 | Acc: 62.755,95.312,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.703 | Acc: 62.883,95.269,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.703 | Acc: 62.979,95.338,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.702 | Acc: 62.904,95.336,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.704 | Acc: 62.885,95.320,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.702 | Acc: 62.886,95.296,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.708 | Acc: 62.748,95.292,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.708 | Acc: 62.747,95.287,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.713 | Acc: 62.544,95.222,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.709 | Acc: 62.556,95.196,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.709 | Acc: 62.587,95.161,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.711 | Acc: 62.524,95.131,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.711 | Acc: 62.486,95.120,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.735 | Acc: 57.031,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.961 | Acc: 52.753,69.271,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.966 | Acc: 52.496,68.521,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.954 | Acc: 52.216,68.417,74.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.774 | Acc: 60.156,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.688 | Acc: 62.128,95.908,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.692 | Acc: 61.833,95.789,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.710 | Acc: 62.116,95.722,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.710 | Acc: 61.970,95.669,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.714 | Acc: 61.959,95.459,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.708 | Acc: 62.261,95.474,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.706 | Acc: 62.384,95.434,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.700 | Acc: 62.680,95.419,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.697 | Acc: 62.724,95.459,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.699 | Acc: 62.500,95.491,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.702 | Acc: 62.334,95.503,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.700 | Acc: 62.419,95.488,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.707 | Acc: 62.278,95.426,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.710 | Acc: 62.183,95.415,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.710 | Acc: 62.147,95.409,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.713 | Acc: 62.089,95.364,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.713 | Acc: 62.120,95.358,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.712 | Acc: 62.167,95.328,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.710 | Acc: 62.225,95.349,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.825 | Acc: 55.469,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.058 | Acc: 51.674,68.973,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.061 | Acc: 51.200,68.255,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.048 | Acc: 51.012,68.199,74.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.704 | Acc: 60.938,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.726 | Acc: 61.868,95.424,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.712 | Acc: 62.024,95.503,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.700 | Acc: 62.282,95.453,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.703 | Acc: 62.336,95.438,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.696 | Acc: 62.678,95.521,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.698 | Acc: 62.661,95.435,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.714 | Acc: 62.339,95.473,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.712 | Acc: 62.408,95.434,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.714 | Acc: 62.323,95.386,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.718 | Acc: 62.236,95.347,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.717 | Acc: 62.260,95.316,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.714 | Acc: 62.422,95.290,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.711 | Acc: 62.530,95.283,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.708 | Acc: 62.558,95.296,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.705 | Acc: 62.560,95.305,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.704 | Acc: 62.585,95.339,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.705 | Acc: 62.560,95.315,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.705 | Acc: 62.606,95.297,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.707 | Acc: 62.514,95.282,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.791 | Acc: 57.031,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.991 | Acc: 52.641,69.643,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.996 | Acc: 52.268,68.750,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.984 | Acc: 51.960,68.481,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.689 | Acc: 65.625,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.739 | Acc: 61.310,95.164,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.729 | Acc: 61.566,95.484,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.700 | Acc: 62.065,95.607,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.714 | Acc: 61.671,95.602,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.711 | Acc: 61.989,95.444,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.723 | Acc: 62.074,95.254,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.722 | Acc: 62.217,95.324,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.721 | Acc: 62.185,95.317,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.715 | Acc: 62.289,95.420,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.714 | Acc: 62.201,95.336,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.709 | Acc: 62.295,95.348,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.711 | Acc: 62.312,95.332,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.711 | Acc: 62.308,95.342,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.706 | Acc: 62.428,95.321,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.708 | Acc: 62.479,95.312,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.712 | Acc: 62.359,95.315,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.711 | Acc: 62.344,95.322,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.710 | Acc: 62.368,95.328,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.709 | Acc: 62.436,95.296,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.735 | Acc: 56.250,74.219,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.974 | Acc: 53.199,69.643,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.986 | Acc: 52.649,68.788,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.974 | Acc: 52.318,68.584,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.463 | Acc: 69.531,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.651 | Acc: 64.807,94.680,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.701 | Acc: 62.748,94.931,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.701 | Acc: 62.526,95.031,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.690 | Acc: 62.963,95.187,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.698 | Acc: 62.817,95.266,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.701 | Acc: 62.636,95.248,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.701 | Acc: 62.544,95.229,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.700 | Acc: 62.655,95.259,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.699 | Acc: 62.651,95.287,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.701 | Acc: 62.531,95.347,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.703 | Acc: 62.542,95.259,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.706 | Acc: 62.494,95.180,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.704 | Acc: 62.467,95.205,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.702 | Acc: 62.500,95.215,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.708 | Acc: 62.334,95.227,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.708 | Acc: 62.337,95.252,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.710 | Acc: 62.230,95.241,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.710 | Acc: 62.232,95.178,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.709 | Acc: 62.229,95.177,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.768 | Acc: 57.031,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.007 | Acc: 52.232,69.457,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.014 | Acc: 52.096,68.426,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.002 | Acc: 51.934,68.302,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.789 | Acc: 65.625,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.734 | Acc: 62.016,95.573,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.683 | Acc: 62.805,95.808,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.682 | Acc: 62.500,95.658,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.691 | Acc: 62.490,95.660,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.691 | Acc: 62.438,95.436,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.701 | Acc: 62.274,95.467,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.696 | Acc: 62.350,95.518,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.698 | Acc: 62.320,95.458,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.702 | Acc: 62.301,95.433,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.704 | Acc: 62.185,95.382,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.704 | Acc: 62.210,95.344,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.700 | Acc: 62.312,95.335,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.703 | Acc: 62.264,95.336,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.706 | Acc: 62.158,95.360,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.707 | Acc: 62.095,95.377,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.705 | Acc: 62.111,95.366,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.705 | Acc: 62.156,95.345,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.708 | Acc: 62.069,95.319,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.710 | Acc: 62.082,95.310,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.701 | Acc: 56.250,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.959 | Acc: 53.088,69.606,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.965 | Acc: 52.591,68.540,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.952 | Acc: 52.280,68.404,74.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.447 | Acc: 67.969,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.743 | Acc: 61.644,94.829,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.719 | Acc: 61.490,95.579,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.715 | Acc: 61.834,95.543,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 62.182,95.583,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.696 | Acc: 62.423,95.545,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.707 | Acc: 62.126,95.538,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.697 | Acc: 62.422,95.512,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.705 | Acc: 62.296,95.502,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.704 | Acc: 62.219,95.446,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.704 | Acc: 62.403,95.425,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.705 | Acc: 62.242,95.344,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.707 | Acc: 62.237,95.348,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.709 | Acc: 62.183,95.318,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.708 | Acc: 62.191,95.338,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.710 | Acc: 62.142,95.364,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.711 | Acc: 62.106,95.368,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.709 | Acc: 62.129,95.329,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.710 | Acc: 62.108,95.312,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.713 | Acc: 62.106,95.308,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.806 | Acc: 55.469,75.781,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.026 | Acc: 52.232,69.680,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.033 | Acc: 51.944,68.731,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.022 | Acc: 51.639,68.404,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.614 | Acc: 61.719,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.690 | Acc: 61.682,95.871,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.684 | Acc: 61.890,95.655,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.684 | Acc: 62.026,95.812,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.692 | Acc: 62.105,95.727,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.692 | Acc: 62.291,95.529,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.708 | Acc: 62.080,95.390,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.705 | Acc: 62.068,95.324,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.705 | Acc: 62.029,95.356,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.704 | Acc: 61.917,95.399,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.703 | Acc: 61.971,95.441,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.700 | Acc: 62.069,95.450,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.703 | Acc: 62.101,95.419,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.705 | Acc: 62.129,95.408,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.707 | Acc: 62.111,95.399,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.705 | Acc: 62.214,95.383,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.701 | Acc: 62.356,95.395,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.704 | Acc: 62.296,95.390,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.705 | Acc: 62.327,95.371,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.710 | Acc: 62.137,95.329,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.739 | Acc: 55.469,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.965 | Acc: 53.013,69.308,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.972 | Acc: 52.553,68.712,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.960 | Acc: 52.203,68.545,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.735 | Acc: 67.188,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.629 | Acc: 64.918,95.536,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.667 | Acc: 64.158,95.274,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.700 | Acc: 63.345,95.492,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.705 | Acc: 62.847,95.438,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.697 | Acc: 62.902,95.606,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.691 | Acc: 62.971,95.590,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.693 | Acc: 62.844,95.590,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.698 | Acc: 62.733,95.482,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.703 | Acc: 62.573,95.550,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.710 | Acc: 62.294,95.515,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.715 | Acc: 62.207,95.454,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.718 | Acc: 62.156,95.475,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.718 | Acc: 62.111,95.423,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.716 | Acc: 62.172,95.435,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.717 | Acc: 62.160,95.422,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.714 | Acc: 62.264,95.427,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.718 | Acc: 62.195,95.404,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.713 | Acc: 62.312,95.423,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.715 | Acc: 62.260,95.407,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.765 | Acc: 57.031,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.001 | Acc: 52.530,69.494,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.006 | Acc: 52.058,68.598,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.996 | Acc: 51.793,68.379,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.786 | Acc: 65.625,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.608 | Acc: 64.546,96.354,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.654 | Acc: 63.872,95.941,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.666 | Acc: 63.448,95.633,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.671 | Acc: 63.252,95.496,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.677 | Acc: 62.933,95.514,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.680 | Acc: 63.017,95.487,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.681 | Acc: 63.054,95.518,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.681 | Acc: 63.068,95.507,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.684 | Acc: 63.074,95.468,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.689 | Acc: 62.869,95.417,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.696 | Acc: 62.663,95.369,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.697 | Acc: 62.620,95.368,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.705 | Acc: 62.413,95.295,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.705 | Acc: 62.386,95.376,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.702 | Acc: 62.471,95.424,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.700 | Acc: 62.488,95.459,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.704 | Acc: 62.422,95.434,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.703 | Acc: 62.446,95.401,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.701 | Acc: 62.475,95.417,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.741 | Acc: 56.250,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.957 | Acc: 53.125,69.010,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.965 | Acc: 52.611,68.464,73.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.951 | Acc: 52.152,68.327,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.663 | Acc: 64.844,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.659 | Acc: 63.467,95.833,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.680 | Acc: 63.072,95.865,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.678 | Acc: 63.166,95.876,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.687 | Acc: 62.693,95.814,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.686 | Acc: 62.755,95.777,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.687 | Acc: 62.707,95.687,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.691 | Acc: 62.539,95.634,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.689 | Acc: 62.733,95.638,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.695 | Acc: 62.599,95.597,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.700 | Acc: 62.457,95.577,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.701 | Acc: 62.440,95.532,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.697 | Acc: 62.571,95.520,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.698 | Acc: 62.533,95.444,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.701 | Acc: 62.478,95.390,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.702 | Acc: 62.471,95.390,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.703 | Acc: 62.527,95.368,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.703 | Acc: 62.509,95.340,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.703 | Acc: 62.502,95.341,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.705 | Acc: 62.436,95.366,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.723 | Acc: 55.469,75.781,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.970 | Acc: 53.088,69.792,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.971 | Acc: 52.763,68.979,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.957 | Acc: 52.472,68.635,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.721 | Acc: 65.625,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.730 | Acc: 61.868,94.606,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.714 | Acc: 62.062,95.255,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.718 | Acc: 61.949,95.223,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.730 | Acc: 61.719,95.206,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.724 | Acc: 62.136,95.274,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.721 | Acc: 62.345,95.306,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.713 | Acc: 62.472,95.285,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.706 | Acc: 62.636,95.288,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.700 | Acc: 62.673,95.369,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.694 | Acc: 62.760,95.402,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.699 | Acc: 62.656,95.447,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.698 | Acc: 62.643,95.423,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.698 | Acc: 62.647,95.360,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.696 | Acc: 62.689,95.393,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.696 | Acc: 62.705,95.377,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.696 | Acc: 62.704,95.429,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.695 | Acc: 62.731,95.386,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.698 | Acc: 62.669,95.410,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.699 | Acc: 62.557,95.448,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.755 | Acc: 56.250,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.006 | Acc: 52.418,69.792,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.013 | Acc: 52.058,68.788,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.000 | Acc: 51.678,68.379,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.649 | Acc: 60.938,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.724 | Acc: 61.272,95.126,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.694 | Acc: 62.138,95.293,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.700 | Acc: 62.372,95.479,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.697 | Acc: 62.722,95.486,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.701 | Acc: 62.678,95.413,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.706 | Acc: 62.642,95.338,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.698 | Acc: 62.988,95.390,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.695 | Acc: 62.912,95.361,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.693 | Acc: 62.815,95.438,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.691 | Acc: 62.912,95.437,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.688 | Acc: 63.002,95.496,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.688 | Acc: 62.938,95.546,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.686 | Acc: 62.931,95.567,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.687 | Acc: 62.886,95.574,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.688 | Acc: 62.845,95.531,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.693 | Acc: 62.721,95.478,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.694 | Acc: 62.690,95.516,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.691 | Acc: 62.790,95.499,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.692 | Acc: 62.736,95.474,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.735 | Acc: 57.031,75.000,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.994 | Acc: 52.641,69.271,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.003 | Acc: 52.344,68.483,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.990 | Acc: 52.088,68.263,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.543 | Acc: 67.188,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.712 | Acc: 63.393,96.131,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.719 | Acc: 62.595,95.751,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.712 | Acc: 62.564,95.761,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.707 | Acc: 62.452,95.824,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.697 | Acc: 62.678,95.614,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.707 | Acc: 62.293,95.532,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.704 | Acc: 62.345,95.545,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.705 | Acc: 62.379,95.555,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.702 | Acc: 62.578,95.533,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.699 | Acc: 62.605,95.468,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.693 | Acc: 62.779,95.482,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.694 | Acc: 62.756,95.419,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.695 | Acc: 62.689,95.456,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.696 | Acc: 62.586,95.438,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.697 | Acc: 62.609,95.419,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.697 | Acc: 62.648,95.405,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.698 | Acc: 62.644,95.386,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.702 | Acc: 62.504,95.408,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.705 | Acc: 62.426,95.341,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.760 | Acc: 57.031,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.985 | Acc: 52.939,69.010,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.994 | Acc: 52.401,68.350,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.982 | Acc: 52.062,68.212,74.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.773 | Acc: 59.375,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.716 | Acc: 60.975,95.871,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.719 | Acc: 61.547,95.655,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.701 | Acc: 62.065,95.645,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 62.355,95.785,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.698 | Acc: 62.260,95.769,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.706 | Acc: 62.100,95.603,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.701 | Acc: 62.223,95.545,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.709 | Acc: 61.971,95.487,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.709 | Acc: 61.948,95.468,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.709 | Acc: 61.929,95.472,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.711 | Acc: 61.952,95.518,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.717 | Acc: 61.916,95.478,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.716 | Acc: 61.904,95.483,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.710 | Acc: 62.108,95.529,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.708 | Acc: 62.100,95.515,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.708 | Acc: 62.135,95.507,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.711 | Acc: 62.106,95.468,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.712 | Acc: 62.106,95.447,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.710 | Acc: 62.188,95.456,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.750 | Acc: 57.031,74.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.995 | Acc: 52.976,69.196,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.004 | Acc: 52.534,68.445,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.992 | Acc: 52.100,68.199,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.710 | Acc: 59.375,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.686 | Acc: 62.240,95.945,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.698 | Acc: 62.176,95.598,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.702 | Acc: 61.949,95.633,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.719 | Acc: 61.767,95.534,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.726 | Acc: 61.525,95.529,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.720 | Acc: 61.770,95.455,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.724 | Acc: 61.818,95.362,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.722 | Acc: 61.850,95.264,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.722 | Acc: 61.818,95.252,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.721 | Acc: 61.913,95.219,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.719 | Acc: 62.026,95.182,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.715 | Acc: 62.101,95.225,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.717 | Acc: 62.045,95.217,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.715 | Acc: 62.083,95.190,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.716 | Acc: 62.046,95.185,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.714 | Acc: 62.081,95.210,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.712 | Acc: 62.166,95.219,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.711 | Acc: 62.123,95.224,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.711 | Acc: 62.102,95.233,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.772 | Acc: 57.031,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.998 | Acc: 52.827,69.531,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.004 | Acc: 52.344,68.598,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.988 | Acc: 52.024,68.315,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.597 | Acc: 57.812,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.591 | Acc: 63.021,96.317,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.653 | Acc: 62.767,95.941,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.682 | Acc: 62.090,95.389,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.698 | Acc: 62.182,95.351,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.691 | Acc: 62.399,95.436,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.686 | Acc: 62.661,95.467,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.688 | Acc: 62.661,95.468,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.699 | Acc: 62.422,95.385,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.707 | Acc: 62.306,95.438,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.707 | Acc: 62.278,95.484,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.707 | Acc: 62.344,95.443,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.706 | Acc: 62.318,95.484,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.705 | Acc: 62.314,95.453,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.706 | Acc: 62.367,95.426,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.701 | Acc: 62.440,95.440,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.704 | Acc: 62.429,95.424,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.706 | Acc: 62.342,95.395,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.706 | Acc: 62.374,95.349,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.707 | Acc: 62.318,95.364,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.734 | Acc: 55.469,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.983 | Acc: 53.237,69.234,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.990 | Acc: 52.706,68.388,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.978 | Acc: 52.433,68.327,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.610 | Acc: 60.938,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.699 | Acc: 62.500,95.796,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.699 | Acc: 62.671,95.789,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.700 | Acc: 62.705,95.722,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.712 | Acc: 62.568,95.631,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.708 | Acc: 62.477,95.599,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.695 | Acc: 62.681,95.597,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.700 | Acc: 62.589,95.584,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.694 | Acc: 62.714,95.570,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.700 | Acc: 62.448,95.602,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.706 | Acc: 62.313,95.526,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.704 | Acc: 62.344,95.507,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.701 | Acc: 62.370,95.513,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.700 | Acc: 62.455,95.498,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.704 | Acc: 62.389,95.465,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.709 | Acc: 62.256,95.416,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.707 | Acc: 62.259,95.393,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.708 | Acc: 62.292,95.365,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.705 | Acc: 62.355,95.384,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.705 | Acc: 62.397,95.384,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.708 | Acc: 60.156,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.943 | Acc: 53.423,69.308,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.949 | Acc: 52.915,68.617,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.937 | Acc: 52.433,68.468,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.758 | Acc: 62.500,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.682 | Acc: 62.388,95.461,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.704 | Acc: 62.367,95.465,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.702 | Acc: 62.167,95.453,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 62.240,95.428,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.697 | Acc: 62.415,95.452,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.703 | Acc: 62.410,95.351,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.711 | Acc: 62.195,95.362,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.705 | Acc: 62.257,95.434,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.707 | Acc: 62.332,95.334,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.706 | Acc: 62.329,95.344,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.713 | Acc: 62.196,95.344,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.709 | Acc: 62.302,95.338,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.708 | Acc: 62.293,95.333,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.707 | Acc: 62.405,95.376,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.707 | Acc: 62.336,95.445,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.709 | Acc: 62.293,95.454,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.706 | Acc: 62.429,95.459,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.704 | Acc: 62.468,95.449,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.704 | Acc: 62.465,95.438,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.750 | Acc: 55.469,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.956 | Acc: 53.274,69.271,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.967 | Acc: 52.801,68.617,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.954 | Acc: 52.433,68.455,74.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.689 | Acc: 64.062,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.709 | Acc: 61.905,95.647,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.685 | Acc: 62.424,95.370,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.682 | Acc: 62.590,95.402,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 62.780,95.467,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.689 | Acc: 62.407,95.552,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.684 | Acc: 62.636,95.564,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.687 | Acc: 62.611,95.556,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.685 | Acc: 62.704,95.575,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.681 | Acc: 62.750,95.576,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.686 | Acc: 62.636,95.573,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.689 | Acc: 62.518,95.500,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.691 | Acc: 62.490,95.533,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.688 | Acc: 62.602,95.558,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.691 | Acc: 62.494,95.488,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.692 | Acc: 62.440,95.479,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.696 | Acc: 62.344,95.454,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.697 | Acc: 62.321,95.489,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.701 | Acc: 62.232,95.492,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.703 | Acc: 62.279,95.479,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.770 | Acc: 55.469,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.988 | Acc: 52.976,69.903,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.997 | Acc: 52.515,69.017,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.986 | Acc: 52.075,68.648,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.680 | Acc: 61.719,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.642 | Acc: 63.579,95.499,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.658 | Acc: 63.700,95.446,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.669 | Acc: 63.448,95.389,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.663 | Acc: 63.503,95.428,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.673 | Acc: 63.204,95.560,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.692 | Acc: 62.661,95.435,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.688 | Acc: 62.871,95.407,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.690 | Acc: 62.675,95.410,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.690 | Acc: 62.789,95.455,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.691 | Acc: 62.745,95.433,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.697 | Acc: 62.581,95.401,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.704 | Acc: 62.370,95.397,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.702 | Acc: 62.473,95.408,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.705 | Acc: 62.439,95.363,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.704 | Acc: 62.456,95.377,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.705 | Acc: 62.405,95.327,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.704 | Acc: 62.381,95.361,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.703 | Acc: 62.431,95.380,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.702 | Acc: 62.416,95.364,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.776 | Acc: 54.688,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.011 | Acc: 52.493,69.234,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.016 | Acc: 52.153,68.636,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.005 | Acc: 51.819,68.315,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.694 | Acc: 59.375,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.712 | Acc: 61.942,96.057,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.706 | Acc: 61.986,95.998,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.704 | Acc: 61.962,95.863,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.697 | Acc: 62.625,95.756,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.709 | Acc: 62.237,95.761,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.710 | Acc: 62.293,95.732,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.705 | Acc: 62.278,95.734,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.698 | Acc: 62.388,95.773,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.695 | Acc: 62.379,95.787,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.695 | Acc: 62.457,95.732,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.693 | Acc: 62.549,95.715,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.693 | Acc: 62.594,95.646,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.701 | Acc: 62.440,95.606,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.703 | Acc: 62.392,95.602,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.706 | Acc: 62.347,95.608,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.705 | Acc: 62.386,95.592,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.704 | Acc: 62.420,95.571,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.704 | Acc: 62.398,95.522,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.703 | Acc: 62.418,95.516,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.758 | Acc: 54.688,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.963 | Acc: 52.604,69.680,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.971 | Acc: 52.420,68.636,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.961 | Acc: 52.216,68.532,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.579 | Acc: 71.094,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.706 | Acc: 61.458,95.350,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.733 | Acc: 61.776,95.084,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.737 | Acc: 61.591,95.530,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.737 | Acc: 61.699,95.563,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.722 | Acc: 62.020,95.622,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.716 | Acc: 62.190,95.726,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.706 | Acc: 62.389,95.700,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.706 | Acc: 62.451,95.638,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.706 | Acc: 62.401,95.615,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.706 | Acc: 62.449,95.573,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.706 | Acc: 62.373,95.553,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.703 | Acc: 62.416,95.539,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.701 | Acc: 62.362,95.519,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.703 | Acc: 62.328,95.488,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.699 | Acc: 62.399,95.489,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.699 | Acc: 62.459,95.471,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.698 | Acc: 62.452,95.482,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.698 | Acc: 62.431,95.507,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.696 | Acc: 62.455,95.542,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.791 | Acc: 54.688,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.019 | Acc: 52.083,69.568,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.030 | Acc: 51.829,68.712,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.017 | Acc: 51.601,68.455,74.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.760 | Acc: 59.375,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.711 | Acc: 61.793,96.615,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.702 | Acc: 61.623,96.608,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.708 | Acc: 61.770,96.376,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.705 | Acc: 62.191,96.277,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.715 | Acc: 61.943,96.109,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.712 | Acc: 62.087,95.978,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.711 | Acc: 62.123,95.972,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.709 | Acc: 61.947,95.934,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.701 | Acc: 62.206,95.895,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.696 | Acc: 62.348,95.884,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.697 | Acc: 62.260,95.860,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.695 | Acc: 62.293,95.818,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.697 | Acc: 62.287,95.729,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.696 | Acc: 62.378,95.763,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.693 | Acc: 62.443,95.746,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 62.546,95.734,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.693 | Acc: 62.587,95.693,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.699 | Acc: 62.491,95.648,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.699 | Acc: 62.477,95.641,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.756 | Acc: 57.031,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.991 | Acc: 52.827,69.420,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.999 | Acc: 52.344,68.426,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.988 | Acc: 51.844,68.315,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.197 | Acc: 53.125,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.786 | Acc: 60.677,94.866,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.749 | Acc: 61.871,95.255,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.723 | Acc: 61.924,95.338,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.717 | Acc: 62.336,95.438,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.723 | Acc: 62.090,95.398,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.720 | Acc: 62.190,95.306,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.713 | Acc: 62.256,95.373,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.714 | Acc: 62.253,95.342,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.710 | Acc: 62.345,95.360,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.706 | Acc: 62.519,95.386,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.699 | Acc: 62.666,95.447,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.701 | Acc: 62.675,95.429,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.703 | Acc: 62.596,95.453,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.700 | Acc: 62.592,95.477,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.702 | Acc: 62.490,95.481,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.699 | Acc: 62.546,95.497,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.699 | Acc: 62.521,95.510,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.700 | Acc: 62.574,95.466,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.698 | Acc: 62.633,95.442,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.806 | Acc: 55.469,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.048 | Acc: 52.009,69.457,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 51.772,68.540,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.040 | Acc: 51.473,68.468,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.917 | Acc: 58.594,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.697 | Acc: 63.467,94.643,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.706 | Acc: 63.224,95.198,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.697 | Acc: 63.128,95.428,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.700 | Acc: 62.818,95.351,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.705 | Acc: 62.740,95.297,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.701 | Acc: 62.713,95.274,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.709 | Acc: 62.583,95.346,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.703 | Acc: 62.791,95.434,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.706 | Acc: 62.595,95.481,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.708 | Acc: 62.512,95.526,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.709 | Acc: 62.458,95.489,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.704 | Acc: 62.519,95.510,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.698 | Acc: 62.659,95.495,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.698 | Acc: 62.586,95.540,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.699 | Acc: 62.518,95.536,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.694 | Acc: 62.624,95.570,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.697 | Acc: 62.507,95.523,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.698 | Acc: 62.481,95.548,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.697 | Acc: 62.461,95.571,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.736 | Acc: 57.031,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.998 | Acc: 52.604,69.234,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.005 | Acc: 52.363,68.579,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.995 | Acc: 52.024,68.443,74.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.620 | Acc: 66.406,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.808 | Acc: 60.491,95.461,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.763 | Acc: 61.300,95.389,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.757 | Acc: 61.335,95.325,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.752 | Acc: 61.574,95.322,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.745 | Acc: 61.726,95.444,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.740 | Acc: 61.732,95.396,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.737 | Acc: 61.802,95.340,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.733 | Acc: 61.835,95.410,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.724 | Acc: 62.150,95.382,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.721 | Acc: 62.104,95.402,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.717 | Acc: 62.086,95.426,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.715 | Acc: 62.130,95.442,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.716 | Acc: 62.039,95.498,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.710 | Acc: 62.119,95.513,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.708 | Acc: 62.204,95.544,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.706 | Acc: 62.310,95.549,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.704 | Acc: 62.356,95.546,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.703 | Acc: 62.338,95.605,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.699 | Acc: 62.383,95.622,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.751 | Acc: 57.031,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.990 | Acc: 52.530,69.420,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.996 | Acc: 52.515,68.826,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.984 | Acc: 52.152,68.712,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.715 | Acc: 64.062,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.708 | Acc: 62.426,95.685,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.698 | Acc: 62.462,95.751,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.681 | Acc: 63.064,95.863,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 63.030,95.882,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.683 | Acc: 62.864,95.939,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.691 | Acc: 62.571,95.868,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.688 | Acc: 62.555,95.961,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.682 | Acc: 62.704,95.992,99.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.676 | Acc: 62.914,95.969,99.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.678 | Acc: 62.916,95.942,99.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.678 | Acc: 62.967,95.906,99.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.678 | Acc: 62.954,95.906,99.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.681 | Acc: 62.892,95.851,99.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.680 | Acc: 62.864,95.846,99.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.681 | Acc: 62.897,95.821,99.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.683 | Acc: 62.787,95.819,99.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.687 | Acc: 62.672,95.768,99.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.689 | Acc: 62.664,95.747,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.691 | Acc: 62.521,95.727,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.797 | Acc: 56.250,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.035 | Acc: 51.711,69.717,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.045 | Acc: 51.620,68.788,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.034 | Acc: 51.409,68.571,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.442 | Acc: 66.406,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.650 | Acc: 63.244,95.908,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.654 | Acc: 63.072,95.903,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.663 | Acc: 62.807,95.953,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.676 | Acc: 62.847,95.988,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 62.778,95.993,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.670 | Acc: 62.881,95.997,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.672 | Acc: 62.988,95.939,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.678 | Acc: 62.859,95.880,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.672 | Acc: 62.996,95.882,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.675 | Acc: 62.935,95.868,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.677 | Acc: 62.988,95.822,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.676 | Acc: 63.012,95.834,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.677 | Acc: 62.985,95.830,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.680 | Acc: 62.814,95.838,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.684 | Acc: 62.741,95.806,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.685 | Acc: 62.695,95.768,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.685 | Acc: 62.688,95.757,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 62.773,95.735,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.681 | Acc: 62.721,95.757,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.767 | Acc: 57.812,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.993 | Acc: 52.827,69.643,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.999 | Acc: 52.515,68.864,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.987 | Acc: 52.139,68.712,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.494 | Acc: 71.875,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.676 | Acc: 62.798,95.796,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.689 | Acc: 62.443,95.465,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.704 | Acc: 62.244,95.722,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.676 | Acc: 62.809,95.939,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.684 | Acc: 62.469,95.908,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.679 | Acc: 62.390,95.919,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.676 | Acc: 62.561,95.905,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.680 | Acc: 62.481,95.875,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.682 | Acc: 62.314,95.882,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.675 | Acc: 62.617,95.868,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.676 | Acc: 62.673,95.832,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.677 | Acc: 62.678,95.870,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.675 | Acc: 62.674,95.875,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.676 | Acc: 62.764,95.869,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.677 | Acc: 62.767,95.873,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 62.639,95.865,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 62.715,95.872,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.680 | Acc: 62.742,95.808,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.679 | Acc: 62.820,95.794,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.778 | Acc: 56.250,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.995 | Acc: 52.455,69.494,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.999 | Acc: 52.363,68.655,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.988 | Acc: 51.972,68.545,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.616 | Acc: 56.250,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.734 | Acc: 60.603,95.871,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.706 | Acc: 61.509,95.865,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.695 | Acc: 61.988,95.786,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 61.593,95.737,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.681 | Acc: 62.036,95.800,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.685 | Acc: 62.029,95.874,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.683 | Acc: 62.256,95.822,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.692 | Acc: 62.262,95.715,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.695 | Acc: 62.250,95.723,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.690 | Acc: 62.341,95.701,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.690 | Acc: 62.380,95.737,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.691 | Acc: 62.406,95.708,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.690 | Acc: 62.413,95.756,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.687 | Acc: 62.419,95.810,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.686 | Acc: 62.497,95.808,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.691 | Acc: 62.415,95.741,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.693 | Acc: 62.319,95.736,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.695 | Acc: 62.281,95.698,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.693 | Acc: 62.385,95.696,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.794 | Acc: 56.250,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.998 | Acc: 52.418,69.457,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.004 | Acc: 52.287,68.807,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.990 | Acc: 52.075,68.699,74.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.426 | Acc: 72.656,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.663 | Acc: 62.500,96.243,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.646 | Acc: 62.976,96.189,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.655 | Acc: 63.243,96.158,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.674 | Acc: 62.924,96.036,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.671 | Acc: 63.034,96.094,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.675 | Acc: 63.062,96.036,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.687 | Acc: 62.794,95.983,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.675 | Acc: 62.995,96.045,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 62.988,96.003,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.682 | Acc: 62.768,96.000,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.688 | Acc: 62.694,95.974,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.686 | Acc: 62.737,95.967,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.686 | Acc: 62.745,95.965,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.683 | Acc: 62.828,95.935,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.685 | Acc: 62.791,95.899,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.683 | Acc: 62.853,95.904,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.681 | Acc: 62.906,95.869,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.681 | Acc: 62.885,95.804,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.682 | Acc: 62.808,95.809,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.737 | Acc: 56.250,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.960 | Acc: 53.162,69.271,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.968 | Acc: 52.744,68.502,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.957 | Acc: 52.421,68.404,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.752 | Acc: 59.375,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.654 | Acc: 65.030,96.019,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.690 | Acc: 63.396,95.827,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.713 | Acc: 62.666,95.722,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.704 | Acc: 62.789,95.689,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.696 | Acc: 62.825,95.645,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.699 | Acc: 62.700,95.545,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.704 | Acc: 62.489,95.518,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.702 | Acc: 62.563,95.536,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.706 | Acc: 62.569,95.563,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.703 | Acc: 62.527,95.550,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.701 | Acc: 62.571,95.645,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.699 | Acc: 62.568,95.653,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.696 | Acc: 62.572,95.666,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.691 | Acc: 62.742,95.718,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.692 | Acc: 62.679,95.699,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.696 | Acc: 62.575,95.651,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.695 | Acc: 62.582,95.688,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.692 | Acc: 62.660,95.683,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.695 | Acc: 62.576,95.677,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.768 | Acc: 57.031,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.992 | Acc: 52.939,69.531,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.999 | Acc: 52.477,68.712,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.985 | Acc: 52.177,68.596,74.449,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.154 | Acc: 47.656,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.741 | Acc: 60.528,95.461,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.722 | Acc: 61.147,95.293,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.714 | Acc: 61.386,95.466,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.703 | Acc: 61.622,95.486,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.691 | Acc: 62.129,95.591,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.686 | Acc: 62.145,95.597,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.692 | Acc: 62.096,95.523,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.692 | Acc: 62.160,95.604,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.689 | Acc: 62.301,95.641,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.690 | Acc: 62.189,95.686,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.686 | Acc: 62.344,95.684,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.691 | Acc: 62.234,95.669,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.691 | Acc: 62.284,95.669,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.690 | Acc: 62.347,95.591,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.693 | Acc: 62.248,95.637,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.691 | Acc: 62.308,95.653,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.690 | Acc: 62.319,95.672,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.689 | Acc: 62.398,95.674,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.692 | Acc: 62.334,95.641,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.770 | Acc: 57.031,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.981 | Acc: 53.125,69.234,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.989 | Acc: 52.706,68.674,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.976 | Acc: 52.433,68.481,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.925 | Acc: 54.688,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.696 | Acc: 62.686,95.387,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.713 | Acc: 61.414,95.675,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.710 | Acc: 61.744,95.761,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.710 | Acc: 61.690,95.775,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.695 | Acc: 62.252,95.962,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.695 | Acc: 62.248,95.887,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.687 | Acc: 62.317,95.961,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.686 | Acc: 62.515,95.895,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.689 | Acc: 62.409,95.956,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.693 | Acc: 62.348,95.876,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.685 | Acc: 62.673,95.846,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.687 | Acc: 62.685,95.828,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.681 | Acc: 62.757,95.869,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.686 | Acc: 62.636,95.871,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.690 | Acc: 62.591,95.847,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 62.651,95.802,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.688 | Acc: 62.725,95.784,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.689 | Acc: 62.669,95.812,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.685 | Acc: 62.785,95.813,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.787 | Acc: 57.031,75.000,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.036 | Acc: 52.121,69.196,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.040 | Acc: 51.677,68.502,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.025 | Acc: 51.370,68.430,74.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.695 | Acc: 60.938,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.689 | Acc: 62.872,95.647,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.713 | Acc: 62.538,95.617,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.705 | Acc: 62.551,95.761,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.705 | Acc: 62.249,95.727,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.697 | Acc: 62.198,95.815,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.691 | Acc: 62.209,95.926,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.684 | Acc: 62.295,96.011,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.686 | Acc: 62.388,96.055,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.682 | Acc: 62.509,95.977,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.683 | Acc: 62.527,96.012,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.683 | Acc: 62.511,95.928,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.681 | Acc: 62.604,95.902,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.683 | Acc: 62.599,95.848,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.682 | Acc: 62.570,95.821,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.684 | Acc: 62.560,95.824,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.685 | Acc: 62.534,95.828,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.688 | Acc: 62.507,95.819,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.689 | Acc: 62.465,95.791,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.691 | Acc: 62.395,95.784,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.752 | Acc: 57.031,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.972 | Acc: 52.976,69.271,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.978 | Acc: 52.649,68.617,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.966 | Acc: 52.241,68.443,74.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.740 | Acc: 60.938,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.670 | Acc: 62.500,95.908,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.676 | Acc: 62.957,95.351,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.678 | Acc: 62.615,95.479,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.690 | Acc: 62.365,95.428,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.686 | Acc: 62.639,95.545,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.680 | Acc: 62.758,95.590,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.672 | Acc: 62.971,95.711,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.674 | Acc: 63.039,95.589,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 63.009,95.589,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.670 | Acc: 63.110,95.693,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.672 | Acc: 63.150,95.765,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.678 | Acc: 63.061,95.705,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.676 | Acc: 63.060,95.741,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.675 | Acc: 63.012,95.752,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.679 | Acc: 62.892,95.699,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.684 | Acc: 62.790,95.661,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.683 | Acc: 62.807,95.686,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 62.807,95.722,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.680 | Acc: 62.875,95.708,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.798 | Acc: 57.031,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.029 | Acc: 52.269,69.048,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.034 | Acc: 51.867,68.426,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.020 | Acc: 51.550,68.430,74.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.478 | Acc: 66.406,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.684 | Acc: 62.463,95.833,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.696 | Acc: 62.443,96.208,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.705 | Acc: 62.257,96.145,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.701 | Acc: 62.394,96.065,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.701 | Acc: 62.283,96.001,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.708 | Acc: 62.119,95.835,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.705 | Acc: 62.112,95.872,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.699 | Acc: 62.316,95.866,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.695 | Acc: 62.314,95.878,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.696 | Acc: 62.317,95.849,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.695 | Acc: 62.362,95.846,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.691 | Acc: 62.348,95.909,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.690 | Acc: 62.356,95.890,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.688 | Acc: 62.436,95.882,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.685 | Acc: 62.497,95.886,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.683 | Acc: 62.515,95.892,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.685 | Acc: 62.459,95.865,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.681 | Acc: 62.604,95.869,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.682 | Acc: 62.562,95.874,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.766 | Acc: 55.469,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.027 | Acc: 52.121,69.308,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.031 | Acc: 52.020,68.579,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.018 | Acc: 51.793,68.391,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.957 | Acc: 60.938,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.679 | Acc: 62.574,96.280,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.690 | Acc: 62.424,96.189,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.669 | Acc: 62.999,96.299,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.663 | Acc: 63.117,96.316,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.667 | Acc: 63.142,96.349,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.675 | Acc: 63.081,96.197,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.683 | Acc: 62.838,96.182,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.681 | Acc: 62.811,96.210,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.683 | Acc: 62.768,96.158,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.686 | Acc: 62.628,96.067,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.681 | Acc: 62.751,96.069,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.678 | Acc: 62.870,96.052,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.682 | Acc: 62.760,96.061,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.681 | Acc: 62.811,96.052,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.680 | Acc: 62.866,96.026,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.683 | Acc: 62.707,96.006,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.683 | Acc: 62.773,95.984,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 62.773,95.981,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.684 | Acc: 62.697,96.001,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.775 | Acc: 55.469,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.984 | Acc: 52.790,69.271,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.992 | Acc: 52.515,68.559,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.978 | Acc: 52.113,68.379,74.475,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.537 | Acc: 64.844,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.675 | Acc: 63.021,95.461,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.695 | Acc: 62.443,95.217,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.680 | Acc: 62.718,95.594,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.684 | Acc: 62.674,95.611,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 62.941,95.761,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.677 | Acc: 62.926,95.745,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.673 | Acc: 63.043,95.844,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.677 | Acc: 62.946,95.832,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.675 | Acc: 62.996,95.744,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.672 | Acc: 62.986,95.748,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.678 | Acc: 62.829,95.701,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.680 | Acc: 62.763,95.747,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.682 | Acc: 62.775,95.741,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.679 | Acc: 62.828,95.741,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.681 | Acc: 62.814,95.697,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 62.885,95.685,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.682 | Acc: 62.855,95.642,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.686 | Acc: 62.892,95.596,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.686 | Acc: 62.881,95.606,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.774 | Acc: 57.031,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.036 | Acc: 51.637,68.973,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.044 | Acc: 51.562,68.293,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.031 | Acc: 51.434,68.276,74.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.384 | Acc: 65.625,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.708 | Acc: 61.830,95.424,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.720 | Acc: 61.357,95.484,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.710 | Acc: 61.719,95.569,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.711 | Acc: 61.892,95.621,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.705 | Acc: 62.090,95.715,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.705 | Acc: 62.003,95.726,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.697 | Acc: 62.245,95.795,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.701 | Acc: 62.214,95.749,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.694 | Acc: 62.409,95.744,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.687 | Acc: 62.655,95.798,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.690 | Acc: 62.528,95.712,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.686 | Acc: 62.675,95.799,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.685 | Acc: 62.727,95.776,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.684 | Acc: 62.720,95.782,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.679 | Acc: 62.804,95.782,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 62.724,95.797,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 62.743,95.800,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.679 | Acc: 62.779,95.789,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.683 | Acc: 62.758,95.782,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.727 | Acc: 57.031,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.953 | Acc: 53.348,69.531,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.955 | Acc: 53.011,68.807,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.942 | Acc: 52.613,68.648,74.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.699 | Acc: 63.281,93.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.638 | Acc: 64.100,96.243,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.661 | Acc: 63.129,95.979,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.684 | Acc: 62.410,95.607,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.679 | Acc: 62.568,95.573,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.678 | Acc: 62.686,95.722,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.677 | Acc: 62.784,95.835,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.672 | Acc: 62.977,95.894,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.673 | Acc: 62.767,95.900,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.672 | Acc: 62.828,95.960,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.671 | Acc: 62.799,95.962,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.674 | Acc: 62.691,95.896,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.672 | Acc: 62.811,95.883,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.673 | Acc: 62.841,95.884,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.673 | Acc: 62.848,95.896,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.676 | Acc: 62.796,95.876,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.677 | Acc: 62.860,95.860,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.680 | Acc: 62.860,95.842,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.678 | Acc: 62.842,95.867,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.680 | Acc: 62.822,95.878,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.779 | Acc: 58.594,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.007 | Acc: 52.679,69.420,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.013 | Acc: 52.344,68.750,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.003 | Acc: 51.985,68.571,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.471 | Acc: 65.625,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.624 | Acc: 63.802,96.094,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.629 | Acc: 63.681,96.037,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.655 | Acc: 63.089,95.991,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.662 | Acc: 62.953,95.882,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.672 | Acc: 62.647,95.877,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.669 | Acc: 62.791,95.823,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.674 | Acc: 62.661,95.817,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.673 | Acc: 62.752,95.837,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.670 | Acc: 62.876,95.809,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.672 | Acc: 62.718,95.857,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.669 | Acc: 62.769,95.896,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.673 | Acc: 62.724,95.870,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.670 | Acc: 62.760,95.917,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.666 | Acc: 62.936,95.907,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.668 | Acc: 62.957,95.933,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.668 | Acc: 62.955,95.943,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.673 | Acc: 62.894,95.888,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.675 | Acc: 62.870,95.871,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.678 | Acc: 62.828,95.852,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.786 | Acc: 56.250,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.014 | Acc: 52.307,69.196,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.020 | Acc: 52.134,68.483,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.007 | Acc: 51.908,68.443,74.667,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.598 | Acc: 64.062,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.657 | Acc: 63.095,96.205,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.675 | Acc: 62.786,96.075,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.668 | Acc: 62.538,96.119,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.683 | Acc: 62.346,96.065,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.687 | Acc: 62.299,96.032,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.687 | Acc: 62.364,95.984,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.688 | Acc: 62.389,95.977,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.694 | Acc: 62.325,95.900,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.696 | Acc: 62.267,95.869,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.696 | Acc: 62.232,95.822,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.694 | Acc: 62.320,95.846,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.692 | Acc: 62.348,95.890,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.692 | Acc: 62.437,95.902,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.688 | Acc: 62.636,95.896,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.686 | Acc: 62.726,95.863,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.686 | Acc: 62.719,95.884,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.684 | Acc: 62.741,95.899,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 62.758,95.947,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.686 | Acc: 62.603,95.956,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.726 | Acc: 57.031,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.954 | Acc: 53.385,69.382,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.962 | Acc: 52.915,68.540,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.948 | Acc: 52.485,68.545,74.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.723 | Acc: 64.062,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.675 | Acc: 63.876,95.350,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.680 | Acc: 63.681,95.560,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.667 | Acc: 63.601,95.838,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.665 | Acc: 63.358,95.949,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.671 | Acc: 63.049,95.955,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.667 | Acc: 63.339,95.945,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.665 | Acc: 63.320,95.950,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.663 | Acc: 63.335,95.963,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.662 | Acc: 63.264,95.891,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.664 | Acc: 63.192,95.853,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.663 | Acc: 63.150,95.871,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.662 | Acc: 63.226,95.851,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.669 | Acc: 63.144,95.812,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.673 | Acc: 62.962,95.782,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.677 | Acc: 62.811,95.790,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.679 | Acc: 62.809,95.785,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.678 | Acc: 62.860,95.771,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.676 | Acc: 62.879,95.760,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.675 | Acc: 62.849,95.782,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.764 | Acc: 56.250,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.997 | Acc: 52.567,69.568,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.003 | Acc: 52.496,68.807,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.991 | Acc: 52.164,68.609,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.878 | Acc: 60.156,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.702 | Acc: 61.756,95.647,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.658 | Acc: 62.443,95.941,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.660 | Acc: 62.756,95.902,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.659 | Acc: 62.741,95.747,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.669 | Acc: 62.647,95.599,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.666 | Acc: 62.765,95.674,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.665 | Acc: 62.888,95.723,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.666 | Acc: 62.971,95.759,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.666 | Acc: 63.027,95.852,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.666 | Acc: 63.091,95.876,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.663 | Acc: 63.182,95.899,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.673 | Acc: 62.873,95.851,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.680 | Acc: 62.692,95.842,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.684 | Acc: 62.592,95.802,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.684 | Acc: 62.593,95.816,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.682 | Acc: 62.702,95.785,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.684 | Acc: 62.654,95.775,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 62.716,95.763,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.683 | Acc: 62.678,95.755,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.804 | Acc: 55.469,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.035 | Acc: 51.935,68.824,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.043 | Acc: 51.791,68.159,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.029 | Acc: 51.434,68.148,74.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.049 | Acc: 53.125,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.631 | Acc: 63.914,95.833,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.692 | Acc: 62.519,96.075,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.697 | Acc: 62.346,95.710,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.700 | Acc: 62.375,95.611,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.675 | Acc: 63.026,95.630,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.680 | Acc: 62.874,95.622,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.681 | Acc: 62.738,95.617,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.683 | Acc: 62.728,95.579,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.683 | Acc: 62.711,95.619,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.676 | Acc: 62.904,95.647,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.682 | Acc: 62.832,95.602,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.686 | Acc: 62.785,95.627,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.689 | Acc: 62.683,95.618,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.685 | Acc: 62.834,95.649,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.683 | Acc: 62.835,95.676,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.686 | Acc: 62.729,95.673,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.683 | Acc: 62.800,95.713,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.687 | Acc: 62.682,95.719,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.687 | Acc: 62.668,95.727,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.798 | Acc: 56.250,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.024 | Acc: 52.195,69.494,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.031 | Acc: 51.982,68.540,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.020 | Acc: 51.831,68.417,74.654,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.549 | Acc: 71.875,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.696 | Acc: 63.430,95.573,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.700 | Acc: 62.652,95.503,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.684 | Acc: 62.910,95.991,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.675 | Acc: 62.992,96.026,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.683 | Acc: 62.740,96.078,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.682 | Acc: 62.571,96.139,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.683 | Acc: 62.722,96.016,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.679 | Acc: 62.786,96.036,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.674 | Acc: 62.953,95.999,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.675 | Acc: 62.904,95.958,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.672 | Acc: 62.952,95.991,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.670 | Acc: 62.989,95.980,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.677 | Acc: 62.817,95.944,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.679 | Acc: 62.806,95.946,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.680 | Acc: 62.728,95.951,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.679 | Acc: 62.797,95.960,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.681 | Acc: 62.786,95.938,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.685 | Acc: 62.712,95.888,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.684 | Acc: 62.711,95.893,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.766 | Acc: 56.250,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.014 | Acc: 52.530,69.085,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.016 | Acc: 52.268,68.369,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.001 | Acc: 51.895,68.340,74.616,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.683 | Acc: 62.500,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.678 | Acc: 61.756,96.503,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.680 | Acc: 62.119,96.208,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.690 | Acc: 61.386,96.017,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.680 | Acc: 62.056,96.046,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.692 | Acc: 61.920,96.016,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.692 | Acc: 62.080,96.010,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.687 | Acc: 62.256,95.950,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.683 | Acc: 62.437,95.938,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.679 | Acc: 62.578,95.986,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.681 | Acc: 62.586,95.927,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.683 | Acc: 62.567,95.843,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.682 | Acc: 62.588,95.851,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.681 | Acc: 62.557,95.803,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 62.653,95.793,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.680 | Acc: 62.552,95.821,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.678 | Acc: 62.619,95.770,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.678 | Acc: 62.599,95.741,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.678 | Acc: 62.643,95.767,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.677 | Acc: 62.691,95.741,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.801 | Acc: 55.469,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.023 | Acc: 51.935,69.345,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.029 | Acc: 51.963,68.521,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.018 | Acc: 51.678,68.494,74.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.757 | Acc: 63.281,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.722 | Acc: 61.942,95.871,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.723 | Acc: 62.043,95.770,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.697 | Acc: 62.193,95.710,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.698 | Acc: 62.027,95.872,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.697 | Acc: 61.781,95.877,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.693 | Acc: 61.887,95.971,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.691 | Acc: 61.868,95.961,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.698 | Acc: 61.670,95.875,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.700 | Acc: 61.701,95.878,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.701 | Acc: 61.719,95.841,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.699 | Acc: 61.842,95.783,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.699 | Acc: 61.910,95.760,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.697 | Acc: 61.961,95.809,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.697 | Acc: 62.050,95.771,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.696 | Acc: 62.087,95.759,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.692 | Acc: 62.201,95.765,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.693 | Acc: 62.216,95.713,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.693 | Acc: 62.268,95.698,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.691 | Acc: 62.322,95.698,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.819 | Acc: 57.031,74.219,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.048 | Acc: 51.600,69.271,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.050 | Acc: 51.410,68.426,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.036 | Acc: 51.191,68.353,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.892 | Acc: 54.688,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.704 | Acc: 61.719,95.796,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.675 | Acc: 63.167,95.694,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.667 | Acc: 63.358,95.799,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.681 | Acc: 62.741,95.727,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.699 | Acc: 62.423,95.661,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.693 | Acc: 62.474,95.655,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.685 | Acc: 62.705,95.828,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.682 | Acc: 62.718,95.895,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.681 | Acc: 62.755,95.938,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.680 | Acc: 62.749,95.977,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.680 | Acc: 62.709,95.956,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.680 | Acc: 62.714,95.961,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.678 | Acc: 62.811,95.938,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 62.836,95.946,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.679 | Acc: 62.801,95.933,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.678 | Acc: 62.797,95.940,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.678 | Acc: 62.807,95.933,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.679 | Acc: 62.721,95.908,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.678 | Acc: 62.797,95.880,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.783 | Acc: 57.812,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.035 | Acc: 51.897,69.234,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.040 | Acc: 51.677,68.521,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.028 | Acc: 51.396,68.455,74.475,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.763 | Acc: 57.031,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.675 | Acc: 62.909,95.982,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.688 | Acc: 62.557,95.579,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.696 | Acc: 62.538,95.889,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 62.539,95.775,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.700 | Acc: 62.616,95.568,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.700 | Acc: 62.623,95.661,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.705 | Acc: 62.517,95.628,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.699 | Acc: 62.869,95.667,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.692 | Acc: 63.009,95.632,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.692 | Acc: 62.900,95.678,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.694 | Acc: 62.790,95.673,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.695 | Acc: 62.656,95.705,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.689 | Acc: 62.742,95.738,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.689 | Acc: 62.739,95.705,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.691 | Acc: 62.599,95.720,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.685 | Acc: 62.717,95.787,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.684 | Acc: 62.626,95.821,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 62.651,95.784,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.682 | Acc: 62.625,95.803,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.759 | Acc: 55.469,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.001 | Acc: 52.381,69.420,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.015 | Acc: 52.229,68.655,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.004 | Acc: 51.947,68.481,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.747 | Acc: 55.469,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.732 | Acc: 61.124,95.685,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.705 | Acc: 62.195,95.598,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.685 | Acc: 62.718,95.914,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.693 | Acc: 62.596,95.853,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.682 | Acc: 62.639,95.916,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.677 | Acc: 62.545,96.049,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.684 | Acc: 62.212,96.022,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.684 | Acc: 62.325,96.060,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.678 | Acc: 62.547,96.033,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.679 | Acc: 62.589,95.989,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.680 | Acc: 62.500,95.966,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.677 | Acc: 62.545,95.948,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.678 | Acc: 62.587,95.902,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.681 | Acc: 62.600,95.927,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.683 | Acc: 62.510,95.891,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.680 | Acc: 62.656,95.926,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.680 | Acc: 62.658,95.947,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.680 | Acc: 62.630,95.940,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.684 | Acc: 62.592,95.868,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.774 | Acc: 57.812,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.002 | Acc: 52.455,69.308,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.006 | Acc: 52.210,68.521,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.992 | Acc: 51.960,68.404,74.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.703 | Acc: 60.938,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.637 | Acc: 62.537,96.243,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.663 | Acc: 62.767,95.998,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.680 | Acc: 62.641,95.863,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.685 | Acc: 62.336,95.631,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.668 | Acc: 62.856,95.684,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.672 | Acc: 62.816,95.700,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.681 | Acc: 62.489,95.673,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.678 | Acc: 62.641,95.681,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.671 | Acc: 62.837,95.723,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.674 | Acc: 62.729,95.674,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.673 | Acc: 62.846,95.751,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.675 | Acc: 62.727,95.750,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.678 | Acc: 62.695,95.735,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 62.697,95.743,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.677 | Acc: 62.726,95.782,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 62.588,95.729,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 62.670,95.766,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.679 | Acc: 62.725,95.793,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.680 | Acc: 62.760,95.766,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.726 | Acc: 57.812,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.968 | Acc: 53.311,69.382,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.976 | Acc: 52.896,68.598,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.962 | Acc: 52.446,68.494,74.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.667 | Acc: 59.375,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.688 | Acc: 61.979,95.722,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.672 | Acc: 63.053,95.579,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.678 | Acc: 62.974,95.633,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.687 | Acc: 62.731,95.679,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.685 | Acc: 62.655,95.769,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.686 | Acc: 62.455,95.758,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.686 | Acc: 62.533,95.695,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.685 | Acc: 62.694,95.676,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.682 | Acc: 62.711,95.792,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.685 | Acc: 62.760,95.829,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.683 | Acc: 62.875,95.818,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.682 | Acc: 62.925,95.799,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.681 | Acc: 62.901,95.833,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.685 | Acc: 62.817,95.816,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.683 | Acc: 62.783,95.795,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 62.814,95.833,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 62.869,95.833,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.678 | Acc: 62.957,95.791,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.678 | Acc: 62.955,95.762,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.832 | Acc: 54.688,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.059 | Acc: 51.153,69.085,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.063 | Acc: 51.315,68.331,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.047 | Acc: 51.204,68.379,74.424,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.742 | Acc: 63.281,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.701 | Acc: 61.719,96.019,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.692 | Acc: 62.176,95.827,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.695 | Acc: 62.039,95.876,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.680 | Acc: 62.394,96.103,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.686 | Acc: 62.531,95.947,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.687 | Acc: 62.442,95.952,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.685 | Acc: 62.472,95.950,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.683 | Acc: 62.665,95.953,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.687 | Acc: 62.703,95.925,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.686 | Acc: 62.760,95.872,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.684 | Acc: 62.846,95.797,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.685 | Acc: 62.669,95.825,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.686 | Acc: 62.608,95.779,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.682 | Acc: 62.714,95.841,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.683 | Acc: 62.689,95.847,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 62.741,95.863,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.678 | Acc: 62.814,95.865,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.676 | Acc: 62.816,95.895,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.675 | Acc: 62.883,95.885,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.759 | Acc: 57.031,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.008 | Acc: 52.530,69.122,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.014 | Acc: 52.306,68.502,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.001 | Acc: 52.011,68.379,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.751 | Acc: 60.156,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.665 | Acc: 63.876,95.982,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.669 | Acc: 63.377,96.018,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.669 | Acc: 63.140,96.247,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.674 | Acc: 62.751,96.152,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.668 | Acc: 62.802,96.187,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.679 | Acc: 62.513,96.145,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.676 | Acc: 62.627,96.121,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.689 | Acc: 62.432,96.108,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.684 | Acc: 62.655,95.982,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.688 | Acc: 62.652,95.965,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.694 | Acc: 62.521,95.928,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.699 | Acc: 62.396,95.867,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.693 | Acc: 62.524,95.887,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.690 | Acc: 62.497,95.869,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.688 | Acc: 62.536,95.871,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.684 | Acc: 62.661,95.889,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.682 | Acc: 62.704,95.901,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 62.738,95.877,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.682 | Acc: 62.758,95.874,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.799 | Acc: 56.250,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.028 | Acc: 52.121,69.345,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.031 | Acc: 51.925,68.636,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.015 | Acc: 51.652,68.481,74.513,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.767 | Acc: 59.375,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.735 | Acc: 60.119,95.982,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.700 | Acc: 61.319,95.636,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.703 | Acc: 61.808,95.543,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.694 | Acc: 62.230,95.563,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.687 | Acc: 62.407,95.653,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.681 | Acc: 62.390,95.803,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.682 | Acc: 62.483,95.844,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.683 | Acc: 62.500,95.837,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.683 | Acc: 62.621,95.891,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.681 | Acc: 62.620,95.899,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.681 | Acc: 62.578,95.868,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.680 | Acc: 62.600,95.857,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.680 | Acc: 62.683,95.842,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.677 | Acc: 62.728,95.802,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.680 | Acc: 62.648,95.795,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.680 | Acc: 62.646,95.836,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.677 | Acc: 62.674,95.837,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.676 | Acc: 62.734,95.862,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.677 | Acc: 62.726,95.837,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.739 | Acc: 57.031,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.965 | Acc: 53.125,69.271,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.973 | Acc: 52.782,68.579,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.961 | Acc: 52.549,68.430,74.629,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.541 | Acc: 63.281,96.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.680 | Acc: 63.095,95.275,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.680 | Acc: 62.919,95.560,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.662 | Acc: 63.512,95.761,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.669 | Acc: 63.127,95.727,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.676 | Acc: 62.701,95.784,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.684 | Acc: 62.539,95.784,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.694 | Acc: 62.323,95.867,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.690 | Acc: 62.403,95.861,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.689 | Acc: 62.362,95.912,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.686 | Acc: 62.422,95.965,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.686 | Acc: 62.461,95.903,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.687 | Acc: 62.403,95.838,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.682 | Acc: 62.500,95.884,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.683 | Acc: 62.522,95.880,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.679 | Acc: 62.682,95.873,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.682 | Acc: 62.707,95.860,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.682 | Acc: 62.713,95.855,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 62.706,95.849,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.684 | Acc: 62.644,95.858,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.780 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.981 | Acc: 52.790,69.457,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.983 | Acc: 52.477,68.750,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.968 | Acc: 52.203,68.673,74.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.893 | Acc: 55.469,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.700 | Acc: 62.202,95.424,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 62.786,95.579,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.671 | Acc: 62.961,95.684,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.668 | Acc: 62.992,95.640,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.683 | Acc: 62.925,95.738,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.679 | Acc: 63.075,95.668,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.672 | Acc: 63.215,95.806,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.676 | Acc: 63.039,95.793,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.680 | Acc: 62.880,95.830,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.681 | Acc: 62.842,95.767,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.678 | Acc: 62.967,95.822,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.677 | Acc: 62.905,95.841,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.680 | Acc: 62.763,95.863,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.682 | Acc: 62.642,95.844,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.679 | Acc: 62.741,95.837,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.679 | Acc: 62.734,95.809,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.683 | Acc: 62.628,95.787,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 62.671,95.784,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.682 | Acc: 62.646,95.774,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.763 | Acc: 56.250,75.000,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.005 | Acc: 52.418,69.568,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.013 | Acc: 52.268,68.769,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.002 | Acc: 51.883,68.584,74.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.742 | Acc: 65.625,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.739 | Acc: 61.421,95.312,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.718 | Acc: 61.604,95.541,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.708 | Acc: 61.732,95.492,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.700 | Acc: 62.114,95.727,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.697 | Acc: 62.036,95.831,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.697 | Acc: 62.126,95.790,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.706 | Acc: 61.824,95.783,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.695 | Acc: 62.088,95.812,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.699 | Acc: 62.181,95.787,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.700 | Acc: 62.142,95.767,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.698 | Acc: 62.256,95.761,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.695 | Acc: 62.293,95.828,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.689 | Acc: 62.509,95.806,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.691 | Acc: 62.542,95.766,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.690 | Acc: 62.599,95.798,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.688 | Acc: 62.600,95.816,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.689 | Acc: 62.564,95.817,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.690 | Acc: 62.550,95.802,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.690 | Acc: 62.562,95.782,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.785 | Acc: 57.812,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.028 | Acc: 51.972,69.420,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.037 | Acc: 51.791,68.579,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.023 | Acc: 51.639,68.545,74.411,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.724 | Acc: 63.281,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.699 | Acc: 62.091,95.238,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.685 | Acc: 62.290,95.579,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.686 | Acc: 62.756,95.710,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.697 | Acc: 62.133,95.669,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.681 | Acc: 62.515,95.591,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.690 | Acc: 62.636,95.564,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.687 | Acc: 62.694,95.490,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.694 | Acc: 62.602,95.458,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.689 | Acc: 62.746,95.464,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.690 | Acc: 62.706,95.499,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.693 | Acc: 62.648,95.500,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.689 | Acc: 62.711,95.488,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.689 | Acc: 62.722,95.504,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.689 | Acc: 62.628,95.532,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.689 | Acc: 62.643,95.575,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.687 | Acc: 62.687,95.592,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.685 | Acc: 62.686,95.594,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 62.693,95.631,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.681 | Acc: 62.670,95.673,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.783 | Acc: 57.812,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.013 | Acc: 52.641,69.048,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.017 | Acc: 52.229,68.274,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.005 | Acc: 51.934,68.238,74.462,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.637 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.710 | Acc: 61.644,95.945,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 62.157,96.075,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.691 | Acc: 62.269,95.902,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.685 | Acc: 62.529,95.978,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.688 | Acc: 62.485,95.800,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.691 | Acc: 62.197,95.842,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.690 | Acc: 62.301,95.911,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.695 | Acc: 62.126,95.885,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.689 | Acc: 62.371,95.874,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.686 | Acc: 62.481,95.833,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.687 | Acc: 62.574,95.836,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.688 | Acc: 62.604,95.867,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.687 | Acc: 62.590,95.848,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.689 | Acc: 62.519,95.819,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.689 | Acc: 62.583,95.808,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.691 | Acc: 62.515,95.748,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.689 | Acc: 62.537,95.764,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.689 | Acc: 62.539,95.765,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.688 | Acc: 62.504,95.749,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.759 | Acc: 56.250,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.979 | Acc: 52.641,69.457,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.988 | Acc: 52.363,68.712,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.976 | Acc: 52.100,68.648,74.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 1.818 | Acc: 61.719,92.969,100.000,% | Adaptive Acc: 92.969% | clf_exit: 0.477 0.406 0.117
Batch: 20 | Loss: 1.704 | Acc: 62.165,95.647,100.000,% | Adaptive Acc: 94.382% | clf_exit: 0.430 0.477 0.093
Batch: 40 | Loss: 1.677 | Acc: 62.671,95.808,100.000,% | Adaptive Acc: 94.588% | clf_exit: 0.432 0.479 0.089
Batch: 60 | Loss: 1.668 | Acc: 62.923,95.799,100.000,% | Adaptive Acc: 94.326% | clf_exit: 0.436 0.476 0.088
Batch: 80 | Loss: 1.673 | Acc: 62.895,95.804,100.000,% | Adaptive Acc: 94.387% | clf_exit: 0.436 0.475 0.089
Batch: 100 | Loss: 1.669 | Acc: 63.088,95.823,100.000,% | Adaptive Acc: 94.446% | clf_exit: 0.435 0.477 0.088
Batch: 120 | Loss: 1.662 | Acc: 63.062,95.907,99.987,% | Adaptive Acc: 94.570% | clf_exit: 0.434 0.480 0.087
Batch: 140 | Loss: 1.673 | Acc: 62.882,95.922,99.989,% | Adaptive Acc: 94.509% | clf_exit: 0.431 0.482 0.087
Batch: 160 | Loss: 1.674 | Acc: 62.811,95.919,99.990,% | Adaptive Acc: 94.570% | clf_exit: 0.429 0.484 0.087
Batch: 180 | Loss: 1.677 | Acc: 62.604,95.964,99.991,% | Adaptive Acc: 94.579% | clf_exit: 0.427 0.487 0.086
Batch: 200 | Loss: 1.675 | Acc: 62.850,95.962,99.988,% | Adaptive Acc: 94.663% | clf_exit: 0.427 0.487 0.087
Batch: 220 | Loss: 1.675 | Acc: 62.786,96.023,99.986,% | Adaptive Acc: 94.602% | clf_exit: 0.428 0.487 0.086
Batch: 240 | Loss: 1.673 | Acc: 62.857,96.029,99.984,% | Adaptive Acc: 94.603% | clf_exit: 0.429 0.485 0.086
Batch: 260 | Loss: 1.679 | Acc: 62.710,95.950,99.985,% | Adaptive Acc: 94.546% | clf_exit: 0.428 0.486 0.086
Batch: 280 | Loss: 1.684 | Acc: 62.597,95.846,99.986,% | Adaptive Acc: 94.484% | clf_exit: 0.427 0.486 0.087
Batch: 300 | Loss: 1.680 | Acc: 62.676,95.871,99.984,% | Adaptive Acc: 94.513% | clf_exit: 0.428 0.486 0.087
Batch: 320 | Loss: 1.683 | Acc: 62.578,95.860,99.983,% | Adaptive Acc: 94.502% | clf_exit: 0.427 0.486 0.087
Batch: 340 | Loss: 1.684 | Acc: 62.564,95.872,99.982,% | Adaptive Acc: 94.474% | clf_exit: 0.427 0.486 0.087
Batch: 360 | Loss: 1.682 | Acc: 62.682,95.864,99.981,% | Adaptive Acc: 94.453% | clf_exit: 0.428 0.486 0.087
Batch: 380 | Loss: 1.682 | Acc: 62.705,95.844,99.979,% | Adaptive Acc: 94.478% | clf_exit: 0.428 0.486 0.087
Batch: 0 | Loss: 3.805 | Acc: 57.812,72.656,77.344,% | Adaptive Acc: 73.438% | clf_exit: 0.422 0.406 0.172
Batch: 20 | Loss: 4.013 | Acc: 52.269,69.568,74.405,% | Adaptive Acc: 70.945% | clf_exit: 0.348 0.431 0.221
Batch: 40 | Loss: 4.016 | Acc: 51.944,68.769,74.143,% | Adaptive Acc: 70.694% | clf_exit: 0.344 0.428 0.229
Batch: 60 | Loss: 4.003 | Acc: 51.806,68.686,74.424,% | Adaptive Acc: 70.902% | clf_exit: 0.340 0.426 0.234

