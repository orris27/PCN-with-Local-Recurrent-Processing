Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 12.168 |  Acc: 6.374,10.260,12.778,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=0 | Loss: 11.087 |  Acc: 9.130,14.490,18.520,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 10.490 |  Acc: 11.402,18.284,23.784,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=1 | Loss: 9.922 |  Acc: 12.780,20.660,26.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 9.421 |  Acc: 15.116,24.468,32.012,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=2 | Loss: 9.220 |  Acc: 13.530,23.740,33.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 8.626 |  Acc: 18.612,29.452,38.554,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=3 | Loss: 8.562 |  Acc: 17.710,27.900,39.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 7.987 |  Acc: 21.356,33.704,44.134,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=4 | Loss: 8.010 |  Acc: 20.340,32.320,43.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 7.496 |  Acc: 23.912,37.028,48.080,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=5 | Loss: 7.546 |  Acc: 22.680,34.970,47.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 7.103 |  Acc: 25.852,39.884,51.512,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=6 | Loss: 7.049 |  Acc: 24.380,39.500,52.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 6.770 |  Acc: 27.798,42.296,54.530,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=7 | Loss: 7.113 |  Acc: 23.380,40.280,51.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 6.477 |  Acc: 29.456,44.606,57.164,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=8 | Loss: 6.861 |  Acc: 25.800,40.490,53.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 6.214 |  Acc: 30.482,46.596,59.510,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=9 | Loss: 6.650 |  Acc: 27.300,43.060,54.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 6.002 |  Acc: 32.110,48.258,61.600,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=10 | Loss: 6.213 |  Acc: 30.390,47.160,58.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 5.799 |  Acc: 33.112,50.000,63.394,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=11 | Loss: 6.157 |  Acc: 29.370,47.470,58.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 5.616 |  Acc: 33.876,51.440,65.406,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=12 | Loss: 6.127 |  Acc: 30.090,47.720,60.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 5.462 |  Acc: 35.156,52.454,66.612,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=13 | Loss: 5.920 |  Acc: 32.880,48.580,61.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 5.321 |  Acc: 35.814,53.586,68.168,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=14 | Loss: 6.025 |  Acc: 31.260,48.870,61.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 5.189 |  Acc: 36.740,54.800,69.554,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=15 | Loss: 5.749 |  Acc: 33.120,51.890,62.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 5.055 |  Acc: 37.546,55.642,71.122,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=16 | Loss: 5.690 |  Acc: 33.820,52.410,63.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 4.952 |  Acc: 38.048,56.670,72.068,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=17 | Loss: 5.890 |  Acc: 31.170,51.060,62.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 4.846 |  Acc: 38.718,57.516,73.158,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=18 | Loss: 5.434 |  Acc: 35.270,53.420,64.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 4.743 |  Acc: 39.168,58.490,74.610,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=19 | Loss: 5.489 |  Acc: 35.030,53.530,64.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 4.643 |  Acc: 39.966,59.294,75.724,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=20 | Loss: 5.325 |  Acc: 35.940,55.370,65.520,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 4.570 |  Acc: 40.306,59.654,76.362,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=21 | Loss: 5.412 |  Acc: 36.660,54.710,64.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 4.505 |  Acc: 40.644,60.086,77.426,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=22 | Loss: 5.374 |  Acc: 36.140,54.290,65.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 4.431 |  Acc: 40.936,60.742,78.270,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=23 | Loss: 5.319 |  Acc: 38.400,55.520,65.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 4.337 |  Acc: 41.398,61.482,79.420,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=24 | Loss: 5.160 |  Acc: 38.580,57.010,65.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 4.293 |  Acc: 41.866,62.072,79.504,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=25 | Loss: 5.309 |  Acc: 36.130,55.910,65.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 4.236 |  Acc: 42.246,62.410,80.528,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=26 | Loss: 5.311 |  Acc: 35.460,56.440,66.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 4.177 |  Acc: 42.640,62.988,81.090,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=27 | Loss: 5.241 |  Acc: 37.320,56.980,66.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 4.118 |  Acc: 42.882,63.444,81.756,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=28 | Loss: 5.109 |  Acc: 38.420,58.680,67.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 4.055 |  Acc: 43.198,63.896,82.984,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=29 | Loss: 5.176 |  Acc: 37.430,57.700,66.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 4.021 |  Acc: 43.526,64.182,83.078,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=30 | Loss: 5.130 |  Acc: 39.220,57.000,66.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 3.971 |  Acc: 43.844,64.562,83.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=31 | Loss: 5.068 |  Acc: 39.810,58.250,65.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 3.933 |  Acc: 43.948,64.828,84.462,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=32 | Loss: 5.332 |  Acc: 38.020,55.840,65.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 3.883 |  Acc: 44.062,65.444,84.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=33 | Loss: 5.058 |  Acc: 40.500,58.060,66.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 3.863 |  Acc: 44.194,65.492,85.238,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=34 | Loss: 5.208 |  Acc: 38.890,57.950,66.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 3.822 |  Acc: 44.624,66.058,85.522,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=35 | Loss: 5.185 |  Acc: 38.530,57.520,66.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 3.780 |  Acc: 44.978,66.408,86.292,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=36 | Loss: 4.978 |  Acc: 40.210,59.460,66.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 3.765 |  Acc: 45.062,66.572,86.340,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=37 | Loss: 5.105 |  Acc: 38.690,58.460,66.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 3.718 |  Acc: 45.210,66.920,87.020,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=38 | Loss: 5.266 |  Acc: 38.830,57.910,66.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 3.683 |  Acc: 45.286,67.252,87.600,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=39 | Loss: 5.187 |  Acc: 37.440,58.850,66.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 3.655 |  Acc: 45.474,67.348,87.876,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=40 | Loss: 5.237 |  Acc: 38.400,58.220,67.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 3.639 |  Acc: 45.594,67.656,87.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=41 | Loss: 5.156 |  Acc: 39.850,58.300,66.530,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 3.611 |  Acc: 45.936,67.756,88.492,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=42 | Loss: 4.980 |  Acc: 42.040,59.380,66.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 3.585 |  Acc: 46.108,68.008,88.686,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=43 | Loss: 5.060 |  Acc: 39.840,59.430,66.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 3.571 |  Acc: 46.356,68.432,88.612,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=44 | Loss: 5.008 |  Acc: 40.420,60.160,66.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 3.550 |  Acc: 46.356,68.556,89.078,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=45 | Loss: 5.125 |  Acc: 40.700,58.340,67.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 3.532 |  Acc: 46.380,68.634,89.182,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=46 | Loss: 4.929 |  Acc: 41.190,60.830,66.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 3.496 |  Acc: 46.520,68.942,89.570,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=47 | Loss: 5.121 |  Acc: 39.580,58.370,66.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 3.471 |  Acc: 46.806,69.276,89.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=48 | Loss: 4.905 |  Acc: 41.870,60.440,67.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 3.463 |  Acc: 46.726,69.208,90.044,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=49 | Loss: 4.939 |  Acc: 41.570,60.870,67.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 3.452 |  Acc: 47.072,69.392,89.888,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=50 | Loss: 5.039 |  Acc: 42.500,59.300,66.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 3.419 |  Acc: 47.122,69.992,90.432,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=51 | Loss: 4.997 |  Acc: 41.010,59.820,67.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 3.422 |  Acc: 46.902,69.668,90.226,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=52 | Loss: 4.930 |  Acc: 42.160,60.550,67.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 3.404 |  Acc: 47.402,70.072,90.478,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=53 | Loss: 4.900 |  Acc: 43.120,60.850,68.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 3.385 |  Acc: 47.432,70.532,90.664,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=54 | Loss: 4.893 |  Acc: 43.460,59.640,66.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 3.357 |  Acc: 47.584,70.470,91.288,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=55 | Loss: 4.937 |  Acc: 41.090,61.190,68.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 3.351 |  Acc: 47.700,70.542,90.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=56 | Loss: 5.200 |  Acc: 39.700,60.110,66.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 3.346 |  Acc: 47.552,70.780,91.030,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=57 | Loss: 5.005 |  Acc: 42.430,60.720,66.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 3.324 |  Acc: 48.014,70.820,91.308,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=58 | Loss: 5.071 |  Acc: 41.170,60.030,66.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 3.309 |  Acc: 48.028,71.108,91.452,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=59 | Loss: 4.861 |  Acc: 42.240,61.730,67.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 3.296 |  Acc: 48.122,71.158,91.430,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=60 | Loss: 4.881 |  Acc: 42.400,61.390,67.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 3.286 |  Acc: 48.094,71.306,91.752,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=61 | Loss: 5.019 |  Acc: 42.200,60.270,66.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 3.279 |  Acc: 48.316,71.440,91.806,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=62 | Loss: 4.960 |  Acc: 42.210,60.470,67.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 3.248 |  Acc: 48.494,71.768,92.032,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=63 | Loss: 5.083 |  Acc: 41.740,58.980,66.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 3.239 |  Acc: 48.636,71.818,91.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=64 | Loss: 4.910 |  Acc: 41.930,60.940,68.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 3.241 |  Acc: 48.390,71.668,91.868,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=65 | Loss: 5.114 |  Acc: 41.130,60.750,67.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 3.245 |  Acc: 48.458,71.834,91.846,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=66 | Loss: 4.868 |  Acc: 43.610,61.390,67.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 3.227 |  Acc: 48.488,72.194,91.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=67 | Loss: 4.955 |  Acc: 42.500,60.570,67.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 3.214 |  Acc: 48.842,72.210,91.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=68 | Loss: 4.880 |  Acc: 42.550,61.510,67.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 3.218 |  Acc: 49.006,72.020,92.126,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=69 | Loss: 5.098 |  Acc: 41.600,59.670,66.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 3.192 |  Acc: 48.802,72.396,92.492,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=70 | Loss: 4.991 |  Acc: 42.200,60.650,66.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 3.178 |  Acc: 48.920,72.718,92.556,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=71 | Loss: 5.179 |  Acc: 40.590,59.400,66.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 3.163 |  Acc: 49.264,73.060,92.440,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=72 | Loss: 4.947 |  Acc: 42.080,61.080,67.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 3.169 |  Acc: 49.150,72.700,92.526,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=73 | Loss: 5.020 |  Acc: 41.990,60.340,67.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 3.153 |  Acc: 49.362,72.972,92.678,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=74 | Loss: 4.985 |  Acc: 40.430,61.300,67.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 3.164 |  Acc: 49.190,72.830,92.526,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=75 | Loss: 4.919 |  Acc: 42.760,60.680,67.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 3.150 |  Acc: 49.336,73.242,92.584,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=76 | Loss: 5.216 |  Acc: 41.270,59.220,66.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 3.145 |  Acc: 49.354,72.978,92.622,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=77 | Loss: 4.955 |  Acc: 42.240,61.240,67.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 3.129 |  Acc: 49.514,73.252,92.622,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=78 | Loss: 4.780 |  Acc: 43.640,61.600,68.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 3.116 |  Acc: 49.640,73.500,92.992,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=79 | Loss: 4.757 |  Acc: 44.400,62.130,68.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 3.108 |  Acc: 49.824,73.606,92.922,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=80 | Loss: 4.829 |  Acc: 44.170,61.800,67.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 3.103 |  Acc: 49.566,73.678,92.872,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=81 | Loss: 4.929 |  Acc: 43.680,60.650,66.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 3.100 |  Acc: 49.734,73.656,93.068,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=82 | Loss: 4.901 |  Acc: 42.920,61.180,68.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 3.093 |  Acc: 49.754,73.828,92.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=83 | Loss: 5.001 |  Acc: 42.530,60.280,66.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 3.085 |  Acc: 50.198,73.766,92.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=84 | Loss: 5.030 |  Acc: 40.870,61.130,67.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 3.077 |  Acc: 49.766,74.046,93.136,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=85 | Loss: 5.017 |  Acc: 43.350,60.460,66.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 3.081 |  Acc: 49.894,73.684,92.838,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=86 | Loss: 4.799 |  Acc: 45.010,61.650,68.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 3.052 |  Acc: 50.084,74.078,93.254,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=87 | Loss: 4.939 |  Acc: 42.570,60.770,67.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 3.062 |  Acc: 49.962,73.926,93.228,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=88 | Loss: 4.697 |  Acc: 44.330,62.630,68.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 3.047 |  Acc: 49.834,74.264,93.354,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=89 | Loss: 4.873 |  Acc: 44.000,62.080,67.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 3.045 |  Acc: 50.116,74.148,93.278,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=90 | Loss: 4.838 |  Acc: 44.160,61.520,68.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 3.035 |  Acc: 50.324,74.486,93.402,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=91 | Loss: 4.838 |  Acc: 43.570,62.000,67.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 3.046 |  Acc: 50.030,74.386,93.050,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=92 | Loss: 4.909 |  Acc: 42.490,62.090,67.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 3.032 |  Acc: 50.464,74.760,93.200,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=93 | Loss: 4.932 |  Acc: 44.540,61.140,66.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 3.028 |  Acc: 50.322,74.564,93.284,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=94 | Loss: 4.789 |  Acc: 43.600,62.210,68.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 3.017 |  Acc: 50.638,74.840,93.340,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=95 | Loss: 4.919 |  Acc: 42.300,61.790,67.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 3.004 |  Acc: 50.414,74.948,93.518,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=96 | Loss: 4.793 |  Acc: 44.120,62.400,67.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 3.001 |  Acc: 50.350,74.982,93.502,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=97 | Loss: 4.704 |  Acc: 45.490,62.980,68.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 3.013 |  Acc: 50.576,75.044,93.374,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=98 | Loss: 4.951 |  Acc: 44.140,60.990,67.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 3.013 |  Acc: 50.644,74.734,93.162,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=99 | Loss: 4.737 |  Acc: 46.440,62.550,67.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 3.000 |  Acc: 50.632,75.200,93.320,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=100 | Loss: 4.853 |  Acc: 45.360,61.520,67.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 2.975 |  Acc: 50.768,75.180,93.588,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=101 | Loss: 4.793 |  Acc: 43.170,62.650,68.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 2.978 |  Acc: 50.808,75.420,93.580,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=102 | Loss: 4.690 |  Acc: 45.740,63.090,68.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 2.977 |  Acc: 50.926,75.356,93.460,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=103 | Loss: 4.899 |  Acc: 44.340,61.300,66.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 2.967 |  Acc: 50.782,75.418,93.772,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=104 | Loss: 5.070 |  Acc: 41.790,61.170,66.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 2.957 |  Acc: 50.886,75.618,93.614,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=105 | Loss: 4.961 |  Acc: 44.850,60.990,66.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 2.972 |  Acc: 51.010,75.472,93.466,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=106 | Loss: 4.722 |  Acc: 45.450,62.120,68.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 2.945 |  Acc: 51.176,75.740,93.866,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=107 | Loss: 4.903 |  Acc: 41.260,61.990,68.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 2.960 |  Acc: 50.902,75.374,93.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=108 | Loss: 4.721 |  Acc: 46.480,62.710,68.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 2.942 |  Acc: 51.214,76.030,93.692,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=109 | Loss: 4.779 |  Acc: 45.170,61.960,68.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 2.942 |  Acc: 50.996,75.794,93.536,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=110 | Loss: 4.868 |  Acc: 44.740,61.200,67.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 2.938 |  Acc: 51.176,75.966,93.656,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=111 | Loss: 5.056 |  Acc: 43.410,60.060,66.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 2.940 |  Acc: 51.256,75.734,93.598,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=112 | Loss: 4.860 |  Acc: 46.350,62.580,67.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 2.931 |  Acc: 51.282,75.950,93.860,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=113 | Loss: 4.940 |  Acc: 43.830,61.460,66.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 2.909 |  Acc: 51.268,76.280,94.156,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=114 | Loss: 4.721 |  Acc: 46.300,62.620,67.530,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 2.938 |  Acc: 51.284,75.970,93.636,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=115 | Loss: 5.011 |  Acc: 42.660,61.370,66.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 2.925 |  Acc: 51.384,76.042,93.578,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=116 | Loss: 4.879 |  Acc: 43.750,61.700,67.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 2.925 |  Acc: 51.398,75.952,93.680,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=117 | Loss: 4.725 |  Acc: 45.440,62.640,67.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 2.895 |  Acc: 51.460,76.252,94.208,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=118 | Loss: 4.689 |  Acc: 46.470,63.000,68.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 2.908 |  Acc: 51.476,76.274,93.662,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=119 | Loss: 4.787 |  Acc: 44.470,62.910,67.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 2.886 |  Acc: 51.598,76.620,93.982,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=120 | Loss: 4.721 |  Acc: 45.490,63.380,67.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 2.909 |  Acc: 51.550,76.204,93.840,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=121 | Loss: 4.974 |  Acc: 43.750,62.210,66.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 2.896 |  Acc: 51.444,76.746,93.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=122 | Loss: 5.061 |  Acc: 43.150,60.880,65.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 2.900 |  Acc: 51.510,76.552,93.692,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=123 | Loss: 4.956 |  Acc: 43.260,61.880,66.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 2.885 |  Acc: 51.630,76.654,94.106,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=124 | Loss: 4.664 |  Acc: 45.610,63.790,69.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 2.865 |  Acc: 51.916,76.814,94.012,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=125 | Loss: 4.717 |  Acc: 45.220,63.680,68.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 2.872 |  Acc: 51.810,76.642,94.116,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=126 | Loss: 4.792 |  Acc: 45.660,62.270,67.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 2.890 |  Acc: 51.796,76.578,93.700,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=127 | Loss: 4.833 |  Acc: 44.550,62.570,67.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 2.871 |  Acc: 51.864,76.738,93.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=128 | Loss: 4.656 |  Acc: 47.690,63.020,67.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 2.873 |  Acc: 51.800,76.762,93.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=129 | Loss: 4.917 |  Acc: 44.580,61.800,66.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 2.868 |  Acc: 51.836,76.948,94.074,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=130 | Loss: 4.652 |  Acc: 47.070,63.100,68.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 2.862 |  Acc: 51.822,77.000,94.004,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=131 | Loss: 4.727 |  Acc: 45.610,63.070,67.590,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 2.847 |  Acc: 51.994,77.200,94.268,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=132 | Loss: 4.830 |  Acc: 46.080,62.550,68.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 2.852 |  Acc: 51.984,77.178,94.016,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=133 | Loss: 4.797 |  Acc: 44.360,61.970,68.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 2.857 |  Acc: 51.718,76.980,94.116,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=134 | Loss: 4.792 |  Acc: 44.250,62.960,67.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 2.858 |  Acc: 51.978,76.834,94.020,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=135 | Loss: 4.816 |  Acc: 44.380,61.850,67.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 2.860 |  Acc: 52.000,77.114,93.896,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=136 | Loss: 4.795 |  Acc: 45.850,62.250,67.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 2.830 |  Acc: 52.020,77.314,94.214,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=137 | Loss: 4.593 |  Acc: 46.920,63.720,68.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 2.849 |  Acc: 51.954,76.910,94.154,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=138 | Loss: 4.837 |  Acc: 45.110,61.910,67.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 2.836 |  Acc: 52.270,77.016,94.136,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=139 | Loss: 4.731 |  Acc: 44.980,62.380,67.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 2.829 |  Acc: 52.274,77.312,94.154,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=140 | Loss: 4.738 |  Acc: 45.840,63.320,68.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 2.830 |  Acc: 51.944,77.544,94.216,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=141 | Loss: 4.706 |  Acc: 45.990,62.710,68.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 2.843 |  Acc: 52.108,77.206,93.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=142 | Loss: 4.741 |  Acc: 44.760,63.740,67.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 2.836 |  Acc: 52.114,77.282,94.152,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=143 | Loss: 4.635 |  Acc: 46.650,63.590,68.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 2.826 |  Acc: 52.190,77.672,94.366,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=144 | Loss: 4.779 |  Acc: 46.120,62.790,67.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 2.820 |  Acc: 52.372,77.558,94.218,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=145 | Loss: 4.837 |  Acc: 44.730,62.550,68.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 2.820 |  Acc: 52.334,77.676,94.088,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=146 | Loss: 4.756 |  Acc: 45.680,62.810,67.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 2.802 |  Acc: 52.430,77.710,94.224,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=147 | Loss: 4.682 |  Acc: 45.730,63.490,68.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 2.815 |  Acc: 52.566,77.454,94.044,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=148 | Loss: 4.890 |  Acc: 44.320,62.630,67.500,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 2.798 |  Acc: 52.686,77.678,94.452,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=149 | Loss: 5.129 |  Acc: 42.330,60.510,66.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 2.333 |  Acc: 56.478,84.488,98.494,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=150 | Loss: 3.927 |  Acc: 52.370,69.160,73.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 2.197 |  Acc: 57.600,86.704,99.576,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=151 | Loss: 3.908 |  Acc: 52.810,69.370,73.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 2.156 |  Acc: 57.780,87.454,99.670,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=152 | Loss: 3.887 |  Acc: 52.730,69.510,74.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 2.133 |  Acc: 57.962,87.910,99.750,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=153 | Loss: 3.880 |  Acc: 52.900,69.410,74.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 2.109 |  Acc: 58.284,88.306,99.804,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=154 | Loss: 3.876 |  Acc: 52.810,69.360,74.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 2.092 |  Acc: 58.380,88.502,99.850,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=155 | Loss: 3.881 |  Acc: 53.280,69.430,74.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 2.075 |  Acc: 58.556,88.798,99.838,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=156 | Loss: 3.880 |  Acc: 53.220,69.530,74.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 2.069 |  Acc: 58.606,88.946,99.888,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=157 | Loss: 3.885 |  Acc: 52.920,69.690,74.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 2.059 |  Acc: 58.780,89.166,99.850,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=158 | Loss: 3.874 |  Acc: 53.060,69.350,74.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 2.047 |  Acc: 58.782,89.330,99.852,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=159 | Loss: 3.867 |  Acc: 53.470,69.340,74.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 2.036 |  Acc: 58.726,89.598,99.884,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=160 | Loss: 3.855 |  Acc: 53.440,69.400,74.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 2.030 |  Acc: 59.180,89.602,99.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=161 | Loss: 3.855 |  Acc: 53.510,69.140,74.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 2.024 |  Acc: 58.962,89.720,99.900,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=162 | Loss: 3.859 |  Acc: 53.500,69.610,74.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 2.015 |  Acc: 59.288,89.856,99.902,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=163 | Loss: 3.866 |  Acc: 53.210,69.660,74.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 2.005 |  Acc: 59.194,89.930,99.900,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=164 | Loss: 3.863 |  Acc: 53.190,69.450,74.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.999 |  Acc: 59.306,90.130,99.918,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=165 | Loss: 3.865 |  Acc: 53.490,69.010,74.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.993 |  Acc: 59.460,90.166,99.898,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=166 | Loss: 3.878 |  Acc: 53.450,69.310,74.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.989 |  Acc: 59.264,90.386,99.924,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=167 | Loss: 3.863 |  Acc: 53.640,69.260,74.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.978 |  Acc: 59.710,90.220,99.896,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=168 | Loss: 3.858 |  Acc: 53.400,69.220,74.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.977 |  Acc: 59.468,90.494,99.914,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=169 | Loss: 3.874 |  Acc: 53.640,69.140,74.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.971 |  Acc: 59.546,90.584,99.920,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=170 | Loss: 3.880 |  Acc: 53.280,68.970,74.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.962 |  Acc: 59.610,90.570,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=171 | Loss: 3.863 |  Acc: 53.790,69.470,74.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.957 |  Acc: 59.838,90.844,99.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=172 | Loss: 3.882 |  Acc: 53.860,69.140,74.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.952 |  Acc: 59.932,90.954,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=173 | Loss: 3.866 |  Acc: 53.490,69.120,74.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.950 |  Acc: 59.706,90.780,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=174 | Loss: 3.877 |  Acc: 53.820,69.280,74.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.947 |  Acc: 59.766,90.924,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=175 | Loss: 3.876 |  Acc: 53.790,69.190,74.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.938 |  Acc: 59.920,91.036,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=176 | Loss: 3.871 |  Acc: 53.780,69.080,74.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.937 |  Acc: 59.952,90.974,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=177 | Loss: 3.862 |  Acc: 53.680,69.280,74.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.934 |  Acc: 59.958,91.146,99.930,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=178 | Loss: 3.853 |  Acc: 53.900,69.570,74.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.928 |  Acc: 60.144,91.208,99.926,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=179 | Loss: 3.873 |  Acc: 53.820,69.210,74.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.923 |  Acc: 60.104,91.244,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=180 | Loss: 3.885 |  Acc: 53.720,68.960,74.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.923 |  Acc: 60.040,91.208,99.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=181 | Loss: 3.874 |  Acc: 53.800,69.260,74.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 1.915 |  Acc: 60.202,91.496,99.922,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=182 | Loss: 3.883 |  Acc: 53.830,69.050,74.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 1.912 |  Acc: 60.086,91.316,99.920,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=183 | Loss: 3.875 |  Acc: 53.550,69.150,74.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 1.905 |  Acc: 60.330,91.624,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=184 | Loss: 3.886 |  Acc: 53.360,69.000,74.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 1.905 |  Acc: 60.328,91.276,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=185 | Loss: 3.884 |  Acc: 53.690,68.790,74.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 1.901 |  Acc: 60.288,91.664,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=186 | Loss: 3.886 |  Acc: 53.410,68.920,74.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 1.897 |  Acc: 60.320,91.592,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=187 | Loss: 3.868 |  Acc: 53.810,69.010,74.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 1.894 |  Acc: 60.442,91.558,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=188 | Loss: 3.879 |  Acc: 53.970,68.840,74.590,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 1.893 |  Acc: 60.416,91.736,99.920,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=189 | Loss: 3.863 |  Acc: 53.890,68.950,74.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 1.890 |  Acc: 60.364,91.684,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=190 | Loss: 3.891 |  Acc: 53.720,69.210,74.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 1.888 |  Acc: 60.454,91.754,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=191 | Loss: 3.865 |  Acc: 54.010,68.970,74.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 1.880 |  Acc: 60.646,91.840,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=192 | Loss: 3.886 |  Acc: 53.750,68.710,74.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 1.882 |  Acc: 60.648,91.880,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=193 | Loss: 3.902 |  Acc: 53.620,69.060,74.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 1.877 |  Acc: 60.732,91.980,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=194 | Loss: 3.906 |  Acc: 53.690,68.670,74.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 1.873 |  Acc: 60.762,91.884,99.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=195 | Loss: 3.897 |  Acc: 53.920,69.000,74.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 1.869 |  Acc: 60.738,92.000,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=196 | Loss: 3.915 |  Acc: 53.630,68.740,74.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 1.870 |  Acc: 60.790,91.882,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=197 | Loss: 3.900 |  Acc: 53.800,68.890,74.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 1.863 |  Acc: 60.700,92.126,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=198 | Loss: 3.884 |  Acc: 53.810,68.730,74.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 1.863 |  Acc: 61.140,91.974,99.930,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=199 | Loss: 3.867 |  Acc: 53.960,68.780,74.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 1.863 |  Acc: 61.046,91.958,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=200 | Loss: 3.891 |  Acc: 53.980,69.030,74.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 1.860 |  Acc: 60.642,92.212,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=201 | Loss: 3.919 |  Acc: 53.690,68.430,74.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 1.855 |  Acc: 61.130,92.118,99.922,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=202 | Loss: 3.922 |  Acc: 53.280,68.850,74.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 1.855 |  Acc: 60.934,92.278,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=203 | Loss: 3.893 |  Acc: 53.980,68.740,74.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 1.848 |  Acc: 61.172,92.348,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=204 | Loss: 3.925 |  Acc: 53.780,68.310,74.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 1.853 |  Acc: 61.054,92.200,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=205 | Loss: 3.911 |  Acc: 53.710,68.360,74.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 1.849 |  Acc: 61.204,92.074,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=206 | Loss: 3.892 |  Acc: 53.650,68.880,74.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 1.845 |  Acc: 61.320,92.312,99.926,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=207 | Loss: 3.947 |  Acc: 52.590,68.390,74.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 1.845 |  Acc: 61.384,92.164,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=208 | Loss: 3.941 |  Acc: 53.260,68.780,74.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 1.844 |  Acc: 61.332,92.148,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=209 | Loss: 3.913 |  Acc: 53.730,68.880,74.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 1.840 |  Acc: 61.418,92.298,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=210 | Loss: 3.910 |  Acc: 53.430,68.520,74.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 1.840 |  Acc: 61.156,92.344,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=211 | Loss: 3.947 |  Acc: 53.170,68.100,74.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 1.833 |  Acc: 61.270,92.348,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=212 | Loss: 3.912 |  Acc: 54.140,68.770,74.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 1.835 |  Acc: 61.242,92.402,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=213 | Loss: 3.942 |  Acc: 53.660,68.000,74.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 1.831 |  Acc: 61.354,92.498,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=214 | Loss: 3.947 |  Acc: 53.270,68.290,73.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 1.834 |  Acc: 61.070,92.270,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=215 | Loss: 3.935 |  Acc: 53.600,68.410,74.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 1.831 |  Acc: 61.336,92.326,99.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=216 | Loss: 3.934 |  Acc: 53.440,68.390,73.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 1.828 |  Acc: 61.408,92.466,99.922,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=217 | Loss: 3.924 |  Acc: 53.590,68.120,74.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 1.824 |  Acc: 61.416,92.360,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=218 | Loss: 3.925 |  Acc: 53.690,68.390,74.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 1.824 |  Acc: 61.322,92.360,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=219 | Loss: 3.972 |  Acc: 53.320,68.120,73.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 1.823 |  Acc: 61.406,92.590,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=220 | Loss: 3.940 |  Acc: 53.460,68.300,73.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 1.825 |  Acc: 61.402,92.498,99.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=221 | Loss: 3.936 |  Acc: 53.590,68.260,73.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 1.821 |  Acc: 61.440,92.580,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=222 | Loss: 3.944 |  Acc: 53.110,68.710,73.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 1.824 |  Acc: 61.400,92.452,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=223 | Loss: 3.962 |  Acc: 53.770,68.280,74.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 1.819 |  Acc: 61.570,92.398,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=224 | Loss: 3.917 |  Acc: 53.620,68.460,74.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 1.729 |  Acc: 62.762,94.414,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=225 | Loss: 3.830 |  Acc: 54.860,69.260,74.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 1.709 |  Acc: 62.880,94.920,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=226 | Loss: 3.835 |  Acc: 54.920,69.160,74.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 1.705 |  Acc: 62.872,95.100,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=227 | Loss: 3.840 |  Acc: 54.820,69.300,74.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 1.703 |  Acc: 63.030,95.290,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=228 | Loss: 3.828 |  Acc: 54.870,69.200,74.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 1.701 |  Acc: 63.148,95.316,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=229 | Loss: 3.831 |  Acc: 54.840,69.280,74.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 1.698 |  Acc: 63.172,95.172,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=230 | Loss: 3.834 |  Acc: 55.110,69.360,74.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 1.696 |  Acc: 63.038,95.356,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=231 | Loss: 3.839 |  Acc: 54.970,69.230,74.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 1.693 |  Acc: 63.136,95.270,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=232 | Loss: 3.838 |  Acc: 54.990,69.310,74.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 1.692 |  Acc: 62.984,95.378,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=233 | Loss: 3.838 |  Acc: 54.960,69.270,74.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 1.692 |  Acc: 63.032,95.302,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=234 | Loss: 3.846 |  Acc: 54.870,69.130,74.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 1.693 |  Acc: 63.162,95.398,99.982,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=235 | Loss: 3.850 |  Acc: 54.730,69.080,74.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 1.691 |  Acc: 63.196,95.276,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=236 | Loss: 3.844 |  Acc: 54.860,69.200,74.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 1.690 |  Acc: 63.246,95.384,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=237 | Loss: 3.841 |  Acc: 54.870,69.140,74.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 1.687 |  Acc: 63.244,95.456,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=238 | Loss: 3.840 |  Acc: 55.120,69.220,74.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 1.686 |  Acc: 63.278,95.486,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=239 | Loss: 3.845 |  Acc: 54.950,69.200,74.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 1.686 |  Acc: 63.230,95.480,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=240 | Loss: 3.838 |  Acc: 54.960,69.190,74.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 1.688 |  Acc: 63.354,95.422,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=241 | Loss: 3.844 |  Acc: 54.940,69.180,74.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 1.688 |  Acc: 63.072,95.368,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=242 | Loss: 3.846 |  Acc: 54.900,69.230,74.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 1.683 |  Acc: 63.182,95.482,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=243 | Loss: 3.845 |  Acc: 54.920,69.190,74.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 1.684 |  Acc: 63.304,95.370,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=244 | Loss: 3.847 |  Acc: 54.840,69.320,74.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 1.680 |  Acc: 63.278,95.580,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=245 | Loss: 3.848 |  Acc: 54.860,69.310,74.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 1.685 |  Acc: 63.184,95.460,99.982,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=246 | Loss: 3.848 |  Acc: 55.080,69.330,74.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 1.681 |  Acc: 63.118,95.612,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=247 | Loss: 3.848 |  Acc: 55.130,69.160,74.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 1.684 |  Acc: 63.004,95.598,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=248 | Loss: 3.838 |  Acc: 54.860,69.170,74.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 1.679 |  Acc: 63.388,95.480,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=249 | Loss: 3.842 |  Acc: 54.910,69.490,74.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 1.681 |  Acc: 63.396,95.676,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=250 | Loss: 3.846 |  Acc: 54.850,69.370,74.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 1.681 |  Acc: 63.418,95.512,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=251 | Loss: 3.845 |  Acc: 54.710,69.380,74.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 1.680 |  Acc: 63.408,95.610,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=252 | Loss: 3.844 |  Acc: 54.760,69.080,74.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 1.681 |  Acc: 63.140,95.542,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=253 | Loss: 3.845 |  Acc: 54.800,68.980,74.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 1.677 |  Acc: 63.380,95.540,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=254 | Loss: 3.843 |  Acc: 54.810,69.110,74.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 1.679 |  Acc: 63.294,95.616,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=255 | Loss: 3.850 |  Acc: 54.980,69.200,74.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 1.679 |  Acc: 63.378,95.574,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=256 | Loss: 3.840 |  Acc: 54.890,69.040,74.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 1.674 |  Acc: 63.334,95.700,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=257 | Loss: 3.850 |  Acc: 54.790,69.140,74.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 1.677 |  Acc: 63.416,95.618,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=258 | Loss: 3.851 |  Acc: 54.830,68.910,74.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 1.676 |  Acc: 63.250,95.670,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=259 | Loss: 3.843 |  Acc: 54.810,69.290,74.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 1.676 |  Acc: 63.198,95.536,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=260 | Loss: 3.849 |  Acc: 54.740,69.180,74.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 1.675 |  Acc: 63.222,95.690,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=261 | Loss: 3.844 |  Acc: 54.860,69.310,74.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 1.666 |  Acc: 63.686,95.830,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=262 | Loss: 3.848 |  Acc: 54.830,69.270,74.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 1.665 |  Acc: 63.708,95.874,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=263 | Loss: 3.843 |  Acc: 55.160,69.040,74.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 1.663 |  Acc: 63.374,95.798,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=264 | Loss: 3.841 |  Acc: 55.060,69.170,74.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 1.660 |  Acc: 63.584,95.840,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=265 | Loss: 3.849 |  Acc: 54.740,69.320,74.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 1.665 |  Acc: 63.566,95.946,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=266 | Loss: 3.845 |  Acc: 55.010,69.190,74.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 1.665 |  Acc: 63.448,95.846,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=267 | Loss: 3.847 |  Acc: 54.860,69.380,74.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 1.665 |  Acc: 63.562,95.832,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=268 | Loss: 3.844 |  Acc: 54.950,69.230,74.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 1.661 |  Acc: 63.564,95.870,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=269 | Loss: 3.843 |  Acc: 54.900,69.320,74.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 1.668 |  Acc: 63.506,95.738,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=270 | Loss: 3.846 |  Acc: 55.070,69.370,74.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 1.660 |  Acc: 63.600,95.886,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=271 | Loss: 3.846 |  Acc: 54.980,69.220,74.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 1.661 |  Acc: 63.570,95.918,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=272 | Loss: 3.844 |  Acc: 54.890,69.360,74.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 1.659 |  Acc: 63.642,95.978,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=273 | Loss: 3.844 |  Acc: 55.030,69.150,74.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 1.665 |  Acc: 63.652,95.966,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=274 | Loss: 3.844 |  Acc: 54.980,69.240,74.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 1.659 |  Acc: 63.570,95.824,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=275 | Loss: 3.848 |  Acc: 55.020,69.160,74.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 1.661 |  Acc: 63.620,95.902,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=276 | Loss: 3.853 |  Acc: 54.910,69.140,74.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 1.657 |  Acc: 63.662,96.000,99.984,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=277 | Loss: 3.838 |  Acc: 55.010,69.190,74.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 1.662 |  Acc: 63.444,95.810,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=278 | Loss: 3.846 |  Acc: 54.930,69.120,74.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 1.661 |  Acc: 63.686,95.958,99.980,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=279 | Loss: 3.841 |  Acc: 54.910,69.260,74.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 1.662 |  Acc: 63.586,95.928,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=280 | Loss: 3.846 |  Acc: 54.860,69.280,74.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 1.659 |  Acc: 63.796,95.922,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=281 | Loss: 3.841 |  Acc: 54.960,69.070,74.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 1.665 |  Acc: 63.494,95.930,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=282 | Loss: 3.846 |  Acc: 54.920,69.320,74.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 1.663 |  Acc: 63.532,95.986,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=283 | Loss: 3.842 |  Acc: 54.970,69.160,74.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 1.661 |  Acc: 63.396,95.888,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=284 | Loss: 3.841 |  Acc: 55.090,69.200,74.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 1.663 |  Acc: 63.402,95.836,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=285 | Loss: 3.842 |  Acc: 54.900,69.330,74.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 1.661 |  Acc: 63.542,95.906,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=286 | Loss: 3.846 |  Acc: 54.840,69.290,74.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 1.663 |  Acc: 63.618,95.976,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=287 | Loss: 3.847 |  Acc: 54.840,69.250,74.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 1.658 |  Acc: 63.620,95.914,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=288 | Loss: 3.851 |  Acc: 54.900,69.220,74.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 1.657 |  Acc: 63.678,95.996,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=289 | Loss: 3.846 |  Acc: 54.850,69.310,74.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 1.659 |  Acc: 63.602,95.972,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=290 | Loss: 3.849 |  Acc: 54.900,69.240,74.130,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 1.662 |  Acc: 63.630,95.920,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=291 | Loss: 3.845 |  Acc: 54.980,69.280,74.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 1.659 |  Acc: 63.482,95.940,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=292 | Loss: 3.846 |  Acc: 54.960,69.320,74.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 1.661 |  Acc: 63.570,95.968,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=293 | Loss: 3.843 |  Acc: 54.960,69.290,74.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 1.657 |  Acc: 63.730,95.862,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=294 | Loss: 3.844 |  Acc: 54.780,69.180,74.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 1.660 |  Acc: 63.610,95.942,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=295 | Loss: 3.848 |  Acc: 54.930,69.150,74.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 1.661 |  Acc: 63.642,96.008,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=296 | Loss: 3.843 |  Acc: 55.050,69.210,74.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 1.659 |  Acc: 63.332,95.918,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=297 | Loss: 3.846 |  Acc: 54.830,69.240,74.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 1.662 |  Acc: 63.596,95.902,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=298 | Loss: 3.842 |  Acc: 54.910,69.180,74.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=1, backend='modelE', batch_size=128, circles=10, dataset_name='cifar100', dropout=0.5, fb='1:1:1', ge=1, lmbda=0.01, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 1.658 |  Acc: 63.684,96.060,99.978,% | Adaptive Acc:94.806% | clf_exit: 0.421 0.493 0.087 
Testing: Epoch=299 | Loss: 3.848 |  Acc: 54.850,69.130,74.150,% | Adaptive Acc:69.170% | clf_exit: 0.474 0.349 0.177 


==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32x1x1])
      (FBconv): ConvTranspose2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(288, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=64, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=64, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 15.423 | Acc: 0.000,0.781,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.130 | Acc: 1.339,3.013,4.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.871 | Acc: 1.963,4.306,5.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.658 | Acc: 2.408,4.880,5.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.503 | Acc: 2.961,5.343,6.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.335 | Acc: 3.450,6.002,7.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.217 | Acc: 3.706,6.315,7.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.099 | Acc: 4.045,6.666,8.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.991 | Acc: 4.372,7.138,8.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.888 | Acc: 4.662,7.605,9.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.797 | Acc: 4.851,7.809,9.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.705 | Acc: 5.009,8.155,9.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.632 | Acc: 5.222,8.441,10.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.569 | Acc: 5.346,8.657,10.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.501 | Acc: 5.455,8.922,10.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.434 | Acc: 5.645,9.196,11.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.369 | Acc: 5.822,9.446,11.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.313 | Acc: 5.964,9.668,11.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.253 | Acc: 6.118,9.890,12.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.195 | Acc: 6.266,10.158,12.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.034 | Acc: 14.062,15.625,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.126 | Acc: 9.821,14.472,18.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.114 | Acc: 9.242,14.310,18.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.109 | Acc: 9.144,14.549,18.455,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 11.206 | Acc: 7.812,13.281,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.048 | Acc: 9.263,14.769,19.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.045 | Acc: 9.318,14.710,19.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.020 | Acc: 9.849,15.356,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.006 | Acc: 9.857,15.268,20.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.951 | Acc: 9.839,15.439,20.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.907 | Acc: 9.956,15.606,20.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.868 | Acc: 10.079,15.880,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.839 | Acc: 10.098,15.965,21.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.805 | Acc: 10.329,16.259,21.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.777 | Acc: 10.475,16.465,21.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.750 | Acc: 10.626,16.625,21.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.724 | Acc: 10.691,16.763,21.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.686 | Acc: 10.866,17.125,22.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.658 | Acc: 10.926,17.285,22.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.626 | Acc: 11.002,17.496,22.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.597 | Acc: 11.113,17.665,22.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.568 | Acc: 11.173,17.836,23.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.535 | Acc: 11.323,18.038,23.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.504 | Acc: 11.370,18.233,23.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.028 | Acc: 13.281,20.312,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.006 | Acc: 13.021,20.499,25.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.948 | Acc: 12.614,20.522,26.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.944 | Acc: 12.795,20.799,26.498,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 9.534 | Acc: 17.188,27.344,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.706 | Acc: 13.393,22.805,31.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.728 | Acc: 13.586,22.256,30.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.682 | Acc: 14.152,22.938,30.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.653 | Acc: 14.217,23.071,30.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.651 | Acc: 14.101,23.074,30.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.668 | Acc: 14.062,22.934,30.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.664 | Acc: 14.085,23.011,30.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.644 | Acc: 14.160,23.098,30.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.644 | Acc: 14.162,23.027,30.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.630 | Acc: 14.269,23.099,30.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.599 | Acc: 14.480,23.377,30.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.588 | Acc: 14.503,23.395,30.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.569 | Acc: 14.529,23.536,30.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.548 | Acc: 14.649,23.691,31.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.520 | Acc: 14.787,23.918,31.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.493 | Acc: 14.880,24.112,31.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.475 | Acc: 14.945,24.212,31.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.447 | Acc: 15.039,24.294,31.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.428 | Acc: 15.114,24.432,31.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.230 | Acc: 14.062,25.781,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.285 | Acc: 13.393,23.549,33.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.227 | Acc: 13.529,23.933,33.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.238 | Acc: 13.640,23.694,33.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 9.290 | Acc: 14.844,21.875,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.910 | Acc: 16.481,25.707,35.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.891 | Acc: 16.940,26.696,36.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.841 | Acc: 17.444,27.690,36.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.826 | Acc: 17.689,28.154,36.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.816 | Acc: 17.837,28.140,36.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.802 | Acc: 17.794,28.138,37.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.784 | Acc: 17.819,28.147,37.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.769 | Acc: 17.906,28.222,37.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.772 | Acc: 17.783,28.242,37.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.763 | Acc: 18.015,28.483,37.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.737 | Acc: 18.167,28.701,37.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.730 | Acc: 18.196,28.709,37.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.730 | Acc: 18.115,28.523,37.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.724 | Acc: 18.111,28.561,37.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.698 | Acc: 18.265,28.834,37.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.679 | Acc: 18.334,29.028,37.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.658 | Acc: 18.386,29.174,38.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.643 | Acc: 18.469,29.302,38.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.631 | Acc: 18.568,29.402,38.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.503 | Acc: 17.969,28.906,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.587 | Acc: 18.304,28.460,40.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.565 | Acc: 17.797,28.258,40.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.576 | Acc: 17.789,27.997,39.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 7.760 | Acc: 23.438,35.938,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.164 | Acc: 20.350,31.808,43.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.151 | Acc: 20.789,32.317,42.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.156 | Acc: 20.441,32.275,42.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.155 | Acc: 20.312,31.925,42.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.145 | Acc: 20.444,32.256,42.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.136 | Acc: 20.442,32.444,42.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.119 | Acc: 20.423,32.619,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.102 | Acc: 20.657,32.832,43.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.088 | Acc: 20.770,32.860,43.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.070 | Acc: 20.934,32.999,43.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.080 | Acc: 20.804,32.933,43.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.072 | Acc: 20.808,33.179,43.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.056 | Acc: 20.827,33.244,43.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.054 | Acc: 20.924,33.257,43.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.048 | Acc: 20.935,33.282,43.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.037 | Acc: 20.965,33.321,43.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.025 | Acc: 21.101,33.465,43.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.010 | Acc: 21.191,33.548,44.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.993 | Acc: 21.338,33.709,44.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.836 | Acc: 25.000,32.812,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.025 | Acc: 20.759,33.259,43.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.999 | Acc: 20.560,33.136,43.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.013 | Acc: 20.530,32.787,43.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 8.009 | Acc: 22.656,32.812,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.612 | Acc: 23.140,36.272,49.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.698 | Acc: 22.866,36.052,48.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.672 | Acc: 22.541,35.835,47.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.665 | Acc: 22.560,35.957,47.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.647 | Acc: 22.942,35.992,47.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.629 | Acc: 22.998,36.176,47.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.599 | Acc: 23.122,36.270,47.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.594 | Acc: 23.171,36.374,47.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.587 | Acc: 23.213,36.421,47.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.584 | Acc: 23.270,36.291,47.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.582 | Acc: 23.459,36.298,47.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.569 | Acc: 23.509,36.356,47.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.563 | Acc: 23.590,36.357,47.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.552 | Acc: 23.599,36.491,47.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.539 | Acc: 23.648,36.605,47.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.536 | Acc: 23.654,36.592,47.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.520 | Acc: 23.717,36.783,47.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.508 | Acc: 23.812,36.909,47.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.501 | Acc: 23.852,36.998,48.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.337 | Acc: 28.125,39.062,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.560 | Acc: 22.917,35.268,47.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.540 | Acc: 22.637,35.271,47.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.558 | Acc: 22.631,34.939,47.515,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 7.247 | Acc: 20.312,35.938,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.164 | Acc: 24.516,38.579,52.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.194 | Acc: 25.343,38.472,51.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.185 | Acc: 25.743,38.845,51.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.194 | Acc: 25.347,38.927,50.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.183 | Acc: 25.364,39.233,51.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.194 | Acc: 25.374,39.153,50.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.174 | Acc: 25.587,39.428,50.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.184 | Acc: 25.558,39.325,50.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.170 | Acc: 25.587,39.434,50.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.158 | Acc: 25.630,39.560,51.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.141 | Acc: 25.732,39.731,51.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.136 | Acc: 25.778,39.759,51.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.137 | Acc: 25.748,39.712,51.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.135 | Acc: 25.745,39.755,51.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.124 | Acc: 25.732,39.802,51.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.118 | Acc: 25.832,39.878,51.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.111 | Acc: 25.889,39.901,51.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.112 | Acc: 25.853,39.883,51.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.110 | Acc: 25.828,39.856,51.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.802 | Acc: 28.125,42.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.094 | Acc: 25.595,39.955,52.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.056 | Acc: 24.905,39.691,51.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.066 | Acc: 24.513,39.460,51.998,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 7.689 | Acc: 25.000,37.500,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.778 | Acc: 26.972,41.853,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.835 | Acc: 27.096,41.597,54.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.827 | Acc: 27.164,41.547,54.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.820 | Acc: 27.257,41.445,54.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.795 | Acc: 27.429,41.739,54.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.808 | Acc: 27.725,41.865,54.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.820 | Acc: 27.687,41.833,54.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.813 | Acc: 27.669,42.008,54.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.814 | Acc: 27.724,41.920,54.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.814 | Acc: 27.721,42.016,54.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.820 | Acc: 27.513,41.937,54.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.806 | Acc: 27.551,41.980,54.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.803 | Acc: 27.556,42.050,54.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.802 | Acc: 27.633,42.074,54.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.791 | Acc: 27.728,42.156,54.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.783 | Acc: 27.740,42.253,54.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.776 | Acc: 27.765,42.281,54.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.771 | Acc: 27.779,42.309,54.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.768 | Acc: 27.776,42.294,54.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.831 | Acc: 32.031,42.969,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.118 | Acc: 23.549,40.513,52.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.117 | Acc: 23.228,40.301,51.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.119 | Acc: 23.348,40.151,51.486,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 6.627 | Acc: 28.906,40.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.577 | Acc: 28.757,43.080,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.585 | Acc: 28.468,43.769,56.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.538 | Acc: 28.689,44.083,57.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.546 | Acc: 28.771,44.203,57.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.536 | Acc: 28.767,44.059,57.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.513 | Acc: 29.203,44.299,57.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.522 | Acc: 29.205,44.110,57.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.517 | Acc: 29.217,44.080,57.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.507 | Acc: 29.325,44.324,57.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.512 | Acc: 29.248,44.333,57.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.507 | Acc: 29.323,44.199,57.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.510 | Acc: 29.263,44.149,56.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.503 | Acc: 29.307,44.217,56.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.498 | Acc: 29.254,44.186,57.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.496 | Acc: 29.345,44.282,56.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.488 | Acc: 29.376,44.397,57.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.483 | Acc: 29.435,44.449,57.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.480 | Acc: 29.484,44.527,57.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.478 | Acc: 29.470,44.556,57.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.627 | Acc: 28.125,42.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.916 | Acc: 25.670,39.918,53.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.888 | Acc: 26.277,39.996,52.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.881 | Acc: 25.602,40.343,53.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 6.559 | Acc: 27.344,48.438,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.316 | Acc: 29.576,45.461,60.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.322 | Acc: 29.478,45.694,59.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.264 | Acc: 29.995,45.927,59.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.279 | Acc: 29.755,45.737,59.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.262 | Acc: 29.989,46.055,59.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.252 | Acc: 30.120,46.242,59.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.254 | Acc: 30.125,46.277,59.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.277 | Acc: 29.891,46.230,59.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.258 | Acc: 30.020,46.266,59.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.251 | Acc: 30.115,46.420,59.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.250 | Acc: 30.105,46.419,59.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.252 | Acc: 30.080,46.353,59.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.246 | Acc: 30.241,46.372,59.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.240 | Acc: 30.196,46.466,59.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.233 | Acc: 30.329,46.564,59.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.231 | Acc: 30.259,46.544,59.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.223 | Acc: 30.356,46.547,59.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.215 | Acc: 30.404,46.604,59.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.212 | Acc: 30.487,46.617,59.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.552 | Acc: 28.125,42.188,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.721 | Acc: 27.604,43.415,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.692 | Acc: 27.477,43.350,54.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.697 | Acc: 27.344,43.097,54.419,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 5.651 | Acc: 33.594,50.781,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.037 | Acc: 31.138,47.842,63.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.963 | Acc: 32.069,48.952,63.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.009 | Acc: 31.724,48.309,62.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.049 | Acc: 31.462,48.139,62.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.033 | Acc: 31.513,48.144,62.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.022 | Acc: 31.553,48.166,62.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.019 | Acc: 31.538,48.305,62.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.024 | Acc: 31.410,48.234,61.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.027 | Acc: 31.440,48.209,61.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.036 | Acc: 31.499,48.025,61.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.025 | Acc: 31.741,48.179,61.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.032 | Acc: 31.658,48.042,61.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.024 | Acc: 31.753,48.084,61.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.019 | Acc: 31.862,48.162,61.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.024 | Acc: 31.899,48.131,61.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.020 | Acc: 31.924,48.128,61.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.018 | Acc: 31.930,48.124,61.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.008 | Acc: 32.075,48.258,61.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.003 | Acc: 32.085,48.290,61.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.184 | Acc: 31.250,46.875,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.218 | Acc: 29.204,47.396,59.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.211 | Acc: 30.069,47.046,58.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.230 | Acc: 30.174,47.067,58.056,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 5.590 | Acc: 38.281,53.125,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.755 | Acc: 32.812,49.516,63.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.750 | Acc: 33.136,49.657,63.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.732 | Acc: 33.299,50.090,64.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.720 | Acc: 33.266,50.174,63.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.743 | Acc: 33.462,50.062,63.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.757 | Acc: 33.400,50.013,63.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.771 | Acc: 33.333,49.911,63.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.769 | Acc: 33.293,49.951,63.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.788 | Acc: 33.235,49.706,63.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.789 | Acc: 33.209,49.743,63.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.795 | Acc: 33.095,49.724,63.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.793 | Acc: 33.091,49.838,63.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.796 | Acc: 33.097,49.880,63.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.789 | Acc: 33.124,49.967,63.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.789 | Acc: 33.103,49.987,63.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.795 | Acc: 33.053,49.968,63.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.801 | Acc: 33.046,49.993,63.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.800 | Acc: 33.077,49.965,63.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.805 | Acc: 33.089,49.967,63.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.705 | Acc: 33.594,51.562,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.158 | Acc: 29.576,48.028,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.158 | Acc: 29.707,47.904,58.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.177 | Acc: 29.316,47.707,58.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 5.327 | Acc: 37.500,57.812,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.722 | Acc: 33.333,51.749,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.626 | Acc: 33.632,52.077,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.619 | Acc: 33.491,52.024,66.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.646 | Acc: 33.362,51.659,66.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.610 | Acc: 33.547,52.034,66.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.596 | Acc: 33.723,52.195,66.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.608 | Acc: 33.594,51.934,66.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.600 | Acc: 33.807,51.931,66.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.608 | Acc: 33.892,51.731,65.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.616 | Acc: 33.850,51.625,65.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.621 | Acc: 33.774,51.598,65.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.625 | Acc: 33.743,51.472,65.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.621 | Acc: 33.824,51.458,65.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.612 | Acc: 33.855,51.507,65.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.608 | Acc: 33.825,51.446,65.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.598 | Acc: 33.944,51.536,65.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.602 | Acc: 33.892,51.473,65.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.615 | Acc: 33.819,51.426,65.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.619 | Acc: 33.844,51.423,65.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.609 | Acc: 34.375,54.688,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.105 | Acc: 30.097,48.847,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.123 | Acc: 30.107,47.809,60.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.138 | Acc: 30.149,47.861,59.836,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 5.316 | Acc: 33.594,53.906,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.424 | Acc: 34.635,52.604,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.443 | Acc: 35.309,52.801,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.419 | Acc: 35.412,52.920,67.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.445 | Acc: 35.301,52.344,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.423 | Acc: 35.272,52.452,67.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.417 | Acc: 35.440,52.673,67.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.425 | Acc: 35.406,52.831,67.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.422 | Acc: 35.428,52.776,67.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.437 | Acc: 35.350,52.465,66.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.438 | Acc: 35.308,52.523,66.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.444 | Acc: 35.266,52.521,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.451 | Acc: 35.237,52.486,66.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.455 | Acc: 35.216,52.332,66.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.460 | Acc: 35.087,52.283,66.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.463 | Acc: 35.060,52.237,66.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.467 | Acc: 35.049,52.188,66.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.458 | Acc: 35.147,52.360,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.462 | Acc: 35.145,52.383,66.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.460 | Acc: 35.197,52.420,66.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.741 | Acc: 36.719,50.781,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.964 | Acc: 32.329,48.661,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.923 | Acc: 32.622,48.590,60.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.939 | Acc: 32.646,48.835,60.848,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 5.274 | Acc: 35.938,57.031,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.243 | Acc: 36.793,55.134,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.244 | Acc: 36.414,54.821,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.259 | Acc: 35.989,54.508,69.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.250 | Acc: 36.005,54.765,69.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.278 | Acc: 35.968,54.347,69.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.274 | Acc: 35.950,54.410,69.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.296 | Acc: 35.710,54.061,69.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.300 | Acc: 35.777,53.853,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.315 | Acc: 35.743,53.738,68.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.320 | Acc: 35.755,53.790,68.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.320 | Acc: 35.701,53.726,68.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.321 | Acc: 35.785,53.670,68.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.328 | Acc: 35.761,53.517,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.327 | Acc: 35.921,53.534,68.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.330 | Acc: 35.823,53.582,68.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.330 | Acc: 35.799,53.553,68.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.334 | Acc: 35.775,53.466,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.328 | Acc: 35.816,53.538,68.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.323 | Acc: 35.817,53.595,68.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.487 | Acc: 34.375,53.906,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.021 | Acc: 31.771,49.814,62.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.007 | Acc: 31.955,49.486,61.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.036 | Acc: 31.391,48.617,61.283,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 5.340 | Acc: 31.250,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.112 | Acc: 35.826,56.027,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.148 | Acc: 36.490,55.183,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.105 | Acc: 36.860,55.392,71.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.103 | Acc: 36.921,55.459,71.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.093 | Acc: 37.144,55.469,71.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.089 | Acc: 37.158,55.669,71.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.100 | Acc: 37.168,55.602,71.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.113 | Acc: 37.141,55.420,70.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.115 | Acc: 37.073,55.564,70.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.122 | Acc: 37.045,55.407,70.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.134 | Acc: 36.874,55.278,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.146 | Acc: 36.761,55.141,70.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.164 | Acc: 36.830,54.963,69.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.170 | Acc: 36.794,54.924,69.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.172 | Acc: 36.732,54.854,69.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.179 | Acc: 36.621,54.812,69.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.189 | Acc: 36.661,54.731,69.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.192 | Acc: 36.680,54.735,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.187 | Acc: 36.711,54.788,69.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.643 | Acc: 34.375,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.804 | Acc: 33.222,51.823,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.778 | Acc: 32.946,51.867,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.783 | Acc: 33.094,51.639,61.796,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 5.031 | Acc: 38.281,54.688,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.951 | Acc: 37.500,55.357,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.000 | Acc: 36.681,55.164,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.999 | Acc: 36.808,55.686,72.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.980 | Acc: 37.461,55.883,72.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.004 | Acc: 37.260,55.894,72.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.996 | Acc: 37.080,55.992,72.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.009 | Acc: 37.289,55.762,72.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.017 | Acc: 37.223,55.697,72.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.030 | Acc: 37.047,55.676,71.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.032 | Acc: 37.166,55.671,71.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.036 | Acc: 37.231,55.638,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.044 | Acc: 37.176,55.534,71.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.051 | Acc: 37.219,55.475,71.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.058 | Acc: 37.183,55.421,71.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.065 | Acc: 37.199,55.432,71.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.055 | Acc: 37.344,55.551,71.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.053 | Acc: 37.420,55.636,71.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.057 | Acc: 37.465,55.622,71.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.057 | Acc: 37.469,55.647,71.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.428 | Acc: 39.062,54.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.684 | Acc: 33.557,52.679,64.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.693 | Acc: 33.994,52.325,62.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.697 | Acc: 33.965,52.395,62.795,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 4.465 | Acc: 41.406,58.594,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.934 | Acc: 37.872,57.106,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.946 | Acc: 37.710,56.669,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.903 | Acc: 37.974,57.582,74.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.863 | Acc: 38.638,57.639,74.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.888 | Acc: 38.506,57.379,73.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.929 | Acc: 38.262,57.064,73.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.947 | Acc: 38.076,56.760,72.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.944 | Acc: 38.024,56.784,72.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.941 | Acc: 38.009,56.729,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.944 | Acc: 38.130,56.748,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.938 | Acc: 38.193,56.734,72.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.941 | Acc: 38.275,56.620,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.946 | Acc: 38.170,56.600,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.949 | Acc: 38.064,56.553,72.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.945 | Acc: 38.102,56.608,72.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.954 | Acc: 38.065,56.566,72.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.953 | Acc: 38.048,56.589,72.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.955 | Acc: 38.063,56.648,72.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.950 | Acc: 38.123,56.720,72.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.535 | Acc: 34.375,51.562,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.937 | Acc: 32.031,49.777,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.918 | Acc: 31.707,50.572,61.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.914 | Acc: 31.250,50.679,61.783,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 4.802 | Acc: 36.719,55.469,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.707 | Acc: 40.960,58.408,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.779 | Acc: 40.720,57.832,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.825 | Acc: 39.472,57.505,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.811 | Acc: 39.236,57.996,73.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.798 | Acc: 39.279,58.075,73.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.796 | Acc: 39.314,58.103,73.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.818 | Acc: 38.990,57.829,73.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.834 | Acc: 38.912,57.599,73.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.843 | Acc: 38.769,57.601,73.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.836 | Acc: 38.763,57.630,73.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.839 | Acc: 38.617,57.565,73.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.848 | Acc: 38.502,57.524,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.848 | Acc: 38.608,57.549,73.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.841 | Acc: 38.712,57.604,73.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.847 | Acc: 38.624,57.514,73.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.845 | Acc: 38.712,57.508,73.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.842 | Acc: 38.767,57.544,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.843 | Acc: 38.692,57.488,73.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.844 | Acc: 38.695,57.482,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.192 | Acc: 41.406,57.812,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.423 | Acc: 35.379,53.609,64.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.433 | Acc: 35.004,53.296,63.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.443 | Acc: 34.951,53.381,63.986,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 4.906 | Acc: 32.031,54.688,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.647 | Acc: 40.030,59.152,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.642 | Acc: 39.787,59.223,75.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 39.344,59.260,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.707 | Acc: 39.497,58.999,75.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.711 | Acc: 39.604,58.934,75.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.708 | Acc: 39.514,59.033,75.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.705 | Acc: 39.450,58.893,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.715 | Acc: 39.359,58.739,75.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.720 | Acc: 39.412,58.762,75.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.722 | Acc: 39.331,58.644,75.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.744 | Acc: 39.031,58.491,75.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.743 | Acc: 39.066,58.480,75.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.744 | Acc: 39.089,58.468,75.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.749 | Acc: 39.093,58.455,74.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.745 | Acc: 39.159,58.508,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.736 | Acc: 39.233,58.596,74.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.736 | Acc: 39.241,58.630,74.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.738 | Acc: 39.231,58.581,74.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.745 | Acc: 39.179,58.475,74.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.223 | Acc: 41.406,58.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.487 | Acc: 36.496,55.022,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.457 | Acc: 35.595,53.792,65.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.480 | Acc: 35.336,53.753,64.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 4.582 | Acc: 31.250,58.594,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.615 | Acc: 39.732,59.152,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.589 | Acc: 39.653,59.870,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 40.356,59.900,77.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.590 | Acc: 39.844,59.616,77.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.591 | Acc: 39.674,59.692,77.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.600 | Acc: 39.760,59.614,76.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.596 | Acc: 39.816,59.829,76.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.593 | Acc: 39.980,59.880,76.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.609 | Acc: 39.956,59.586,76.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.624 | Acc: 39.883,59.406,76.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.630 | Acc: 39.886,59.428,76.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.626 | Acc: 40.016,59.521,76.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.629 | Acc: 40.029,59.555,76.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.630 | Acc: 40.144,59.558,75.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.642 | Acc: 40.041,59.455,75.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.637 | Acc: 40.046,59.421,75.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.643 | Acc: 39.954,59.336,75.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.641 | Acc: 39.982,59.299,75.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.642 | Acc: 39.959,59.272,75.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.013 | Acc: 38.281,57.812,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.384 | Acc: 35.528,54.911,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.352 | Acc: 35.899,54.821,65.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.345 | Acc: 35.681,55.059,65.369,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 4.458 | Acc: 39.844,64.844,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.623 | Acc: 39.695,59.301,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.497 | Acc: 40.396,60.480,78.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.484 | Acc: 40.023,60.336,78.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.523 | Acc: 39.680,59.790,77.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.516 | Acc: 39.689,59.947,77.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.520 | Acc: 39.695,60.105,78.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.511 | Acc: 39.888,60.289,78.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.523 | Acc: 39.819,60.195,77.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.534 | Acc: 39.939,60.031,77.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.549 | Acc: 39.921,59.838,77.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.546 | Acc: 40.042,59.757,77.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.547 | Acc: 40.071,59.845,77.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.555 | Acc: 40.005,59.779,76.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.559 | Acc: 40.177,59.745,76.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.550 | Acc: 40.342,59.845,76.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.557 | Acc: 40.350,59.772,76.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.564 | Acc: 40.291,59.714,76.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.569 | Acc: 40.279,59.674,76.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.573 | Acc: 40.237,59.631,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.168 | Acc: 38.281,56.250,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.497 | Acc: 35.826,55.506,64.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.467 | Acc: 36.109,54.573,63.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.449 | Acc: 36.386,54.444,63.947,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 4.653 | Acc: 39.844,59.375,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.465 | Acc: 39.286,60.528,78.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.460 | Acc: 40.301,60.976,78.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.427 | Acc: 40.638,60.938,79.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.438 | Acc: 40.403,60.552,78.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.462 | Acc: 40.416,60.203,78.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.463 | Acc: 40.774,60.240,78.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.458 | Acc: 40.874,60.350,78.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.453 | Acc: 40.931,60.457,78.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.463 | Acc: 40.785,60.260,78.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.470 | Acc: 40.769,60.265,78.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.480 | Acc: 40.791,60.181,78.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.486 | Acc: 40.732,60.095,78.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.483 | Acc: 40.733,60.189,78.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.487 | Acc: 40.783,60.159,78.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.493 | Acc: 40.776,60.135,77.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.496 | Acc: 40.730,60.129,77.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.500 | Acc: 40.669,60.120,77.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.500 | Acc: 40.610,60.078,77.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.506 | Acc: 40.609,60.039,77.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.277 | Acc: 32.031,53.906,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.394 | Acc: 35.193,53.609,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.402 | Acc: 35.899,53.830,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.413 | Acc: 35.848,54.009,64.972,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 4.809 | Acc: 34.375,53.125,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.421 | Acc: 40.774,61.086,79.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.381 | Acc: 41.444,61.166,80.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.360 | Acc: 41.137,61.591,80.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.339 | Acc: 41.107,61.603,80.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.351 | Acc: 41.097,61.409,80.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.341 | Acc: 41.096,61.338,80.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.359 | Acc: 41.035,61.287,79.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.357 | Acc: 41.266,61.306,79.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.364 | Acc: 41.182,61.304,79.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.369 | Acc: 41.138,61.186,79.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.377 | Acc: 41.258,61.125,79.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.381 | Acc: 41.290,61.145,78.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.391 | Acc: 41.281,61.069,78.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.403 | Acc: 41.098,60.924,78.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.417 | Acc: 40.970,60.862,78.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.422 | Acc: 40.973,60.755,78.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.426 | Acc: 40.900,60.775,78.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.426 | Acc: 40.982,60.780,78.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.430 | Acc: 40.951,60.739,78.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.092 | Acc: 42.188,52.344,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.363 | Acc: 37.500,54.911,65.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.372 | Acc: 37.767,54.611,64.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.354 | Acc: 38.371,55.033,64.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 4.167 | Acc: 41.406,61.719,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.258 | Acc: 41.592,61.756,79.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.296 | Acc: 41.235,62.100,79.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.287 | Acc: 41.573,61.783,80.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.289 | Acc: 41.377,61.545,80.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.286 | Acc: 41.561,61.618,80.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.269 | Acc: 41.665,61.983,80.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.266 | Acc: 41.705,61.763,80.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.276 | Acc: 41.576,61.738,80.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.289 | Acc: 41.493,61.727,80.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.302 | Acc: 41.398,61.559,80.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.305 | Acc: 41.396,61.514,80.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.320 | Acc: 41.332,61.404,79.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.328 | Acc: 41.334,61.395,79.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.319 | Acc: 41.442,61.507,79.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.314 | Acc: 41.520,61.612,79.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.317 | Acc: 41.435,61.626,79.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.320 | Acc: 41.406,61.623,79.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.330 | Acc: 41.343,61.513,79.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.332 | Acc: 41.412,61.518,79.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.055 | Acc: 34.375,56.250,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.215 | Acc: 38.802,56.957,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.210 | Acc: 38.396,56.479,65.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.199 | Acc: 38.192,56.826,64.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 4.152 | Acc: 39.062,64.844,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.249 | Acc: 42.076,62.574,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.178 | Acc: 42.607,63.243,81.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.216 | Acc: 42.226,63.025,81.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.216 | Acc: 42.043,62.886,80.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.231 | Acc: 41.886,62.523,81.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.233 | Acc: 42.065,62.513,80.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.244 | Acc: 41.988,62.589,80.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.257 | Acc: 41.901,62.500,80.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.256 | Acc: 41.894,62.552,80.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.254 | Acc: 41.950,62.527,80.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.254 | Acc: 42.007,62.486,80.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.268 | Acc: 41.915,62.370,80.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.272 | Acc: 41.885,62.308,79.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.281 | Acc: 41.854,62.241,79.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.285 | Acc: 41.814,62.214,79.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.280 | Acc: 41.915,62.227,79.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.279 | Acc: 41.938,62.214,79.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.288 | Acc: 41.848,62.152,79.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.292 | Acc: 41.839,62.092,79.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.064 | Acc: 40.625,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.356 | Acc: 35.491,56.176,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.318 | Acc: 36.223,55.297,65.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.315 | Acc: 36.155,55.584,65.343,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 4.921 | Acc: 39.062,52.344,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.031 | Acc: 43.862,64.769,82.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.138 | Acc: 42.569,63.567,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.140 | Acc: 42.456,63.102,82.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.141 | Acc: 42.419,62.905,82.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.139 | Acc: 42.458,63.096,82.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.148 | Acc: 42.465,63.075,82.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.156 | Acc: 42.465,63.032,82.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.164 | Acc: 42.474,62.908,82.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.169 | Acc: 42.442,62.897,81.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.164 | Acc: 42.751,62.928,81.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.179 | Acc: 42.594,62.889,81.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.180 | Acc: 42.528,62.883,81.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.195 | Acc: 42.490,62.701,81.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.211 | Acc: 42.318,62.556,81.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.221 | Acc: 42.237,62.495,80.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.224 | Acc: 42.314,62.532,80.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.231 | Acc: 42.270,62.434,80.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.232 | Acc: 42.229,62.442,80.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.234 | Acc: 42.257,62.410,80.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.053 | Acc: 40.625,53.906,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.361 | Acc: 35.677,56.287,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.365 | Acc: 35.423,55.659,65.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.345 | Acc: 35.387,55.955,66.073,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 3.675 | Acc: 52.344,64.062,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.041 | Acc: 42.820,63.207,83.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.124 | Acc: 42.264,63.129,83.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.108 | Acc: 42.700,63.384,83.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.119 | Acc: 42.496,63.484,83.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.102 | Acc: 42.783,63.606,83.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.120 | Acc: 42.807,63.385,82.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.120 | Acc: 42.952,63.364,82.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.120 | Acc: 42.784,63.291,82.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.117 | Acc: 42.874,63.255,82.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.122 | Acc: 42.786,63.258,82.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.138 | Acc: 42.693,63.112,82.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.152 | Acc: 42.645,63.032,81.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.159 | Acc: 42.631,63.105,81.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.161 | Acc: 42.655,63.084,81.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.165 | Acc: 42.631,62.988,81.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.167 | Acc: 42.609,63.045,81.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.165 | Acc: 42.616,63.137,81.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.173 | Acc: 42.610,63.093,81.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.172 | Acc: 42.708,63.062,81.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.128 | Acc: 35.156,56.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.273 | Acc: 37.537,57.143,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.289 | Acc: 37.595,56.574,65.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.266 | Acc: 37.205,56.826,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 3.951 | Acc: 46.094,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.027 | Acc: 42.708,64.062,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.999 | Acc: 42.950,64.101,83.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.045 | Acc: 42.661,63.883,83.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.051 | Acc: 42.882,63.918,83.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.077 | Acc: 42.698,63.521,82.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.089 | Acc: 42.859,63.385,82.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.074 | Acc: 42.958,63.508,82.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.078 | Acc: 42.862,63.393,82.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.076 | Acc: 43.016,63.510,82.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.071 | Acc: 43.015,63.592,82.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.079 | Acc: 42.972,63.561,82.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.087 | Acc: 42.936,63.473,82.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.089 | Acc: 42.942,63.422,82.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.098 | Acc: 42.838,63.303,82.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.095 | Acc: 42.979,63.421,82.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.100 | Acc: 42.952,63.505,82.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.105 | Acc: 42.955,63.465,81.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.108 | Acc: 42.962,63.495,81.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.114 | Acc: 42.954,63.456,81.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.981 | Acc: 42.188,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.092 | Acc: 37.909,59.003,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.127 | Acc: 38.510,58.289,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.147 | Acc: 38.345,58.363,67.149,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 3.824 | Acc: 40.625,69.531,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.037 | Acc: 42.225,64.583,84.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.972 | Acc: 42.931,64.844,84.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.956 | Acc: 42.508,64.728,85.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.961 | Acc: 42.737,64.632,84.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.963 | Acc: 42.891,64.403,84.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.964 | Acc: 43.033,64.495,84.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.979 | Acc: 43.091,64.212,84.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.981 | Acc: 43.134,64.169,84.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.986 | Acc: 43.305,64.110,84.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.989 | Acc: 43.361,64.338,84.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.992 | Acc: 43.319,64.342,84.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.010 | Acc: 43.361,64.241,84.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.014 | Acc: 43.331,64.203,83.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.021 | Acc: 43.327,64.135,83.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.034 | Acc: 43.319,63.979,83.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.039 | Acc: 43.290,63.934,83.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.043 | Acc: 43.278,63.932,83.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.050 | Acc: 43.220,63.876,83.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.053 | Acc: 43.200,63.927,83.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.695 | Acc: 40.625,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.211 | Acc: 37.612,57.440,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.209 | Acc: 37.862,57.374,65.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.202 | Acc: 37.385,57.415,65.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 3.958 | Acc: 41.406,60.156,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.883 | Acc: 44.271,64.769,84.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.947 | Acc: 43.483,64.386,84.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.959 | Acc: 43.468,64.408,84.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.944 | Acc: 43.567,64.680,84.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.958 | Acc: 43.456,64.689,84.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.965 | Acc: 43.543,64.682,84.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.960 | Acc: 43.650,64.816,84.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.954 | Acc: 44.012,64.781,84.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.961 | Acc: 43.828,64.697,84.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.967 | Acc: 43.762,64.618,84.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.978 | Acc: 43.676,64.674,83.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.986 | Acc: 43.614,64.533,83.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.992 | Acc: 43.627,64.497,83.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.995 | Acc: 43.678,64.466,83.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.002 | Acc: 43.599,64.408,83.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.000 | Acc: 43.611,64.428,83.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.007 | Acc: 43.587,64.301,83.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.012 | Acc: 43.536,64.285,83.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.021 | Acc: 43.500,64.175,83.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.716 | Acc: 40.625,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.181 | Acc: 39.137,56.808,66.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.180 | Acc: 39.158,56.536,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.160 | Acc: 39.088,56.737,65.663,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 4.142 | Acc: 41.406,58.594,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.912 | Acc: 43.378,64.583,84.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.913 | Acc: 44.226,65.549,85.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.927 | Acc: 43.648,65.279,85.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.919 | Acc: 43.692,65.307,85.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.923 | Acc: 43.796,65.455,85.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.913 | Acc: 43.769,65.548,85.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.915 | Acc: 43.711,65.376,85.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.907 | Acc: 43.920,65.436,85.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.902 | Acc: 44.039,65.405,85.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.906 | Acc: 44.197,65.435,85.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.905 | Acc: 44.238,65.367,85.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.921 | Acc: 44.168,65.139,84.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.935 | Acc: 43.930,65.089,84.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.949 | Acc: 43.900,65.011,84.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.953 | Acc: 43.945,64.844,84.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.954 | Acc: 43.967,64.759,84.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.959 | Acc: 43.894,64.709,84.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.960 | Acc: 43.960,64.679,84.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.970 | Acc: 43.894,64.559,83.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.718 | Acc: 40.625,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.097 | Acc: 39.286,58.668,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.062 | Acc: 40.091,57.946,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.078 | Acc: 39.664,57.877,65.420,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 3.798 | Acc: 47.656,67.188,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.840 | Acc: 43.527,64.955,86.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.882 | Acc: 44.131,64.901,86.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.874 | Acc: 44.442,65.394,86.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.860 | Acc: 44.338,65.615,86.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.880 | Acc: 44.075,65.292,85.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.877 | Acc: 44.163,65.102,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.871 | Acc: 44.232,65.331,85.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.864 | Acc: 44.347,65.314,85.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.870 | Acc: 44.389,65.280,85.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.877 | Acc: 44.279,65.248,85.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.883 | Acc: 44.248,65.173,85.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.894 | Acc: 44.256,65.029,85.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.899 | Acc: 44.211,65.083,85.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.907 | Acc: 44.111,64.974,85.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.910 | Acc: 44.093,64.976,85.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.921 | Acc: 43.952,64.883,84.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.923 | Acc: 44.007,64.894,84.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.922 | Acc: 44.001,64.948,84.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.928 | Acc: 43.988,64.885,84.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.318 | Acc: 38.281,54.688,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.349 | Acc: 37.426,55.171,65.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.350 | Acc: 37.995,54.916,65.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.357 | Acc: 37.654,55.430,65.420,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 4.023 | Acc: 35.938,65.625,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.828 | Acc: 43.341,66.667,86.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.822 | Acc: 43.902,66.292,86.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.795 | Acc: 44.173,66.265,87.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.793 | Acc: 44.088,66.281,87.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.836 | Acc: 43.549,65.710,86.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.833 | Acc: 43.795,65.935,86.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.843 | Acc: 43.988,65.775,86.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.845 | Acc: 44.031,65.572,86.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.852 | Acc: 43.923,65.556,86.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.849 | Acc: 44.030,65.532,86.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.852 | Acc: 44.043,65.551,85.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.847 | Acc: 44.081,65.560,85.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.849 | Acc: 44.148,65.595,85.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.849 | Acc: 44.237,65.722,85.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.849 | Acc: 44.225,65.711,85.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.852 | Acc: 44.234,65.647,85.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.864 | Acc: 44.133,65.526,85.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.872 | Acc: 44.046,65.456,85.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.879 | Acc: 44.023,65.410,84.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.949 | Acc: 42.188,54.688,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.061 | Acc: 39.955,57.552,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.069 | Acc: 40.187,57.298,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.078 | Acc: 40.279,57.800,66.573,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 4.079 | Acc: 39.844,61.719,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.874 | Acc: 42.746,64.472,85.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.858 | Acc: 43.693,65.149,86.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.836 | Acc: 43.391,65.190,86.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.832 | Acc: 43.519,65.345,86.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.813 | Acc: 43.789,65.424,86.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.800 | Acc: 44.021,65.728,86.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.792 | Acc: 44.299,65.969,86.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.805 | Acc: 44.090,65.882,86.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.812 | Acc: 44.138,65.811,86.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.813 | Acc: 44.255,65.858,86.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.815 | Acc: 44.202,65.816,86.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.817 | Acc: 44.246,65.823,86.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.823 | Acc: 44.223,65.802,86.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.828 | Acc: 44.223,65.736,85.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.829 | Acc: 44.248,65.760,85.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.835 | Acc: 44.166,65.623,85.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.850 | Acc: 44.107,65.515,85.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.857 | Acc: 44.114,65.506,85.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.863 | Acc: 44.121,65.488,85.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.173 | Acc: 38.281,56.250,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.204 | Acc: 39.249,58.557,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.266 | Acc: 38.777,57.508,65.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.241 | Acc: 38.794,57.390,65.625,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 3.620 | Acc: 45.312,69.531,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.739 | Acc: 46.019,67.932,87.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.726 | Acc: 45.293,67.340,87.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.757 | Acc: 45.261,67.136,87.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.736 | Acc: 45.139,67.390,87.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.756 | Acc: 44.856,66.940,87.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.768 | Acc: 44.757,66.852,87.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.767 | Acc: 44.786,66.739,86.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.764 | Acc: 44.842,66.853,86.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.765 | Acc: 44.851,66.825,86.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.770 | Acc: 44.764,66.667,86.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.794 | Acc: 44.552,66.403,86.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.796 | Acc: 44.567,66.361,86.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.802 | Acc: 44.615,66.290,86.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.801 | Acc: 44.656,66.237,86.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.799 | Acc: 44.653,66.269,86.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.803 | Acc: 44.592,66.229,85.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.807 | Acc: 44.586,66.191,85.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.812 | Acc: 44.590,66.203,85.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.821 | Acc: 44.630,66.117,85.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.254 | Acc: 41.406,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.206 | Acc: 38.207,57.366,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.216 | Acc: 38.377,56.898,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.213 | Acc: 38.448,56.967,65.958,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 3.755 | Acc: 44.531,69.531,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.705 | Acc: 44.978,67.560,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.718 | Acc: 44.703,66.711,88.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.701 | Acc: 44.647,66.919,88.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.695 | Acc: 44.493,66.956,88.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.692 | Acc: 44.771,67.149,88.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.693 | Acc: 45.087,67.136,87.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.714 | Acc: 45.030,66.894,87.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.698 | Acc: 45.191,67.149,87.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.701 | Acc: 45.243,67.257,87.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.725 | Acc: 44.967,66.950,87.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.728 | Acc: 45.136,66.975,87.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.740 | Acc: 45.073,66.889,87.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.745 | Acc: 45.055,66.756,87.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.757 | Acc: 45.001,66.584,86.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.759 | Acc: 45.043,66.596,86.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.764 | Acc: 45.035,66.547,86.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.774 | Acc: 44.985,66.480,86.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.775 | Acc: 45.033,66.463,86.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.780 | Acc: 45.003,66.417,86.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.943 | Acc: 39.844,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.936 | Acc: 39.881,60.156,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.998 | Acc: 40.206,59.051,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.018 | Acc: 40.343,59.080,66.598,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 3.484 | Acc: 51.562,67.188,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.630 | Acc: 45.945,67.708,87.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.636 | Acc: 46.170,67.435,88.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.639 | Acc: 46.132,67.700,88.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.652 | Acc: 46.258,67.564,88.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.653 | Acc: 46.233,67.466,88.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.640 | Acc: 46.236,67.439,88.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.659 | Acc: 45.966,67.287,88.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.667 | Acc: 45.948,67.251,87.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.676 | Acc: 45.887,67.196,87.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.694 | Acc: 45.690,67.016,87.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.707 | Acc: 45.560,66.933,87.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.708 | Acc: 45.523,67.051,87.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.710 | Acc: 45.435,67.041,87.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.719 | Acc: 45.357,66.954,87.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.727 | Acc: 45.341,66.889,87.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.731 | Acc: 45.305,66.876,86.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.742 | Acc: 45.271,66.777,86.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.752 | Acc: 45.144,66.759,86.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.763 | Acc: 45.064,66.615,86.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.953 | Acc: 39.062,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.080 | Acc: 37.314,58.966,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.130 | Acc: 38.224,58.498,66.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.152 | Acc: 38.102,58.274,66.112,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 3.656 | Acc: 44.531,68.750,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.623 | Acc: 43.638,68.713,88.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.634 | Acc: 44.607,68.064,88.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.648 | Acc: 45.325,68.161,88.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.670 | Acc: 44.907,67.737,88.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.689 | Acc: 44.817,67.319,88.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.703 | Acc: 45.003,67.246,87.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.698 | Acc: 44.997,67.365,88.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.692 | Acc: 45.114,67.348,88.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.691 | Acc: 45.265,67.356,88.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.702 | Acc: 45.328,67.156,87.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.707 | Acc: 45.312,66.972,87.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.711 | Acc: 45.241,66.876,87.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.715 | Acc: 45.187,66.736,87.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.714 | Acc: 45.165,66.798,87.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.714 | Acc: 45.191,66.868,87.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.712 | Acc: 45.154,66.939,87.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.709 | Acc: 45.248,66.986,87.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.711 | Acc: 45.241,66.975,87.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.715 | Acc: 45.243,66.943,87.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.222 | Acc: 37.500,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.202 | Acc: 38.839,58.705,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.291 | Acc: 38.491,57.393,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.304 | Acc: 38.691,57.480,65.945,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 3.715 | Acc: 45.312,66.406,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.583 | Acc: 45.238,68.415,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.623 | Acc: 45.103,67.950,89.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.610 | Acc: 44.903,67.905,89.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.587 | Acc: 45.419,68.403,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.606 | Acc: 45.235,68.116,89.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.617 | Acc: 45.106,68.091,89.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.619 | Acc: 45.191,67.991,88.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.615 | Acc: 45.317,67.930,88.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.623 | Acc: 45.300,67.839,88.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.627 | Acc: 45.289,67.883,88.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.622 | Acc: 45.454,67.944,88.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.625 | Acc: 45.556,67.897,88.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.632 | Acc: 45.447,67.789,88.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.637 | Acc: 45.435,67.705,88.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.650 | Acc: 45.359,67.564,88.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.648 | Acc: 45.449,67.616,88.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.653 | Acc: 45.526,67.511,87.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.666 | Acc: 45.477,67.400,87.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.678 | Acc: 45.351,67.288,87.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.903 | Acc: 42.188,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.148 | Acc: 37.537,59.375,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.200 | Acc: 37.481,58.632,66.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.203 | Acc: 36.821,58.530,66.419,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.933 | Acc: 43.750,67.188,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.628 | Acc: 45.722,66.853,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.609 | Acc: 45.903,67.283,89.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.591 | Acc: 45.991,67.495,89.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.602 | Acc: 45.833,67.602,89.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.604 | Acc: 45.483,67.799,88.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.604 | Acc: 45.564,67.969,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.604 | Acc: 45.473,67.803,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.607 | Acc: 45.366,67.668,88.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.598 | Acc: 45.589,67.744,88.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.606 | Acc: 45.522,67.600,88.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.607 | Acc: 45.574,67.633,88.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.626 | Acc: 45.400,67.379,88.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.635 | Acc: 45.474,67.346,88.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.631 | Acc: 45.502,67.468,88.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.635 | Acc: 45.445,67.455,88.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.646 | Acc: 45.378,67.416,88.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.647 | Acc: 45.482,67.362,88.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.655 | Acc: 45.455,67.285,88.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.651 | Acc: 45.507,67.388,87.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.875 | Acc: 39.844,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.163 | Acc: 38.170,59.189,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.233 | Acc: 38.110,58.060,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.279 | Acc: 38.140,57.812,66.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 3.771 | Acc: 35.156,67.188,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.653 | Acc: 44.940,67.522,89.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.550 | Acc: 45.941,68.636,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.536 | Acc: 45.863,68.673,89.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.538 | Acc: 46.113,68.981,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.545 | Acc: 45.962,68.735,89.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.556 | Acc: 45.739,68.492,89.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.568 | Acc: 45.634,68.273,89.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.567 | Acc: 45.642,68.245,89.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.573 | Acc: 45.748,68.094,89.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.577 | Acc: 45.643,68.004,89.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.582 | Acc: 45.588,67.969,89.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.591 | Acc: 45.549,67.933,89.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.601 | Acc: 45.537,67.834,88.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.614 | Acc: 45.477,67.727,88.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.618 | Acc: 45.588,67.797,88.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.628 | Acc: 45.551,67.723,88.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.634 | Acc: 45.548,67.708,88.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.634 | Acc: 45.611,67.698,88.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.638 | Acc: 45.563,67.624,87.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.291 | Acc: 41.406,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.137 | Acc: 39.881,58.966,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.202 | Acc: 39.768,57.755,66.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.194 | Acc: 39.191,57.812,66.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 3.353 | Acc: 46.094,71.094,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.443 | Acc: 48.177,69.792,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.472 | Acc: 47.771,69.360,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.483 | Acc: 46.555,69.006,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.507 | Acc: 46.499,68.953,90.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.499 | Acc: 46.535,68.866,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.501 | Acc: 46.417,68.679,90.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.504 | Acc: 46.398,68.667,90.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.505 | Acc: 46.429,68.609,90.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.519 | Acc: 46.435,68.608,89.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.534 | Acc: 46.300,68.598,89.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.550 | Acc: 46.179,68.492,89.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.561 | Acc: 46.107,68.316,89.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.573 | Acc: 46.004,68.109,89.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.577 | Acc: 46.083,68.022,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.583 | Acc: 45.967,67.945,88.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.588 | Acc: 45.945,67.881,88.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.592 | Acc: 46.007,67.861,88.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.597 | Acc: 45.970,67.819,88.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.602 | Acc: 45.963,67.813,88.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.764 | Acc: 45.312,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.982 | Acc: 41.555,59.933,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.988 | Acc: 41.825,59.165,66.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.006 | Acc: 41.522,59.106,66.112,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 3.259 | Acc: 51.562,70.312,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.453 | Acc: 47.991,70.126,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.470 | Acc: 47.675,69.379,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.491 | Acc: 46.913,68.712,90.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.514 | Acc: 46.566,68.345,90.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.531 | Acc: 46.341,68.108,90.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.535 | Acc: 46.365,68.246,89.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.531 | Acc: 46.393,68.346,89.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.546 | Acc: 46.268,68.265,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.529 | Acc: 46.495,68.456,89.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.541 | Acc: 46.339,68.338,89.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.552 | Acc: 46.126,68.227,89.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.563 | Acc: 45.996,68.076,89.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.569 | Acc: 45.992,67.999,89.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.565 | Acc: 46.102,67.980,89.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.573 | Acc: 46.151,67.873,89.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.580 | Acc: 46.060,67.854,89.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.579 | Acc: 46.046,67.934,89.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.580 | Acc: 46.094,67.960,88.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.584 | Acc: 46.127,67.971,88.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.933 | Acc: 38.281,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.037 | Acc: 38.467,59.821,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.098 | Acc: 38.910,58.956,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.108 | Acc: 39.485,58.965,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 3.366 | Acc: 49.219,67.969,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.519 | Acc: 46.354,68.973,89.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.521 | Acc: 46.113,68.636,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.497 | Acc: 46.734,68.852,90.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.487 | Acc: 47.078,69.223,90.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.487 | Acc: 46.983,69.144,90.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.488 | Acc: 46.920,69.370,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.497 | Acc: 46.847,69.387,90.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.508 | Acc: 46.705,69.114,90.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.522 | Acc: 46.543,68.927,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.533 | Acc: 46.459,68.839,89.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.540 | Acc: 46.292,68.867,89.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.543 | Acc: 46.317,68.805,89.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.541 | Acc: 46.408,68.816,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.538 | Acc: 46.469,68.856,89.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.544 | Acc: 46.452,68.745,89.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.547 | Acc: 46.447,68.709,89.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.552 | Acc: 46.442,68.665,88.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.552 | Acc: 46.477,68.659,88.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.565 | Acc: 46.393,68.524,88.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.624 | Acc: 45.312,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.024 | Acc: 40.960,60.156,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.031 | Acc: 40.434,59.775,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.032 | Acc: 40.369,59.785,66.176,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 3.765 | Acc: 43.750,65.625,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.436 | Acc: 47.545,69.717,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.479 | Acc: 47.542,69.569,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.467 | Acc: 47.362,69.672,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.461 | Acc: 47.222,69.502,90.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.468 | Acc: 47.014,69.291,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.475 | Acc: 46.798,69.008,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.481 | Acc: 46.664,68.922,90.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.483 | Acc: 46.526,69.056,90.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.501 | Acc: 46.366,68.819,90.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.501 | Acc: 46.393,68.828,89.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.510 | Acc: 46.324,68.821,89.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.520 | Acc: 46.317,68.792,89.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.526 | Acc: 46.246,68.756,89.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.531 | Acc: 46.238,68.742,89.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.536 | Acc: 46.307,68.719,89.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.541 | Acc: 46.364,68.619,89.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.539 | Acc: 46.428,68.661,89.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.543 | Acc: 46.403,68.668,89.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.546 | Acc: 46.420,68.596,89.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.798 | Acc: 42.188,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.128 | Acc: 40.551,58.371,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.165 | Acc: 40.530,58.060,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.166 | Acc: 40.740,58.376,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 3.225 | Acc: 48.438,71.094,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.435 | Acc: 47.954,70.387,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.418 | Acc: 47.542,70.293,90.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.425 | Acc: 46.785,69.928,90.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.419 | Acc: 47.078,69.878,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.437 | Acc: 47.014,69.748,90.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.437 | Acc: 46.856,69.731,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.439 | Acc: 46.809,69.675,90.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.451 | Acc: 46.788,69.366,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.471 | Acc: 46.629,69.216,90.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.481 | Acc: 46.498,69.209,90.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.483 | Acc: 46.624,69.248,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.489 | Acc: 46.551,69.178,89.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.502 | Acc: 46.498,68.945,89.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.507 | Acc: 46.430,68.814,89.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.509 | Acc: 46.387,68.854,89.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.513 | Acc: 46.400,68.801,89.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.517 | Acc: 46.449,68.796,89.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.520 | Acc: 46.429,68.689,89.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.526 | Acc: 46.369,68.670,89.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.357 | Acc: 46.094,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.871 | Acc: 40.774,61.496,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.931 | Acc: 40.892,60.175,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.968 | Acc: 40.868,60.425,66.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 3.877 | Acc: 47.656,60.938,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.462 | Acc: 46.726,69.643,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.419 | Acc: 47.008,69.665,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.404 | Acc: 47.503,69.634,90.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.409 | Acc: 47.463,69.416,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.439 | Acc: 47.068,69.299,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.438 | Acc: 46.940,69.325,90.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.433 | Acc: 46.986,69.426,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.439 | Acc: 46.991,69.313,90.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.456 | Acc: 46.767,69.130,90.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.453 | Acc: 46.681,69.127,90.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.450 | Acc: 46.811,69.146,90.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.460 | Acc: 46.775,69.081,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.458 | Acc: 46.818,69.076,90.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.466 | Acc: 46.780,69.064,90.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.475 | Acc: 46.709,68.981,90.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.478 | Acc: 46.697,68.986,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.484 | Acc: 46.655,68.924,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.485 | Acc: 46.652,68.973,89.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.493 | Acc: 46.537,68.961,89.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.779 | Acc: 40.625,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.089 | Acc: 39.658,58.557,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.132 | Acc: 39.787,58.175,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.169 | Acc: 39.485,58.017,66.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 3.461 | Acc: 45.312,71.875,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.396 | Acc: 46.280,70.722,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.384 | Acc: 47.046,70.503,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.366 | Acc: 47.567,70.287,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.386 | Acc: 47.444,70.042,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.385 | Acc: 47.393,70.212,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.411 | Acc: 47.153,70.106,91.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.414 | Acc: 47.025,69.941,91.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.414 | Acc: 47.079,69.910,91.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.411 | Acc: 47.203,70.041,91.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.421 | Acc: 47.132,69.967,91.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.412 | Acc: 47.306,70.030,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.422 | Acc: 47.235,69.911,90.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.427 | Acc: 47.297,69.813,90.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.440 | Acc: 47.256,69.553,90.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.451 | Acc: 47.116,69.477,90.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.457 | Acc: 46.958,69.407,90.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.464 | Acc: 46.900,69.371,90.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.467 | Acc: 46.862,69.365,90.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.469 | Acc: 46.832,69.326,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.609 | Acc: 43.750,58.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.939 | Acc: 40.811,60.007,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.934 | Acc: 41.997,59.813,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.942 | Acc: 41.611,60.156,66.586,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 3.261 | Acc: 51.562,67.969,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.450 | Acc: 46.280,69.048,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.458 | Acc: 46.113,69.284,90.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.446 | Acc: 46.440,69.390,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.423 | Acc: 46.586,69.551,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.427 | Acc: 46.481,69.438,91.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.424 | Acc: 46.643,69.434,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.437 | Acc: 46.471,69.116,91.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.438 | Acc: 46.380,68.949,91.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.436 | Acc: 46.551,68.944,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.448 | Acc: 46.482,68.905,90.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.455 | Acc: 46.426,68.944,90.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.465 | Acc: 46.262,68.912,90.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.458 | Acc: 46.438,69.001,90.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.457 | Acc: 46.555,69.117,90.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.458 | Acc: 46.610,69.165,90.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.463 | Acc: 46.634,69.132,90.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.458 | Acc: 46.763,69.190,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.461 | Acc: 46.713,69.183,90.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.462 | Acc: 46.721,69.220,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.348 | Acc: 49.219,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.916 | Acc: 41.815,60.938,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.942 | Acc: 41.502,60.575,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.966 | Acc: 41.329,60.566,67.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 3.192 | Acc: 50.781,74.219,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.455 | Acc: 46.019,68.750,89.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.391 | Acc: 47.313,69.398,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.405 | Acc: 47.029,69.736,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.395 | Acc: 47.097,69.637,90.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.383 | Acc: 47.146,69.810,90.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.390 | Acc: 46.952,69.499,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.396 | Acc: 47.086,69.459,90.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.399 | Acc: 47.113,69.570,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.413 | Acc: 47.004,69.467,90.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.418 | Acc: 47.062,69.407,90.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.417 | Acc: 46.985,69.549,90.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.427 | Acc: 46.943,69.473,90.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.428 | Acc: 47.037,69.528,90.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.432 | Acc: 47.078,69.470,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.436 | Acc: 47.119,69.448,90.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.438 | Acc: 47.199,69.480,90.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.442 | Acc: 47.221,69.440,90.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.444 | Acc: 47.217,69.473,90.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.453 | Acc: 47.049,69.373,89.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.989 | Acc: 46.875,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.999 | Acc: 42.671,59.375,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.084 | Acc: 42.207,58.708,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.069 | Acc: 42.136,59.144,66.675,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 3.342 | Acc: 42.969,71.094,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.403 | Acc: 45.833,71.057,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.381 | Acc: 46.627,70.751,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.350 | Acc: 46.888,70.838,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.324 | Acc: 47.415,70.988,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.331 | Acc: 47.447,70.792,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.330 | Acc: 47.463,70.874,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.322 | Acc: 47.828,71.000,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.327 | Acc: 47.739,71.060,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.339 | Acc: 47.427,70.757,91.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.349 | Acc: 47.489,70.612,91.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.360 | Acc: 47.497,70.585,91.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.357 | Acc: 47.390,70.646,91.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.362 | Acc: 47.384,70.534,91.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.374 | Acc: 47.403,70.440,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.381 | Acc: 47.298,70.318,90.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.386 | Acc: 47.269,70.278,90.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.398 | Acc: 47.203,70.148,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.408 | Acc: 47.122,70.098,90.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.414 | Acc: 47.135,70.075,90.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.662 | Acc: 42.969,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.974 | Acc: 40.216,61.570,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.995 | Acc: 40.854,60.137,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.007 | Acc: 40.932,59.708,67.713,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 3.233 | Acc: 42.969,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.300 | Acc: 46.689,71.019,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.293 | Acc: 46.894,71.437,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.343 | Acc: 46.952,70.722,91.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.357 | Acc: 46.923,70.534,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.370 | Acc: 47.169,70.251,91.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.372 | Acc: 46.952,70.254,91.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.366 | Acc: 47.008,70.257,91.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.355 | Acc: 47.200,70.405,91.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.353 | Acc: 47.186,70.584,91.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.364 | Acc: 47.093,70.476,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.374 | Acc: 46.946,70.277,91.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.383 | Acc: 46.914,70.160,91.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.389 | Acc: 46.917,70.010,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.397 | Acc: 46.875,69.912,90.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.406 | Acc: 46.805,69.817,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.411 | Acc: 46.899,69.721,90.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.417 | Acc: 46.848,69.630,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.419 | Acc: 46.918,69.676,90.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.426 | Acc: 46.830,69.619,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.516 | Acc: 44.531,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.892 | Acc: 41.555,60.938,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.948 | Acc: 42.149,60.137,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.958 | Acc: 42.021,60.348,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 2.969 | Acc: 48.438,72.656,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.295 | Acc: 47.210,70.945,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.311 | Acc: 47.085,70.636,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.317 | Acc: 47.784,70.786,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.310 | Acc: 48.119,70.698,92.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.330 | Acc: 47.888,70.467,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.335 | Acc: 47.927,70.493,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.335 | Acc: 47.850,70.523,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.345 | Acc: 47.729,70.414,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.346 | Acc: 47.794,70.425,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.361 | Acc: 47.656,70.398,91.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.368 | Acc: 47.617,70.383,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.372 | Acc: 47.598,70.332,90.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.372 | Acc: 47.507,70.348,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.377 | Acc: 47.514,70.285,90.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.376 | Acc: 47.571,70.344,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.385 | Acc: 47.462,70.186,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.397 | Acc: 47.413,70.129,90.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.399 | Acc: 47.360,70.074,90.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.404 | Acc: 47.347,70.027,90.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.387 | Acc: 50.781,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.862 | Acc: 42.560,61.570,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.896 | Acc: 43.216,60.309,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.915 | Acc: 42.802,60.387,67.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 3.056 | Acc: 45.312,75.000,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.325 | Acc: 47.024,72.768,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.340 | Acc: 47.046,71.970,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.343 | Acc: 46.849,71.440,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.327 | Acc: 47.357,71.412,91.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.344 | Acc: 47.285,70.962,91.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.342 | Acc: 47.366,71.107,91.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.351 | Acc: 47.246,70.994,91.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.343 | Acc: 47.302,71.002,91.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.334 | Acc: 47.501,71.120,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.343 | Acc: 47.520,70.973,91.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.350 | Acc: 47.568,70.928,91.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.354 | Acc: 47.627,70.857,91.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.355 | Acc: 47.680,70.833,91.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.352 | Acc: 47.762,70.902,91.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.358 | Acc: 47.755,70.907,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.363 | Acc: 47.746,70.794,90.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.369 | Acc: 47.654,70.704,90.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.374 | Acc: 47.615,70.628,90.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.381 | Acc: 47.484,70.600,90.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.587 | Acc: 49.219,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.846 | Acc: 43.601,59.859,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.921 | Acc: 43.369,59.108,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.922 | Acc: 43.366,59.375,66.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 3.573 | Acc: 41.406,69.531,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.302 | Acc: 47.954,70.238,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.259 | Acc: 48.514,71.056,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.267 | Acc: 48.399,71.247,92.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.277 | Acc: 48.322,71.364,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.289 | Acc: 48.113,71.295,92.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.301 | Acc: 47.927,71.197,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.308 | Acc: 47.883,70.950,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.309 | Acc: 47.884,70.832,92.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.311 | Acc: 47.816,70.839,91.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.310 | Acc: 47.808,70.927,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.316 | Acc: 47.921,70.917,91.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.315 | Acc: 47.951,70.896,91.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.319 | Acc: 47.920,70.851,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.325 | Acc: 47.859,70.816,91.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.329 | Acc: 47.848,70.754,91.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.335 | Acc: 47.868,70.656,91.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.341 | Acc: 47.794,70.606,91.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.347 | Acc: 47.745,70.516,91.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.354 | Acc: 47.638,70.477,91.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.804 | Acc: 44.531,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.020 | Acc: 40.588,61.458,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.975 | Acc: 41.063,61.204,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.974 | Acc: 40.984,61.053,67.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 3.089 | Acc: 52.344,69.531,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.316 | Acc: 46.949,72.061,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 47.199,71.475,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.286 | Acc: 47.157,71.580,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.297 | Acc: 47.357,71.470,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.283 | Acc: 47.772,71.318,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.281 | Acc: 47.837,71.404,92.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.284 | Acc: 47.850,71.349,92.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.288 | Acc: 47.724,71.230,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.288 | Acc: 47.777,71.176,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.294 | Acc: 47.796,71.047,92.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.297 | Acc: 47.780,71.076,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.298 | Acc: 47.809,70.980,91.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.298 | Acc: 47.878,70.986,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.303 | Acc: 47.879,70.988,91.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.308 | Acc: 47.942,70.943,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.321 | Acc: 47.880,70.824,91.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.329 | Acc: 47.830,70.748,91.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.338 | Acc: 47.726,70.665,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.344 | Acc: 47.734,70.632,91.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.869 | Acc: 44.531,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.130 | Acc: 39.881,60.863,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.179 | Acc: 39.806,60.271,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.234 | Acc: 39.447,59.862,66.086,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 3.214 | Acc: 46.875,71.094,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.236 | Acc: 48.103,72.321,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.203 | Acc: 48.323,72.256,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.253 | Acc: 48.092,71.593,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.240 | Acc: 48.351,71.595,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.255 | Acc: 48.058,71.310,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.260 | Acc: 48.057,71.268,92.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.265 | Acc: 48.055,71.243,91.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.275 | Acc: 47.797,71.244,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.276 | Acc: 47.812,71.335,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.289 | Acc: 47.726,71.234,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.299 | Acc: 47.681,71.175,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.302 | Acc: 47.672,71.081,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.307 | Acc: 47.722,71.100,91.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.314 | Acc: 47.659,71.122,91.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.328 | Acc: 47.529,70.933,91.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.333 | Acc: 47.552,70.848,91.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.338 | Acc: 47.549,70.849,91.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.344 | Acc: 47.494,70.763,91.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.347 | Acc: 47.488,70.735,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.571 | Acc: 41.406,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.961 | Acc: 42.374,61.421,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.036 | Acc: 42.359,60.042,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.037 | Acc: 42.098,60.348,66.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.284 | Acc: 44.531,67.188,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.184 | Acc: 49.777,73.363,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.162 | Acc: 50.210,73.095,92.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.165 | Acc: 49.693,72.810,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.169 | Acc: 49.624,72.608,93.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.200 | Acc: 49.196,72.076,92.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.202 | Acc: 49.148,72.114,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.213 | Acc: 48.903,71.997,92.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.229 | Acc: 48.535,71.671,92.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.234 | Acc: 48.558,71.664,92.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.247 | Acc: 48.519,71.615,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.254 | Acc: 48.508,71.529,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.254 | Acc: 48.525,71.528,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.265 | Acc: 48.393,71.468,92.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.279 | Acc: 48.340,71.322,91.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.288 | Acc: 48.282,71.164,91.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.293 | Acc: 48.284,71.174,91.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.299 | Acc: 48.160,71.117,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.309 | Acc: 48.119,70.996,91.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.321 | Acc: 48.038,70.862,91.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.855 | Acc: 41.406,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.049 | Acc: 39.993,59.635,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.072 | Acc: 40.796,59.318,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.105 | Acc: 40.932,59.670,66.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 3.151 | Acc: 52.344,72.656,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.214 | Acc: 47.507,72.842,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.216 | Acc: 47.809,72.294,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.210 | Acc: 48.322,72.477,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.225 | Acc: 48.052,72.029,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.227 | Acc: 48.321,71.852,93.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.247 | Acc: 47.992,71.436,93.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.261 | Acc: 47.972,71.349,92.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.252 | Acc: 48.156,71.530,92.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.255 | Acc: 48.299,71.586,92.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.269 | Acc: 48.107,71.444,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.275 | Acc: 48.027,71.341,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.277 | Acc: 48.091,71.330,92.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.281 | Acc: 48.021,71.273,92.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.286 | Acc: 47.926,71.249,92.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.290 | Acc: 47.952,71.133,92.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.296 | Acc: 47.783,71.167,91.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.295 | Acc: 47.940,71.224,91.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.303 | Acc: 47.959,71.167,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.309 | Acc: 47.988,71.086,91.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.571 | Acc: 42.969,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.850 | Acc: 42.671,62.054,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.890 | Acc: 42.264,61.204,67.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.902 | Acc: 42.072,61.475,67.482,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 3.599 | Acc: 48.438,67.969,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.160 | Acc: 48.549,73.214,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.188 | Acc: 48.361,73.056,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.209 | Acc: 48.297,72.464,93.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.223 | Acc: 48.052,72.000,93.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.217 | Acc: 48.151,72.231,93.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.212 | Acc: 48.379,72.321,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.212 | Acc: 48.471,72.207,93.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.220 | Acc: 48.214,72.103,93.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.234 | Acc: 48.230,71.879,92.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.246 | Acc: 48.169,71.723,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.260 | Acc: 48.215,71.596,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.268 | Acc: 48.207,71.463,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.270 | Acc: 48.216,71.387,92.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.279 | Acc: 48.118,71.325,92.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.282 | Acc: 48.108,71.366,91.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.282 | Acc: 48.158,71.286,91.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.280 | Acc: 48.218,71.302,91.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.286 | Acc: 48.165,71.273,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.293 | Acc: 48.146,71.168,91.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.313 | Acc: 49.219,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.899 | Acc: 42.225,61.905,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.887 | Acc: 42.111,60.957,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.906 | Acc: 42.546,61.206,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 3.392 | Acc: 44.531,68.750,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.203 | Acc: 47.954,71.949,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.204 | Acc: 47.923,71.989,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.227 | Acc: 47.298,71.427,93.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.243 | Acc: 47.434,71.171,92.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.241 | Acc: 47.625,71.272,92.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.240 | Acc: 47.456,71.326,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.245 | Acc: 47.623,71.498,92.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.256 | Acc: 47.540,71.487,92.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.248 | Acc: 47.786,71.504,92.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.256 | Acc: 47.816,71.412,92.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.258 | Acc: 47.872,71.451,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.257 | Acc: 48.045,71.522,92.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.263 | Acc: 47.991,71.459,92.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.267 | Acc: 48.034,71.439,92.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.277 | Acc: 47.939,71.371,92.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.281 | Acc: 47.968,71.340,92.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.278 | Acc: 48.055,71.325,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.280 | Acc: 48.115,71.343,91.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.285 | Acc: 48.128,71.289,91.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.638 | Acc: 40.625,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.997 | Acc: 41.518,60.045,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.047 | Acc: 42.264,59.413,66.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.051 | Acc: 42.072,59.900,65.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 2.943 | Acc: 48.438,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.140 | Acc: 48.698,73.475,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.178 | Acc: 49.181,73.114,93.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.208 | Acc: 48.732,72.707,93.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.225 | Acc: 48.399,72.473,93.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.214 | Acc: 48.368,72.386,93.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.225 | Acc: 48.547,72.269,93.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.233 | Acc: 48.360,72.302,93.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.242 | Acc: 48.438,72.336,92.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.238 | Acc: 48.498,72.333,92.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.239 | Acc: 48.531,72.108,92.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.250 | Acc: 48.476,71.939,92.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.258 | Acc: 48.499,71.813,92.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.259 | Acc: 48.473,71.710,92.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.259 | Acc: 48.549,71.569,92.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.265 | Acc: 48.461,71.519,92.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.268 | Acc: 48.484,71.473,92.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.270 | Acc: 48.355,71.511,91.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.272 | Acc: 48.336,71.492,91.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.277 | Acc: 48.290,71.436,91.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.893 | Acc: 40.625,56.250,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.965 | Acc: 41.741,60.454,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.009 | Acc: 41.921,59.966,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.003 | Acc: 41.816,59.849,67.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 3.123 | Acc: 50.781,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.196 | Acc: 48.921,72.247,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.140 | Acc: 49.333,73.190,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.138 | Acc: 49.091,73.002,93.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.160 | Acc: 48.544,72.704,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.163 | Acc: 48.507,72.594,93.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.174 | Acc: 48.470,72.430,93.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.181 | Acc: 48.604,72.313,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.189 | Acc: 48.515,72.292,93.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.181 | Acc: 48.610,72.389,92.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.188 | Acc: 48.733,72.384,92.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.187 | Acc: 48.819,72.366,92.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.194 | Acc: 48.762,72.313,92.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.201 | Acc: 48.791,72.237,92.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.210 | Acc: 48.682,72.147,92.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.219 | Acc: 48.604,72.026,92.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.232 | Acc: 48.537,71.902,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.235 | Acc: 48.554,71.919,92.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.242 | Acc: 48.498,71.819,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.245 | Acc: 48.493,71.791,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.771 | Acc: 41.406,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.128 | Acc: 41.592,59.077,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.158 | Acc: 41.959,58.346,65.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.131 | Acc: 41.483,58.594,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 3.247 | Acc: 49.219,72.656,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.252 | Acc: 48.958,72.433,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.248 | Acc: 47.923,71.932,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.213 | Acc: 48.284,72.029,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.212 | Acc: 48.254,72.193,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.195 | Acc: 48.438,72.239,92.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.196 | Acc: 48.496,72.269,92.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.198 | Acc: 48.537,72.357,92.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.203 | Acc: 48.481,72.205,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.222 | Acc: 48.416,71.957,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.224 | Acc: 48.406,72.007,92.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.222 | Acc: 48.579,72.101,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.224 | Acc: 48.600,72.031,92.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.227 | Acc: 48.686,72.004,92.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.231 | Acc: 48.713,71.906,92.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.235 | Acc: 48.705,71.891,92.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.235 | Acc: 48.705,71.860,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.236 | Acc: 48.669,71.868,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.237 | Acc: 48.632,71.856,92.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.238 | Acc: 48.655,71.850,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.570 | Acc: 47.656,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.830 | Acc: 42.225,61.124,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.885 | Acc: 42.283,60.861,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.930 | Acc: 41.675,60.643,68.033,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 3.007 | Acc: 46.875,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.108 | Acc: 48.921,72.284,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.127 | Acc: 48.933,72.561,92.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.131 | Acc: 48.527,72.554,93.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.110 | Acc: 48.727,72.762,93.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.126 | Acc: 48.786,72.873,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.121 | Acc: 49.077,73.011,93.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.138 | Acc: 48.809,72.773,93.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.152 | Acc: 48.724,72.622,93.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.159 | Acc: 48.809,72.501,93.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.165 | Acc: 48.834,72.474,93.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.177 | Acc: 48.862,72.299,92.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.189 | Acc: 48.839,72.154,92.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.194 | Acc: 48.827,72.138,92.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.200 | Acc: 48.710,72.097,92.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.207 | Acc: 48.635,72.051,92.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.212 | Acc: 48.618,72.011,92.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.219 | Acc: 48.504,72.003,92.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.228 | Acc: 48.466,71.881,92.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.236 | Acc: 48.446,71.738,91.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.886 | Acc: 37.500,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.095 | Acc: 41.071,61.310,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.150 | Acc: 41.063,60.728,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.155 | Acc: 40.971,60.451,66.650,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 2.828 | Acc: 51.562,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.097 | Acc: 49.814,73.028,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.106 | Acc: 49.829,73.361,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.153 | Acc: 49.180,72.631,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.177 | Acc: 48.929,72.598,92.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.197 | Acc: 48.855,72.517,92.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.205 | Acc: 48.960,72.198,92.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.213 | Acc: 48.947,72.058,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.214 | Acc: 48.811,72.137,92.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.209 | Acc: 48.787,72.311,92.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.211 | Acc: 48.787,72.217,92.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.209 | Acc: 48.717,72.264,92.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.211 | Acc: 48.742,72.219,92.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.203 | Acc: 48.845,72.288,92.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.206 | Acc: 48.846,72.303,92.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.211 | Acc: 48.829,72.275,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.212 | Acc: 48.861,72.243,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.223 | Acc: 48.719,72.097,92.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.236 | Acc: 48.615,71.938,91.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.244 | Acc: 48.442,71.842,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.783 | Acc: 40.625,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.832 | Acc: 43.043,62.872,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.867 | Acc: 43.159,61.528,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.915 | Acc: 43.251,61.168,66.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 3.096 | Acc: 52.344,73.438,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.126 | Acc: 48.810,73.549,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.131 | Acc: 48.990,73.476,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.154 | Acc: 49.027,73.002,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.162 | Acc: 48.872,73.090,92.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.175 | Acc: 48.739,72.765,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.177 | Acc: 48.915,72.818,92.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.177 | Acc: 48.759,72.867,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.187 | Acc: 48.695,72.899,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.181 | Acc: 48.774,72.868,92.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.185 | Acc: 48.698,72.816,92.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.185 | Acc: 48.791,72.713,92.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.189 | Acc: 48.794,72.747,92.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.190 | Acc: 48.872,72.638,92.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.191 | Acc: 48.846,72.620,92.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.196 | Acc: 48.850,72.591,92.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.200 | Acc: 48.742,72.486,92.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.215 | Acc: 48.612,72.310,92.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.220 | Acc: 48.546,72.215,92.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.225 | Acc: 48.503,72.213,91.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.205 | Acc: 45.312,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.968 | Acc: 42.411,60.119,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.965 | Acc: 42.397,59.851,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.979 | Acc: 42.469,60.143,67.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 3.291 | Acc: 50.781,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.097 | Acc: 49.702,74.256,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.145 | Acc: 48.590,73.571,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.154 | Acc: 48.322,73.489,93.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.151 | Acc: 48.708,73.389,93.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.153 | Acc: 48.546,73.321,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.132 | Acc: 49.051,73.386,93.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.148 | Acc: 48.958,73.100,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.155 | Acc: 48.947,72.865,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.169 | Acc: 48.813,72.695,92.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.165 | Acc: 48.978,72.785,92.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.169 | Acc: 49.035,72.670,92.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.176 | Acc: 48.943,72.617,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.177 | Acc: 48.964,72.692,92.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.184 | Acc: 48.927,72.626,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.193 | Acc: 48.845,72.521,92.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.192 | Acc: 48.912,72.476,92.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.198 | Acc: 48.825,72.370,92.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.207 | Acc: 48.797,72.265,92.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.213 | Acc: 48.798,72.207,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.314 | Acc: 48.438,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.881 | Acc: 41.220,61.012,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.906 | Acc: 41.768,60.766,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.905 | Acc: 42.354,61.206,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 3.607 | Acc: 40.625,61.719,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.103 | Acc: 50.670,73.698,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.116 | Acc: 49.657,73.552,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.118 | Acc: 49.526,73.348,93.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.132 | Acc: 49.508,73.158,92.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.134 | Acc: 49.296,73.229,93.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.124 | Acc: 49.464,73.212,93.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.140 | Acc: 49.219,73.050,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.154 | Acc: 49.209,73.035,93.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.165 | Acc: 49.072,72.773,92.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.182 | Acc: 48.951,72.703,92.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.185 | Acc: 48.996,72.639,92.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.191 | Acc: 48.992,72.504,92.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.194 | Acc: 48.997,72.444,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.189 | Acc: 49.174,72.517,92.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.193 | Acc: 49.247,72.464,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.196 | Acc: 49.192,72.386,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.202 | Acc: 49.125,72.322,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.206 | Acc: 49.108,72.187,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.214 | Acc: 49.057,72.092,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.643 | Acc: 47.656,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.001 | Acc: 43.676,61.161,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.106 | Acc: 42.054,59.966,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.127 | Acc: 41.624,59.477,66.586,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 3.410 | Acc: 49.219,69.531,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.124 | Acc: 49.182,73.065,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.101 | Acc: 49.714,73.457,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.120 | Acc: 49.488,73.450,93.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.129 | Acc: 49.470,73.245,93.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.134 | Acc: 49.196,73.028,93.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.142 | Acc: 49.128,72.740,93.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.154 | Acc: 48.881,72.645,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.150 | Acc: 49.000,72.705,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.163 | Acc: 48.873,72.583,93.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.172 | Acc: 48.710,72.505,93.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.174 | Acc: 48.660,72.469,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.174 | Acc: 48.716,72.478,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.182 | Acc: 48.632,72.477,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.183 | Acc: 48.615,72.456,92.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.180 | Acc: 48.746,72.490,92.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.183 | Acc: 48.793,72.469,92.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.187 | Acc: 48.772,72.416,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.190 | Acc: 48.745,72.451,92.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.189 | Acc: 48.821,72.451,92.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.577 | Acc: 43.750,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.060 | Acc: 42.039,60.454,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.063 | Acc: 41.921,60.194,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.054 | Acc: 42.008,60.092,65.984,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 3.094 | Acc: 51.562,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.075 | Acc: 50.558,75.223,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.075 | Acc: 49.829,74.600,93.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.060 | Acc: 49.782,74.565,93.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.056 | Acc: 49.981,74.373,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.067 | Acc: 49.899,74.157,93.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.079 | Acc: 49.826,73.993,93.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.084 | Acc: 49.734,73.897,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.094 | Acc: 49.500,73.607,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.107 | Acc: 49.422,73.450,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.117 | Acc: 49.246,73.449,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.117 | Acc: 49.307,73.370,93.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.127 | Acc: 49.164,73.175,93.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.135 | Acc: 49.042,73.057,93.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.140 | Acc: 49.110,73.020,93.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.146 | Acc: 49.105,72.996,92.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.154 | Acc: 49.029,72.875,92.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.162 | Acc: 48.987,72.844,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.168 | Acc: 48.940,72.803,92.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.176 | Acc: 48.915,72.734,92.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.787 | Acc: 42.969,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.138 | Acc: 40.402,60.342,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.215 | Acc: 40.682,59.108,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.226 | Acc: 40.599,59.029,66.214,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 2.895 | Acc: 48.438,74.219,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.101 | Acc: 50.595,74.479,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.106 | Acc: 50.133,73.742,93.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.081 | Acc: 50.179,73.899,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.112 | Acc: 49.865,73.621,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.106 | Acc: 49.899,73.453,93.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.110 | Acc: 49.587,73.476,93.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.104 | Acc: 49.629,73.487,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.113 | Acc: 49.568,73.350,93.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.124 | Acc: 49.478,73.265,93.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.119 | Acc: 49.510,73.371,93.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.110 | Acc: 49.650,73.526,93.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.119 | Acc: 49.660,73.386,93.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.122 | Acc: 49.698,73.414,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.127 | Acc: 49.461,73.385,92.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.128 | Acc: 49.504,73.422,92.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.137 | Acc: 49.474,73.301,92.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.142 | Acc: 49.478,73.273,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.152 | Acc: 49.390,73.219,92.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.162 | Acc: 49.252,73.075,92.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.674 | Acc: 40.625,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.912 | Acc: 41.555,61.198,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.968 | Acc: 41.635,60.842,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.989 | Acc: 41.765,60.707,67.328,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 2.653 | Acc: 52.344,74.219,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.133 | Acc: 49.107,73.512,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.092 | Acc: 50.152,73.399,92.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.078 | Acc: 50.205,73.617,93.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.084 | Acc: 49.894,73.476,93.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.092 | Acc: 49.644,73.461,93.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.101 | Acc: 49.774,73.399,93.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.110 | Acc: 49.623,73.510,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.117 | Acc: 49.617,73.481,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.120 | Acc: 49.698,73.351,93.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.121 | Acc: 49.697,73.235,93.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.120 | Acc: 49.650,73.123,93.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.127 | Acc: 49.462,73.052,93.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.138 | Acc: 49.309,72.997,93.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.136 | Acc: 49.397,73.079,92.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.142 | Acc: 49.390,72.988,92.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.145 | Acc: 49.445,72.992,92.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.147 | Acc: 49.423,72.959,92.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.162 | Acc: 49.243,72.825,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.168 | Acc: 49.170,72.736,92.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.457 | Acc: 45.312,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.989 | Acc: 42.336,60.826,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.066 | Acc: 41.902,59.775,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.059 | Acc: 41.931,59.849,67.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 2.708 | Acc: 57.812,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.103 | Acc: 49.516,74.479,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.099 | Acc: 50.133,74.009,93.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.075 | Acc: 49.923,74.475,93.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.061 | Acc: 50.029,74.498,94.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.072 | Acc: 49.954,74.126,94.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.072 | Acc: 49.780,74.128,93.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.073 | Acc: 49.640,74.113,93.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.089 | Acc: 49.539,73.777,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.088 | Acc: 49.568,73.800,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.095 | Acc: 49.685,73.663,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.097 | Acc: 49.682,73.699,93.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.104 | Acc: 49.653,73.574,93.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.107 | Acc: 49.704,73.548,93.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.118 | Acc: 49.605,73.362,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.130 | Acc: 49.530,73.219,93.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.135 | Acc: 49.491,73.209,92.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.137 | Acc: 49.432,73.229,92.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.145 | Acc: 49.336,73.104,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.151 | Acc: 49.338,72.978,92.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.365 | Acc: 45.312,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.017 | Acc: 40.551,62.500,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.031 | Acc: 40.911,61.052,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.037 | Acc: 40.394,60.963,66.995,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 3.126 | Acc: 48.438,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.102 | Acc: 48.921,73.549,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.068 | Acc: 49.486,73.933,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.069 | Acc: 49.565,73.963,94.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.079 | Acc: 49.740,74.142,93.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.083 | Acc: 49.768,74.064,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.095 | Acc: 49.477,73.960,93.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.093 | Acc: 49.596,73.892,93.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.105 | Acc: 49.427,73.753,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.110 | Acc: 49.353,73.614,93.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.115 | Acc: 49.180,73.542,93.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.119 | Acc: 49.159,73.452,93.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.124 | Acc: 49.144,73.392,93.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.117 | Acc: 49.318,73.429,93.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.117 | Acc: 49.344,73.368,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.125 | Acc: 49.271,73.201,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.132 | Acc: 49.343,73.162,92.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.142 | Acc: 49.308,73.055,92.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.149 | Acc: 49.275,72.953,92.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.161 | Acc: 49.202,72.853,92.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.542 | Acc: 44.531,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.892 | Acc: 42.411,61.533,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.949 | Acc: 42.530,60.194,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.964 | Acc: 42.649,60.079,66.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 3.401 | Acc: 36.719,70.312,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.089 | Acc: 49.368,74.033,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.057 | Acc: 50.610,74.638,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.051 | Acc: 50.628,74.462,93.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.051 | Acc: 50.289,74.479,94.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.045 | Acc: 50.348,74.729,94.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.043 | Acc: 50.439,74.884,94.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.047 | Acc: 50.371,74.596,94.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.050 | Acc: 50.417,74.583,94.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.057 | Acc: 50.263,74.499,93.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.065 | Acc: 50.155,74.230,93.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.073 | Acc: 50.007,74.130,93.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.083 | Acc: 49.893,73.901,93.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.096 | Acc: 49.811,73.728,93.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.106 | Acc: 49.655,73.557,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.109 | Acc: 49.683,73.572,93.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.119 | Acc: 49.618,73.515,93.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.122 | Acc: 49.604,73.525,92.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.138 | Acc: 49.396,73.334,92.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.145 | Acc: 49.344,73.286,92.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.980 | Acc: 42.969,59.375,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.184 | Acc: 41.778,58.705,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.245 | Acc: 41.502,58.289,65.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.256 | Acc: 41.124,58.632,65.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 3.103 | Acc: 50.781,68.750,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.121 | Acc: 49.182,73.251,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.050 | Acc: 49.848,74.085,93.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.053 | Acc: 50.026,74.039,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.064 | Acc: 49.711,73.756,93.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.063 | Acc: 49.606,73.878,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.070 | Acc: 49.406,73.786,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.073 | Acc: 49.402,73.842,93.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.078 | Acc: 49.403,73.777,93.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.081 | Acc: 49.396,73.757,93.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.091 | Acc: 49.300,73.581,93.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.104 | Acc: 49.219,73.476,93.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.100 | Acc: 49.381,73.483,93.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.107 | Acc: 49.464,73.458,93.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.113 | Acc: 49.399,73.362,93.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.117 | Acc: 49.408,73.300,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.121 | Acc: 49.469,73.267,93.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.129 | Acc: 49.473,73.119,92.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.137 | Acc: 49.409,73.046,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.142 | Acc: 49.387,72.972,92.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.317 | Acc: 44.531,67.188,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.923 | Acc: 41.964,61.421,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.953 | Acc: 41.959,60.861,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.999 | Acc: 41.944,60.797,67.508,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 3.140 | Acc: 49.219,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.128 | Acc: 49.777,73.810,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.107 | Acc: 49.771,73.361,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.091 | Acc: 50.038,73.233,93.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.079 | Acc: 50.019,73.515,93.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.085 | Acc: 50.062,73.530,93.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.070 | Acc: 50.387,73.722,93.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.069 | Acc: 50.427,73.526,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.077 | Acc: 50.262,73.491,93.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.085 | Acc: 50.009,73.494,93.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.089 | Acc: 49.833,73.581,93.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.090 | Acc: 49.844,73.529,93.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.091 | Acc: 49.734,73.541,93.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.103 | Acc: 49.548,73.455,93.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.107 | Acc: 49.447,73.418,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.111 | Acc: 49.411,73.396,93.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.112 | Acc: 49.418,73.347,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.119 | Acc: 49.427,73.307,92.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.121 | Acc: 49.502,73.284,92.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.126 | Acc: 49.504,73.241,92.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.065 | Acc: 47.656,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.794 | Acc: 43.787,61.682,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.827 | Acc: 43.731,61.071,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.839 | Acc: 43.455,60.899,67.994,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 3.167 | Acc: 51.562,70.312,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.067 | Acc: 50.298,73.772,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.076 | Acc: 50.057,73.571,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.059 | Acc: 50.077,73.847,93.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.054 | Acc: 49.875,74.277,94.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.065 | Acc: 49.683,73.940,94.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.061 | Acc: 49.697,74.083,94.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.077 | Acc: 49.607,74.019,93.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.080 | Acc: 49.728,73.966,93.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.082 | Acc: 49.758,73.999,93.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.089 | Acc: 49.677,73.857,93.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.092 | Acc: 49.629,73.784,93.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.095 | Acc: 49.608,73.690,93.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.097 | Acc: 49.599,73.677,93.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.098 | Acc: 49.636,73.682,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.100 | Acc: 49.761,73.749,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.104 | Acc: 49.769,73.678,93.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.107 | Acc: 49.707,73.625,93.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.110 | Acc: 49.649,73.593,93.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.115 | Acc: 49.610,73.528,93.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.298 | Acc: 46.875,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.741 | Acc: 45.015,63.058,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.796 | Acc: 44.665,62.176,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.794 | Acc: 44.634,61.949,68.353,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 2.821 | Acc: 52.344,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.006 | Acc: 50.967,73.586,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.982 | Acc: 51.181,74.371,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.964 | Acc: 51.101,74.705,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.993 | Acc: 50.907,74.354,94.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.006 | Acc: 50.859,74.420,94.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.017 | Acc: 50.710,74.193,94.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.036 | Acc: 50.371,74.130,93.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.040 | Acc: 50.378,73.976,93.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.044 | Acc: 50.414,73.934,93.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.060 | Acc: 50.260,73.830,93.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.066 | Acc: 50.152,73.872,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.068 | Acc: 50.146,73.911,93.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.071 | Acc: 50.111,73.919,93.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.078 | Acc: 50.103,73.860,93.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.084 | Acc: 50.031,73.835,93.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.088 | Acc: 49.990,73.822,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.095 | Acc: 49.888,73.747,93.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.102 | Acc: 49.870,73.658,93.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.104 | Acc: 49.850,73.665,92.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 50.781,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.840 | Acc: 43.936,61.607,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.872 | Acc: 43.998,61.357,66.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.878 | Acc: 44.109,61.373,66.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 2.946 | Acc: 52.344,71.094,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.011 | Acc: 51.637,76.228,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.025 | Acc: 50.400,75.133,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.058 | Acc: 49.590,74.846,93.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.059 | Acc: 49.527,74.730,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.055 | Acc: 49.497,74.667,93.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.050 | Acc: 49.477,74.587,93.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.058 | Acc: 49.418,74.363,93.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.055 | Acc: 49.520,74.204,93.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.045 | Acc: 49.715,74.344,93.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.040 | Acc: 49.751,74.401,93.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.044 | Acc: 49.795,74.342,93.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.058 | Acc: 49.744,74.251,93.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.062 | Acc: 49.835,74.168,93.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.071 | Acc: 49.711,74.046,93.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.080 | Acc: 49.694,73.933,93.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.085 | Acc: 49.657,73.851,93.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.091 | Acc: 49.588,73.820,93.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.093 | Acc: 49.541,73.788,92.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.098 | Acc: 49.594,73.735,92.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.720 | Acc: 47.656,64.844,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.915 | Acc: 44.754,59.747,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.938 | Acc: 44.017,60.213,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.969 | Acc: 43.712,60.220,65.868,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 3.423 | Acc: 46.094,70.312,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.014 | Acc: 49.777,73.735,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.013 | Acc: 50.114,75.324,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.025 | Acc: 49.744,74.872,94.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.010 | Acc: 49.672,75.039,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.021 | Acc: 49.660,74.930,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.011 | Acc: 49.890,74.935,94.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.004 | Acc: 50.089,74.873,94.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.012 | Acc: 50.262,74.675,94.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.018 | Acc: 50.168,74.590,94.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.021 | Acc: 50.214,74.448,94.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.029 | Acc: 50.092,74.339,94.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.042 | Acc: 49.925,74.170,94.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.050 | Acc: 49.964,74.126,93.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.053 | Acc: 49.919,74.063,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.060 | Acc: 49.930,74.068,93.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.068 | Acc: 49.900,74.061,93.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.077 | Acc: 49.798,73.944,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.085 | Acc: 49.742,73.842,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.100 | Acc: 49.672,73.624,93.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.313 | Acc: 48.438,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.847 | Acc: 43.118,61.942,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.932 | Acc: 42.854,60.499,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.937 | Acc: 42.456,60.656,67.713,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 2.736 | Acc: 51.562,75.000,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.997 | Acc: 51.265,74.702,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.010 | Acc: 50.152,74.905,93.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.991 | Acc: 50.461,75.115,94.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.989 | Acc: 50.289,75.087,94.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.976 | Acc: 50.627,75.317,94.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.978 | Acc: 50.581,75.316,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.984 | Acc: 50.515,75.238,94.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.001 | Acc: 50.432,74.971,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.012 | Acc: 50.332,74.953,94.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.022 | Acc: 50.257,74.837,94.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.026 | Acc: 50.177,74.763,93.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.035 | Acc: 50.058,74.624,93.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.048 | Acc: 50.006,74.476,93.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.052 | Acc: 50.025,74.430,93.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.059 | Acc: 49.979,74.297,93.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.065 | Acc: 49.954,74.187,93.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.076 | Acc: 49.872,74.061,93.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.079 | Acc: 49.788,74.000,93.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.088 | Acc: 49.764,73.874,93.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.914 | Acc: 43.750,60.938,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.973 | Acc: 41.704,60.268,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.029 | Acc: 41.940,59.585,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.044 | Acc: 42.213,59.951,66.637,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 2.734 | Acc: 57.812,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.035 | Acc: 52.195,73.810,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.998 | Acc: 52.039,74.581,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 51.358,74.821,93.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.993 | Acc: 51.379,74.932,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.011 | Acc: 51.067,74.451,93.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.017 | Acc: 50.923,74.316,94.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.030 | Acc: 50.698,74.269,94.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.038 | Acc: 50.417,74.185,93.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.043 | Acc: 50.414,74.089,93.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.044 | Acc: 50.400,74.149,93.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.043 | Acc: 50.346,74.254,93.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.047 | Acc: 50.347,74.154,93.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.058 | Acc: 50.293,73.982,93.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.064 | Acc: 50.325,73.966,93.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.071 | Acc: 50.215,73.853,93.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.076 | Acc: 50.321,73.771,93.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.078 | Acc: 50.321,73.779,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.080 | Acc: 50.277,73.827,93.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.082 | Acc: 50.209,73.835,93.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.441 | Acc: 46.094,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.130 | Acc: 40.216,60.714,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.116 | Acc: 40.873,60.366,66.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.089 | Acc: 40.817,60.694,66.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 2.912 | Acc: 53.906,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.933 | Acc: 50.112,76.525,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.949 | Acc: 49.771,76.086,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.961 | Acc: 50.141,75.717,94.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.985 | Acc: 50.000,75.270,94.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.995 | Acc: 50.217,75.278,94.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.993 | Acc: 50.200,75.239,94.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.986 | Acc: 50.587,75.177,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.992 | Acc: 50.534,75.010,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.993 | Acc: 50.574,75.022,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.009 | Acc: 50.408,74.810,94.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.008 | Acc: 50.569,74.791,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.017 | Acc: 50.399,74.695,93.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.026 | Acc: 50.186,74.569,93.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.038 | Acc: 50.031,74.438,93.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.054 | Acc: 49.886,74.271,93.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.065 | Acc: 49.761,74.090,93.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.065 | Acc: 49.824,74.116,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.070 | Acc: 49.829,74.115,93.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.073 | Acc: 49.789,74.071,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.617 | Acc: 46.875,67.969,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.988 | Acc: 43.043,60.677,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.035 | Acc: 42.969,60.347,65.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.054 | Acc: 42.905,60.028,65.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 3.029 | Acc: 50.781,75.000,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.947 | Acc: 51.600,76.451,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.993 | Acc: 50.648,75.343,94.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.994 | Acc: 50.858,75.231,94.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.984 | Acc: 51.003,75.347,94.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.012 | Acc: 50.325,74.985,94.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.999 | Acc: 50.562,75.155,94.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.011 | Acc: 50.377,75.033,93.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.015 | Acc: 50.257,74.820,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.024 | Acc: 50.035,74.676,93.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.027 | Acc: 50.206,74.553,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.037 | Acc: 50.148,74.335,93.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.038 | Acc: 50.071,74.277,93.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.040 | Acc: 50.024,74.315,93.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.047 | Acc: 50.064,74.199,93.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.058 | Acc: 49.979,74.006,93.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.068 | Acc: 49.954,73.856,93.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.074 | Acc: 49.954,73.779,93.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.080 | Acc: 49.892,73.762,92.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.081 | Acc: 49.869,73.718,92.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.541 | Acc: 48.438,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.817 | Acc: 44.792,61.979,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.845 | Acc: 44.569,61.185,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.848 | Acc: 44.647,61.437,67.956,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 2.890 | Acc: 57.031,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.067 | Acc: 49.628,74.256,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.034 | Acc: 49.638,74.600,93.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.032 | Acc: 49.641,74.436,93.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.036 | Acc: 49.643,74.296,93.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.029 | Acc: 49.899,74.366,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.020 | Acc: 50.077,74.451,93.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.009 | Acc: 50.122,74.662,93.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.007 | Acc: 50.306,74.573,93.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.007 | Acc: 50.354,74.620,93.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.012 | Acc: 50.264,74.506,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.013 | Acc: 50.265,74.558,93.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.018 | Acc: 50.188,74.540,93.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.025 | Acc: 50.230,74.518,93.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.026 | Acc: 50.328,74.494,93.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.029 | Acc: 50.254,74.421,93.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.032 | Acc: 50.277,74.340,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.038 | Acc: 50.186,74.276,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.043 | Acc: 50.119,74.188,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.051 | Acc: 50.072,74.133,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.973 | Acc: 43.750,63.281,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.953 | Acc: 42.262,61.570,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.988 | Acc: 42.359,60.232,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.985 | Acc: 42.328,60.361,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 3.239 | Acc: 47.656,70.312,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.022 | Acc: 49.777,75.000,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.008 | Acc: 50.057,75.305,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.996 | Acc: 50.064,75.461,93.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.995 | Acc: 50.068,75.154,94.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.985 | Acc: 50.108,75.170,94.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.980 | Acc: 50.194,75.026,94.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.978 | Acc: 50.238,75.083,94.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.984 | Acc: 50.214,75.029,94.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.993 | Acc: 50.181,74.918,94.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.002 | Acc: 50.031,74.775,93.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.012 | Acc: 50.018,74.664,93.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.023 | Acc: 49.971,74.481,93.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.026 | Acc: 49.979,74.365,93.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.027 | Acc: 50.058,74.352,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.042 | Acc: 49.992,74.159,93.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.049 | Acc: 50.010,74.104,93.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.055 | Acc: 49.961,73.997,93.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.052 | Acc: 50.067,74.035,93.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.059 | Acc: 50.025,73.950,93.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.303 | Acc: 47.656,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.715 | Acc: 44.754,62.574,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.744 | Acc: 44.779,62.424,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.743 | Acc: 44.249,62.180,68.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 2.886 | Acc: 46.875,75.000,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.914 | Acc: 50.670,76.042,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.914 | Acc: 50.324,76.181,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.936 | Acc: 50.320,75.768,94.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.951 | Acc: 50.338,75.675,94.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.966 | Acc: 49.977,75.441,94.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.982 | Acc: 49.832,75.168,94.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.979 | Acc: 50.011,75.199,94.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.987 | Acc: 49.995,74.918,94.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.995 | Acc: 49.996,74.853,94.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.995 | Acc: 50.070,74.883,94.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.004 | Acc: 49.968,74.756,93.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.013 | Acc: 49.854,74.673,93.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.022 | Acc: 49.871,74.548,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.027 | Acc: 49.950,74.536,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.031 | Acc: 49.888,74.486,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.039 | Acc: 49.800,74.384,93.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.043 | Acc: 49.778,74.301,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.043 | Acc: 49.788,74.286,93.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.046 | Acc: 49.803,74.274,93.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.533 | Acc: 50.781,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.816 | Acc: 44.196,63.207,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.880 | Acc: 44.150,61.947,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.888 | Acc: 43.993,62.013,67.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 2.600 | Acc: 57.031,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.905 | Acc: 52.046,76.637,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.927 | Acc: 51.524,76.029,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.947 | Acc: 51.345,75.640,94.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.959 | Acc: 51.022,74.932,94.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.946 | Acc: 51.238,75.193,94.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.957 | Acc: 50.988,75.071,94.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.964 | Acc: 51.097,75.017,94.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.974 | Acc: 51.024,74.922,94.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.984 | Acc: 50.833,74.793,93.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.998 | Acc: 50.731,74.631,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.000 | Acc: 50.841,74.650,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.004 | Acc: 50.616,74.569,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.010 | Acc: 50.518,74.566,93.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.015 | Acc: 50.442,74.519,93.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.023 | Acc: 50.345,74.416,93.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.032 | Acc: 50.280,74.314,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.038 | Acc: 50.208,74.214,93.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.041 | Acc: 50.117,74.191,93.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.044 | Acc: 50.129,74.174,93.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.316 | Acc: 49.219,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.870 | Acc: 43.490,61.496,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.890 | Acc: 43.598,60.880,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.890 | Acc: 43.916,61.117,67.546,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 3.099 | Acc: 46.094,75.781,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.909 | Acc: 52.121,75.967,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.979 | Acc: 51.029,75.724,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.946 | Acc: 51.153,75.961,94.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.935 | Acc: 51.331,75.839,94.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.951 | Acc: 50.936,75.634,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.951 | Acc: 50.814,75.484,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.962 | Acc: 50.471,75.288,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.970 | Acc: 50.315,75.320,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.973 | Acc: 50.453,75.216,94.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.978 | Acc: 50.486,75.190,94.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.982 | Acc: 50.509,75.141,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.987 | Acc: 50.502,75.117,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.994 | Acc: 50.560,75.069,93.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.996 | Acc: 50.553,75.042,93.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.003 | Acc: 50.491,74.878,93.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.009 | Acc: 50.472,74.825,93.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.018 | Acc: 50.406,74.716,93.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.026 | Acc: 50.392,74.613,93.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.030 | Acc: 50.367,74.551,93.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.609 | Acc: 44.531,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.801 | Acc: 43.973,62.649,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.852 | Acc: 43.502,61.852,67.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.875 | Acc: 43.276,61.757,67.623,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 2.834 | Acc: 57.031,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.995 | Acc: 50.446,76.190,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.990 | Acc: 50.324,75.667,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.972 | Acc: 50.730,75.615,94.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.966 | Acc: 50.598,75.685,94.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.957 | Acc: 50.866,75.410,94.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.956 | Acc: 50.885,75.368,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.955 | Acc: 50.837,75.460,94.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.964 | Acc: 50.830,75.456,94.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.978 | Acc: 50.557,75.259,94.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.986 | Acc: 50.447,75.074,94.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.987 | Acc: 50.470,75.103,94.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.989 | Acc: 50.389,74.977,93.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.996 | Acc: 50.353,74.886,93.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.013 | Acc: 50.114,74.747,93.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.024 | Acc: 50.013,74.652,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.033 | Acc: 49.988,74.521,93.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.035 | Acc: 50.016,74.464,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.041 | Acc: 50.017,74.418,93.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.046 | Acc: 50.018,74.395,93.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.534 | Acc: 50.000,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.889 | Acc: 41.778,62.128,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.950 | Acc: 42.264,61.223,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.959 | Acc: 42.367,61.527,66.150,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 2.836 | Acc: 51.562,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.900 | Acc: 51.637,76.860,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.945 | Acc: 51.239,76.315,94.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.977 | Acc: 50.589,75.897,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.967 | Acc: 50.280,75.801,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.952 | Acc: 50.758,75.719,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.953 | Acc: 50.717,75.801,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.963 | Acc: 50.543,75.687,94.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.961 | Acc: 50.510,75.655,94.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.956 | Acc: 50.686,75.630,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.962 | Acc: 50.606,75.575,94.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.976 | Acc: 50.569,75.460,94.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.983 | Acc: 50.538,75.428,93.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.990 | Acc: 50.494,75.311,93.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.997 | Acc: 50.520,75.253,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.004 | Acc: 50.524,75.099,93.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.011 | Acc: 50.496,74.963,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.016 | Acc: 50.456,74.950,93.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.027 | Acc: 50.439,74.797,93.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.027 | Acc: 50.453,74.791,93.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.564 | Acc: 44.531,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.934 | Acc: 44.420,60.863,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.003 | Acc: 44.550,60.518,65.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.986 | Acc: 44.442,60.733,66.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 3.066 | Acc: 59.375,75.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.029 | Acc: 50.521,75.074,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.967 | Acc: 50.762,75.648,93.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.940 | Acc: 51.191,76.076,93.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.939 | Acc: 50.897,75.936,94.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.934 | Acc: 51.006,75.928,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.936 | Acc: 51.014,75.814,94.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.950 | Acc: 51.269,75.665,94.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.966 | Acc: 51.092,75.471,94.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.966 | Acc: 50.928,75.466,94.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.966 | Acc: 50.906,75.466,94.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.978 | Acc: 50.643,75.247,94.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.992 | Acc: 50.502,75.065,93.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.998 | Acc: 50.443,75.075,93.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.005 | Acc: 50.450,74.903,93.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.010 | Acc: 50.428,74.821,93.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.013 | Acc: 50.438,74.781,93.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.022 | Acc: 50.318,74.613,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.027 | Acc: 50.292,74.502,93.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.032 | Acc: 50.236,74.524,93.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.442 | Acc: 43.750,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.785 | Acc: 43.155,62.091,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.835 | Acc: 43.502,61.833,67.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.840 | Acc: 43.327,61.834,67.623,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 3.013 | Acc: 50.000,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.036 | Acc: 50.074,76.004,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 50.724,76.162,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.940 | Acc: 50.832,76.281,94.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.929 | Acc: 51.119,76.244,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.920 | Acc: 51.207,76.539,94.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.921 | Acc: 51.091,76.524,94.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.929 | Acc: 51.119,76.269,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.938 | Acc: 50.990,76.063,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.948 | Acc: 50.846,75.881,94.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.951 | Acc: 50.863,75.808,94.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.963 | Acc: 50.824,75.615,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.965 | Acc: 50.778,75.554,94.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.965 | Acc: 50.901,75.524,94.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.974 | Acc: 50.884,75.381,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.981 | Acc: 50.789,75.260,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.997 | Acc: 50.667,75.044,93.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.006 | Acc: 50.690,74.959,93.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.009 | Acc: 50.673,74.929,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.014 | Acc: 50.656,74.889,93.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.430 | Acc: 43.750,62.500,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.880 | Acc: 42.299,61.942,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.953 | Acc: 42.302,61.433,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.977 | Acc: 42.290,61.296,67.136,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 3.186 | Acc: 53.125,75.781,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.940 | Acc: 49.963,75.521,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.904 | Acc: 51.220,76.258,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.925 | Acc: 50.346,76.550,94.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.935 | Acc: 50.492,76.148,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.962 | Acc: 50.441,75.557,94.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.965 | Acc: 50.426,75.400,94.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.962 | Acc: 50.549,75.327,94.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.953 | Acc: 50.645,75.505,94.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.952 | Acc: 50.626,75.531,94.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.955 | Acc: 50.630,75.490,94.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.963 | Acc: 50.527,75.385,94.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.966 | Acc: 50.454,75.314,94.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.975 | Acc: 50.332,75.204,94.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.978 | Acc: 50.417,75.150,94.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.986 | Acc: 50.382,75.034,94.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.992 | Acc: 50.353,75.012,93.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.997 | Acc: 50.396,75.000,93.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.001 | Acc: 50.387,74.957,93.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.004 | Acc: 50.404,74.961,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.423 | Acc: 43.750,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.810 | Acc: 43.341,62.165,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.841 | Acc: 43.845,62.195,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.833 | Acc: 44.006,61.898,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.543 | Acc: 60.156,76.562,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.898 | Acc: 51.228,75.856,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.921 | Acc: 50.705,75.819,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.914 | Acc: 50.948,76.217,94.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.912 | Acc: 50.858,76.273,94.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.905 | Acc: 51.044,76.354,94.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.910 | Acc: 51.033,76.272,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.921 | Acc: 50.831,76.247,94.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.926 | Acc: 50.602,76.063,94.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.926 | Acc: 50.790,75.893,94.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.933 | Acc: 50.692,75.762,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.939 | Acc: 50.658,75.626,94.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.944 | Acc: 50.661,75.554,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.950 | Acc: 50.703,75.542,94.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.955 | Acc: 50.553,75.545,94.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.969 | Acc: 50.431,75.366,93.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.973 | Acc: 50.484,75.309,93.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.983 | Acc: 50.417,75.133,93.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.987 | Acc: 50.405,75.102,93.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.998 | Acc: 50.371,75.012,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.113 | Acc: 50.781,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.644 | Acc: 46.652,63.728,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.695 | Acc: 46.189,63.072,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.738 | Acc: 45.607,62.602,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 3.099 | Acc: 46.094,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 51.823,75.298,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 51.181,75.591,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.943 | Acc: 51.370,75.704,94.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.941 | Acc: 50.762,75.666,94.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.926 | Acc: 51.276,75.750,94.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.935 | Acc: 51.143,75.620,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.940 | Acc: 51.008,75.626,94.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.951 | Acc: 51.082,75.558,94.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.962 | Acc: 50.932,75.509,94.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.965 | Acc: 50.948,75.490,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.963 | Acc: 51.036,75.587,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.972 | Acc: 50.917,75.395,94.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.978 | Acc: 50.886,75.314,93.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.983 | Acc: 50.809,75.264,93.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.989 | Acc: 50.698,75.260,93.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.997 | Acc: 50.608,75.197,93.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.001 | Acc: 50.577,75.121,93.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.006 | Acc: 50.569,75.061,93.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.008 | Acc: 50.564,75.094,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.503 | Acc: 46.875,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.963 | Acc: 43.006,61.161,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.986 | Acc: 43.674,60.385,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.982 | Acc: 43.635,60.643,67.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 3.174 | Acc: 52.344,75.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.932 | Acc: 51.414,75.930,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.933 | Acc: 51.677,75.972,94.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.906 | Acc: 51.921,75.909,94.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.917 | Acc: 51.505,75.492,94.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.937 | Acc: 51.230,75.580,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.938 | Acc: 51.085,75.484,94.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.940 | Acc: 50.992,75.543,94.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.944 | Acc: 51.068,75.602,94.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.943 | Acc: 51.148,75.604,94.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.948 | Acc: 51.007,75.649,94.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.960 | Acc: 50.866,75.392,94.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.972 | Acc: 50.778,75.243,93.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.976 | Acc: 50.754,75.192,93.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.980 | Acc: 50.854,75.136,93.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.988 | Acc: 50.818,75.042,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.001 | Acc: 50.604,74.920,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.010 | Acc: 50.564,74.801,93.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.013 | Acc: 50.556,74.779,93.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.012 | Acc: 50.634,74.772,93.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.332 | Acc: 50.781,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.742 | Acc: 45.908,62.686,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.778 | Acc: 46.227,61.814,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.774 | Acc: 46.094,62.052,67.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.776 | Acc: 55.469,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.925 | Acc: 52.009,76.190,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.877 | Acc: 52.382,76.677,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.852 | Acc: 52.523,77.228,94.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.875 | Acc: 51.370,76.910,94.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.878 | Acc: 51.477,76.756,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.875 | Acc: 51.511,76.698,94.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.891 | Acc: 51.324,76.418,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.893 | Acc: 51.155,76.431,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.904 | Acc: 51.196,76.390,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.916 | Acc: 51.127,76.329,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.931 | Acc: 51.039,76.068,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.940 | Acc: 50.985,75.914,94.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.949 | Acc: 50.982,75.847,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.955 | Acc: 50.945,75.687,93.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.967 | Acc: 50.833,75.506,93.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.975 | Acc: 50.806,75.453,93.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.980 | Acc: 50.822,75.380,93.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.987 | Acc: 50.794,75.303,93.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.996 | Acc: 50.687,75.228,93.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.343 | Acc: 46.094,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.848 | Acc: 45.387,61.905,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.882 | Acc: 45.274,61.280,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.896 | Acc: 44.992,61.399,66.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.379 | Acc: 58.594,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.932 | Acc: 50.260,76.414,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.929 | Acc: 50.629,76.029,94.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.946 | Acc: 50.768,76.063,94.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.915 | Acc: 51.186,76.437,94.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.917 | Acc: 51.199,76.183,94.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.915 | Acc: 51.201,76.156,94.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.911 | Acc: 51.042,76.147,94.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.917 | Acc: 50.970,76.082,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.921 | Acc: 51.075,75.984,94.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.937 | Acc: 50.812,75.688,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.939 | Acc: 50.855,75.580,94.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.930 | Acc: 51.005,75.700,94.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.943 | Acc: 50.901,75.575,94.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.952 | Acc: 50.834,75.514,94.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.954 | Acc: 50.846,75.483,94.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.955 | Acc: 50.842,75.487,93.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.958 | Acc: 50.868,75.415,93.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.966 | Acc: 50.805,75.266,93.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.972 | Acc: 50.771,75.205,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.219 | Acc: 45.312,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.777 | Acc: 43.676,63.095,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.829 | Acc: 43.121,62.005,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.835 | Acc: 42.892,62.090,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 2.927 | Acc: 53.906,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.843 | Acc: 52.009,78.795,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.914 | Acc: 50.781,77.591,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.860 | Acc: 51.217,77.766,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.855 | Acc: 51.620,77.672,94.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.864 | Acc: 51.555,77.336,94.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.873 | Acc: 51.369,76.976,94.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.897 | Acc: 51.020,76.618,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.902 | Acc: 51.043,76.398,94.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.920 | Acc: 50.937,76.140,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.919 | Acc: 51.158,76.189,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.926 | Acc: 51.160,76.011,94.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.936 | Acc: 51.154,75.840,94.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.953 | Acc: 50.994,75.641,94.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.954 | Acc: 51.015,75.684,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.962 | Acc: 50.916,75.594,93.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.967 | Acc: 50.925,75.550,93.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.973 | Acc: 50.857,75.438,93.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.973 | Acc: 50.799,75.444,93.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.980 | Acc: 50.787,75.371,93.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.247 | Acc: 47.656,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.713 | Acc: 45.573,63.542,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.725 | Acc: 45.522,62.691,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.713 | Acc: 45.569,62.500,68.276,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 2.718 | Acc: 53.906,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.851 | Acc: 51.972,76.897,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.876 | Acc: 51.543,76.753,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.896 | Acc: 51.460,76.652,94.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.887 | Acc: 51.669,76.582,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.893 | Acc: 51.493,76.431,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.913 | Acc: 51.052,76.246,94.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.917 | Acc: 50.898,76.114,94.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.924 | Acc: 50.966,76.053,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.929 | Acc: 50.898,76.019,94.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.926 | Acc: 51.084,76.022,94.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.921 | Acc: 51.195,75.909,94.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.929 | Acc: 51.154,75.823,94.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.940 | Acc: 51.116,75.778,94.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.947 | Acc: 51.048,75.703,93.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.950 | Acc: 51.046,75.662,93.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.952 | Acc: 51.076,75.674,93.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.964 | Acc: 50.965,75.570,93.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.968 | Acc: 50.980,75.485,93.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.972 | Acc: 50.999,75.445,93.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.321 | Acc: 46.094,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.807 | Acc: 44.531,61.533,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.905 | Acc: 44.493,60.633,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.927 | Acc: 44.070,60.873,66.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 2.871 | Acc: 50.781,79.688,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.913 | Acc: 51.153,77.158,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.897 | Acc: 51.048,76.848,94.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.876 | Acc: 50.730,77.113,94.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.870 | Acc: 50.887,76.890,94.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.878 | Acc: 50.905,76.825,94.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.880 | Acc: 50.872,76.685,94.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.896 | Acc: 50.787,76.396,94.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.891 | Acc: 50.961,76.402,94.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.909 | Acc: 50.773,76.157,94.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.924 | Acc: 50.665,75.995,94.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.923 | Acc: 50.951,75.979,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.921 | Acc: 51.109,76.002,94.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.926 | Acc: 51.134,75.934,94.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.934 | Acc: 51.051,75.829,94.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.937 | Acc: 51.020,75.815,94.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.940 | Acc: 50.961,75.769,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.949 | Acc: 50.880,75.662,93.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.952 | Acc: 50.902,75.617,93.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.962 | Acc: 50.851,75.500,93.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.499 | Acc: 42.969,67.188,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.003 | Acc: 43.155,61.384,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.089 | Acc: 42.321,60.556,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.112 | Acc: 41.855,60.848,66.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 2.799 | Acc: 53.125,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.930 | Acc: 50.595,75.967,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.928 | Acc: 50.133,75.877,94.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.906 | Acc: 50.602,76.294,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.916 | Acc: 50.772,76.042,94.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.893 | Acc: 50.859,76.385,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.884 | Acc: 51.194,76.543,94.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.893 | Acc: 51.130,76.490,94.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.897 | Acc: 51.053,76.504,94.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.904 | Acc: 51.036,76.355,94.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.911 | Acc: 50.987,76.205,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.913 | Acc: 50.863,76.082,94.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.917 | Acc: 50.872,76.079,94.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.920 | Acc: 50.901,76.021,94.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.921 | Acc: 50.887,76.001,94.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.923 | Acc: 50.919,75.950,94.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.927 | Acc: 50.978,75.857,94.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.936 | Acc: 50.942,75.822,93.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.946 | Acc: 50.900,75.742,93.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.953 | Acc: 50.912,75.681,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.526 | Acc: 46.875,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.933 | Acc: 45.052,61.235,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.040 | Acc: 44.798,60.156,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.034 | Acc: 44.544,60.387,66.022,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 3.071 | Acc: 53.125,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.898 | Acc: 52.232,76.190,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 51.048,76.200,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.911 | Acc: 51.524,76.511,94.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.894 | Acc: 51.495,76.659,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.900 | Acc: 51.377,76.524,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.882 | Acc: 51.795,76.814,94.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.892 | Acc: 51.457,76.662,94.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.897 | Acc: 51.465,76.504,94.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.901 | Acc: 51.575,76.381,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.901 | Acc: 51.407,76.337,94.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.913 | Acc: 51.464,76.075,94.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.917 | Acc: 51.410,76.096,94.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.925 | Acc: 51.269,75.982,94.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.934 | Acc: 51.104,75.845,94.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.944 | Acc: 51.088,75.716,93.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.953 | Acc: 51.081,75.623,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.957 | Acc: 51.168,75.623,93.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.968 | Acc: 51.026,75.580,93.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.974 | Acc: 51.013,75.490,93.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.488 | Acc: 46.094,63.281,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.698 | Acc: 45.126,62.128,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.747 | Acc: 45.274,61.585,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.776 | Acc: 45.261,61.668,67.508,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.773 | Acc: 54.688,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.830 | Acc: 52.604,77.827,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.867 | Acc: 51.372,76.505,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.859 | Acc: 51.345,76.447,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.868 | Acc: 50.829,76.466,95.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.879 | Acc: 50.866,76.307,95.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.885 | Acc: 50.839,76.085,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.891 | Acc: 50.870,76.147,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.896 | Acc: 51.043,76.024,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.906 | Acc: 50.906,76.079,94.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.913 | Acc: 51.014,76.042,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.917 | Acc: 51.103,76.124,94.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.914 | Acc: 51.203,76.170,94.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.921 | Acc: 51.275,76.069,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.925 | Acc: 51.287,76.029,94.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.925 | Acc: 51.248,76.025,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.928 | Acc: 51.263,76.005,94.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.935 | Acc: 51.194,75.930,94.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.938 | Acc: 51.175,75.881,94.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.943 | Acc: 51.144,75.789,93.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 49.219,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.967 | Acc: 40.662,62.240,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.966 | Acc: 41.044,61.776,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.963 | Acc: 41.073,61.539,68.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 2.867 | Acc: 51.562,69.531,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.807 | Acc: 51.414,76.302,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.865 | Acc: 51.410,76.220,94.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.866 | Acc: 51.294,76.691,94.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.876 | Acc: 51.138,76.235,94.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.881 | Acc: 51.330,76.330,94.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.883 | Acc: 51.265,76.349,94.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.873 | Acc: 51.341,76.479,94.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.880 | Acc: 51.359,76.330,94.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.889 | Acc: 51.230,76.286,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.895 | Acc: 51.131,76.189,94.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.909 | Acc: 50.972,76.022,94.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.914 | Acc: 51.028,75.917,94.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.916 | Acc: 51.099,75.850,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.922 | Acc: 51.107,75.798,94.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.926 | Acc: 51.113,75.732,94.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.931 | Acc: 50.993,75.652,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.944 | Acc: 50.891,75.522,93.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.952 | Acc: 50.959,75.424,93.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.957 | Acc: 50.960,75.412,93.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.302 | Acc: 51.562,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.688 | Acc: 46.466,62.537,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.760 | Acc: 46.037,61.928,68.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.775 | Acc: 46.209,62.180,68.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 3.016 | Acc: 50.000,72.656,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.905 | Acc: 51.153,77.009,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.893 | Acc: 51.181,76.372,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.891 | Acc: 50.961,76.844,94.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.901 | Acc: 51.119,76.726,94.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.888 | Acc: 51.338,76.856,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.879 | Acc: 51.472,76.995,94.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.885 | Acc: 51.357,76.779,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.881 | Acc: 51.567,76.844,94.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.889 | Acc: 51.506,76.675,94.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.896 | Acc: 51.356,76.613,94.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.891 | Acc: 51.414,76.623,94.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.899 | Acc: 51.355,76.524,94.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.903 | Acc: 51.416,76.482,94.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.912 | Acc: 51.412,76.371,94.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.917 | Acc: 51.324,76.272,94.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.927 | Acc: 51.266,76.149,94.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.935 | Acc: 51.166,76.141,93.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.938 | Acc: 51.186,76.091,93.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.939 | Acc: 51.230,76.058,93.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.029 | Acc: 48.438,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.820 | Acc: 44.829,61.942,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.848 | Acc: 45.027,61.319,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.813 | Acc: 45.300,61.744,67.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 2.736 | Acc: 53.906,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.827 | Acc: 51.339,77.641,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.837 | Acc: 50.991,77.896,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.870 | Acc: 50.576,77.472,94.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.888 | Acc: 50.772,76.919,94.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.882 | Acc: 51.214,76.849,94.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.890 | Acc: 50.930,76.640,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.892 | Acc: 50.881,76.468,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.905 | Acc: 50.752,76.237,94.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.902 | Acc: 50.863,76.222,94.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.910 | Acc: 50.805,76.205,94.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.913 | Acc: 50.760,76.237,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.921 | Acc: 50.784,76.128,94.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.920 | Acc: 50.949,76.161,94.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.928 | Acc: 50.962,76.059,93.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.933 | Acc: 50.906,76.004,93.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.934 | Acc: 50.930,75.920,93.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.928 | Acc: 51.086,75.987,93.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.933 | Acc: 51.119,75.946,93.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.937 | Acc: 51.060,75.851,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.399 | Acc: 42.969,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.849 | Acc: 44.903,61.496,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.928 | Acc: 45.046,60.575,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.935 | Acc: 44.813,60.630,66.573,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 2.513 | Acc: 58.594,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.844 | Acc: 52.827,78.497,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.854 | Acc: 52.210,78.182,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.849 | Acc: 52.228,77.574,94.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.865 | Acc: 51.929,76.929,94.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.876 | Acc: 51.617,76.849,94.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.861 | Acc: 51.737,77.234,94.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.863 | Acc: 51.585,77.083,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.867 | Acc: 51.533,76.970,94.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.873 | Acc: 51.640,76.968,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.883 | Acc: 51.597,76.881,94.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.886 | Acc: 51.499,76.838,94.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.903 | Acc: 51.290,76.546,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.911 | Acc: 51.182,76.407,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.903 | Acc: 51.326,76.507,94.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.912 | Acc: 51.243,76.331,94.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.915 | Acc: 51.307,76.317,93.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.924 | Acc: 51.274,76.214,93.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.931 | Acc: 51.231,76.086,93.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.933 | Acc: 51.191,76.003,93.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.763 | Acc: 46.094,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.104 | Acc: 41.853,59.561,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.144 | Acc: 42.778,59.299,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.120 | Acc: 43.058,59.362,66.457,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 3.436 | Acc: 42.188,67.188,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.902 | Acc: 50.930,76.302,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 50.915,76.143,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.880 | Acc: 50.909,76.524,94.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.875 | Acc: 51.302,76.543,94.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.881 | Acc: 51.501,76.446,94.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.881 | Acc: 51.491,76.601,94.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.884 | Acc: 51.413,76.568,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.885 | Acc: 51.543,76.572,94.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.884 | Acc: 51.619,76.554,94.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.885 | Acc: 51.551,76.508,94.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.890 | Acc: 51.467,76.372,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.894 | Acc: 51.511,76.407,94.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.902 | Acc: 51.554,76.320,94.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.911 | Acc: 51.393,76.223,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.914 | Acc: 51.339,76.168,93.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.923 | Acc: 51.239,76.056,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.926 | Acc: 51.331,75.951,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.931 | Acc: 51.318,75.879,93.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.936 | Acc: 51.316,75.798,93.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.313 | Acc: 46.875,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.801 | Acc: 45.722,63.616,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.850 | Acc: 45.922,62.671,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.896 | Acc: 46.030,62.321,66.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.890 | Acc: 50.000,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.845 | Acc: 52.455,78.088,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.856 | Acc: 51.734,77.248,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.869 | Acc: 51.498,77.152,94.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.838 | Acc: 51.804,77.411,94.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.832 | Acc: 51.942,77.212,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.851 | Acc: 51.814,76.898,94.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.872 | Acc: 51.562,76.612,94.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.882 | Acc: 51.296,76.616,94.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.893 | Acc: 51.222,76.411,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.898 | Acc: 51.174,76.325,94.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.894 | Acc: 51.276,76.361,94.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.904 | Acc: 51.180,76.154,94.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.903 | Acc: 51.389,76.161,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.902 | Acc: 51.487,76.184,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.907 | Acc: 51.451,76.132,94.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.916 | Acc: 51.380,76.027,94.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.921 | Acc: 51.425,75.987,94.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.926 | Acc: 51.435,75.998,93.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.929 | Acc: 51.300,75.997,93.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.414 | Acc: 46.094,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.898 | Acc: 43.229,61.830,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.005 | Acc: 43.216,60.842,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.006 | Acc: 43.430,60.976,66.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 2.761 | Acc: 57.812,75.000,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.775 | Acc: 52.865,78.981,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.829 | Acc: 52.172,78.049,94.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.852 | Acc: 52.126,77.561,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.874 | Acc: 51.196,77.296,94.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.873 | Acc: 50.998,76.856,94.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.858 | Acc: 51.485,77.157,94.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.858 | Acc: 51.313,77.178,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.846 | Acc: 51.402,77.218,94.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.840 | Acc: 51.537,77.227,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.835 | Acc: 51.648,77.227,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.844 | Acc: 51.492,77.054,94.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.853 | Acc: 51.446,76.994,94.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.861 | Acc: 51.506,76.790,94.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.867 | Acc: 51.462,76.685,94.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.879 | Acc: 51.235,76.586,94.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.885 | Acc: 51.246,76.531,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.892 | Acc: 51.281,76.393,94.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.896 | Acc: 51.262,76.411,94.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.906 | Acc: 51.220,76.312,94.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.386 | Acc: 46.875,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.730 | Acc: 46.019,62.760,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.773 | Acc: 46.399,61.890,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.767 | Acc: 46.388,61.988,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 2.976 | Acc: 44.531,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.893 | Acc: 50.632,76.749,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.859 | Acc: 51.677,77.287,94.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.842 | Acc: 52.011,77.344,94.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.843 | Acc: 51.871,77.267,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.833 | Acc: 52.088,77.027,94.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.844 | Acc: 51.801,76.905,94.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.841 | Acc: 51.823,77.056,94.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.850 | Acc: 51.844,76.897,94.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.863 | Acc: 51.649,76.826,94.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.871 | Acc: 51.664,76.648,94.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.874 | Acc: 51.672,76.478,94.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.884 | Acc: 51.634,76.443,94.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.888 | Acc: 51.667,76.368,94.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.899 | Acc: 51.593,76.290,94.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.907 | Acc: 51.542,76.212,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.919 | Acc: 51.480,76.110,93.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.927 | Acc: 51.418,76.038,93.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.926 | Acc: 51.415,76.065,93.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.935 | Acc: 51.323,76.007,93.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.534 | Acc: 45.312,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.975 | Acc: 43.080,62.649,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.017 | Acc: 43.312,61.433,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.036 | Acc: 42.520,61.296,66.611,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 2.888 | Acc: 49.219,82.812,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.852 | Acc: 51.600,77.567,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.818 | Acc: 52.229,77.668,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.842 | Acc: 51.883,77.497,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.847 | Acc: 51.890,77.083,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 52.073,77.197,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.841 | Acc: 52.182,77.027,94.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.853 | Acc: 52.139,76.884,94.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.854 | Acc: 52.009,76.820,94.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.861 | Acc: 51.903,76.683,94.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.866 | Acc: 51.803,76.710,94.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.872 | Acc: 51.725,76.665,94.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.884 | Acc: 51.657,76.575,94.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.897 | Acc: 51.506,76.350,94.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.906 | Acc: 51.415,76.273,94.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.915 | Acc: 51.316,76.147,93.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.918 | Acc: 51.295,76.105,93.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.915 | Acc: 51.375,76.132,93.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.920 | Acc: 51.327,76.069,93.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.921 | Acc: 51.345,76.070,93.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.646 | Acc: 45.312,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.921 | Acc: 43.080,61.012,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.924 | Acc: 43.579,60.652,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.917 | Acc: 43.609,60.822,66.970,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 2.813 | Acc: 51.562,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.872 | Acc: 51.972,77.790,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.893 | Acc: 51.620,77.210,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.893 | Acc: 51.396,77.024,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.880 | Acc: 51.582,77.122,94.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.874 | Acc: 51.640,77.096,94.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.862 | Acc: 51.892,77.098,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.861 | Acc: 51.707,77.056,94.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.869 | Acc: 51.592,76.854,94.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.876 | Acc: 51.528,76.891,94.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.882 | Acc: 51.485,76.772,94.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.884 | Acc: 51.446,76.718,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.884 | Acc: 51.507,76.699,94.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.881 | Acc: 51.586,76.640,94.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.893 | Acc: 51.529,76.426,94.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.902 | Acc: 51.466,76.373,94.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.906 | Acc: 51.465,76.317,94.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.911 | Acc: 51.427,76.168,93.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.915 | Acc: 51.396,76.095,93.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.922 | Acc: 51.386,75.970,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.503 | Acc: 46.094,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.731 | Acc: 45.424,61.607,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.781 | Acc: 45.427,61.700,67.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.769 | Acc: 45.364,62.052,67.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.782 | Acc: 52.344,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.806 | Acc: 52.195,77.121,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.832 | Acc: 51.925,77.058,95.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.800 | Acc: 51.934,77.638,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 51.842,77.595,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.818 | Acc: 51.841,77.328,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.823 | Acc: 51.730,77.189,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.837 | Acc: 51.673,76.984,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.837 | Acc: 51.800,76.951,95.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.844 | Acc: 51.727,76.895,95.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.854 | Acc: 51.629,76.718,94.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.849 | Acc: 51.577,76.711,94.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.847 | Acc: 51.715,76.770,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.848 | Acc: 51.778,76.727,94.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.858 | Acc: 51.679,76.629,94.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.864 | Acc: 51.604,76.601,94.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.868 | Acc: 51.631,76.580,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.877 | Acc: 51.613,76.391,94.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.886 | Acc: 51.482,76.344,94.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.892 | Acc: 51.417,76.288,94.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.214 | Acc: 46.875,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.706 | Acc: 46.466,62.984,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.757 | Acc: 46.399,62.443,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.748 | Acc: 46.388,62.654,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 2.626 | Acc: 50.781,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.778 | Acc: 51.897,78.013,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.766 | Acc: 52.382,77.782,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.784 | Acc: 52.446,77.664,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.773 | Acc: 52.691,77.884,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.769 | Acc: 52.638,77.854,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.768 | Acc: 52.589,78.002,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.786 | Acc: 52.521,77.820,94.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.801 | Acc: 52.446,77.625,94.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.818 | Acc: 52.145,77.413,94.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.823 | Acc: 52.126,77.317,94.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.828 | Acc: 52.050,77.266,94.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.840 | Acc: 51.945,77.091,94.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.853 | Acc: 51.859,76.961,94.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.866 | Acc: 51.888,76.774,94.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.874 | Acc: 51.882,76.682,94.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.881 | Acc: 51.750,76.611,94.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.892 | Acc: 51.691,76.480,93.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.895 | Acc: 51.606,76.420,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.904 | Acc: 51.509,76.312,93.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.429 | Acc: 47.656,64.844,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.731 | Acc: 44.903,63.616,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.807 | Acc: 45.351,62.500,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.822 | Acc: 44.429,62.372,67.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 3.341 | Acc: 45.312,72.656,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.929 | Acc: 51.897,77.232,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.839 | Acc: 52.801,77.801,94.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.854 | Acc: 52.485,77.395,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.842 | Acc: 52.672,77.508,94.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.838 | Acc: 52.282,77.313,94.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 52.299,77.157,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.821 | Acc: 52.205,77.294,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.821 | Acc: 52.145,77.271,94.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.824 | Acc: 52.141,77.249,94.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.827 | Acc: 52.017,77.258,94.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.829 | Acc: 52.072,77.354,94.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.836 | Acc: 52.010,77.240,94.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.839 | Acc: 51.973,77.242,94.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.842 | Acc: 52.016,77.191,94.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 51.918,77.102,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.857 | Acc: 51.842,76.984,94.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.863 | Acc: 51.803,76.899,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.872 | Acc: 51.738,76.712,94.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.879 | Acc: 51.671,76.659,94.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.293 | Acc: 46.875,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.663 | Acc: 45.201,64.435,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.743 | Acc: 45.046,63.034,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.758 | Acc: 45.261,62.871,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.975 | Acc: 50.781,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.782 | Acc: 53.311,77.716,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.841 | Acc: 52.458,76.867,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.836 | Acc: 52.049,76.486,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.839 | Acc: 52.083,76.707,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.856 | Acc: 51.733,76.539,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.868 | Acc: 51.588,76.479,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.868 | Acc: 51.557,76.452,94.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.870 | Acc: 51.529,76.480,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.873 | Acc: 51.627,76.632,94.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.871 | Acc: 51.601,76.625,94.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.865 | Acc: 51.700,76.746,94.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.868 | Acc: 51.747,76.712,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.879 | Acc: 51.679,76.613,94.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.882 | Acc: 51.626,76.496,94.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.885 | Acc: 51.537,76.464,94.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.892 | Acc: 51.538,76.397,94.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.896 | Acc: 51.514,76.356,94.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.900 | Acc: 51.558,76.301,94.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.904 | Acc: 51.546,76.230,93.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.751 | Acc: 51.562,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.890 | Acc: 43.750,62.388,65.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.007 | Acc: 43.483,61.757,65.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.023 | Acc: 43.468,61.885,66.009,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 2.780 | Acc: 48.438,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.831 | Acc: 52.269,78.125,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.859 | Acc: 51.734,77.801,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.819 | Acc: 52.152,78.163,94.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.831 | Acc: 51.813,77.980,94.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.819 | Acc: 51.972,78.218,94.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 51.808,77.789,94.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.835 | Acc: 51.601,77.826,94.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.834 | Acc: 51.694,77.911,94.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.842 | Acc: 51.627,77.762,94.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.850 | Acc: 51.508,77.550,94.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.848 | Acc: 51.647,77.499,94.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.849 | Acc: 51.585,77.379,94.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.854 | Acc: 51.557,77.299,94.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.863 | Acc: 51.585,77.180,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.869 | Acc: 51.591,77.079,94.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.878 | Acc: 51.616,76.988,94.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.878 | Acc: 51.622,76.970,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.885 | Acc: 51.524,76.872,94.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.893 | Acc: 51.460,76.796,93.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.460 | Acc: 37.500,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.078 | Acc: 43.601,61.012,65.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.110 | Acc: 43.312,60.404,65.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.115 | Acc: 43.007,60.617,65.535,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 3.088 | Acc: 51.562,77.344,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.839 | Acc: 51.972,77.790,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.813 | Acc: 51.925,78.296,94.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.825 | Acc: 51.639,77.741,94.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.820 | Acc: 51.707,77.691,94.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.825 | Acc: 51.462,77.684,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.841 | Acc: 51.420,77.550,94.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.849 | Acc: 51.302,77.521,94.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.837 | Acc: 51.465,77.494,94.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.839 | Acc: 51.601,77.301,94.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.846 | Acc: 51.496,77.157,94.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.847 | Acc: 51.577,77.040,94.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.855 | Acc: 51.546,76.971,94.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.862 | Acc: 51.425,76.958,94.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.865 | Acc: 51.429,76.879,94.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.874 | Acc: 51.511,76.775,94.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.879 | Acc: 51.550,76.784,94.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.881 | Acc: 51.611,76.711,93.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.891 | Acc: 51.543,76.612,93.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.894 | Acc: 51.552,76.577,93.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.755 | Acc: 44.531,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.949 | Acc: 43.229,62.686,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.015 | Acc: 43.464,61.719,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.009 | Acc: 43.404,61.578,66.227,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 2.826 | Acc: 52.344,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.762 | Acc: 53.237,79.650,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.740 | Acc: 53.296,79.154,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.745 | Acc: 52.946,79.419,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.765 | Acc: 52.691,78.916,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.776 | Acc: 52.506,78.697,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.797 | Acc: 52.260,78.112,95.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.799 | Acc: 52.227,77.842,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.811 | Acc: 52.019,77.620,95.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.818 | Acc: 52.016,77.426,94.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.824 | Acc: 51.866,77.437,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.836 | Acc: 51.771,77.291,94.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.839 | Acc: 51.796,77.250,94.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.845 | Acc: 51.835,77.257,94.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.851 | Acc: 51.799,77.107,94.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.859 | Acc: 51.809,77.001,94.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.865 | Acc: 51.825,76.886,94.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.870 | Acc: 51.771,76.815,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.874 | Acc: 51.695,76.805,94.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.885 | Acc: 51.583,76.673,94.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.174 | Acc: 48.438,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.669 | Acc: 45.350,63.690,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.688 | Acc: 46.018,63.453,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.698 | Acc: 45.697,63.422,68.712,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 2.672 | Acc: 54.688,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.813 | Acc: 52.827,77.195,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.813 | Acc: 52.534,77.420,94.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.770 | Acc: 53.138,78.138,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.762 | Acc: 53.077,78.279,95.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.775 | Acc: 52.978,78.086,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.777 | Acc: 52.686,78.054,95.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.790 | Acc: 52.565,77.931,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.787 | Acc: 52.480,78.047,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.800 | Acc: 52.301,77.819,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 52.173,77.674,94.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.820 | Acc: 52.050,77.390,94.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.827 | Acc: 52.065,77.243,94.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.830 | Acc: 52.053,77.257,94.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.834 | Acc: 52.057,77.088,94.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.845 | Acc: 51.895,76.954,94.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.850 | Acc: 51.930,76.935,94.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.851 | Acc: 51.991,76.915,94.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.856 | Acc: 51.922,76.883,94.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.862 | Acc: 51.911,76.843,94.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.366 | Acc: 42.969,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.667 | Acc: 45.573,64.025,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.732 | Acc: 45.560,63.510,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.747 | Acc: 44.980,63.422,67.969,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.682 | Acc: 56.250,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.814 | Acc: 52.046,77.641,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.802 | Acc: 52.668,77.858,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.807 | Acc: 52.293,77.907,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.804 | Acc: 52.267,77.971,94.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.810 | Acc: 52.166,77.746,95.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.811 | Acc: 52.260,77.738,94.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.812 | Acc: 52.150,77.632,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.819 | Acc: 52.053,77.475,94.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 52.266,77.564,94.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.819 | Acc: 52.146,77.410,94.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.821 | Acc: 52.234,77.436,94.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.821 | Acc: 52.191,77.392,94.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.827 | Acc: 52.059,77.266,94.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 51.957,77.130,94.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.840 | Acc: 51.895,77.035,94.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.846 | Acc: 51.908,76.981,94.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 51.821,76.890,94.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.860 | Acc: 51.868,76.790,94.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.870 | Acc: 51.819,76.669,94.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.273 | Acc: 50.000,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.828 | Acc: 45.908,61.719,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.859 | Acc: 45.941,61.604,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.850 | Acc: 45.697,61.796,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 3.198 | Acc: 44.531,67.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.782 | Acc: 52.976,79.055,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 52.896,78.487,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.768 | Acc: 52.626,78.381,94.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.774 | Acc: 52.797,78.096,94.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.779 | Acc: 52.460,78.117,94.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.793 | Acc: 52.370,77.854,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.806 | Acc: 52.227,77.671,94.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.813 | Acc: 52.077,77.751,94.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.815 | Acc: 52.059,77.581,94.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.824 | Acc: 52.072,77.429,94.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.833 | Acc: 52.040,77.400,94.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.835 | Acc: 52.094,77.357,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.844 | Acc: 52.029,77.176,94.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.853 | Acc: 51.907,77.060,94.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.864 | Acc: 51.822,76.869,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.868 | Acc: 51.862,76.852,93.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.870 | Acc: 51.936,76.828,93.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.880 | Acc: 51.881,76.705,93.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.884 | Acc: 51.809,76.661,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.620 | Acc: 45.312,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.846 | Acc: 43.899,63.244,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.895 | Acc: 44.588,62.024,66.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.886 | Acc: 44.314,62.141,66.790,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 2.793 | Acc: 57.812,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.774 | Acc: 53.869,79.055,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.798 | Acc: 53.163,78.392,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.778 | Acc: 53.394,78.420,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.792 | Acc: 52.971,77.836,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.791 | Acc: 52.684,77.746,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.802 | Acc: 52.505,77.576,94.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.805 | Acc: 52.327,77.504,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.800 | Acc: 52.295,77.640,94.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 52.318,77.486,94.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.817 | Acc: 52.208,77.445,94.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.821 | Acc: 52.033,77.315,94.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.826 | Acc: 52.065,77.318,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.829 | Acc: 52.104,77.233,94.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.837 | Acc: 52.046,77.149,94.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.843 | Acc: 51.949,77.063,94.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.849 | Acc: 51.937,76.949,94.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.855 | Acc: 51.897,76.943,94.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.864 | Acc: 51.861,76.881,94.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.872 | Acc: 51.804,76.766,93.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.423 | Acc: 53.125,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.652 | Acc: 47.917,62.649,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.700 | Acc: 48.095,62.138,67.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.696 | Acc: 47.707,62.474,67.392,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 2.436 | Acc: 57.812,82.031,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.775 | Acc: 53.423,78.385,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 52.858,78.773,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.769 | Acc: 52.869,78.817,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.792 | Acc: 52.257,78.453,95.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.788 | Acc: 52.421,78.164,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.793 | Acc: 52.563,78.080,95.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.787 | Acc: 52.660,77.992,95.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.785 | Acc: 52.620,77.887,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.789 | Acc: 52.676,77.719,95.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.793 | Acc: 52.542,77.651,94.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.801 | Acc: 52.531,77.556,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.813 | Acc: 52.366,77.467,94.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.818 | Acc: 52.269,77.368,94.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.818 | Acc: 52.327,77.372,94.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.833 | Acc: 52.198,77.178,94.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.845 | Acc: 52.159,77.044,94.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.852 | Acc: 52.105,76.973,94.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.859 | Acc: 51.985,76.881,94.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.869 | Acc: 51.823,76.770,93.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.423 | Acc: 51.562,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.935 | Acc: 44.754,62.016,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.953 | Acc: 44.684,61.128,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.941 | Acc: 44.659,61.309,66.176,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 2.847 | Acc: 57.812,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.861 | Acc: 51.302,77.121,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.889 | Acc: 51.696,76.448,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.861 | Acc: 51.844,77.293,94.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.851 | Acc: 52.074,77.228,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.836 | Acc: 52.050,77.584,94.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.829 | Acc: 52.221,77.699,94.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.839 | Acc: 52.028,77.466,94.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.838 | Acc: 52.125,77.538,94.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.837 | Acc: 52.171,77.452,94.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.838 | Acc: 52.250,77.414,94.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.847 | Acc: 52.086,77.386,94.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.848 | Acc: 51.851,77.396,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.849 | Acc: 51.859,77.287,94.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.847 | Acc: 51.852,77.341,94.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.854 | Acc: 51.830,77.268,94.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.855 | Acc: 51.867,77.266,94.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.856 | Acc: 51.853,77.151,94.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.861 | Acc: 51.874,77.080,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.865 | Acc: 51.854,77.024,94.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.909 | Acc: 51.562,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.629 | Acc: 47.396,63.690,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.693 | Acc: 47.313,62.957,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.698 | Acc: 46.926,62.820,67.546,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 2.966 | Acc: 49.219,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.748 | Acc: 52.418,78.795,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.756 | Acc: 52.344,78.716,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.769 | Acc: 52.100,78.291,94.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.776 | Acc: 51.562,78.308,94.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.783 | Acc: 52.003,78.094,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.787 | Acc: 51.866,77.938,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.785 | Acc: 52.039,77.892,95.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.785 | Acc: 51.956,77.858,95.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.789 | Acc: 51.964,77.857,95.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.790 | Acc: 52.037,77.802,94.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.799 | Acc: 51.987,77.729,94.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.808 | Acc: 51.887,77.687,94.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 51.925,77.655,94.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.813 | Acc: 52.021,77.575,94.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 52.048,77.507,94.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.826 | Acc: 52.025,77.444,94.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.843 | Acc: 51.844,77.227,94.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.850 | Acc: 51.842,77.132,94.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.859 | Acc: 51.864,77.063,94.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.088 | Acc: 48.438,70.312,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.680 | Acc: 45.722,63.876,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.772 | Acc: 45.751,62.710,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.766 | Acc: 45.364,62.538,66.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 2.781 | Acc: 58.594,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.664 | Acc: 55.171,80.022,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.712 | Acc: 54.249,79.649,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 53.163,79.623,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.715 | Acc: 53.048,79.321,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.724 | Acc: 52.908,78.960,95.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.744 | Acc: 52.628,78.842,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.763 | Acc: 52.516,78.535,95.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.760 | Acc: 52.567,78.421,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.774 | Acc: 52.400,78.216,95.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.786 | Acc: 52.297,78.039,94.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.789 | Acc: 52.234,77.938,94.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.806 | Acc: 52.033,77.723,94.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 52.020,77.643,94.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.814 | Acc: 52.107,77.577,94.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.821 | Acc: 52.087,77.549,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.827 | Acc: 52.100,77.504,94.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.837 | Acc: 51.993,77.280,94.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.846 | Acc: 51.896,77.190,94.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.846 | Acc: 52.010,77.188,94.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.376 | Acc: 50.781,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.766 | Acc: 46.466,62.463,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.845 | Acc: 46.456,62.176,68.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.860 | Acc: 46.004,62.218,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 2.796 | Acc: 54.688,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.780 | Acc: 51.600,79.167,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.759 | Acc: 52.020,78.639,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.740 | Acc: 52.241,79.175,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.732 | Acc: 52.440,78.935,95.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.739 | Acc: 52.483,78.759,95.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.765 | Acc: 52.202,78.493,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.773 | Acc: 52.178,78.197,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.779 | Acc: 52.266,78.125,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.789 | Acc: 52.162,77.944,95.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.791 | Acc: 52.219,77.931,94.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.799 | Acc: 52.146,77.828,94.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.798 | Acc: 52.182,77.752,94.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.807 | Acc: 52.161,77.661,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.818 | Acc: 52.060,77.561,94.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.823 | Acc: 52.079,77.481,94.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.834 | Acc: 51.935,77.388,94.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.843 | Acc: 51.892,77.316,94.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.849 | Acc: 51.885,77.259,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.850 | Acc: 51.954,77.225,94.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.440 | Acc: 42.969,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.829 | Acc: 44.234,62.463,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.864 | Acc: 44.607,61.528,67.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.848 | Acc: 44.339,61.424,67.687,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 2.582 | Acc: 54.688,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.796 | Acc: 52.976,77.827,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.773 | Acc: 53.373,78.335,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.768 | Acc: 52.894,78.548,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.773 | Acc: 52.363,78.588,95.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.779 | Acc: 51.988,78.496,95.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.782 | Acc: 51.950,78.338,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.784 | Acc: 52.056,78.302,95.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.792 | Acc: 52.014,78.043,94.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.811 | Acc: 51.809,77.771,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.810 | Acc: 51.870,77.678,94.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.812 | Acc: 51.867,77.718,94.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.817 | Acc: 51.802,77.593,94.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.820 | Acc: 51.742,77.478,94.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.829 | Acc: 51.724,77.338,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.838 | Acc: 51.716,77.274,94.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.844 | Acc: 51.687,77.195,94.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.847 | Acc: 51.725,77.142,94.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.851 | Acc: 51.675,77.041,94.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.853 | Acc: 51.722,76.993,94.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.513 | Acc: 39.062,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.764 | Acc: 43.936,62.723,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.869 | Acc: 44.226,62.024,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.852 | Acc: 43.904,62.295,67.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 2.555 | Acc: 53.906,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.757 | Acc: 51.823,77.827,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.756 | Acc: 53.144,78.392,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.790 | Acc: 52.523,77.933,94.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.798 | Acc: 52.382,77.527,94.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.795 | Acc: 52.584,77.707,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.803 | Acc: 52.505,77.550,94.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.801 | Acc: 52.521,77.588,94.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.805 | Acc: 52.383,77.426,94.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.806 | Acc: 52.253,77.404,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.806 | Acc: 52.332,77.464,94.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 52.330,77.305,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.818 | Acc: 52.392,77.237,94.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.832 | Acc: 52.260,77.071,94.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 52.291,76.988,94.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.839 | Acc: 52.258,76.910,94.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.845 | Acc: 52.249,76.954,94.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 52.183,76.991,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.852 | Acc: 52.084,76.898,94.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.853 | Acc: 52.038,76.860,94.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.426 | Acc: 50.781,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.800 | Acc: 44.494,60.677,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.854 | Acc: 44.874,61.109,67.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.873 | Acc: 44.570,61.283,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 2.617 | Acc: 57.031,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.768 | Acc: 53.646,77.716,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.802 | Acc: 52.782,77.611,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.806 | Acc: 52.280,77.331,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.818 | Acc: 51.890,77.498,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.816 | Acc: 51.996,77.413,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.813 | Acc: 52.163,77.370,94.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.804 | Acc: 52.360,77.571,94.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.806 | Acc: 52.319,77.625,94.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.813 | Acc: 52.266,77.573,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.815 | Acc: 52.247,77.499,94.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.830 | Acc: 52.064,77.351,94.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.831 | Acc: 52.146,77.305,94.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.833 | Acc: 52.215,77.281,94.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.831 | Acc: 52.277,77.330,94.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.837 | Acc: 52.232,77.294,94.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.844 | Acc: 52.188,77.288,93.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.849 | Acc: 52.103,77.248,93.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.855 | Acc: 51.995,77.171,93.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.859 | Acc: 52.003,77.120,93.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.662 | Acc: 47.656,67.188,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.765 | Acc: 46.168,62.128,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.818 | Acc: 45.865,62.024,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.834 | Acc: 45.953,61.834,67.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 3.195 | Acc: 45.312,75.000,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.673 | Acc: 54.315,79.613,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.723 | Acc: 53.258,78.982,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.741 | Acc: 53.061,78.919,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.743 | Acc: 53.202,78.675,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.743 | Acc: 53.055,78.496,94.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.742 | Acc: 53.157,78.416,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.749 | Acc: 52.892,78.324,95.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.761 | Acc: 52.853,78.164,94.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.779 | Acc: 52.655,77.914,94.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.785 | Acc: 52.526,77.919,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.784 | Acc: 52.634,77.853,94.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.785 | Acc: 52.529,77.791,94.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.784 | Acc: 52.568,77.820,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.793 | Acc: 52.458,77.708,94.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.798 | Acc: 52.409,77.697,94.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.809 | Acc: 52.220,77.590,94.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.818 | Acc: 52.128,77.461,94.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.825 | Acc: 52.026,77.391,94.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.828 | Acc: 52.020,77.362,94.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.388 | Acc: 46.875,71.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.623 | Acc: 46.057,63.765,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.648 | Acc: 46.684,63.186,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.639 | Acc: 46.760,63.397,68.673,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 2.598 | Acc: 51.562,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.856 | Acc: 50.744,77.753,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.783 | Acc: 51.372,78.582,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.775 | Acc: 51.934,78.420,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.793 | Acc: 51.784,78.057,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.770 | Acc: 52.158,78.202,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.766 | Acc: 52.337,78.022,95.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.769 | Acc: 52.033,77.975,95.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.779 | Acc: 51.956,77.693,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.788 | Acc: 51.800,77.499,95.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 51.609,77.324,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.803 | Acc: 51.813,77.358,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 51.955,77.224,94.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.820 | Acc: 52.047,77.041,94.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.821 | Acc: 52.021,77.057,94.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.823 | Acc: 52.030,77.069,94.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.830 | Acc: 51.986,76.991,94.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.832 | Acc: 52.002,76.989,94.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 51.972,76.956,94.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.848 | Acc: 51.966,76.893,94.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.278 | Acc: 48.438,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.859 | Acc: 45.201,62.612,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.877 | Acc: 45.198,61.852,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.888 | Acc: 45.172,61.411,66.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 2.749 | Acc: 48.438,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.718 | Acc: 53.088,79.576,93.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.758 | Acc: 53.220,78.944,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.743 | Acc: 53.420,79.047,94.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.733 | Acc: 53.675,78.810,94.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.727 | Acc: 53.636,78.636,94.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.729 | Acc: 53.551,78.487,94.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.735 | Acc: 53.319,78.319,94.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.750 | Acc: 53.125,78.159,94.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.759 | Acc: 53.017,78.034,94.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.767 | Acc: 52.903,77.973,94.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.764 | Acc: 52.952,78.051,94.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.766 | Acc: 52.914,77.973,94.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.775 | Acc: 52.853,77.817,94.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.788 | Acc: 52.752,77.547,94.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.806 | Acc: 52.624,77.331,94.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.816 | Acc: 52.538,77.212,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.821 | Acc: 52.376,77.195,94.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.827 | Acc: 52.316,77.155,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.834 | Acc: 52.292,77.026,94.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.092 | Acc: 48.438,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.721 | Acc: 45.312,63.021,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.761 | Acc: 45.312,62.214,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.766 | Acc: 44.954,62.026,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 2.861 | Acc: 49.219,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.775 | Acc: 54.390,78.274,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.758 | Acc: 53.773,78.411,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.757 | Acc: 53.535,78.817,94.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.751 | Acc: 53.501,78.916,95.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.750 | Acc: 53.349,78.674,95.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.765 | Acc: 53.112,78.319,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.781 | Acc: 52.743,77.898,95.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.779 | Acc: 52.649,77.965,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.778 | Acc: 52.542,77.935,94.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.780 | Acc: 52.581,77.868,94.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.780 | Acc: 52.570,77.874,94.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.791 | Acc: 52.428,77.717,94.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.790 | Acc: 52.556,77.715,94.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.797 | Acc: 52.469,77.658,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.803 | Acc: 52.411,77.650,94.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.811 | Acc: 52.346,77.500,94.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.815 | Acc: 52.303,77.431,94.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.826 | Acc: 52.231,77.320,94.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.824 | Acc: 52.305,77.358,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.589 | Acc: 46.875,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.721 | Acc: 45.833,62.574,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.733 | Acc: 46.170,63.300,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.765 | Acc: 45.697,62.974,68.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 2.838 | Acc: 43.750,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.852 | Acc: 51.116,77.902,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.765 | Acc: 52.896,78.544,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.764 | Acc: 52.472,78.650,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.747 | Acc: 52.585,78.926,95.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.745 | Acc: 52.429,78.922,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.739 | Acc: 52.608,78.932,95.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.733 | Acc: 52.748,78.934,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.739 | Acc: 52.824,78.712,95.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.747 | Acc: 52.667,78.513,95.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.761 | Acc: 52.441,78.347,95.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.769 | Acc: 52.365,78.256,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.774 | Acc: 52.324,78.183,94.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.780 | Acc: 52.188,78.140,94.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.788 | Acc: 52.121,78.094,94.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.801 | Acc: 52.022,77.967,94.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.807 | Acc: 52.044,77.835,94.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.813 | Acc: 52.032,77.745,94.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.820 | Acc: 52.010,77.675,94.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.825 | Acc: 51.981,77.575,94.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.097 | Acc: 49.219,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.693 | Acc: 46.838,63.504,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.729 | Acc: 46.475,62.652,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.723 | Acc: 45.953,62.500,67.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 2.864 | Acc: 45.312,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.856 | Acc: 50.744,77.195,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.826 | Acc: 51.467,77.515,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.819 | Acc: 51.614,77.690,94.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.797 | Acc: 52.054,77.980,95.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.802 | Acc: 52.166,77.638,95.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.793 | Acc: 52.163,77.776,95.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.806 | Acc: 52.045,77.654,94.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.809 | Acc: 52.155,77.645,94.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.811 | Acc: 52.085,77.706,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 52.219,77.732,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.810 | Acc: 52.086,77.591,94.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 52.253,77.516,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.824 | Acc: 52.062,77.386,94.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.826 | Acc: 52.121,77.422,94.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.830 | Acc: 52.108,77.419,94.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.829 | Acc: 52.105,77.458,94.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.834 | Acc: 52.110,77.337,94.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.838 | Acc: 52.108,77.220,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.839 | Acc: 52.130,77.208,94.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.520 | Acc: 44.531,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.757 | Acc: 44.829,64.137,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.806 | Acc: 44.912,63.186,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.793 | Acc: 44.826,63.230,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.797 | Acc: 55.469,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.667 | Acc: 53.497,80.246,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.726 | Acc: 52.649,78.544,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.741 | Acc: 52.408,78.317,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.743 | Acc: 52.324,78.376,94.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.743 | Acc: 52.522,78.411,94.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.751 | Acc: 52.705,78.357,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.761 | Acc: 52.493,78.241,94.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.763 | Acc: 52.412,78.237,94.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.769 | Acc: 52.318,78.073,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.780 | Acc: 52.239,77.927,94.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 52.234,77.757,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.795 | Acc: 52.279,77.707,94.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.795 | Acc: 52.311,77.709,94.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.800 | Acc: 52.285,77.672,94.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.809 | Acc: 52.305,77.562,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.812 | Acc: 52.205,77.590,94.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.816 | Acc: 52.179,77.525,94.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.821 | Acc: 52.184,77.417,94.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.834 | Acc: 52.147,77.266,94.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.324 | Acc: 44.531,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.592 | Acc: 46.317,63.914,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.663 | Acc: 46.742,63.434,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.683 | Acc: 46.542,63.166,67.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.591 | Acc: 54.688,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.720 | Acc: 54.464,80.246,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.742 | Acc: 53.030,79.364,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.724 | Acc: 53.215,79.086,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.759 | Acc: 52.459,78.935,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 52.398,78.821,95.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.751 | Acc: 52.583,78.777,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.759 | Acc: 52.787,78.640,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.757 | Acc: 52.863,78.688,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.761 | Acc: 52.758,78.600,95.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.771 | Acc: 52.694,78.479,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.780 | Acc: 52.517,78.330,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.785 | Acc: 52.473,78.313,94.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.794 | Acc: 52.344,78.095,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.801 | Acc: 52.335,77.969,94.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.804 | Acc: 52.279,77.969,94.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.810 | Acc: 52.149,77.869,94.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.817 | Acc: 52.179,77.781,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.824 | Acc: 52.181,77.677,94.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 52.167,77.690,94.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.600 | Acc: 47.656,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.811 | Acc: 46.689,62.537,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.828 | Acc: 46.094,62.062,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.829 | Acc: 45.940,62.141,67.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 2.841 | Acc: 47.656,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.769 | Acc: 51.897,79.315,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.784 | Acc: 52.134,79.154,95.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.779 | Acc: 52.254,78.765,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.753 | Acc: 52.855,78.675,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.757 | Acc: 53.102,78.519,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.742 | Acc: 53.448,78.661,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.745 | Acc: 53.341,78.535,95.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.749 | Acc: 53.285,78.450,95.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.756 | Acc: 53.142,78.410,95.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.760 | Acc: 53.121,78.234,94.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.767 | Acc: 52.994,78.065,94.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.773 | Acc: 53.005,77.960,94.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.786 | Acc: 52.805,77.844,94.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.791 | Acc: 52.663,77.830,94.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.791 | Acc: 52.645,77.907,94.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.798 | Acc: 52.573,77.762,94.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.806 | Acc: 52.557,77.694,94.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.812 | Acc: 52.467,77.623,94.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.817 | Acc: 52.418,77.596,94.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.519 | Acc: 46.875,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.892 | Acc: 44.494,62.314,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.891 | Acc: 45.046,61.871,67.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.877 | Acc: 44.941,62.013,67.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 2.884 | Acc: 51.562,77.344,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.782 | Acc: 52.790,78.088,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.791 | Acc: 52.934,77.954,94.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.776 | Acc: 52.856,78.420,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.784 | Acc: 52.527,78.164,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.767 | Acc: 52.645,78.496,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.752 | Acc: 52.867,78.416,94.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.757 | Acc: 52.848,78.358,94.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.764 | Acc: 52.819,78.411,94.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.773 | Acc: 52.836,78.319,94.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.777 | Acc: 52.732,78.343,94.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.779 | Acc: 52.676,78.249,94.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.778 | Acc: 52.730,78.248,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.787 | Acc: 52.619,78.152,94.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.789 | Acc: 52.613,78.167,94.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.797 | Acc: 52.528,78.016,94.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.802 | Acc: 52.431,77.896,94.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.808 | Acc: 52.396,77.845,94.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.811 | Acc: 52.339,77.798,94.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.819 | Acc: 52.319,77.696,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.321 | Acc: 44.531,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.729 | Acc: 45.945,62.946,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.793 | Acc: 45.846,62.652,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.795 | Acc: 45.594,62.602,67.316,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 2.956 | Acc: 47.656,77.344,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.860 | Acc: 51.823,77.158,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.788 | Acc: 52.649,78.220,94.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.759 | Acc: 52.497,78.509,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.745 | Acc: 52.951,78.684,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 52.553,78.527,95.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.779 | Acc: 52.279,78.370,94.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.770 | Acc: 52.405,78.435,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.773 | Acc: 52.319,78.358,95.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.766 | Acc: 52.503,78.462,94.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.764 | Acc: 52.565,78.455,94.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.764 | Acc: 52.563,78.334,94.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.770 | Acc: 52.441,78.206,94.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.769 | Acc: 52.523,78.167,94.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.768 | Acc: 52.600,78.119,94.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.779 | Acc: 52.497,78.037,94.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.786 | Acc: 52.482,77.933,94.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.794 | Acc: 52.442,77.786,94.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.797 | Acc: 52.419,77.753,94.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.799 | Acc: 52.426,77.752,94.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.562 | Acc: 49.219,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.673 | Acc: 44.903,63.876,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.730 | Acc: 45.351,63.091,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.730 | Acc: 45.364,63.166,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 3.038 | Acc: 44.531,80.469,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.758 | Acc: 52.530,79.092,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 51.886,78.697,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.784 | Acc: 52.062,78.484,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.755 | Acc: 52.826,78.781,94.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.776 | Acc: 52.707,78.512,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.770 | Acc: 52.796,78.467,94.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.768 | Acc: 52.998,78.396,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.774 | Acc: 52.902,78.222,94.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.779 | Acc: 52.680,78.047,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.783 | Acc: 52.659,78.059,94.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.781 | Acc: 52.768,78.083,94.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.781 | Acc: 52.798,77.960,94.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.788 | Acc: 52.721,77.856,94.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.798 | Acc: 52.661,77.675,94.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.800 | Acc: 52.653,77.707,94.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.803 | Acc: 52.546,77.702,94.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.809 | Acc: 52.502,77.552,94.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.809 | Acc: 52.623,77.539,94.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.813 | Acc: 52.610,77.473,94.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.263 | Acc: 47.656,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.872 | Acc: 44.271,62.426,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.919 | Acc: 44.893,62.176,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.918 | Acc: 44.570,62.346,67.034,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.743 | Acc: 46.094,78.125,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.722 | Acc: 52.679,78.013,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.728 | Acc: 52.572,78.506,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 53.074,78.573,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.718 | Acc: 52.942,78.887,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.699 | Acc: 53.303,79.038,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.698 | Acc: 53.319,79.055,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.716 | Acc: 53.103,78.757,95.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.722 | Acc: 52.926,78.766,95.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.728 | Acc: 53.008,78.621,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.739 | Acc: 52.903,78.525,95.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.741 | Acc: 52.874,78.425,95.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.744 | Acc: 52.911,78.443,95.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.753 | Acc: 52.805,78.230,95.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.756 | Acc: 52.808,78.225,95.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.765 | Acc: 52.764,78.019,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.772 | Acc: 52.726,77.955,94.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.782 | Acc: 52.635,77.850,94.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.787 | Acc: 52.634,77.761,94.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.793 | Acc: 52.678,77.748,94.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 42.188,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.105 | Acc: 42.448,61.905,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.162 | Acc: 42.702,60.918,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.178 | Acc: 42.316,60.297,66.176,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 2.989 | Acc: 45.312,72.656,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.666 | Acc: 53.571,79.799,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.575 | Acc: 53.925,80.164,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.502 | Acc: 55.571,81.276,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.466 | Acc: 55.941,82.060,97.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.444 | Acc: 56.119,82.611,97.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.433 | Acc: 56.121,82.884,97.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.419 | Acc: 56.239,83.073,97.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.417 | Acc: 56.158,83.109,97.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.403 | Acc: 56.297,83.257,97.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.391 | Acc: 56.468,83.458,97.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.381 | Acc: 56.515,83.696,98.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.368 | Acc: 56.594,83.908,98.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.361 | Acc: 56.591,83.995,98.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.357 | Acc: 56.517,84.055,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.355 | Acc: 56.434,84.118,98.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.351 | Acc: 56.355,84.222,98.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.347 | Acc: 56.376,84.288,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.341 | Acc: 56.423,84.345,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.336 | Acc: 56.432,84.451,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.477 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.933 | Acc: 52.641,68.899,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.970 | Acc: 52.325,68.293,72.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.971 | Acc: 52.318,68.558,73.169,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 2.243 | Acc: 57.031,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.323 | Acc: 55.878,84.747,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.272 | Acc: 56.650,85.537,99.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.249 | Acc: 56.673,86.194,99.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.228 | Acc: 56.916,86.275,99.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.232 | Acc: 56.907,86.340,99.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.221 | Acc: 57.025,86.454,99.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.208 | Acc: 57.137,86.658,99.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.205 | Acc: 57.279,86.651,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.203 | Acc: 57.411,86.628,99.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.203 | Acc: 57.404,86.583,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.206 | Acc: 57.452,86.461,99.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.202 | Acc: 57.466,86.553,99.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.205 | Acc: 57.366,86.596,99.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.198 | Acc: 57.548,86.652,99.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.197 | Acc: 57.556,86.646,99.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.197 | Acc: 57.547,86.697,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.199 | Acc: 57.563,86.659,99.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.199 | Acc: 57.568,86.641,99.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.199 | Acc: 57.558,86.680,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.464 | Acc: 58.594,71.875,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.918 | Acc: 53.460,69.903,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.953 | Acc: 52.725,68.712,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.955 | Acc: 52.664,68.776,73.694,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 2.324 | Acc: 57.031,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.145 | Acc: 58.147,87.612,99.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.183 | Acc: 57.203,87.576,99.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.183 | Acc: 57.262,87.398,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.179 | Acc: 57.398,87.365,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.161 | Acc: 57.921,87.593,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.152 | Acc: 58.019,87.649,99.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.155 | Acc: 58.012,87.561,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.153 | Acc: 58.109,87.578,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.151 | Acc: 57.925,87.543,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.157 | Acc: 57.836,87.508,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.152 | Acc: 57.880,87.532,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.155 | Acc: 57.787,87.458,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.153 | Acc: 57.824,87.413,99.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.150 | Acc: 57.952,87.414,99.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.153 | Acc: 57.893,87.394,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.155 | Acc: 57.856,87.342,99.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.157 | Acc: 57.831,87.369,99.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.158 | Acc: 57.800,87.409,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.156 | Acc: 57.808,87.443,99.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.463 | Acc: 57.812,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.893 | Acc: 53.348,69.680,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.935 | Acc: 52.591,68.769,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.933 | Acc: 52.613,68.891,73.758,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 2.091 | Acc: 57.031,89.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.111 | Acc: 59.077,88.058,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.128 | Acc: 58.899,87.976,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.116 | Acc: 58.824,88.371,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.136 | Acc: 58.449,88.252,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.128 | Acc: 58.601,88.181,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.132 | Acc: 58.445,88.094,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.126 | Acc: 58.428,88.043,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.127 | Acc: 58.346,87.985,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.125 | Acc: 58.382,87.949,99.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.126 | Acc: 58.368,87.928,99.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.127 | Acc: 58.265,87.903,99.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.126 | Acc: 58.292,87.957,99.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.126 | Acc: 58.202,87.979,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.126 | Acc: 58.230,88.031,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.130 | Acc: 58.147,87.933,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.127 | Acc: 58.168,88.004,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.133 | Acc: 58.021,87.949,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.134 | Acc: 58.072,87.920,99.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.135 | Acc: 57.981,87.929,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.468 | Acc: 54.688,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.902 | Acc: 53.423,69.531,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.928 | Acc: 52.934,68.540,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.923 | Acc: 52.792,68.840,73.617,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.869 | Acc: 65.625,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.052 | Acc: 59.821,88.839,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.089 | Acc: 58.803,88.319,99.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.091 | Acc: 58.735,88.140,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.092 | Acc: 58.845,88.117,99.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.090 | Acc: 58.578,88.274,99.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.102 | Acc: 58.407,88.352,99.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.107 | Acc: 58.228,88.270,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.102 | Acc: 58.142,88.291,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.096 | Acc: 58.356,88.242,99.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.097 | Acc: 58.376,88.258,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.097 | Acc: 58.396,88.260,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.095 | Acc: 58.406,88.349,99.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.098 | Acc: 58.399,88.416,99.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.105 | Acc: 58.313,88.384,99.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.108 | Acc: 58.264,88.250,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.109 | Acc: 58.231,88.284,99.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.109 | Acc: 58.142,88.320,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.107 | Acc: 58.258,88.357,99.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.110 | Acc: 58.241,88.277,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.426 | Acc: 57.031,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.884 | Acc: 53.274,69.568,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.923 | Acc: 52.954,68.902,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.918 | Acc: 52.894,68.814,73.745,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 2.016 | Acc: 59.375,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.055 | Acc: 59.710,88.988,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.065 | Acc: 59.280,88.815,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.073 | Acc: 58.824,88.653,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.051 | Acc: 59.095,89.053,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.066 | Acc: 59.135,88.954,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.077 | Acc: 58.813,89.017,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.077 | Acc: 58.682,88.985,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.083 | Acc: 58.497,88.912,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.080 | Acc: 58.443,88.816,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.081 | Acc: 58.337,88.860,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.084 | Acc: 58.314,88.766,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.087 | Acc: 58.325,88.686,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.092 | Acc: 58.202,88.646,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.092 | Acc: 58.193,88.607,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.095 | Acc: 58.145,88.613,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.094 | Acc: 58.165,88.583,99.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.094 | Acc: 58.156,88.522,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.089 | Acc: 58.334,88.504,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.091 | Acc: 58.376,88.497,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.441 | Acc: 58.594,75.000,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.885 | Acc: 53.795,69.903,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.923 | Acc: 53.487,68.788,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.926 | Acc: 53.343,68.737,73.591,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 2.022 | Acc: 63.281,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.080 | Acc: 58.296,88.988,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.065 | Acc: 58.479,89.005,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.078 | Acc: 58.338,89.101,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.066 | Acc: 58.353,89.101,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.064 | Acc: 58.803,89.101,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.055 | Acc: 59.123,88.933,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.054 | Acc: 59.242,89.057,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.068 | Acc: 58.890,88.849,99.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.068 | Acc: 58.948,88.847,99.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.066 | Acc: 58.850,88.860,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.066 | Acc: 58.891,88.857,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.068 | Acc: 58.714,88.894,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.070 | Acc: 58.552,88.925,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.070 | Acc: 58.513,88.935,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.073 | Acc: 58.493,88.865,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.077 | Acc: 58.436,88.787,99.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.076 | Acc: 58.481,88.815,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.077 | Acc: 58.475,88.783,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.079 | Acc: 58.510,88.753,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.377 | Acc: 56.250,76.562,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.881 | Acc: 53.497,70.275,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.923 | Acc: 53.544,69.131,73.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.921 | Acc: 53.227,69.083,73.566,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 2.224 | Acc: 58.594,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.052 | Acc: 57.812,89.286,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.045 | Acc: 58.613,89.405,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.031 | Acc: 59.029,89.972,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.042 | Acc: 59.134,89.574,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.046 | Acc: 59.135,89.534,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.052 | Acc: 58.878,89.527,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.056 | Acc: 58.699,89.556,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.057 | Acc: 58.686,89.465,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.059 | Acc: 58.732,89.347,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.065 | Acc: 58.668,89.230,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.059 | Acc: 58.841,89.317,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.061 | Acc: 58.740,89.221,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.061 | Acc: 58.660,89.227,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.061 | Acc: 58.608,89.210,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.065 | Acc: 58.578,89.146,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.067 | Acc: 58.603,89.082,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.068 | Acc: 58.633,89.049,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.068 | Acc: 58.620,89.028,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.070 | Acc: 58.571,88.976,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.450 | Acc: 57.031,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.892 | Acc: 53.534,70.126,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.933 | Acc: 53.239,68.979,73.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.927 | Acc: 52.933,69.160,73.847,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 2.142 | Acc: 56.250,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.015 | Acc: 59.189,89.249,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.005 | Acc: 59.013,89.291,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.030 | Acc: 58.632,89.293,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.045 | Acc: 58.574,89.246,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.052 | Acc: 58.485,89.372,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.043 | Acc: 58.549,89.256,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.043 | Acc: 58.505,89.356,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.040 | Acc: 58.628,89.261,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.044 | Acc: 58.607,89.278,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.052 | Acc: 58.477,89.257,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.056 | Acc: 58.424,89.292,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.061 | Acc: 58.503,89.270,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.064 | Acc: 58.549,89.251,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.062 | Acc: 58.577,89.265,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.055 | Acc: 58.807,89.301,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.056 | Acc: 58.769,89.223,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.057 | Acc: 58.800,89.237,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.059 | Acc: 58.760,89.199,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.057 | Acc: 58.801,89.186,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.437 | Acc: 59.375,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.883 | Acc: 53.534,70.089,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.917 | Acc: 53.487,68.921,73.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.915 | Acc: 53.087,68.840,73.796,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 2.159 | Acc: 60.156,86.719,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.012 | Acc: 59.896,89.435,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.020 | Acc: 59.680,89.539,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.026 | Acc: 59.375,89.664,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.031 | Acc: 59.057,89.824,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.033 | Acc: 58.787,89.728,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.049 | Acc: 58.652,89.547,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.041 | Acc: 58.671,89.727,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.042 | Acc: 58.657,89.596,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.037 | Acc: 58.801,89.619,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.044 | Acc: 58.776,89.502,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.041 | Acc: 58.806,89.497,99.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.044 | Acc: 58.937,89.442,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.043 | Acc: 58.947,89.413,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.042 | Acc: 58.944,89.371,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.042 | Acc: 58.952,89.358,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.044 | Acc: 58.905,89.342,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.046 | Acc: 58.832,89.376,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.047 | Acc: 58.836,89.363,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.046 | Acc: 58.799,89.335,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.394 | Acc: 57.812,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.872 | Acc: 54.427,69.754,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.911 | Acc: 54.021,68.845,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.909 | Acc: 53.509,68.763,73.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 2.400 | Acc: 53.906,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.028 | Acc: 59.710,89.881,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 59.985,89.710,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.013 | Acc: 59.362,89.997,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.019 | Acc: 59.433,89.844,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.026 | Acc: 59.120,89.728,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.038 | Acc: 58.678,89.463,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.038 | Acc: 58.688,89.450,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.043 | Acc: 58.701,89.451,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.041 | Acc: 58.848,89.321,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.040 | Acc: 58.710,89.420,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.042 | Acc: 58.626,89.451,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.036 | Acc: 58.727,89.555,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.032 | Acc: 58.782,89.652,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.032 | Acc: 58.855,89.682,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.033 | Acc: 58.778,89.680,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.035 | Acc: 58.771,89.686,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.034 | Acc: 58.772,89.651,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.031 | Acc: 58.786,89.679,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.033 | Acc: 58.764,89.616,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.458 | Acc: 57.031,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.862 | Acc: 54.167,69.792,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.899 | Acc: 53.620,68.750,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.897 | Acc: 53.407,68.827,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 2.127 | Acc: 60.938,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.001 | Acc: 60.305,90.030,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.002 | Acc: 60.118,90.130,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.015 | Acc: 59.734,90.023,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.027 | Acc: 59.549,89.757,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.010 | Acc: 59.924,90.029,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.009 | Acc: 59.930,89.921,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.011 | Acc: 59.874,89.833,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.011 | Acc: 59.720,89.878,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.013 | Acc: 59.509,89.969,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.012 | Acc: 59.515,89.968,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.014 | Acc: 59.481,89.957,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.018 | Acc: 59.339,89.964,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.023 | Acc: 59.252,89.880,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.024 | Acc: 59.272,89.824,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.024 | Acc: 59.349,89.776,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.024 | Acc: 59.314,89.746,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.027 | Acc: 59.242,89.677,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.025 | Acc: 59.319,89.638,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.029 | Acc: 59.205,89.606,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.461 | Acc: 58.594,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.854 | Acc: 53.943,70.015,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.897 | Acc: 53.792,68.521,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.897 | Acc: 53.471,68.481,73.886,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 1.830 | Acc: 66.406,87.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.968 | Acc: 59.784,90.551,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.979 | Acc: 59.451,90.206,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.986 | Acc: 59.221,89.933,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.983 | Acc: 59.635,89.979,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.990 | Acc: 59.669,90.076,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.003 | Acc: 59.517,89.844,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.012 | Acc: 59.275,89.805,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.014 | Acc: 59.166,89.800,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.019 | Acc: 59.099,89.770,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.021 | Acc: 59.033,89.824,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.021 | Acc: 58.965,89.770,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.018 | Acc: 59.012,89.724,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.021 | Acc: 58.875,89.679,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.024 | Acc: 58.833,89.644,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.021 | Acc: 58.978,89.649,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.023 | Acc: 58.937,89.669,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.021 | Acc: 58.940,89.704,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.022 | Acc: 58.955,89.729,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.025 | Acc: 58.944,89.696,99.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.481 | Acc: 56.250,71.875,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.863 | Acc: 54.688,70.052,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.899 | Acc: 54.078,68.998,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.900 | Acc: 53.599,69.083,73.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.998 | Acc: 55.469,85.156,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.001 | Acc: 57.924,90.365,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.006 | Acc: 58.727,90.111,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.013 | Acc: 58.607,90.330,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.024 | Acc: 58.893,89.988,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.021 | Acc: 59.097,89.890,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.022 | Acc: 59.072,89.947,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.019 | Acc: 58.921,90.093,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.019 | Acc: 58.880,90.048,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.021 | Acc: 58.917,90.060,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.014 | Acc: 59.002,90.112,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.015 | Acc: 58.933,90.049,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.018 | Acc: 58.905,90.064,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.013 | Acc: 59.022,90.056,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.014 | Acc: 59.108,90.016,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.016 | Acc: 59.121,89.968,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.020 | Acc: 59.124,89.863,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.017 | Acc: 59.228,89.878,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.016 | Acc: 59.258,89.891,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.016 | Acc: 59.281,89.842,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.434 | Acc: 56.250,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.850 | Acc: 53.981,70.424,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.898 | Acc: 53.963,69.379,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.905 | Acc: 53.509,69.185,73.809,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 2.137 | Acc: 57.031,85.938,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 59.375,90.253,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.969 | Acc: 60.004,90.053,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.996 | Acc: 59.388,90.061,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.987 | Acc: 59.240,90.471,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.981 | Acc: 59.344,90.470,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.974 | Acc: 59.407,90.464,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.983 | Acc: 59.309,90.453,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.986 | Acc: 59.259,90.329,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.991 | Acc: 59.176,90.310,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.996 | Acc: 59.177,90.244,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.996 | Acc: 59.170,90.197,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.999 | Acc: 59.180,90.113,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.005 | Acc: 59.118,89.987,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.003 | Acc: 59.200,89.974,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.004 | Acc: 59.287,89.950,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.003 | Acc: 59.278,89.892,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.004 | Acc: 59.226,89.940,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.003 | Acc: 59.182,89.958,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.003 | Acc: 59.215,89.942,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.440 | Acc: 58.594,75.781,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.865 | Acc: 54.241,70.312,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.905 | Acc: 53.659,69.055,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.904 | Acc: 53.202,69.032,74.014,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.969 | Acc: 62.500,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.006 | Acc: 60.231,89.695,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.974 | Acc: 60.328,90.339,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.987 | Acc: 59.990,90.420,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.986 | Acc: 59.963,90.365,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.983 | Acc: 59.886,90.447,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.984 | Acc: 59.717,90.412,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.979 | Acc: 59.730,90.464,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.983 | Acc: 59.690,90.378,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.986 | Acc: 59.617,90.353,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.986 | Acc: 59.604,90.376,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.988 | Acc: 59.573,90.381,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.988 | Acc: 59.557,90.353,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.989 | Acc: 59.561,90.284,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.992 | Acc: 59.514,90.200,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.993 | Acc: 59.463,90.225,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.992 | Acc: 59.487,90.238,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.991 | Acc: 59.478,90.222,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.993 | Acc: 59.399,90.177,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.999 | Acc: 59.268,90.104,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.478 | Acc: 57.812,71.094,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.866 | Acc: 54.576,69.159,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.908 | Acc: 53.925,68.274,73.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.907 | Acc: 53.599,68.519,73.783,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 2.069 | Acc: 57.812,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.938 | Acc: 61.272,91.034,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.938 | Acc: 60.728,90.873,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.941 | Acc: 60.118,90.996,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.954 | Acc: 59.809,90.885,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.965 | Acc: 59.584,90.664,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.968 | Acc: 59.724,90.638,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.976 | Acc: 59.630,90.603,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.979 | Acc: 59.501,90.543,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.979 | Acc: 59.660,90.500,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.979 | Acc: 59.655,90.466,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.980 | Acc: 59.700,90.395,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.979 | Acc: 59.793,90.366,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.986 | Acc: 59.644,90.236,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.985 | Acc: 59.650,90.239,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.985 | Acc: 59.640,90.285,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.988 | Acc: 59.509,90.216,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.992 | Acc: 59.446,90.208,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.994 | Acc: 59.429,90.190,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.992 | Acc: 59.469,90.203,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.517 | Acc: 57.812,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.890 | Acc: 54.092,69.494,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.920 | Acc: 53.754,68.807,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.921 | Acc: 53.599,68.878,74.129,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.848 | Acc: 60.156,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.981 | Acc: 60.119,90.439,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.915 | Acc: 61.033,91.044,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.926 | Acc: 60.669,91.124,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.941 | Acc: 60.301,91.088,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.959 | Acc: 60.017,90.803,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.966 | Acc: 59.853,90.638,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.972 | Acc: 59.641,90.697,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.982 | Acc: 59.302,90.654,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.981 | Acc: 59.336,90.677,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.984 | Acc: 59.270,90.613,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.981 | Acc: 59.361,90.682,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.986 | Acc: 59.326,90.615,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.984 | Acc: 59.315,90.625,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.980 | Acc: 59.419,90.625,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.981 | Acc: 59.365,90.578,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.985 | Acc: 59.295,90.533,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.986 | Acc: 59.304,90.488,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.989 | Acc: 59.239,90.422,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.989 | Acc: 59.244,90.397,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.424 | Acc: 57.812,75.000,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.881 | Acc: 54.129,69.643,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.914 | Acc: 53.906,68.712,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.907 | Acc: 53.676,68.814,73.847,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 1.977 | Acc: 58.594,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.937 | Acc: 60.305,91.629,99.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.922 | Acc: 60.156,91.673,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.939 | Acc: 60.003,91.278,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.946 | Acc: 59.954,91.078,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.945 | Acc: 60.280,91.019,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.956 | Acc: 59.898,90.845,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.967 | Acc: 59.890,90.680,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.968 | Acc: 59.826,90.513,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.970 | Acc: 59.720,90.483,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.972 | Acc: 59.667,90.462,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.976 | Acc: 59.714,90.406,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.980 | Acc: 59.599,90.349,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.978 | Acc: 59.701,90.377,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.980 | Acc: 59.753,90.264,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.980 | Acc: 59.692,90.269,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.977 | Acc: 59.738,90.292,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.982 | Acc: 59.638,90.236,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.981 | Acc: 59.667,90.203,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.980 | Acc: 59.666,90.211,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.461 | Acc: 57.812,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.869 | Acc: 54.167,69.531,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.904 | Acc: 53.830,68.636,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.897 | Acc: 53.381,68.712,74.206,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 2.220 | Acc: 57.812,92.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.950 | Acc: 58.557,90.551,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.973 | Acc: 58.708,90.568,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.006 | Acc: 58.171,90.523,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.981 | Acc: 58.989,90.557,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.971 | Acc: 59.135,90.625,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.962 | Acc: 59.459,90.916,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.965 | Acc: 59.464,90.896,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.959 | Acc: 59.618,90.921,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.955 | Acc: 59.759,90.884,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.956 | Acc: 59.725,90.858,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.959 | Acc: 59.668,90.819,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.968 | Acc: 59.437,90.693,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.968 | Acc: 59.444,90.715,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.970 | Acc: 59.461,90.678,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.971 | Acc: 59.492,90.641,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.973 | Acc: 59.533,90.579,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.970 | Acc: 59.652,90.570,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.973 | Acc: 59.533,90.569,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.975 | Acc: 59.504,90.512,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.508 | Acc: 59.375,74.219,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.870 | Acc: 54.241,69.494,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.916 | Acc: 53.849,68.464,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.913 | Acc: 53.586,68.622,74.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 2.010 | Acc: 59.375,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.983 | Acc: 60.119,90.923,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.948 | Acc: 59.794,91.540,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 59.990,91.086,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.955 | Acc: 59.848,91.329,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.945 | Acc: 60.009,91.151,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.945 | Acc: 60.046,91.083,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.953 | Acc: 59.912,90.874,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.955 | Acc: 59.880,90.936,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.952 | Acc: 59.897,90.979,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.960 | Acc: 59.838,90.862,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.963 | Acc: 59.711,90.812,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.964 | Acc: 59.664,90.751,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.970 | Acc: 59.564,90.613,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.971 | Acc: 59.533,90.681,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.970 | Acc: 59.510,90.695,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.969 | Acc: 59.572,90.647,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.967 | Acc: 59.554,90.659,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.969 | Acc: 59.591,90.614,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.971 | Acc: 59.560,90.594,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.552 | Acc: 54.688,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.882 | Acc: 53.348,68.936,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.928 | Acc: 53.068,68.045,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.917 | Acc: 53.163,68.340,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 2.046 | Acc: 57.031,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.940 | Acc: 59.561,91.369,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 60.061,91.197,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.948 | Acc: 59.734,91.163,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.958 | Acc: 59.664,91.049,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.969 | Acc: 59.406,90.842,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.963 | Acc: 59.511,90.903,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.972 | Acc: 59.236,90.719,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.969 | Acc: 59.341,90.761,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.968 | Acc: 59.284,90.763,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.965 | Acc: 59.387,90.804,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.963 | Acc: 59.463,90.738,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.965 | Acc: 59.485,90.667,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.966 | Acc: 59.492,90.679,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.966 | Acc: 59.564,90.667,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.964 | Acc: 59.577,90.698,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.963 | Acc: 59.565,90.637,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.959 | Acc: 59.719,90.678,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.962 | Acc: 59.646,90.599,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.962 | Acc: 59.627,90.551,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.425 | Acc: 60.156,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.852 | Acc: 55.022,70.052,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.898 | Acc: 54.364,68.902,73.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.906 | Acc: 53.842,68.916,73.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 2.206 | Acc: 57.812,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.933 | Acc: 61.421,91.815,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.936 | Acc: 61.109,91.025,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 60.579,90.651,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.952 | Acc: 60.552,90.934,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.954 | Acc: 60.288,90.842,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.954 | Acc: 60.066,90.748,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.951 | Acc: 60.250,90.769,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.942 | Acc: 60.394,90.916,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.941 | Acc: 60.368,91.013,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.944 | Acc: 60.168,90.936,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.951 | Acc: 60.050,90.915,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.957 | Acc: 59.874,90.878,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.957 | Acc: 59.788,90.838,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.957 | Acc: 59.739,90.856,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.955 | Acc: 59.723,90.861,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.956 | Acc: 59.694,90.927,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.953 | Acc: 59.824,90.953,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.952 | Acc: 59.903,90.954,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.957 | Acc: 59.812,90.871,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.499 | Acc: 57.031,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.870 | Acc: 54.390,69.717,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.919 | Acc: 54.230,68.636,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.923 | Acc: 53.893,68.712,73.719,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 2.008 | Acc: 57.031,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.910 | Acc: 60.640,91.406,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.930 | Acc: 60.499,91.311,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.951 | Acc: 59.849,91.099,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.947 | Acc: 59.896,90.953,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.950 | Acc: 59.692,91.166,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.948 | Acc: 59.853,91.225,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.949 | Acc: 59.901,91.262,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.944 | Acc: 60.016,91.173,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.948 | Acc: 59.966,91.083,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.956 | Acc: 59.845,90.917,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.949 | Acc: 59.916,90.971,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.950 | Acc: 59.903,90.959,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.954 | Acc: 59.803,90.867,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.953 | Acc: 59.842,90.859,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.951 | Acc: 59.850,90.960,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.951 | Acc: 59.927,90.915,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.952 | Acc: 59.943,90.884,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.953 | Acc: 59.929,90.917,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.954 | Acc: 59.929,90.931,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.498 | Acc: 56.250,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.861 | Acc: 54.315,69.271,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.908 | Acc: 53.735,68.388,73.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.909 | Acc: 53.394,68.571,73.809,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 1.695 | Acc: 64.844,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.917 | Acc: 59.784,91.257,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.917 | Acc: 59.870,91.254,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.929 | Acc: 59.772,91.073,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.930 | Acc: 59.635,91.001,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.931 | Acc: 59.537,90.996,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.934 | Acc: 59.524,91.129,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.934 | Acc: 59.563,91.085,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.931 | Acc: 59.763,91.023,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.934 | Acc: 59.768,90.940,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.943 | Acc: 59.694,90.850,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.943 | Acc: 59.675,90.851,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.947 | Acc: 59.634,90.790,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.949 | Acc: 59.692,90.796,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.951 | Acc: 59.567,90.772,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.951 | Acc: 59.577,90.783,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.950 | Acc: 59.640,90.766,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.949 | Acc: 59.726,90.762,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.948 | Acc: 59.791,90.800,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.949 | Acc: 59.732,90.803,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.503 | Acc: 58.594,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.881 | Acc: 54.278,69.531,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.922 | Acc: 53.982,68.407,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.920 | Acc: 53.881,68.776,74.039,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 2.123 | Acc: 57.031,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.960 | Acc: 59.338,91.109,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.906 | Acc: 60.518,91.559,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.936 | Acc: 60.041,91.368,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.940 | Acc: 59.857,90.963,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.939 | Acc: 60.002,91.081,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.933 | Acc: 60.150,91.167,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.942 | Acc: 60.051,91.018,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.935 | Acc: 60.117,91.115,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.940 | Acc: 59.940,91.035,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.939 | Acc: 59.900,91.076,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.929 | Acc: 60.153,91.198,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.927 | Acc: 60.208,91.186,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.925 | Acc: 60.192,91.233,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.931 | Acc: 60.112,91.078,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.936 | Acc: 59.959,91.043,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.940 | Acc: 59.889,91.034,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.944 | Acc: 59.806,90.964,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.945 | Acc: 59.836,90.980,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.946 | Acc: 59.787,90.933,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.552 | Acc: 58.594,74.219,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.894 | Acc: 54.241,69.717,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.921 | Acc: 53.887,68.769,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.919 | Acc: 53.765,68.814,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 2.157 | Acc: 49.219,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.959 | Acc: 59.487,90.365,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 59.604,91.178,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.955 | Acc: 59.606,91.278,99.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.939 | Acc: 60.069,91.184,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.935 | Acc: 59.947,91.282,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.936 | Acc: 59.917,91.264,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.943 | Acc: 59.796,91.140,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.936 | Acc: 60.001,91.135,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.938 | Acc: 59.949,91.126,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.939 | Acc: 59.935,91.134,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.935 | Acc: 59.958,91.169,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.936 | Acc: 59.946,91.108,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.936 | Acc: 59.851,91.092,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.937 | Acc: 59.917,91.073,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.934 | Acc: 59.975,91.105,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.933 | Acc: 60.022,91.126,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.934 | Acc: 60.005,91.136,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.936 | Acc: 59.953,91.090,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.936 | Acc: 59.994,91.052,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.548 | Acc: 58.594,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.869 | Acc: 53.943,69.754,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.905 | Acc: 53.830,68.521,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.910 | Acc: 53.676,68.609,74.296,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.905 | Acc: 57.812,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.934 | Acc: 60.268,92.150,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.928 | Acc: 59.928,91.749,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.931 | Acc: 59.593,91.867,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.923 | Acc: 60.118,91.763,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.932 | Acc: 59.901,91.685,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.937 | Acc: 59.950,91.393,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.936 | Acc: 59.868,91.345,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.944 | Acc: 59.773,91.168,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.946 | Acc: 59.643,90.966,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.944 | Acc: 59.663,91.049,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.941 | Acc: 59.732,91.074,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.938 | Acc: 59.826,91.127,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.937 | Acc: 59.908,91.044,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.934 | Acc: 59.973,91.045,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.932 | Acc: 60.013,91.061,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.932 | Acc: 60.047,91.068,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.933 | Acc: 60.046,91.031,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.933 | Acc: 60.068,91.010,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.937 | Acc: 59.970,90.969,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.529 | Acc: 57.031,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.856 | Acc: 54.464,69.940,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.900 | Acc: 53.811,68.712,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.899 | Acc: 53.548,68.712,74.270,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.945 | Acc: 57.812,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.959 | Acc: 60.268,91.443,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.929 | Acc: 60.137,92.168,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.920 | Acc: 60.412,92.328,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.912 | Acc: 60.802,92.024,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.933 | Acc: 60.087,91.801,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.936 | Acc: 59.956,91.665,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.932 | Acc: 60.051,91.672,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.925 | Acc: 60.200,91.639,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.929 | Acc: 60.061,91.549,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.929 | Acc: 60.079,91.476,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.930 | Acc: 60.057,91.374,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.925 | Acc: 60.114,91.380,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.925 | Acc: 60.237,91.358,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.927 | Acc: 60.090,91.289,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.929 | Acc: 60.039,91.279,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.933 | Acc: 59.988,91.219,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.932 | Acc: 59.987,91.193,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.935 | Acc: 59.860,91.149,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.935 | Acc: 59.884,91.142,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.537 | Acc: 60.156,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.847 | Acc: 54.874,69.903,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.886 | Acc: 54.078,68.998,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.890 | Acc: 53.919,69.032,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.966 | Acc: 58.594,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.919 | Acc: 61.756,91.481,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.910 | Acc: 61.147,91.692,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.901 | Acc: 61.027,91.803,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.898 | Acc: 61.053,91.879,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.918 | Acc: 60.582,91.522,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.914 | Acc: 60.653,91.503,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.914 | Acc: 60.616,91.417,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.916 | Acc: 60.472,91.367,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.913 | Acc: 60.432,91.320,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.912 | Acc: 60.491,91.204,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.916 | Acc: 60.436,91.194,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.913 | Acc: 60.406,91.325,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.916 | Acc: 60.426,91.400,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.917 | Acc: 60.409,91.367,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.919 | Acc: 60.312,91.365,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.922 | Acc: 60.283,91.343,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.924 | Acc: 60.250,91.260,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.926 | Acc: 60.182,91.255,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.927 | Acc: 60.125,91.238,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.490 | Acc: 58.594,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.887 | Acc: 54.799,68.973,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.916 | Acc: 54.173,68.388,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.908 | Acc: 53.778,68.776,73.847,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 1.664 | Acc: 63.281,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.930 | Acc: 59.635,91.704,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.900 | Acc: 60.385,91.978,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.904 | Acc: 60.438,91.880,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.908 | Acc: 60.455,91.715,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.909 | Acc: 60.280,91.801,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.909 | Acc: 60.260,91.697,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.912 | Acc: 60.383,91.656,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.914 | Acc: 60.404,91.600,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.915 | Acc: 60.320,91.600,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.915 | Acc: 60.265,91.503,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.917 | Acc: 60.255,91.470,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.915 | Acc: 60.198,91.588,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.912 | Acc: 60.201,91.526,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.911 | Acc: 60.273,91.498,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.917 | Acc: 60.138,91.414,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.918 | Acc: 60.147,91.375,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.921 | Acc: 60.124,91.317,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.920 | Acc: 60.139,91.292,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.920 | Acc: 60.146,91.298,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.578 | Acc: 56.250,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.903 | Acc: 54.278,69.457,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.937 | Acc: 53.811,68.331,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.926 | Acc: 53.586,68.468,73.822,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 2.029 | Acc: 57.031,86.719,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.843 | Acc: 61.570,92.634,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.843 | Acc: 60.938,92.473,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.853 | Acc: 60.976,92.392,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.871 | Acc: 60.774,91.985,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.880 | Acc: 60.528,91.917,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.885 | Acc: 60.434,91.845,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.892 | Acc: 60.345,91.705,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.895 | Acc: 60.472,91.644,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.899 | Acc: 60.450,91.575,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.901 | Acc: 60.382,91.507,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.906 | Acc: 60.252,91.442,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.910 | Acc: 60.185,91.468,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.915 | Acc: 60.057,91.445,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.918 | Acc: 59.959,91.440,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.919 | Acc: 60.013,91.370,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.920 | Acc: 60.020,91.294,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.921 | Acc: 59.996,91.260,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.923 | Acc: 59.996,91.231,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.925 | Acc: 59.994,91.181,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.522 | Acc: 59.375,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.870 | Acc: 54.353,69.382,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.910 | Acc: 54.040,68.693,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.914 | Acc: 53.727,68.814,73.694,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 1.761 | Acc: 59.375,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.894 | Acc: 60.193,91.964,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.906 | Acc: 60.061,91.825,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.881 | Acc: 60.400,92.303,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.885 | Acc: 60.503,92.168,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.901 | Acc: 60.102,92.087,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.899 | Acc: 60.253,92.065,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.898 | Acc: 60.289,91.977,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.904 | Acc: 60.171,91.862,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.908 | Acc: 60.087,91.777,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.914 | Acc: 59.966,91.674,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.910 | Acc: 60.040,91.710,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.917 | Acc: 59.903,91.656,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.919 | Acc: 59.956,91.595,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.920 | Acc: 60.001,91.554,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.918 | Acc: 60.071,91.572,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.915 | Acc: 60.161,91.586,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.915 | Acc: 60.200,91.562,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.913 | Acc: 60.269,91.556,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.915 | Acc: 60.185,91.515,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.527 | Acc: 57.812,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.866 | Acc: 54.278,69.457,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.911 | Acc: 53.849,68.617,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.918 | Acc: 53.727,68.571,74.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.958 | Acc: 60.156,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.892 | Acc: 59.747,91.295,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.877 | Acc: 60.366,91.768,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.888 | Acc: 60.348,91.675,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.894 | Acc: 60.224,91.590,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.906 | Acc: 59.909,91.607,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.903 | Acc: 60.098,91.619,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.903 | Acc: 60.029,91.694,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.908 | Acc: 59.986,91.629,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.908 | Acc: 60.087,91.596,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.911 | Acc: 60.110,91.585,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.910 | Acc: 60.121,91.526,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.909 | Acc: 60.104,91.484,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.908 | Acc: 60.219,91.448,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.908 | Acc: 60.298,91.428,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.906 | Acc: 60.359,91.398,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.909 | Acc: 60.246,91.355,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.910 | Acc: 60.241,91.365,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.907 | Acc: 60.241,91.343,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.911 | Acc: 60.146,91.330,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.502 | Acc: 55.469,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.885 | Acc: 54.501,69.457,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.907 | Acc: 53.887,68.845,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.912 | Acc: 53.599,68.737,73.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.890 | Acc: 60.938,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.882 | Acc: 60.454,92.374,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.893 | Acc: 60.556,92.245,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.905 | Acc: 60.195,91.931,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.913 | Acc: 59.963,91.889,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.906 | Acc: 60.156,91.886,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.905 | Acc: 60.266,91.703,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.907 | Acc: 60.140,91.650,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.901 | Acc: 60.375,91.712,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.902 | Acc: 60.260,91.752,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.904 | Acc: 60.269,91.694,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.905 | Acc: 60.241,91.710,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.906 | Acc: 60.221,91.730,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.907 | Acc: 60.237,91.679,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.907 | Acc: 60.276,91.673,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.906 | Acc: 60.195,91.609,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.902 | Acc: 60.322,91.628,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.904 | Acc: 60.342,91.640,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.905 | Acc: 60.321,91.610,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.904 | Acc: 60.341,91.609,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.573 | Acc: 57.031,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.897 | Acc: 53.385,69.420,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.925 | Acc: 53.468,68.331,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.922 | Acc: 53.394,68.545,74.014,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 1.917 | Acc: 59.375,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.873 | Acc: 61.012,91.518,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.906 | Acc: 60.099,91.482,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.905 | Acc: 59.785,91.240,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.910 | Acc: 59.877,91.532,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.899 | Acc: 60.497,91.313,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.884 | Acc: 60.744,91.471,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.886 | Acc: 60.666,91.534,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.891 | Acc: 60.700,91.401,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.889 | Acc: 60.666,91.449,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.890 | Acc: 60.607,91.430,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.892 | Acc: 60.513,91.463,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.890 | Acc: 60.519,91.516,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.888 | Acc: 60.584,91.478,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.890 | Acc: 60.565,91.415,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.894 | Acc: 60.475,91.326,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.899 | Acc: 60.431,91.294,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.901 | Acc: 60.378,91.333,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.901 | Acc: 60.438,91.309,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.903 | Acc: 60.408,91.283,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.472 | Acc: 57.812,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.880 | Acc: 53.943,69.010,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.914 | Acc: 53.792,68.388,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.917 | Acc: 53.663,68.327,73.975,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.196 | Acc: 52.344,90.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.941 | Acc: 59.412,91.592,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.902 | Acc: 60.442,91.997,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.893 | Acc: 60.438,92.021,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.894 | Acc: 60.532,91.917,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.892 | Acc: 60.466,91.940,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.898 | Acc: 60.369,91.742,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.899 | Acc: 60.361,91.722,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.898 | Acc: 60.413,91.853,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.897 | Acc: 60.545,91.903,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.898 | Acc: 60.413,91.892,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.898 | Acc: 60.333,91.880,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.899 | Acc: 60.425,91.857,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.901 | Acc: 60.420,91.828,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.899 | Acc: 60.420,91.795,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.900 | Acc: 60.351,91.759,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.899 | Acc: 60.424,91.730,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.898 | Acc: 60.438,91.743,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.897 | Acc: 60.448,91.722,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.900 | Acc: 60.365,91.683,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.506 | Acc: 58.594,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.883 | Acc: 53.534,69.420,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.919 | Acc: 53.449,68.293,74.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.924 | Acc: 53.202,68.379,74.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 2.105 | Acc: 58.594,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.870 | Acc: 60.677,92.150,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.872 | Acc: 60.328,92.302,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.872 | Acc: 60.515,91.803,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.878 | Acc: 60.368,92.024,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.882 | Acc: 60.442,91.839,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.879 | Acc: 60.492,91.787,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.879 | Acc: 60.622,91.755,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.886 | Acc: 60.350,91.688,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.885 | Acc: 60.463,91.678,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.886 | Acc: 60.405,91.686,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.885 | Acc: 60.411,91.601,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.884 | Acc: 60.490,91.646,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.889 | Acc: 60.396,91.646,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.892 | Acc: 60.359,91.637,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.889 | Acc: 60.475,91.593,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.892 | Acc: 60.414,91.577,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.893 | Acc: 60.436,91.596,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.893 | Acc: 60.407,91.627,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.896 | Acc: 60.314,91.599,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.575 | Acc: 56.250,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.881 | Acc: 54.092,68.973,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.908 | Acc: 53.944,68.407,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.908 | Acc: 53.778,68.430,74.052,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 1.749 | Acc: 64.844,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.885 | Acc: 61.272,92.076,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.885 | Acc: 60.842,92.302,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.872 | Acc: 60.976,92.316,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.860 | Acc: 61.188,92.255,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.876 | Acc: 60.968,91.901,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.871 | Acc: 60.925,91.852,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.880 | Acc: 60.522,91.833,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.876 | Acc: 60.641,91.848,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.878 | Acc: 60.609,91.855,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.884 | Acc: 60.401,91.756,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.888 | Acc: 60.326,91.717,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.889 | Acc: 60.318,91.662,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.885 | Acc: 60.375,91.679,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.888 | Acc: 60.384,91.645,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.890 | Acc: 60.346,91.650,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.890 | Acc: 60.436,91.659,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.892 | Acc: 60.401,91.610,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.893 | Acc: 60.386,91.601,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.892 | Acc: 60.474,91.587,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.466 | Acc: 57.031,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.879 | Acc: 54.427,69.382,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.912 | Acc: 54.097,68.274,74.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.917 | Acc: 53.868,68.302,74.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 1.842 | Acc: 65.625,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.886 | Acc: 60.491,92.188,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.881 | Acc: 60.385,92.035,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.872 | Acc: 60.630,91.867,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.875 | Acc: 60.639,92.004,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.879 | Acc: 60.280,91.886,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.879 | Acc: 60.421,91.987,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.876 | Acc: 60.511,92.016,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.886 | Acc: 60.428,92.027,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.886 | Acc: 60.545,91.980,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.885 | Acc: 60.560,92.005,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.887 | Acc: 60.552,91.965,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.889 | Acc: 60.458,91.941,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.888 | Acc: 60.548,91.882,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.889 | Acc: 60.526,91.832,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.886 | Acc: 60.538,91.842,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.889 | Acc: 60.546,91.808,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.892 | Acc: 60.452,91.761,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.894 | Acc: 60.336,91.737,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.892 | Acc: 60.458,91.751,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.528 | Acc: 54.688,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.870 | Acc: 54.650,69.085,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.905 | Acc: 54.230,68.121,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.899 | Acc: 54.073,68.417,73.886,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.863 | Acc: 60.938,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.864 | Acc: 61.458,92.634,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.861 | Acc: 60.823,92.321,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.865 | Acc: 60.835,92.111,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.868 | Acc: 60.793,92.072,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.873 | Acc: 60.968,92.079,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.869 | Acc: 61.021,92.188,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.875 | Acc: 60.904,92.110,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.872 | Acc: 60.865,92.139,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.875 | Acc: 60.735,92.101,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.879 | Acc: 60.630,92.032,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.880 | Acc: 60.520,91.979,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.884 | Acc: 60.429,91.880,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.883 | Acc: 60.459,91.870,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.886 | Acc: 60.440,91.854,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.886 | Acc: 60.475,91.783,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.885 | Acc: 60.521,91.793,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.887 | Acc: 60.433,91.761,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.888 | Acc: 60.435,91.755,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.886 | Acc: 60.398,91.757,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.568 | Acc: 61.719,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.885 | Acc: 54.948,70.015,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.922 | Acc: 54.040,68.826,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.932 | Acc: 53.778,68.699,73.822,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 1.689 | Acc: 64.062,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.859 | Acc: 59.784,92.894,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.812 | Acc: 60.880,92.988,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.835 | Acc: 60.630,92.866,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.841 | Acc: 60.812,92.776,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.846 | Acc: 60.891,92.605,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.859 | Acc: 60.744,92.407,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.851 | Acc: 60.915,92.525,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.859 | Acc: 60.705,92.357,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.858 | Acc: 60.825,92.339,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.861 | Acc: 60.903,92.242,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.864 | Acc: 60.920,92.180,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.869 | Acc: 60.892,92.074,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.872 | Acc: 60.902,91.978,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.876 | Acc: 60.815,91.901,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.877 | Acc: 60.743,91.907,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.878 | Acc: 60.677,91.908,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.880 | Acc: 60.610,91.906,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.882 | Acc: 60.591,91.822,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.887 | Acc: 60.454,91.790,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.559 | Acc: 57.031,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.856 | Acc: 54.688,69.866,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.905 | Acc: 54.154,68.540,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.903 | Acc: 53.881,68.379,73.988,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 1.896 | Acc: 60.938,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.911 | Acc: 60.193,91.592,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.862 | Acc: 61.147,91.978,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.869 | Acc: 60.912,92.047,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.881 | Acc: 60.397,91.705,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.868 | Acc: 60.729,92.017,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.868 | Acc: 60.647,92.033,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.866 | Acc: 60.721,92.021,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.869 | Acc: 60.739,91.984,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.865 | Acc: 60.666,92.041,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.871 | Acc: 60.611,92.020,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.871 | Acc: 60.605,92.000,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.873 | Acc: 60.574,91.987,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.870 | Acc: 60.587,92.044,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.869 | Acc: 60.651,92.026,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.874 | Acc: 60.678,91.907,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.874 | Acc: 60.704,91.861,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.878 | Acc: 60.688,91.787,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.879 | Acc: 60.699,91.800,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.882 | Acc: 60.630,91.806,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.551 | Acc: 60.156,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.893 | Acc: 54.464,69.048,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.916 | Acc: 53.925,68.540,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.917 | Acc: 53.612,68.430,74.039,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 1.828 | Acc: 58.594,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.841 | Acc: 62.016,92.113,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.859 | Acc: 60.823,92.283,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.869 | Acc: 60.464,92.290,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.854 | Acc: 60.909,92.361,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.850 | Acc: 60.999,92.273,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.853 | Acc: 60.963,92.207,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.860 | Acc: 60.882,92.171,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.857 | Acc: 61.093,92.217,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.863 | Acc: 60.963,92.162,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.854 | Acc: 61.116,92.250,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.860 | Acc: 61.146,92.134,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.866 | Acc: 61.116,91.987,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.866 | Acc: 61.111,92.002,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.866 | Acc: 61.118,92.018,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.869 | Acc: 61.085,92.008,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.872 | Acc: 60.942,91.993,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.876 | Acc: 60.857,91.924,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.881 | Acc: 60.743,91.867,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.882 | Acc: 60.655,91.884,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.569 | Acc: 59.375,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.907 | Acc: 54.985,68.936,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.939 | Acc: 54.173,68.007,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.940 | Acc: 53.624,68.468,74.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 1.977 | Acc: 54.688,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.850 | Acc: 60.082,92.262,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.841 | Acc: 60.918,92.645,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.845 | Acc: 61.206,92.495,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.861 | Acc: 60.986,92.294,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.858 | Acc: 61.216,92.273,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.853 | Acc: 61.235,92.291,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.856 | Acc: 61.021,92.243,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.860 | Acc: 61.020,92.328,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.866 | Acc: 61.011,92.252,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.862 | Acc: 61.031,92.226,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.868 | Acc: 60.927,92.163,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.872 | Acc: 60.847,92.126,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.873 | Acc: 60.758,92.140,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.871 | Acc: 60.846,92.121,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.873 | Acc: 60.792,92.053,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.873 | Acc: 60.799,92.022,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.875 | Acc: 60.740,92.011,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.876 | Acc: 60.708,91.978,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.876 | Acc: 60.749,91.984,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.540 | Acc: 55.469,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.889 | Acc: 54.241,69.308,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.937 | Acc: 53.659,68.102,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.941 | Acc: 53.548,68.046,73.758,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 1.840 | Acc: 61.719,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.854 | Acc: 62.351,92.448,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.882 | Acc: 60.995,91.978,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.870 | Acc: 61.168,92.149,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.869 | Acc: 60.976,92.226,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.859 | Acc: 61.309,92.211,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.863 | Acc: 61.364,92.175,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.867 | Acc: 61.220,91.994,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.869 | Acc: 61.253,91.993,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.867 | Acc: 61.045,92.015,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.868 | Acc: 61.035,92.040,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.865 | Acc: 61.033,92.004,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.863 | Acc: 60.996,92.032,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.866 | Acc: 61.009,92.035,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.868 | Acc: 60.982,92.054,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.871 | Acc: 60.948,92.011,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.871 | Acc: 60.906,91.990,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.870 | Acc: 60.853,91.908,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.873 | Acc: 60.775,91.895,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.872 | Acc: 60.780,91.882,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.598 | Acc: 58.594,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.908 | Acc: 54.762,69.308,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.940 | Acc: 53.944,68.388,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.936 | Acc: 53.881,68.622,73.835,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.965 | Acc: 55.469,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.799 | Acc: 61.570,93.155,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.777 | Acc: 61.928,93.312,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.779 | Acc: 62.013,93.174,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.796 | Acc: 62.027,92.795,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.813 | Acc: 61.479,92.621,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.824 | Acc: 61.389,92.594,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.830 | Acc: 61.331,92.503,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.838 | Acc: 61.098,92.435,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.835 | Acc: 61.214,92.377,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.842 | Acc: 61.031,92.238,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.843 | Acc: 61.111,92.195,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.843 | Acc: 61.145,92.184,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.849 | Acc: 60.929,92.113,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.850 | Acc: 60.868,92.143,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.855 | Acc: 60.823,92.091,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.858 | Acc: 60.784,92.102,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.859 | Acc: 60.830,92.107,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.866 | Acc: 60.756,92.049,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.868 | Acc: 60.745,92.015,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.503 | Acc: 57.031,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.890 | Acc: 54.688,69.048,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.947 | Acc: 53.982,67.988,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.948 | Acc: 53.573,68.251,73.847,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.849 | Acc: 53.906,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.830 | Acc: 61.124,93.750,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.816 | Acc: 61.814,93.559,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.848 | Acc: 60.771,93.084,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.849 | Acc: 60.899,92.824,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.842 | Acc: 61.092,92.814,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.850 | Acc: 60.983,92.665,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.843 | Acc: 61.126,92.537,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.848 | Acc: 61.156,92.469,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.854 | Acc: 61.045,92.364,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.854 | Acc: 61.081,92.370,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.854 | Acc: 61.086,92.318,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.855 | Acc: 61.028,92.298,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.856 | Acc: 61.048,92.241,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.864 | Acc: 60.940,92.118,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.865 | Acc: 60.883,92.110,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.865 | Acc: 60.894,92.073,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.867 | Acc: 60.848,92.032,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.867 | Acc: 60.866,91.978,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.868 | Acc: 60.812,91.929,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.583 | Acc: 57.812,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.903 | Acc: 54.539,69.196,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.934 | Acc: 53.697,68.426,73.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.938 | Acc: 53.586,68.366,73.719,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 1.850 | Acc: 62.500,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.825 | Acc: 61.533,92.634,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.843 | Acc: 61.338,92.835,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.840 | Acc: 61.168,92.597,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.844 | Acc: 60.957,92.660,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.836 | Acc: 61.069,92.760,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.838 | Acc: 61.202,92.652,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.838 | Acc: 61.292,92.681,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.840 | Acc: 61.287,92.648,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.845 | Acc: 61.205,92.533,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.849 | Acc: 61.147,92.479,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.851 | Acc: 61.093,92.488,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.857 | Acc: 60.808,92.447,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.861 | Acc: 60.692,92.340,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.861 | Acc: 60.684,92.332,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.867 | Acc: 60.522,92.289,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.864 | Acc: 60.633,92.231,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.867 | Acc: 60.610,92.151,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.865 | Acc: 60.671,92.133,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.864 | Acc: 60.685,92.124,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.586 | Acc: 57.031,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.901 | Acc: 54.762,69.271,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.918 | Acc: 54.097,68.312,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.924 | Acc: 53.829,68.212,73.911,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 1.825 | Acc: 60.156,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.802 | Acc: 62.463,93.341,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.814 | Acc: 62.138,93.121,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.817 | Acc: 61.911,92.879,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.806 | Acc: 61.863,92.969,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.813 | Acc: 62.028,92.961,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.812 | Acc: 62.054,92.885,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.824 | Acc: 61.669,92.708,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.832 | Acc: 61.534,92.576,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.840 | Acc: 61.378,92.550,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.844 | Acc: 61.268,92.471,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.850 | Acc: 61.068,92.350,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.849 | Acc: 61.113,92.311,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.851 | Acc: 61.159,92.235,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.854 | Acc: 61.140,92.193,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.857 | Acc: 61.085,92.104,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.859 | Acc: 61.103,92.071,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.859 | Acc: 61.178,92.039,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.861 | Acc: 61.121,92.001,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.863 | Acc: 61.128,91.956,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.475 | Acc: 57.031,72.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.886 | Acc: 54.464,68.936,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.906 | Acc: 54.268,68.293,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.910 | Acc: 54.111,68.315,74.014,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 1.955 | Acc: 57.812,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.830 | Acc: 60.938,92.188,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.862 | Acc: 60.499,92.016,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.847 | Acc: 60.873,92.034,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.848 | Acc: 61.024,92.120,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.845 | Acc: 61.402,92.141,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.849 | Acc: 61.351,92.071,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.851 | Acc: 61.397,92.099,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.854 | Acc: 61.316,92.115,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.848 | Acc: 61.360,92.157,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.852 | Acc: 61.334,92.098,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.857 | Acc: 61.263,92.074,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.861 | Acc: 61.155,92.032,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.857 | Acc: 61.309,92.122,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.858 | Acc: 61.277,92.093,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.855 | Acc: 61.340,92.123,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.857 | Acc: 61.312,92.061,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.859 | Acc: 61.256,92.041,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.860 | Acc: 61.178,91.999,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.863 | Acc: 61.087,91.941,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.529 | Acc: 54.688,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.879 | Acc: 54.241,69.643,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.923 | Acc: 53.887,68.598,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.931 | Acc: 53.804,68.468,74.078,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.657 | Acc: 64.844,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.777 | Acc: 61.868,93.452,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.787 | Acc: 61.357,93.064,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.814 | Acc: 60.758,92.866,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.829 | Acc: 60.687,92.612,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.837 | Acc: 60.659,92.512,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.844 | Acc: 60.647,92.465,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.847 | Acc: 60.467,92.509,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.853 | Acc: 60.302,92.522,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.851 | Acc: 60.549,92.520,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.849 | Acc: 60.619,92.522,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.851 | Acc: 60.591,92.488,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.850 | Acc: 60.655,92.531,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.852 | Acc: 60.677,92.484,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.851 | Acc: 60.704,92.468,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.854 | Acc: 60.595,92.390,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.855 | Acc: 60.607,92.370,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.859 | Acc: 60.571,92.288,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.860 | Acc: 60.604,92.250,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.860 | Acc: 60.616,92.210,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.537 | Acc: 58.594,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.927 | Acc: 54.539,69.048,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.957 | Acc: 54.154,67.759,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.963 | Acc: 53.868,67.943,73.758,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 1.982 | Acc: 60.156,87.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.820 | Acc: 62.165,92.634,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.833 | Acc: 61.719,92.473,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.839 | Acc: 61.501,92.328,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.854 | Acc: 61.179,92.178,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.852 | Acc: 61.456,92.118,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.841 | Acc: 61.415,92.246,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.838 | Acc: 61.547,92.165,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.835 | Acc: 61.743,92.178,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.841 | Acc: 61.658,92.175,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.851 | Acc: 61.470,92.086,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.854 | Acc: 61.365,92.060,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.854 | Acc: 61.365,92.136,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.853 | Acc: 61.375,92.143,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.853 | Acc: 61.357,92.110,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.857 | Acc: 61.246,92.112,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.853 | Acc: 61.293,92.141,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.858 | Acc: 61.137,92.114,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.858 | Acc: 61.111,92.092,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.856 | Acc: 61.116,92.118,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.593 | Acc: 56.250,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.924 | Acc: 54.427,69.308,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.952 | Acc: 53.868,68.350,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.960 | Acc: 53.368,68.353,73.847,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 1.613 | Acc: 64.062,95.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.830 | Acc: 61.198,92.671,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.866 | Acc: 60.690,92.588,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.855 | Acc: 61.194,92.456,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.848 | Acc: 61.420,92.486,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.844 | Acc: 61.278,92.590,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.846 | Acc: 61.273,92.639,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.844 | Acc: 61.287,92.670,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.843 | Acc: 61.229,92.576,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.849 | Acc: 61.011,92.498,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.846 | Acc: 61.147,92.518,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.852 | Acc: 61.086,92.417,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.856 | Acc: 60.973,92.330,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.857 | Acc: 60.926,92.295,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.857 | Acc: 60.899,92.329,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.858 | Acc: 60.818,92.346,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.858 | Acc: 60.843,92.338,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.856 | Acc: 60.905,92.309,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.857 | Acc: 60.886,92.274,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.856 | Acc: 60.899,92.267,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.603 | Acc: 58.594,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.885 | Acc: 54.464,69.457,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.924 | Acc: 54.554,68.102,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.929 | Acc: 54.188,68.289,73.770,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 1.899 | Acc: 62.500,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.849 | Acc: 61.682,92.522,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.833 | Acc: 61.604,92.702,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.845 | Acc: 61.552,92.495,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.844 | Acc: 61.400,92.438,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.854 | Acc: 60.876,92.636,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.844 | Acc: 61.067,92.698,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.839 | Acc: 61.198,92.814,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.838 | Acc: 61.248,92.697,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.835 | Acc: 61.291,92.723,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.837 | Acc: 61.206,92.677,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.837 | Acc: 61.139,92.672,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.837 | Acc: 61.151,92.628,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.838 | Acc: 61.192,92.607,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.836 | Acc: 61.291,92.624,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.839 | Acc: 61.280,92.587,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.839 | Acc: 61.271,92.567,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.841 | Acc: 61.251,92.501,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.844 | Acc: 61.167,92.434,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.845 | Acc: 61.214,92.388,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.665 | Acc: 55.469,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.933 | Acc: 53.981,68.750,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.972 | Acc: 53.735,67.702,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.965 | Acc: 53.573,67.764,73.745,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 2.031 | Acc: 49.219,89.062,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.825 | Acc: 60.417,92.485,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.831 | Acc: 61.395,92.302,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.837 | Acc: 60.771,92.392,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.840 | Acc: 60.677,92.602,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.842 | Acc: 60.690,92.713,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.835 | Acc: 61.073,92.659,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.839 | Acc: 61.131,92.531,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.840 | Acc: 61.141,92.542,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.844 | Acc: 61.020,92.446,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.844 | Acc: 61.074,92.351,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.848 | Acc: 61.093,92.262,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.844 | Acc: 61.210,92.307,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.847 | Acc: 61.087,92.244,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.849 | Acc: 60.996,92.199,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.850 | Acc: 61.034,92.133,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.850 | Acc: 61.084,92.141,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.854 | Acc: 61.031,92.098,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.850 | Acc: 61.091,92.157,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.852 | Acc: 61.032,92.181,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.579 | Acc: 53.906,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.890 | Acc: 54.241,69.159,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.935 | Acc: 54.135,67.912,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.947 | Acc: 53.829,67.892,73.924,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.859 | Acc: 65.625,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.773 | Acc: 62.798,92.969,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.787 | Acc: 62.309,93.064,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.783 | Acc: 62.423,93.212,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.785 | Acc: 62.413,93.046,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.794 | Acc: 62.175,92.884,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.799 | Acc: 62.054,92.904,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.808 | Acc: 61.852,92.797,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.815 | Acc: 61.801,92.731,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.816 | Acc: 61.801,92.662,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.819 | Acc: 61.800,92.650,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.824 | Acc: 61.623,92.576,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.827 | Acc: 61.560,92.457,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.828 | Acc: 61.623,92.472,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.828 | Acc: 61.624,92.379,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.833 | Acc: 61.477,92.328,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.839 | Acc: 61.303,92.287,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.841 | Acc: 61.306,92.201,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.842 | Acc: 61.314,92.140,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.845 | Acc: 61.286,92.095,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.577 | Acc: 59.375,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.883 | Acc: 53.460,69.606,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.920 | Acc: 53.620,68.388,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.930 | Acc: 53.509,68.340,73.860,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 1.984 | Acc: 60.938,88.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.850 | Acc: 60.603,92.411,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.863 | Acc: 60.423,92.492,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.844 | Acc: 60.643,92.533,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.832 | Acc: 60.831,92.795,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.835 | Acc: 61.270,92.698,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.839 | Acc: 61.351,92.620,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.835 | Acc: 61.480,92.686,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.830 | Acc: 61.568,92.765,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.823 | Acc: 61.822,92.779,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.825 | Acc: 61.808,92.720,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.831 | Acc: 61.708,92.640,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.835 | Acc: 61.706,92.547,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.835 | Acc: 61.725,92.523,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.836 | Acc: 61.666,92.471,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.837 | Acc: 61.592,92.413,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.841 | Acc: 61.502,92.394,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.841 | Acc: 61.430,92.403,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.843 | Acc: 61.401,92.332,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.844 | Acc: 61.339,92.317,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.714 | Acc: 53.906,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.926 | Acc: 52.753,68.862,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.967 | Acc: 52.934,68.045,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.983 | Acc: 52.613,67.892,74.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 1.820 | Acc: 60.156,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.827 | Acc: 63.095,92.560,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.821 | Acc: 61.681,92.873,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.830 | Acc: 61.552,92.764,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.834 | Acc: 61.362,92.593,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.840 | Acc: 61.193,92.628,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.833 | Acc: 61.318,92.633,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.837 | Acc: 61.442,92.586,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.836 | Acc: 61.481,92.488,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.826 | Acc: 61.676,92.598,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.824 | Acc: 61.808,92.638,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.820 | Acc: 61.906,92.605,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.823 | Acc: 61.842,92.515,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.821 | Acc: 61.907,92.493,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.830 | Acc: 61.772,92.393,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.834 | Acc: 61.662,92.341,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.838 | Acc: 61.541,92.297,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.844 | Acc: 61.391,92.222,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.844 | Acc: 61.388,92.200,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.846 | Acc: 61.376,92.167,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.584 | Acc: 59.375,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.936 | Acc: 53.869,69.196,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.958 | Acc: 53.697,68.426,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.971 | Acc: 53.240,68.327,73.860,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 1.740 | Acc: 64.062,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.867 | Acc: 62.016,91.815,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.841 | Acc: 61.947,92.454,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.838 | Acc: 61.706,92.264,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.843 | Acc: 61.632,92.255,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.834 | Acc: 61.556,92.489,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.842 | Acc: 61.325,92.330,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.848 | Acc: 61.093,92.293,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.848 | Acc: 61.229,92.246,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.843 | Acc: 61.369,92.287,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.841 | Acc: 61.388,92.316,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.843 | Acc: 61.429,92.219,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.839 | Acc: 61.365,92.249,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.838 | Acc: 61.410,92.196,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.841 | Acc: 61.374,92.176,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.839 | Acc: 61.410,92.232,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.840 | Acc: 61.395,92.161,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.840 | Acc: 61.412,92.167,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.844 | Acc: 61.314,92.136,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.844 | Acc: 61.370,92.132,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.662 | Acc: 60.156,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.920 | Acc: 54.167,69.159,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.942 | Acc: 54.097,68.445,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.947 | Acc: 53.727,68.353,73.873,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 1.853 | Acc: 58.594,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.853 | Acc: 60.714,92.597,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.814 | Acc: 61.376,93.007,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.821 | Acc: 61.142,92.661,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.808 | Acc: 61.535,92.766,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.816 | Acc: 61.378,92.783,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.824 | Acc: 61.247,92.749,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.832 | Acc: 61.203,92.592,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.834 | Acc: 61.161,92.503,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.833 | Acc: 61.149,92.468,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.832 | Acc: 61.248,92.487,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.833 | Acc: 61.418,92.506,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.834 | Acc: 61.433,92.492,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.833 | Acc: 61.434,92.517,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.830 | Acc: 61.502,92.496,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.833 | Acc: 61.425,92.426,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.833 | Acc: 61.475,92.387,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.837 | Acc: 61.478,92.348,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.839 | Acc: 61.427,92.335,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.838 | Acc: 61.456,92.325,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.531 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.902 | Acc: 53.683,69.196,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.946 | Acc: 53.659,68.102,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.947 | Acc: 53.394,68.046,73.796,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 2.029 | Acc: 55.469,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.820 | Acc: 60.305,93.229,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.817 | Acc: 60.556,93.045,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.832 | Acc: 60.617,92.725,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.833 | Acc: 60.841,92.641,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.837 | Acc: 60.914,92.613,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.834 | Acc: 60.886,92.530,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.833 | Acc: 61.048,92.453,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.831 | Acc: 61.112,92.517,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.836 | Acc: 61.071,92.455,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.842 | Acc: 60.988,92.366,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.846 | Acc: 60.909,92.368,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.838 | Acc: 61.113,92.424,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.836 | Acc: 61.222,92.349,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.835 | Acc: 61.218,92.365,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.836 | Acc: 61.231,92.335,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.838 | Acc: 61.161,92.351,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.836 | Acc: 61.199,92.389,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.837 | Acc: 61.202,92.384,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.839 | Acc: 61.186,92.354,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.565 | Acc: 57.031,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.944 | Acc: 54.092,68.341,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.980 | Acc: 53.792,67.511,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.982 | Acc: 53.227,67.674,73.796,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 2.053 | Acc: 55.469,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.873 | Acc: 60.565,92.522,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.798 | Acc: 62.500,93.255,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.800 | Acc: 62.090,93.161,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.796 | Acc: 62.452,92.892,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.804 | Acc: 62.175,92.768,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.811 | Acc: 61.996,92.698,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.809 | Acc: 61.857,92.830,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.816 | Acc: 61.685,92.746,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.819 | Acc: 61.766,92.693,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.821 | Acc: 61.680,92.623,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.826 | Acc: 61.581,92.555,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.828 | Acc: 61.495,92.551,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.831 | Acc: 61.467,92.421,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.828 | Acc: 61.499,92.413,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.826 | Acc: 61.472,92.439,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.828 | Acc: 61.380,92.448,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.829 | Acc: 61.336,92.394,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.830 | Acc: 61.275,92.428,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.834 | Acc: 61.239,92.380,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.617 | Acc: 60.938,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.898 | Acc: 54.613,69.717,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.937 | Acc: 54.364,68.388,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.944 | Acc: 54.188,68.379,73.847,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 1.913 | Acc: 60.938,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.820 | Acc: 60.900,92.597,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.807 | Acc: 62.005,92.626,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.794 | Acc: 62.244,93.020,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.781 | Acc: 62.490,93.200,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.783 | Acc: 62.399,93.270,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.795 | Acc: 61.874,93.104,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.797 | Acc: 61.896,93.002,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.798 | Acc: 62.005,92.896,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.807 | Acc: 61.706,92.835,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.811 | Acc: 61.629,92.852,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.813 | Acc: 61.606,92.813,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.817 | Acc: 61.544,92.674,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.822 | Acc: 61.443,92.535,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.822 | Acc: 61.538,92.535,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.827 | Acc: 61.428,92.528,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.826 | Acc: 61.410,92.540,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.829 | Acc: 61.384,92.499,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.831 | Acc: 61.338,92.443,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.833 | Acc: 61.282,92.407,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.696 | Acc: 57.031,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.945 | Acc: 53.981,68.527,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.970 | Acc: 53.849,67.721,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.977 | Acc: 53.624,67.546,74.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 1.585 | Acc: 64.062,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.748 | Acc: 62.984,94.717,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.791 | Acc: 62.119,93.883,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.817 | Acc: 61.796,93.443,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.818 | Acc: 61.651,93.181,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.824 | Acc: 61.696,93.007,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.816 | Acc: 61.680,93.175,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.824 | Acc: 61.519,93.019,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.815 | Acc: 61.801,93.061,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.816 | Acc: 61.697,92.990,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.817 | Acc: 61.762,92.961,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.817 | Acc: 61.797,92.866,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.822 | Acc: 61.576,92.829,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.823 | Acc: 61.542,92.825,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.826 | Acc: 61.463,92.796,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.824 | Acc: 61.540,92.694,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.827 | Acc: 61.497,92.628,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.827 | Acc: 61.421,92.614,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.829 | Acc: 61.372,92.581,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.830 | Acc: 61.382,92.563,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.606 | Acc: 60.156,71.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.922 | Acc: 53.869,69.234,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.969 | Acc: 53.639,68.102,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.979 | Acc: 53.381,67.751,73.438,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 1.843 | Acc: 63.281,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.804 | Acc: 62.463,93.564,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.817 | Acc: 61.319,93.045,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.807 | Acc: 61.847,92.943,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.816 | Acc: 61.622,92.699,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.824 | Acc: 61.200,92.605,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.824 | Acc: 61.112,92.523,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.825 | Acc: 61.226,92.570,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.826 | Acc: 61.170,92.532,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.822 | Acc: 61.158,92.485,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.816 | Acc: 61.229,92.537,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.812 | Acc: 61.323,92.562,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.818 | Acc: 61.223,92.551,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.819 | Acc: 61.222,92.490,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.823 | Acc: 61.168,92.454,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.825 | Acc: 61.189,92.419,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.828 | Acc: 61.122,92.375,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.826 | Acc: 61.208,92.350,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.831 | Acc: 61.093,92.296,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.834 | Acc: 61.091,92.249,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.627 | Acc: 57.031,73.438,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.936 | Acc: 54.167,69.010,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.967 | Acc: 53.639,68.121,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.979 | Acc: 53.522,67.892,73.860,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 1.836 | Acc: 59.375,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.757 | Acc: 61.868,93.192,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.766 | Acc: 62.024,93.121,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.811 | Acc: 61.450,92.636,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.816 | Acc: 61.304,92.622,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.804 | Acc: 61.572,92.775,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.818 | Acc: 61.454,92.665,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.820 | Acc: 61.331,92.614,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.818 | Acc: 61.462,92.648,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.817 | Acc: 61.412,92.671,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.817 | Acc: 61.505,92.596,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.812 | Acc: 61.726,92.622,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.819 | Acc: 61.560,92.521,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.815 | Acc: 61.671,92.529,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.823 | Acc: 61.519,92.491,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.825 | Acc: 61.493,92.424,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.829 | Acc: 61.371,92.360,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.825 | Acc: 61.476,92.387,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.827 | Acc: 61.455,92.365,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.829 | Acc: 61.395,92.360,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.584 | Acc: 58.594,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.956 | Acc: 53.943,68.750,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.976 | Acc: 53.582,67.835,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.980 | Acc: 53.432,67.802,73.373,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 1.992 | Acc: 55.469,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.736 | Acc: 62.500,93.601,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.763 | Acc: 62.805,93.236,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.788 | Acc: 62.526,93.007,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.806 | Acc: 61.979,92.921,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.815 | Acc: 61.819,92.768,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.826 | Acc: 61.712,92.491,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.830 | Acc: 61.602,92.531,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.833 | Acc: 61.466,92.600,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.835 | Acc: 61.369,92.528,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.836 | Acc: 61.396,92.522,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.833 | Acc: 61.379,92.562,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.830 | Acc: 61.531,92.547,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.832 | Acc: 61.431,92.529,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.830 | Acc: 61.449,92.563,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.831 | Acc: 61.503,92.533,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.832 | Acc: 61.390,92.548,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.829 | Acc: 61.400,92.566,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.826 | Acc: 61.401,92.553,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.826 | Acc: 61.456,92.479,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.709 | Acc: 55.469,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.932 | Acc: 54.092,68.304,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.961 | Acc: 53.735,67.759,73.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.963 | Acc: 53.509,67.802,73.630,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 1.835 | Acc: 61.719,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.833 | Acc: 60.603,93.118,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.789 | Acc: 61.814,93.636,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.794 | Acc: 61.924,93.110,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.784 | Acc: 61.941,93.027,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.796 | Acc: 61.533,92.891,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.798 | Acc: 61.648,92.853,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.808 | Acc: 61.774,92.797,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.804 | Acc: 61.898,92.721,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.808 | Acc: 61.883,92.654,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.814 | Acc: 61.633,92.572,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.818 | Acc: 61.510,92.530,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.818 | Acc: 61.550,92.482,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.821 | Acc: 61.503,92.427,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.818 | Acc: 61.574,92.441,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.815 | Acc: 61.641,92.465,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.817 | Acc: 61.607,92.467,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.819 | Acc: 61.517,92.423,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.820 | Acc: 61.479,92.404,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.824 | Acc: 61.409,92.378,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.616 | Acc: 58.594,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.921 | Acc: 54.725,68.638,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.960 | Acc: 54.135,67.759,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.966 | Acc: 53.637,67.674,73.783,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 1.706 | Acc: 64.844,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.829 | Acc: 61.793,92.225,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.833 | Acc: 61.033,92.511,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.831 | Acc: 61.488,92.649,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.825 | Acc: 61.410,92.650,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.824 | Acc: 61.262,92.775,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.822 | Acc: 61.415,92.782,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.827 | Acc: 61.420,92.725,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.826 | Acc: 61.428,92.658,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.818 | Acc: 61.671,92.684,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.815 | Acc: 61.618,92.697,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.816 | Acc: 61.613,92.668,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.819 | Acc: 61.527,92.622,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.817 | Acc: 61.608,92.577,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.820 | Acc: 61.430,92.504,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.824 | Acc: 61.379,92.424,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.824 | Acc: 61.376,92.353,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.827 | Acc: 61.288,92.311,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.828 | Acc: 61.249,92.317,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.825 | Acc: 61.329,92.345,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.661 | Acc: 52.344,71.875,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.992 | Acc: 53.609,68.118,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.008 | Acc: 53.525,67.321,73.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.012 | Acc: 53.266,67.559,73.297,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 1.653 | Acc: 62.500,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.783 | Acc: 62.091,93.713,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.807 | Acc: 61.585,93.369,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.798 | Acc: 61.668,93.379,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.798 | Acc: 61.632,93.306,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.809 | Acc: 61.440,93.054,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.818 | Acc: 61.260,92.853,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.819 | Acc: 61.220,92.924,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.820 | Acc: 61.306,92.833,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.812 | Acc: 61.525,92.895,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.810 | Acc: 61.622,92.802,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.816 | Acc: 61.538,92.686,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.820 | Acc: 61.531,92.674,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.824 | Acc: 61.413,92.648,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.826 | Acc: 61.349,92.618,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.825 | Acc: 61.342,92.626,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.822 | Acc: 61.371,92.657,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.822 | Acc: 61.368,92.616,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.823 | Acc: 61.340,92.616,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.823 | Acc: 61.417,92.594,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.629 | Acc: 59.375,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.940 | Acc: 53.646,68.824,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.974 | Acc: 53.468,68.064,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.976 | Acc: 53.407,67.866,73.694,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 1.681 | Acc: 64.062,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.772 | Acc: 61.868,93.899,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.772 | Acc: 61.585,93.064,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.779 | Acc: 61.898,92.892,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.786 | Acc: 62.105,92.824,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.790 | Acc: 62.067,92.744,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.790 | Acc: 62.138,92.782,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.801 | Acc: 61.830,92.742,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.809 | Acc: 61.694,92.682,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.810 | Acc: 61.615,92.731,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.816 | Acc: 61.540,92.693,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.816 | Acc: 61.489,92.640,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.814 | Acc: 61.469,92.677,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.815 | Acc: 61.578,92.628,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.815 | Acc: 61.569,92.616,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.819 | Acc: 61.467,92.553,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.814 | Acc: 61.612,92.562,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.820 | Acc: 61.524,92.499,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.824 | Acc: 61.459,92.486,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.824 | Acc: 61.423,92.479,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.548 | Acc: 60.156,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.921 | Acc: 54.278,69.494,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.967 | Acc: 53.849,68.236,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.972 | Acc: 53.637,67.930,73.706,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 1.852 | Acc: 59.375,89.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.765 | Acc: 62.388,94.010,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.795 | Acc: 61.928,93.655,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.827 | Acc: 61.002,93.417,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.826 | Acc: 60.986,93.277,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.821 | Acc: 61.262,93.185,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.819 | Acc: 61.209,93.111,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.811 | Acc: 61.464,93.107,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.816 | Acc: 61.316,93.022,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.816 | Acc: 61.309,92.947,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.816 | Acc: 61.373,92.949,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.816 | Acc: 61.457,92.863,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.817 | Acc: 61.450,92.771,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.819 | Acc: 61.378,92.720,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.821 | Acc: 61.288,92.699,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.823 | Acc: 61.270,92.642,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.824 | Acc: 61.251,92.623,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.822 | Acc: 61.377,92.646,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.823 | Acc: 61.349,92.635,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.822 | Acc: 61.399,92.587,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.550 | Acc: 62.500,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.960 | Acc: 53.720,69.494,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.983 | Acc: 53.411,68.350,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.986 | Acc: 53.099,68.276,73.476,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 1.871 | Acc: 59.375,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.781 | Acc: 62.016,93.862,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.791 | Acc: 61.890,93.236,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.784 | Acc: 61.898,93.481,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.782 | Acc: 62.143,93.422,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.791 | Acc: 61.788,93.309,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.804 | Acc: 61.435,92.975,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.804 | Acc: 61.425,92.924,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.804 | Acc: 61.423,93.012,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.806 | Acc: 61.512,92.900,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.809 | Acc: 61.462,92.860,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.810 | Acc: 61.503,92.796,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.817 | Acc: 61.223,92.654,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.820 | Acc: 61.213,92.595,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.820 | Acc: 61.238,92.560,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.822 | Acc: 61.275,92.504,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.821 | Acc: 61.295,92.492,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.825 | Acc: 61.245,92.467,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.824 | Acc: 61.292,92.462,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.825 | Acc: 61.327,92.458,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.714 | Acc: 57.031,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.970 | Acc: 54.390,68.713,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.004 | Acc: 53.811,67.835,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.007 | Acc: 53.778,67.661,73.681,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 1.653 | Acc: 62.500,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.741 | Acc: 62.351,93.304,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.775 | Acc: 62.252,93.045,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.787 | Acc: 61.821,93.097,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.808 | Acc: 61.507,92.863,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.798 | Acc: 61.804,92.930,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.809 | Acc: 61.635,92.782,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.808 | Acc: 61.602,92.764,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.808 | Acc: 61.893,92.726,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.808 | Acc: 61.844,92.688,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.812 | Acc: 61.769,92.588,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.810 | Acc: 61.779,92.636,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.810 | Acc: 61.628,92.635,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.813 | Acc: 61.686,92.508,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.813 | Acc: 61.652,92.538,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.816 | Acc: 61.514,92.551,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.818 | Acc: 61.466,92.531,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.821 | Acc: 61.425,92.474,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.818 | Acc: 61.513,92.447,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.819 | Acc: 61.544,92.395,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.622 | Acc: 53.906,75.000,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.922 | Acc: 54.018,69.531,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.958 | Acc: 54.059,67.969,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.964 | Acc: 53.689,67.969,74.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 1.906 | Acc: 58.594,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.719 | Acc: 63.504,93.862,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.708 | Acc: 64.196,93.979,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.723 | Acc: 63.486,93.878,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.737 | Acc: 63.310,93.731,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.732 | Acc: 63.390,93.967,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.731 | Acc: 63.178,93.970,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.733 | Acc: 62.888,94.132,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.723 | Acc: 63.141,94.206,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.725 | Acc: 63.040,94.203,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.725 | Acc: 63.017,94.267,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.726 | Acc: 62.963,94.266,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.728 | Acc: 62.824,94.324,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.729 | Acc: 62.859,94.337,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.728 | Acc: 62.831,94.345,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.732 | Acc: 62.760,94.347,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.730 | Acc: 62.829,94.349,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.731 | Acc: 62.786,94.389,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.731 | Acc: 62.764,94.393,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.729 | Acc: 62.754,94.396,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.499 | Acc: 56.250,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.827 | Acc: 55.729,69.829,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.869 | Acc: 55.259,68.826,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.872 | Acc: 54.905,68.840,74.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 1.637 | Acc: 67.969,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.737 | Acc: 61.830,94.754,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.726 | Acc: 62.157,94.931,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.728 | Acc: 62.167,94.928,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.707 | Acc: 62.905,95.023,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.714 | Acc: 63.011,95.057,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.705 | Acc: 63.068,95.074,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.710 | Acc: 63.087,94.941,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.711 | Acc: 62.990,94.900,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.713 | Acc: 62.888,94.872,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.712 | Acc: 62.931,94.889,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.713 | Acc: 62.875,94.892,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.710 | Acc: 63.019,94.888,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.708 | Acc: 63.021,94.917,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.707 | Acc: 63.064,94.929,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.705 | Acc: 62.996,94.931,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.710 | Acc: 62.804,94.918,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.711 | Acc: 62.775,94.914,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.714 | Acc: 62.764,94.893,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.711 | Acc: 62.875,94.911,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.475 | Acc: 59.375,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.835 | Acc: 55.841,69.978,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.873 | Acc: 55.278,68.941,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.877 | Acc: 54.969,68.699,74.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.575 | Acc: 64.062,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.675 | Acc: 63.839,95.238,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.695 | Acc: 63.091,95.274,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.698 | Acc: 63.012,95.133,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.704 | Acc: 62.741,95.042,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.705 | Acc: 62.972,94.910,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.709 | Acc: 62.803,95.015,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.717 | Acc: 62.639,94.975,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.712 | Acc: 62.728,95.046,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.713 | Acc: 62.629,95.105,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.709 | Acc: 62.776,95.130,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.706 | Acc: 62.875,95.175,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.703 | Acc: 63.015,95.199,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.702 | Acc: 62.997,95.181,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.702 | Acc: 63.006,95.148,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.704 | Acc: 62.933,95.094,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.706 | Acc: 62.906,95.103,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.707 | Acc: 62.862,95.083,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.706 | Acc: 62.827,95.113,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.705 | Acc: 62.842,95.126,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.511 | Acc: 58.594,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.843 | Acc: 55.394,70.015,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.877 | Acc: 54.992,69.074,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.880 | Acc: 54.739,68.776,74.142,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 1.621 | Acc: 65.625,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.694 | Acc: 63.356,95.350,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.697 | Acc: 63.434,95.255,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.688 | Acc: 63.691,95.184,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.683 | Acc: 63.667,95.187,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.680 | Acc: 63.745,95.282,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.678 | Acc: 63.598,95.300,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.693 | Acc: 63.231,95.329,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.704 | Acc: 62.946,95.196,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.709 | Acc: 62.871,95.179,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.706 | Acc: 62.877,95.227,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.705 | Acc: 62.928,95.270,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.702 | Acc: 63.045,95.270,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.704 | Acc: 62.961,95.292,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.703 | Acc: 63.006,95.276,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.704 | Acc: 62.998,95.263,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.704 | Acc: 63.021,95.257,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.705 | Acc: 63.038,95.248,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.704 | Acc: 63.091,95.254,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.703 | Acc: 63.070,95.274,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.509 | Acc: 60.156,74.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.831 | Acc: 55.766,69.680,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.866 | Acc: 55.297,68.921,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.868 | Acc: 54.905,68.737,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 1.725 | Acc: 58.594,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.673 | Acc: 64.621,95.871,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.684 | Acc: 63.624,95.655,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.695 | Acc: 63.115,95.556,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.706 | Acc: 62.857,95.467,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.710 | Acc: 62.778,95.367,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.713 | Acc: 62.642,95.351,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.715 | Acc: 62.367,95.479,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.716 | Acc: 62.442,95.424,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.712 | Acc: 62.668,95.459,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.706 | Acc: 62.854,95.441,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.705 | Acc: 62.914,95.419,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.705 | Acc: 62.912,95.416,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.705 | Acc: 62.913,95.405,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.703 | Acc: 63.025,95.401,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.707 | Acc: 63.029,95.357,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.702 | Acc: 63.108,95.371,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.702 | Acc: 63.077,95.338,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.702 | Acc: 63.082,95.332,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.703 | Acc: 63.066,95.292,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.514 | Acc: 59.375,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.836 | Acc: 55.543,69.978,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.869 | Acc: 55.183,69.036,74.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.871 | Acc: 54.790,68.878,74.155,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 1.649 | Acc: 66.406,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.699 | Acc: 63.467,95.536,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.695 | Acc: 63.262,95.389,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.689 | Acc: 63.204,95.338,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.689 | Acc: 63.185,95.399,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.695 | Acc: 63.181,95.320,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.693 | Acc: 63.165,95.345,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.692 | Acc: 63.353,95.285,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.694 | Acc: 63.291,95.312,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.698 | Acc: 63.221,95.269,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.699 | Acc: 63.114,95.293,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.699 | Acc: 63.239,95.210,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.695 | Acc: 63.391,95.163,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.694 | Acc: 63.359,95.151,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.692 | Acc: 63.379,95.171,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.690 | Acc: 63.437,95.154,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.693 | Acc: 63.306,95.152,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.694 | Acc: 63.361,95.143,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.694 | Acc: 63.281,95.165,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.696 | Acc: 63.250,95.187,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.470 | Acc: 60.156,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.830 | Acc: 56.176,70.312,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.870 | Acc: 55.450,69.169,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.872 | Acc: 54.995,68.968,74.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 1.864 | Acc: 62.500,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.707 | Acc: 62.612,95.461,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.702 | Acc: 62.652,95.579,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.712 | Acc: 62.615,95.325,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.706 | Acc: 62.645,95.448,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.692 | Acc: 63.274,95.421,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.693 | Acc: 63.152,95.287,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.693 | Acc: 63.375,95.335,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.690 | Acc: 63.407,95.346,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.692 | Acc: 63.324,95.343,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.691 | Acc: 63.258,95.402,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.693 | Acc: 63.179,95.344,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.697 | Acc: 63.071,95.322,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.697 | Acc: 63.027,95.348,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.690 | Acc: 63.145,95.404,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.690 | Acc: 63.126,95.432,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 63.196,95.403,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.690 | Acc: 63.180,95.393,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.692 | Acc: 63.108,95.395,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.694 | Acc: 63.050,95.374,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.472 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.836 | Acc: 55.804,69.978,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.879 | Acc: 55.354,68.941,73.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.879 | Acc: 55.085,68.724,73.937,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 1.845 | Acc: 60.938,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.672 | Acc: 63.579,96.168,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 62.748,95.503,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.708 | Acc: 62.731,95.377,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.700 | Acc: 62.867,95.419,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.688 | Acc: 63.258,95.436,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.691 | Acc: 63.210,95.532,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.692 | Acc: 63.049,95.479,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.696 | Acc: 63.014,95.482,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.692 | Acc: 63.061,95.489,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.684 | Acc: 63.266,95.534,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.682 | Acc: 63.359,95.482,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.682 | Acc: 63.353,95.432,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.686 | Acc: 63.305,95.366,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.686 | Acc: 63.309,95.346,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.687 | Acc: 63.253,95.385,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 63.147,95.344,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.690 | Acc: 63.178,95.351,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.690 | Acc: 63.193,95.323,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.692 | Acc: 63.138,95.282,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.482 | Acc: 57.031,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.832 | Acc: 55.692,69.903,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.873 | Acc: 55.335,69.093,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.878 | Acc: 54.956,68.865,74.142,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 1.982 | Acc: 51.562,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.716 | Acc: 62.091,94.940,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.726 | Acc: 62.710,95.141,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.719 | Acc: 62.999,95.325,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.705 | Acc: 63.291,95.390,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.707 | Acc: 63.157,95.429,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.702 | Acc: 63.152,95.377,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.692 | Acc: 63.148,95.484,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.693 | Acc: 63.179,95.487,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.687 | Acc: 63.299,95.515,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.686 | Acc: 63.238,95.472,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.685 | Acc: 63.292,95.475,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.690 | Acc: 63.158,95.452,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.688 | Acc: 63.099,95.459,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.687 | Acc: 63.128,95.443,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.687 | Acc: 63.068,95.468,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.685 | Acc: 63.106,95.429,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.689 | Acc: 63.038,95.420,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.689 | Acc: 63.002,95.440,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.692 | Acc: 62.957,95.397,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.497 | Acc: 59.375,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.837 | Acc: 55.580,69.792,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.872 | Acc: 55.107,68.921,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.877 | Acc: 54.854,68.750,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 1.975 | Acc: 55.469,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.672 | Acc: 62.388,95.722,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.685 | Acc: 62.462,95.617,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.689 | Acc: 62.385,95.428,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.695 | Acc: 62.249,95.303,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.693 | Acc: 62.500,95.235,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.697 | Acc: 62.487,95.222,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.687 | Acc: 62.855,95.318,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.691 | Acc: 62.738,95.380,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.686 | Acc: 62.966,95.425,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.689 | Acc: 62.963,95.433,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.687 | Acc: 62.910,95.429,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.688 | Acc: 62.915,95.397,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.690 | Acc: 62.853,95.348,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.690 | Acc: 62.939,95.343,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.690 | Acc: 63.004,95.351,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.689 | Acc: 63.072,95.354,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.688 | Acc: 63.128,95.319,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.688 | Acc: 63.136,95.328,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.690 | Acc: 63.066,95.308,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.488 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.842 | Acc: 55.804,69.754,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.880 | Acc: 55.316,69.017,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.886 | Acc: 54.892,68.724,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 1.470 | Acc: 67.969,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.677 | Acc: 63.318,95.982,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.694 | Acc: 62.919,96.113,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.694 | Acc: 62.820,95.825,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 62.953,95.698,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.687 | Acc: 63.188,95.614,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.692 | Acc: 63.197,95.487,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.693 | Acc: 63.342,95.462,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.694 | Acc: 63.272,95.376,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.692 | Acc: 63.255,95.343,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.691 | Acc: 63.297,95.344,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.690 | Acc: 63.292,95.351,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.689 | Acc: 63.349,95.329,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.690 | Acc: 63.272,95.324,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.692 | Acc: 63.215,95.332,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.694 | Acc: 63.190,95.359,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.694 | Acc: 63.174,95.368,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.694 | Acc: 63.164,95.374,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.690 | Acc: 63.257,95.408,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.691 | Acc: 63.201,95.403,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.506 | Acc: 57.812,71.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.853 | Acc: 55.729,69.457,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.889 | Acc: 55.164,68.655,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.888 | Acc: 54.803,68.571,74.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 1.785 | Acc: 60.938,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.616 | Acc: 64.732,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.654 | Acc: 63.910,95.808,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.671 | Acc: 63.473,95.620,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.671 | Acc: 63.320,95.592,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.675 | Acc: 63.235,95.444,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.669 | Acc: 63.533,95.487,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.672 | Acc: 63.481,95.396,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.679 | Acc: 63.461,95.351,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.682 | Acc: 63.342,95.325,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.687 | Acc: 63.262,95.258,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.691 | Acc: 63.143,95.252,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.687 | Acc: 63.207,95.283,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.688 | Acc: 63.102,95.315,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.688 | Acc: 63.159,95.304,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.689 | Acc: 63.118,95.305,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.693 | Acc: 63.055,95.264,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.693 | Acc: 63.066,95.248,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.690 | Acc: 63.160,95.282,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.690 | Acc: 63.177,95.278,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.535 | Acc: 57.812,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.843 | Acc: 55.469,69.606,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.881 | Acc: 55.297,68.636,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.883 | Acc: 54.892,68.699,74.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 1.900 | Acc: 63.281,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.669 | Acc: 63.876,95.833,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.655 | Acc: 62.976,95.713,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.655 | Acc: 63.179,95.569,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.673 | Acc: 62.886,95.525,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.684 | Acc: 62.631,95.560,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.683 | Acc: 62.707,95.545,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.680 | Acc: 62.866,95.556,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.679 | Acc: 62.980,95.511,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.678 | Acc: 63.126,95.537,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.683 | Acc: 63.036,95.487,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.679 | Acc: 63.225,95.496,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.683 | Acc: 63.113,95.507,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.681 | Acc: 63.248,95.561,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.686 | Acc: 63.137,95.499,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.692 | Acc: 63.014,95.434,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 63.218,95.434,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.691 | Acc: 63.226,95.400,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.691 | Acc: 63.273,95.367,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.690 | Acc: 63.242,95.388,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.469 | Acc: 60.938,74.219,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.843 | Acc: 55.655,69.903,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.881 | Acc: 55.259,68.769,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.879 | Acc: 54.905,68.699,73.822,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.557 | Acc: 66.406,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.695 | Acc: 61.905,94.978,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.680 | Acc: 62.595,95.560,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.693 | Acc: 62.641,95.569,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.688 | Acc: 62.867,95.515,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.697 | Acc: 62.709,95.591,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.695 | Acc: 62.913,95.622,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.691 | Acc: 62.982,95.601,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.695 | Acc: 62.951,95.482,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.694 | Acc: 63.027,95.416,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.691 | Acc: 63.169,95.449,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.689 | Acc: 63.331,95.465,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.688 | Acc: 63.330,95.462,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.691 | Acc: 63.269,95.438,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.688 | Acc: 63.320,95.446,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.687 | Acc: 63.318,95.455,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.684 | Acc: 63.362,95.441,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.685 | Acc: 63.302,95.477,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.689 | Acc: 63.190,95.447,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.688 | Acc: 63.236,95.458,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.503 | Acc: 59.375,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.840 | Acc: 55.655,69.568,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.878 | Acc: 55.278,68.883,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.881 | Acc: 55.085,68.712,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 1.874 | Acc: 62.500,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.636 | Acc: 63.951,96.168,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.646 | Acc: 64.348,95.770,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.645 | Acc: 64.600,95.569,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.652 | Acc: 64.361,95.756,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.657 | Acc: 64.001,95.645,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.660 | Acc: 63.920,95.655,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.670 | Acc: 63.941,95.590,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.677 | Acc: 63.645,95.642,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.681 | Acc: 63.475,95.623,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.683 | Acc: 63.390,95.581,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.686 | Acc: 63.285,95.620,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.685 | Acc: 63.411,95.646,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.683 | Acc: 63.404,95.630,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.684 | Acc: 63.387,95.632,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.682 | Acc: 63.403,95.577,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.683 | Acc: 63.357,95.532,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.683 | Acc: 63.284,95.514,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.684 | Acc: 63.283,95.501,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.685 | Acc: 63.240,95.487,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.496 | Acc: 59.375,73.438,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.841 | Acc: 55.655,69.903,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.880 | Acc: 55.183,68.902,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.883 | Acc: 54.931,68.763,73.937,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 1.596 | Acc: 67.188,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.689 | Acc: 63.356,95.424,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.676 | Acc: 63.567,95.370,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.676 | Acc: 63.230,95.556,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.673 | Acc: 63.407,95.640,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.677 | Acc: 63.250,95.583,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.683 | Acc: 63.249,95.584,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.688 | Acc: 63.071,95.650,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.690 | Acc: 63.019,95.550,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.690 | Acc: 63.035,95.537,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.687 | Acc: 63.032,95.557,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.686 | Acc: 63.143,95.574,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.689 | Acc: 63.058,95.546,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.691 | Acc: 63.090,95.519,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.686 | Acc: 63.151,95.507,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.686 | Acc: 63.154,95.489,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.686 | Acc: 63.113,95.493,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.687 | Acc: 63.119,95.450,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.687 | Acc: 63.193,95.468,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.686 | Acc: 63.216,95.487,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.488 | Acc: 59.375,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.833 | Acc: 55.990,69.792,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.873 | Acc: 55.297,68.864,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.879 | Acc: 54.918,68.660,74.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 1.664 | Acc: 64.062,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.700 | Acc: 62.984,95.164,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.716 | Acc: 62.957,95.484,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.717 | Acc: 62.884,95.517,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.704 | Acc: 63.223,95.370,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.702 | Acc: 63.119,95.359,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.695 | Acc: 63.184,95.455,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.697 | Acc: 63.259,95.412,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.694 | Acc: 63.412,95.405,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.692 | Acc: 63.294,95.494,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.695 | Acc: 63.266,95.495,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.695 | Acc: 63.242,95.436,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.691 | Acc: 63.281,95.445,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.688 | Acc: 63.368,95.528,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.685 | Acc: 63.445,95.485,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.684 | Acc: 63.471,95.440,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.685 | Acc: 63.432,95.410,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.687 | Acc: 63.389,95.384,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.688 | Acc: 63.325,95.388,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.687 | Acc: 63.355,95.425,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.482 | Acc: 57.812,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.849 | Acc: 55.394,69.420,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.884 | Acc: 55.221,68.693,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.883 | Acc: 54.956,68.609,73.988,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 1.623 | Acc: 68.750,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.668 | Acc: 63.170,95.499,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.674 | Acc: 63.034,95.446,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.682 | Acc: 63.166,95.415,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.694 | Acc: 63.050,95.573,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.700 | Acc: 62.918,95.444,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.696 | Acc: 62.887,95.467,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.693 | Acc: 62.838,95.462,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.689 | Acc: 63.121,95.410,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.686 | Acc: 63.195,95.399,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.688 | Acc: 63.211,95.425,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.684 | Acc: 63.302,95.457,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.684 | Acc: 63.197,95.371,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.689 | Acc: 63.132,95.345,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.690 | Acc: 63.178,95.310,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.689 | Acc: 63.167,95.331,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.691 | Acc: 63.128,95.308,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.690 | Acc: 63.148,95.342,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.689 | Acc: 63.106,95.354,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.686 | Acc: 63.158,95.378,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.479 | Acc: 58.594,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.846 | Acc: 55.618,69.717,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.883 | Acc: 55.145,69.017,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.883 | Acc: 54.854,68.891,73.975,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 1.837 | Acc: 58.594,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.695 | Acc: 61.942,95.982,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.701 | Acc: 61.700,95.522,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.702 | Acc: 62.154,95.517,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.686 | Acc: 62.568,95.621,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.683 | Acc: 62.631,95.545,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.680 | Acc: 62.713,95.648,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.678 | Acc: 62.799,95.612,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.680 | Acc: 62.908,95.652,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.680 | Acc: 62.884,95.597,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.682 | Acc: 62.873,95.526,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.679 | Acc: 63.009,95.563,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.677 | Acc: 62.967,95.595,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.678 | Acc: 62.985,95.588,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.680 | Acc: 63.025,95.527,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.680 | Acc: 63.045,95.499,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 63.087,95.512,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.682 | Acc: 63.139,95.493,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 63.171,95.466,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.683 | Acc: 63.224,95.470,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.528 | Acc: 58.594,74.219,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.851 | Acc: 55.506,69.122,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.886 | Acc: 55.107,68.712,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.885 | Acc: 54.867,68.609,74.039,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 1.710 | Acc: 59.375,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.649 | Acc: 64.435,95.424,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.656 | Acc: 64.501,95.389,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.662 | Acc: 64.229,95.338,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.680 | Acc: 63.773,95.332,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.684 | Acc: 63.567,95.429,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.680 | Acc: 63.604,95.571,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.677 | Acc: 63.608,95.567,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.678 | Acc: 63.568,95.531,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.681 | Acc: 63.389,95.485,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.681 | Acc: 63.503,95.429,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.682 | Acc: 63.507,95.440,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.683 | Acc: 63.456,95.419,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.683 | Acc: 63.386,95.438,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.685 | Acc: 63.295,95.393,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.684 | Acc: 63.320,95.388,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 63.418,95.383,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.682 | Acc: 63.414,95.370,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 63.424,95.388,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.684 | Acc: 63.337,95.360,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.495 | Acc: 60.156,75.000,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.851 | Acc: 55.580,69.643,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.886 | Acc: 55.107,68.960,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.887 | Acc: 54.816,68.904,73.886,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 1.775 | Acc: 55.469,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.719 | Acc: 62.760,95.759,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.706 | Acc: 62.652,95.770,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.684 | Acc: 63.614,95.389,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.693 | Acc: 63.320,95.409,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.687 | Acc: 63.436,95.490,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.685 | Acc: 63.081,95.519,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.686 | Acc: 63.004,95.506,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.687 | Acc: 62.946,95.531,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.691 | Acc: 62.975,95.576,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.694 | Acc: 62.963,95.511,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.690 | Acc: 63.203,95.457,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.688 | Acc: 63.129,95.507,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.685 | Acc: 63.200,95.513,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.684 | Acc: 63.295,95.490,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.678 | Acc: 63.411,95.520,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.678 | Acc: 63.454,95.556,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.682 | Acc: 63.320,95.555,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.680 | Acc: 63.381,95.561,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.680 | Acc: 63.277,95.571,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.486 | Acc: 60.938,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.851 | Acc: 55.766,69.717,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.887 | Acc: 55.107,68.883,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.886 | Acc: 54.764,68.904,73.911,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 1.832 | Acc: 60.156,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.648 | Acc: 63.914,95.871,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.669 | Acc: 63.910,95.655,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.677 | Acc: 63.537,95.620,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.678 | Acc: 63.436,95.505,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.677 | Acc: 63.490,95.568,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.682 | Acc: 63.197,95.538,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.679 | Acc: 63.303,95.584,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.677 | Acc: 63.373,95.662,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.675 | Acc: 63.402,95.632,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.681 | Acc: 63.238,95.596,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.680 | Acc: 63.228,95.578,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.678 | Acc: 63.200,95.572,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.676 | Acc: 63.185,95.588,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.679 | Acc: 63.162,95.568,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.678 | Acc: 63.190,95.533,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.682 | Acc: 63.123,95.495,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.681 | Acc: 63.180,95.484,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 63.210,95.438,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.683 | Acc: 63.203,95.454,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.475 | Acc: 59.375,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.843 | Acc: 55.990,69.940,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.882 | Acc: 55.583,68.883,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.885 | Acc: 55.136,68.840,74.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.777 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.706 | Acc: 62.798,95.647,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.709 | Acc: 62.081,95.675,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.701 | Acc: 62.500,95.645,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.693 | Acc: 62.664,95.631,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.696 | Acc: 62.717,95.630,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.695 | Acc: 62.816,95.571,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.700 | Acc: 62.544,95.590,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.691 | Acc: 62.723,95.604,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.689 | Acc: 62.711,95.602,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.684 | Acc: 62.889,95.627,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.683 | Acc: 62.914,95.666,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.684 | Acc: 62.886,95.737,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.682 | Acc: 62.850,95.723,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.682 | Acc: 62.964,95.718,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.680 | Acc: 62.933,95.704,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 62.916,95.678,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.682 | Acc: 63.022,95.658,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.680 | Acc: 63.056,95.680,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.680 | Acc: 63.091,95.634,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.518 | Acc: 59.375,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.853 | Acc: 55.692,69.457,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.887 | Acc: 55.412,68.540,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.887 | Acc: 55.149,68.571,73.835,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 1.886 | Acc: 58.594,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.670 | Acc: 64.546,95.833,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.691 | Acc: 63.129,95.598,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.681 | Acc: 63.435,95.530,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.677 | Acc: 63.445,95.679,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.682 | Acc: 63.057,95.552,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.687 | Acc: 62.855,95.635,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.688 | Acc: 62.755,95.523,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.681 | Acc: 62.942,95.609,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.680 | Acc: 63.022,95.606,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.684 | Acc: 62.963,95.592,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.682 | Acc: 63.020,95.602,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.681 | Acc: 63.103,95.604,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.679 | Acc: 63.144,95.582,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 63.095,95.613,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.680 | Acc: 63.053,95.627,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.685 | Acc: 62.975,95.570,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.685 | Acc: 62.944,95.597,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.685 | Acc: 63.013,95.620,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.685 | Acc: 63.045,95.606,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.458 | Acc: 61.719,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.837 | Acc: 55.952,69.717,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.873 | Acc: 55.297,68.941,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.874 | Acc: 54.880,68.788,74.155,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 1.560 | Acc: 67.969,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.641 | Acc: 64.397,95.982,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.653 | Acc: 64.329,96.018,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.662 | Acc: 63.922,95.876,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.649 | Acc: 64.072,95.891,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.663 | Acc: 63.668,95.808,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.661 | Acc: 63.966,95.771,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.662 | Acc: 63.835,95.678,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.674 | Acc: 63.558,95.575,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.672 | Acc: 63.488,95.584,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.678 | Acc: 63.262,95.577,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.676 | Acc: 63.433,95.560,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.677 | Acc: 63.476,95.533,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.676 | Acc: 63.443,95.537,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.676 | Acc: 63.409,95.490,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.676 | Acc: 63.382,95.497,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.676 | Acc: 63.466,95.510,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.676 | Acc: 63.485,95.491,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.677 | Acc: 63.470,95.494,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.678 | Acc: 63.398,95.505,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.499 | Acc: 60.156,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.849 | Acc: 55.394,69.978,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.881 | Acc: 55.107,69.188,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.881 | Acc: 54.854,69.057,74.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 1.622 | Acc: 63.281,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.748 | Acc: 62.649,95.647,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.735 | Acc: 63.014,95.617,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.719 | Acc: 63.166,95.645,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.696 | Acc: 63.657,95.775,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.691 | Acc: 63.653,95.692,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.692 | Acc: 63.494,95.700,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.695 | Acc: 63.398,95.667,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.692 | Acc: 63.398,95.730,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.687 | Acc: 63.463,95.723,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.686 | Acc: 63.448,95.713,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.684 | Acc: 63.504,95.691,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.684 | Acc: 63.563,95.714,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.684 | Acc: 63.488,95.660,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.681 | Acc: 63.509,95.721,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.679 | Acc: 63.528,95.725,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.682 | Acc: 63.437,95.721,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.682 | Acc: 63.414,95.732,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 63.450,95.715,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.681 | Acc: 63.380,95.706,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.521 | Acc: 59.375,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.845 | Acc: 55.543,70.089,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.881 | Acc: 55.030,69.074,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.882 | Acc: 54.764,68.968,73.911,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 1.635 | Acc: 63.281,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.642 | Acc: 65.365,95.350,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.676 | Acc: 63.472,95.179,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.681 | Acc: 63.499,95.210,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.686 | Acc: 63.252,95.312,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.687 | Acc: 63.312,95.351,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.687 | Acc: 63.055,95.267,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.683 | Acc: 63.187,95.412,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.681 | Acc: 63.233,95.400,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.686 | Acc: 63.078,95.429,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.689 | Acc: 62.994,95.468,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.689 | Acc: 62.991,95.457,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.690 | Acc: 62.960,95.439,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.690 | Acc: 62.985,95.462,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.686 | Acc: 63.064,95.543,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.685 | Acc: 63.113,95.528,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.686 | Acc: 63.104,95.507,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.683 | Acc: 63.270,95.493,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.681 | Acc: 63.396,95.481,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.680 | Acc: 63.423,95.518,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.533 | Acc: 57.812,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.852 | Acc: 55.246,69.792,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.883 | Acc: 54.764,68.998,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.885 | Acc: 54.623,68.878,73.835,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 1.667 | Acc: 64.844,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.677 | Acc: 63.728,95.833,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.681 | Acc: 62.957,95.675,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.682 | Acc: 62.935,95.530,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.688 | Acc: 63.281,95.737,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.691 | Acc: 62.980,95.676,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.690 | Acc: 63.100,95.668,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.685 | Acc: 63.337,95.695,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.682 | Acc: 63.339,95.672,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 63.406,95.684,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.674 | Acc: 63.398,95.701,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.678 | Acc: 63.306,95.723,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.680 | Acc: 63.333,95.682,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.681 | Acc: 63.332,95.645,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.677 | Acc: 63.498,95.696,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.677 | Acc: 63.471,95.681,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.680 | Acc: 63.347,95.624,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.680 | Acc: 63.382,95.624,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 63.355,95.574,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.681 | Acc: 63.396,95.585,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.479 | Acc: 60.156,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.843 | Acc: 55.543,69.568,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.879 | Acc: 54.954,68.769,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.880 | Acc: 54.700,68.571,74.052,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 1.614 | Acc: 65.625,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.689 | Acc: 61.942,96.019,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.664 | Acc: 62.652,95.960,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.651 | Acc: 63.320,95.863,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.651 | Acc: 63.503,95.775,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.667 | Acc: 63.266,95.699,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.676 | Acc: 63.146,95.661,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.681 | Acc: 62.965,95.717,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.684 | Acc: 62.801,95.672,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.689 | Acc: 62.837,95.658,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.686 | Acc: 62.858,95.635,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.688 | Acc: 62.839,95.571,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.688 | Acc: 62.863,95.549,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.687 | Acc: 62.916,95.549,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.687 | Acc: 62.898,95.563,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.687 | Acc: 62.905,95.567,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.686 | Acc: 63.006,95.539,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.685 | Acc: 63.027,95.546,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 63.082,95.551,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.681 | Acc: 63.125,95.540,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.487 | Acc: 60.156,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.852 | Acc: 55.618,69.494,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.883 | Acc: 55.088,68.693,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.883 | Acc: 54.816,68.558,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 1.749 | Acc: 63.281,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.701 | Acc: 61.570,95.796,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.700 | Acc: 62.329,95.522,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.692 | Acc: 62.500,95.812,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.692 | Acc: 62.442,95.814,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.671 | Acc: 63.088,95.916,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.671 | Acc: 63.230,95.868,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.664 | Acc: 63.375,95.806,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.664 | Acc: 63.354,95.764,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.673 | Acc: 63.139,95.761,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.679 | Acc: 63.106,95.740,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.678 | Acc: 63.168,95.751,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.678 | Acc: 63.249,95.666,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.675 | Acc: 63.308,95.693,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.680 | Acc: 63.259,95.632,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.680 | Acc: 63.284,95.621,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.679 | Acc: 63.352,95.607,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 63.345,95.581,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.676 | Acc: 63.333,95.577,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.674 | Acc: 63.388,95.565,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.454 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.847 | Acc: 55.543,69.457,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.879 | Acc: 55.107,68.712,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.882 | Acc: 54.803,68.596,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 1.876 | Acc: 62.500,90.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.645 | Acc: 62.649,96.243,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.632 | Acc: 63.529,96.265,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.657 | Acc: 63.614,95.991,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.649 | Acc: 63.725,95.891,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.656 | Acc: 63.606,95.815,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.660 | Acc: 63.404,95.687,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.660 | Acc: 63.470,95.645,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.660 | Acc: 63.427,95.744,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.661 | Acc: 63.493,95.710,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.663 | Acc: 63.371,95.748,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.668 | Acc: 63.292,95.712,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.668 | Acc: 63.408,95.659,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.674 | Acc: 63.293,95.630,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 63.192,95.607,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.679 | Acc: 63.185,95.645,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.682 | Acc: 63.133,95.619,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 63.192,95.615,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.683 | Acc: 63.188,95.611,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.680 | Acc: 63.265,95.600,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.481 | Acc: 57.812,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.852 | Acc: 55.729,69.457,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.886 | Acc: 55.221,68.617,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.887 | Acc: 54.841,68.635,73.796,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 1.658 | Acc: 64.844,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.656 | Acc: 64.174,95.275,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.666 | Acc: 63.510,95.103,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.670 | Acc: 63.435,95.184,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.672 | Acc: 63.455,95.496,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 63.498,95.483,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.675 | Acc: 63.501,95.590,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.673 | Acc: 63.580,95.573,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.677 | Acc: 63.233,95.609,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.682 | Acc: 63.208,95.632,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.683 | Acc: 63.172,95.522,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.681 | Acc: 63.334,95.532,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.680 | Acc: 63.362,95.539,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.678 | Acc: 63.455,95.543,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.680 | Acc: 63.392,95.554,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.677 | Acc: 63.393,95.559,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.679 | Acc: 63.332,95.536,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 63.336,95.560,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.679 | Acc: 63.307,95.598,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.679 | Acc: 63.349,95.598,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.471 | Acc: 59.375,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.855 | Acc: 55.283,69.382,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.880 | Acc: 55.050,68.655,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.879 | Acc: 54.854,68.519,74.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 1.478 | Acc: 69.531,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.619 | Acc: 65.141,96.354,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.659 | Acc: 64.405,96.018,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.672 | Acc: 63.589,95.991,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.667 | Acc: 63.821,95.901,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.666 | Acc: 63.877,95.908,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.663 | Acc: 63.940,95.907,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.662 | Acc: 63.869,95.822,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.662 | Acc: 63.825,95.861,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.664 | Acc: 63.670,95.822,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.666 | Acc: 63.514,95.822,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.672 | Acc: 63.437,95.670,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.674 | Acc: 63.297,95.685,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.673 | Acc: 63.398,95.681,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.671 | Acc: 63.404,95.721,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.668 | Acc: 63.432,95.759,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.669 | Acc: 63.398,95.765,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.670 | Acc: 63.377,95.757,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.672 | Acc: 63.331,95.717,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.673 | Acc: 63.353,95.719,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.450 | Acc: 60.156,74.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.850 | Acc: 55.729,69.792,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.885 | Acc: 55.164,68.731,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.888 | Acc: 54.816,68.660,73.988,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 1.659 | Acc: 59.375,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.702 | Acc: 63.616,96.019,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.687 | Acc: 63.262,96.132,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.668 | Acc: 63.819,96.004,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.666 | Acc: 63.937,95.901,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.663 | Acc: 63.954,95.924,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.663 | Acc: 63.791,95.803,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.668 | Acc: 63.752,95.761,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.671 | Acc: 63.718,95.769,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.674 | Acc: 63.523,95.731,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.680 | Acc: 63.378,95.670,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.679 | Acc: 63.363,95.627,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.675 | Acc: 63.447,95.627,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.679 | Acc: 63.296,95.687,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.678 | Acc: 63.320,95.705,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.676 | Acc: 63.406,95.689,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.679 | Acc: 63.347,95.639,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.677 | Acc: 63.384,95.617,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.677 | Acc: 63.383,95.622,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.677 | Acc: 63.429,95.634,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.485 | Acc: 60.938,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.849 | Acc: 55.766,69.048,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.885 | Acc: 55.183,68.369,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.888 | Acc: 54.777,68.327,73.668,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 1.541 | Acc: 66.406,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.647 | Acc: 62.723,95.685,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.673 | Acc: 62.748,95.617,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.678 | Acc: 62.910,95.671,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.661 | Acc: 63.320,95.631,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.656 | Acc: 63.475,95.808,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.658 | Acc: 63.443,95.797,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.672 | Acc: 63.182,95.706,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.678 | Acc: 63.087,95.604,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.675 | Acc: 63.191,95.576,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.674 | Acc: 63.293,95.577,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.675 | Acc: 63.239,95.631,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.677 | Acc: 63.265,95.633,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.675 | Acc: 63.296,95.636,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.679 | Acc: 63.215,95.652,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.678 | Acc: 63.297,95.614,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.677 | Acc: 63.323,95.675,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.676 | Acc: 63.293,95.677,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.673 | Acc: 63.322,95.702,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.676 | Acc: 63.224,95.690,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.491 | Acc: 59.375,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.845 | Acc: 55.543,69.680,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.881 | Acc: 55.011,69.112,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.881 | Acc: 54.777,68.852,74.168,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 1.767 | Acc: 63.281,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.648 | Acc: 64.360,95.536,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.662 | Acc: 63.338,95.408,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.671 | Acc: 63.537,95.415,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.675 | Acc: 63.185,95.525,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.673 | Acc: 63.072,95.591,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.676 | Acc: 63.062,95.610,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.682 | Acc: 62.977,95.590,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.676 | Acc: 63.252,95.623,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.680 | Acc: 63.130,95.610,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.680 | Acc: 63.149,95.658,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.683 | Acc: 63.119,95.659,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.679 | Acc: 63.187,95.682,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.676 | Acc: 63.239,95.660,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.677 | Acc: 63.151,95.674,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.677 | Acc: 63.110,95.650,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.677 | Acc: 63.147,95.646,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.675 | Acc: 63.171,95.606,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.675 | Acc: 63.188,95.579,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.675 | Acc: 63.220,95.544,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.476 | Acc: 59.375,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.858 | Acc: 55.357,69.866,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.888 | Acc: 54.935,68.845,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.889 | Acc: 54.623,68.763,73.899,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 1.548 | Acc: 70.312,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.650 | Acc: 64.174,95.759,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.664 | Acc: 63.453,95.675,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.666 | Acc: 63.486,95.722,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.661 | Acc: 63.503,95.891,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.659 | Acc: 63.382,95.900,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.665 | Acc: 63.146,95.771,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.674 | Acc: 62.810,95.800,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.670 | Acc: 62.976,95.841,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.670 | Acc: 62.992,95.826,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.666 | Acc: 63.141,95.787,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.663 | Acc: 63.274,95.740,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.663 | Acc: 63.382,95.718,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.664 | Acc: 63.431,95.699,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.667 | Acc: 63.381,95.713,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.667 | Acc: 63.432,95.712,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.671 | Acc: 63.374,95.663,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.669 | Acc: 63.368,95.686,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.671 | Acc: 63.286,95.674,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.672 | Acc: 63.285,95.700,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.485 | Acc: 58.594,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.851 | Acc: 55.692,69.903,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.882 | Acc: 55.221,68.941,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.884 | Acc: 54.828,68.827,74.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 1.568 | Acc: 69.531,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.714 | Acc: 62.128,95.796,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.691 | Acc: 62.843,96.113,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.681 | Acc: 62.871,96.107,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 62.982,95.988,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.687 | Acc: 63.011,96.024,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.681 | Acc: 63.268,95.952,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.674 | Acc: 63.647,95.878,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.674 | Acc: 63.689,95.827,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.672 | Acc: 63.713,95.852,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.665 | Acc: 63.853,95.884,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 63.999,95.910,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.666 | Acc: 63.832,95.851,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.667 | Acc: 63.823,95.863,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.665 | Acc: 63.807,95.882,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.666 | Acc: 63.772,95.902,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.664 | Acc: 63.734,95.904,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.667 | Acc: 63.657,95.851,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.666 | Acc: 63.669,95.828,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.665 | Acc: 63.728,95.831,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.475 | Acc: 59.375,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.856 | Acc: 55.432,69.568,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.885 | Acc: 55.088,68.826,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.886 | Acc: 54.688,68.840,74.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 1.678 | Acc: 62.500,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.658 | Acc: 63.653,95.350,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.671 | Acc: 62.995,95.598,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.672 | Acc: 63.051,95.556,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.671 | Acc: 63.117,95.833,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.665 | Acc: 63.405,95.931,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.672 | Acc: 63.268,95.835,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.670 | Acc: 63.420,95.889,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.663 | Acc: 63.592,95.909,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.662 | Acc: 63.618,95.878,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.664 | Acc: 63.662,95.915,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.665 | Acc: 63.631,95.931,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.666 | Acc: 63.557,95.909,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.667 | Acc: 63.554,95.911,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.663 | Acc: 63.648,95.919,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.663 | Acc: 63.725,95.907,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.663 | Acc: 63.756,95.906,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.665 | Acc: 63.680,95.869,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.664 | Acc: 63.701,95.901,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.664 | Acc: 63.704,95.887,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.493 | Acc: 59.375,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.849 | Acc: 56.138,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.882 | Acc: 55.583,68.617,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.882 | Acc: 55.225,68.558,74.014,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 1.944 | Acc: 56.250,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.705 | Acc: 61.868,94.420,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.684 | Acc: 63.243,95.389,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.692 | Acc: 63.320,95.428,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.680 | Acc: 63.098,95.631,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.676 | Acc: 63.258,95.645,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.673 | Acc: 63.004,95.764,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.666 | Acc: 63.220,95.828,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.663 | Acc: 63.296,95.798,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.669 | Acc: 63.165,95.869,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.668 | Acc: 63.188,95.829,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.668 | Acc: 63.214,95.829,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.670 | Acc: 63.229,95.844,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.666 | Acc: 63.332,95.878,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.665 | Acc: 63.270,95.852,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.670 | Acc: 63.170,95.808,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.669 | Acc: 63.199,95.821,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.666 | Acc: 63.309,95.800,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.667 | Acc: 63.288,95.784,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.665 | Acc: 63.374,95.780,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.468 | Acc: 59.375,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.847 | Acc: 55.952,69.717,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.878 | Acc: 55.335,68.807,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.879 | Acc: 55.020,68.712,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 1.809 | Acc: 62.500,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.704 | Acc: 62.686,95.908,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.663 | Acc: 63.491,95.884,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.651 | Acc: 63.768,96.043,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.657 | Acc: 63.436,95.910,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.657 | Acc: 63.459,95.823,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.658 | Acc: 63.617,95.881,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.661 | Acc: 63.736,95.916,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.661 | Acc: 63.563,95.895,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.660 | Acc: 63.605,95.943,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.656 | Acc: 63.732,95.973,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.655 | Acc: 63.797,95.945,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.656 | Acc: 63.790,95.941,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.657 | Acc: 63.775,95.941,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.659 | Acc: 63.690,95.905,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.657 | Acc: 63.712,95.891,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.656 | Acc: 63.751,95.894,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.656 | Acc: 63.707,95.888,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.656 | Acc: 63.666,95.880,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.659 | Acc: 63.630,95.850,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.485 | Acc: 59.375,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.853 | Acc: 55.543,69.829,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.886 | Acc: 54.859,68.921,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.886 | Acc: 54.598,68.904,74.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 1.831 | Acc: 58.594,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.713 | Acc: 61.496,95.722,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.692 | Acc: 62.633,95.713,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.670 | Acc: 63.153,96.068,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.679 | Acc: 63.030,96.017,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.675 | Acc: 63.127,95.939,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.677 | Acc: 63.468,95.868,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.679 | Acc: 63.259,95.872,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.673 | Acc: 63.388,95.890,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.676 | Acc: 63.428,95.878,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.672 | Acc: 63.495,95.934,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.674 | Acc: 63.380,95.928,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.673 | Acc: 63.479,95.883,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.669 | Acc: 63.628,95.902,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.669 | Acc: 63.587,95.888,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.670 | Acc: 63.530,95.930,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.667 | Acc: 63.568,95.936,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.667 | Acc: 63.616,95.949,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.667 | Acc: 63.623,95.927,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.665 | Acc: 63.595,95.934,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.467 | Acc: 58.594,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.850 | Acc: 55.729,69.568,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.884 | Acc: 55.335,68.750,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.884 | Acc: 54.944,68.724,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 1.629 | Acc: 66.406,98.438,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.649 | Acc: 63.802,96.094,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.676 | Acc: 63.491,95.903,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.645 | Acc: 64.331,95.799,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.657 | Acc: 63.947,95.862,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.661 | Acc: 63.714,95.900,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.667 | Acc: 63.623,95.881,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.667 | Acc: 63.614,95.867,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.661 | Acc: 63.786,95.924,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.663 | Acc: 63.739,95.934,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.659 | Acc: 63.724,95.985,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.661 | Acc: 63.610,95.963,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.662 | Acc: 63.518,95.948,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.663 | Acc: 63.536,95.941,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.663 | Acc: 63.476,95.963,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.665 | Acc: 63.463,95.935,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.669 | Acc: 63.408,95.865,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.670 | Acc: 63.391,95.844,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.668 | Acc: 63.398,95.849,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.665 | Acc: 63.492,95.852,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.476 | Acc: 60.156,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.853 | Acc: 55.618,69.680,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.884 | Acc: 55.088,68.921,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.885 | Acc: 54.816,68.916,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 1.718 | Acc: 53.906,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.676 | Acc: 63.318,95.759,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.677 | Acc: 63.148,95.979,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.675 | Acc: 63.294,95.799,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.664 | Acc: 63.416,96.046,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.665 | Acc: 63.467,95.993,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.659 | Acc: 63.591,96.100,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.656 | Acc: 63.730,96.072,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.653 | Acc: 63.864,96.040,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.656 | Acc: 63.851,95.973,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.661 | Acc: 63.682,95.872,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.660 | Acc: 63.660,95.875,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.661 | Acc: 63.628,95.860,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.658 | Acc: 63.688,95.824,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.662 | Acc: 63.648,95.796,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.663 | Acc: 63.702,95.777,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.664 | Acc: 63.649,95.819,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.662 | Acc: 63.694,95.812,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.663 | Acc: 63.664,95.836,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.665 | Acc: 63.556,95.809,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.480 | Acc: 57.812,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.847 | Acc: 55.766,69.717,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.878 | Acc: 55.221,68.807,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.882 | Acc: 54.892,68.750,74.168,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 1.361 | Acc: 69.531,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.649 | Acc: 63.430,95.312,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.647 | Acc: 63.815,95.941,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.645 | Acc: 63.525,96.004,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.650 | Acc: 63.368,95.910,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.652 | Acc: 63.413,95.993,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.661 | Acc: 63.255,95.971,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.661 | Acc: 63.248,95.950,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.659 | Acc: 63.252,95.982,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.657 | Acc: 63.303,95.938,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.659 | Acc: 63.312,95.931,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.661 | Acc: 63.260,95.966,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.663 | Acc: 63.340,95.971,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.665 | Acc: 63.326,95.932,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.666 | Acc: 63.248,95.963,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.662 | Acc: 63.434,95.920,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.661 | Acc: 63.515,95.870,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.664 | Acc: 63.476,95.849,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.662 | Acc: 63.560,95.858,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.661 | Acc: 63.554,95.883,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.485 | Acc: 60.938,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.848 | Acc: 55.878,69.754,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.881 | Acc: 55.278,68.960,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.882 | Acc: 54.956,68.852,73.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 1.765 | Acc: 60.938,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.680 | Acc: 64.323,95.685,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.668 | Acc: 63.720,95.789,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.650 | Acc: 64.075,95.838,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.653 | Acc: 64.477,95.679,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.651 | Acc: 64.194,95.668,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.658 | Acc: 63.998,95.681,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.661 | Acc: 63.891,95.689,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.662 | Acc: 63.665,95.696,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.664 | Acc: 63.545,95.710,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.665 | Acc: 63.577,95.690,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.667 | Acc: 63.444,95.666,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.663 | Acc: 63.570,95.705,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.662 | Acc: 63.655,95.729,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.663 | Acc: 63.626,95.741,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.664 | Acc: 63.582,95.790,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.668 | Acc: 63.508,95.760,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.670 | Acc: 63.506,95.748,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.668 | Acc: 63.513,95.771,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.668 | Acc: 63.505,95.737,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.495 | Acc: 60.156,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.851 | Acc: 55.915,69.717,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.882 | Acc: 55.297,69.017,73.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.883 | Acc: 54.956,68.904,73.924,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 1.567 | Acc: 68.750,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.670 | Acc: 63.170,96.429,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.668 | Acc: 63.872,96.361,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.664 | Acc: 63.973,96.145,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.678 | Acc: 63.551,95.978,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.669 | Acc: 63.591,95.947,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.666 | Acc: 63.501,95.990,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.665 | Acc: 63.586,95.905,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.665 | Acc: 63.655,95.919,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.663 | Acc: 63.670,95.969,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.666 | Acc: 63.658,95.942,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.671 | Acc: 63.592,95.818,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.668 | Acc: 63.518,95.893,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.664 | Acc: 63.575,95.902,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.661 | Acc: 63.615,95.916,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.662 | Acc: 63.533,95.928,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.663 | Acc: 63.527,95.906,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.662 | Acc: 63.538,95.924,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.662 | Acc: 63.517,95.897,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.660 | Acc: 63.566,95.885,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.479 | Acc: 58.594,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.855 | Acc: 55.766,69.792,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.886 | Acc: 55.145,68.864,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.885 | Acc: 54.905,68.814,74.078,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 1.587 | Acc: 69.531,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.626 | Acc: 64.174,96.391,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.630 | Acc: 64.386,96.246,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.633 | Acc: 64.447,96.081,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.654 | Acc: 64.014,95.853,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.659 | Acc: 63.830,95.715,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.656 | Acc: 63.888,95.745,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.656 | Acc: 64.046,95.750,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.653 | Acc: 64.135,95.769,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.659 | Acc: 63.911,95.714,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.664 | Acc: 63.790,95.709,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.667 | Acc: 63.695,95.751,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.666 | Acc: 63.644,95.724,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.667 | Acc: 63.608,95.788,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.663 | Acc: 63.687,95.827,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.662 | Acc: 63.652,95.852,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.660 | Acc: 63.646,95.870,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.661 | Acc: 63.639,95.876,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.661 | Acc: 63.604,95.890,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.661 | Acc: 63.613,95.901,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.487 | Acc: 58.594,74.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.850 | Acc: 55.878,69.792,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.882 | Acc: 55.202,68.921,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.885 | Acc: 54.918,68.840,73.937,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.803 | Acc: 60.938,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.713 | Acc: 62.240,95.796,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.703 | Acc: 61.986,95.827,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.683 | Acc: 62.756,95.978,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.673 | Acc: 62.876,96.017,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.673 | Acc: 62.693,96.109,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.671 | Acc: 62.694,96.178,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.671 | Acc: 62.838,96.227,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.673 | Acc: 62.786,96.147,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 62.850,96.055,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.673 | Acc: 63.083,96.047,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.667 | Acc: 63.175,96.037,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.666 | Acc: 63.323,96.055,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.666 | Acc: 63.374,96.052,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.666 | Acc: 63.401,96.038,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.665 | Acc: 63.476,96.024,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.664 | Acc: 63.515,96.057,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.661 | Acc: 63.570,96.039,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.657 | Acc: 63.679,96.033,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.658 | Acc: 63.708,95.977,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.480 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.851 | Acc: 55.766,69.754,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.883 | Acc: 55.278,68.864,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.882 | Acc: 55.020,68.673,74.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 1.636 | Acc: 64.844,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.677 | Acc: 62.054,96.391,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.657 | Acc: 63.262,96.361,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.654 | Acc: 63.845,96.183,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.646 | Acc: 64.188,96.200,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.644 | Acc: 64.349,96.287,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.650 | Acc: 64.056,96.236,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.655 | Acc: 63.852,96.249,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.665 | Acc: 63.582,96.162,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.665 | Acc: 63.588,96.120,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.669 | Acc: 63.514,96.063,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.669 | Acc: 63.479,96.080,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.668 | Acc: 63.570,96.058,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.670 | Acc: 63.530,96.040,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.671 | Acc: 63.479,96.044,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.669 | Acc: 63.533,96.013,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.668 | Acc: 63.583,95.992,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.667 | Acc: 63.616,96.011,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.665 | Acc: 63.617,95.996,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.666 | Acc: 63.622,95.979,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.499 | Acc: 60.938,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.847 | Acc: 55.580,69.717,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.881 | Acc: 55.202,68.864,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.884 | Acc: 54.854,68.763,73.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 1.567 | Acc: 63.281,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.645 | Acc: 64.360,96.019,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.648 | Acc: 64.005,95.998,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.652 | Acc: 63.832,96.030,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.663 | Acc: 63.368,95.910,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.659 | Acc: 63.614,95.808,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.667 | Acc: 63.572,95.732,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.655 | Acc: 63.824,95.878,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.661 | Acc: 63.703,95.919,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.659 | Acc: 63.709,95.900,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.660 | Acc: 63.592,95.810,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.661 | Acc: 63.645,95.832,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.663 | Acc: 63.576,95.808,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.665 | Acc: 63.536,95.812,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.666 | Acc: 63.568,95.832,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.665 | Acc: 63.559,95.865,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.662 | Acc: 63.651,95.870,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.662 | Acc: 63.618,95.830,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.661 | Acc: 63.589,95.834,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.659 | Acc: 63.574,95.842,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.502 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.850 | Acc: 55.878,69.643,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.886 | Acc: 55.259,68.807,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.888 | Acc: 54.995,68.699,73.911,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 1.600 | Acc: 61.719,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.615 | Acc: 63.914,96.615,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.644 | Acc: 63.529,96.284,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.656 | Acc: 63.550,96.107,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.657 | Acc: 63.368,96.209,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.646 | Acc: 63.815,96.357,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.653 | Acc: 63.662,96.268,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.644 | Acc: 63.852,96.354,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.649 | Acc: 63.781,96.307,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.652 | Acc: 63.722,96.206,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.652 | Acc: 63.724,96.245,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.656 | Acc: 63.617,96.225,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.659 | Acc: 63.534,96.152,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.658 | Acc: 63.611,96.100,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.657 | Acc: 63.707,96.066,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.657 | Acc: 63.717,96.068,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.659 | Acc: 63.637,95.955,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.658 | Acc: 63.639,95.945,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.658 | Acc: 63.664,95.975,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.658 | Acc: 63.677,95.940,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.475 | Acc: 59.375,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.858 | Acc: 55.655,69.606,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.892 | Acc: 55.183,68.788,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.893 | Acc: 54.790,68.660,73.860,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 1.707 | Acc: 59.375,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.630 | Acc: 64.881,96.057,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.641 | Acc: 63.929,96.361,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.636 | Acc: 63.858,96.196,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.642 | Acc: 63.966,96.190,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.646 | Acc: 63.869,96.071,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.646 | Acc: 63.979,96.023,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.647 | Acc: 63.664,96.072,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.656 | Acc: 63.417,96.031,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.655 | Acc: 63.519,96.033,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.655 | Acc: 63.584,96.086,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 63.529,96.058,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.657 | Acc: 63.638,96.084,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.657 | Acc: 63.640,96.091,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.658 | Acc: 63.648,96.085,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.658 | Acc: 63.658,96.089,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.660 | Acc: 63.568,96.062,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 63.616,96.043,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.658 | Acc: 63.615,96.033,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.657 | Acc: 63.659,96.006,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.496 | Acc: 60.156,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.845 | Acc: 55.729,69.568,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.878 | Acc: 55.221,68.750,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.877 | Acc: 54.969,68.763,74.206,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 1.639 | Acc: 60.156,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.642 | Acc: 64.583,95.833,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.645 | Acc: 64.024,95.636,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.663 | Acc: 63.627,95.517,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.657 | Acc: 63.831,95.660,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.652 | Acc: 63.892,95.699,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.641 | Acc: 64.075,95.706,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.643 | Acc: 63.990,95.706,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.645 | Acc: 63.796,95.638,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.652 | Acc: 63.601,95.623,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.652 | Acc: 63.752,95.686,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.656 | Acc: 63.568,95.694,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 63.460,95.750,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.659 | Acc: 63.524,95.759,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.658 | Acc: 63.490,95.799,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.658 | Acc: 63.466,95.826,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 63.520,95.824,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.663 | Acc: 63.419,95.803,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.664 | Acc: 63.368,95.795,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.662 | Acc: 63.427,95.801,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.482 | Acc: 60.938,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.857 | Acc: 55.915,69.643,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.886 | Acc: 55.450,68.636,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.884 | Acc: 54.918,68.609,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.539 | Acc: 70.312,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.645 | Acc: 62.612,95.685,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.648 | Acc: 63.186,95.389,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.658 | Acc: 63.448,95.569,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.663 | Acc: 63.561,95.718,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.668 | Acc: 63.482,95.715,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.666 | Acc: 63.585,95.745,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.663 | Acc: 63.542,95.811,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.660 | Acc: 63.674,95.807,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.658 | Acc: 63.640,95.865,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.654 | Acc: 63.806,95.919,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.661 | Acc: 63.610,95.928,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.662 | Acc: 63.583,95.886,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.662 | Acc: 63.611,95.851,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.664 | Acc: 63.568,95.857,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.662 | Acc: 63.621,95.891,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.661 | Acc: 63.671,95.884,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.663 | Acc: 63.643,95.897,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.662 | Acc: 63.651,95.927,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.662 | Acc: 63.671,95.944,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.484 | Acc: 59.375,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.845 | Acc: 55.543,69.531,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.878 | Acc: 55.164,68.902,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.879 | Acc: 54.841,68.827,74.014,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 1.539 | Acc: 71.094,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.645 | Acc: 63.802,95.796,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.634 | Acc: 64.024,96.170,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.645 | Acc: 63.909,96.376,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.648 | Acc: 63.976,96.325,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.655 | Acc: 63.838,96.179,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.654 | Acc: 63.662,95.997,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.656 | Acc: 63.619,95.966,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.651 | Acc: 63.728,95.968,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.655 | Acc: 63.674,95.994,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.658 | Acc: 63.619,96.012,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.661 | Acc: 63.507,95.945,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 63.644,95.954,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.661 | Acc: 63.631,95.887,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.661 | Acc: 63.579,95.902,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.660 | Acc: 63.616,95.920,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.662 | Acc: 63.566,95.880,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 63.680,95.904,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.662 | Acc: 63.602,95.886,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.662 | Acc: 63.558,95.903,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.465 | Acc: 59.375,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.845 | Acc: 55.320,69.754,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.880 | Acc: 55.030,69.055,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.883 | Acc: 54.764,68.878,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 1.890 | Acc: 53.906,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.635 | Acc: 64.509,96.019,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.664 | Acc: 63.700,95.770,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.675 | Acc: 63.256,95.914,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.668 | Acc: 63.079,95.939,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.672 | Acc: 63.219,95.908,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.673 | Acc: 63.417,95.945,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.670 | Acc: 63.542,95.878,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.669 | Acc: 63.504,95.905,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.666 | Acc: 63.570,95.908,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.662 | Acc: 63.674,96.000,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.660 | Acc: 63.737,95.984,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.662 | Acc: 63.758,95.987,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.662 | Acc: 63.781,95.947,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.660 | Acc: 63.846,95.930,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.659 | Acc: 63.824,95.951,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.659 | Acc: 63.805,95.943,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.657 | Acc: 63.778,95.947,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.658 | Acc: 63.731,95.942,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.659 | Acc: 63.759,95.938,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.478 | Acc: 59.375,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.839 | Acc: 55.841,69.680,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.877 | Acc: 55.202,68.731,74.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.878 | Acc: 54.995,68.673,73.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 1.929 | Acc: 50.781,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.625 | Acc: 63.839,96.243,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.658 | Acc: 63.281,95.998,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.667 | Acc: 63.397,95.991,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.674 | Acc: 63.204,96.007,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.670 | Acc: 63.041,96.055,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.665 | Acc: 63.339,96.068,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.667 | Acc: 63.314,96.077,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.661 | Acc: 63.325,96.089,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.660 | Acc: 63.575,96.072,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.662 | Acc: 63.569,96.074,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.662 | Acc: 63.557,96.058,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 63.631,96.065,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.663 | Acc: 63.500,96.004,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.664 | Acc: 63.479,96.016,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.666 | Acc: 63.525,96.003,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.665 | Acc: 63.486,96.028,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.666 | Acc: 63.389,95.986,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.666 | Acc: 63.480,95.949,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.666 | Acc: 63.513,95.944,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.470 | Acc: 60.938,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.846 | Acc: 55.878,69.903,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.880 | Acc: 55.335,69.017,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.884 | Acc: 54.816,68.891,74.014,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 1.774 | Acc: 67.188,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.640 | Acc: 63.430,96.168,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 62.824,95.865,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.676 | Acc: 63.115,95.722,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 63.108,95.747,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.679 | Acc: 63.235,95.893,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.672 | Acc: 63.520,95.952,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.669 | Acc: 63.713,96.055,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.662 | Acc: 63.815,96.031,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.661 | Acc: 63.825,95.943,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.659 | Acc: 63.825,95.946,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 63.840,95.959,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.661 | Acc: 63.771,95.958,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.658 | Acc: 63.799,95.983,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.658 | Acc: 63.721,96.016,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.658 | Acc: 63.707,96.037,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.656 | Acc: 63.712,96.038,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.661 | Acc: 63.597,95.998,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.661 | Acc: 63.537,95.964,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.663 | Acc: 63.505,95.975,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.475 | Acc: 59.375,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.844 | Acc: 55.841,69.717,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.879 | Acc: 55.278,68.864,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.880 | Acc: 54.956,68.724,74.014,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 1.694 | Acc: 64.844,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.677 | Acc: 62.760,95.871,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.682 | Acc: 62.671,95.827,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.656 | Acc: 63.589,95.658,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.668 | Acc: 62.982,95.747,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.679 | Acc: 62.910,95.699,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.675 | Acc: 62.887,95.732,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.666 | Acc: 63.204,95.795,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.663 | Acc: 63.296,95.875,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.661 | Acc: 63.299,95.904,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.662 | Acc: 63.289,95.911,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 63.355,95.906,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.655 | Acc: 63.492,95.915,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.656 | Acc: 63.491,95.926,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.655 | Acc: 63.554,95.935,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.661 | Acc: 63.434,95.839,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.659 | Acc: 63.493,95.870,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.658 | Acc: 63.492,95.892,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.659 | Acc: 63.450,95.903,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.660 | Acc: 63.404,95.895,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.475 | Acc: 58.594,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.838 | Acc: 55.766,69.866,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.877 | Acc: 55.297,68.941,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.880 | Acc: 55.020,68.763,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 1.652 | Acc: 64.844,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.674 | Acc: 62.649,96.168,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.648 | Acc: 63.453,96.208,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.649 | Acc: 62.987,96.030,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.661 | Acc: 62.722,96.065,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.664 | Acc: 62.740,96.032,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.674 | Acc: 62.506,95.958,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.669 | Acc: 62.522,96.038,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.663 | Acc: 62.752,96.031,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.660 | Acc: 62.953,95.930,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.660 | Acc: 63.009,95.942,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.664 | Acc: 63.087,95.903,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.662 | Acc: 63.126,95.883,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.659 | Acc: 63.191,95.926,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.658 | Acc: 63.315,95.874,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.660 | Acc: 63.260,95.855,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.663 | Acc: 63.208,95.816,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.666 | Acc: 63.293,95.826,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.664 | Acc: 63.368,95.823,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.664 | Acc: 63.419,95.829,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.455 | Acc: 60.156,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.841 | Acc: 55.729,69.717,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.877 | Acc: 55.240,68.941,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.879 | Acc: 54.790,68.891,73.975,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 1.511 | Acc: 72.656,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.684 | Acc: 63.728,95.908,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.682 | Acc: 63.453,95.732,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.665 | Acc: 63.691,95.966,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.676 | Acc: 63.542,95.997,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.669 | Acc: 63.575,95.993,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.672 | Acc: 63.275,95.958,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.666 | Acc: 63.342,96.022,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.667 | Acc: 63.199,96.011,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.667 | Acc: 63.186,95.982,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.666 | Acc: 63.242,95.977,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.665 | Acc: 63.313,96.020,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.661 | Acc: 63.391,96.006,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.660 | Acc: 63.401,96.001,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.659 | Acc: 63.420,95.988,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.661 | Acc: 63.372,95.930,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 63.510,95.955,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.661 | Acc: 63.476,95.945,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.662 | Acc: 63.504,95.934,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.661 | Acc: 63.525,95.917,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.494 | Acc: 57.812,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.850 | Acc: 55.357,69.866,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.882 | Acc: 55.069,68.960,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.883 | Acc: 54.726,68.801,73.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 1.666 | Acc: 64.844,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.628 | Acc: 64.881,96.168,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.664 | Acc: 63.662,95.713,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.677 | Acc: 63.358,95.761,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.669 | Acc: 63.407,95.756,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.672 | Acc: 63.297,95.792,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.669 | Acc: 63.352,95.861,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.661 | Acc: 63.608,96.000,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.666 | Acc: 63.568,95.982,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.663 | Acc: 63.519,95.947,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.664 | Acc: 63.421,95.989,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.661 | Acc: 63.561,96.023,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.661 | Acc: 63.570,96.022,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.662 | Acc: 63.572,95.986,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.663 | Acc: 63.629,95.958,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.667 | Acc: 63.530,95.977,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.663 | Acc: 63.612,95.972,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.664 | Acc: 63.542,95.979,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.663 | Acc: 63.591,95.996,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.661 | Acc: 63.659,96.001,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.481 | Acc: 58.594,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.852 | Acc: 55.580,69.568,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.887 | Acc: 55.069,68.807,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.886 | Acc: 54.777,68.814,74.129,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 1.790 | Acc: 66.406,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.721 | Acc: 62.128,96.019,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.692 | Acc: 62.538,95.713,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.686 | Acc: 62.692,95.812,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.694 | Acc: 62.751,95.718,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.679 | Acc: 63.312,95.862,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.677 | Acc: 63.391,95.887,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.672 | Acc: 63.248,95.900,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.667 | Acc: 63.233,95.866,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.661 | Acc: 63.359,95.848,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.661 | Acc: 63.390,95.868,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.660 | Acc: 63.561,95.832,99.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.667 | Acc: 63.427,95.805,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.665 | Acc: 63.524,95.845,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.660 | Acc: 63.629,95.885,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.660 | Acc: 63.626,95.845,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 63.654,95.884,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.656 | Acc: 63.694,95.913,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.657 | Acc: 63.617,95.897,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.659 | Acc: 63.605,95.903,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.477 | Acc: 58.594,72.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.856 | Acc: 55.543,69.643,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.889 | Acc: 54.973,68.826,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.890 | Acc: 54.713,68.724,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 1.222 | Acc: 77.344,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.616 | Acc: 64.993,96.801,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.637 | Acc: 64.653,96.151,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.656 | Acc: 63.922,96.183,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.665 | Acc: 63.532,96.132,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.662 | Acc: 63.552,96.094,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.656 | Acc: 63.675,96.132,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.652 | Acc: 63.913,96.105,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.647 | Acc: 64.145,96.079,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.651 | Acc: 64.024,96.016,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.655 | Acc: 63.647,96.012,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 63.465,95.995,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 63.440,95.984,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.663 | Acc: 63.485,95.962,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.658 | Acc: 63.587,95.977,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.656 | Acc: 63.588,96.008,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.653 | Acc: 63.685,96.033,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.654 | Acc: 63.728,95.988,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.654 | Acc: 63.723,95.996,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.657 | Acc: 63.626,96.006,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.467 | Acc: 57.812,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.843 | Acc: 55.394,69.792,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.881 | Acc: 54.935,68.998,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.884 | Acc: 54.739,68.916,74.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 1.647 | Acc: 66.406,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.611 | Acc: 64.769,96.354,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.652 | Acc: 63.777,95.960,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.639 | Acc: 64.165,96.107,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.647 | Acc: 63.628,96.209,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.641 | Acc: 63.707,96.264,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.639 | Acc: 63.837,96.255,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.642 | Acc: 63.797,96.193,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.645 | Acc: 63.718,96.162,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.647 | Acc: 63.627,96.120,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.652 | Acc: 63.619,96.074,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.653 | Acc: 63.762,96.058,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.654 | Acc: 63.696,96.029,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.654 | Acc: 63.715,96.064,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.656 | Acc: 63.707,95.999,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.654 | Acc: 63.735,96.013,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.654 | Acc: 63.732,96.038,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.654 | Acc: 63.751,96.030,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.654 | Acc: 63.753,96.012,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.656 | Acc: 63.677,95.969,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.484 | Acc: 60.938,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.856 | Acc: 55.618,69.606,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.887 | Acc: 55.202,68.902,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.889 | Acc: 54.816,68.763,73.822,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 1.452 | Acc: 75.000,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.635 | Acc: 65.179,95.647,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.635 | Acc: 64.691,95.922,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.651 | Acc: 63.922,95.722,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.649 | Acc: 63.966,95.737,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.645 | Acc: 64.047,95.900,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.651 | Acc: 63.862,95.855,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.656 | Acc: 63.802,95.883,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.660 | Acc: 63.592,95.909,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.658 | Acc: 63.609,95.921,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.657 | Acc: 63.697,95.965,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.662 | Acc: 63.681,95.945,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.661 | Acc: 63.615,95.938,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.659 | Acc: 63.679,95.944,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.661 | Acc: 63.626,95.963,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.662 | Acc: 63.551,95.959,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.665 | Acc: 63.493,95.972,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.663 | Acc: 63.577,95.940,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.663 | Acc: 63.554,95.931,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.663 | Acc: 63.574,95.922,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.468 | Acc: 58.594,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.849 | Acc: 55.766,69.754,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.881 | Acc: 55.450,68.941,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.884 | Acc: 55.008,68.840,74.039,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 1.649 | Acc: 64.844,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.650 | Acc: 63.653,95.759,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.639 | Acc: 63.491,95.941,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.633 | Acc: 63.742,96.043,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.640 | Acc: 63.715,96.046,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.632 | Acc: 63.985,96.163,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.642 | Acc: 63.901,96.087,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.654 | Acc: 63.780,95.911,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.652 | Acc: 63.742,95.987,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.656 | Acc: 63.683,95.951,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.656 | Acc: 63.732,95.993,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 63.546,95.952,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 63.579,95.945,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.660 | Acc: 63.518,95.938,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.660 | Acc: 63.504,95.907,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.660 | Acc: 63.572,95.889,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.660 | Acc: 63.578,95.889,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.659 | Acc: 63.533,95.906,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.661 | Acc: 63.446,95.905,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.659 | Acc: 63.505,95.932,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.470 | Acc: 57.812,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.848 | Acc: 55.580,69.754,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.882 | Acc: 55.126,69.036,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.885 | Acc: 54.816,68.840,73.886,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 1.894 | Acc: 57.812,92.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.655 | Acc: 63.616,95.722,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.662 | Acc: 63.186,95.922,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.659 | Acc: 63.115,95.914,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.672 | Acc: 63.050,95.775,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.663 | Acc: 63.181,95.808,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.668 | Acc: 62.991,95.771,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.670 | Acc: 63.198,95.711,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.673 | Acc: 63.155,95.720,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.668 | Acc: 63.156,95.865,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.665 | Acc: 63.305,95.915,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.665 | Acc: 63.278,95.906,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.664 | Acc: 63.327,95.915,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.664 | Acc: 63.338,95.905,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.660 | Acc: 63.493,95.924,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.659 | Acc: 63.510,95.972,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 63.588,95.977,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 63.517,95.988,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.666 | Acc: 63.500,95.940,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.662 | Acc: 63.583,95.969,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.462 | Acc: 57.812,73.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.848 | Acc: 55.543,69.717,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.880 | Acc: 55.126,69.055,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.880 | Acc: 54.892,68.840,74.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 1.795 | Acc: 61.719,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.686 | Acc: 62.984,96.391,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.650 | Acc: 63.338,95.960,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.655 | Acc: 63.614,95.902,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.669 | Acc: 63.648,95.795,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.662 | Acc: 63.769,95.947,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.666 | Acc: 63.527,95.952,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.664 | Acc: 63.547,95.933,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.664 | Acc: 63.582,95.871,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.667 | Acc: 63.562,95.779,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.664 | Acc: 63.631,95.826,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.667 | Acc: 63.621,95.832,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.668 | Acc: 63.592,95.831,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.668 | Acc: 63.548,95.830,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.665 | Acc: 63.543,95.857,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.662 | Acc: 63.577,95.876,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.663 | Acc: 63.646,95.880,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 63.696,95.872,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.659 | Acc: 63.716,95.856,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.658 | Acc: 63.710,95.872,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.472 | Acc: 60.156,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.851 | Acc: 55.543,69.531,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.884 | Acc: 54.992,68.807,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.884 | Acc: 54.713,68.673,73.963,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 1.450 | Acc: 71.094,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.673 | Acc: 62.426,95.945,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.677 | Acc: 61.871,95.732,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.683 | Acc: 62.026,95.620,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.666 | Acc: 62.760,95.824,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.672 | Acc: 62.647,95.800,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.669 | Acc: 62.765,95.919,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.666 | Acc: 62.949,95.911,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.660 | Acc: 63.097,95.929,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.658 | Acc: 63.307,95.900,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.660 | Acc: 63.231,95.911,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.658 | Acc: 63.331,95.959,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.656 | Acc: 63.404,95.958,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.656 | Acc: 63.485,95.929,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.656 | Acc: 63.576,95.930,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.660 | Acc: 63.481,95.961,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.656 | Acc: 63.559,95.992,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.658 | Acc: 63.570,95.954,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.658 | Acc: 63.604,95.942,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.660 | Acc: 63.601,95.938,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.457 | Acc: 58.594,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.848 | Acc: 55.841,69.457,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.883 | Acc: 55.221,68.788,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.887 | Acc: 54.867,68.660,74.014,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.792 | Acc: 60.156,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.687 | Acc: 63.021,96.280,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.683 | Acc: 63.777,95.827,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.654 | Acc: 64.127,96.055,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.657 | Acc: 63.648,96.065,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.660 | Acc: 63.861,95.985,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.658 | Acc: 63.720,96.087,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.656 | Acc: 63.758,96.061,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.649 | Acc: 63.864,96.055,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.647 | Acc: 63.916,96.012,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.648 | Acc: 63.911,96.000,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.649 | Acc: 63.932,96.027,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.646 | Acc: 63.962,96.074,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.651 | Acc: 63.805,96.004,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.653 | Acc: 63.809,96.038,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.655 | Acc: 63.772,96.068,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 63.717,96.004,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.659 | Acc: 63.666,95.988,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.659 | Acc: 63.634,96.018,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.658 | Acc: 63.661,96.012,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.476 | Acc: 59.375,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.846 | Acc: 55.729,69.494,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.882 | Acc: 55.240,68.826,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.883 | Acc: 54.944,68.724,74.039,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 1.749 | Acc: 59.375,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.630 | Acc: 63.988,96.391,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.635 | Acc: 63.777,96.322,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.626 | Acc: 64.165,96.196,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.630 | Acc: 63.995,96.142,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.644 | Acc: 63.691,95.939,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.646 | Acc: 63.623,96.055,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.649 | Acc: 63.586,95.961,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.648 | Acc: 63.529,96.011,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.651 | Acc: 63.415,95.982,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.653 | Acc: 63.425,95.911,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.659 | Acc: 63.334,95.885,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.656 | Acc: 63.421,95.867,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.659 | Acc: 63.347,95.830,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.658 | Acc: 63.312,95.855,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.659 | Acc: 63.284,95.863,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.661 | Acc: 63.208,95.928,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.658 | Acc: 63.316,95.913,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.659 | Acc: 63.301,95.899,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.659 | Acc: 63.300,95.926,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.476 | Acc: 58.594,73.438,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.853 | Acc: 55.618,69.754,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.886 | Acc: 54.973,68.883,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.884 | Acc: 54.713,68.750,73.988,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 1.886 | Acc: 57.812,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.690 | Acc: 61.942,95.610,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.688 | Acc: 62.767,95.770,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.675 | Acc: 62.884,95.697,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.677 | Acc: 62.780,95.679,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.675 | Acc: 62.809,95.653,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.673 | Acc: 62.907,95.681,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.672 | Acc: 62.910,95.667,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.669 | Acc: 63.073,95.735,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.665 | Acc: 63.147,95.822,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.666 | Acc: 63.227,95.806,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.668 | Acc: 63.179,95.804,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.670 | Acc: 63.307,95.789,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.667 | Acc: 63.407,95.782,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.667 | Acc: 63.456,95.780,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.665 | Acc: 63.494,95.816,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.665 | Acc: 63.576,95.826,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.662 | Acc: 63.616,95.885,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.662 | Acc: 63.593,95.899,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.661 | Acc: 63.640,95.903,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.462 | Acc: 60.156,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.844 | Acc: 55.543,69.643,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.878 | Acc: 55.069,68.807,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.882 | Acc: 54.790,68.699,74.155,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
main.py:184: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  confidence, idx = torch.topk(F.softmax(outputs[j][i]), k=1)
Batch: 0 | Loss: 1.823 | Acc: 57.031,93.750,100.000,% | Adaptive Acc: 94.531% | clf_exit: 0.414 0.484 0.102
Batch: 20 | Loss: 1.581 | Acc: 65.513,96.280,99.963,% | Adaptive Acc: 94.903% | clf_exit: 0.436 0.485 0.080
Batch: 40 | Loss: 1.604 | Acc: 64.405,96.246,99.981,% | Adaptive Acc: 94.436% | clf_exit: 0.432 0.490 0.078
Batch: 60 | Loss: 1.631 | Acc: 63.806,96.388,99.987,% | Adaptive Acc: 94.518% | clf_exit: 0.429 0.490 0.081
Batch: 80 | Loss: 1.651 | Acc: 63.638,96.229,99.990,% | Adaptive Acc: 94.396% | clf_exit: 0.427 0.489 0.084
Batch: 100 | Loss: 1.649 | Acc: 63.800,96.202,99.985,% | Adaptive Acc: 94.508% | clf_exit: 0.427 0.489 0.084
Batch: 120 | Loss: 1.649 | Acc: 63.927,96.184,99.987,% | Adaptive Acc: 94.680% | clf_exit: 0.426 0.489 0.084
Batch: 140 | Loss: 1.651 | Acc: 63.763,96.205,99.989,% | Adaptive Acc: 94.576% | clf_exit: 0.427 0.489 0.085
Batch: 160 | Loss: 1.654 | Acc: 63.655,96.176,99.990,% | Adaptive Acc: 94.628% | clf_exit: 0.425 0.491 0.084
Batch: 180 | Loss: 1.647 | Acc: 63.808,96.146,99.991,% | Adaptive Acc: 94.656% | clf_exit: 0.425 0.491 0.084
Batch: 200 | Loss: 1.642 | Acc: 63.888,96.164,99.984,% | Adaptive Acc: 94.667% | clf_exit: 0.426 0.491 0.083
Batch: 220 | Loss: 1.645 | Acc: 63.720,96.168,99.982,% | Adaptive Acc: 94.676% | clf_exit: 0.424 0.492 0.084
Batch: 240 | Loss: 1.647 | Acc: 63.712,96.188,99.984,% | Adaptive Acc: 94.732% | clf_exit: 0.424 0.492 0.084
Batch: 260 | Loss: 1.650 | Acc: 63.724,96.166,99.979,% | Adaptive Acc: 94.816% | clf_exit: 0.423 0.492 0.085
Batch: 280 | Loss: 1.650 | Acc: 63.782,96.138,99.981,% | Adaptive Acc: 94.818% | clf_exit: 0.423 0.492 0.085
Batch: 300 | Loss: 1.653 | Acc: 63.704,96.102,99.979,% | Adaptive Acc: 94.801% | clf_exit: 0.422 0.492 0.086
Batch: 320 | Loss: 1.652 | Acc: 63.773,96.121,99.981,% | Adaptive Acc: 94.809% | clf_exit: 0.422 0.492 0.086
Batch: 340 | Loss: 1.657 | Acc: 63.733,96.117,99.977,% | Adaptive Acc: 94.811% | clf_exit: 0.422 0.492 0.086
Batch: 360 | Loss: 1.659 | Acc: 63.669,96.085,99.976,% | Adaptive Acc: 94.823% | clf_exit: 0.421 0.493 0.087
Batch: 380 | Loss: 1.657 | Acc: 63.708,96.071,99.977,% | Adaptive Acc: 94.810% | clf_exit: 0.421 0.492 0.086
main.py:265: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  confidence, idx = torch.topk(F.softmax(outputs[j][i]), k=1)
Batch: 0 | Loss: 3.483 | Acc: 59.375,72.656,75.781,% | Adaptive Acc: 73.438% | clf_exit: 0.477 0.430 0.094
Batch: 20 | Loss: 3.856 | Acc: 55.580,69.643,75.112,% | Adaptive Acc: 69.643% | clf_exit: 0.467 0.366 0.167
Batch: 40 | Loss: 3.886 | Acc: 55.145,68.598,73.971,% | Adaptive Acc: 68.960% | clf_exit: 0.473 0.351 0.175
Batch: 60 | Loss: 3.886 | Acc: 54.752,68.571,73.899,% | Adaptive Acc: 68.916% | clf_exit: 0.476 0.346 0.178

