==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32x1x1])
      (FBconv): ConvTranspose2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(288, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=64, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=64, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x128x1x1])
      (FBconv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x128x1x1])
      (FBconv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x256x1x1])
      (FBconv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x256x1x1])
      (FBconv): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x512x1x1])
      (FBconv): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x512x1x1])
      (FBconv): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 13.906 | Acc: 0.000,0.781,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.520 | Acc: 2.381,3.237,3.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.302 | Acc: 3.220,3.906,4.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.131 | Acc: 3.778,4.803,5.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.971 | Acc: 4.070,5.449,6.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.855 | Acc: 4.293,6.018,7.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.739 | Acc: 4.655,6.547,7.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.644 | Acc: 4.920,6.976,8.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.556 | Acc: 5.163,7.376,8.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.469 | Acc: 5.335,7.933,9.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.384 | Acc: 5.508,8.306,9.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.314 | Acc: 5.642,8.675,10.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.245 | Acc: 5.897,9.080,10.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.168 | Acc: 6.139,9.462,11.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.099 | Acc: 6.328,9.898,11.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.037 | Acc: 6.572,10.174,11.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.974 | Acc: 6.737,10.521,12.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.905 | Acc: 6.965,10.954,12.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.841 | Acc: 7.150,11.256,13.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.777 | Acc: 7.324,11.618,13.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.688 | Acc: 7.031,14.844,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.653 | Acc: 9.970,17.076,19.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.604 | Acc: 10.252,17.492,20.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.604 | Acc: 10.515,17.585,19.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 11.260 | Acc: 6.250,9.375,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.555 | Acc: 11.272,16.853,21.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.486 | Acc: 11.414,17.645,21.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.388 | Acc: 11.783,18.058,22.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.344 | Acc: 11.526,18.605,22.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.290 | Acc: 11.595,18.912,23.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.237 | Acc: 11.835,19.441,23.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.186 | Acc: 11.990,19.891,24.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.140 | Acc: 12.180,20.002,24.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.107 | Acc: 12.371,20.360,24.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.074 | Acc: 12.531,20.561,25.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.044 | Acc: 12.641,20.740,25.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.014 | Acc: 12.714,20.886,25.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.976 | Acc: 12.850,21.025,25.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.931 | Acc: 13.017,21.313,26.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.889 | Acc: 13.227,21.644,26.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.858 | Acc: 13.291,21.800,26.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.821 | Acc: 13.412,22.022,27.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.784 | Acc: 13.515,22.215,27.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.745 | Acc: 13.654,22.435,27.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.970 | Acc: 17.969,22.656,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.246 | Acc: 14.174,24.368,31.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.254 | Acc: 14.196,24.219,31.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.279 | Acc: 13.832,23.630,30.917,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 9.686 | Acc: 12.500,20.312,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.979 | Acc: 17.374,26.972,34.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.856 | Acc: 17.912,27.934,35.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.841 | Acc: 17.700,27.792,35.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.787 | Acc: 17.708,28.144,35.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.760 | Acc: 17.713,28.241,36.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.728 | Acc: 17.710,28.596,36.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.705 | Acc: 17.803,28.768,36.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.678 | Acc: 18.032,29.105,37.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.671 | Acc: 18.077,29.036,36.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.658 | Acc: 17.973,29.038,36.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.636 | Acc: 18.181,29.224,37.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.596 | Acc: 18.329,29.551,37.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.570 | Acc: 18.394,29.768,37.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.546 | Acc: 18.453,29.946,37.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.527 | Acc: 18.493,30.017,38.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.498 | Acc: 18.597,30.174,38.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.468 | Acc: 18.734,30.354,38.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.451 | Acc: 18.811,30.475,38.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.424 | Acc: 18.935,30.678,38.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.962 | Acc: 16.406,34.375,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.241 | Acc: 17.634,30.060,40.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.254 | Acc: 17.702,30.335,39.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.273 | Acc: 17.802,29.969,39.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 7.980 | Acc: 21.094,32.812,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.039 | Acc: 19.754,31.808,42.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.906 | Acc: 20.522,32.927,43.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.785 | Acc: 21.196,34.157,44.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.739 | Acc: 21.113,34.558,45.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.759 | Acc: 21.078,34.537,44.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.747 | Acc: 21.249,34.911,44.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.725 | Acc: 21.338,35.101,45.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.694 | Acc: 21.584,35.477,45.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.665 | Acc: 21.702,35.843,45.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.655 | Acc: 21.751,35.918,45.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.635 | Acc: 21.882,36.019,45.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.625 | Acc: 22.092,36.138,45.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.615 | Acc: 22.126,36.174,45.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.603 | Acc: 22.175,36.266,46.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.580 | Acc: 22.254,36.488,46.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.555 | Acc: 22.423,36.719,46.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.531 | Acc: 22.546,36.966,46.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.511 | Acc: 22.697,37.154,46.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.495 | Acc: 22.736,37.285,46.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.221 | Acc: 27.344,36.719,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.321 | Acc: 23.400,37.277,48.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.308 | Acc: 23.628,37.729,48.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.324 | Acc: 23.450,37.077,48.258,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 7.385 | Acc: 14.062,29.688,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.084 | Acc: 23.735,40.141,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.048 | Acc: 24.638,40.625,52.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.023 | Acc: 24.565,40.945,52.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.995 | Acc: 24.759,41.551,52.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.975 | Acc: 25.015,41.592,52.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.925 | Acc: 25.536,42.084,52.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.909 | Acc: 25.565,42.204,52.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.891 | Acc: 25.543,42.299,52.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.881 | Acc: 25.626,42.395,52.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.873 | Acc: 25.777,42.467,52.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.859 | Acc: 25.831,42.583,52.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.868 | Acc: 25.710,42.463,52.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.855 | Acc: 25.835,42.544,52.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.848 | Acc: 25.865,42.657,53.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.835 | Acc: 25.934,42.759,53.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.823 | Acc: 26.003,42.803,53.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.820 | Acc: 26.072,42.840,53.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.809 | Acc: 26.115,42.945,53.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.801 | Acc: 26.148,43.012,53.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.771 | Acc: 26.562,44.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.865 | Acc: 24.702,42.299,52.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.872 | Acc: 24.505,41.978,51.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.855 | Acc: 24.411,42.021,51.831,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 6.690 | Acc: 21.875,46.094,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.303 | Acc: 29.055,47.284,58.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.336 | Acc: 28.716,46.837,58.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.295 | Acc: 28.445,47.182,58.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.296 | Acc: 28.540,47.405,58.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.300 | Acc: 28.527,47.169,58.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.301 | Acc: 28.609,47.282,58.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.297 | Acc: 28.668,47.279,57.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.292 | Acc: 28.625,47.321,58.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.299 | Acc: 28.604,47.328,57.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.308 | Acc: 28.502,47.233,57.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.309 | Acc: 28.560,47.306,57.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.295 | Acc: 28.683,47.374,57.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.297 | Acc: 28.601,47.387,57.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.299 | Acc: 28.478,47.248,57.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.298 | Acc: 28.706,47.205,57.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.289 | Acc: 28.858,47.272,57.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.279 | Acc: 28.897,47.322,57.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.277 | Acc: 28.930,47.338,57.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.280 | Acc: 28.970,47.287,57.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.526 | Acc: 30.469,45.312,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.581 | Acc: 26.079,43.713,55.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.578 | Acc: 26.486,43.540,54.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.572 | Acc: 26.588,43.494,54.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 5.477 | Acc: 40.625,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.991 | Acc: 30.097,50.149,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.941 | Acc: 30.145,50.438,61.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.880 | Acc: 30.686,50.499,61.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.869 | Acc: 30.845,50.550,61.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.888 | Acc: 30.917,50.673,61.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.882 | Acc: 31.011,50.833,60.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.883 | Acc: 30.995,50.765,60.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.884 | Acc: 31.090,50.835,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.871 | Acc: 31.013,50.846,61.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.862 | Acc: 31.141,50.828,61.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.877 | Acc: 30.950,50.647,61.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.881 | Acc: 30.942,50.626,60.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.875 | Acc: 31.052,50.653,60.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.873 | Acc: 30.997,50.676,60.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.869 | Acc: 31.076,50.758,60.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.868 | Acc: 31.089,50.764,60.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.868 | Acc: 31.101,50.701,60.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.865 | Acc: 31.120,50.762,60.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.867 | Acc: 31.158,50.757,60.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.757 | Acc: 39.062,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.047 | Acc: 31.250,49.442,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.016 | Acc: 31.250,49.505,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.011 | Acc: 31.135,49.488,58.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 5.185 | Acc: 35.156,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.450 | Acc: 32.329,55.729,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.470 | Acc: 32.508,54.459,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.527 | Acc: 32.531,53.356,65.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.561 | Acc: 32.552,53.164,64.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.583 | Acc: 32.604,52.916,64.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.562 | Acc: 32.935,52.860,64.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.567 | Acc: 33.067,52.754,64.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.571 | Acc: 33.070,52.800,64.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.560 | Acc: 33.059,52.732,64.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.563 | Acc: 33.112,52.787,64.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.550 | Acc: 33.201,52.913,64.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.544 | Acc: 33.205,53.008,64.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.533 | Acc: 33.297,53.125,64.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.529 | Acc: 33.380,53.086,64.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.529 | Acc: 33.467,53.221,64.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.527 | Acc: 33.404,53.198,64.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.514 | Acc: 33.477,53.251,64.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.507 | Acc: 33.529,53.348,64.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.503 | Acc: 33.528,53.453,64.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.830 | Acc: 33.594,57.031,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.920 | Acc: 30.990,51.116,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.914 | Acc: 31.402,50.267,59.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.939 | Acc: 31.186,50.000,59.695,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 5.051 | Acc: 30.469,50.781,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.211 | Acc: 34.821,55.655,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.167 | Acc: 35.099,56.098,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.165 | Acc: 35.118,56.416,67.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.179 | Acc: 34.944,56.472,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.197 | Acc: 34.994,56.157,67.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.212 | Acc: 34.808,55.746,67.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.210 | Acc: 34.962,55.906,67.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.221 | Acc: 34.899,56.003,67.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.202 | Acc: 35.027,56.198,67.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.195 | Acc: 35.273,56.188,67.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.208 | Acc: 35.241,56.070,67.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.204 | Acc: 35.348,56.114,67.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.205 | Acc: 35.378,56.079,66.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.214 | Acc: 35.215,56.044,66.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.221 | Acc: 35.289,56.019,66.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.225 | Acc: 35.229,56.046,66.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.227 | Acc: 35.216,56.076,66.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.227 | Acc: 35.206,56.003,66.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.229 | Acc: 35.183,56.024,66.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.583 | Acc: 32.031,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.798 | Acc: 31.808,51.265,61.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.787 | Acc: 32.298,50.934,60.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.783 | Acc: 32.198,51.345,61.104,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 4.606 | Acc: 41.406,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.048 | Acc: 35.082,56.882,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.951 | Acc: 36.052,57.851,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.943 | Acc: 36.437,57.953,69.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.935 | Acc: 36.854,58.304,69.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.949 | Acc: 36.502,58.253,69.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.933 | Acc: 36.867,58.497,69.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.937 | Acc: 36.907,58.500,69.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.951 | Acc: 36.913,58.337,69.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.945 | Acc: 36.827,58.365,69.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.945 | Acc: 36.878,58.252,69.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.955 | Acc: 36.747,58.053,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.965 | Acc: 36.777,57.981,69.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.976 | Acc: 36.853,57.932,69.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.976 | Acc: 36.888,57.952,69.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.975 | Acc: 36.919,57.841,69.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.977 | Acc: 36.945,57.825,69.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.974 | Acc: 37.049,57.874,69.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.969 | Acc: 37.145,57.888,69.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.966 | Acc: 37.137,57.960,69.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.715 | Acc: 30.469,54.688,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.695 | Acc: 31.362,53.832,62.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.751 | Acc: 30.831,52.287,61.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.757 | Acc: 30.981,52.357,61.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 4.896 | Acc: 33.594,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.688 | Acc: 38.393,60.900,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.752 | Acc: 37.824,59.794,72.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.761 | Acc: 37.935,59.375,72.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.732 | Acc: 38.175,59.491,72.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.724 | Acc: 38.188,59.669,72.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.708 | Acc: 38.675,59.956,72.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.710 | Acc: 38.664,59.852,72.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.728 | Acc: 38.592,59.656,71.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.724 | Acc: 38.674,59.755,71.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.717 | Acc: 38.767,59.810,71.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.724 | Acc: 38.794,59.714,71.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.729 | Acc: 38.722,59.654,71.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.746 | Acc: 38.554,59.570,71.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.745 | Acc: 38.582,59.528,71.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.751 | Acc: 38.554,59.497,71.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.756 | Acc: 38.534,59.487,71.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.750 | Acc: 38.707,59.583,71.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.756 | Acc: 38.634,59.511,71.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.759 | Acc: 38.597,59.465,71.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.564 | Acc: 31.250,56.250,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.488 | Acc: 33.705,54.650,62.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.499 | Acc: 34.165,53.754,62.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.521 | Acc: 33.927,53.868,62.205,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 5.300 | Acc: 28.906,49.219,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 39.025,62.240,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.525 | Acc: 39.577,61.566,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.500 | Acc: 39.408,61.680,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.464 | Acc: 39.805,61.998,74.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.500 | Acc: 39.581,61.850,73.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.511 | Acc: 39.773,61.454,73.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.509 | Acc: 40.054,61.508,73.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.517 | Acc: 40.130,61.500,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.505 | Acc: 40.111,61.589,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.507 | Acc: 40.330,61.567,73.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.510 | Acc: 40.254,61.627,73.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.518 | Acc: 40.178,61.472,73.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.527 | Acc: 40.200,61.515,73.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.521 | Acc: 40.322,61.602,73.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.525 | Acc: 40.360,61.516,73.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.530 | Acc: 40.267,61.432,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.531 | Acc: 40.323,61.442,73.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.537 | Acc: 40.244,61.424,73.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.541 | Acc: 40.190,61.352,73.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.083 | Acc: 40.625,57.812,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.502 | Acc: 34.598,55.841,64.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.473 | Acc: 35.080,55.316,64.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.464 | Acc: 34.593,55.648,64.267,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 3.725 | Acc: 46.875,65.625,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.403 | Acc: 40.327,62.426,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.354 | Acc: 41.502,62.652,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.445 | Acc: 40.330,62.282,74.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.416 | Acc: 40.548,62.500,74.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.386 | Acc: 40.787,62.809,75.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.376 | Acc: 40.851,62.946,75.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.368 | Acc: 40.830,62.982,75.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.380 | Acc: 40.737,62.845,74.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.389 | Acc: 40.677,62.552,74.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.386 | Acc: 40.773,62.516,74.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.384 | Acc: 40.982,62.638,74.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.388 | Acc: 41.085,62.659,74.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.387 | Acc: 41.101,62.575,74.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.387 | Acc: 41.036,62.631,74.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.388 | Acc: 41.087,62.573,74.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.382 | Acc: 41.151,62.563,74.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.385 | Acc: 41.179,62.573,74.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.389 | Acc: 41.192,62.554,74.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.394 | Acc: 41.168,62.539,74.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.300 | Acc: 36.719,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.554 | Acc: 35.007,54.762,62.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.538 | Acc: 35.004,54.688,63.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.560 | Acc: 34.823,54.956,62.910,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 4.335 | Acc: 44.531,63.281,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.237 | Acc: 40.588,63.504,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.204 | Acc: 41.673,63.681,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.174 | Acc: 41.906,64.408,77.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.199 | Acc: 41.705,64.516,77.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.165 | Acc: 42.048,64.774,77.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.158 | Acc: 42.323,64.786,77.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.155 | Acc: 42.304,64.750,77.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.184 | Acc: 42.241,64.436,76.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.185 | Acc: 42.291,64.339,76.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.194 | Acc: 42.285,64.257,76.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.208 | Acc: 42.230,64.232,76.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.216 | Acc: 42.252,64.199,76.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.210 | Acc: 42.409,64.203,76.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.215 | Acc: 42.343,64.188,76.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.218 | Acc: 42.330,64.075,76.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.222 | Acc: 42.338,64.050,76.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.232 | Acc: 42.297,63.991,75.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.235 | Acc: 42.307,64.013,75.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.232 | Acc: 42.321,64.042,75.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.709 | Acc: 39.062,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.151 | Acc: 37.984,58.371,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.161 | Acc: 37.500,57.107,65.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.162 | Acc: 37.654,57.018,65.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 4.182 | Acc: 37.500,60.938,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.055 | Acc: 42.262,65.402,78.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.098 | Acc: 42.035,64.653,78.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.058 | Acc: 42.815,65.228,78.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.046 | Acc: 42.814,65.384,78.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.044 | Acc: 42.976,65.261,78.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.029 | Acc: 43.175,65.489,78.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.041 | Acc: 43.395,65.437,78.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.041 | Acc: 43.459,65.407,77.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.039 | Acc: 43.487,65.323,77.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.046 | Acc: 43.497,65.283,77.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.054 | Acc: 43.587,65.261,77.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.057 | Acc: 43.539,65.291,77.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.062 | Acc: 43.514,65.197,77.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.070 | Acc: 43.514,65.122,77.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.081 | Acc: 43.537,65.116,77.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.077 | Acc: 43.675,65.177,77.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.077 | Acc: 43.684,65.119,77.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.076 | Acc: 43.731,65.073,77.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.091 | Acc: 43.643,64.926,77.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.076 | Acc: 38.281,53.125,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.083 | Acc: 38.281,56.548,65.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.099 | Acc: 39.158,56.402,64.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.101 | Acc: 39.639,56.455,64.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 3.917 | Acc: 48.438,66.406,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.924 | Acc: 44.420,67.522,80.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.924 | Acc: 45.408,67.702,80.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.935 | Acc: 45.210,67.277,80.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.906 | Acc: 44.830,67.120,80.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.908 | Acc: 44.524,67.157,80.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.923 | Acc: 44.473,66.858,79.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.918 | Acc: 44.570,66.872,79.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.915 | Acc: 44.667,66.809,79.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.919 | Acc: 44.708,66.752,79.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.918 | Acc: 44.714,66.647,79.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.915 | Acc: 44.782,66.640,79.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.917 | Acc: 44.946,66.685,79.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.922 | Acc: 44.872,66.622,78.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.935 | Acc: 44.809,66.462,78.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.947 | Acc: 44.703,66.279,78.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.950 | Acc: 44.728,66.233,78.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.950 | Acc: 44.644,66.166,78.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.959 | Acc: 44.572,66.047,78.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.959 | Acc: 44.576,66.052,78.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.835 | Acc: 46.094,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.880 | Acc: 40.104,59.338,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.941 | Acc: 39.863,58.441,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.941 | Acc: 40.036,58.466,66.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 3.654 | Acc: 50.781,71.875,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.665 | Acc: 47.135,68.973,81.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.749 | Acc: 45.960,67.778,81.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.762 | Acc: 45.415,67.764,81.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.789 | Acc: 44.965,67.612,81.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.803 | Acc: 45.065,67.481,80.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.799 | Acc: 45.345,67.472,80.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.802 | Acc: 45.562,67.420,80.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.794 | Acc: 45.725,67.600,80.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.797 | Acc: 45.662,67.606,80.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.802 | Acc: 45.682,67.596,80.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.809 | Acc: 45.560,67.569,80.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.825 | Acc: 45.510,67.382,80.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.834 | Acc: 45.486,67.286,80.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.839 | Acc: 45.329,67.235,80.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.847 | Acc: 45.263,67.091,80.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.853 | Acc: 45.232,67.022,79.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.857 | Acc: 45.264,66.947,79.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.864 | Acc: 45.243,66.913,79.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.865 | Acc: 45.288,66.905,79.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.854 | Acc: 38.281,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.128 | Acc: 36.124,58.445,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.113 | Acc: 36.452,58.098,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.106 | Acc: 36.629,58.248,66.522,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 4.228 | Acc: 39.844,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.653 | Acc: 46.801,69.085,81.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.652 | Acc: 47.180,68.826,81.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.655 | Acc: 47.349,68.609,81.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.656 | Acc: 47.097,68.692,81.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.659 | Acc: 46.960,68.858,81.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.677 | Acc: 46.746,68.821,81.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.690 | Acc: 46.842,68.589,81.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.688 | Acc: 46.705,68.439,81.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.701 | Acc: 46.659,68.193,81.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.701 | Acc: 46.669,68.260,81.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.716 | Acc: 46.645,67.993,81.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.716 | Acc: 46.638,68.014,81.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.726 | Acc: 46.561,67.969,80.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.736 | Acc: 46.419,67.841,80.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.741 | Acc: 46.405,67.834,80.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.738 | Acc: 46.466,67.835,80.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.742 | Acc: 46.378,67.788,80.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.743 | Acc: 46.392,67.787,80.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.752 | Acc: 46.254,67.678,80.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.815 | Acc: 41.406,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.707 | Acc: 41.927,59.524,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.745 | Acc: 41.749,58.918,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.764 | Acc: 41.739,58.991,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 3.678 | Acc: 49.219,67.969,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.513 | Acc: 48.661,69.866,83.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.532 | Acc: 47.866,69.817,83.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.513 | Acc: 47.823,70.146,83.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.514 | Acc: 47.666,70.129,83.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.509 | Acc: 47.966,69.980,83.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.514 | Acc: 47.721,69.977,83.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.519 | Acc: 47.584,69.941,83.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.540 | Acc: 47.273,69.609,83.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.560 | Acc: 47.091,69.264,83.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.569 | Acc: 47.081,69.213,82.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.573 | Acc: 47.278,69.259,82.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.580 | Acc: 47.306,69.165,82.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.582 | Acc: 47.297,69.088,82.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.601 | Acc: 47.178,68.853,82.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.617 | Acc: 47.155,68.708,82.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.624 | Acc: 47.145,68.638,81.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.631 | Acc: 47.152,68.619,81.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.637 | Acc: 47.063,68.605,81.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.645 | Acc: 47.004,68.553,81.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.295 | Acc: 48.438,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.858 | Acc: 41.629,60.565,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.879 | Acc: 41.006,59.889,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.879 | Acc: 41.253,59.721,68.481,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 3.488 | Acc: 46.875,68.750,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.593 | Acc: 45.350,69.531,84.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.462 | Acc: 47.504,70.789,84.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.486 | Acc: 47.733,70.479,84.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.509 | Acc: 47.637,70.322,83.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.487 | Acc: 47.726,70.777,83.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.486 | Acc: 47.921,70.784,83.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.480 | Acc: 48.077,70.717,83.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.488 | Acc: 47.967,70.492,83.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.487 | Acc: 48.045,70.425,83.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.498 | Acc: 47.963,70.293,83.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.507 | Acc: 47.808,70.115,83.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.515 | Acc: 47.760,70.001,83.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.523 | Acc: 47.794,69.843,83.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.532 | Acc: 47.692,69.762,82.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.548 | Acc: 47.537,69.627,82.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.549 | Acc: 47.629,69.711,82.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.556 | Acc: 47.622,69.639,82.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.563 | Acc: 47.635,69.527,82.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.568 | Acc: 47.656,69.459,82.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.372 | Acc: 44.531,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.710 | Acc: 41.927,60.677,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.778 | Acc: 41.578,60.271,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.779 | Acc: 41.304,60.553,68.289,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 3.575 | Acc: 44.531,60.938,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.516 | Acc: 46.763,69.234,83.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.497 | Acc: 47.142,70.198,84.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.470 | Acc: 47.413,70.236,84.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.473 | Acc: 47.483,70.399,84.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.478 | Acc: 47.432,70.413,84.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.475 | Acc: 47.404,70.474,84.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.474 | Acc: 47.390,70.534,83.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.480 | Acc: 47.554,70.419,83.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.474 | Acc: 47.738,70.261,83.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.472 | Acc: 47.792,70.258,83.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.474 | Acc: 47.921,70.238,83.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.471 | Acc: 47.942,70.235,83.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.476 | Acc: 48.048,70.208,83.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.482 | Acc: 48.079,70.246,83.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.486 | Acc: 48.178,70.203,83.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.488 | Acc: 48.160,70.169,83.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.496 | Acc: 48.098,70.134,83.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.497 | Acc: 48.139,70.113,83.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.496 | Acc: 48.253,70.116,83.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.597 | Acc: 44.531,57.812,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.861 | Acc: 41.071,59.301,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.838 | Acc: 41.311,58.937,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.853 | Acc: 41.855,59.209,66.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 3.123 | Acc: 53.125,75.000,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.269 | Acc: 50.521,71.726,85.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.270 | Acc: 50.476,72.237,85.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.275 | Acc: 50.487,72.131,85.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.280 | Acc: 50.048,72.155,85.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.266 | Acc: 49.977,72.030,85.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.287 | Acc: 49.819,71.998,85.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.304 | Acc: 49.640,71.847,85.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.317 | Acc: 49.612,71.594,85.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.326 | Acc: 49.629,71.499,85.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.339 | Acc: 49.409,71.358,85.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.337 | Acc: 49.410,71.447,85.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.339 | Acc: 49.420,71.424,84.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.350 | Acc: 49.258,71.375,84.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.359 | Acc: 49.277,71.236,84.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.368 | Acc: 49.190,71.146,84.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.378 | Acc: 49.114,71.089,84.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.381 | Acc: 49.148,71.073,84.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.387 | Acc: 49.087,71.029,84.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.400 | Acc: 48.930,70.944,84.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.523 | Acc: 42.969,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.456 | Acc: 44.717,62.984,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.493 | Acc: 44.322,62.462,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.484 | Acc: 44.493,62.705,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 3.118 | Acc: 50.000,77.344,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.190 | Acc: 50.744,74.144,86.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.159 | Acc: 50.324,73.571,87.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.198 | Acc: 49.872,73.169,86.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.239 | Acc: 49.585,72.656,86.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.239 | Acc: 49.582,72.540,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.268 | Acc: 49.361,72.140,86.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.266 | Acc: 49.507,72.174,86.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.261 | Acc: 49.554,72.215,86.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.261 | Acc: 49.564,72.078,86.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.278 | Acc: 49.452,71.852,86.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.296 | Acc: 49.300,71.702,85.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.302 | Acc: 49.293,71.736,85.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.306 | Acc: 49.377,71.734,85.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.307 | Acc: 49.447,71.647,85.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.304 | Acc: 49.564,71.758,85.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.308 | Acc: 49.496,71.688,85.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.313 | Acc: 49.494,71.655,85.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.316 | Acc: 49.569,71.604,85.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.326 | Acc: 49.543,71.438,84.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.676 | Acc: 44.531,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.851 | Acc: 42.225,60.603,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.884 | Acc: 41.864,60.023,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.893 | Acc: 41.829,60.028,67.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 3.229 | Acc: 48.438,69.531,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.185 | Acc: 50.112,73.177,86.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.158 | Acc: 51.220,73.514,87.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.130 | Acc: 51.614,73.745,87.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.131 | Acc: 51.717,73.746,87.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.126 | Acc: 51.787,73.847,87.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.145 | Acc: 51.265,73.496,87.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.170 | Acc: 51.025,73.160,86.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.171 | Acc: 50.941,73.151,86.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.194 | Acc: 50.669,72.859,86.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.199 | Acc: 50.548,72.862,86.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.195 | Acc: 50.594,72.858,86.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.209 | Acc: 50.386,72.705,86.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.223 | Acc: 50.168,72.516,86.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.222 | Acc: 50.275,72.451,86.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.224 | Acc: 50.273,72.456,86.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.230 | Acc: 50.290,72.323,86.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.237 | Acc: 50.213,72.230,85.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.248 | Acc: 50.175,72.098,85.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.256 | Acc: 50.103,71.973,85.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.903 | Acc: 49.219,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.437 | Acc: 45.201,63.728,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.471 | Acc: 44.855,63.091,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.493 | Acc: 44.339,62.871,68.596,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 3.013 | Acc: 55.469,78.906,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.018 | Acc: 52.716,74.628,88.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.048 | Acc: 52.191,74.409,87.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.062 | Acc: 51.652,74.257,88.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.078 | Acc: 51.215,74.045,87.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.101 | Acc: 51.114,73.739,87.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.108 | Acc: 51.014,73.528,87.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.108 | Acc: 51.180,73.327,87.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.117 | Acc: 50.937,73.229,87.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.122 | Acc: 50.859,73.144,87.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.126 | Acc: 50.921,73.014,87.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.134 | Acc: 50.880,72.992,87.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.137 | Acc: 50.879,73.039,87.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.155 | Acc: 50.778,72.905,86.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.164 | Acc: 50.634,72.754,86.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.166 | Acc: 50.727,72.729,86.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.174 | Acc: 50.759,72.610,86.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.182 | Acc: 50.653,72.558,86.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.188 | Acc: 50.580,72.472,86.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.191 | Acc: 50.509,72.461,86.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.153 | Acc: 51.562,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.435 | Acc: 46.652,62.723,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.461 | Acc: 46.341,62.767,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.484 | Acc: 46.171,62.590,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 3.184 | Acc: 51.562,77.344,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.157 | Acc: 48.586,72.917,87.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.058 | Acc: 50.514,74.238,87.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.056 | Acc: 51.268,74.347,87.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.039 | Acc: 51.312,74.547,87.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.066 | Acc: 51.392,74.157,87.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.085 | Acc: 51.375,73.806,87.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.070 | Acc: 51.684,73.892,87.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.083 | Acc: 51.689,73.670,87.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.098 | Acc: 51.511,73.438,87.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.111 | Acc: 51.380,73.298,87.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.116 | Acc: 51.361,73.293,87.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.121 | Acc: 51.222,73.214,87.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.123 | Acc: 51.212,73.183,87.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.128 | Acc: 51.034,73.212,87.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.126 | Acc: 51.056,73.269,86.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.131 | Acc: 51.029,73.153,86.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.126 | Acc: 51.086,73.206,86.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.132 | Acc: 51.080,73.195,86.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.140 | Acc: 50.976,73.155,86.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.705 | Acc: 42.188,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.642 | Acc: 44.234,61.682,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.670 | Acc: 44.036,60.728,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.688 | Acc: 43.865,60.886,67.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 2.917 | Acc: 50.781,79.688,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.007 | Acc: 50.781,74.814,88.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.039 | Acc: 51.181,74.524,87.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.024 | Acc: 51.447,74.923,88.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.047 | Acc: 51.196,74.556,88.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.037 | Acc: 51.555,74.606,88.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.020 | Acc: 51.453,74.858,88.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.001 | Acc: 51.679,74.934,88.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.002 | Acc: 51.650,74.796,88.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.997 | Acc: 51.657,74.814,88.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.008 | Acc: 51.671,74.697,88.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.019 | Acc: 51.654,74.487,88.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.018 | Acc: 51.640,74.559,88.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.028 | Acc: 51.607,74.491,88.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.048 | Acc: 51.437,74.269,87.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.055 | Acc: 51.524,74.123,87.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.066 | Acc: 51.416,73.983,87.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.080 | Acc: 51.299,73.809,87.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.087 | Acc: 51.279,73.708,87.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.095 | Acc: 51.294,73.575,87.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.386 | Acc: 42.969,69.531,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 44.717,64.211,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.491 | Acc: 44.017,63.529,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.522 | Acc: 44.160,63.448,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 2.863 | Acc: 49.219,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.970 | Acc: 51.749,74.740,89.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.975 | Acc: 51.296,74.848,88.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.956 | Acc: 51.447,74.859,89.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.973 | Acc: 51.331,74.585,89.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.980 | Acc: 51.300,74.675,89.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.974 | Acc: 51.750,74.638,89.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.965 | Acc: 51.928,74.823,89.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.979 | Acc: 51.786,74.811,88.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.994 | Acc: 51.722,74.624,88.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.997 | Acc: 51.699,74.541,88.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.004 | Acc: 51.722,74.505,88.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.003 | Acc: 51.757,74.575,88.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.006 | Acc: 51.757,74.548,88.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.005 | Acc: 51.977,74.538,88.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.008 | Acc: 52.027,74.468,88.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.011 | Acc: 51.959,74.450,88.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.007 | Acc: 52.034,74.416,88.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.015 | Acc: 51.974,74.394,88.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.027 | Acc: 51.889,74.208,87.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.095 | Acc: 47.656,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.601 | Acc: 45.610,62.649,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.633 | Acc: 44.836,62.100,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.662 | Acc: 44.403,61.706,67.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 3.127 | Acc: 46.875,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.891 | Acc: 52.827,75.298,88.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.920 | Acc: 51.791,75.343,89.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.922 | Acc: 51.562,75.461,89.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.913 | Acc: 52.045,75.588,89.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.908 | Acc: 51.911,75.743,89.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.917 | Acc: 51.898,75.575,89.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.907 | Acc: 52.178,75.549,89.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.899 | Acc: 52.412,75.684,89.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.905 | Acc: 52.292,75.652,89.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.909 | Acc: 52.449,75.459,89.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.918 | Acc: 52.492,75.354,89.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.932 | Acc: 52.308,75.175,89.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.940 | Acc: 52.332,75.021,88.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.944 | Acc: 52.299,74.953,88.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.950 | Acc: 52.245,74.948,88.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.946 | Acc: 52.368,75.027,88.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.959 | Acc: 52.378,74.883,88.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.965 | Acc: 52.331,74.823,88.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.978 | Acc: 52.266,74.660,88.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.173 | Acc: 48.438,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.421 | Acc: 47.470,63.021,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.467 | Acc: 47.675,62.538,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.476 | Acc: 47.720,62.615,68.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 2.733 | Acc: 55.469,83.594,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.863 | Acc: 52.641,76.562,89.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.877 | Acc: 52.801,75.915,89.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.869 | Acc: 52.869,76.127,90.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.884 | Acc: 52.845,75.984,89.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.909 | Acc: 52.676,75.340,89.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.899 | Acc: 52.776,75.362,89.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.898 | Acc: 52.898,75.416,89.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.894 | Acc: 53.043,75.514,89.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.894 | Acc: 53.039,75.574,89.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.902 | Acc: 52.938,75.439,89.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.906 | Acc: 52.902,75.421,89.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.903 | Acc: 52.976,75.399,89.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.907 | Acc: 52.993,75.326,89.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.909 | Acc: 53.058,75.323,89.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.917 | Acc: 53.058,75.161,89.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.925 | Acc: 53.020,75.075,88.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.932 | Acc: 52.960,75.034,88.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.938 | Acc: 52.930,74.989,88.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.948 | Acc: 52.865,74.916,88.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.288 | Acc: 46.875,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.476 | Acc: 47.619,63.616,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.525 | Acc: 46.589,63.072,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 46.363,62.859,67.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 2.998 | Acc: 54.688,71.094,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.828 | Acc: 53.162,76.079,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.812 | Acc: 53.659,75.800,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.841 | Acc: 53.202,75.717,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.827 | Acc: 53.395,75.829,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.831 | Acc: 53.202,75.920,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 53.222,75.820,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.838 | Acc: 53.352,75.776,90.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.849 | Acc: 53.149,75.810,90.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.858 | Acc: 53.108,75.816,90.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.862 | Acc: 52.938,75.773,90.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.867 | Acc: 52.991,75.703,89.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.878 | Acc: 52.918,75.587,89.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.886 | Acc: 52.868,75.464,89.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.888 | Acc: 52.914,75.414,89.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.893 | Acc: 53.019,75.343,89.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.900 | Acc: 52.996,75.253,89.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.907 | Acc: 53.017,75.154,89.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.913 | Acc: 52.989,75.071,89.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.914 | Acc: 53.041,75.096,89.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.098 | Acc: 52.344,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.396 | Acc: 48.586,63.318,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.435 | Acc: 48.190,62.691,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.431 | Acc: 48.130,62.641,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 2.528 | Acc: 55.469,81.250,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.824 | Acc: 52.381,77.009,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.801 | Acc: 52.706,76.524,91.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.780 | Acc: 52.843,76.767,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.788 | Acc: 52.980,76.620,91.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.798 | Acc: 53.156,76.609,91.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.798 | Acc: 53.293,76.666,91.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.816 | Acc: 53.424,76.346,90.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.825 | Acc: 53.397,76.179,90.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.825 | Acc: 53.526,76.101,90.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.821 | Acc: 53.692,76.201,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.842 | Acc: 53.471,75.976,90.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.852 | Acc: 53.433,75.823,90.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.853 | Acc: 53.463,75.796,89.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.862 | Acc: 53.459,75.695,89.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.862 | Acc: 53.418,75.662,89.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.865 | Acc: 53.354,75.601,89.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.865 | Acc: 53.398,75.570,89.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.867 | Acc: 53.471,75.541,89.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.874 | Acc: 53.455,75.433,89.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.300 | Acc: 45.312,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.517 | Acc: 47.470,61.161,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.522 | Acc: 46.932,61.604,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.506 | Acc: 46.606,61.629,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 2.795 | Acc: 60.938,76.562,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.802 | Acc: 53.869,77.121,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.743 | Acc: 54.173,77.001,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.742 | Acc: 54.150,76.921,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.718 | Acc: 54.311,77.267,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.734 | Acc: 54.038,76.957,91.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.759 | Acc: 53.571,76.937,91.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.761 | Acc: 53.507,76.840,91.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.766 | Acc: 53.562,76.718,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.775 | Acc: 53.466,76.649,90.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.800 | Acc: 53.343,76.376,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.804 | Acc: 53.440,76.343,90.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.801 | Acc: 53.504,76.355,90.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.815 | Acc: 53.317,76.161,90.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.813 | Acc: 53.331,76.140,90.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.814 | Acc: 53.496,76.158,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.820 | Acc: 53.493,76.117,90.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.827 | Acc: 53.457,76.015,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.836 | Acc: 53.447,75.920,89.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.840 | Acc: 53.488,75.871,89.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.598 | Acc: 46.875,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 45.833,63.579,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 45.179,62.691,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.521 | Acc: 45.812,62.718,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 2.471 | Acc: 57.031,80.469,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.716 | Acc: 54.650,77.716,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.738 | Acc: 54.230,77.458,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.736 | Acc: 54.214,77.318,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.708 | Acc: 54.504,77.604,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.704 | Acc: 54.649,77.491,91.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.710 | Acc: 54.662,77.176,91.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.713 | Acc: 54.710,77.161,91.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.714 | Acc: 54.843,76.980,91.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.715 | Acc: 54.696,77.063,91.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.724 | Acc: 54.672,76.928,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.737 | Acc: 54.585,76.803,90.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.747 | Acc: 54.480,76.806,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.757 | Acc: 54.469,76.673,90.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.766 | Acc: 54.382,76.601,90.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.778 | Acc: 54.389,76.542,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.786 | Acc: 54.281,76.339,90.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.790 | Acc: 54.250,76.304,90.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.796 | Acc: 54.175,76.283,90.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.803 | Acc: 54.076,76.216,90.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.297 | Acc: 50.781,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.347 | Acc: 50.112,63.318,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.400 | Acc: 48.800,62.843,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.378 | Acc: 48.668,63.217,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 2.557 | Acc: 55.469,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.688 | Acc: 54.613,77.121,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.716 | Acc: 54.211,77.458,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.688 | Acc: 54.688,77.792,91.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.696 | Acc: 54.755,77.797,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.690 | Acc: 54.664,77.808,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.694 | Acc: 54.939,77.686,91.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.695 | Acc: 54.843,77.499,91.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.696 | Acc: 54.620,77.421,91.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.695 | Acc: 54.476,77.404,91.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.691 | Acc: 54.540,77.484,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.701 | Acc: 54.546,77.372,91.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.705 | Acc: 54.688,77.373,91.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.710 | Acc: 54.598,77.272,91.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.724 | Acc: 54.593,77.144,90.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.727 | Acc: 54.584,77.053,90.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.731 | Acc: 54.614,77.005,90.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.736 | Acc: 54.612,76.941,90.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.742 | Acc: 54.568,76.861,90.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.748 | Acc: 54.550,76.747,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.696 | Acc: 46.094,62.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.681 | Acc: 44.457,61.607,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.749 | Acc: 44.703,61.623,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.756 | Acc: 44.429,61.283,68.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 2.694 | Acc: 56.250,78.125,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.640 | Acc: 55.060,77.232,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.681 | Acc: 54.173,77.115,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.677 | Acc: 54.521,77.216,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.669 | Acc: 54.736,77.382,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.661 | Acc: 54.834,77.576,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.665 | Acc: 54.810,77.667,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.659 | Acc: 55.092,77.837,91.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.664 | Acc: 55.115,77.727,91.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.668 | Acc: 55.024,77.585,91.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.675 | Acc: 54.975,77.526,91.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.681 | Acc: 54.921,77.510,91.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.688 | Acc: 54.798,77.451,91.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.698 | Acc: 54.714,77.266,91.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.705 | Acc: 54.621,77.149,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.716 | Acc: 54.591,77.012,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.722 | Acc: 54.624,76.971,90.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.727 | Acc: 54.536,76.911,90.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.732 | Acc: 54.517,76.909,90.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.738 | Acc: 54.564,76.878,90.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.141 | Acc: 45.312,68.750,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 46.391,63.542,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 46.303,62.824,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.598 | Acc: 46.171,62.436,69.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 2.624 | Acc: 59.375,78.906,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.592 | Acc: 57.552,78.869,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.618 | Acc: 56.098,78.030,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.607 | Acc: 56.340,78.138,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.612 | Acc: 56.038,78.221,92.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.616 | Acc: 56.018,78.102,91.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.630 | Acc: 55.424,78.093,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.636 | Acc: 55.186,77.892,91.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.659 | Acc: 54.877,77.649,91.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.673 | Acc: 54.834,77.521,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.676 | Acc: 54.901,77.581,91.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.676 | Acc: 55.006,77.559,91.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.669 | Acc: 55.151,77.642,91.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.677 | Acc: 55.110,77.559,91.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.688 | Acc: 54.938,77.511,91.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.696 | Acc: 54.784,77.357,90.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.699 | Acc: 54.838,77.207,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.703 | Acc: 54.788,77.202,90.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.709 | Acc: 54.798,77.134,90.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.711 | Acc: 54.782,77.100,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.014 | Acc: 46.875,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.335 | Acc: 48.958,65.327,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.352 | Acc: 48.647,64.672,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.366 | Acc: 48.963,64.421,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 2.555 | Acc: 55.469,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 54.650,78.311,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.605 | Acc: 55.926,78.639,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.575 | Acc: 56.199,79.073,92.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.563 | Acc: 56.539,79.022,92.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.570 | Acc: 56.281,78.697,92.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.574 | Acc: 56.295,78.396,92.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.592 | Acc: 56.034,78.164,92.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.602 | Acc: 55.988,78.198,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.611 | Acc: 55.849,78.116,92.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.618 | Acc: 55.830,78.078,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.624 | Acc: 55.713,78.100,91.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.631 | Acc: 55.663,77.999,91.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.637 | Acc: 55.660,77.903,91.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.645 | Acc: 55.594,77.811,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.658 | Acc: 55.456,77.692,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.665 | Acc: 55.306,77.626,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.673 | Acc: 55.214,77.557,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.683 | Acc: 55.114,77.400,91.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.686 | Acc: 55.067,77.383,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.051 | Acc: 47.656,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.428 | Acc: 47.991,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.443 | Acc: 47.790,64.158,69.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.446 | Acc: 47.464,63.947,69.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 2.533 | Acc: 55.469,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.535 | Acc: 57.887,79.464,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.555 | Acc: 56.574,78.659,92.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.550 | Acc: 56.301,78.740,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.562 | Acc: 56.211,78.356,92.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.579 | Acc: 55.817,78.241,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.593 | Acc: 55.811,78.022,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.598 | Acc: 55.685,78.097,92.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.596 | Acc: 55.755,78.130,91.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.604 | Acc: 55.650,78.121,91.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.612 | Acc: 55.628,77.907,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.621 | Acc: 55.462,77.754,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.631 | Acc: 55.397,77.697,91.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.637 | Acc: 55.433,77.697,91.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.646 | Acc: 55.371,77.547,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.652 | Acc: 55.393,77.554,91.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.660 | Acc: 55.306,77.473,91.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.666 | Acc: 55.265,77.449,91.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.672 | Acc: 55.259,77.376,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.675 | Acc: 55.290,77.290,90.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.410 | Acc: 46.094,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 47.917,62.463,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 47.942,62.481,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 48.079,62.244,69.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 2.582 | Acc: 59.375,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.559 | Acc: 55.952,78.646,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.569 | Acc: 55.774,78.449,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.551 | Acc: 55.955,78.291,92.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.562 | Acc: 55.835,78.318,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.585 | Acc: 55.507,78.326,92.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.576 | Acc: 55.475,78.538,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.574 | Acc: 55.796,78.596,92.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.577 | Acc: 55.794,78.625,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.590 | Acc: 55.568,78.488,91.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.594 | Acc: 55.566,78.533,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.614 | Acc: 55.363,78.362,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.626 | Acc: 55.274,78.235,91.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.623 | Acc: 55.337,78.212,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.622 | Acc: 55.433,78.139,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.628 | Acc: 55.435,78.019,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.634 | Acc: 55.369,77.901,91.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.640 | Acc: 55.379,77.781,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.645 | Acc: 55.417,77.798,91.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.647 | Acc: 55.481,77.799,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.183 | Acc: 49.219,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.595 | Acc: 49.405,62.351,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 48.418,61.700,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.595 | Acc: 48.758,61.296,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 3.033 | Acc: 53.906,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.603 | Acc: 55.766,79.688,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.567 | Acc: 55.678,79.554,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.525 | Acc: 56.609,79.777,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.531 | Acc: 56.684,79.389,92.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.535 | Acc: 56.544,79.177,92.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.532 | Acc: 56.592,79.287,92.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.535 | Acc: 56.787,79.261,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.545 | Acc: 56.706,79.217,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.545 | Acc: 56.617,79.165,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.565 | Acc: 56.425,78.825,92.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.569 | Acc: 56.370,78.705,92.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.578 | Acc: 56.406,78.517,92.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.580 | Acc: 56.391,78.475,91.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.589 | Acc: 56.308,78.384,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.590 | Acc: 56.299,78.395,91.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.602 | Acc: 56.133,78.230,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.605 | Acc: 56.051,78.201,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.610 | Acc: 55.949,78.101,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.616 | Acc: 55.940,78.053,91.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.137 | Acc: 51.562,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.441 | Acc: 49.554,62.984,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.460 | Acc: 48.952,63.338,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.512 | Acc: 48.463,63.025,69.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 2.894 | Acc: 48.438,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.460 | Acc: 58.557,80.060,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.481 | Acc: 58.003,79.745,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.524 | Acc: 56.916,79.316,92.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.517 | Acc: 56.867,79.533,92.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.527 | Acc: 56.621,79.401,92.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.540 | Acc: 56.379,79.113,92.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.535 | Acc: 56.372,79.056,92.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.530 | Acc: 56.575,79.086,92.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.542 | Acc: 56.427,78.924,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.553 | Acc: 56.242,78.759,92.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.564 | Acc: 55.992,78.652,92.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.576 | Acc: 55.855,78.508,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.581 | Acc: 55.879,78.469,92.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.581 | Acc: 55.997,78.356,92.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.580 | Acc: 56.081,78.314,92.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.585 | Acc: 55.987,78.242,92.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.589 | Acc: 55.993,78.194,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.597 | Acc: 55.886,78.125,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.601 | Acc: 55.860,78.102,91.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.888 | Acc: 52.344,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.446 | Acc: 49.182,64.137,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.401 | Acc: 48.628,64.024,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.416 | Acc: 48.642,63.998,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 2.453 | Acc: 62.500,85.156,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.444 | Acc: 57.478,79.836,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.442 | Acc: 57.184,80.107,93.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.446 | Acc: 56.954,80.085,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.455 | Acc: 57.099,80.179,93.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.468 | Acc: 57.163,79.981,93.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 57.018,79.985,93.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.479 | Acc: 56.992,80.042,93.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.491 | Acc: 56.687,79.964,93.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.498 | Acc: 56.634,79.826,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.507 | Acc: 56.650,79.688,92.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 56.565,79.514,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.519 | Acc: 56.500,79.454,92.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.522 | Acc: 56.591,79.388,92.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.528 | Acc: 56.603,79.237,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.528 | Acc: 56.704,79.192,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.538 | Acc: 56.581,79.050,92.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.549 | Acc: 56.440,78.904,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.559 | Acc: 56.319,78.792,92.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.564 | Acc: 56.266,78.734,92.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.146 | Acc: 52.344,69.531,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.382 | Acc: 50.335,62.537,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.348 | Acc: 50.114,63.205,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.393 | Acc: 49.834,63.243,68.648,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 2.496 | Acc: 58.594,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.524 | Acc: 56.436,79.055,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.474 | Acc: 56.402,80.069,93.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.476 | Acc: 56.737,79.867,93.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.466 | Acc: 57.215,80.112,93.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.463 | Acc: 57.356,80.090,93.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.493 | Acc: 56.986,79.688,93.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.507 | Acc: 56.743,79.588,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.518 | Acc: 56.687,79.343,92.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.517 | Acc: 56.690,79.204,92.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.517 | Acc: 56.763,79.237,92.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.510 | Acc: 56.854,79.323,92.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.523 | Acc: 56.662,79.192,92.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.526 | Acc: 56.783,79.152,92.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.531 | Acc: 56.698,79.156,92.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.539 | Acc: 56.676,79.039,92.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.543 | Acc: 56.686,79.016,92.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.548 | Acc: 56.669,79.000,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.550 | Acc: 56.598,78.984,92.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.553 | Acc: 56.523,78.927,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.120 | Acc: 54.688,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.225 | Acc: 50.298,66.257,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.203 | Acc: 50.457,65.720,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.243 | Acc: 50.205,64.972,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 2.308 | Acc: 63.281,82.812,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.426 | Acc: 56.845,81.176,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.393 | Acc: 57.012,81.383,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.410 | Acc: 57.070,80.776,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.409 | Acc: 57.176,80.758,93.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.437 | Acc: 56.977,80.647,93.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.446 | Acc: 56.973,80.404,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.464 | Acc: 56.727,80.120,93.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.475 | Acc: 56.667,79.950,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.479 | Acc: 56.591,79.908,93.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.484 | Acc: 56.681,79.734,93.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.500 | Acc: 56.444,79.514,92.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.500 | Acc: 56.626,79.499,92.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.508 | Acc: 56.588,79.415,92.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.523 | Acc: 56.461,79.365,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.529 | Acc: 56.380,79.264,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.540 | Acc: 56.313,79.099,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.545 | Acc: 56.369,79.025,92.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.548 | Acc: 56.417,78.999,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.551 | Acc: 56.414,78.972,92.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.017 | Acc: 50.000,70.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 51.079,64.807,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.301 | Acc: 50.819,65.206,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.314 | Acc: 50.397,65.126,69.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 2.460 | Acc: 54.688,82.812,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.352 | Acc: 59.449,82.254,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.355 | Acc: 58.784,81.593,93.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.340 | Acc: 58.607,81.749,93.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.354 | Acc: 58.449,81.385,93.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.367 | Acc: 58.269,81.281,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.374 | Acc: 58.297,81.263,93.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.382 | Acc: 57.940,81.067,93.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.394 | Acc: 57.808,80.876,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.404 | Acc: 57.847,80.767,93.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.427 | Acc: 57.653,80.422,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.434 | Acc: 57.653,80.395,93.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.443 | Acc: 57.514,80.303,93.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.454 | Acc: 57.450,80.157,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.459 | Acc: 57.429,80.049,92.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.458 | Acc: 57.511,80.118,92.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.471 | Acc: 57.467,80.001,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.487 | Acc: 57.341,79.804,92.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.500 | Acc: 57.198,79.649,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.503 | Acc: 57.197,79.599,92.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.280 | Acc: 53.906,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.434 | Acc: 49.070,63.876,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.502 | Acc: 47.999,63.891,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.511 | Acc: 47.643,63.435,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 2.240 | Acc: 60.938,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.437 | Acc: 56.548,80.692,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.419 | Acc: 57.298,80.716,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.415 | Acc: 57.313,80.712,93.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.409 | Acc: 57.166,80.826,93.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.443 | Acc: 56.915,80.368,93.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.438 | Acc: 57.290,80.443,93.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.436 | Acc: 57.624,80.319,93.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.443 | Acc: 57.672,80.313,93.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.448 | Acc: 57.541,80.231,93.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.457 | Acc: 57.253,80.177,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.460 | Acc: 57.265,80.094,93.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.471 | Acc: 57.077,80.064,92.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.471 | Acc: 57.196,80.026,92.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.476 | Acc: 57.231,79.960,92.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.483 | Acc: 57.195,79.864,92.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.482 | Acc: 57.238,79.816,92.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 57.226,79.777,92.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 57.165,79.653,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.499 | Acc: 57.095,79.583,92.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.430 | Acc: 51.562,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.469 | Acc: 49.405,63.207,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.444 | Acc: 48.819,63.891,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.448 | Acc: 48.297,63.742,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 2.248 | Acc: 60.156,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.405 | Acc: 58.519,79.688,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.415 | Acc: 57.203,80.107,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.411 | Acc: 57.736,80.072,93.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.411 | Acc: 57.533,80.141,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.394 | Acc: 57.820,80.376,93.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.408 | Acc: 57.677,80.114,93.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.411 | Acc: 57.713,80.186,93.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.427 | Acc: 57.492,80.115,93.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.432 | Acc: 57.437,80.076,93.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.440 | Acc: 57.412,80.103,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.451 | Acc: 57.183,79.981,93.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.458 | Acc: 57.060,79.879,92.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.464 | Acc: 57.004,79.822,92.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.469 | Acc: 56.981,79.751,92.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.474 | Acc: 57.000,79.726,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.483 | Acc: 56.873,79.622,92.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 56.768,79.518,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 56.847,79.465,92.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 56.953,79.493,92.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.409 | Acc: 53.906,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.348 | Acc: 51.562,65.253,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.349 | Acc: 50.629,64.672,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.392 | Acc: 50.333,63.947,69.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 2.290 | Acc: 61.719,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.336 | Acc: 59.003,80.952,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.355 | Acc: 58.308,81.059,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.376 | Acc: 57.697,81.071,93.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.381 | Acc: 57.861,80.990,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.383 | Acc: 58.106,80.840,93.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.372 | Acc: 58.122,80.669,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.378 | Acc: 58.283,80.646,93.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.388 | Acc: 58.065,80.609,93.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.406 | Acc: 57.951,80.365,93.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.413 | Acc: 57.929,80.212,93.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.414 | Acc: 57.894,80.214,93.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.422 | Acc: 57.796,80.161,93.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.437 | Acc: 57.591,80.020,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.441 | Acc: 57.654,79.938,92.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.446 | Acc: 57.636,79.934,92.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.454 | Acc: 57.557,79.804,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.457 | Acc: 57.464,79.820,92.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.458 | Acc: 57.466,79.802,92.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.465 | Acc: 57.435,79.690,92.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.392 | Acc: 44.531,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.341 | Acc: 48.884,65.253,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.349 | Acc: 48.609,64.825,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.387 | Acc: 48.040,64.600,69.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 1.937 | Acc: 59.375,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.337 | Acc: 58.445,81.101,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.354 | Acc: 57.851,80.869,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.345 | Acc: 57.979,81.404,94.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.350 | Acc: 57.851,81.472,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.368 | Acc: 57.542,81.103,93.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.375 | Acc: 57.528,80.927,93.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.372 | Acc: 57.591,80.840,93.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.393 | Acc: 57.424,80.580,93.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.397 | Acc: 57.549,80.451,93.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.416 | Acc: 57.373,80.321,93.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.418 | Acc: 57.339,80.387,93.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.417 | Acc: 57.287,80.443,93.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.419 | Acc: 57.292,80.409,93.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.428 | Acc: 57.279,80.310,93.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.427 | Acc: 57.449,80.204,93.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.429 | Acc: 57.491,80.152,93.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.435 | Acc: 57.421,80.052,93.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.443 | Acc: 57.384,79.945,93.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.452 | Acc: 57.331,79.870,92.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.169 | Acc: 47.656,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.638 | Acc: 46.466,63.356,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.617 | Acc: 46.456,63.377,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 45.991,63.140,68.673,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 2.781 | Acc: 44.531,73.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.326 | Acc: 58.185,81.213,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.351 | Acc: 57.946,81.002,93.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.335 | Acc: 58.081,81.391,94.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.320 | Acc: 58.237,81.491,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.325 | Acc: 58.431,81.459,93.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.334 | Acc: 58.110,81.347,94.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.333 | Acc: 58.184,81.350,94.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.346 | Acc: 58.186,81.003,93.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.353 | Acc: 58.253,80.900,93.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.360 | Acc: 58.201,80.784,93.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.366 | Acc: 58.159,80.815,93.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.368 | Acc: 58.273,80.816,93.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.382 | Acc: 58.175,80.585,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.389 | Acc: 58.177,80.533,93.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.397 | Acc: 58.132,80.399,93.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.406 | Acc: 58.034,80.291,93.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.417 | Acc: 57.922,80.175,93.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.423 | Acc: 57.862,80.099,92.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.430 | Acc: 57.829,79.956,92.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.254 | Acc: 48.438,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.461 | Acc: 50.781,64.435,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.484 | Acc: 49.790,63.053,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.509 | Acc: 49.885,63.064,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 2.249 | Acc: 62.500,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.340 | Acc: 58.259,81.101,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.345 | Acc: 58.194,81.155,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.344 | Acc: 58.466,81.352,94.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.331 | Acc: 58.488,81.337,94.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.330 | Acc: 58.485,81.242,94.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.313 | Acc: 58.697,81.502,94.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.314 | Acc: 58.749,81.383,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.323 | Acc: 58.691,81.100,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.333 | Acc: 58.568,81.026,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.344 | Acc: 58.500,80.939,94.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.351 | Acc: 58.530,80.843,93.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.366 | Acc: 58.409,80.718,93.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.370 | Acc: 58.342,80.681,93.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.380 | Acc: 58.255,80.538,93.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.387 | Acc: 58.298,80.453,93.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.392 | Acc: 58.263,80.405,93.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.395 | Acc: 58.232,80.389,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.400 | Acc: 58.252,80.384,93.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.412 | Acc: 58.112,80.278,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.234 | Acc: 50.000,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.205 | Acc: 51.414,66.109,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.241 | Acc: 51.105,65.911,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.261 | Acc: 50.551,65.932,69.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 2.377 | Acc: 55.469,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.342 | Acc: 58.594,81.510,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.319 | Acc: 58.994,81.688,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.314 | Acc: 58.786,81.391,94.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.293 | Acc: 59.124,81.800,94.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.304 | Acc: 58.988,81.668,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.307 | Acc: 58.942,81.844,94.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.321 | Acc: 58.688,81.643,94.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.327 | Acc: 58.667,81.658,93.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.337 | Acc: 58.546,81.544,93.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.342 | Acc: 58.485,81.487,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.348 | Acc: 58.382,81.423,93.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.359 | Acc: 58.279,81.224,93.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.362 | Acc: 58.226,81.130,93.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.365 | Acc: 58.263,81.069,93.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.365 | Acc: 58.332,81.074,93.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.368 | Acc: 58.326,80.990,93.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.374 | Acc: 58.266,80.906,93.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.378 | Acc: 58.202,80.774,93.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.385 | Acc: 58.083,80.682,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.021 | Acc: 45.312,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.300 | Acc: 48.958,65.476,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.295 | Acc: 48.876,65.530,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.334 | Acc: 48.566,65.305,71.055,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 2.235 | Acc: 62.500,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.253 | Acc: 60.603,82.961,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.254 | Acc: 59.985,82.755,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.251 | Acc: 59.657,82.761,94.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.283 | Acc: 59.028,82.272,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.291 | Acc: 58.988,82.178,94.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.308 | Acc: 58.852,82.076,94.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.310 | Acc: 58.854,82.076,94.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.309 | Acc: 58.865,81.978,94.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.316 | Acc: 58.857,81.768,94.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.325 | Acc: 58.753,81.580,94.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.331 | Acc: 58.742,81.522,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.340 | Acc: 58.756,81.419,93.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.351 | Acc: 58.728,81.208,93.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.353 | Acc: 58.749,81.128,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.358 | Acc: 58.768,81.092,93.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.366 | Acc: 58.708,80.941,93.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.373 | Acc: 58.603,80.842,93.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.385 | Acc: 58.522,80.778,93.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.394 | Acc: 58.444,80.647,93.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.508 | Acc: 49.219,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.390 | Acc: 48.400,65.402,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.397 | Acc: 48.266,65.644,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.445 | Acc: 48.514,64.831,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 2.223 | Acc: 59.375,84.375,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.269 | Acc: 59.561,81.957,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.314 | Acc: 59.108,81.479,93.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.292 | Acc: 59.529,81.788,93.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.301 | Acc: 59.491,81.896,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.304 | Acc: 59.336,81.838,94.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.318 | Acc: 59.149,81.541,94.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.315 | Acc: 59.137,81.566,94.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.319 | Acc: 59.225,81.352,94.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.327 | Acc: 59.073,81.185,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.333 | Acc: 59.025,81.122,93.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.340 | Acc: 58.990,80.999,93.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.347 | Acc: 58.980,80.880,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.362 | Acc: 58.803,80.780,93.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.376 | Acc: 58.597,80.652,93.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.385 | Acc: 58.500,80.612,93.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.388 | Acc: 58.533,80.627,93.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.389 | Acc: 58.475,80.604,93.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.391 | Acc: 58.442,80.551,93.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.397 | Acc: 58.376,80.426,92.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.893 | Acc: 52.344,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 46.838,63.728,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.483 | Acc: 48.190,63.319,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.482 | Acc: 48.438,63.307,69.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 2.217 | Acc: 57.031,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.266 | Acc: 58.743,82.701,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.306 | Acc: 58.632,82.012,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.324 | Acc: 58.607,81.954,93.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.321 | Acc: 58.507,81.771,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.334 | Acc: 58.331,81.536,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.326 | Acc: 58.316,81.728,93.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.326 | Acc: 58.355,81.749,93.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.320 | Acc: 58.608,81.692,93.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.311 | Acc: 58.866,81.746,93.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.312 | Acc: 58.944,81.600,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.323 | Acc: 58.664,81.540,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.327 | Acc: 58.766,81.464,93.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.329 | Acc: 58.731,81.421,93.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.339 | Acc: 58.624,81.325,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.344 | Acc: 58.640,81.211,93.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.352 | Acc: 58.567,81.109,93.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.358 | Acc: 58.562,81.023,93.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.364 | Acc: 58.550,80.938,93.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.368 | Acc: 58.534,80.805,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.405 | Acc: 51.562,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.397 | Acc: 51.488,64.025,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.407 | Acc: 50.305,64.310,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.440 | Acc: 49.744,63.986,69.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 2.044 | Acc: 63.281,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.273 | Acc: 59.933,82.961,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.254 | Acc: 59.204,83.155,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.239 | Acc: 59.477,83.005,94.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.273 | Acc: 59.008,82.475,94.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.275 | Acc: 58.919,82.611,94.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.270 | Acc: 59.149,82.599,94.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.277 | Acc: 59.098,82.414,94.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.268 | Acc: 59.142,82.468,94.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.267 | Acc: 59.371,82.437,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.275 | Acc: 59.441,82.276,94.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.289 | Acc: 59.336,82.180,94.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.293 | Acc: 59.232,82.106,93.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.297 | Acc: 59.195,82.067,93.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.306 | Acc: 59.019,81.912,93.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.313 | Acc: 58.838,81.821,93.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.321 | Acc: 58.881,81.703,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.331 | Acc: 58.848,81.555,93.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.335 | Acc: 58.847,81.482,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.347 | Acc: 58.745,81.309,93.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.129 | Acc: 57.812,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.248 | Acc: 52.269,65.811,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.254 | Acc: 51.429,65.091,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.259 | Acc: 51.140,64.921,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 2.293 | Acc: 57.031,82.031,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.350 | Acc: 57.738,81.957,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.252 | Acc: 58.975,82.812,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.261 | Acc: 58.645,82.889,94.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.261 | Acc: 58.912,82.562,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.248 | Acc: 58.957,82.596,94.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.251 | Acc: 59.110,82.709,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.255 | Acc: 59.131,82.591,94.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.254 | Acc: 59.356,82.672,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.261 | Acc: 59.271,82.541,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.274 | Acc: 59.181,82.338,94.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.274 | Acc: 59.227,82.314,94.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.285 | Acc: 59.057,82.180,94.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.293 | Acc: 59.031,82.031,94.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.306 | Acc: 58.833,81.817,93.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.310 | Acc: 58.871,81.707,93.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.316 | Acc: 58.896,81.571,93.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.319 | Acc: 58.942,81.543,93.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.326 | Acc: 58.899,81.384,93.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.328 | Acc: 58.969,81.336,93.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.167 | Acc: 54.688,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.389 | Acc: 49.740,65.662,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.420 | Acc: 49.752,64.768,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.433 | Acc: 49.270,64.191,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 2.126 | Acc: 65.625,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.156 | Acc: 61.198,83.519,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.206 | Acc: 60.118,83.136,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.186 | Acc: 60.297,83.491,94.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.186 | Acc: 60.340,83.565,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.207 | Acc: 60.071,83.199,94.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.219 | Acc: 59.814,82.916,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.217 | Acc: 59.929,82.835,94.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.228 | Acc: 59.899,82.735,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.238 | Acc: 59.858,82.627,94.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.247 | Acc: 59.771,82.432,94.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.252 | Acc: 59.817,82.438,94.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.256 | Acc: 59.806,82.359,94.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.264 | Acc: 59.761,82.238,94.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.283 | Acc: 59.564,82.053,94.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.297 | Acc: 59.417,81.894,93.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.305 | Acc: 59.441,81.768,93.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.318 | Acc: 59.265,81.594,93.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.328 | Acc: 59.226,81.536,93.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.331 | Acc: 59.209,81.471,93.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.214 | Acc: 50.781,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 51.451,65.327,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.287 | Acc: 51.467,65.225,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.294 | Acc: 51.153,65.471,70.120,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 2.251 | Acc: 60.938,81.250,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.205 | Acc: 59.226,82.961,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.237 | Acc: 59.413,82.774,94.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.211 | Acc: 59.874,82.851,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.195 | Acc: 60.147,82.774,94.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.201 | Acc: 59.785,82.867,94.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.213 | Acc: 59.801,82.599,94.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.211 | Acc: 59.935,82.619,94.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.225 | Acc: 59.647,82.444,94.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.240 | Acc: 59.444,82.351,94.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.247 | Acc: 59.441,82.194,94.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.256 | Acc: 59.467,82.113,94.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.268 | Acc: 59.430,82.028,94.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.282 | Acc: 59.177,81.950,94.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.282 | Acc: 59.239,81.990,94.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.291 | Acc: 59.175,81.961,93.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.296 | Acc: 59.197,81.912,93.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.303 | Acc: 59.217,81.827,93.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.309 | Acc: 59.109,81.713,93.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.312 | Acc: 59.100,81.666,93.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.174 | Acc: 53.125,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.407 | Acc: 49.628,64.323,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.449 | Acc: 48.990,64.158,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.443 | Acc: 48.860,63.998,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 2.194 | Acc: 58.594,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.232 | Acc: 60.082,82.664,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.247 | Acc: 59.642,82.165,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.212 | Acc: 60.143,82.492,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.212 | Acc: 59.954,82.417,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.222 | Acc: 59.932,82.580,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.220 | Acc: 60.040,82.632,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.225 | Acc: 60.073,82.502,94.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.230 | Acc: 59.860,82.536,94.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.240 | Acc: 59.841,82.359,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.250 | Acc: 59.597,82.233,94.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.254 | Acc: 59.396,82.159,94.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.268 | Acc: 59.281,81.996,94.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.270 | Acc: 59.375,81.956,94.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.271 | Acc: 59.347,81.951,94.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.277 | Acc: 59.341,81.917,94.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.282 | Acc: 59.397,81.829,94.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.289 | Acc: 59.297,81.733,94.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.299 | Acc: 59.202,81.681,93.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.303 | Acc: 59.166,81.629,93.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.371 | Acc: 53.906,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.216 | Acc: 52.790,66.518,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.195 | Acc: 52.287,66.006,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.239 | Acc: 51.767,65.779,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 2.135 | Acc: 66.406,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.179 | Acc: 61.310,82.999,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.196 | Acc: 60.080,83.175,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.149 | Acc: 60.553,83.735,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.148 | Acc: 60.503,83.642,95.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.173 | Acc: 60.071,83.385,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.186 | Acc: 59.904,83.013,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.196 | Acc: 59.779,82.868,94.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.189 | Acc: 59.967,83.011,94.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.190 | Acc: 59.927,82.959,94.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.202 | Acc: 59.612,82.855,94.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.210 | Acc: 59.633,82.830,94.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.223 | Acc: 59.482,82.621,94.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.229 | Acc: 59.483,82.519,94.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.243 | Acc: 59.406,82.462,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.247 | Acc: 59.487,82.426,94.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.256 | Acc: 59.460,82.245,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.271 | Acc: 59.302,82.022,93.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.277 | Acc: 59.291,81.973,93.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.284 | Acc: 59.316,81.824,93.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.225 | Acc: 52.344,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.325 | Acc: 51.786,65.699,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.329 | Acc: 50.762,65.320,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.352 | Acc: 50.576,65.343,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 2.308 | Acc: 57.812,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.255 | Acc: 60.454,82.701,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.218 | Acc: 60.309,83.175,94.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.212 | Acc: 60.233,83.222,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.201 | Acc: 60.185,83.044,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.225 | Acc: 59.684,82.812,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.229 | Acc: 59.717,82.632,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.228 | Acc: 59.846,82.624,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.227 | Acc: 59.918,82.652,94.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.226 | Acc: 59.919,82.631,94.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.228 | Acc: 59.981,82.505,94.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.225 | Acc: 60.022,82.593,94.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.235 | Acc: 59.900,82.414,94.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.243 | Acc: 59.953,82.292,94.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.251 | Acc: 59.817,82.279,94.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.260 | Acc: 59.666,82.114,94.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.271 | Acc: 59.640,82.019,94.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.277 | Acc: 59.641,81.841,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.282 | Acc: 59.624,81.789,93.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.290 | Acc: 59.560,81.670,93.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.734 | Acc: 57.031,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.022 | Acc: 53.720,67.560,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.054 | Acc: 53.201,66.635,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.111 | Acc: 53.356,66.086,70.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 2.086 | Acc: 57.031,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.175 | Acc: 59.933,83.036,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.160 | Acc: 60.804,83.346,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.167 | Acc: 60.720,83.145,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.189 | Acc: 60.349,82.841,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.180 | Acc: 60.473,83.153,94.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.180 | Acc: 60.363,82.955,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.188 | Acc: 60.295,82.868,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.200 | Acc: 60.171,82.779,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.207 | Acc: 60.169,82.623,94.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.218 | Acc: 59.950,82.478,94.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.221 | Acc: 59.955,82.325,94.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.224 | Acc: 59.936,82.317,94.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.233 | Acc: 59.830,82.253,94.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.236 | Acc: 59.862,82.156,94.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.240 | Acc: 59.777,82.158,94.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.251 | Acc: 59.638,82.056,93.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.257 | Acc: 59.579,81.969,93.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.266 | Acc: 59.598,81.878,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.270 | Acc: 59.623,81.828,93.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.379 | Acc: 49.219,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.603 | Acc: 48.214,62.463,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.554 | Acc: 48.323,62.824,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.598 | Acc: 48.207,62.334,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 2.428 | Acc: 56.250,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.254 | Acc: 58.333,83.705,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.253 | Acc: 58.594,83.022,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.248 | Acc: 58.402,82.941,95.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.247 | Acc: 58.478,82.803,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.234 | Acc: 58.710,83.122,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.230 | Acc: 58.981,83.181,94.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.222 | Acc: 59.253,83.018,94.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.235 | Acc: 59.259,82.720,94.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.230 | Acc: 59.315,82.683,94.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.228 | Acc: 59.468,82.696,94.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.226 | Acc: 59.562,82.671,94.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.230 | Acc: 59.651,82.527,94.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.236 | Acc: 59.567,82.399,94.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.243 | Acc: 59.600,82.334,94.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.248 | Acc: 59.585,82.244,94.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.255 | Acc: 59.528,82.095,94.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.263 | Acc: 59.533,81.967,94.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.269 | Acc: 59.490,81.875,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.275 | Acc: 59.506,81.779,93.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.333 | Acc: 50.000,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.301 | Acc: 50.856,66.220,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 51.067,63.967,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.346 | Acc: 50.730,64.306,70.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 2.179 | Acc: 60.156,89.062,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.217 | Acc: 61.272,83.185,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.178 | Acc: 61.433,83.651,95.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.160 | Acc: 61.258,83.632,95.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.176 | Acc: 61.285,83.372,94.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.183 | Acc: 60.976,83.207,94.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.180 | Acc: 61.009,83.142,94.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.176 | Acc: 61.037,83.200,94.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.185 | Acc: 61.039,83.070,94.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.190 | Acc: 60.985,82.933,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.198 | Acc: 60.844,82.879,94.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.206 | Acc: 60.641,82.682,94.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.216 | Acc: 60.503,82.479,94.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.219 | Acc: 60.468,82.480,94.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.230 | Acc: 60.326,82.315,94.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.242 | Acc: 60.206,82.208,94.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.245 | Acc: 60.132,82.155,94.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.250 | Acc: 60.106,82.089,94.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.262 | Acc: 59.994,81.943,93.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.270 | Acc: 59.900,81.853,93.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.218 | Acc: 48.438,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.238 | Acc: 51.302,65.104,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.285 | Acc: 50.210,65.511,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.317 | Acc: 50.243,65.330,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 2.199 | Acc: 64.062,82.812,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.139 | Acc: 61.830,84.673,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.113 | Acc: 62.081,84.508,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.145 | Acc: 61.335,84.260,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.146 | Acc: 61.140,84.240,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.155 | Acc: 60.705,84.066,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.152 | Acc: 60.938,83.981,94.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.157 | Acc: 60.749,83.821,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.158 | Acc: 60.700,83.734,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.165 | Acc: 60.575,83.585,94.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.173 | Acc: 60.623,83.434,94.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.182 | Acc: 60.531,83.170,94.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.195 | Acc: 60.477,82.991,94.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.205 | Acc: 60.459,82.944,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.212 | Acc: 60.448,82.796,94.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.223 | Acc: 60.390,82.584,94.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.233 | Acc: 60.193,82.482,94.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.241 | Acc: 60.143,82.391,94.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.252 | Acc: 59.985,82.233,93.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.265 | Acc: 59.838,82.054,93.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.213 | Acc: 54.688,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.405 | Acc: 51.749,64.955,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.332 | Acc: 51.372,65.396,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.339 | Acc: 51.434,64.754,70.044,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 2.316 | Acc: 60.938,81.250,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.130 | Acc: 60.975,83.519,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.113 | Acc: 61.204,83.975,94.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.118 | Acc: 61.206,83.824,94.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.134 | Acc: 61.034,83.729,94.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.140 | Acc: 61.100,83.609,94.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.139 | Acc: 60.983,83.607,94.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.162 | Acc: 60.677,83.317,94.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.176 | Acc: 60.506,83.109,94.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.199 | Acc: 60.195,82.907,94.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.201 | Acc: 60.234,82.840,94.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.205 | Acc: 60.262,82.809,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.207 | Acc: 60.292,82.702,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.211 | Acc: 60.300,82.567,94.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.216 | Acc: 60.206,82.540,94.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.223 | Acc: 60.146,82.436,94.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.229 | Acc: 60.224,82.328,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.238 | Acc: 60.154,82.150,93.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.244 | Acc: 60.052,82.144,93.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.255 | Acc: 59.898,81.994,93.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.231 | Acc: 49.219,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.423 | Acc: 48.996,64.955,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.400 | Acc: 49.066,64.653,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.441 | Acc: 48.822,64.395,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 2.198 | Acc: 60.938,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.169 | Acc: 61.310,82.589,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.180 | Acc: 60.099,82.946,95.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.173 | Acc: 60.387,83.222,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.175 | Acc: 60.513,83.034,94.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.166 | Acc: 60.551,83.308,94.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.157 | Acc: 60.873,83.419,94.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.156 | Acc: 60.915,83.367,94.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.163 | Acc: 60.734,83.438,94.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.149 | Acc: 60.942,83.456,95.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.156 | Acc: 60.794,83.450,95.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.161 | Acc: 60.545,83.364,95.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.171 | Acc: 60.442,83.321,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.183 | Acc: 60.333,83.220,94.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.188 | Acc: 60.304,83.152,94.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.195 | Acc: 60.294,83.067,94.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.195 | Acc: 60.349,83.075,94.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.198 | Acc: 60.312,83.053,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.205 | Acc: 60.204,82.940,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.209 | Acc: 60.230,82.876,94.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.048 | Acc: 59.375,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.217 | Acc: 53.571,64.881,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.162 | Acc: 53.601,65.701,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.171 | Acc: 53.804,65.446,70.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 1.851 | Acc: 62.500,86.719,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.147 | Acc: 62.612,84.263,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.118 | Acc: 62.271,84.299,94.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.123 | Acc: 61.680,84.106,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.133 | Acc: 61.613,83.835,94.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.130 | Acc: 61.610,83.957,94.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.148 | Acc: 61.525,83.626,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.168 | Acc: 61.165,83.394,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.177 | Acc: 60.996,83.288,94.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.188 | Acc: 60.709,83.028,94.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.193 | Acc: 60.654,82.949,94.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.195 | Acc: 60.595,82.816,94.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.203 | Acc: 60.561,82.709,94.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.209 | Acc: 60.560,82.564,94.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.219 | Acc: 60.498,82.420,94.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.227 | Acc: 60.424,82.369,93.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.232 | Acc: 60.307,82.306,93.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.238 | Acc: 60.220,82.205,93.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.241 | Acc: 60.128,82.144,93.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.247 | Acc: 60.015,82.146,93.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.197 | Acc: 50.781,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.563 | Acc: 48.624,63.653,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.531 | Acc: 48.361,63.853,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.534 | Acc: 48.655,63.473,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 2.151 | Acc: 57.812,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.135 | Acc: 62.314,84.561,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.122 | Acc: 61.833,84.680,94.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.094 | Acc: 61.885,84.836,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.093 | Acc: 61.863,84.655,95.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.100 | Acc: 61.463,84.228,95.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.112 | Acc: 61.293,84.104,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.117 | Acc: 61.198,84.020,95.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.121 | Acc: 60.991,83.987,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.116 | Acc: 61.123,83.948,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.119 | Acc: 61.175,83.928,95.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.129 | Acc: 61.135,83.767,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.139 | Acc: 61.106,83.584,95.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.148 | Acc: 61.051,83.453,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.153 | Acc: 60.976,83.402,94.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.163 | Acc: 60.816,83.285,94.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.165 | Acc: 60.816,83.234,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.172 | Acc: 60.773,83.140,94.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.186 | Acc: 60.619,82.942,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.192 | Acc: 60.661,82.895,94.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.817 | Acc: 60.156,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.183 | Acc: 52.939,65.513,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.189 | Acc: 52.858,64.977,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.221 | Acc: 52.766,64.805,69.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 2.054 | Acc: 64.062,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.178 | Acc: 61.570,82.961,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.224 | Acc: 60.080,82.717,94.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.166 | Acc: 60.938,83.504,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.166 | Acc: 60.571,83.777,94.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.157 | Acc: 60.288,83.926,95.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.137 | Acc: 60.498,83.962,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.146 | Acc: 60.566,83.804,95.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.150 | Acc: 60.433,83.841,95.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.158 | Acc: 60.281,83.719,94.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.167 | Acc: 60.117,83.586,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.173 | Acc: 60.054,83.463,94.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.176 | Acc: 60.027,83.412,94.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.180 | Acc: 60.051,83.276,94.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.186 | Acc: 60.137,83.207,94.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.189 | Acc: 60.143,83.168,94.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.196 | Acc: 60.125,83.097,94.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.198 | Acc: 60.181,83.023,94.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.204 | Acc: 60.154,82.901,94.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.207 | Acc: 60.220,82.843,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.529 | Acc: 53.125,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.519 | Acc: 51.302,64.658,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 51.543,64.863,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.451 | Acc: 51.473,64.485,69.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 1.865 | Acc: 63.281,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.067 | Acc: 61.644,84.375,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.086 | Acc: 62.538,84.032,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.095 | Acc: 62.308,83.837,95.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.116 | Acc: 61.748,83.632,95.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.128 | Acc: 61.634,83.671,95.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.117 | Acc: 61.590,83.723,95.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.123 | Acc: 61.558,83.538,95.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.118 | Acc: 61.685,83.633,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.128 | Acc: 61.373,83.533,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.135 | Acc: 61.377,83.446,95.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.146 | Acc: 61.259,83.322,94.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.158 | Acc: 61.232,83.169,94.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.157 | Acc: 61.225,83.157,94.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.161 | Acc: 61.210,83.091,94.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.167 | Acc: 61.106,83.093,94.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.173 | Acc: 61.142,83.022,94.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.178 | Acc: 61.084,82.975,94.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.184 | Acc: 60.994,82.888,94.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.189 | Acc: 60.905,82.837,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.254 | Acc: 56.250,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.226 | Acc: 53.981,64.807,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.233 | Acc: 53.544,65.320,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.242 | Acc: 53.099,65.010,70.620,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 2.625 | Acc: 46.875,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.176 | Acc: 58.891,83.705,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.129 | Acc: 60.690,83.670,94.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.133 | Acc: 60.733,83.619,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.119 | Acc: 60.928,83.796,94.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.120 | Acc: 60.922,83.872,94.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.131 | Acc: 60.724,83.904,94.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.143 | Acc: 60.638,83.677,94.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.143 | Acc: 60.685,83.686,94.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.147 | Acc: 60.670,83.624,94.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.154 | Acc: 60.619,83.434,94.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.165 | Acc: 60.439,83.389,94.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.178 | Acc: 60.360,83.146,94.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.181 | Acc: 60.393,83.064,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.187 | Acc: 60.440,83.018,94.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.191 | Acc: 60.457,82.885,94.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.194 | Acc: 60.429,82.820,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.197 | Acc: 60.530,82.783,94.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.197 | Acc: 60.619,82.776,94.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.202 | Acc: 60.581,82.724,94.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.115 | Acc: 57.031,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.249 | Acc: 52.381,65.551,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.274 | Acc: 52.134,65.244,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.281 | Acc: 51.742,65.356,70.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 2.192 | Acc: 56.250,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.135 | Acc: 60.268,83.929,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.072 | Acc: 60.842,84.985,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.053 | Acc: 61.847,85.220,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.071 | Acc: 61.642,84.799,95.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.087 | Acc: 61.440,84.522,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.102 | Acc: 61.138,84.252,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.102 | Acc: 61.381,84.043,95.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.098 | Acc: 61.573,84.050,95.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.103 | Acc: 61.507,83.987,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.118 | Acc: 61.272,83.862,95.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.128 | Acc: 61.114,83.845,94.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.135 | Acc: 61.048,83.798,94.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.137 | Acc: 61.054,83.749,94.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.146 | Acc: 60.954,83.647,94.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.149 | Acc: 60.974,83.547,94.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.154 | Acc: 60.950,83.535,94.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.155 | Acc: 60.970,83.470,94.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.164 | Acc: 60.855,83.341,94.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.169 | Acc: 60.776,83.294,94.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.021 | Acc: 50.000,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 51.004,65.699,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.287 | Acc: 51.810,65.663,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.317 | Acc: 51.447,65.023,70.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 2.137 | Acc: 64.062,86.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.099 | Acc: 61.124,84.821,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.080 | Acc: 61.300,84.775,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.065 | Acc: 61.732,84.759,95.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.064 | Acc: 61.651,84.722,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.071 | Acc: 61.556,84.514,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.091 | Acc: 61.480,84.272,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.101 | Acc: 61.503,84.054,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.095 | Acc: 61.850,84.045,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.109 | Acc: 61.723,83.922,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.117 | Acc: 61.590,83.796,95.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.130 | Acc: 61.482,83.562,95.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.135 | Acc: 61.359,83.568,94.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.145 | Acc: 61.273,83.492,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.149 | Acc: 61.238,83.491,94.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.152 | Acc: 61.143,83.430,94.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.159 | Acc: 61.020,83.348,94.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.162 | Acc: 61.041,83.255,94.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.164 | Acc: 61.078,83.196,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.167 | Acc: 61.134,83.149,94.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.811 | Acc: 49.219,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.253 | Acc: 50.707,65.179,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.248 | Acc: 51.124,65.473,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.259 | Acc: 51.153,65.535,69.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 1.887 | Acc: 67.969,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.139 | Acc: 61.756,83.743,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.160 | Acc: 61.090,83.479,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.160 | Acc: 60.925,83.619,94.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.167 | Acc: 60.899,83.420,94.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.168 | Acc: 61.224,83.238,94.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.166 | Acc: 61.241,83.342,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.162 | Acc: 61.043,83.361,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.156 | Acc: 61.161,83.371,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.162 | Acc: 60.907,83.365,94.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.171 | Acc: 60.895,83.326,94.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.181 | Acc: 60.814,83.173,94.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.180 | Acc: 60.795,83.185,94.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.177 | Acc: 60.863,83.184,94.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.179 | Acc: 60.901,83.110,94.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.183 | Acc: 60.995,83.101,94.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.188 | Acc: 60.991,83.019,94.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.195 | Acc: 60.903,82.929,94.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.206 | Acc: 60.797,82.821,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.211 | Acc: 60.681,82.739,93.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.262 | Acc: 56.250,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.339 | Acc: 52.009,63.914,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.300 | Acc: 52.553,64.539,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.333 | Acc: 52.549,64.536,69.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 1.931 | Acc: 64.844,90.625,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.003 | Acc: 62.351,85.714,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.037 | Acc: 62.062,84.851,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.039 | Acc: 61.808,84.939,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.056 | Acc: 61.304,84.954,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.055 | Acc: 61.533,84.932,95.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.071 | Acc: 61.273,84.711,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.074 | Acc: 61.303,84.652,95.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.078 | Acc: 61.243,84.627,95.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.076 | Acc: 61.408,84.496,95.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.076 | Acc: 61.353,84.426,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.079 | Acc: 61.443,84.343,95.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.093 | Acc: 61.268,84.239,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.096 | Acc: 61.261,84.133,95.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.106 | Acc: 61.135,83.994,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.112 | Acc: 61.187,83.879,94.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.120 | Acc: 61.105,83.767,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.127 | Acc: 61.183,83.665,94.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.135 | Acc: 61.093,83.568,94.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.142 | Acc: 61.083,83.463,94.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.076 | Acc: 57.031,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.373 | Acc: 52.455,64.993,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.342 | Acc: 52.096,65.701,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.357 | Acc: 51.678,65.561,70.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 2.074 | Acc: 60.938,87.500,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.048 | Acc: 63.207,84.821,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 63.338,85.061,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.013 | Acc: 62.666,85.259,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.031 | Acc: 62.471,85.041,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.032 | Acc: 62.423,84.947,95.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.040 | Acc: 62.222,84.866,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.049 | Acc: 62.035,84.774,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.054 | Acc: 61.952,84.700,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.070 | Acc: 61.848,84.453,95.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.085 | Acc: 61.692,84.142,95.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.098 | Acc: 61.673,83.930,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.107 | Acc: 61.466,83.843,95.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.119 | Acc: 61.267,83.767,94.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.128 | Acc: 61.182,83.583,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.141 | Acc: 61.114,83.415,94.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.143 | Acc: 61.140,83.397,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.143 | Acc: 61.235,83.443,94.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.152 | Acc: 61.156,83.334,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.160 | Acc: 61.110,83.206,94.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.317 | Acc: 53.125,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.258 | Acc: 50.893,66.369,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.277 | Acc: 51.391,65.796,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.301 | Acc: 51.511,65.523,69.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 2.313 | Acc: 60.156,87.500,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.198 | Acc: 60.193,83.668,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.137 | Acc: 61.604,84.318,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.119 | Acc: 61.475,84.452,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.101 | Acc: 61.970,84.404,94.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.090 | Acc: 62.067,84.390,94.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.093 | Acc: 61.841,84.472,94.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.084 | Acc: 62.007,84.336,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.085 | Acc: 61.850,84.293,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.084 | Acc: 61.732,84.271,95.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.088 | Acc: 61.625,84.204,94.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.097 | Acc: 61.447,84.029,94.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.102 | Acc: 61.395,84.005,94.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.111 | Acc: 61.389,83.890,94.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.119 | Acc: 61.357,83.774,94.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.129 | Acc: 61.303,83.627,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.134 | Acc: 61.242,83.579,94.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.137 | Acc: 61.258,83.543,94.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.141 | Acc: 61.240,83.490,94.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.149 | Acc: 61.233,83.383,94.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.264 | Acc: 57.812,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.398 | Acc: 51.935,64.583,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.331 | Acc: 51.925,64.634,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.308 | Acc: 51.755,64.793,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 2.046 | Acc: 67.188,86.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.019 | Acc: 62.351,85.268,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.044 | Acc: 62.005,84.909,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.026 | Acc: 62.526,85.156,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.024 | Acc: 62.326,85.214,95.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.032 | Acc: 61.935,85.087,95.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.019 | Acc: 62.126,85.272,95.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.031 | Acc: 62.035,85.101,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.042 | Acc: 62.058,84.972,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.041 | Acc: 62.137,85.079,95.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.049 | Acc: 62.037,84.946,95.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.055 | Acc: 62.005,84.835,95.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.067 | Acc: 61.913,84.719,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.072 | Acc: 61.880,84.737,95.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.078 | Acc: 61.749,84.606,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.088 | Acc: 61.643,84.437,94.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.097 | Acc: 61.541,84.304,94.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.106 | Acc: 61.526,84.201,94.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.113 | Acc: 61.530,84.137,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.121 | Acc: 61.458,84.026,94.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.629 | Acc: 53.125,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.535 | Acc: 47.470,64.918,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.556 | Acc: 47.008,64.634,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 46.977,64.383,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 2.239 | Acc: 56.250,78.906,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 62.016,86.086,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.991 | Acc: 62.538,85.518,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 63.166,85.515,95.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.005 | Acc: 62.712,85.253,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.025 | Acc: 62.376,84.862,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.041 | Acc: 62.209,84.821,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.044 | Acc: 62.173,84.879,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.055 | Acc: 62.146,84.632,95.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.050 | Acc: 62.198,84.660,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.062 | Acc: 62.006,84.593,95.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.073 | Acc: 61.874,84.495,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.089 | Acc: 61.813,84.229,95.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.105 | Acc: 61.728,83.998,94.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.107 | Acc: 61.758,83.922,94.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.112 | Acc: 61.628,83.887,94.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.120 | Acc: 61.570,83.735,94.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.125 | Acc: 61.538,83.624,94.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.128 | Acc: 61.530,83.600,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.135 | Acc: 61.411,83.506,94.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.315 | Acc: 47.656,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.331 | Acc: 50.707,64.658,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.325 | Acc: 50.724,65.015,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.338 | Acc: 50.948,65.177,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 2.074 | Acc: 63.281,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.087 | Acc: 60.900,85.342,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.087 | Acc: 61.814,85.004,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.044 | Acc: 62.180,85.336,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.053 | Acc: 62.076,85.185,95.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.050 | Acc: 62.252,85.056,95.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.040 | Acc: 62.448,85.072,95.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.044 | Acc: 62.240,85.007,95.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.054 | Acc: 62.185,84.807,95.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.056 | Acc: 62.202,84.798,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.064 | Acc: 62.107,84.655,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.076 | Acc: 62.040,84.509,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.082 | Acc: 61.933,84.401,95.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.091 | Acc: 61.776,84.240,95.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.093 | Acc: 61.791,84.158,95.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.100 | Acc: 61.662,84.095,95.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.111 | Acc: 61.629,83.947,94.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.118 | Acc: 61.556,83.866,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.126 | Acc: 61.461,83.776,94.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.128 | Acc: 61.446,83.743,94.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.686 | Acc: 58.594,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.179 | Acc: 52.269,66.629,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.218 | Acc: 52.496,65.930,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.253 | Acc: 52.459,65.394,70.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 2.167 | Acc: 60.938,89.062,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.989 | Acc: 61.682,85.789,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.017 | Acc: 60.804,85.652,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.030 | Acc: 61.232,85.105,95.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.056 | Acc: 60.966,84.886,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.045 | Acc: 61.572,84.963,95.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.047 | Acc: 61.499,84.950,95.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.048 | Acc: 61.458,84.896,95.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.056 | Acc: 61.520,84.729,95.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.062 | Acc: 61.550,84.595,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.067 | Acc: 61.381,84.589,95.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.078 | Acc: 61.291,84.421,95.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.089 | Acc: 61.126,84.258,95.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.091 | Acc: 61.189,84.288,95.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.099 | Acc: 61.154,84.166,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.109 | Acc: 61.098,84.056,94.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.115 | Acc: 61.086,83.925,94.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.120 | Acc: 61.164,83.837,94.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.123 | Acc: 61.137,83.802,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.127 | Acc: 61.122,83.707,94.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.906 | Acc: 54.688,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.211 | Acc: 51.414,65.960,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.196 | Acc: 50.724,66.292,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.207 | Acc: 51.012,66.304,70.991,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 2.190 | Acc: 62.500,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.073 | Acc: 62.240,84.487,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.033 | Acc: 62.843,85.099,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.025 | Acc: 63.115,85.105,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.009 | Acc: 63.175,85.204,95.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.017 | Acc: 62.918,85.365,95.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.019 | Acc: 62.732,85.214,95.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.027 | Acc: 62.533,85.106,95.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.039 | Acc: 62.379,84.894,95.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.052 | Acc: 62.258,84.643,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.065 | Acc: 62.034,84.484,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.069 | Acc: 62.005,84.513,95.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.072 | Acc: 62.030,84.453,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.076 | Acc: 61.967,84.405,95.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.090 | Acc: 61.841,84.147,95.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.095 | Acc: 61.825,84.095,95.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.100 | Acc: 61.787,84.054,94.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.111 | Acc: 61.668,83.910,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.116 | Acc: 61.695,83.784,94.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.118 | Acc: 61.762,83.760,94.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.075 | Acc: 53.906,70.312,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.726 | Acc: 48.028,65.179,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.772 | Acc: 47.389,64.691,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.772 | Acc: 47.349,64.562,68.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 2.052 | Acc: 62.500,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.058 | Acc: 61.198,84.710,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.025 | Acc: 61.738,85.309,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.028 | Acc: 61.488,85.233,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.022 | Acc: 61.593,85.436,95.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.020 | Acc: 61.904,85.520,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.009 | Acc: 61.990,85.653,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.005 | Acc: 62.201,85.539,95.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.007 | Acc: 62.248,85.433,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.003 | Acc: 62.297,85.407,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.014 | Acc: 62.251,85.180,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.019 | Acc: 62.203,85.124,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.030 | Acc: 62.108,84.952,95.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.034 | Acc: 62.195,84.926,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.046 | Acc: 62.136,84.775,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.053 | Acc: 62.033,84.699,95.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.058 | Acc: 62.050,84.706,95.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.071 | Acc: 61.925,84.549,95.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.081 | Acc: 61.864,84.418,94.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.090 | Acc: 61.741,84.338,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.302 | Acc: 50.000,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.786 | Acc: 47.731,63.021,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.678 | Acc: 48.438,63.300,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.672 | Acc: 48.566,63.128,69.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 1.999 | Acc: 64.062,88.281,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.144 | Acc: 61.756,84.338,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.091 | Acc: 62.119,84.413,94.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.091 | Acc: 61.808,84.593,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.101 | Acc: 61.921,84.471,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.081 | Acc: 62.067,84.499,94.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.076 | Acc: 62.042,84.485,94.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.061 | Acc: 62.223,84.735,94.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.046 | Acc: 62.490,84.904,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.053 | Acc: 62.280,84.841,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.057 | Acc: 62.127,84.799,94.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.064 | Acc: 61.963,84.743,94.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.064 | Acc: 61.962,84.719,94.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.077 | Acc: 61.862,84.522,94.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.084 | Acc: 61.788,84.397,94.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.092 | Acc: 61.781,84.284,94.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.098 | Acc: 61.765,84.231,94.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.101 | Acc: 61.801,84.100,94.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.108 | Acc: 61.624,83.968,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.116 | Acc: 61.583,83.877,94.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.984 | Acc: 50.781,65.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.203 | Acc: 50.856,65.885,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.253 | Acc: 50.610,65.606,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.275 | Acc: 50.871,65.535,70.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 1.936 | Acc: 67.969,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.056 | Acc: 62.872,85.751,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.025 | Acc: 63.205,85.690,95.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 63.115,85.400,95.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.023 | Acc: 62.944,85.272,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.023 | Acc: 62.879,85.156,95.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.023 | Acc: 62.707,85.092,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.031 | Acc: 62.688,84.990,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.038 | Acc: 62.505,84.749,95.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.048 | Acc: 62.219,84.612,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.052 | Acc: 62.197,84.507,95.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.059 | Acc: 62.125,84.396,95.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.062 | Acc: 62.150,84.343,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.072 | Acc: 61.967,84.207,95.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.077 | Acc: 61.936,84.141,94.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.078 | Acc: 61.960,84.097,94.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.083 | Acc: 61.991,84.003,94.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.084 | Acc: 62.090,83.997,94.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.094 | Acc: 62.048,83.869,94.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.101 | Acc: 61.938,83.811,94.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.167 | Acc: 53.906,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.318 | Acc: 52.567,64.732,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.357 | Acc: 51.886,64.863,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.340 | Acc: 52.369,65.164,69.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 2.302 | Acc: 61.719,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.079 | Acc: 62.463,84.412,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.055 | Acc: 62.805,85.023,94.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.029 | Acc: 62.551,85.451,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.029 | Acc: 62.519,85.359,95.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.044 | Acc: 62.461,85.025,95.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.049 | Acc: 62.429,84.995,95.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.052 | Acc: 62.361,84.901,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.063 | Acc: 62.253,84.715,94.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.047 | Acc: 62.504,84.863,94.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.043 | Acc: 62.457,84.989,94.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.047 | Acc: 62.277,84.849,94.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.054 | Acc: 62.127,84.706,94.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.065 | Acc: 62.051,84.620,94.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.073 | Acc: 61.972,84.489,94.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.076 | Acc: 61.942,84.404,94.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.080 | Acc: 61.974,84.338,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.083 | Acc: 62.033,84.258,94.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.089 | Acc: 62.020,84.198,94.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.098 | Acc: 61.844,84.080,94.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.305 | Acc: 52.344,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.281 | Acc: 52.976,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.290 | Acc: 52.268,64.920,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.301 | Acc: 52.164,65.228,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 2.130 | Acc: 57.031,90.625,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.081 | Acc: 61.086,84.449,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.058 | Acc: 61.852,85.347,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.055 | Acc: 61.872,84.939,95.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.056 | Acc: 62.230,84.877,95.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.033 | Acc: 62.523,85.319,95.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.040 | Acc: 62.636,85.150,95.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.045 | Acc: 62.533,85.018,95.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.045 | Acc: 62.607,84.972,95.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.055 | Acc: 62.591,84.833,95.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.062 | Acc: 62.434,84.604,95.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.064 | Acc: 62.352,84.605,95.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.072 | Acc: 62.312,84.488,95.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.077 | Acc: 62.261,84.486,95.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.073 | Acc: 62.317,84.486,94.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.077 | Acc: 62.287,84.367,94.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.080 | Acc: 62.259,84.292,94.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.086 | Acc: 62.195,84.130,94.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.091 | Acc: 62.117,84.074,94.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.100 | Acc: 62.026,84.002,94.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.005 | Acc: 54.688,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.198 | Acc: 52.939,66.927,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.234 | Acc: 52.915,66.197,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.267 | Acc: 52.754,66.176,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 2.229 | Acc: 63.281,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.054 | Acc: 61.979,84.449,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.025 | Acc: 62.462,85.099,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.011 | Acc: 62.615,85.694,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.011 | Acc: 62.625,85.407,95.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.016 | Acc: 62.438,85.179,95.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.009 | Acc: 62.313,85.324,95.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.023 | Acc: 62.090,85.045,95.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.030 | Acc: 61.879,85.025,95.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.031 | Acc: 61.978,85.048,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.031 | Acc: 62.111,84.970,95.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.026 | Acc: 62.168,84.976,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.023 | Acc: 62.234,85.010,95.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.033 | Acc: 62.099,84.884,95.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.035 | Acc: 62.097,84.892,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.048 | Acc: 62.077,84.681,95.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.066 | Acc: 61.960,84.429,94.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.080 | Acc: 61.815,84.276,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.090 | Acc: 61.747,84.161,94.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.098 | Acc: 61.729,84.035,94.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.000 | Acc: 59.375,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.117 | Acc: 54.464,66.518,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.140 | Acc: 52.954,66.330,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.154 | Acc: 52.587,66.009,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 2.296 | Acc: 64.062,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.018 | Acc: 63.504,86.086,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.011 | Acc: 62.824,85.823,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.031 | Acc: 62.334,85.182,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.040 | Acc: 62.066,85.118,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.042 | Acc: 62.020,85.017,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.044 | Acc: 62.003,84.975,95.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.041 | Acc: 61.974,85.145,95.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.043 | Acc: 62.044,85.113,95.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.048 | Acc: 62.038,84.837,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.050 | Acc: 61.995,84.771,95.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.051 | Acc: 61.984,84.796,95.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.055 | Acc: 62.036,84.702,95.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.060 | Acc: 62.105,84.579,95.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.060 | Acc: 62.077,84.589,94.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.065 | Acc: 62.041,84.455,94.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.073 | Acc: 61.955,84.380,94.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.084 | Acc: 61.854,84.240,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.092 | Acc: 61.725,84.193,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.097 | Acc: 61.711,84.129,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.828 | Acc: 53.906,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.141 | Acc: 53.385,66.815,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.144 | Acc: 52.763,66.444,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.194 | Acc: 52.459,66.470,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 1.969 | Acc: 65.625,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.051 | Acc: 61.830,85.491,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.026 | Acc: 62.367,85.194,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.024 | Acc: 62.769,85.131,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.003 | Acc: 63.050,85.320,95.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.998 | Acc: 63.065,85.404,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.005 | Acc: 62.958,85.415,95.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.013 | Acc: 62.827,85.228,95.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.022 | Acc: 62.544,85.117,95.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.026 | Acc: 62.431,84.966,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.030 | Acc: 62.383,84.919,95.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.038 | Acc: 62.397,84.767,95.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.040 | Acc: 62.351,84.702,95.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.047 | Acc: 62.219,84.668,95.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.056 | Acc: 62.122,84.531,94.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.065 | Acc: 62.041,84.442,94.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.074 | Acc: 61.955,84.290,94.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.085 | Acc: 61.776,84.155,94.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.090 | Acc: 61.775,84.109,94.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.098 | Acc: 61.723,84.004,94.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.621 | Acc: 58.594,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.964 | Acc: 54.799,67.485,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.016 | Acc: 54.821,66.482,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.045 | Acc: 54.854,66.176,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 2.091 | Acc: 64.844,81.250,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.895 | Acc: 64.993,86.272,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.952 | Acc: 63.262,85.995,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.943 | Acc: 63.448,86.194,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.954 | Acc: 63.137,86.053,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.948 | Acc: 63.281,86.030,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.946 | Acc: 63.191,86.080,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.954 | Acc: 63.198,85.938,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.949 | Acc: 63.301,86.015,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.952 | Acc: 63.204,85.877,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.960 | Acc: 63.118,85.801,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.976 | Acc: 62.924,85.648,95.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.985 | Acc: 62.899,85.506,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.996 | Acc: 62.775,85.390,95.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.013 | Acc: 62.642,85.173,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.021 | Acc: 62.567,85.032,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.035 | Acc: 62.490,84.847,95.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.047 | Acc: 62.395,84.691,94.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.058 | Acc: 62.292,84.524,94.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.068 | Acc: 62.250,84.348,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.026 | Acc: 55.469,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.339 | Acc: 52.009,66.815,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.290 | Acc: 51.944,66.635,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.302 | Acc: 51.844,66.227,69.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 1.849 | Acc: 61.719,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.016 | Acc: 64.286,85.007,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.020 | Acc: 63.605,85.004,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.026 | Acc: 63.115,84.721,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.028 | Acc: 62.857,84.780,95.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.033 | Acc: 62.485,84.831,95.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.029 | Acc: 62.519,84.872,95.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.021 | Acc: 62.705,84.940,95.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.019 | Acc: 62.835,84.933,95.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.020 | Acc: 62.932,84.902,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.017 | Acc: 62.966,84.923,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.030 | Acc: 62.800,84.785,95.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.037 | Acc: 62.604,84.654,95.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.047 | Acc: 62.458,84.576,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.055 | Acc: 62.389,84.464,95.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.066 | Acc: 62.313,84.333,94.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.072 | Acc: 62.269,84.231,94.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.074 | Acc: 62.292,84.180,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.076 | Acc: 62.288,84.146,94.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.081 | Acc: 62.231,84.145,94.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.646 | Acc: 53.906,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.459 | Acc: 50.967,65.365,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.481 | Acc: 50.495,64.615,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.487 | Acc: 50.615,64.588,69.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 2.232 | Acc: 58.594,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.127 | Acc: 62.388,83.743,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.082 | Acc: 62.919,84.432,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.078 | Acc: 62.654,84.465,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.066 | Acc: 62.442,84.664,95.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.040 | Acc: 62.601,84.855,95.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.033 | Acc: 62.461,85.021,95.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.031 | Acc: 62.511,85.145,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.033 | Acc: 62.529,85.083,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.034 | Acc: 62.526,85.001,95.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.040 | Acc: 62.457,84.950,95.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.046 | Acc: 62.394,84.824,95.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.045 | Acc: 62.429,84.845,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.047 | Acc: 62.368,84.743,95.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.056 | Acc: 62.250,84.581,95.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.058 | Acc: 62.269,84.448,95.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.059 | Acc: 62.242,84.463,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.062 | Acc: 62.312,84.402,94.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.066 | Acc: 62.323,84.325,94.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.074 | Acc: 62.215,84.215,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.112 | Acc: 52.344,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.180 | Acc: 53.348,65.811,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.169 | Acc: 53.335,65.511,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.209 | Acc: 53.266,65.356,70.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 2.455 | Acc: 57.812,81.250,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.054 | Acc: 61.682,85.007,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 62.062,84.661,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.028 | Acc: 62.026,84.439,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.021 | Acc: 62.220,84.645,95.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.009 | Acc: 62.090,84.986,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.999 | Acc: 62.229,85.169,95.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.007 | Acc: 62.229,85.156,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.003 | Acc: 62.534,85.326,95.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.016 | Acc: 62.418,85.221,95.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.021 | Acc: 62.345,85.168,95.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.029 | Acc: 62.355,85.008,95.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.032 | Acc: 62.442,84.936,95.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.033 | Acc: 62.431,84.962,95.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.035 | Acc: 62.405,84.920,95.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.039 | Acc: 62.474,84.808,95.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.047 | Acc: 62.410,84.691,94.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.051 | Acc: 62.443,84.604,94.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.057 | Acc: 62.383,84.492,94.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.065 | Acc: 62.301,84.391,94.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.332 | Acc: 52.344,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 52.902,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.316 | Acc: 52.039,66.063,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.378 | Acc: 51.793,65.407,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.076 | Acc: 60.938,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.989 | Acc: 64.323,85.714,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.989 | Acc: 63.491,86.052,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.976 | Acc: 63.448,86.066,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.960 | Acc: 63.474,86.372,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.959 | Acc: 63.134,86.386,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.958 | Acc: 63.094,86.241,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.972 | Acc: 62.810,85.976,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.981 | Acc: 62.723,85.889,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.984 | Acc: 62.629,85.843,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.994 | Acc: 62.519,85.677,95.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.994 | Acc: 62.723,85.531,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.004 | Acc: 62.510,85.351,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.004 | Acc: 62.578,85.315,95.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.012 | Acc: 62.558,85.204,95.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.014 | Acc: 62.542,85.167,95.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.012 | Acc: 62.583,85.137,95.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.016 | Acc: 62.573,85.030,95.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.024 | Acc: 62.506,84.929,95.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.028 | Acc: 62.537,84.849,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.102 | Acc: 56.250,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.443 | Acc: 53.013,64.769,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 51.696,65.492,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.464 | Acc: 51.550,64.575,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 1.708 | Acc: 67.188,88.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 63.579,87.016,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.981 | Acc: 63.148,85.957,95.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.982 | Acc: 62.961,85.822,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.963 | Acc: 62.895,86.044,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.950 | Acc: 63.111,86.162,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.949 | Acc: 63.146,86.041,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.954 | Acc: 63.037,85.987,95.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.965 | Acc: 62.757,85.933,95.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.974 | Acc: 62.655,85.782,95.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.984 | Acc: 62.543,85.545,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.988 | Acc: 62.624,85.527,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.995 | Acc: 62.623,85.393,95.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.005 | Acc: 62.530,85.339,95.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.011 | Acc: 62.494,85.190,95.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.015 | Acc: 62.435,85.143,95.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.024 | Acc: 62.417,85.037,95.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.029 | Acc: 62.440,84.973,95.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.040 | Acc: 62.409,84.829,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.049 | Acc: 62.287,84.678,94.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.123 | Acc: 49.219,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.228 | Acc: 50.967,66.220,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.213 | Acc: 51.315,66.311,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.226 | Acc: 51.819,66.009,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 1.668 | Acc: 67.188,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.939 | Acc: 65.365,86.049,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.948 | Acc: 64.253,85.880,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.974 | Acc: 63.614,85.630,95.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.983 | Acc: 63.349,85.407,95.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.989 | Acc: 63.119,85.373,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.990 | Acc: 63.042,85.298,95.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.991 | Acc: 63.076,85.245,95.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.993 | Acc: 63.048,85.142,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.998 | Acc: 62.940,85.191,95.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.997 | Acc: 63.040,85.265,95.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.999 | Acc: 63.016,85.209,95.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.008 | Acc: 62.808,85.159,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.011 | Acc: 62.760,85.129,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.017 | Acc: 62.720,84.998,95.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.021 | Acc: 62.721,84.980,95.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.028 | Acc: 62.670,84.859,95.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.030 | Acc: 62.692,84.831,95.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.041 | Acc: 62.522,84.667,94.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.047 | Acc: 62.492,84.586,94.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.010 | Acc: 57.812,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.165 | Acc: 54.129,66.704,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.202 | Acc: 52.973,66.311,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.250 | Acc: 53.087,66.009,70.056,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.289 | Acc: 60.938,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.040 | Acc: 61.979,85.938,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.982 | Acc: 62.919,86.357,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.976 | Acc: 62.833,86.117,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.967 | Acc: 63.002,86.092,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.968 | Acc: 62.995,85.783,95.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.966 | Acc: 62.939,85.821,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.974 | Acc: 63.060,85.710,95.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.986 | Acc: 62.781,85.472,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.992 | Acc: 62.785,85.519,95.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.997 | Acc: 62.768,85.386,95.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.000 | Acc: 62.705,85.432,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.004 | Acc: 62.779,85.357,95.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.007 | Acc: 62.841,85.246,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.011 | Acc: 62.792,85.217,95.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.019 | Acc: 62.783,85.128,95.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.025 | Acc: 62.658,85.052,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.029 | Acc: 62.695,84.929,95.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.031 | Acc: 62.662,84.823,95.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.038 | Acc: 62.603,84.746,94.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.958 | Acc: 54.688,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.331 | Acc: 52.567,64.993,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.328 | Acc: 52.820,65.415,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.336 | Acc: 53.163,65.202,70.056,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.403 | Acc: 60.938,83.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.998 | Acc: 62.351,85.417,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.951 | Acc: 63.338,85.633,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.952 | Acc: 63.486,85.707,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.962 | Acc: 63.281,85.774,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.968 | Acc: 63.018,85.659,95.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.960 | Acc: 63.359,85.750,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.973 | Acc: 63.143,85.666,95.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.973 | Acc: 62.961,85.700,95.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.972 | Acc: 62.996,85.722,95.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.976 | Acc: 62.916,85.665,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.980 | Acc: 62.931,85.549,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.985 | Acc: 62.970,85.493,95.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.989 | Acc: 63.018,85.441,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.999 | Acc: 62.970,85.267,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.999 | Acc: 62.962,85.221,95.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.003 | Acc: 62.970,85.156,95.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.012 | Acc: 62.869,85.039,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.017 | Acc: 62.760,84.948,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.024 | Acc: 62.656,84.810,95.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.897 | Acc: 52.344,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.121 | Acc: 54.613,65.848,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.135 | Acc: 54.611,65.987,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.165 | Acc: 54.790,65.856,70.902,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 1.974 | Acc: 57.031,86.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 63.653,86.086,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.964 | Acc: 63.205,86.166,95.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 63.179,86.219,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.949 | Acc: 63.291,86.343,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.949 | Acc: 63.343,86.224,95.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.957 | Acc: 63.197,86.028,95.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.961 | Acc: 63.254,85.871,95.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.971 | Acc: 63.155,85.734,95.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.973 | Acc: 63.225,85.679,95.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.969 | Acc: 63.301,85.693,95.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.978 | Acc: 63.200,85.478,95.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.990 | Acc: 63.080,85.205,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.997 | Acc: 62.967,85.120,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.005 | Acc: 62.881,85.023,95.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.014 | Acc: 62.814,84.956,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.016 | Acc: 62.790,84.947,95.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.017 | Acc: 62.894,84.902,95.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.025 | Acc: 62.835,84.819,94.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.030 | Acc: 62.853,84.760,94.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.231 | Acc: 54.688,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.515 | Acc: 50.818,64.174,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.536 | Acc: 51.162,62.995,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.531 | Acc: 50.973,63.499,69.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 1.859 | Acc: 65.625,86.719,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.951 | Acc: 64.695,85.417,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.917 | Acc: 64.615,86.319,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.910 | Acc: 64.524,86.411,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.927 | Acc: 63.947,86.246,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.926 | Acc: 63.861,86.247,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.923 | Acc: 63.733,86.196,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.926 | Acc: 63.702,86.192,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.924 | Acc: 63.674,86.297,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.936 | Acc: 63.562,86.089,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.951 | Acc: 63.433,85.875,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.959 | Acc: 63.324,85.775,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.974 | Acc: 63.142,85.604,95.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.985 | Acc: 63.045,85.524,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.988 | Acc: 62.973,85.490,95.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.992 | Acc: 63.042,85.390,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.002 | Acc: 62.970,85.317,95.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.007 | Acc: 62.933,85.259,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.011 | Acc: 62.946,85.226,95.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.021 | Acc: 62.844,85.105,94.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.694 | Acc: 46.094,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.835 | Acc: 46.540,64.509,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.833 | Acc: 46.284,64.463,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.841 | Acc: 46.516,64.139,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 1.886 | Acc: 63.281,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.948 | Acc: 62.574,86.496,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.923 | Acc: 63.815,86.204,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.909 | Acc: 63.909,86.527,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.928 | Acc: 63.715,86.362,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.940 | Acc: 63.769,86.216,95.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.944 | Acc: 63.649,86.151,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.956 | Acc: 63.420,86.021,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.950 | Acc: 63.524,86.166,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.954 | Acc: 63.601,86.067,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.966 | Acc: 63.437,85.899,95.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.976 | Acc: 63.288,85.718,95.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.989 | Acc: 63.171,85.548,95.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.992 | Acc: 63.185,85.521,95.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.997 | Acc: 63.220,85.329,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.005 | Acc: 63.162,85.135,95.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.009 | Acc: 63.164,85.088,95.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.011 | Acc: 63.187,85.014,95.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.019 | Acc: 63.093,84.942,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.026 | Acc: 63.013,84.847,94.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.918 | Acc: 51.562,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.301 | Acc: 52.753,65.737,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.353 | Acc: 52.001,64.596,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 52.139,64.447,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 2.006 | Acc: 64.844,89.062,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.053 | Acc: 61.682,85.938,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.979 | Acc: 62.633,86.242,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.968 | Acc: 63.051,86.219,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.962 | Acc: 63.214,86.082,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.965 | Acc: 63.196,85.953,95.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.967 | Acc: 63.159,85.905,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.970 | Acc: 63.087,85.821,95.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.978 | Acc: 62.976,85.719,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.974 | Acc: 63.147,85.752,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.970 | Acc: 63.223,85.891,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.966 | Acc: 63.225,85.952,95.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.967 | Acc: 63.281,85.892,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.975 | Acc: 63.165,85.683,95.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.982 | Acc: 63.123,85.532,95.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.986 | Acc: 63.118,85.390,95.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.995 | Acc: 62.996,85.297,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.998 | Acc: 62.977,85.227,95.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.003 | Acc: 62.957,85.178,95.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.010 | Acc: 62.847,85.050,95.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.632 | Acc: 55.469,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.350 | Acc: 51.897,65.848,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.329 | Acc: 52.001,65.301,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.329 | Acc: 51.716,65.407,70.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 1.824 | Acc: 60.938,86.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.938 | Acc: 63.802,86.496,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.937 | Acc: 64.062,86.147,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 63.640,85.797,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.962 | Acc: 63.561,85.812,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.976 | Acc: 63.274,85.845,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.984 | Acc: 63.255,85.679,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.984 | Acc: 63.231,85.433,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.994 | Acc: 63.189,85.365,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.992 | Acc: 63.134,85.355,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.990 | Acc: 63.270,85.261,95.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.994 | Acc: 63.211,85.146,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.998 | Acc: 63.275,85.004,95.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.005 | Acc: 63.096,84.950,95.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.006 | Acc: 63.123,84.906,94.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.013 | Acc: 63.076,84.840,94.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.020 | Acc: 62.962,84.840,94.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.021 | Acc: 63.098,84.819,94.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.028 | Acc: 63.000,84.704,94.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.036 | Acc: 62.888,84.613,94.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.094 | Acc: 50.781,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 52.567,62.463,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.499 | Acc: 52.782,63.129,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.476 | Acc: 52.856,63.422,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 1.990 | Acc: 60.938,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.008 | Acc: 63.021,85.231,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.997 | Acc: 62.786,85.385,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.973 | Acc: 63.012,85.771,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.969 | Acc: 63.455,85.648,95.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.972 | Acc: 63.513,85.729,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.974 | Acc: 63.475,85.511,95.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.988 | Acc: 63.259,85.367,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.987 | Acc: 63.291,85.321,95.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.989 | Acc: 63.134,85.294,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.989 | Acc: 63.184,85.285,95.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.995 | Acc: 62.984,85.291,95.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.998 | Acc: 63.006,85.215,95.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.002 | Acc: 62.901,85.183,95.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.003 | Acc: 62.828,85.112,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.007 | Acc: 62.723,85.058,95.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.008 | Acc: 62.782,85.022,95.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.015 | Acc: 62.720,84.900,95.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.020 | Acc: 62.675,84.827,94.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.029 | Acc: 62.582,84.818,94.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.701 | Acc: 57.812,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.196 | Acc: 53.460,64.993,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.190 | Acc: 53.468,65.454,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.236 | Acc: 53.099,65.702,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 2.060 | Acc: 58.594,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.028 | Acc: 62.277,85.714,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.986 | Acc: 63.186,85.747,94.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.944 | Acc: 63.922,86.155,95.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.951 | Acc: 64.053,85.986,95.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.949 | Acc: 63.900,86.046,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.954 | Acc: 63.623,86.028,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.949 | Acc: 63.603,86.059,95.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.955 | Acc: 63.451,85.894,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.955 | Acc: 63.337,85.847,95.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.963 | Acc: 63.277,85.623,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.968 | Acc: 63.136,85.584,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.971 | Acc: 63.213,85.503,95.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.974 | Acc: 63.335,85.489,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.973 | Acc: 63.434,85.495,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.982 | Acc: 63.372,85.387,95.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.990 | Acc: 63.327,85.280,95.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.001 | Acc: 63.219,85.147,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.009 | Acc: 63.138,85.042,95.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.018 | Acc: 63.144,84.939,94.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.928 | Acc: 49.219,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.389 | Acc: 49.070,65.290,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.380 | Acc: 49.771,65.473,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.433 | Acc: 49.769,65.190,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 2.287 | Acc: 60.156,81.250,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 63.393,86.347,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.930 | Acc: 63.624,86.452,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.912 | Acc: 63.704,86.450,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.907 | Acc: 64.140,86.680,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.920 | Acc: 63.614,86.463,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.928 | Acc: 63.598,86.222,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.926 | Acc: 63.713,86.237,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.934 | Acc: 63.655,86.010,95.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.952 | Acc: 63.424,85.899,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.963 | Acc: 63.406,85.658,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.964 | Acc: 63.557,85.648,95.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.964 | Acc: 63.592,85.610,95.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.961 | Acc: 63.599,85.725,95.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.962 | Acc: 63.568,85.648,95.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.971 | Acc: 63.473,85.546,95.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.980 | Acc: 63.405,85.443,95.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.986 | Acc: 63.322,85.360,95.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.992 | Acc: 63.273,85.241,95.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.998 | Acc: 63.230,85.128,95.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.974 | Acc: 57.812,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.427 | Acc: 51.302,63.616,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.387 | Acc: 51.429,64.215,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.379 | Acc: 51.550,64.203,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 2.109 | Acc: 59.375,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.893 | Acc: 65.439,87.054,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.913 | Acc: 64.653,86.452,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.912 | Acc: 64.664,86.399,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.908 | Acc: 64.709,86.545,95.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.912 | Acc: 64.426,86.510,95.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.915 | Acc: 64.340,86.538,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.907 | Acc: 64.378,86.602,95.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.914 | Acc: 64.465,86.360,95.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.916 | Acc: 64.451,86.391,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.925 | Acc: 64.043,86.350,95.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.937 | Acc: 63.857,86.181,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.945 | Acc: 63.852,85.993,95.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.955 | Acc: 63.655,85.881,95.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.961 | Acc: 63.615,85.746,95.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.971 | Acc: 63.554,85.652,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.976 | Acc: 63.564,85.614,95.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.985 | Acc: 63.483,85.493,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.994 | Acc: 63.351,85.401,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.001 | Acc: 63.283,85.281,95.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.353 | Acc: 57.031,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.999 | Acc: 56.213,67.634,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.017 | Acc: 55.526,67.035,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.052 | Acc: 55.251,66.931,71.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 1.843 | Acc: 64.844,87.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.887 | Acc: 65.067,86.570,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.876 | Acc: 65.187,86.795,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.914 | Acc: 64.088,86.616,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.915 | Acc: 64.226,86.584,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.919 | Acc: 64.171,86.417,95.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.919 | Acc: 64.237,86.428,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.918 | Acc: 64.168,86.469,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.921 | Acc: 64.048,86.413,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.917 | Acc: 64.153,86.490,95.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.929 | Acc: 64.047,86.353,95.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.925 | Acc: 64.165,86.305,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.933 | Acc: 64.033,86.275,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.935 | Acc: 64.015,86.135,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.938 | Acc: 63.962,86.107,95.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.941 | Acc: 63.904,86.057,95.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.944 | Acc: 63.875,86.013,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.955 | Acc: 63.765,85.828,95.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.964 | Acc: 63.682,85.712,95.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.974 | Acc: 63.613,85.515,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.540 | Acc: 52.344,75.781,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.146 | Acc: 53.311,66.295,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.161 | Acc: 53.392,66.406,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.208 | Acc: 53.291,65.740,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 1.900 | Acc: 61.719,86.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.022 | Acc: 62.240,85.007,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.980 | Acc: 63.415,84.851,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.977 | Acc: 63.256,84.951,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.965 | Acc: 63.465,85.204,95.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.972 | Acc: 63.575,85.118,95.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.986 | Acc: 63.326,84.963,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.984 | Acc: 63.237,85.123,95.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.983 | Acc: 63.242,85.035,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.985 | Acc: 63.217,84.940,95.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.992 | Acc: 63.099,84.771,95.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.995 | Acc: 63.165,84.810,95.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.989 | Acc: 63.213,84.871,95.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.993 | Acc: 63.215,84.890,95.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.991 | Acc: 63.340,84.898,95.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.004 | Acc: 63.188,84.676,94.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.014 | Acc: 63.060,84.582,94.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.016 | Acc: 62.977,84.586,94.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.015 | Acc: 63.026,84.600,94.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.014 | Acc: 63.136,84.605,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.851 | Acc: 54.688,76.562,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.252 | Acc: 52.827,66.704,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.267 | Acc: 52.896,66.044,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.280 | Acc: 52.818,65.702,70.223,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 1.768 | Acc: 66.406,88.281,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.986 | Acc: 63.616,86.086,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.970 | Acc: 63.338,85.880,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 63.832,85.925,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.943 | Acc: 64.198,86.275,95.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.932 | Acc: 64.527,86.494,95.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.934 | Acc: 64.424,86.312,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.942 | Acc: 64.229,86.209,95.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.938 | Acc: 64.184,86.200,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.939 | Acc: 64.041,86.110,95.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.949 | Acc: 63.926,85.899,95.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.961 | Acc: 63.780,85.828,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.968 | Acc: 63.845,85.655,95.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.979 | Acc: 63.829,85.521,95.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.988 | Acc: 63.715,85.409,94.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.001 | Acc: 63.564,85.234,94.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.010 | Acc: 63.486,85.100,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.018 | Acc: 63.334,85.014,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.025 | Acc: 63.227,84.894,94.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.027 | Acc: 63.300,84.855,94.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.461 | Acc: 59.375,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.179 | Acc: 54.315,65.662,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.199 | Acc: 54.249,65.663,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.255 | Acc: 54.188,65.228,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 2.001 | Acc: 60.156,87.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.996 | Acc: 63.765,85.454,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.973 | Acc: 63.910,85.518,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 63.576,85.822,95.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.952 | Acc: 63.696,86.024,95.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.941 | Acc: 63.823,86.123,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.942 | Acc: 63.707,86.176,95.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.945 | Acc: 63.813,86.159,95.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.954 | Acc: 63.480,86.078,95.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.964 | Acc: 63.290,85.938,95.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.963 | Acc: 63.367,85.836,95.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.964 | Acc: 63.490,85.785,95.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.973 | Acc: 63.330,85.633,95.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.979 | Acc: 63.311,85.533,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.988 | Acc: 63.256,85.320,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.993 | Acc: 63.273,85.273,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.996 | Acc: 63.349,85.224,94.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.996 | Acc: 63.359,85.200,94.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.999 | Acc: 63.366,85.102,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.004 | Acc: 63.302,85.021,94.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.804 | Acc: 57.031,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.366 | Acc: 51.972,64.062,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.418 | Acc: 50.610,64.444,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.461 | Acc: 50.743,63.922,70.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 1.740 | Acc: 66.406,87.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.933 | Acc: 62.909,86.830,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.962 | Acc: 62.386,86.185,94.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 62.743,86.066,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.960 | Acc: 62.953,85.880,95.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.960 | Acc: 63.065,85.945,95.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.961 | Acc: 63.133,86.034,95.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.962 | Acc: 63.032,86.054,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.956 | Acc: 63.276,86.088,95.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.956 | Acc: 63.299,86.132,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.963 | Acc: 63.223,85.941,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.966 | Acc: 63.334,85.782,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.965 | Acc: 63.359,85.785,95.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.967 | Acc: 63.431,85.725,95.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.974 | Acc: 63.356,85.735,95.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.977 | Acc: 63.323,85.709,95.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.982 | Acc: 63.225,85.660,95.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.987 | Acc: 63.215,85.585,94.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.991 | Acc: 63.229,85.487,94.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.998 | Acc: 63.226,85.378,94.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.686 | Acc: 51.562,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.247 | Acc: 52.679,65.811,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.247 | Acc: 52.839,65.930,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.243 | Acc: 53.023,65.663,70.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 2.054 | Acc: 64.062,89.844,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 63.690,85.231,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.956 | Acc: 63.929,85.804,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.931 | Acc: 64.331,86.066,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.950 | Acc: 63.831,85.909,95.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.941 | Acc: 63.977,85.891,95.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.946 | Acc: 63.785,85.899,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.941 | Acc: 63.846,85.904,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.939 | Acc: 63.703,85.928,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.934 | Acc: 63.791,85.981,95.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.941 | Acc: 63.612,85.938,95.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.947 | Acc: 63.575,85.803,95.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.943 | Acc: 63.615,85.866,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.940 | Acc: 63.694,85.866,95.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.942 | Acc: 63.715,85.815,95.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.942 | Acc: 63.707,85.860,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.946 | Acc: 63.646,85.782,95.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.953 | Acc: 63.520,85.750,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.958 | Acc: 63.470,85.669,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.963 | Acc: 63.400,85.564,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.596 | Acc: 57.812,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.059 | Acc: 54.911,67.188,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.039 | Acc: 54.802,66.787,72.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.056 | Acc: 54.777,66.752,71.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 1.809 | Acc: 61.719,85.156,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.875 | Acc: 65.402,87.128,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.885 | Acc: 64.634,86.509,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.872 | Acc: 64.588,87.001,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.859 | Acc: 64.497,87.220,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.864 | Acc: 64.186,87.067,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.867 | Acc: 64.037,86.841,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.876 | Acc: 64.085,86.674,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.887 | Acc: 63.961,86.515,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.891 | Acc: 64.114,86.499,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.901 | Acc: 63.888,86.381,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.910 | Acc: 63.808,86.309,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.915 | Acc: 63.635,86.307,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.931 | Acc: 63.374,86.159,95.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.934 | Acc: 63.354,86.132,95.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.945 | Acc: 63.289,85.958,95.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.948 | Acc: 63.286,85.899,95.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.952 | Acc: 63.242,85.814,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.956 | Acc: 63.225,85.725,95.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.961 | Acc: 63.218,85.704,95.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.029 | Acc: 56.250,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.273 | Acc: 51.339,64.546,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.313 | Acc: 51.867,64.691,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.335 | Acc: 51.614,65.010,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.086 | Acc: 63.281,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.890 | Acc: 64.323,86.644,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.857 | Acc: 64.596,86.871,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.866 | Acc: 64.575,86.732,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.875 | Acc: 64.593,86.680,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.870 | Acc: 64.581,86.850,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.863 | Acc: 64.902,86.977,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.871 | Acc: 64.511,86.924,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.877 | Acc: 64.436,86.942,95.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.884 | Acc: 64.270,86.853,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.895 | Acc: 64.214,86.676,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.907 | Acc: 63.999,86.528,95.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.914 | Acc: 63.978,86.320,95.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.925 | Acc: 63.910,86.105,95.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.936 | Acc: 63.871,85.954,95.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.941 | Acc: 63.873,85.826,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.950 | Acc: 63.831,85.694,95.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.954 | Acc: 63.831,85.614,95.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.961 | Acc: 63.805,85.537,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.974 | Acc: 63.708,85.365,94.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.115 | Acc: 57.031,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.166 | Acc: 52.902,64.472,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.230 | Acc: 52.915,64.539,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.239 | Acc: 53.151,64.062,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 2.072 | Acc: 65.625,83.594,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.014 | Acc: 62.574,85.454,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.940 | Acc: 64.405,86.033,94.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.933 | Acc: 64.331,86.040,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.925 | Acc: 64.419,86.179,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.931 | Acc: 64.225,86.162,95.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.929 | Acc: 64.030,86.209,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.929 | Acc: 63.880,86.159,95.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.930 | Acc: 63.931,86.088,95.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.930 | Acc: 64.067,85.972,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.931 | Acc: 64.202,85.996,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.933 | Acc: 64.253,85.987,95.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.934 | Acc: 64.335,85.947,95.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.931 | Acc: 64.371,85.914,95.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.938 | Acc: 64.254,85.860,95.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.943 | Acc: 64.073,85.769,95.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.949 | Acc: 64.009,85.731,95.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.954 | Acc: 64.005,85.674,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.965 | Acc: 63.781,85.554,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.972 | Acc: 63.720,85.443,95.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.215 | Acc: 57.812,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.326 | Acc: 51.637,65.290,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.289 | Acc: 51.734,65.434,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.314 | Acc: 51.998,65.894,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 1.934 | Acc: 64.844,87.500,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.839 | Acc: 65.253,87.426,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.894 | Acc: 64.520,86.757,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.908 | Acc: 64.114,86.719,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.911 | Acc: 64.284,86.671,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.917 | Acc: 64.225,86.433,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.911 | Acc: 64.321,86.570,95.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.911 | Acc: 64.262,86.442,95.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.911 | Acc: 64.281,86.505,95.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.913 | Acc: 64.170,86.507,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.920 | Acc: 64.062,86.416,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.926 | Acc: 64.009,86.266,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.929 | Acc: 64.020,86.223,95.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.930 | Acc: 64.024,86.186,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.931 | Acc: 63.929,86.068,95.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.931 | Acc: 64.005,85.979,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.942 | Acc: 63.934,85.774,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.949 | Acc: 63.872,85.757,95.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.952 | Acc: 63.837,85.667,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.957 | Acc: 63.759,85.556,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.872 | Acc: 53.906,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.111 | Acc: 54.278,66.034,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.144 | Acc: 53.639,66.006,71.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.161 | Acc: 53.496,65.996,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.138 | Acc: 59.375,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.854 | Acc: 65.365,87.277,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.890 | Acc: 64.520,86.662,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.897 | Acc: 64.011,86.834,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.914 | Acc: 63.870,86.410,95.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.924 | Acc: 63.683,86.378,95.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.937 | Acc: 63.733,86.222,95.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.936 | Acc: 63.658,86.226,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.938 | Acc: 63.713,86.180,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.935 | Acc: 63.713,86.192,95.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.935 | Acc: 63.592,86.144,95.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.932 | Acc: 63.674,86.054,95.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.925 | Acc: 63.790,86.093,95.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.934 | Acc: 63.688,86.030,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.942 | Acc: 63.556,85.918,95.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.947 | Acc: 63.481,85.870,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.955 | Acc: 63.393,85.726,95.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.961 | Acc: 63.364,85.644,95.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.964 | Acc: 63.411,85.611,95.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.971 | Acc: 63.310,85.478,95.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.963 | Acc: 53.125,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.394 | Acc: 51.711,65.551,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.384 | Acc: 51.753,66.159,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.427 | Acc: 51.870,65.984,71.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 2.370 | Acc: 59.375,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.917 | Acc: 64.100,86.868,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.926 | Acc: 63.872,86.776,95.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.922 | Acc: 64.101,86.347,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.919 | Acc: 64.381,86.429,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.917 | Acc: 64.333,86.255,95.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.925 | Acc: 64.011,86.196,95.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.931 | Acc: 63.669,86.192,95.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.920 | Acc: 63.864,86.418,95.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.915 | Acc: 63.998,86.451,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.912 | Acc: 64.144,86.365,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.921 | Acc: 63.967,86.312,95.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.923 | Acc: 63.972,86.262,95.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.920 | Acc: 64.083,86.183,95.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.924 | Acc: 64.121,86.063,95.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.931 | Acc: 64.096,85.922,95.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.934 | Acc: 64.126,85.821,95.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.948 | Acc: 64.049,85.626,95.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.956 | Acc: 63.982,85.448,95.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.964 | Acc: 63.898,85.335,95.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.171 | Acc: 53.906,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.393 | Acc: 51.079,65.662,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.440 | Acc: 50.591,64.806,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.452 | Acc: 50.256,64.728,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 1.995 | Acc: 63.281,89.062,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.873 | Acc: 64.881,86.644,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.835 | Acc: 65.473,87.290,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.837 | Acc: 65.356,87.308,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.836 | Acc: 65.249,87.355,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.841 | Acc: 65.231,87.276,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.842 | Acc: 65.160,87.190,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.855 | Acc: 64.905,87.046,95.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.858 | Acc: 64.955,87.015,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.872 | Acc: 64.693,86.887,95.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.883 | Acc: 64.506,86.758,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.899 | Acc: 64.473,86.528,95.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.910 | Acc: 64.338,86.421,95.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.909 | Acc: 64.374,86.428,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.916 | Acc: 64.310,86.407,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.927 | Acc: 64.262,86.278,95.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.931 | Acc: 64.177,86.208,95.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.950 | Acc: 63.994,85.965,95.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.965 | Acc: 63.811,85.821,95.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.969 | Acc: 63.759,85.734,94.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.894 | Acc: 60.156,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.106 | Acc: 54.799,65.960,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.134 | Acc: 54.230,66.330,71.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.155 | Acc: 54.150,66.099,71.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 1.842 | Acc: 63.281,89.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.874 | Acc: 64.918,86.942,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.872 | Acc: 65.072,86.986,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.886 | Acc: 65.126,86.655,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.870 | Acc: 65.172,86.921,95.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.867 | Acc: 64.998,86.974,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.860 | Acc: 65.037,87.158,96.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.863 | Acc: 64.927,87.129,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.862 | Acc: 64.970,87.039,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.863 | Acc: 64.960,86.991,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.866 | Acc: 64.797,87.061,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.881 | Acc: 64.572,86.839,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.895 | Acc: 64.383,86.706,95.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.902 | Acc: 64.314,86.536,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.910 | Acc: 64.196,86.407,95.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.918 | Acc: 64.187,86.215,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.922 | Acc: 64.221,86.181,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.933 | Acc: 64.131,86.029,95.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.944 | Acc: 63.969,85.860,95.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.948 | Acc: 63.944,85.843,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.978 | Acc: 52.344,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.251 | Acc: 53.162,64.397,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.266 | Acc: 52.344,64.386,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.217 | Acc: 52.984,65.061,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 2.119 | Acc: 60.938,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.985 | Acc: 61.644,85.751,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.927 | Acc: 62.957,86.319,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.919 | Acc: 63.243,86.386,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.929 | Acc: 63.358,85.976,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.917 | Acc: 63.459,86.255,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.910 | Acc: 63.623,86.163,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.904 | Acc: 64.002,86.165,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.900 | Acc: 64.092,86.248,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.905 | Acc: 64.110,86.123,95.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.915 | Acc: 63.981,86.066,95.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.920 | Acc: 63.971,85.976,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.932 | Acc: 63.784,85.876,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.937 | Acc: 63.733,85.866,95.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.942 | Acc: 63.746,85.776,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.951 | Acc: 63.603,85.717,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.959 | Acc: 63.639,85.589,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.966 | Acc: 63.618,85.516,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.971 | Acc: 63.541,85.470,95.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.978 | Acc: 63.501,85.333,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.103 | Acc: 52.344,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.403 | Acc: 50.484,64.769,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.440 | Acc: 50.819,64.825,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.435 | Acc: 51.178,64.972,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.334 | Acc: 60.938,82.812,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.929 | Acc: 64.769,86.458,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.961 | Acc: 64.101,86.147,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.935 | Acc: 64.255,86.078,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.934 | Acc: 64.313,86.063,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.925 | Acc: 64.078,86.185,95.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.906 | Acc: 64.211,86.428,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.908 | Acc: 64.068,86.331,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.912 | Acc: 64.135,86.258,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.904 | Acc: 64.386,86.386,95.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.902 | Acc: 64.490,86.419,95.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.913 | Acc: 64.338,86.234,95.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.917 | Acc: 64.218,86.213,95.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.915 | Acc: 64.311,86.168,95.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.923 | Acc: 64.060,86.071,95.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.930 | Acc: 64.068,85.927,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.934 | Acc: 64.043,85.957,95.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.940 | Acc: 63.909,85.853,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.944 | Acc: 63.861,85.728,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.946 | Acc: 63.972,85.689,95.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.897 | Acc: 54.688,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.108 | Acc: 54.055,66.592,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.161 | Acc: 53.944,65.644,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.139 | Acc: 54.226,65.932,71.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 1.908 | Acc: 69.531,88.281,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.847 | Acc: 65.737,87.760,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.822 | Acc: 65.987,87.576,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.818 | Acc: 65.945,87.654,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.818 | Acc: 65.770,87.674,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.823 | Acc: 65.695,87.546,96.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.837 | Acc: 65.470,87.306,96.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.838 | Acc: 65.370,87.312,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.849 | Acc: 65.086,87.228,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.853 | Acc: 65.159,87.077,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.864 | Acc: 65.069,86.936,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.867 | Acc: 65.077,86.846,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.869 | Acc: 65.110,86.797,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.884 | Acc: 64.937,86.572,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.899 | Acc: 64.694,86.471,95.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.908 | Acc: 64.595,86.322,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.913 | Acc: 64.449,86.195,95.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.913 | Acc: 64.567,86.135,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.922 | Acc: 64.428,86.020,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.933 | Acc: 64.354,85.855,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.023 | Acc: 53.125,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.646 | Acc: 48.958,64.062,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.679 | Acc: 48.304,64.215,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.663 | Acc: 48.860,64.511,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 1.858 | Acc: 68.750,88.281,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.930 | Acc: 64.881,86.458,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.873 | Acc: 65.492,87.100,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.889 | Acc: 65.061,86.949,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.894 | Acc: 64.892,86.786,95.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.901 | Acc: 64.728,86.703,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.903 | Acc: 64.657,86.564,95.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.898 | Acc: 64.567,86.569,95.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.898 | Acc: 64.582,86.481,95.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.899 | Acc: 64.460,86.507,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.908 | Acc: 64.276,86.400,95.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.915 | Acc: 64.179,86.323,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.923 | Acc: 64.150,86.232,95.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.928 | Acc: 64.119,86.141,95.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.940 | Acc: 63.960,85.979,95.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.947 | Acc: 63.915,85.886,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.958 | Acc: 63.834,85.762,95.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.962 | Acc: 63.863,85.656,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.971 | Acc: 63.785,85.578,95.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.983 | Acc: 63.724,85.435,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.775 | Acc: 59.375,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 53.423,65.179,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.344 | Acc: 52.649,64.977,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.377 | Acc: 52.497,65.010,68.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 1.833 | Acc: 68.750,88.281,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.878 | Acc: 65.290,87.054,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.874 | Acc: 65.644,86.738,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.881 | Acc: 65.100,86.834,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.876 | Acc: 64.979,87.008,95.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.871 | Acc: 64.906,87.191,95.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.878 | Acc: 64.792,87.087,95.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.871 | Acc: 64.822,87.051,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.874 | Acc: 64.688,87.020,95.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.881 | Acc: 64.447,86.835,95.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.884 | Acc: 64.471,86.699,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.892 | Acc: 64.398,86.574,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.890 | Acc: 64.406,86.557,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.892 | Acc: 64.338,86.521,95.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.905 | Acc: 64.232,86.363,95.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.907 | Acc: 64.231,86.371,95.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.916 | Acc: 64.191,86.259,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.925 | Acc: 64.072,86.169,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.927 | Acc: 64.110,86.095,95.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.935 | Acc: 64.024,86.052,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.985 | Acc: 56.250,71.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.258 | Acc: 52.083,64.955,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.327 | Acc: 51.582,65.015,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.330 | Acc: 52.216,64.882,70.120,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 1.766 | Acc: 70.312,85.156,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.825 | Acc: 66.815,86.979,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.792 | Acc: 66.654,87.881,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.813 | Acc: 66.304,87.474,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.822 | Acc: 65.818,87.365,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.839 | Acc: 65.408,87.160,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.848 | Acc: 65.238,86.977,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.861 | Acc: 64.971,86.990,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.866 | Acc: 64.718,86.942,95.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.876 | Acc: 64.555,86.861,95.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.881 | Acc: 64.440,86.746,95.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.889 | Acc: 64.409,86.627,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.898 | Acc: 64.364,86.482,95.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.904 | Acc: 64.365,86.413,95.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.902 | Acc: 64.432,86.413,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.909 | Acc: 64.325,86.366,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.914 | Acc: 64.289,86.259,95.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.919 | Acc: 64.253,86.183,95.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.928 | Acc: 64.145,86.095,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.941 | Acc: 63.972,85.964,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.090 | Acc: 51.562,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.431 | Acc: 49.814,65.141,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.421 | Acc: 49.524,65.568,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.436 | Acc: 49.360,65.356,69.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 1.918 | Acc: 62.500,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.924 | Acc: 64.844,86.384,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.897 | Acc: 64.177,86.719,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.878 | Acc: 64.421,87.013,94.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.870 | Acc: 64.497,87.114,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.861 | Acc: 64.434,87.013,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.850 | Acc: 64.650,87.080,95.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.844 | Acc: 64.833,87.140,95.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.848 | Acc: 64.781,87.117,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.853 | Acc: 64.770,87.112,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.869 | Acc: 64.568,86.824,95.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.876 | Acc: 64.660,86.729,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.876 | Acc: 64.711,86.693,95.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.886 | Acc: 64.631,86.491,95.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.891 | Acc: 64.510,86.452,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.896 | Acc: 64.408,86.361,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.904 | Acc: 64.228,86.295,95.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.911 | Acc: 64.138,86.222,95.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.917 | Acc: 64.054,86.137,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.928 | Acc: 63.937,86.013,95.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.754 | Acc: 53.906,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.256 | Acc: 52.679,65.960,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.247 | Acc: 52.763,66.654,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.279 | Acc: 53.010,66.611,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 2.098 | Acc: 62.500,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.889 | Acc: 64.509,86.347,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.845 | Acc: 64.787,86.833,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.835 | Acc: 65.049,87.372,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.849 | Acc: 64.516,87.278,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.845 | Acc: 64.534,87.330,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.850 | Acc: 64.418,87.371,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.869 | Acc: 64.157,87.212,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.867 | Acc: 64.359,87.223,96.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.868 | Acc: 64.343,87.055,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.871 | Acc: 64.300,87.084,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.877 | Acc: 64.352,86.991,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.881 | Acc: 64.448,86.891,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.888 | Acc: 64.506,86.758,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.894 | Acc: 64.432,86.674,95.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.903 | Acc: 64.252,86.527,95.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.911 | Acc: 64.182,86.397,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.914 | Acc: 64.156,86.352,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.922 | Acc: 64.000,86.189,95.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.930 | Acc: 63.898,86.046,95.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.081 | Acc: 47.656,67.188,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.346 | Acc: 51.153,65.625,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.387 | Acc: 50.857,65.587,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.372 | Acc: 50.935,65.663,70.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 1.934 | Acc: 67.188,87.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.894 | Acc: 64.435,86.979,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.897 | Acc: 64.043,86.433,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.880 | Acc: 64.101,87.039,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.878 | Acc: 64.323,87.047,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.871 | Acc: 64.356,86.912,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.872 | Acc: 64.153,86.951,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.879 | Acc: 64.007,86.891,95.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.893 | Acc: 63.878,86.753,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.898 | Acc: 63.985,86.568,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.905 | Acc: 64.028,86.408,95.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.920 | Acc: 63.773,86.220,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.924 | Acc: 63.787,86.171,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.927 | Acc: 63.871,86.069,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.933 | Acc: 63.796,85.949,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.936 | Acc: 63.831,85.834,95.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.942 | Acc: 63.882,85.650,95.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.945 | Acc: 63.882,85.582,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.950 | Acc: 63.831,85.515,95.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.956 | Acc: 63.794,85.452,95.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.135 | Acc: 50.781,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.616 | Acc: 48.438,64.286,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.650 | Acc: 48.266,63.872,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.670 | Acc: 48.566,63.371,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 2.015 | Acc: 66.406,84.375,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.895 | Acc: 64.137,85.826,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.897 | Acc: 64.139,85.652,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.899 | Acc: 64.255,85.925,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.877 | Acc: 64.786,86.439,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.885 | Acc: 64.558,86.324,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.880 | Acc: 64.611,86.402,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.870 | Acc: 64.777,86.580,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.874 | Acc: 64.621,86.462,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.884 | Acc: 64.369,86.430,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.881 | Acc: 64.440,86.532,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.885 | Acc: 64.285,86.549,95.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.889 | Acc: 64.286,86.456,95.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.892 | Acc: 64.320,86.416,95.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.899 | Acc: 64.285,86.307,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.901 | Acc: 64.330,86.278,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.904 | Acc: 64.316,86.278,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.909 | Acc: 64.296,86.187,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.911 | Acc: 64.352,86.193,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.918 | Acc: 64.294,86.136,95.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.754 | Acc: 56.250,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.413 | Acc: 52.269,63.579,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.354 | Acc: 52.363,64.291,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.383 | Acc: 51.921,64.434,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 1.635 | Acc: 67.969,92.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.856 | Acc: 65.104,87.351,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.848 | Acc: 64.939,87.290,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.828 | Acc: 64.818,87.871,96.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.824 | Acc: 64.660,87.886,96.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.796 | Acc: 65.254,88.026,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.814 | Acc: 65.012,87.778,96.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.817 | Acc: 64.999,87.788,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.816 | Acc: 65.077,87.694,96.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.823 | Acc: 64.917,87.673,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.827 | Acc: 64.848,87.434,96.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.832 | Acc: 64.826,87.334,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.840 | Acc: 64.724,87.224,96.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.843 | Acc: 64.700,87.183,96.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.848 | Acc: 64.688,87.130,96.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.857 | Acc: 64.592,87.020,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.868 | Acc: 64.503,86.901,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.879 | Acc: 64.422,86.762,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.889 | Acc: 64.327,86.600,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.896 | Acc: 64.274,86.520,95.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.832 | Acc: 56.250,75.000,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.491 | Acc: 50.893,64.881,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.512 | Acc: 50.686,64.386,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.531 | Acc: 51.114,64.319,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 1.951 | Acc: 64.844,85.938,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.874 | Acc: 65.290,86.607,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.873 | Acc: 64.939,86.623,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.864 | Acc: 65.497,86.885,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.870 | Acc: 65.268,86.671,95.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.859 | Acc: 65.246,86.843,95.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.852 | Acc: 65.315,86.925,95.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.858 | Acc: 65.032,86.708,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.860 | Acc: 64.951,86.670,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.860 | Acc: 64.852,86.641,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.867 | Acc: 64.747,86.579,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.873 | Acc: 64.738,86.485,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.879 | Acc: 64.734,86.414,95.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.882 | Acc: 64.781,86.422,95.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.894 | Acc: 64.599,86.338,95.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.895 | Acc: 64.589,86.376,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.898 | Acc: 64.540,86.378,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.903 | Acc: 64.514,86.332,95.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.910 | Acc: 64.411,86.210,95.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.921 | Acc: 64.360,86.073,95.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.645 | Acc: 56.250,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 52.902,65.811,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.314 | Acc: 52.572,66.101,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.323 | Acc: 52.369,66.214,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 1.603 | Acc: 65.625,91.406,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.779 | Acc: 65.290,88.021,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.798 | Acc: 65.530,88.072,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.793 | Acc: 65.459,88.064,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.794 | Acc: 65.538,87.953,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.801 | Acc: 65.687,87.825,96.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.811 | Acc: 65.192,87.778,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.828 | Acc: 64.999,87.544,96.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.830 | Acc: 65.096,87.456,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.841 | Acc: 65.003,87.366,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.849 | Acc: 64.964,87.174,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.858 | Acc: 64.819,87.093,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.865 | Acc: 64.789,86.907,95.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.874 | Acc: 64.739,86.749,95.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.886 | Acc: 64.543,86.577,95.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.894 | Acc: 64.449,86.488,95.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.898 | Acc: 64.462,86.400,95.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.904 | Acc: 64.468,86.322,95.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.906 | Acc: 64.506,86.308,95.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.914 | Acc: 64.415,86.186,95.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.806 | Acc: 56.250,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.240 | Acc: 53.497,67.039,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.263 | Acc: 53.563,66.216,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.282 | Acc: 53.496,65.727,70.133,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 1.812 | Acc: 64.844,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.910 | Acc: 64.360,86.161,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.906 | Acc: 63.834,86.338,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.885 | Acc: 64.293,86.655,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.889 | Acc: 63.908,86.651,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.870 | Acc: 64.503,86.928,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.872 | Acc: 64.573,86.971,95.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.865 | Acc: 64.639,87.057,95.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.868 | Acc: 64.708,87.000,95.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.874 | Acc: 64.585,86.900,95.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.873 | Acc: 64.715,86.878,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.881 | Acc: 64.731,86.768,95.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.885 | Acc: 64.617,86.670,95.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.890 | Acc: 64.622,86.527,95.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.901 | Acc: 64.482,86.391,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.906 | Acc: 64.478,86.381,95.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.907 | Acc: 64.488,86.395,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.909 | Acc: 64.431,86.357,95.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.912 | Acc: 64.480,86.318,95.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.923 | Acc: 64.362,86.136,95.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.127 | Acc: 53.906,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.226 | Acc: 53.795,65.923,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.282 | Acc: 53.316,65.587,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.276 | Acc: 53.343,65.292,70.812,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 1.928 | Acc: 60.938,87.500,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.921 | Acc: 63.914,86.235,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.913 | Acc: 63.834,86.433,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.879 | Acc: 64.460,86.962,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.861 | Acc: 64.400,87.211,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.860 | Acc: 64.279,87.183,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.840 | Acc: 64.715,87.306,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.836 | Acc: 64.811,87.345,96.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.842 | Acc: 64.688,87.214,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.840 | Acc: 64.839,87.155,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.844 | Acc: 64.953,87.123,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.854 | Acc: 64.812,86.984,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.864 | Acc: 64.776,86.858,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.869 | Acc: 64.706,86.794,95.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.876 | Acc: 64.624,86.744,95.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.885 | Acc: 64.600,86.631,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.894 | Acc: 64.467,86.541,95.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.909 | Acc: 64.289,86.382,95.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.914 | Acc: 64.205,86.273,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.920 | Acc: 64.175,86.175,95.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.120 | Acc: 53.125,61.719,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.258 | Acc: 54.167,64.174,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.247 | Acc: 53.792,64.768,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.247 | Acc: 54.431,64.767,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 1.754 | Acc: 65.625,90.625,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.799 | Acc: 65.662,88.653,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.795 | Acc: 65.720,88.034,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.779 | Acc: 65.574,87.961,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.797 | Acc: 65.249,87.915,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.806 | Acc: 65.138,87.864,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.812 | Acc: 65.154,87.732,96.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.812 | Acc: 65.176,87.627,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.825 | Acc: 65.096,87.485,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.835 | Acc: 65.146,87.228,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.851 | Acc: 64.894,86.917,95.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.867 | Acc: 64.727,86.768,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.871 | Acc: 64.672,86.677,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.874 | Acc: 64.760,86.623,95.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.880 | Acc: 64.705,86.524,95.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.885 | Acc: 64.670,86.433,95.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.893 | Acc: 64.578,86.327,95.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.897 | Acc: 64.594,86.256,95.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.910 | Acc: 64.536,86.106,95.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.916 | Acc: 64.491,86.022,95.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.664 | Acc: 57.812,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.258 | Acc: 53.646,66.890,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.320 | Acc: 52.858,66.159,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.318 | Acc: 53.343,65.715,69.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 2.082 | Acc: 59.375,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.882 | Acc: 65.030,85.751,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.848 | Acc: 65.263,86.719,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.831 | Acc: 65.036,87.154,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.840 | Acc: 64.853,87.191,95.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.847 | Acc: 64.782,87.183,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.845 | Acc: 64.863,87.145,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.869 | Acc: 64.478,86.796,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.876 | Acc: 64.300,86.651,95.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.870 | Acc: 64.580,86.598,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.871 | Acc: 64.657,86.664,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.884 | Acc: 64.441,86.560,95.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.885 | Acc: 64.419,86.612,95.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.888 | Acc: 64.497,86.557,95.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.889 | Acc: 64.543,86.555,95.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.888 | Acc: 64.602,86.524,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.891 | Acc: 64.603,86.492,95.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.893 | Acc: 64.589,86.437,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.899 | Acc: 64.580,86.277,95.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.911 | Acc: 64.528,86.073,95.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.996 | Acc: 57.812,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.214 | Acc: 53.757,66.667,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.243 | Acc: 53.678,66.063,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.257 | Acc: 53.932,65.804,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 1.933 | Acc: 60.938,85.156,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.807 | Acc: 66.034,86.644,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.813 | Acc: 66.006,87.348,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.804 | Acc: 66.432,87.756,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.805 | Acc: 65.876,87.895,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.808 | Acc: 65.455,87.887,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.807 | Acc: 65.438,87.823,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.815 | Acc: 65.337,87.611,96.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.813 | Acc: 65.533,87.655,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.816 | Acc: 65.582,87.526,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.827 | Acc: 65.380,87.473,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.832 | Acc: 65.289,87.443,95.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.841 | Acc: 65.090,87.348,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.844 | Acc: 65.020,87.207,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.845 | Acc: 65.013,87.200,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.851 | Acc: 64.971,87.043,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.858 | Acc: 64.919,87.016,95.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.867 | Acc: 64.890,86.918,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.877 | Acc: 64.803,86.766,95.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.883 | Acc: 64.708,86.665,95.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.995 | Acc: 57.031,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.420 | Acc: 51.488,65.997,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.414 | Acc: 51.277,66.311,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.454 | Acc: 51.806,66.073,69.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 1.823 | Acc: 65.625,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.796 | Acc: 66.667,87.091,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.797 | Acc: 65.892,87.233,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.798 | Acc: 65.817,87.474,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.797 | Acc: 65.683,87.616,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.811 | Acc: 65.370,87.415,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.828 | Acc: 65.076,87.229,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.841 | Acc: 64.822,87.134,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.855 | Acc: 64.674,87.044,95.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.870 | Acc: 64.455,86.796,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.877 | Acc: 64.428,86.754,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.885 | Acc: 64.511,86.648,95.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.896 | Acc: 64.312,86.443,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.899 | Acc: 64.353,86.354,95.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.902 | Acc: 64.341,86.246,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.909 | Acc: 64.257,86.215,95.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.910 | Acc: 64.338,86.200,95.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.918 | Acc: 64.179,86.114,95.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.925 | Acc: 64.123,86.013,95.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.928 | Acc: 64.134,85.950,95.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.891 | Acc: 53.906,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.281 | Acc: 53.981,66.332,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.309 | Acc: 53.735,65.987,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.334 | Acc: 53.791,65.907,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 2.065 | Acc: 62.500,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.996 | Acc: 64.137,84.561,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.923 | Acc: 64.348,85.709,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.891 | Acc: 64.690,86.078,95.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.872 | Acc: 64.738,86.574,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.878 | Acc: 64.867,86.363,95.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.881 | Acc: 64.934,86.377,95.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.883 | Acc: 64.910,86.320,95.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.882 | Acc: 64.975,86.093,95.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.889 | Acc: 64.861,86.097,95.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.888 | Acc: 64.836,86.085,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.878 | Acc: 64.985,86.277,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.879 | Acc: 64.957,86.190,95.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.882 | Acc: 64.946,86.174,95.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.888 | Acc: 64.877,86.093,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.896 | Acc: 64.857,86.023,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.905 | Acc: 64.737,85.903,95.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.912 | Acc: 64.612,85.791,95.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.916 | Acc: 64.578,85.799,95.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.925 | Acc: 64.440,85.650,94.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.315 | Acc: 47.656,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 49.963,65.439,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.495 | Acc: 50.038,64.710,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.473 | Acc: 50.000,64.959,70.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 1.962 | Acc: 66.406,85.938,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.853 | Acc: 65.327,87.463,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.803 | Acc: 66.101,87.500,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.809 | Acc: 65.433,87.513,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.817 | Acc: 65.384,87.558,96.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.816 | Acc: 65.200,87.670,96.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.814 | Acc: 65.147,87.661,96.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.806 | Acc: 65.259,87.794,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.817 | Acc: 65.106,87.752,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.823 | Acc: 65.047,87.565,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.831 | Acc: 64.894,87.449,96.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.834 | Acc: 64.904,87.390,96.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.840 | Acc: 64.821,87.263,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.840 | Acc: 64.889,87.270,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.846 | Acc: 64.791,87.219,95.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.854 | Acc: 64.667,87.072,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.862 | Acc: 64.600,86.999,95.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.878 | Acc: 64.438,86.817,95.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.886 | Acc: 64.417,86.697,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.892 | Acc: 64.423,86.563,95.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.718 | Acc: 58.594,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.189 | Acc: 54.501,66.592,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.166 | Acc: 54.154,66.806,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.142 | Acc: 54.406,66.726,71.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 1.854 | Acc: 64.844,85.938,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.915 | Acc: 62.612,86.719,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.848 | Acc: 64.482,87.595,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.824 | Acc: 64.639,87.602,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.828 | Acc: 64.525,87.587,96.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.835 | Acc: 64.496,87.577,96.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.834 | Acc: 64.605,87.597,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.830 | Acc: 64.683,87.650,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.834 | Acc: 64.771,87.442,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.836 | Acc: 64.757,87.444,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.853 | Acc: 64.673,87.208,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.860 | Acc: 64.653,87.083,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.870 | Acc: 64.656,86.897,95.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.882 | Acc: 64.532,86.665,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.885 | Acc: 64.541,86.574,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.893 | Acc: 64.501,86.451,95.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.900 | Acc: 64.491,86.298,95.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.904 | Acc: 64.514,86.219,95.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.906 | Acc: 64.463,86.206,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.910 | Acc: 64.409,86.188,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.476 | Acc: 58.594,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.150 | Acc: 55.134,66.629,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.218 | Acc: 53.716,66.387,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.244 | Acc: 53.804,66.291,71.055,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 1.828 | Acc: 64.062,89.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.862 | Acc: 64.993,87.574,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.855 | Acc: 64.844,87.157,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.833 | Acc: 65.523,87.372,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.831 | Acc: 65.548,87.394,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.831 | Acc: 65.347,87.322,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.828 | Acc: 65.302,87.242,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.833 | Acc: 64.999,87.273,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.841 | Acc: 64.960,87.194,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.854 | Acc: 64.714,87.008,96.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.847 | Acc: 64.731,87.104,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.848 | Acc: 64.833,87.093,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.845 | Acc: 64.886,87.163,95.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.844 | Acc: 64.925,87.081,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.854 | Acc: 64.883,86.950,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.860 | Acc: 64.883,86.791,95.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.871 | Acc: 64.795,86.733,95.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.878 | Acc: 64.750,86.652,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.883 | Acc: 64.736,86.576,95.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.887 | Acc: 64.741,86.458,95.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.373 | Acc: 52.344,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.416 | Acc: 49.070,65.290,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.488 | Acc: 49.181,64.806,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.482 | Acc: 49.321,64.767,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 1.563 | Acc: 69.531,89.062,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.823 | Acc: 66.629,87.388,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.799 | Acc: 66.635,87.595,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.823 | Acc: 65.881,87.077,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.825 | Acc: 65.442,87.394,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.827 | Acc: 65.269,87.361,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.823 | Acc: 65.418,87.326,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.823 | Acc: 65.664,87.262,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.828 | Acc: 65.479,87.214,96.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.831 | Acc: 65.405,87.198,96.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.842 | Acc: 65.131,87.057,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.853 | Acc: 65.056,86.920,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.855 | Acc: 65.142,86.907,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.862 | Acc: 65.149,86.755,95.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.869 | Acc: 65.063,86.649,95.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.881 | Acc: 64.942,86.480,95.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.883 | Acc: 64.905,86.453,95.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.887 | Acc: 64.922,86.409,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.894 | Acc: 64.818,86.303,95.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.899 | Acc: 64.811,86.243,95.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.862 | Acc: 55.469,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.210 | Acc: 55.543,66.220,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.229 | Acc: 54.745,65.511,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.240 | Acc: 54.739,65.548,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 2.008 | Acc: 56.250,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.815 | Acc: 66.220,88.876,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.791 | Acc: 66.730,88.186,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.802 | Acc: 66.124,88.076,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.806 | Acc: 65.982,87.731,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.812 | Acc: 66.089,87.570,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.812 | Acc: 66.135,87.539,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.820 | Acc: 65.924,87.417,95.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.821 | Acc: 65.994,87.350,95.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.825 | Acc: 65.914,87.327,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.835 | Acc: 65.784,87.201,95.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.848 | Acc: 65.632,86.987,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.851 | Acc: 65.648,86.916,95.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.860 | Acc: 65.448,86.803,95.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.870 | Acc: 65.328,86.680,95.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.877 | Acc: 65.238,86.594,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.883 | Acc: 65.131,86.512,95.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.890 | Acc: 65.043,86.423,95.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.900 | Acc: 64.917,86.299,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.906 | Acc: 64.825,86.253,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.917 | Acc: 55.469,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.325 | Acc: 52.046,66.071,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.303 | Acc: 52.534,66.482,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.290 | Acc: 52.523,66.240,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 1.467 | Acc: 70.312,89.844,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.725 | Acc: 68.527,88.690,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.658 | Acc: 68.579,89.501,97.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.618 | Acc: 68.379,90.190,97.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.580 | Acc: 68.509,90.885,97.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.546 | Acc: 68.835,91.298,97.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.521 | Acc: 69.183,91.600,97.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.502 | Acc: 69.393,91.916,97.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 69.560,92.100,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.472 | Acc: 69.829,92.261,98.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.458 | Acc: 69.951,92.487,98.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.447 | Acc: 70.150,92.598,98.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.437 | Acc: 70.261,92.706,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.427 | Acc: 70.354,92.834,98.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.419 | Acc: 70.443,92.935,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.413 | Acc: 70.536,92.990,98.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.406 | Acc: 70.663,93.093,98.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.400 | Acc: 70.757,93.200,98.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.391 | Acc: 70.899,93.285,98.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.386 | Acc: 70.983,93.367,98.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.771 | Acc: 62.500,78.125,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.306 | Acc: 61.793,73.438,76.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.309 | Acc: 62.100,73.056,76.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.294 | Acc: 62.654,73.040,76.601,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 1.188 | Acc: 72.656,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.260 | Acc: 72.321,95.312,99.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.261 | Acc: 72.351,95.465,99.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.262 | Acc: 72.131,95.274,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.260 | Acc: 72.492,95.235,99.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.244 | Acc: 72.958,95.336,99.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.248 | Acc: 72.624,95.371,99.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.248 | Acc: 72.557,95.351,99.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.243 | Acc: 72.579,95.390,99.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.247 | Acc: 72.410,95.282,99.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.245 | Acc: 72.516,95.297,99.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.249 | Acc: 72.451,95.270,99.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.245 | Acc: 72.585,95.235,99.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.245 | Acc: 72.551,95.292,99.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.241 | Acc: 72.640,95.301,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.239 | Acc: 72.687,95.338,99.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.240 | Acc: 72.574,95.349,99.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.237 | Acc: 72.647,95.370,99.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.238 | Acc: 72.691,95.343,99.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.239 | Acc: 72.634,95.354,99.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.756 | Acc: 63.281,77.344,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.251 | Acc: 62.760,73.103,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.269 | Acc: 62.443,72.961,77.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.264 | Acc: 62.743,73.373,77.024,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.300 | Acc: 76.562,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.221 | Acc: 73.103,95.982,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.214 | Acc: 73.018,96.056,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.203 | Acc: 73.181,96.235,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.201 | Acc: 72.975,96.219,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.192 | Acc: 73.391,96.194,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.198 | Acc: 73.192,96.074,99.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.203 | Acc: 72.928,96.016,99.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.202 | Acc: 72.923,95.958,99.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.200 | Acc: 73.015,95.986,99.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.204 | Acc: 72.998,95.899,99.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.205 | Acc: 72.960,95.857,99.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.202 | Acc: 73.032,95.880,99.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.199 | Acc: 73.081,95.890,99.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.200 | Acc: 73.057,95.905,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.202 | Acc: 72.988,95.943,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.201 | Acc: 73.012,95.957,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.199 | Acc: 73.064,95.968,99.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.199 | Acc: 73.072,95.968,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.197 | Acc: 73.114,95.971,99.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.792 | Acc: 64.844,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.241 | Acc: 63.207,74.182,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.265 | Acc: 62.633,73.819,77.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.259 | Acc: 62.923,73.873,77.036,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.206 | Acc: 73.438,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.180 | Acc: 72.991,96.615,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.175 | Acc: 73.075,96.799,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.174 | Acc: 72.964,96.785,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.174 | Acc: 73.023,96.682,99.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.176 | Acc: 73.035,96.558,99.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.165 | Acc: 73.450,96.565,99.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.160 | Acc: 73.493,96.531,99.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.160 | Acc: 73.471,96.530,99.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.155 | Acc: 73.485,96.607,99.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.159 | Acc: 73.449,96.576,99.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.161 | Acc: 73.469,96.500,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.160 | Acc: 73.554,96.480,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.163 | Acc: 73.542,96.459,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.164 | Acc: 73.540,96.447,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.164 | Acc: 73.583,96.449,99.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.167 | Acc: 73.503,96.456,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.167 | Acc: 73.531,96.453,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.167 | Acc: 73.522,96.455,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.168 | Acc: 73.497,96.428,99.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.759 | Acc: 64.062,78.125,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.232 | Acc: 62.946,74.219,77.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.244 | Acc: 62.481,73.704,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.237 | Acc: 62.961,73.668,77.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.036 | Acc: 78.906,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.189 | Acc: 72.731,96.763,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.176 | Acc: 72.409,96.780,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.168 | Acc: 72.861,96.773,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.160 | Acc: 73.428,96.779,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.156 | Acc: 73.352,96.728,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.162 | Acc: 73.315,96.649,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.157 | Acc: 73.515,96.598,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.159 | Acc: 73.520,96.608,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.154 | Acc: 73.606,96.651,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.149 | Acc: 73.795,96.685,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.150 | Acc: 73.784,96.688,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.152 | Acc: 73.694,96.648,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.151 | Acc: 73.749,96.698,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.152 | Acc: 73.699,96.708,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.155 | Acc: 73.622,96.699,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.155 | Acc: 73.557,96.692,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.154 | Acc: 73.644,96.680,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.153 | Acc: 73.686,96.706,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.154 | Acc: 73.606,96.711,99.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.749 | Acc: 64.062,76.562,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.222 | Acc: 63.132,74.330,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.229 | Acc: 62.710,73.933,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.227 | Acc: 63.204,73.899,77.190,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.045 | Acc: 77.344,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.101 | Acc: 74.516,97.173,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.096 | Acc: 74.600,97.008,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.104 | Acc: 74.411,97.182,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.115 | Acc: 74.045,97.126,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.106 | Acc: 74.621,97.231,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.106 | Acc: 74.632,97.191,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.108 | Acc: 74.562,97.174,99.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.111 | Acc: 74.403,97.118,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.117 | Acc: 74.327,97.061,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.124 | Acc: 74.160,97.027,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.128 | Acc: 74.088,96.939,99.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.128 | Acc: 74.089,96.950,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.128 | Acc: 74.114,96.947,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.126 | Acc: 74.163,96.967,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.130 | Acc: 74.055,96.953,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.134 | Acc: 73.992,96.914,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.136 | Acc: 73.992,96.848,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.136 | Acc: 73.935,96.853,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.137 | Acc: 73.897,96.838,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.743 | Acc: 62.500,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.210 | Acc: 62.649,73.586,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.232 | Acc: 62.767,73.438,77.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.225 | Acc: 63.192,73.591,77.305,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.192 | Acc: 75.781,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.185 | Acc: 73.103,96.801,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.164 | Acc: 73.266,96.723,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.153 | Acc: 73.514,96.619,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.152 | Acc: 73.698,96.624,99.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.141 | Acc: 73.847,96.682,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.135 | Acc: 73.883,96.726,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.132 | Acc: 73.870,96.748,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.131 | Acc: 73.952,96.778,99.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.130 | Acc: 73.964,96.815,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.127 | Acc: 73.954,96.871,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.122 | Acc: 74.017,96.924,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.120 | Acc: 74.096,96.933,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.120 | Acc: 74.096,96.944,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.120 | Acc: 74.071,96.961,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.118 | Acc: 74.133,97.018,99.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.118 | Acc: 74.148,97.036,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.117 | Acc: 74.164,97.058,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.116 | Acc: 74.141,97.102,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.118 | Acc: 74.079,97.105,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.736 | Acc: 62.500,77.344,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.212 | Acc: 63.095,73.884,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.224 | Acc: 62.862,73.514,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.216 | Acc: 63.281,73.668,77.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.117 | Acc: 76.562,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.106 | Acc: 74.368,97.247,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.109 | Acc: 74.143,97.142,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.104 | Acc: 74.103,97.144,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.099 | Acc: 74.412,97.280,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.105 | Acc: 74.219,97.153,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.109 | Acc: 74.064,97.146,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.113 | Acc: 74.019,97.163,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.119 | Acc: 73.923,97.069,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.124 | Acc: 73.791,97.052,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.122 | Acc: 73.919,97.097,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.119 | Acc: 74.021,97.101,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.119 | Acc: 74.063,97.105,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.118 | Acc: 74.135,97.108,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.117 | Acc: 74.191,97.092,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.119 | Acc: 74.263,97.046,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.117 | Acc: 74.246,97.053,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.116 | Acc: 74.237,97.079,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.115 | Acc: 74.236,97.068,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.115 | Acc: 74.262,97.047,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.709 | Acc: 64.844,78.125,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.222 | Acc: 63.281,73.661,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.246 | Acc: 62.538,73.495,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.243 | Acc: 62.910,73.527,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.082 | Acc: 74.219,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.055 | Acc: 75.260,97.619,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.082 | Acc: 74.771,97.580,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.092 | Acc: 74.565,97.605,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.087 | Acc: 74.489,97.589,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.089 | Acc: 74.327,97.548,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.095 | Acc: 74.257,97.605,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.093 | Acc: 74.285,97.595,99.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.093 | Acc: 74.224,97.583,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.092 | Acc: 74.318,97.574,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.095 | Acc: 74.308,97.555,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.096 | Acc: 74.289,97.554,99.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.096 | Acc: 74.274,97.514,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.097 | Acc: 74.240,97.474,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.098 | Acc: 74.288,97.425,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.095 | Acc: 74.362,97.399,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.096 | Acc: 74.321,97.369,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.097 | Acc: 74.317,97.365,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.101 | Acc: 74.245,97.351,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.101 | Acc: 74.272,97.347,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.747 | Acc: 63.281,75.781,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.217 | Acc: 62.835,73.884,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.237 | Acc: 62.481,73.628,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.232 | Acc: 62.884,73.578,77.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 1.038 | Acc: 77.344,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.040 | Acc: 75.074,97.954,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.050 | Acc: 75.248,97.847,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.066 | Acc: 74.757,97.707,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.068 | Acc: 75.068,97.531,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.071 | Acc: 75.054,97.463,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.074 | Acc: 74.884,97.450,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.079 | Acc: 74.673,97.457,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.079 | Acc: 74.675,97.506,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.086 | Acc: 74.465,97.514,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.087 | Acc: 74.541,97.520,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.088 | Acc: 74.625,97.522,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.090 | Acc: 74.585,97.484,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.088 | Acc: 74.692,97.522,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.088 | Acc: 74.627,97.553,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.086 | Acc: 74.686,97.532,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.087 | Acc: 74.725,97.498,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.088 | Acc: 74.711,97.487,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.089 | Acc: 74.712,97.500,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.089 | Acc: 74.647,97.498,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.738 | Acc: 64.844,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.204 | Acc: 63.281,73.661,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.221 | Acc: 62.614,73.628,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.219 | Acc: 63.140,73.758,77.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.148 | Acc: 71.875,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.052 | Acc: 75.074,97.507,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.060 | Acc: 74.790,97.637,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.056 | Acc: 74.898,97.643,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.058 | Acc: 75.000,97.685,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.063 | Acc: 74.969,97.625,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.072 | Acc: 74.722,97.546,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.075 | Acc: 74.839,97.562,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.076 | Acc: 74.709,97.588,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.079 | Acc: 74.719,97.557,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.079 | Acc: 74.759,97.551,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.079 | Acc: 74.784,97.529,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.081 | Acc: 74.815,97.527,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.083 | Acc: 74.767,97.519,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.084 | Acc: 74.772,97.495,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.087 | Acc: 74.748,97.472,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.089 | Acc: 74.774,97.457,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.088 | Acc: 74.737,97.464,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.088 | Acc: 74.708,97.464,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.088 | Acc: 74.688,97.492,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.707 | Acc: 67.188,79.688,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.185 | Acc: 63.616,73.847,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.206 | Acc: 63.053,73.628,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.206 | Acc: 63.243,73.591,77.203,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 0.986 | Acc: 74.219,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.099 | Acc: 73.884,97.917,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.077 | Acc: 74.771,97.561,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.072 | Acc: 75.077,97.784,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.068 | Acc: 75.203,97.733,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.067 | Acc: 75.387,97.726,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.070 | Acc: 75.161,97.760,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.070 | Acc: 75.227,97.811,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.070 | Acc: 75.228,97.739,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.070 | Acc: 75.276,97.734,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.071 | Acc: 75.190,97.730,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.073 | Acc: 75.177,97.688,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.076 | Acc: 75.003,97.689,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.079 | Acc: 74.859,97.650,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.079 | Acc: 74.889,97.653,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.081 | Acc: 74.816,97.620,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.080 | Acc: 74.852,97.595,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.079 | Acc: 74.830,97.599,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.078 | Acc: 74.786,97.602,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.081 | Acc: 74.772,97.566,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.735 | Acc: 66.406,77.344,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.208 | Acc: 63.021,73.624,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.243 | Acc: 62.538,73.361,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.241 | Acc: 62.974,73.399,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 0.950 | Acc: 78.125,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.068 | Acc: 75.781,97.470,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.060 | Acc: 75.629,97.694,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.055 | Acc: 75.474,97.720,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.059 | Acc: 75.415,97.695,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.066 | Acc: 75.070,97.726,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.070 | Acc: 75.065,97.676,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.068 | Acc: 75.127,97.695,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.073 | Acc: 74.951,97.705,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.070 | Acc: 75.022,97.691,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.070 | Acc: 75.004,97.683,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.068 | Acc: 74.951,97.716,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.071 | Acc: 74.831,97.715,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.071 | Acc: 74.895,97.695,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.071 | Acc: 74.894,97.715,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.069 | Acc: 74.945,97.695,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.070 | Acc: 74.873,97.685,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.071 | Acc: 74.824,97.677,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.072 | Acc: 74.812,97.669,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.071 | Acc: 74.836,97.648,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.664 | Acc: 64.844,76.562,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.194 | Acc: 63.058,74.070,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.221 | Acc: 62.691,73.723,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.217 | Acc: 63.089,73.681,77.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.044 | Acc: 74.219,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.078 | Acc: 75.074,97.954,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.042 | Acc: 76.143,98.018,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.060 | Acc: 75.640,97.784,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.065 | Acc: 75.521,97.782,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.071 | Acc: 75.333,97.749,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.067 | Acc: 75.439,97.760,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.065 | Acc: 75.294,97.811,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.065 | Acc: 75.233,97.778,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.068 | Acc: 75.160,97.721,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.068 | Acc: 75.054,97.742,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.067 | Acc: 75.131,97.759,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.064 | Acc: 75.191,97.776,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.064 | Acc: 75.135,97.770,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.062 | Acc: 75.172,97.767,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.065 | Acc: 75.026,97.752,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.066 | Acc: 74.971,97.751,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.064 | Acc: 74.998,97.748,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.065 | Acc: 74.989,97.736,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.066 | Acc: 74.947,97.734,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.726 | Acc: 64.062,77.344,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.222 | Acc: 62.165,73.847,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.239 | Acc: 62.138,73.742,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.233 | Acc: 62.692,73.694,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 0.979 | Acc: 72.656,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.051 | Acc: 75.223,98.177,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.048 | Acc: 75.267,98.114,99.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.033 | Acc: 75.512,98.130,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.043 | Acc: 75.116,98.081,99.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.050 | Acc: 75.077,98.066,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.046 | Acc: 75.245,98.089,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.044 | Acc: 75.499,98.061,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.049 | Acc: 75.330,98.025,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.054 | Acc: 75.147,97.984,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.054 | Acc: 75.167,98.041,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.053 | Acc: 75.141,97.985,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.054 | Acc: 75.143,97.958,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.056 | Acc: 75.102,97.935,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.058 | Acc: 75.075,97.909,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.057 | Acc: 75.099,97.926,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.058 | Acc: 75.088,97.907,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.059 | Acc: 75.048,97.874,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.060 | Acc: 75.084,97.868,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.061 | Acc: 75.016,97.861,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.739 | Acc: 64.844,79.688,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.240 | Acc: 62.240,73.921,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.256 | Acc: 62.043,73.666,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.253 | Acc: 62.654,73.655,77.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.040 | Acc: 78.125,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.052 | Acc: 75.149,97.879,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.050 | Acc: 75.610,97.866,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.041 | Acc: 75.551,98.028,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.047 | Acc: 75.608,97.994,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.046 | Acc: 75.627,97.981,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.043 | Acc: 75.743,97.998,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.037 | Acc: 75.798,98.061,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.043 | Acc: 75.543,97.991,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.049 | Acc: 75.328,97.976,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.052 | Acc: 75.210,97.971,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.053 | Acc: 75.262,97.936,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.052 | Acc: 75.305,97.929,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.053 | Acc: 75.201,97.956,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.054 | Acc: 75.161,97.984,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.058 | Acc: 75.031,97.968,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.058 | Acc: 75.007,97.973,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.060 | Acc: 75.014,97.954,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.058 | Acc: 75.054,97.957,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.060 | Acc: 74.959,97.943,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.771 | Acc: 63.281,77.344,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.243 | Acc: 61.830,74.070,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.255 | Acc: 61.871,73.838,77.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.254 | Acc: 62.474,73.732,77.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 0.999 | Acc: 78.125,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.056 | Acc: 74.442,98.140,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.022 | Acc: 75.991,98.037,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.036 | Acc: 75.448,98.066,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.043 | Acc: 75.212,98.119,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.036 | Acc: 75.588,98.058,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.036 | Acc: 75.717,97.998,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.040 | Acc: 75.587,98.027,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.045 | Acc: 75.451,98.010,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.046 | Acc: 75.470,98.002,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.045 | Acc: 75.552,97.998,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.044 | Acc: 75.566,97.971,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.046 | Acc: 75.444,97.919,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.045 | Acc: 75.473,97.953,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.043 | Acc: 75.553,97.976,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.044 | Acc: 75.548,97.957,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.046 | Acc: 75.514,97.953,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.048 | Acc: 75.424,97.943,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.049 | Acc: 75.377,97.929,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.049 | Acc: 75.349,97.931,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.786 | Acc: 64.062,78.125,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.202 | Acc: 63.430,73.958,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.218 | Acc: 63.072,74.181,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.210 | Acc: 63.678,74.078,77.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.093 | Acc: 74.219,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.034 | Acc: 75.372,97.879,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.040 | Acc: 75.419,97.961,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.034 | Acc: 75.576,98.002,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.030 | Acc: 75.801,98.042,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.034 | Acc: 75.572,98.089,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.030 | Acc: 75.581,98.134,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.036 | Acc: 75.332,98.133,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.037 | Acc: 75.320,98.112,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.045 | Acc: 75.086,98.071,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.046 | Acc: 75.167,98.025,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.043 | Acc: 75.237,98.035,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.043 | Acc: 75.198,98.026,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.045 | Acc: 75.129,97.983,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.048 | Acc: 75.036,97.968,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.047 | Acc: 75.132,97.965,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.046 | Acc: 75.080,97.985,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.049 | Acc: 75.060,98.000,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.048 | Acc: 75.093,98.005,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.048 | Acc: 75.125,97.976,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.752 | Acc: 66.406,76.562,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.199 | Acc: 62.984,73.289,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.219 | Acc: 62.805,73.399,77.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.215 | Acc: 63.128,73.527,77.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 0.990 | Acc: 69.531,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.011 | Acc: 75.558,98.214,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.023 | Acc: 75.248,98.037,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.028 | Acc: 75.602,97.900,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.032 | Acc: 75.328,97.888,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.038 | Acc: 75.116,97.958,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.038 | Acc: 75.110,97.947,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.040 | Acc: 75.033,97.967,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.041 | Acc: 75.082,97.947,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.040 | Acc: 75.168,97.958,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.039 | Acc: 75.136,98.018,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.040 | Acc: 75.049,98.052,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.041 | Acc: 75.062,98.036,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.037 | Acc: 75.251,98.066,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.037 | Acc: 75.239,98.062,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.039 | Acc: 75.249,98.064,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.040 | Acc: 75.214,98.075,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.042 | Acc: 75.156,98.069,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.041 | Acc: 75.253,98.059,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.041 | Acc: 75.291,98.052,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.833 | Acc: 64.062,77.344,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.216 | Acc: 62.537,74.070,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.242 | Acc: 62.729,73.819,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.234 | Acc: 62.987,73.719,77.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.186 | Acc: 75.781,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.026 | Acc: 76.004,98.289,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.015 | Acc: 75.838,98.380,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.009 | Acc: 76.486,98.361,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.010 | Acc: 76.370,98.312,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.013 | Acc: 76.330,98.244,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.020 | Acc: 76.188,98.199,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.025 | Acc: 76.020,98.160,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.034 | Acc: 75.708,98.040,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.036 | Acc: 75.583,97.989,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.035 | Acc: 75.591,98.033,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.036 | Acc: 75.569,97.999,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.040 | Acc: 75.506,97.993,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.039 | Acc: 75.575,98.024,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.042 | Acc: 75.514,98.020,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.039 | Acc: 75.581,98.022,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.037 | Acc: 75.630,98.048,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.038 | Acc: 75.644,98.041,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.041 | Acc: 75.526,98.044,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.042 | Acc: 75.482,98.046,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.760 | Acc: 65.625,77.344,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.234 | Acc: 62.240,73.549,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.255 | Acc: 62.081,73.704,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.245 | Acc: 62.577,73.783,77.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 0.987 | Acc: 72.656,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.031 | Acc: 75.632,98.140,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.037 | Acc: 75.286,98.285,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.040 | Acc: 75.243,98.271,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.031 | Acc: 75.685,98.274,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.033 | Acc: 75.580,98.213,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.037 | Acc: 75.465,98.257,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.040 | Acc: 75.349,98.227,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.039 | Acc: 75.471,98.239,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.034 | Acc: 75.604,98.213,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.034 | Acc: 75.669,98.220,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.035 | Acc: 75.633,98.261,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.037 | Acc: 75.580,98.214,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.038 | Acc: 75.560,98.204,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.039 | Acc: 75.528,98.165,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.040 | Acc: 75.470,98.170,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.043 | Acc: 75.387,98.165,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.043 | Acc: 75.348,98.153,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.040 | Acc: 75.431,98.167,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.038 | Acc: 75.468,98.163,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.763 | Acc: 68.750,76.562,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.216 | Acc: 62.798,73.624,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.238 | Acc: 62.519,73.819,77.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.230 | Acc: 62.935,73.668,77.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 1.073 | Acc: 71.875,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.064 | Acc: 74.963,98.512,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.042 | Acc: 75.800,98.380,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.021 | Acc: 76.217,98.425,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.020 | Acc: 76.177,98.293,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.024 | Acc: 76.029,98.306,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.015 | Acc: 76.285,98.315,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.016 | Acc: 76.219,98.343,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.018 | Acc: 76.014,98.321,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.016 | Acc: 75.984,98.321,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.022 | Acc: 75.727,98.301,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.022 | Acc: 75.834,98.293,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.024 | Acc: 75.746,98.259,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.026 | Acc: 75.742,98.225,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.028 | Acc: 75.656,98.215,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.030 | Acc: 75.571,98.230,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.029 | Acc: 75.638,98.235,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.030 | Acc: 75.566,98.204,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.030 | Acc: 75.589,98.199,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.031 | Acc: 75.506,98.202,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.820 | Acc: 64.844,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.214 | Acc: 63.356,73.698,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.231 | Acc: 62.729,73.704,77.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.226 | Acc: 63.102,73.655,77.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 0.965 | Acc: 78.125,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.981 | Acc: 76.600,98.400,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.984 | Acc: 77.115,98.266,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.999 | Acc: 76.114,98.322,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.012 | Acc: 75.887,98.177,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.018 | Acc: 75.688,98.120,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.017 | Acc: 75.878,98.134,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.022 | Acc: 75.565,98.205,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.020 | Acc: 75.694,98.273,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.020 | Acc: 75.717,98.269,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.022 | Acc: 75.773,98.255,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.025 | Acc: 75.615,98.236,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.027 | Acc: 75.603,98.194,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.027 | Acc: 75.590,98.189,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.029 | Acc: 75.550,98.179,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.029 | Acc: 75.607,98.183,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.029 | Acc: 75.557,98.216,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.027 | Acc: 75.667,98.222,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.026 | Acc: 75.675,98.228,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.027 | Acc: 75.636,98.204,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.754 | Acc: 67.188,76.562,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.208 | Acc: 62.946,73.996,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.231 | Acc: 62.671,73.780,77.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.224 | Acc: 63.064,73.527,77.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 1.176 | Acc: 70.312,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.034 | Acc: 75.112,98.177,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.020 | Acc: 75.553,98.114,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.015 | Acc: 75.781,98.130,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.012 | Acc: 75.945,98.167,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.013 | Acc: 75.944,98.151,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.015 | Acc: 75.930,98.108,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.015 | Acc: 75.942,98.122,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.020 | Acc: 75.699,98.108,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.018 | Acc: 75.850,98.213,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.020 | Acc: 75.910,98.177,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.020 | Acc: 75.937,98.183,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.022 | Acc: 75.836,98.181,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.022 | Acc: 75.907,98.168,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.022 | Acc: 75.940,98.134,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.021 | Acc: 75.940,98.129,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.023 | Acc: 75.886,98.126,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.025 | Acc: 75.845,98.121,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.026 | Acc: 75.794,98.141,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.025 | Acc: 75.777,98.169,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.826 | Acc: 67.188,76.562,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.210 | Acc: 63.281,74.219,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.239 | Acc: 62.729,74.066,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.231 | Acc: 63.102,73.822,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 0.895 | Acc: 78.906,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.987 | Acc: 75.335,98.810,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.973 | Acc: 76.124,98.723,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.978 | Acc: 76.716,98.578,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.999 | Acc: 76.138,98.601,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.008 | Acc: 75.920,98.507,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.010 | Acc: 75.865,98.547,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.008 | Acc: 76.119,98.443,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.011 | Acc: 76.102,98.423,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.013 | Acc: 76.045,98.412,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.012 | Acc: 75.987,98.406,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.017 | Acc: 75.866,98.402,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.015 | Acc: 75.969,98.399,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.015 | Acc: 75.946,98.402,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.017 | Acc: 75.926,98.365,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.016 | Acc: 75.966,98.367,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.016 | Acc: 76.000,98.374,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.017 | Acc: 75.935,98.346,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.020 | Acc: 75.818,98.368,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.020 | Acc: 75.779,98.358,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.826 | Acc: 65.625,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.233 | Acc: 62.686,73.251,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.252 | Acc: 62.500,73.361,77.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.247 | Acc: 62.769,73.258,77.331,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 0.939 | Acc: 79.688,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.026 | Acc: 75.707,98.735,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.001 | Acc: 76.410,98.723,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.001 | Acc: 76.370,98.642,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.997 | Acc: 76.485,98.553,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.998 | Acc: 76.385,98.484,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.999 | Acc: 76.420,98.373,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.995 | Acc: 76.551,98.393,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.997 | Acc: 76.427,98.399,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.997 | Acc: 76.429,98.438,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.000 | Acc: 76.298,98.461,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.001 | Acc: 76.312,98.459,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.005 | Acc: 76.193,98.460,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.005 | Acc: 76.257,98.467,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.012 | Acc: 76.068,98.412,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.014 | Acc: 76.038,98.388,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.016 | Acc: 76.049,98.323,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.019 | Acc: 75.978,98.332,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.016 | Acc: 76.058,98.340,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.019 | Acc: 75.939,98.310,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.793 | Acc: 64.062,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.201 | Acc: 62.760,74.256,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.217 | Acc: 63.014,73.876,77.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.213 | Acc: 63.422,73.847,77.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 1.152 | Acc: 70.312,99.219,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.014 | Acc: 75.372,98.475,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.038 | Acc: 75.210,98.304,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.028 | Acc: 75.474,98.348,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.029 | Acc: 75.231,98.264,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.022 | Acc: 75.557,98.298,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.019 | Acc: 75.568,98.302,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.012 | Acc: 75.803,98.349,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.012 | Acc: 75.810,98.360,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.013 | Acc: 75.721,98.390,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.009 | Acc: 75.921,98.399,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.010 | Acc: 75.887,98.395,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.012 | Acc: 75.772,98.415,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.016 | Acc: 75.632,98.417,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.019 | Acc: 75.589,98.412,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.018 | Acc: 75.602,98.393,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.018 | Acc: 75.625,98.379,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.021 | Acc: 75.600,98.344,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.021 | Acc: 75.591,98.349,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.021 | Acc: 75.591,98.335,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.773 | Acc: 64.062,75.781,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.212 | Acc: 63.430,74.479,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.232 | Acc: 63.014,73.971,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.224 | Acc: 63.256,73.745,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.222 | Acc: 75.781,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.009 | Acc: 75.595,98.326,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.020 | Acc: 74.924,98.247,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.002 | Acc: 75.704,98.450,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.011 | Acc: 75.617,98.447,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.009 | Acc: 75.774,98.523,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.013 | Acc: 75.755,98.463,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.017 | Acc: 75.704,98.438,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.014 | Acc: 75.869,98.423,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.013 | Acc: 75.889,98.446,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.010 | Acc: 75.995,98.441,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.007 | Acc: 76.121,98.441,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.012 | Acc: 75.979,98.389,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.012 | Acc: 75.976,98.387,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.011 | Acc: 76.020,98.412,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.010 | Acc: 75.976,98.419,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.008 | Acc: 75.993,98.401,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.008 | Acc: 75.978,98.392,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.008 | Acc: 76.017,98.409,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.009 | Acc: 75.945,98.401,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.834 | Acc: 67.188,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.228 | Acc: 63.095,73.921,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.242 | Acc: 63.110,73.876,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.242 | Acc: 63.307,73.514,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.159 | Acc: 72.656,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.993 | Acc: 76.600,98.958,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.991 | Acc: 76.658,98.647,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.994 | Acc: 76.319,98.642,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.998 | Acc: 76.225,98.640,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.006 | Acc: 76.044,98.639,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.011 | Acc: 76.117,98.567,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.008 | Acc: 76.108,98.637,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.009 | Acc: 76.048,98.573,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.007 | Acc: 76.165,98.558,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.009 | Acc: 75.933,98.527,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.012 | Acc: 75.880,98.491,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.013 | Acc: 75.817,98.480,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.014 | Acc: 75.838,98.470,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.013 | Acc: 75.829,98.476,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.011 | Acc: 75.836,98.487,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.011 | Acc: 75.893,98.469,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.013 | Acc: 75.877,98.463,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.011 | Acc: 75.950,98.446,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.012 | Acc: 75.900,98.456,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.690 | Acc: 66.406,78.125,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.211 | Acc: 63.095,73.698,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.239 | Acc: 63.034,73.514,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.230 | Acc: 63.499,73.425,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 1.112 | Acc: 71.094,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.055 | Acc: 74.591,98.400,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.018 | Acc: 75.514,98.495,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.015 | Acc: 75.832,98.438,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.005 | Acc: 75.974,98.351,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.000 | Acc: 76.276,98.329,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.997 | Acc: 76.324,98.302,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.004 | Acc: 76.186,98.321,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.007 | Acc: 75.970,98.336,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.008 | Acc: 76.036,98.308,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.007 | Acc: 76.030,98.298,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.006 | Acc: 76.110,98.285,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.005 | Acc: 76.096,98.337,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.005 | Acc: 76.111,98.336,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.006 | Acc: 76.098,98.349,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.009 | Acc: 76.004,98.321,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.011 | Acc: 75.927,98.350,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.008 | Acc: 76.017,98.366,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.004 | Acc: 76.179,98.375,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.007 | Acc: 76.130,98.347,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.789 | Acc: 64.844,75.781,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.225 | Acc: 62.463,73.363,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.268 | Acc: 62.195,73.285,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.276 | Acc: 62.526,73.258,77.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 0.768 | Acc: 83.594,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.003 | Acc: 76.711,98.512,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.986 | Acc: 77.058,98.476,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.991 | Acc: 76.434,98.617,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.996 | Acc: 76.302,98.495,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.997 | Acc: 76.354,98.523,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.999 | Acc: 76.337,98.528,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.989 | Acc: 76.585,98.615,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.992 | Acc: 76.538,98.632,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.993 | Acc: 76.506,98.614,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.996 | Acc: 76.391,98.570,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.996 | Acc: 76.432,98.544,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.999 | Acc: 76.365,98.525,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.001 | Acc: 76.287,98.494,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.001 | Acc: 76.321,98.499,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.001 | Acc: 76.306,98.484,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.002 | Acc: 76.331,98.467,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.003 | Acc: 76.308,98.460,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.003 | Acc: 76.290,98.427,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.003 | Acc: 76.265,98.425,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.775 | Acc: 65.625,76.562,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.210 | Acc: 62.909,73.661,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.228 | Acc: 63.300,73.800,77.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.229 | Acc: 63.576,73.553,77.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 0.898 | Acc: 80.469,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.002 | Acc: 76.376,98.586,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.991 | Acc: 76.086,98.761,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.989 | Acc: 76.063,98.809,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.993 | Acc: 76.119,98.640,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.992 | Acc: 76.361,98.569,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.986 | Acc: 76.562,98.618,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.986 | Acc: 76.441,98.587,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.986 | Acc: 76.388,98.607,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.990 | Acc: 76.213,98.589,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.991 | Acc: 76.248,98.577,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.991 | Acc: 76.312,98.575,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.994 | Acc: 76.290,98.613,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.996 | Acc: 76.275,98.569,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.997 | Acc: 76.237,98.549,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.000 | Acc: 76.145,98.531,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.003 | Acc: 76.098,98.528,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.002 | Acc: 76.146,98.536,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.001 | Acc: 76.086,98.513,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.000 | Acc: 76.101,98.495,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.783 | Acc: 66.406,75.781,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.244 | Acc: 62.686,73.214,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.263 | Acc: 62.500,73.266,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.263 | Acc: 62.871,73.258,77.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 0.995 | Acc: 76.562,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.998 | Acc: 76.749,98.772,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.983 | Acc: 77.496,98.552,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.985 | Acc: 77.139,98.566,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.994 | Acc: 76.611,98.495,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.995 | Acc: 76.408,98.445,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.990 | Acc: 76.420,98.418,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.993 | Acc: 76.363,98.432,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.995 | Acc: 76.446,98.384,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.995 | Acc: 76.420,98.330,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.998 | Acc: 76.380,98.336,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.994 | Acc: 76.456,98.353,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.995 | Acc: 76.404,98.402,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.995 | Acc: 76.368,98.426,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.997 | Acc: 76.337,98.404,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.997 | Acc: 76.383,98.399,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.999 | Acc: 76.317,98.394,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.999 | Acc: 76.317,98.421,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.999 | Acc: 76.279,98.433,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.998 | Acc: 76.382,98.448,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.740 | Acc: 66.406,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.211 | Acc: 62.760,73.958,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.238 | Acc: 62.538,73.514,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.238 | Acc: 63.051,73.489,77.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 1.018 | Acc: 72.656,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.972 | Acc: 76.823,98.847,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.985 | Acc: 76.315,98.761,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.995 | Acc: 76.422,98.630,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.995 | Acc: 76.389,98.592,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.993 | Acc: 76.369,98.561,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.989 | Acc: 76.530,98.489,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.985 | Acc: 76.529,98.515,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.986 | Acc: 76.490,98.486,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.987 | Acc: 76.524,98.489,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.989 | Acc: 76.419,98.511,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.992 | Acc: 76.304,98.529,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.990 | Acc: 76.306,98.541,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.993 | Acc: 76.296,98.542,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.992 | Acc: 76.335,98.535,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.993 | Acc: 76.277,98.531,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.995 | Acc: 76.283,98.515,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.996 | Acc: 76.269,98.513,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.997 | Acc: 76.234,98.502,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.997 | Acc: 76.220,98.507,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.841 | Acc: 66.406,76.562,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.238 | Acc: 62.128,73.326,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.257 | Acc: 62.043,73.247,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.248 | Acc: 62.628,73.399,77.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 1.186 | Acc: 69.531,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.021 | Acc: 75.744,98.140,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.009 | Acc: 76.200,98.457,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.987 | Acc: 76.652,98.617,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.987 | Acc: 76.939,98.466,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.988 | Acc: 77.003,98.499,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.991 | Acc: 76.872,98.502,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.988 | Acc: 76.817,98.521,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.986 | Acc: 77.023,98.486,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.988 | Acc: 76.830,98.498,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.989 | Acc: 76.753,98.496,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.987 | Acc: 76.725,98.505,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.990 | Acc: 76.572,98.496,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.989 | Acc: 76.583,98.485,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.991 | Acc: 76.537,98.465,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.992 | Acc: 76.407,98.476,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.994 | Acc: 76.331,98.506,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.996 | Acc: 76.251,98.506,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.997 | Acc: 76.262,98.509,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.995 | Acc: 76.306,98.538,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.819 | Acc: 67.969,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.237 | Acc: 62.946,73.884,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.258 | Acc: 62.652,73.571,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.253 | Acc: 63.153,73.284,77.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 1.014 | Acc: 76.562,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.976 | Acc: 76.823,98.475,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.970 | Acc: 77.134,98.552,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.978 | Acc: 76.831,98.578,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.983 | Acc: 76.707,98.534,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.986 | Acc: 76.655,98.461,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.989 | Acc: 76.705,98.431,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.987 | Acc: 76.651,98.454,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.985 | Acc: 76.621,98.491,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.988 | Acc: 76.584,98.494,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.990 | Acc: 76.516,98.488,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.996 | Acc: 76.336,98.459,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.996 | Acc: 76.258,98.467,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.993 | Acc: 76.365,98.479,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.992 | Acc: 76.362,98.499,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.992 | Acc: 76.337,98.497,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.995 | Acc: 76.251,98.447,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.993 | Acc: 76.333,98.456,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.993 | Acc: 76.353,98.461,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.995 | Acc: 76.339,98.454,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.879 | Acc: 65.625,74.219,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.220 | Acc: 63.021,73.363,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.246 | Acc: 62.805,73.323,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.247 | Acc: 63.051,73.386,77.395,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 1.095 | Acc: 73.438,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.000 | Acc: 76.153,99.033,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.973 | Acc: 76.791,98.800,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.981 | Acc: 76.614,98.783,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.993 | Acc: 76.408,98.679,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.995 | Acc: 76.315,98.677,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.999 | Acc: 76.207,98.618,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.997 | Acc: 76.352,98.626,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.998 | Acc: 76.456,98.641,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.996 | Acc: 76.515,98.649,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.990 | Acc: 76.644,98.632,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.989 | Acc: 76.669,98.643,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.989 | Acc: 76.618,98.626,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.991 | Acc: 76.494,98.608,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.989 | Acc: 76.526,98.596,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.988 | Acc: 76.557,98.588,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.989 | Acc: 76.555,98.598,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.988 | Acc: 76.569,98.575,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.987 | Acc: 76.575,98.559,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.988 | Acc: 76.519,98.546,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.846 | Acc: 65.625,75.000,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.254 | Acc: 62.277,73.214,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.274 | Acc: 62.424,73.418,77.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.266 | Acc: 62.897,73.502,77.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 1.057 | Acc: 78.906,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.959 | Acc: 77.865,98.958,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.968 | Acc: 77.439,98.704,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.971 | Acc: 77.088,98.706,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.970 | Acc: 76.948,98.659,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.976 | Acc: 76.825,98.615,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.982 | Acc: 76.717,98.580,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.982 | Acc: 76.779,98.593,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.976 | Acc: 76.931,98.622,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.972 | Acc: 77.024,98.640,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.975 | Acc: 76.951,98.605,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.974 | Acc: 76.937,98.632,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.977 | Acc: 76.796,98.632,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.981 | Acc: 76.628,98.629,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.982 | Acc: 76.607,98.632,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.986 | Acc: 76.518,98.624,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.986 | Acc: 76.516,98.622,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.988 | Acc: 76.512,98.609,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.988 | Acc: 76.521,98.624,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.989 | Acc: 76.478,98.616,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.826 | Acc: 67.969,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.226 | Acc: 63.430,73.475,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.242 | Acc: 63.091,73.742,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.246 | Acc: 63.102,73.630,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 0.907 | Acc: 80.469,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.951 | Acc: 76.451,98.810,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.947 | Acc: 76.905,98.819,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.965 | Acc: 76.601,98.783,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.967 | Acc: 76.399,98.785,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.973 | Acc: 76.423,98.762,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.971 | Acc: 76.433,98.689,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.973 | Acc: 76.668,98.659,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.974 | Acc: 76.635,98.612,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.979 | Acc: 76.640,98.593,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.978 | Acc: 76.609,98.620,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.979 | Acc: 76.566,98.628,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.979 | Acc: 76.592,98.613,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.981 | Acc: 76.565,98.575,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.981 | Acc: 76.571,98.590,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.984 | Acc: 76.495,98.598,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.984 | Acc: 76.509,98.618,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.987 | Acc: 76.464,98.596,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.989 | Acc: 76.337,98.574,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.992 | Acc: 76.329,98.546,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.811 | Acc: 67.969,77.344,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.232 | Acc: 63.095,73.512,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.249 | Acc: 62.595,73.514,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.244 | Acc: 62.961,73.476,77.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 0.943 | Acc: 81.250,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.006 | Acc: 76.451,98.586,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.014 | Acc: 75.857,98.838,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.002 | Acc: 76.447,98.809,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.990 | Acc: 76.591,98.775,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.994 | Acc: 76.284,98.739,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.990 | Acc: 76.375,98.709,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.987 | Acc: 76.402,98.703,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.987 | Acc: 76.427,98.690,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.986 | Acc: 76.575,98.671,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.984 | Acc: 76.566,98.663,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.986 | Acc: 76.587,98.653,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.988 | Acc: 76.514,98.642,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.989 | Acc: 76.521,98.629,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.988 | Acc: 76.549,98.649,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.986 | Acc: 76.544,98.653,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.986 | Acc: 76.584,98.659,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.985 | Acc: 76.544,98.641,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.986 | Acc: 76.552,98.617,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.987 | Acc: 76.546,98.608,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.871 | Acc: 65.625,76.562,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.250 | Acc: 62.426,73.847,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.273 | Acc: 62.633,73.647,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.275 | Acc: 62.859,73.386,77.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 1.073 | Acc: 78.125,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.956 | Acc: 76.302,98.810,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.949 | Acc: 76.696,98.838,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.938 | Acc: 77.818,98.719,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.948 | Acc: 77.315,98.746,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.960 | Acc: 76.934,98.670,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.965 | Acc: 76.834,98.638,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.967 | Acc: 76.840,98.665,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.964 | Acc: 77.038,98.675,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.965 | Acc: 77.033,98.658,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.970 | Acc: 76.846,98.585,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.967 | Acc: 76.898,98.618,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.971 | Acc: 76.776,98.606,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.971 | Acc: 76.802,98.632,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.972 | Acc: 76.765,98.624,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.976 | Acc: 76.664,98.604,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.977 | Acc: 76.655,98.610,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.980 | Acc: 76.574,98.593,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.982 | Acc: 76.562,98.554,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.983 | Acc: 76.534,98.536,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.794 | Acc: 66.406,76.562,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.248 | Acc: 62.649,73.065,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.274 | Acc: 62.519,73.285,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.272 | Acc: 62.782,73.207,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 0.989 | Acc: 79.688,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.924 | Acc: 77.641,98.921,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.960 | Acc: 76.772,98.780,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.959 | Acc: 77.100,98.899,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.951 | Acc: 77.353,98.891,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.953 | Acc: 77.406,98.824,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.953 | Acc: 77.395,98.857,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.959 | Acc: 77.238,98.836,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.961 | Acc: 77.319,98.840,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.965 | Acc: 77.154,98.813,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.962 | Acc: 77.215,98.830,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.965 | Acc: 77.089,98.805,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.966 | Acc: 77.075,98.797,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.965 | Acc: 77.062,98.791,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.966 | Acc: 77.063,98.757,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.970 | Acc: 76.978,98.749,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.971 | Acc: 77.018,98.727,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.973 | Acc: 76.938,98.710,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.974 | Acc: 76.896,98.712,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.977 | Acc: 76.796,98.690,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.806 | Acc: 67.188,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.245 | Acc: 63.244,73.251,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.273 | Acc: 62.843,72.923,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.266 | Acc: 62.974,72.951,77.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 1.064 | Acc: 75.000,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.965 | Acc: 77.418,98.772,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.950 | Acc: 77.782,98.838,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.965 | Acc: 77.228,98.860,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.970 | Acc: 76.852,98.765,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.961 | Acc: 77.143,98.755,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.957 | Acc: 77.215,98.722,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.960 | Acc: 77.200,98.715,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.959 | Acc: 77.218,98.719,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.963 | Acc: 77.029,98.714,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.967 | Acc: 76.978,98.698,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.970 | Acc: 76.877,98.678,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.972 | Acc: 76.877,98.642,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.974 | Acc: 76.787,98.662,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.976 | Acc: 76.727,98.654,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.975 | Acc: 76.716,98.666,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.977 | Acc: 76.747,98.671,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.978 | Acc: 76.737,98.673,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.982 | Acc: 76.671,98.665,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.981 | Acc: 76.677,98.643,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.845 | Acc: 64.844,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.245 | Acc: 62.872,73.549,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.266 | Acc: 62.576,73.438,77.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.268 | Acc: 62.846,73.335,77.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 0.923 | Acc: 78.125,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.928 | Acc: 77.976,99.070,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.946 | Acc: 76.905,98.914,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.965 | Acc: 76.729,98.758,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.964 | Acc: 76.823,98.785,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.962 | Acc: 76.911,98.793,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.967 | Acc: 76.918,98.760,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.964 | Acc: 76.989,98.726,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.962 | Acc: 77.150,98.719,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.963 | Acc: 77.128,98.701,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.961 | Acc: 77.192,98.710,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.962 | Acc: 77.181,98.710,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.961 | Acc: 77.285,98.674,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.966 | Acc: 77.182,98.659,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.966 | Acc: 77.194,98.649,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.967 | Acc: 77.105,98.653,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.969 | Acc: 77.035,98.640,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.972 | Acc: 76.975,98.639,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.973 | Acc: 76.946,98.654,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.973 | Acc: 76.911,98.665,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.881 | Acc: 64.062,73.438,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.238 | Acc: 62.537,73.475,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.275 | Acc: 62.271,73.476,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.281 | Acc: 62.474,73.233,77.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 0.920 | Acc: 79.688,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.952 | Acc: 77.753,99.144,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.977 | Acc: 76.734,98.704,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.970 | Acc: 76.780,98.809,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.959 | Acc: 76.881,98.872,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.960 | Acc: 77.011,98.786,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.960 | Acc: 76.853,98.831,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.961 | Acc: 76.945,98.803,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.959 | Acc: 77.019,98.816,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.965 | Acc: 76.809,98.778,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.965 | Acc: 76.893,98.787,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.966 | Acc: 76.863,98.791,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.966 | Acc: 76.783,98.804,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.968 | Acc: 76.790,98.779,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.968 | Acc: 76.757,98.752,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.970 | Acc: 76.705,98.728,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.973 | Acc: 76.611,98.722,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.972 | Acc: 76.638,98.722,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.973 | Acc: 76.692,98.725,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.974 | Acc: 76.665,98.720,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.808 | Acc: 67.188,72.656,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.255 | Acc: 63.058,72.879,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.288 | Acc: 62.786,72.809,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.286 | Acc: 63.076,72.784,77.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 0.928 | Acc: 77.344,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.964 | Acc: 77.046,98.847,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.991 | Acc: 76.277,98.666,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.983 | Acc: 76.614,98.694,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.984 | Acc: 76.669,98.659,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.977 | Acc: 76.671,98.693,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.970 | Acc: 76.788,98.728,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.970 | Acc: 76.801,98.731,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.968 | Acc: 76.912,98.753,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.971 | Acc: 76.951,98.709,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.971 | Acc: 77.029,98.690,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.970 | Acc: 77.029,98.706,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.969 | Acc: 77.068,98.681,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.974 | Acc: 76.970,98.677,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.975 | Acc: 76.927,98.677,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.974 | Acc: 76.921,98.676,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.975 | Acc: 76.889,98.676,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.974 | Acc: 76.906,98.687,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.975 | Acc: 76.837,98.669,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.976 | Acc: 76.792,98.663,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.836 | Acc: 66.406,72.656,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.239 | Acc: 63.356,73.326,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.267 | Acc: 62.881,73.152,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.273 | Acc: 62.795,73.117,77.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 1.030 | Acc: 75.000,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.964 | Acc: 75.632,98.549,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.960 | Acc: 76.791,98.533,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.950 | Acc: 77.216,98.668,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.957 | Acc: 77.199,98.669,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.965 | Acc: 76.911,98.615,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.960 | Acc: 77.195,98.567,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.958 | Acc: 77.222,98.615,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.964 | Acc: 77.043,98.646,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.970 | Acc: 76.873,98.619,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.972 | Acc: 76.749,98.647,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.974 | Acc: 76.693,98.607,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.971 | Acc: 76.744,98.619,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.972 | Acc: 76.697,98.626,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.971 | Acc: 76.757,98.618,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.972 | Acc: 76.705,98.632,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.974 | Acc: 76.638,98.625,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.973 | Acc: 76.693,98.584,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.972 | Acc: 76.740,98.589,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.974 | Acc: 76.751,98.583,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.882 | Acc: 66.406,75.781,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.244 | Acc: 62.612,73.326,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.274 | Acc: 62.329,73.361,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.271 | Acc: 62.782,73.156,77.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 0.872 | Acc: 79.688,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.968 | Acc: 77.939,98.847,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.959 | Acc: 77.687,99.009,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.951 | Acc: 77.920,98.950,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.952 | Acc: 77.826,98.910,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.952 | Acc: 77.854,98.871,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.958 | Acc: 77.570,98.851,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.957 | Acc: 77.549,98.859,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.960 | Acc: 77.446,98.816,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.961 | Acc: 77.413,98.804,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.963 | Acc: 77.293,98.803,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.961 | Acc: 77.284,98.812,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.962 | Acc: 77.217,98.810,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.966 | Acc: 77.158,98.806,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.965 | Acc: 77.074,98.788,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.965 | Acc: 77.136,98.762,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.965 | Acc: 77.108,98.751,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.967 | Acc: 77.044,98.731,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.967 | Acc: 77.030,98.732,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.968 | Acc: 76.985,98.735,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.877 | Acc: 64.844,75.781,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.236 | Acc: 62.686,73.140,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.269 | Acc: 62.652,73.075,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.266 | Acc: 63.102,73.040,77.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 0.947 | Acc: 74.219,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.961 | Acc: 76.711,98.921,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.946 | Acc: 77.515,98.857,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.944 | Acc: 77.382,98.835,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.949 | Acc: 77.479,98.823,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.951 | Acc: 77.468,98.801,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.956 | Acc: 77.415,98.793,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.956 | Acc: 77.222,98.853,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.958 | Acc: 77.174,98.865,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.957 | Acc: 77.232,98.860,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.958 | Acc: 77.215,98.818,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.954 | Acc: 77.238,98.809,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.955 | Acc: 77.165,98.810,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.958 | Acc: 77.092,98.797,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.959 | Acc: 77.049,98.816,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.960 | Acc: 77.071,98.796,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.961 | Acc: 77.098,98.781,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.963 | Acc: 77.078,98.761,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.965 | Acc: 77.017,98.762,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.966 | Acc: 77.003,98.755,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.937 | Acc: 67.188,72.656,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.276 | Acc: 62.984,72.507,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.308 | Acc: 62.348,72.961,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.309 | Acc: 62.500,73.015,77.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 0.889 | Acc: 75.000,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.958 | Acc: 77.083,98.996,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.944 | Acc: 77.363,99.066,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.963 | Acc: 77.177,98.899,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.968 | Acc: 77.045,98.843,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.973 | Acc: 76.787,98.670,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.970 | Acc: 76.860,98.696,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.971 | Acc: 76.845,98.731,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.973 | Acc: 76.786,98.724,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.969 | Acc: 76.916,98.774,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.965 | Acc: 77.095,98.799,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.967 | Acc: 77.001,98.780,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.967 | Acc: 76.939,98.771,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.967 | Acc: 76.937,98.749,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.966 | Acc: 77.035,98.774,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.965 | Acc: 77.027,98.770,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.966 | Acc: 77.032,98.751,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.965 | Acc: 77.009,98.767,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.965 | Acc: 77.004,98.740,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.968 | Acc: 76.946,98.739,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.862 | Acc: 64.062,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.245 | Acc: 63.356,72.991,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.287 | Acc: 62.633,72.866,77.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.280 | Acc: 63.025,72.836,77.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 0.992 | Acc: 76.562,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.967 | Acc: 76.786,98.661,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.961 | Acc: 76.848,98.933,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.955 | Acc: 76.742,99.014,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.951 | Acc: 77.006,99.026,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.956 | Acc: 76.972,99.018,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.955 | Acc: 76.892,98.999,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.953 | Acc: 76.973,98.986,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.958 | Acc: 76.936,98.928,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.956 | Acc: 77.093,98.921,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.961 | Acc: 77.002,98.881,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.959 | Acc: 77.054,98.851,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.959 | Acc: 77.068,98.833,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.959 | Acc: 77.068,98.812,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.960 | Acc: 77.032,98.827,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.961 | Acc: 76.988,98.832,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.962 | Acc: 76.993,98.817,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.959 | Acc: 77.105,98.832,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.962 | Acc: 76.993,98.803,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.961 | Acc: 77.001,98.798,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.927 | Acc: 66.406,74.219,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.241 | Acc: 62.686,73.326,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.277 | Acc: 62.271,73.209,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.271 | Acc: 62.679,72.976,77.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 1.106 | Acc: 70.312,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.917 | Acc: 79.167,99.256,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.934 | Acc: 78.087,99.143,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.932 | Acc: 78.087,99.065,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.946 | Acc: 77.353,99.026,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.954 | Acc: 77.220,98.971,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.957 | Acc: 77.027,98.883,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.956 | Acc: 76.989,98.908,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.956 | Acc: 76.999,98.913,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.960 | Acc: 76.899,98.895,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.960 | Acc: 76.932,98.888,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.962 | Acc: 76.891,98.883,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.962 | Acc: 76.857,98.836,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.965 | Acc: 76.784,98.836,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.964 | Acc: 76.852,98.832,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.963 | Acc: 76.895,98.801,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.960 | Acc: 76.984,98.795,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.960 | Acc: 77.023,98.781,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.959 | Acc: 77.112,98.777,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.960 | Acc: 77.096,98.784,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.891 | Acc: 68.750,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.254 | Acc: 62.835,72.879,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.294 | Acc: 62.252,73.171,77.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.293 | Acc: 62.859,73.194,77.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 0.933 | Acc: 74.219,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.943 | Acc: 77.158,98.772,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.940 | Acc: 77.439,98.876,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.953 | Acc: 77.305,98.694,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.948 | Acc: 77.363,98.794,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.950 | Acc: 77.166,98.801,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.951 | Acc: 77.150,98.773,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.953 | Acc: 77.139,98.781,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.957 | Acc: 76.926,98.753,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.959 | Acc: 76.886,98.791,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.959 | Acc: 76.870,98.764,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.958 | Acc: 76.944,98.749,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.959 | Acc: 76.942,98.749,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.959 | Acc: 76.910,98.743,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.959 | Acc: 76.968,98.746,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.959 | Acc: 76.975,98.752,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.959 | Acc: 76.988,98.747,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.958 | Acc: 76.991,98.742,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.962 | Acc: 76.948,98.719,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.962 | Acc: 77.005,98.723,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.923 | Acc: 67.969,72.656,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.241 | Acc: 63.430,73.363,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.279 | Acc: 63.014,72.999,77.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.282 | Acc: 63.217,72.912,77.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 0.808 | Acc: 78.125,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.943 | Acc: 77.679,99.107,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.957 | Acc: 77.001,99.028,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.961 | Acc: 76.806,99.001,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.961 | Acc: 76.842,98.968,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.966 | Acc: 76.818,98.917,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.967 | Acc: 76.905,98.883,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.968 | Acc: 76.906,98.814,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.967 | Acc: 76.931,98.782,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.967 | Acc: 77.059,98.791,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.967 | Acc: 77.165,98.780,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.963 | Acc: 77.266,98.795,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.961 | Acc: 77.243,98.794,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.963 | Acc: 77.266,98.782,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.963 | Acc: 77.319,98.732,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.962 | Acc: 77.377,98.720,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.958 | Acc: 77.431,98.742,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.958 | Acc: 77.442,98.733,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.957 | Acc: 77.437,98.745,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.958 | Acc: 77.420,98.747,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.902 | Acc: 62.500,74.219,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.267 | Acc: 62.463,72.805,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.294 | Acc: 62.519,73.018,77.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.289 | Acc: 62.897,72.746,77.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 0.864 | Acc: 79.688,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.983 | Acc: 75.781,98.921,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.949 | Acc: 76.582,98.876,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.951 | Acc: 76.844,98.860,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.947 | Acc: 77.103,98.843,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.946 | Acc: 77.259,98.902,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.950 | Acc: 77.221,98.851,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.950 | Acc: 77.305,98.836,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.952 | Acc: 77.290,98.816,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.951 | Acc: 77.326,98.761,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.953 | Acc: 77.340,98.776,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.956 | Acc: 77.220,98.798,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.958 | Acc: 77.188,98.794,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.960 | Acc: 77.131,98.797,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.961 | Acc: 77.082,98.816,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.962 | Acc: 76.967,98.829,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.961 | Acc: 77.025,98.822,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.962 | Acc: 76.996,98.834,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.961 | Acc: 77.013,98.842,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.961 | Acc: 77.073,98.844,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.909 | Acc: 64.844,73.438,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.287 | Acc: 62.872,72.693,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.310 | Acc: 62.462,72.675,77.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.308 | Acc: 62.679,72.464,77.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 0.940 | Acc: 81.250,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.928 | Acc: 78.423,98.884,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.931 | Acc: 77.954,99.085,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.947 | Acc: 77.395,98.975,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.956 | Acc: 77.103,98.910,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.950 | Acc: 77.235,99.010,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.948 | Acc: 77.370,98.967,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.944 | Acc: 77.582,98.969,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.943 | Acc: 77.844,98.957,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.945 | Acc: 77.585,98.930,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.942 | Acc: 77.604,98.919,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.950 | Acc: 77.376,98.918,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.949 | Acc: 77.464,98.927,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.951 | Acc: 77.449,98.875,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.952 | Acc: 77.358,98.852,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.952 | Acc: 77.357,98.832,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.952 | Acc: 77.346,98.834,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.953 | Acc: 77.307,98.820,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.953 | Acc: 77.331,98.838,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.953 | Acc: 77.301,98.837,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.893 | Acc: 64.062,75.000,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.290 | Acc: 62.686,73.028,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.333 | Acc: 62.329,72.637,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.333 | Acc: 62.705,72.605,77.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 1.045 | Acc: 76.562,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.931 | Acc: 77.158,99.107,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.929 | Acc: 77.515,99.047,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.928 | Acc: 77.741,99.027,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.929 | Acc: 77.691,99.055,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.930 | Acc: 77.839,98.987,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.931 | Acc: 77.841,98.922,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.937 | Acc: 77.776,98.947,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.946 | Acc: 77.562,98.898,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.945 | Acc: 77.529,98.891,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.944 | Acc: 77.515,98.884,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.945 | Acc: 77.460,98.872,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.945 | Acc: 77.480,98.878,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.946 | Acc: 77.514,98.884,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.946 | Acc: 77.544,98.857,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.950 | Acc: 77.453,98.848,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.951 | Acc: 77.453,98.827,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.954 | Acc: 77.357,98.797,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.953 | Acc: 77.348,98.795,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.955 | Acc: 77.315,98.796,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.830 | Acc: 65.625,75.781,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.321 | Acc: 62.463,72.545,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.328 | Acc: 62.443,72.885,77.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.328 | Acc: 62.487,72.733,77.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 0.943 | Acc: 75.781,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.950 | Acc: 77.269,99.144,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.941 | Acc: 77.439,99.181,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.945 | Acc: 77.638,99.027,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.945 | Acc: 77.517,99.084,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.942 | Acc: 77.738,99.072,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.943 | Acc: 77.621,99.064,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.944 | Acc: 77.698,99.041,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.944 | Acc: 77.664,99.015,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.944 | Acc: 77.516,99.025,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.947 | Acc: 77.418,98.997,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.948 | Acc: 77.432,98.971,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.947 | Acc: 77.405,98.946,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.948 | Acc: 77.416,98.931,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.948 | Acc: 77.416,98.888,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.948 | Acc: 77.396,98.892,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.950 | Acc: 77.319,98.871,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.950 | Acc: 77.273,98.866,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.953 | Acc: 77.244,98.836,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.953 | Acc: 77.243,98.815,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.876 | Acc: 65.625,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.276 | Acc: 62.463,73.214,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.316 | Acc: 62.043,72.847,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.317 | Acc: 62.602,72.707,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 0.894 | Acc: 75.000,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.971 | Acc: 76.451,99.144,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.968 | Acc: 77.287,98.742,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.948 | Acc: 77.613,98.873,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.947 | Acc: 77.739,98.900,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.949 | Acc: 77.800,98.878,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.945 | Acc: 77.789,98.870,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.947 | Acc: 77.698,98.886,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.950 | Acc: 77.771,98.850,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.952 | Acc: 77.655,98.813,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.948 | Acc: 77.791,98.834,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.948 | Acc: 77.711,98.809,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.950 | Acc: 77.665,98.843,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.952 | Acc: 77.463,98.860,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.952 | Acc: 77.422,98.868,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.954 | Acc: 77.372,98.848,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.953 | Acc: 77.339,98.851,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.951 | Acc: 77.392,98.854,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.952 | Acc: 77.309,98.877,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.951 | Acc: 77.315,98.872,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.905 | Acc: 65.625,72.656,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.298 | Acc: 62.388,72.731,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.334 | Acc: 62.519,72.828,77.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.326 | Acc: 62.756,72.720,77.677,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 0.924 | Acc: 78.125,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.904 | Acc: 78.683,99.144,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.921 | Acc: 78.563,99.066,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.926 | Acc: 78.176,98.937,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.926 | Acc: 78.250,98.891,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.927 | Acc: 78.017,98.878,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.932 | Acc: 78.022,98.812,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.937 | Acc: 77.854,98.781,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.938 | Acc: 77.776,98.792,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.941 | Acc: 77.745,98.817,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.944 | Acc: 77.697,98.850,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.946 | Acc: 77.619,98.823,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.945 | Acc: 77.610,98.788,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.948 | Acc: 77.455,98.794,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.950 | Acc: 77.374,98.779,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.950 | Acc: 77.326,98.770,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.951 | Acc: 77.339,98.764,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.951 | Acc: 77.357,98.751,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.953 | Acc: 77.292,98.756,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.954 | Acc: 77.288,98.755,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.858 | Acc: 67.188,78.125,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.294 | Acc: 62.500,72.656,77.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.325 | Acc: 62.538,72.809,77.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.321 | Acc: 62.807,72.695,77.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 0.891 | Acc: 80.469,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.926 | Acc: 78.757,98.772,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.942 | Acc: 77.687,98.895,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.952 | Acc: 77.344,98.886,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.951 | Acc: 77.382,98.900,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.948 | Acc: 77.452,98.863,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.943 | Acc: 77.789,98.870,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.949 | Acc: 77.576,98.825,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.950 | Acc: 77.582,98.835,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.953 | Acc: 77.408,98.813,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.951 | Acc: 77.421,98.822,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.952 | Acc: 77.319,98.812,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.951 | Acc: 77.324,98.817,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.951 | Acc: 77.344,98.812,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.953 | Acc: 77.296,98.793,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.952 | Acc: 77.323,98.775,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.952 | Acc: 77.329,98.751,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.952 | Acc: 77.330,98.754,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.953 | Acc: 77.270,98.760,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.954 | Acc: 77.247,98.766,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.822 | Acc: 66.406,76.562,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.277 | Acc: 62.351,72.842,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.306 | Acc: 62.119,72.904,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.307 | Acc: 62.513,72.567,77.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 0.869 | Acc: 80.469,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.969 | Acc: 76.562,98.772,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.949 | Acc: 77.325,98.895,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.942 | Acc: 77.561,98.924,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.939 | Acc: 77.633,98.881,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.940 | Acc: 77.700,98.871,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.936 | Acc: 77.815,98.896,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.940 | Acc: 77.588,98.947,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.946 | Acc: 77.552,98.894,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.943 | Acc: 77.620,98.882,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.944 | Acc: 77.604,98.850,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.946 | Acc: 77.574,98.826,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.949 | Acc: 77.425,98.781,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.950 | Acc: 77.395,98.770,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.948 | Acc: 77.469,98.768,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.949 | Acc: 77.429,98.762,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.949 | Acc: 77.409,98.764,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.950 | Acc: 77.369,98.745,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.950 | Acc: 77.376,98.745,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.950 | Acc: 77.405,98.753,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.932 | Acc: 64.062,71.094,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.321 | Acc: 62.500,72.545,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.342 | Acc: 62.805,72.637,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.334 | Acc: 62.679,72.618,77.369,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 1.037 | Acc: 76.562,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.951 | Acc: 76.302,99.070,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.973 | Acc: 76.582,98.952,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.964 | Acc: 76.947,98.924,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.970 | Acc: 76.861,98.881,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.965 | Acc: 76.911,98.933,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.955 | Acc: 77.195,98.954,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.950 | Acc: 77.371,98.958,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.948 | Acc: 77.378,98.923,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.949 | Acc: 77.460,98.895,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.948 | Acc: 77.402,98.896,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.946 | Acc: 77.436,98.901,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.945 | Acc: 77.473,98.882,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.944 | Acc: 77.550,98.892,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.944 | Acc: 77.547,98.880,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.946 | Acc: 77.448,98.866,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.947 | Acc: 77.465,98.859,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.947 | Acc: 77.435,98.852,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.945 | Acc: 77.508,98.866,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.946 | Acc: 77.420,98.872,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.926 | Acc: 65.625,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.291 | Acc: 63.021,72.693,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.320 | Acc: 62.557,72.732,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.314 | Acc: 62.948,72.669,77.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 0.954 | Acc: 78.906,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.908 | Acc: 78.795,98.921,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.916 | Acc: 78.049,98.895,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.933 | Acc: 77.536,98.950,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.932 | Acc: 77.836,98.891,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.930 | Acc: 78.094,98.871,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.927 | Acc: 78.138,98.915,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.930 | Acc: 78.125,98.892,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.930 | Acc: 77.950,98.908,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.935 | Acc: 77.754,98.912,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.937 | Acc: 77.585,98.900,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.935 | Acc: 77.602,98.908,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.933 | Acc: 77.733,98.891,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.936 | Acc: 77.679,98.845,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.935 | Acc: 77.705,98.860,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.937 | Acc: 77.616,98.868,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.937 | Acc: 77.573,98.844,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.942 | Acc: 77.481,98.848,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.944 | Acc: 77.424,98.838,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.944 | Acc: 77.440,98.846,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.935 | Acc: 64.062,73.438,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.269 | Acc: 63.207,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.283 | Acc: 62.881,73.247,77.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.284 | Acc: 63.064,72.989,77.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 0.829 | Acc: 82.812,99.219,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.905 | Acc: 78.497,98.921,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.895 | Acc: 78.830,98.857,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.914 | Acc: 78.381,98.963,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.921 | Acc: 78.279,98.939,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.921 | Acc: 78.148,98.987,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.924 | Acc: 78.028,98.960,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.922 | Acc: 78.086,98.958,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.923 | Acc: 77.984,98.952,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.926 | Acc: 77.918,98.925,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.926 | Acc: 77.880,98.927,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.931 | Acc: 77.715,98.908,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.933 | Acc: 77.726,98.895,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.937 | Acc: 77.703,98.886,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.940 | Acc: 77.655,98.871,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.941 | Acc: 77.619,98.871,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.943 | Acc: 77.548,98.856,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.943 | Acc: 77.559,98.829,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.943 | Acc: 77.539,98.836,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.943 | Acc: 77.516,98.839,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.860 | Acc: 62.500,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.287 | Acc: 62.574,72.619,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.304 | Acc: 62.557,72.637,77.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.297 | Acc: 63.140,72.515,77.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 0.823 | Acc: 84.375,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.944 | Acc: 77.641,99.033,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.934 | Acc: 77.477,98.990,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.926 | Acc: 77.651,99.052,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.926 | Acc: 77.681,99.045,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.923 | Acc: 77.769,99.010,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.923 | Acc: 77.705,99.019,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.920 | Acc: 77.865,99.008,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.921 | Acc: 77.955,99.010,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.925 | Acc: 77.866,98.964,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.929 | Acc: 77.799,98.931,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.932 | Acc: 77.754,98.918,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.933 | Acc: 77.752,98.911,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.934 | Acc: 77.787,98.875,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.936 | Acc: 77.702,98.880,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.934 | Acc: 77.814,98.894,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.935 | Acc: 77.857,98.856,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.937 | Acc: 77.823,98.864,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.938 | Acc: 77.809,98.847,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.940 | Acc: 77.760,98.817,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.971 | Acc: 66.406,73.438,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.299 | Acc: 63.318,72.879,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.335 | Acc: 62.576,72.752,77.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.334 | Acc: 62.769,72.554,77.357,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 0.885 | Acc: 74.219,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.915 | Acc: 76.897,99.256,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.919 | Acc: 77.248,99.143,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.927 | Acc: 77.587,99.052,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.923 | Acc: 77.971,99.007,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.924 | Acc: 78.079,98.994,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.924 | Acc: 77.912,99.025,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.928 | Acc: 77.759,98.997,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.927 | Acc: 77.844,98.962,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.929 | Acc: 77.935,98.947,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.932 | Acc: 77.900,98.947,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.934 | Acc: 77.874,98.947,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.934 | Acc: 77.888,98.946,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.935 | Acc: 77.850,98.925,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.935 | Acc: 77.819,98.927,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.935 | Acc: 77.762,98.918,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.936 | Acc: 77.716,98.932,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.936 | Acc: 77.660,98.937,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.938 | Acc: 77.597,98.927,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.939 | Acc: 77.616,98.889,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.932 | Acc: 65.625,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.316 | Acc: 62.054,72.879,76.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.352 | Acc: 61.814,72.599,76.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.339 | Acc: 62.346,72.669,77.100,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 0.971 | Acc: 76.562,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.916 | Acc: 78.795,99.033,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.899 | Acc: 79.002,99.123,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.913 | Acc: 78.599,98.937,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.915 | Acc: 78.453,98.929,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.917 | Acc: 78.427,99.025,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.912 | Acc: 78.506,99.012,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.918 | Acc: 78.258,98.942,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.924 | Acc: 77.989,98.923,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.925 | Acc: 77.935,98.912,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.928 | Acc: 77.853,98.888,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.928 | Acc: 77.807,98.848,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.929 | Acc: 77.762,98.856,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.929 | Acc: 77.763,98.842,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.932 | Acc: 77.641,98.852,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.933 | Acc: 77.647,98.853,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.936 | Acc: 77.611,98.837,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.936 | Acc: 77.635,98.836,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.938 | Acc: 77.564,98.825,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.937 | Acc: 77.541,98.827,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.958 | Acc: 66.406,75.000,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.343 | Acc: 62.016,72.470,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.360 | Acc: 61.719,72.675,77.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.364 | Acc: 61.975,72.541,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 0.986 | Acc: 75.781,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.915 | Acc: 78.609,98.810,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.910 | Acc: 78.849,98.838,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.927 | Acc: 78.048,98.809,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.927 | Acc: 78.067,98.900,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.929 | Acc: 77.777,98.917,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.929 | Acc: 77.912,98.902,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.927 | Acc: 77.854,98.864,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.929 | Acc: 77.848,98.928,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.927 | Acc: 77.931,98.908,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.931 | Acc: 77.822,98.935,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.928 | Acc: 77.906,98.932,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.930 | Acc: 77.895,98.927,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.933 | Acc: 77.808,98.904,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.934 | Acc: 77.780,98.893,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.934 | Acc: 77.814,98.874,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.935 | Acc: 77.794,98.859,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.936 | Acc: 77.768,98.827,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.939 | Acc: 77.694,98.831,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.939 | Acc: 77.684,98.839,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.927 | Acc: 65.625,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.315 | Acc: 62.426,72.991,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.330 | Acc: 62.233,72.885,77.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.322 | Acc: 62.756,72.810,77.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 0.799 | Acc: 80.469,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.894 | Acc: 79.464,98.698,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.927 | Acc: 78.697,98.742,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.932 | Acc: 78.394,98.873,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.932 | Acc: 78.501,98.833,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.933 | Acc: 78.342,98.824,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.927 | Acc: 78.629,98.889,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.931 | Acc: 78.441,98.836,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.938 | Acc: 78.164,98.816,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.936 | Acc: 78.112,98.800,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.936 | Acc: 78.043,98.822,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.935 | Acc: 77.980,98.816,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.934 | Acc: 77.979,98.814,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.936 | Acc: 77.948,98.806,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.937 | Acc: 77.928,98.810,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.939 | Acc: 77.811,98.798,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.938 | Acc: 77.823,98.788,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.938 | Acc: 77.871,98.802,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.939 | Acc: 77.837,98.810,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.939 | Acc: 77.817,98.819,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.927 | Acc: 65.625,73.438,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.314 | Acc: 62.686,72.507,77.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.344 | Acc: 62.519,72.409,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.338 | Acc: 62.756,72.374,77.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 0.885 | Acc: 81.250,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.931 | Acc: 77.865,98.772,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.944 | Acc: 77.439,98.761,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.942 | Acc: 77.421,98.835,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.950 | Acc: 77.296,98.843,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.947 | Acc: 77.266,98.793,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.940 | Acc: 77.596,98.741,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.932 | Acc: 77.842,98.792,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.934 | Acc: 77.742,98.792,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.938 | Acc: 77.607,98.783,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.943 | Acc: 77.375,98.748,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.942 | Acc: 77.277,98.770,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.940 | Acc: 77.370,98.810,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.940 | Acc: 77.419,98.815,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.941 | Acc: 77.469,98.804,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.939 | Acc: 77.536,98.816,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.939 | Acc: 77.594,98.815,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.940 | Acc: 77.607,98.825,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.940 | Acc: 77.629,98.821,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.941 | Acc: 77.600,98.829,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.033 | Acc: 59.375,72.656,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.335 | Acc: 61.905,72.768,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.366 | Acc: 61.890,72.523,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.359 | Acc: 62.372,72.605,77.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 0.988 | Acc: 79.688,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.937 | Acc: 77.307,99.144,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.918 | Acc: 78.087,99.104,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.938 | Acc: 77.664,98.975,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.931 | Acc: 77.894,98.978,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.924 | Acc: 77.970,99.025,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.922 | Acc: 78.060,99.032,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.918 | Acc: 78.114,99.053,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.918 | Acc: 78.120,99.054,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.923 | Acc: 77.957,99.016,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.922 | Acc: 77.973,99.021,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.926 | Acc: 77.973,98.993,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.927 | Acc: 78.028,99.002,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.931 | Acc: 77.877,98.991,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.931 | Acc: 77.942,98.980,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.932 | Acc: 77.910,98.962,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.936 | Acc: 77.828,98.934,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.937 | Acc: 77.811,98.925,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.939 | Acc: 77.738,98.901,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.938 | Acc: 77.754,98.897,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.011 | Acc: 65.625,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.322 | Acc: 62.240,72.842,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.355 | Acc: 62.100,72.370,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.353 | Acc: 62.449,72.285,77.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 0.792 | Acc: 80.469,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.891 | Acc: 78.869,99.144,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.914 | Acc: 77.858,99.123,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.918 | Acc: 77.561,99.129,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.926 | Acc: 77.488,99.045,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.932 | Acc: 77.336,99.049,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.935 | Acc: 77.292,99.025,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.934 | Acc: 77.405,99.058,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.933 | Acc: 77.533,99.083,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.928 | Acc: 77.693,99.068,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.929 | Acc: 77.666,99.044,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.928 | Acc: 77.757,99.046,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.929 | Acc: 77.785,99.024,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.929 | Acc: 77.826,98.994,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.930 | Acc: 77.769,98.971,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.930 | Acc: 77.780,98.962,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.930 | Acc: 77.787,98.961,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.932 | Acc: 77.781,98.955,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.929 | Acc: 77.906,98.948,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.932 | Acc: 77.824,98.940,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.968 | Acc: 64.062,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.330 | Acc: 62.835,72.693,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.368 | Acc: 62.462,72.123,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.360 | Acc: 62.769,72.157,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 0.976 | Acc: 74.219,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.906 | Acc: 78.237,99.368,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.922 | Acc: 78.068,99.162,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.915 | Acc: 78.215,99.219,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.923 | Acc: 77.942,99.199,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.921 | Acc: 78.102,99.126,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.919 | Acc: 78.228,99.083,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.920 | Acc: 78.180,99.019,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.922 | Acc: 78.198,98.996,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.924 | Acc: 78.013,98.981,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.926 | Acc: 77.962,98.958,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.927 | Acc: 77.980,98.957,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.928 | Acc: 77.963,98.930,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.928 | Acc: 77.975,98.943,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.929 | Acc: 77.972,98.935,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.928 | Acc: 77.967,98.918,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.931 | Acc: 77.894,98.910,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.932 | Acc: 77.868,98.919,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.933 | Acc: 77.813,98.922,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.932 | Acc: 77.881,98.934,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.976 | Acc: 60.156,73.438,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.324 | Acc: 62.091,72.359,77.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.363 | Acc: 62.367,72.523,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.357 | Acc: 62.654,72.426,77.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 0.963 | Acc: 73.438,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.894 | Acc: 78.981,99.144,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.917 | Acc: 78.678,99.104,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.929 | Acc: 78.458,99.078,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.933 | Acc: 78.154,98.949,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.939 | Acc: 77.823,98.871,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.945 | Acc: 77.615,98.838,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.943 | Acc: 77.671,98.831,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.937 | Acc: 77.776,98.869,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.934 | Acc: 77.862,98.886,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.930 | Acc: 77.973,98.892,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.930 | Acc: 77.987,98.894,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.931 | Acc: 77.908,98.901,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.929 | Acc: 77.957,98.934,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.929 | Acc: 77.928,98.918,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.928 | Acc: 77.954,98.915,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.928 | Acc: 77.952,98.915,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.928 | Acc: 77.978,98.916,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.928 | Acc: 77.986,98.905,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.928 | Acc: 77.981,98.923,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.047 | Acc: 64.062,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.329 | Acc: 62.388,72.135,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.345 | Acc: 62.519,72.218,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.343 | Acc: 62.743,72.310,77.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 0.933 | Acc: 74.219,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.880 | Acc: 78.757,99.070,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.881 | Acc: 79.173,99.352,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.891 | Acc: 79.034,99.193,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.901 | Acc: 78.829,99.219,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.897 | Acc: 78.875,99.242,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.903 | Acc: 78.758,99.206,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.898 | Acc: 78.934,99.158,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.898 | Acc: 78.931,99.194,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.896 | Acc: 78.962,99.197,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.897 | Acc: 78.976,99.153,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.895 | Acc: 79.034,99.180,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.890 | Acc: 79.149,99.177,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.890 | Acc: 79.140,99.180,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.888 | Acc: 79.204,99.199,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.888 | Acc: 79.155,99.206,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.887 | Acc: 79.208,99.207,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.888 | Acc: 79.204,99.207,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.888 | Acc: 79.218,99.230,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.889 | Acc: 79.148,99.245,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.905 | Acc: 65.625,75.781,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.263 | Acc: 63.318,72.693,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.283 | Acc: 63.681,72.866,77.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.279 | Acc: 63.934,72.784,77.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 0.840 | Acc: 81.250,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.842 | Acc: 80.208,99.033,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.878 | Acc: 79.611,99.257,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.888 | Acc: 79.162,99.308,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.880 | Acc: 79.196,99.257,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.885 | Acc: 78.976,99.288,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.882 | Acc: 78.932,99.309,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.882 | Acc: 78.912,99.307,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.880 | Acc: 79.003,99.321,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.880 | Acc: 79.079,99.288,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.877 | Acc: 79.116,99.293,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.877 | Acc: 79.104,99.321,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.876 | Acc: 79.166,99.313,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.877 | Acc: 79.140,99.312,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.876 | Acc: 79.106,99.316,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.877 | Acc: 79.124,99.320,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.877 | Acc: 79.145,99.321,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.877 | Acc: 79.151,99.338,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.876 | Acc: 79.159,99.340,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.874 | Acc: 79.226,99.342,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.856 | Acc: 64.844,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.266 | Acc: 63.095,72.768,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.289 | Acc: 63.491,72.561,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.286 | Acc: 63.755,72.643,77.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 1.276 | Acc: 68.750,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.897 | Acc: 77.753,99.256,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.884 | Acc: 78.735,99.276,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.877 | Acc: 79.073,99.193,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.880 | Acc: 79.109,99.286,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.874 | Acc: 79.432,99.281,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.877 | Acc: 79.494,99.245,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.875 | Acc: 79.555,99.241,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.875 | Acc: 79.401,99.262,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.876 | Acc: 79.342,99.249,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.873 | Acc: 79.419,99.269,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 79.511,99.268,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.872 | Acc: 79.415,99.264,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.872 | Acc: 79.514,99.252,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.871 | Acc: 79.523,99.258,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 79.527,99.255,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.871 | Acc: 79.583,99.246,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 79.548,99.260,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.870 | Acc: 79.545,99.258,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.873 | Acc: 79.497,99.258,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.871 | Acc: 66.406,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.253 | Acc: 63.281,72.917,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.281 | Acc: 63.396,72.752,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.273 | Acc: 63.832,72.695,77.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 0.870 | Acc: 79.688,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.855 | Acc: 79.315,99.405,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.857 | Acc: 80.202,99.352,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.860 | Acc: 80.097,99.321,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.867 | Acc: 79.919,99.257,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.863 | Acc: 79.804,99.288,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.869 | Acc: 79.707,99.245,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.872 | Acc: 79.593,99.258,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.873 | Acc: 79.547,99.272,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.872 | Acc: 79.489,99.292,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.874 | Acc: 79.493,99.269,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.872 | Acc: 79.511,99.293,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.870 | Acc: 79.516,99.300,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 79.484,99.306,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.873 | Acc: 79.398,99.324,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 79.454,99.320,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.873 | Acc: 79.403,99.314,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.872 | Acc: 79.415,99.313,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.874 | Acc: 79.359,99.318,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.874 | Acc: 79.320,99.319,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.889 | Acc: 65.625,76.562,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.263 | Acc: 63.170,72.842,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.289 | Acc: 63.338,72.790,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.285 | Acc: 63.704,72.810,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 0.928 | Acc: 75.000,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.868 | Acc: 78.869,99.368,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.857 | Acc: 79.764,99.371,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.856 | Acc: 79.777,99.385,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.856 | Acc: 79.948,99.383,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 79.819,99.366,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.858 | Acc: 79.888,99.341,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.858 | Acc: 79.854,99.335,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.861 | Acc: 79.726,99.359,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 79.688,99.370,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.865 | Acc: 79.625,99.374,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.865 | Acc: 79.702,99.364,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.864 | Acc: 79.749,99.355,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.865 | Acc: 79.693,99.356,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.864 | Acc: 79.743,99.349,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.865 | Acc: 79.700,99.330,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 79.646,99.328,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.869 | Acc: 79.616,99.301,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.871 | Acc: 79.540,99.294,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.873 | Acc: 79.489,99.297,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.893 | Acc: 64.844,75.000,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.255 | Acc: 63.170,72.954,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.283 | Acc: 63.357,72.904,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.279 | Acc: 63.730,72.861,77.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 0.826 | Acc: 85.156,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.848 | Acc: 80.506,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.856 | Acc: 79.821,99.333,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 79.239,99.321,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.863 | Acc: 79.350,99.412,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 79.471,99.397,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.863 | Acc: 79.520,99.329,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.864 | Acc: 79.494,99.291,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.862 | Acc: 79.474,99.296,99.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.864 | Acc: 79.467,99.271,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.867 | Acc: 79.478,99.238,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.869 | Acc: 79.475,99.240,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 79.532,99.248,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.870 | Acc: 79.406,99.255,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.871 | Acc: 79.348,99.274,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 79.335,99.268,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.872 | Acc: 79.374,99.275,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.872 | Acc: 79.376,99.285,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.871 | Acc: 79.439,99.290,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.871 | Acc: 79.431,99.299,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.848 | Acc: 65.625,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.252 | Acc: 63.021,73.251,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.287 | Acc: 63.148,72.885,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.282 | Acc: 63.589,72.784,77.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 0.841 | Acc: 82.812,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.862 | Acc: 80.618,99.368,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.874 | Acc: 80.145,99.276,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.871 | Acc: 79.419,99.296,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 79.581,99.277,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 79.455,99.257,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.877 | Acc: 79.171,99.283,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.874 | Acc: 79.289,99.318,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.874 | Acc: 79.207,99.301,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.871 | Acc: 79.329,99.322,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.869 | Acc: 79.404,99.316,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.869 | Acc: 79.387,99.321,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.870 | Acc: 79.373,99.339,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.869 | Acc: 79.415,99.327,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.869 | Acc: 79.415,99.319,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.870 | Acc: 79.415,99.315,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.872 | Acc: 79.395,99.299,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.873 | Acc: 79.337,99.306,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.871 | Acc: 79.456,99.323,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.869 | Acc: 79.513,99.334,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.871 | Acc: 65.625,75.781,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.262 | Acc: 63.207,72.917,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.292 | Acc: 63.377,72.732,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.288 | Acc: 63.742,72.746,77.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 0.802 | Acc: 85.156,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.876 | Acc: 79.650,99.330,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.870 | Acc: 79.287,99.371,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.873 | Acc: 78.970,99.411,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.863 | Acc: 79.466,99.460,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.864 | Acc: 79.571,99.443,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.866 | Acc: 79.700,99.425,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 79.660,99.407,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.864 | Acc: 79.692,99.403,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.863 | Acc: 79.679,99.417,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.867 | Acc: 79.536,99.417,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 79.493,99.388,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 79.470,99.374,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.865 | Acc: 79.538,99.398,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.866 | Acc: 79.440,99.399,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.866 | Acc: 79.423,99.398,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.865 | Acc: 79.451,99.406,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.865 | Acc: 79.479,99.386,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 79.523,99.370,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 79.526,99.379,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.871 | Acc: 64.844,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.265 | Acc: 63.170,73.065,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.301 | Acc: 63.205,72.809,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.295 | Acc: 63.627,72.733,77.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 0.808 | Acc: 80.469,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.870 | Acc: 79.613,99.405,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.895 | Acc: 79.211,99.104,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.887 | Acc: 79.355,99.206,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.884 | Acc: 79.302,99.190,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.884 | Acc: 79.285,99.203,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.883 | Acc: 79.474,99.199,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.884 | Acc: 79.521,99.197,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.877 | Acc: 79.547,99.253,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.876 | Acc: 79.476,99.288,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.873 | Acc: 79.548,99.328,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.871 | Acc: 79.557,99.342,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 79.665,99.332,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.870 | Acc: 79.676,99.341,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.869 | Acc: 79.690,99.327,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.870 | Acc: 79.659,99.338,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.873 | Acc: 79.585,99.309,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.874 | Acc: 79.555,99.315,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.875 | Acc: 79.484,99.301,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.875 | Acc: 79.501,99.307,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.925 | Acc: 65.625,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.268 | Acc: 63.244,73.065,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.298 | Acc: 63.243,72.809,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.294 | Acc: 63.742,72.810,77.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 0.955 | Acc: 77.344,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.873 | Acc: 80.134,99.182,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.873 | Acc: 79.726,99.276,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.875 | Acc: 79.816,99.219,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 79.919,99.180,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 80.043,99.234,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.858 | Acc: 80.120,99.290,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.858 | Acc: 80.175,99.307,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.854 | Acc: 80.328,99.301,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.858 | Acc: 80.180,99.305,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.859 | Acc: 80.134,99.293,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.861 | Acc: 80.002,99.300,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.862 | Acc: 80.015,99.310,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.865 | Acc: 79.960,99.321,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.863 | Acc: 79.918,99.349,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.865 | Acc: 79.812,99.336,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 79.804,99.338,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.865 | Acc: 79.800,99.329,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 79.748,99.329,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.865 | Acc: 79.753,99.332,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.871 | Acc: 67.188,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.259 | Acc: 63.616,73.140,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.289 | Acc: 63.567,72.847,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.284 | Acc: 63.858,72.733,77.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 0.881 | Acc: 79.688,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.895 | Acc: 79.055,99.293,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.882 | Acc: 78.944,99.276,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.884 | Acc: 78.932,99.321,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.877 | Acc: 78.916,99.373,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.873 | Acc: 79.192,99.397,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.868 | Acc: 79.287,99.387,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.865 | Acc: 79.538,99.418,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.867 | Acc: 79.387,99.398,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.865 | Acc: 79.467,99.396,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.868 | Acc: 79.404,99.363,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 79.401,99.353,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 79.318,99.342,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.870 | Acc: 79.316,99.344,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 79.309,99.338,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 79.303,99.336,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.871 | Acc: 79.325,99.328,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.871 | Acc: 79.353,99.333,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.871 | Acc: 79.356,99.340,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.871 | Acc: 79.392,99.336,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.858 | Acc: 65.625,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.257 | Acc: 63.467,73.103,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.285 | Acc: 63.281,72.942,77.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.280 | Acc: 63.665,72.912,77.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 0.921 | Acc: 78.906,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.858 | Acc: 79.390,99.665,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.853 | Acc: 79.325,99.562,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.857 | Acc: 79.431,99.526,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 79.205,99.460,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.872 | Acc: 79.332,99.466,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.874 | Acc: 79.236,99.425,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.880 | Acc: 79.117,99.402,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.879 | Acc: 79.144,99.408,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.877 | Acc: 79.217,99.396,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.880 | Acc: 79.182,99.351,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.883 | Acc: 79.101,99.364,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.884 | Acc: 79.029,99.342,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.883 | Acc: 79.044,99.353,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.880 | Acc: 79.159,99.363,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.879 | Acc: 79.168,99.343,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.878 | Acc: 79.225,99.331,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.878 | Acc: 79.245,99.340,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.875 | Acc: 79.326,99.340,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.873 | Acc: 79.359,99.338,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.877 | Acc: 65.625,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.263 | Acc: 63.132,72.768,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.292 | Acc: 63.281,72.771,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.286 | Acc: 63.730,72.848,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 0.919 | Acc: 76.562,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.849 | Acc: 78.943,99.293,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.849 | Acc: 79.935,99.295,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.849 | Acc: 80.046,99.321,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.855 | Acc: 79.726,99.306,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.846 | Acc: 80.028,99.373,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.850 | Acc: 79.946,99.400,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.857 | Acc: 79.638,99.418,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.858 | Acc: 79.576,99.398,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.859 | Acc: 79.493,99.413,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 79.338,99.382,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.865 | Acc: 79.316,99.399,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.863 | Acc: 79.422,99.397,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.862 | Acc: 79.439,99.392,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.862 | Acc: 79.434,99.391,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.863 | Acc: 79.467,99.398,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.863 | Acc: 79.476,99.396,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.864 | Acc: 79.488,99.395,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 79.378,99.398,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 79.446,99.395,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.875 | Acc: 65.625,76.562,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.267 | Acc: 63.393,72.954,77.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.299 | Acc: 63.453,72.961,77.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.296 | Acc: 63.742,73.105,77.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 1.071 | Acc: 75.781,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.837 | Acc: 80.432,99.293,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.843 | Acc: 80.393,99.390,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.838 | Acc: 80.315,99.372,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.841 | Acc: 80.276,99.363,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.840 | Acc: 80.237,99.404,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.845 | Acc: 80.139,99.412,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.846 | Acc: 80.086,99.391,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 80.008,99.389,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.850 | Acc: 80.076,99.353,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.853 | Acc: 79.960,99.366,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.855 | Acc: 79.910,99.367,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.856 | Acc: 79.882,99.391,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.859 | Acc: 79.813,99.368,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.862 | Acc: 79.735,99.369,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.862 | Acc: 79.698,99.364,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.864 | Acc: 79.619,99.370,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.863 | Acc: 79.685,99.363,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.862 | Acc: 79.655,99.357,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.865 | Acc: 79.605,99.352,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.882 | Acc: 67.188,75.781,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.265 | Acc: 63.356,72.991,77.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.291 | Acc: 63.224,72.809,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.286 | Acc: 63.704,72.784,77.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 0.810 | Acc: 78.906,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 79.167,99.293,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.869 | Acc: 79.325,99.314,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.872 | Acc: 79.214,99.244,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.874 | Acc: 79.205,99.209,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.868 | Acc: 79.363,99.196,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.864 | Acc: 79.520,99.238,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 79.765,99.269,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.860 | Acc: 79.755,99.287,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.860 | Acc: 79.679,99.292,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.861 | Acc: 79.726,99.300,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.861 | Acc: 79.741,99.325,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.861 | Acc: 79.739,99.326,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.864 | Acc: 79.613,99.327,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.862 | Acc: 79.676,99.327,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.863 | Acc: 79.680,99.328,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.862 | Acc: 79.651,99.348,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.863 | Acc: 79.655,99.352,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.864 | Acc: 79.594,99.359,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.864 | Acc: 79.618,99.350,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.881 | Acc: 64.844,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.267 | Acc: 63.132,73.363,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.295 | Acc: 63.186,72.904,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.291 | Acc: 63.614,72.938,77.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 0.831 | Acc: 79.688,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.877 | Acc: 78.460,99.405,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.879 | Acc: 78.792,99.352,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.872 | Acc: 79.226,99.347,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 79.437,99.306,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.879 | Acc: 79.285,99.296,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.878 | Acc: 79.455,99.283,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.877 | Acc: 79.510,99.324,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.874 | Acc: 79.605,99.326,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.873 | Acc: 79.593,99.331,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.874 | Acc: 79.485,99.316,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.877 | Acc: 79.369,99.321,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.875 | Acc: 79.438,99.339,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.874 | Acc: 79.448,99.347,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.876 | Acc: 79.359,99.341,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 79.431,99.341,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.870 | Acc: 79.539,99.348,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 79.568,99.340,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.869 | Acc: 79.597,99.346,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 79.649,99.348,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.883 | Acc: 67.188,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.273 | Acc: 63.021,73.103,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.300 | Acc: 63.072,72.828,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.294 | Acc: 63.473,72.823,77.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 0.946 | Acc: 76.562,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.865 | Acc: 79.799,99.330,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.861 | Acc: 79.707,99.352,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.852 | Acc: 80.174,99.372,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.855 | Acc: 80.083,99.412,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.859 | Acc: 80.020,99.412,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 79.978,99.445,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.857 | Acc: 79.998,99.446,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.861 | Acc: 79.872,99.432,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.864 | Acc: 79.662,99.391,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.865 | Acc: 79.629,99.409,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.866 | Acc: 79.691,99.378,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.866 | Acc: 79.658,99.391,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.864 | Acc: 79.717,99.377,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.864 | Acc: 79.721,99.372,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.865 | Acc: 79.688,99.372,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 79.649,99.360,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 79.671,99.354,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 79.698,99.344,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 79.700,99.352,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.884 | Acc: 65.625,75.781,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.266 | Acc: 62.835,73.140,76.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.292 | Acc: 63.072,72.866,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.287 | Acc: 63.601,72.874,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 0.940 | Acc: 78.125,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.876 | Acc: 78.795,99.330,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.858 | Acc: 79.440,99.428,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.870 | Acc: 79.201,99.244,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 79.302,99.248,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.865 | Acc: 79.347,99.265,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.867 | Acc: 79.339,99.296,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.865 | Acc: 79.516,99.318,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.870 | Acc: 79.353,99.330,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.869 | Acc: 79.407,99.340,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.871 | Acc: 79.408,99.339,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.869 | Acc: 79.437,99.364,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 79.503,99.374,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.870 | Acc: 79.406,99.380,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.872 | Acc: 79.373,99.386,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.871 | Acc: 79.366,99.377,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.870 | Acc: 79.412,99.377,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 79.431,99.368,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.870 | Acc: 79.454,99.364,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 79.489,99.360,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.852 | Acc: 68.750,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.270 | Acc: 63.356,72.917,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.300 | Acc: 63.338,72.542,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.294 | Acc: 63.768,72.656,77.369,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 0.986 | Acc: 77.344,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.889 | Acc: 79.464,99.479,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.882 | Acc: 79.649,99.466,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.871 | Acc: 79.969,99.385,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.872 | Acc: 79.668,99.325,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.879 | Acc: 79.455,99.312,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.876 | Acc: 79.358,99.329,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.870 | Acc: 79.532,99.368,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.865 | Acc: 79.610,99.393,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.865 | Acc: 79.735,99.409,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.863 | Acc: 79.703,99.433,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.865 | Acc: 79.500,99.441,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.866 | Acc: 79.454,99.420,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.865 | Acc: 79.466,99.425,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.864 | Acc: 79.512,99.424,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.864 | Acc: 79.524,99.408,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.865 | Acc: 79.520,99.396,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.865 | Acc: 79.454,99.386,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.864 | Acc: 79.469,99.392,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.864 | Acc: 79.474,99.403,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.882 | Acc: 67.188,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.266 | Acc: 63.244,72.731,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.295 | Acc: 63.281,72.656,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.293 | Acc: 63.665,72.643,77.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 0.737 | Acc: 85.156,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 79.613,99.144,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.875 | Acc: 79.345,99.390,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 79.726,99.372,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.863 | Acc: 79.909,99.383,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.868 | Acc: 79.827,99.389,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.873 | Acc: 79.771,99.322,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.870 | Acc: 79.615,99.313,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.873 | Acc: 79.566,99.321,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.875 | Acc: 79.450,99.322,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.872 | Acc: 79.520,99.308,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.874 | Acc: 79.415,99.325,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 79.457,99.329,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 79.451,99.335,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 79.426,99.330,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.869 | Acc: 79.423,99.349,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 79.415,99.362,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 79.378,99.347,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 79.467,99.351,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 79.511,99.362,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.903 | Acc: 66.406,75.000,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.273 | Acc: 63.244,73.065,76.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.297 | Acc: 63.300,72.904,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.291 | Acc: 63.781,72.938,77.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 0.584 | Acc: 92.188,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 79.874,99.516,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.864 | Acc: 80.030,99.466,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.870 | Acc: 79.534,99.424,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 79.244,99.402,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.863 | Acc: 79.517,99.373,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.865 | Acc: 79.474,99.412,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 79.776,99.440,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.861 | Acc: 79.799,99.408,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.860 | Acc: 79.735,99.409,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 79.594,99.378,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 79.656,99.396,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.867 | Acc: 79.626,99.410,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.867 | Acc: 79.622,99.398,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 79.487,99.386,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.871 | Acc: 79.472,99.387,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 79.605,99.389,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 79.557,99.372,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.869 | Acc: 79.579,99.383,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 79.523,99.393,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.890 | Acc: 67.188,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.266 | Acc: 63.653,72.619,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.294 | Acc: 63.548,72.656,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.291 | Acc: 63.896,72.707,77.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 0.758 | Acc: 85.156,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.858 | Acc: 80.246,99.368,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.871 | Acc: 79.726,99.428,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 80.110,99.449,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 80.054,99.470,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.855 | Acc: 80.213,99.420,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.857 | Acc: 80.133,99.412,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.863 | Acc: 79.893,99.402,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.865 | Acc: 79.789,99.427,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.861 | Acc: 79.873,99.430,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.859 | Acc: 79.983,99.409,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.860 | Acc: 79.953,99.403,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.859 | Acc: 79.982,99.404,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.860 | Acc: 79.939,99.383,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.860 | Acc: 79.852,99.394,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.861 | Acc: 79.822,99.393,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.861 | Acc: 79.841,99.389,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.860 | Acc: 79.873,99.391,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.863 | Acc: 79.798,99.388,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.862 | Acc: 79.856,99.385,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.914 | Acc: 66.406,75.781,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.276 | Acc: 63.504,73.177,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.305 | Acc: 63.453,72.961,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 63.691,72.784,77.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 1.000 | Acc: 75.781,99.219,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.853 | Acc: 79.874,99.293,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.846 | Acc: 80.126,99.524,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.855 | Acc: 80.033,99.501,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 79.900,99.498,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 79.881,99.497,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.858 | Acc: 79.817,99.496,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.858 | Acc: 79.726,99.457,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.857 | Acc: 79.804,99.437,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.858 | Acc: 79.683,99.435,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.859 | Acc: 79.602,99.425,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.860 | Acc: 79.617,99.403,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.860 | Acc: 79.652,99.404,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.862 | Acc: 79.646,99.428,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.863 | Acc: 79.607,99.419,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.864 | Acc: 79.604,99.393,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.864 | Acc: 79.612,99.379,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.865 | Acc: 79.598,99.384,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 79.562,99.385,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.866 | Acc: 79.569,99.389,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.873 | Acc: 66.406,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.269 | Acc: 63.170,73.177,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.298 | Acc: 63.167,72.923,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.289 | Acc: 63.640,72.861,77.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 0.944 | Acc: 78.125,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.845 | Acc: 80.469,99.256,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.867 | Acc: 79.211,99.352,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.854 | Acc: 79.726,99.347,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.853 | Acc: 79.986,99.354,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.848 | Acc: 80.206,99.381,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.847 | Acc: 80.275,99.393,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.844 | Acc: 80.397,99.402,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.853 | Acc: 80.153,99.398,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.855 | Acc: 80.003,99.374,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.853 | Acc: 79.971,99.370,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.856 | Acc: 79.832,99.388,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.854 | Acc: 79.879,99.410,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.855 | Acc: 79.843,99.410,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.856 | Acc: 79.874,99.411,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 79.825,99.411,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.859 | Acc: 79.775,99.413,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.859 | Acc: 79.770,99.420,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.861 | Acc: 79.750,99.409,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.862 | Acc: 79.704,99.403,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.891 | Acc: 66.406,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.266 | Acc: 62.835,73.512,77.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.300 | Acc: 63.014,73.114,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.293 | Acc: 63.358,73.028,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 0.945 | Acc: 78.125,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.860 | Acc: 79.018,99.479,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.867 | Acc: 78.944,99.447,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 79.329,99.475,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 79.524,99.431,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 79.618,99.451,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.867 | Acc: 79.513,99.387,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.867 | Acc: 79.610,99.391,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.868 | Acc: 79.595,99.393,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.864 | Acc: 79.705,99.430,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.860 | Acc: 79.886,99.436,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.859 | Acc: 79.914,99.441,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.862 | Acc: 79.820,99.423,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.862 | Acc: 79.786,99.434,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.863 | Acc: 79.721,99.424,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.862 | Acc: 79.685,99.439,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.865 | Acc: 79.622,99.433,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.864 | Acc: 79.676,99.432,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 79.610,99.420,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.865 | Acc: 79.634,99.409,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.873 | Acc: 64.844,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.262 | Acc: 62.909,73.028,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.294 | Acc: 62.976,72.790,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.288 | Acc: 63.512,72.823,77.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 0.879 | Acc: 77.344,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 79.613,99.293,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.870 | Acc: 79.478,99.352,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.863 | Acc: 79.764,99.424,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.854 | Acc: 79.900,99.450,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 79.796,99.428,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.861 | Acc: 79.804,99.380,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 79.826,99.402,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.857 | Acc: 79.964,99.423,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.861 | Acc: 79.817,99.387,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 79.820,99.386,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.865 | Acc: 79.776,99.392,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.867 | Acc: 79.688,99.387,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.866 | Acc: 79.720,99.380,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.864 | Acc: 79.749,99.358,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.863 | Acc: 79.784,99.364,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 79.690,99.365,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.864 | Acc: 79.742,99.375,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.865 | Acc: 79.700,99.375,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.863 | Acc: 79.747,99.356,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.892 | Acc: 67.188,75.000,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.266 | Acc: 63.132,73.251,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 63.224,73.037,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.297 | Acc: 63.665,72.887,77.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 0.841 | Acc: 79.688,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.847 | Acc: 80.841,99.516,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.821 | Acc: 81.117,99.543,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.839 | Acc: 80.482,99.411,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.849 | Acc: 80.295,99.421,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.839 | Acc: 80.515,99.443,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.843 | Acc: 80.533,99.374,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.848 | Acc: 80.369,99.402,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.849 | Acc: 80.284,99.413,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.852 | Acc: 80.210,99.348,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 80.018,99.366,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.856 | Acc: 79.977,99.388,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.858 | Acc: 79.924,99.384,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.859 | Acc: 79.780,99.383,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.857 | Acc: 79.824,99.388,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.861 | Acc: 79.781,99.385,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.860 | Acc: 79.860,99.377,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.861 | Acc: 79.832,99.370,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.861 | Acc: 79.768,99.381,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.862 | Acc: 79.751,99.370,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.902 | Acc: 64.844,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.270 | Acc: 62.500,73.028,76.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.300 | Acc: 62.862,72.809,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.295 | Acc: 63.358,72.720,77.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 0.941 | Acc: 76.562,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 79.725,99.516,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.863 | Acc: 79.535,99.543,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.853 | Acc: 79.905,99.539,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.863 | Acc: 79.524,99.421,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.858 | Acc: 79.571,99.381,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 79.571,99.393,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.861 | Acc: 79.654,99.379,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.866 | Acc: 79.571,99.389,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.866 | Acc: 79.597,99.391,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.869 | Acc: 79.466,99.382,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 79.412,99.385,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.870 | Acc: 79.441,99.397,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 79.343,99.386,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 79.368,99.374,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 79.519,99.385,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 79.500,99.404,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.865 | Acc: 79.580,99.411,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.863 | Acc: 79.640,99.398,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.864 | Acc: 79.608,99.395,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.881 | Acc: 65.625,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.273 | Acc: 63.430,72.805,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 63.434,72.618,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.297 | Acc: 63.730,72.528,77.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 0.934 | Acc: 80.469,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.895 | Acc: 79.576,99.665,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.859 | Acc: 79.859,99.562,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.863 | Acc: 79.918,99.411,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 79.880,99.392,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 79.989,99.435,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.852 | Acc: 80.081,99.406,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.853 | Acc: 79.953,99.368,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.854 | Acc: 80.032,99.359,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.851 | Acc: 80.076,99.370,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.855 | Acc: 80.061,99.347,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 80.073,99.342,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 80.008,99.332,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.858 | Acc: 79.990,99.338,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.856 | Acc: 80.077,99.349,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.858 | Acc: 79.978,99.330,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.858 | Acc: 79.987,99.336,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.858 | Acc: 79.956,99.352,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.858 | Acc: 79.971,99.353,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.860 | Acc: 79.932,99.356,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.883 | Acc: 65.625,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.258 | Acc: 63.244,72.842,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.295 | Acc: 63.396,72.713,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.291 | Acc: 63.640,72.733,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 0.932 | Acc: 75.781,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.873 | Acc: 78.757,99.405,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.866 | Acc: 79.287,99.333,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.851 | Acc: 79.752,99.372,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.851 | Acc: 79.774,99.354,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.845 | Acc: 80.012,99.358,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.851 | Acc: 79.855,99.367,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.852 | Acc: 79.876,99.352,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 79.969,99.345,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.849 | Acc: 79.981,99.340,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.853 | Acc: 79.878,99.347,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 79.719,99.321,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 79.749,99.335,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 79.690,99.347,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 79.693,99.352,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.859 | Acc: 79.672,99.362,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.857 | Acc: 79.780,99.382,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.857 | Acc: 79.775,99.384,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.860 | Acc: 79.718,99.383,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.860 | Acc: 79.702,99.389,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.898 | Acc: 64.844,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.259 | Acc: 62.872,73.177,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.296 | Acc: 63.072,72.866,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.289 | Acc: 63.512,72.707,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 0.816 | Acc: 79.688,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.829 | Acc: 80.394,99.516,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.834 | Acc: 80.335,99.333,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.847 | Acc: 80.123,99.308,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.848 | Acc: 80.179,99.334,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.852 | Acc: 80.105,99.296,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.850 | Acc: 80.114,99.283,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.855 | Acc: 79.832,99.302,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 79.877,99.340,99.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.856 | Acc: 79.856,99.387,99.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.857 | Acc: 79.719,99.390,99.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.855 | Acc: 79.744,99.367,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.854 | Acc: 79.681,99.378,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.852 | Acc: 79.792,99.371,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.855 | Acc: 79.724,99.358,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 79.659,99.369,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.856 | Acc: 79.717,99.370,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.859 | Acc: 79.646,99.352,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.860 | Acc: 79.616,99.359,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.859 | Acc: 79.675,99.370,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.905 | Acc: 64.844,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.274 | Acc: 63.058,72.805,77.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.309 | Acc: 63.148,72.752,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.304 | Acc: 63.614,72.643,77.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 0.906 | Acc: 80.469,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.844 | Acc: 80.320,99.516,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.864 | Acc: 80.050,99.543,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.856 | Acc: 80.033,99.603,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 79.890,99.566,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 79.958,99.551,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.856 | Acc: 80.185,99.561,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.855 | Acc: 80.081,99.518,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.856 | Acc: 80.076,99.515,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.853 | Acc: 80.089,99.504,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.852 | Acc: 80.107,99.464,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.852 | Acc: 80.098,99.449,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.855 | Acc: 79.992,99.436,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.856 | Acc: 79.933,99.446,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.857 | Acc: 79.890,99.450,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.857 | Acc: 79.848,99.426,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.857 | Acc: 79.848,99.428,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.858 | Acc: 79.791,99.416,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.862 | Acc: 79.685,99.403,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.860 | Acc: 79.782,99.403,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.902 | Acc: 66.406,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.270 | Acc: 63.281,73.028,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 63.224,72.771,77.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.295 | Acc: 63.563,72.759,77.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 0.848 | Acc: 83.594,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.875 | Acc: 79.799,99.554,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.873 | Acc: 79.345,99.505,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.884 | Acc: 78.945,99.449,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.881 | Acc: 79.003,99.450,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 79.440,99.497,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.868 | Acc: 79.390,99.445,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 79.521,99.424,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.863 | Acc: 79.639,99.408,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 79.662,99.417,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 79.660,99.390,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.864 | Acc: 79.688,99.392,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.861 | Acc: 79.762,99.404,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.862 | Acc: 79.765,99.362,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.862 | Acc: 79.818,99.347,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.862 | Acc: 79.758,99.351,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.861 | Acc: 79.746,99.355,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.862 | Acc: 79.706,99.359,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.861 | Acc: 79.666,99.353,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.862 | Acc: 79.651,99.370,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.904 | Acc: 64.844,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.265 | Acc: 63.281,73.140,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.297 | Acc: 63.243,73.075,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.292 | Acc: 63.627,72.964,77.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 0.820 | Acc: 80.469,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.832 | Acc: 81.882,99.293,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.854 | Acc: 80.412,99.333,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.845 | Acc: 80.494,99.372,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.847 | Acc: 80.411,99.412,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.853 | Acc: 80.005,99.420,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 79.985,99.432,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.848 | Acc: 79.848,99.468,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 79.843,99.476,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.850 | Acc: 79.899,99.469,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.854 | Acc: 79.722,99.468,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.849 | Acc: 79.910,99.456,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.850 | Acc: 79.895,99.449,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.852 | Acc: 79.888,99.437,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.854 | Acc: 79.813,99.436,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.854 | Acc: 79.822,99.421,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.854 | Acc: 79.841,99.409,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 79.749,99.411,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.857 | Acc: 79.670,99.411,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.858 | Acc: 79.589,99.405,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.915 | Acc: 64.062,74.219,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.265 | Acc: 62.872,72.954,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.303 | Acc: 62.976,72.809,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 63.512,72.797,77.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 0.863 | Acc: 81.250,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.845 | Acc: 80.283,99.182,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.850 | Acc: 80.088,99.200,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.862 | Acc: 79.444,99.232,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.864 | Acc: 79.552,99.219,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 79.564,99.312,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.859 | Acc: 79.610,99.309,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 79.466,99.335,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.860 | Acc: 79.455,99.379,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.856 | Acc: 79.580,99.396,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.858 | Acc: 79.548,99.417,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.858 | Acc: 79.613,99.403,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.859 | Acc: 79.629,99.381,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.861 | Acc: 79.604,99.362,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.861 | Acc: 79.626,99.372,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.861 | Acc: 79.685,99.374,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.861 | Acc: 79.658,99.370,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.860 | Acc: 79.690,99.377,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.860 | Acc: 79.748,99.370,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.859 | Acc: 79.753,99.373,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.875 | Acc: 64.844,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.270 | Acc: 62.835,72.805,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.306 | Acc: 62.957,72.580,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.301 | Acc: 63.486,72.656,77.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 0.725 | Acc: 84.375,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.862 | Acc: 79.799,99.368,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.854 | Acc: 79.992,99.466,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.872 | Acc: 79.611,99.372,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.867 | Acc: 79.697,99.354,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.866 | Acc: 79.571,99.350,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.862 | Acc: 79.681,99.374,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.865 | Acc: 79.566,99.368,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.862 | Acc: 79.688,99.379,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.863 | Acc: 79.649,99.348,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.863 | Acc: 79.761,99.347,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.862 | Acc: 79.744,99.374,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.864 | Acc: 79.710,99.378,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.861 | Acc: 79.729,99.380,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.861 | Acc: 79.760,99.374,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.862 | Acc: 79.703,99.385,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.862 | Acc: 79.717,99.382,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.861 | Acc: 79.811,99.379,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.862 | Acc: 79.726,99.359,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.863 | Acc: 79.718,99.373,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.901 | Acc: 65.625,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.276 | Acc: 63.244,73.251,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.304 | Acc: 63.281,72.980,77.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.298 | Acc: 63.691,72.887,77.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 0.842 | Acc: 81.250,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.878 | Acc: 80.357,99.330,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.858 | Acc: 80.526,99.333,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 80.149,99.308,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.874 | Acc: 79.977,99.286,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.866 | Acc: 79.935,99.281,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.867 | Acc: 79.713,99.361,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.865 | Acc: 79.854,99.379,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.860 | Acc: 79.998,99.389,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.861 | Acc: 79.873,99.366,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.862 | Acc: 79.789,99.347,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.860 | Acc: 79.783,99.364,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.861 | Acc: 79.752,99.371,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.860 | Acc: 79.688,99.374,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.859 | Acc: 79.724,99.380,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.857 | Acc: 79.786,99.390,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.858 | Acc: 79.743,99.377,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.859 | Acc: 79.733,99.375,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.859 | Acc: 79.744,99.353,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.860 | Acc: 79.743,99.364,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.907 | Acc: 64.844,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.278 | Acc: 63.058,72.991,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.309 | Acc: 63.072,72.771,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.304 | Acc: 63.384,72.631,77.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 0.707 | Acc: 85.938,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.828 | Acc: 80.655,99.442,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.863 | Acc: 79.516,99.466,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.870 | Acc: 79.239,99.360,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 79.234,99.402,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 79.185,99.350,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.866 | Acc: 79.474,99.361,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.867 | Acc: 79.183,99.357,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.863 | Acc: 79.290,99.369,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.857 | Acc: 79.502,99.383,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.855 | Acc: 79.443,99.409,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.856 | Acc: 79.521,99.396,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 79.509,99.400,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.858 | Acc: 79.499,99.407,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 79.501,99.405,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.859 | Acc: 79.578,99.398,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.858 | Acc: 79.646,99.401,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.857 | Acc: 79.665,99.400,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 79.765,99.401,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 79.802,99.399,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.923 | Acc: 65.625,75.000,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.273 | Acc: 62.723,73.214,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.309 | Acc: 62.805,72.866,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.305 | Acc: 63.332,72.772,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 0.833 | Acc: 78.906,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.856 | Acc: 79.539,99.554,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.871 | Acc: 79.478,99.390,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.859 | Acc: 79.944,99.411,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.853 | Acc: 80.257,99.441,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.856 | Acc: 79.896,99.466,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.854 | Acc: 79.849,99.464,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.856 | Acc: 79.771,99.446,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.852 | Acc: 80.027,99.447,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.851 | Acc: 80.089,99.478,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.849 | Acc: 80.088,99.471,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.849 | Acc: 80.073,99.452,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.852 | Acc: 80.028,99.455,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 80.056,99.455,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 79.974,99.450,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.853 | Acc: 79.947,99.450,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.854 | Acc: 79.911,99.455,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 79.990,99.450,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 79.973,99.457,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 80.014,99.434,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.899 | Acc: 66.406,77.344,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.271 | Acc: 63.170,72.805,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.303 | Acc: 63.110,72.675,77.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.298 | Acc: 63.525,72.631,77.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 0.920 | Acc: 75.000,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.842 | Acc: 79.204,99.665,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.865 | Acc: 79.002,99.581,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.852 | Acc: 79.355,99.475,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 79.379,99.470,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 79.278,99.381,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.861 | Acc: 79.468,99.425,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.855 | Acc: 79.726,99.463,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.854 | Acc: 79.789,99.466,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.856 | Acc: 79.774,99.478,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.858 | Acc: 79.711,99.471,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.859 | Acc: 79.680,99.449,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.859 | Acc: 79.688,99.436,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.860 | Acc: 79.610,99.434,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.861 | Acc: 79.624,99.416,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.860 | Acc: 79.630,99.416,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.858 | Acc: 79.656,99.423,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.858 | Acc: 79.653,99.434,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.859 | Acc: 79.601,99.433,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.858 | Acc: 79.632,99.434,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.886 | Acc: 64.844,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.273 | Acc: 62.984,73.103,77.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 63.186,72.866,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.295 | Acc: 63.640,72.823,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 0.805 | Acc: 83.594,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.824 | Acc: 81.324,99.293,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.840 | Acc: 80.869,99.352,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.841 | Acc: 80.789,99.411,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.845 | Acc: 80.729,99.431,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.846 | Acc: 80.453,99.435,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.848 | Acc: 80.288,99.406,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.844 | Acc: 80.314,99.429,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.845 | Acc: 80.309,99.418,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.844 | Acc: 80.218,99.422,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.846 | Acc: 80.154,99.417,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.848 | Acc: 80.133,99.410,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.851 | Acc: 80.083,99.410,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 80.077,99.383,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 80.038,99.397,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.854 | Acc: 79.983,99.372,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.854 | Acc: 79.982,99.392,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.854 | Acc: 79.976,99.402,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.856 | Acc: 79.887,99.409,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.857 | Acc: 79.870,99.414,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.895 | Acc: 65.625,75.781,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.278 | Acc: 62.909,73.103,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.311 | Acc: 62.938,72.790,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.304 | Acc: 63.473,72.720,77.677,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 0.827 | Acc: 80.469,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.864 | Acc: 78.981,99.479,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.850 | Acc: 79.821,99.371,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.855 | Acc: 79.828,99.372,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.858 | Acc: 79.707,99.334,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 79.633,99.350,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.858 | Acc: 79.739,99.367,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.857 | Acc: 79.760,99.391,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.859 | Acc: 79.688,99.432,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.856 | Acc: 79.722,99.435,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.854 | Acc: 79.738,99.444,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.853 | Acc: 79.765,99.466,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.852 | Acc: 79.863,99.468,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.853 | Acc: 79.828,99.443,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 79.824,99.444,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.855 | Acc: 79.804,99.434,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.854 | Acc: 79.829,99.421,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 79.850,99.416,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 79.902,99.420,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 79.923,99.424,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.903 | Acc: 65.625,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.272 | Acc: 63.095,73.028,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.299 | Acc: 63.186,72.847,77.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.292 | Acc: 63.665,72.784,77.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 0.834 | Acc: 82.812,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 79.613,99.368,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.840 | Acc: 80.697,99.409,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.832 | Acc: 80.904,99.411,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.846 | Acc: 80.459,99.441,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.847 | Acc: 80.360,99.459,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.854 | Acc: 80.139,99.445,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.858 | Acc: 80.014,99.435,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.854 | Acc: 80.105,99.447,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.855 | Acc: 80.072,99.430,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.852 | Acc: 80.068,99.452,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.852 | Acc: 80.066,99.434,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.853 | Acc: 80.070,99.391,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.853 | Acc: 80.044,99.404,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 80.032,99.405,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.855 | Acc: 79.960,99.406,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.853 | Acc: 79.945,99.418,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 79.878,99.420,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 79.897,99.429,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 79.915,99.432,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.895 | Acc: 64.844,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.269 | Acc: 63.132,73.065,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.305 | Acc: 63.167,72.809,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.300 | Acc: 63.537,72.784,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 0.908 | Acc: 78.125,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.894 | Acc: 78.348,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.865 | Acc: 79.535,99.295,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.862 | Acc: 79.547,99.321,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.859 | Acc: 79.697,99.383,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.859 | Acc: 79.742,99.373,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 79.688,99.374,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 79.610,99.368,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.861 | Acc: 79.712,99.345,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 79.705,99.361,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.862 | Acc: 79.726,99.347,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.859 | Acc: 79.910,99.346,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.858 | Acc: 80.002,99.339,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.858 | Acc: 80.029,99.344,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 80.041,99.361,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.857 | Acc: 80.051,99.356,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.857 | Acc: 80.045,99.357,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 80.127,99.377,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.852 | Acc: 80.144,99.385,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 80.137,99.379,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.914 | Acc: 65.625,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.270 | Acc: 62.909,72.954,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.301 | Acc: 63.072,72.809,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.296 | Acc: 63.525,72.836,77.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 0.854 | Acc: 78.125,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.852 | Acc: 79.241,99.405,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.845 | Acc: 80.069,99.447,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.842 | Acc: 79.995,99.424,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.850 | Acc: 79.977,99.441,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.852 | Acc: 79.734,99.466,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.855 | Acc: 79.552,99.432,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.850 | Acc: 79.837,99.451,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 79.848,99.466,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 79.873,99.460,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.847 | Acc: 79.998,99.456,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.848 | Acc: 79.928,99.473,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.848 | Acc: 79.970,99.465,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 79.912,99.443,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 79.882,99.441,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.851 | Acc: 79.861,99.437,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 79.890,99.435,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 79.862,99.443,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 79.962,99.439,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 79.948,99.442,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.914 | Acc: 64.844,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.273 | Acc: 63.207,73.103,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.304 | Acc: 63.186,72.923,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 63.601,72.912,77.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 0.824 | Acc: 80.469,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.838 | Acc: 81.287,99.219,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.856 | Acc: 80.450,99.352,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.855 | Acc: 80.635,99.296,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.850 | Acc: 80.546,99.325,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.852 | Acc: 80.476,99.296,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.854 | Acc: 80.294,99.322,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.852 | Acc: 80.197,99.335,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.854 | Acc: 80.182,99.379,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.854 | Acc: 80.201,99.387,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.854 | Acc: 80.201,99.390,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.855 | Acc: 80.228,99.374,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.854 | Acc: 80.242,99.371,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.852 | Acc: 80.265,99.362,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 80.232,99.336,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.850 | Acc: 80.357,99.354,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 80.328,99.355,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.851 | Acc: 80.283,99.347,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 80.196,99.355,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 80.106,99.344,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.897 | Acc: 64.844,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.269 | Acc: 63.095,72.842,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 63.148,72.732,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.296 | Acc: 63.499,72.656,77.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 0.910 | Acc: 82.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.833 | Acc: 80.134,99.702,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.833 | Acc: 80.202,99.695,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.842 | Acc: 80.225,99.680,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.834 | Acc: 80.421,99.605,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.844 | Acc: 80.213,99.528,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.847 | Acc: 80.314,99.496,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.845 | Acc: 80.391,99.512,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.843 | Acc: 80.483,99.490,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.847 | Acc: 80.374,99.465,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.847 | Acc: 80.348,99.456,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.846 | Acc: 80.352,99.459,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.849 | Acc: 80.277,99.446,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.847 | Acc: 80.298,99.449,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 80.305,99.458,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.848 | Acc: 80.297,99.447,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.849 | Acc: 80.259,99.457,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.849 | Acc: 80.217,99.452,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.850 | Acc: 80.166,99.439,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 80.069,99.432,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.915 | Acc: 65.625,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.275 | Acc: 62.984,72.954,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.301 | Acc: 63.148,72.771,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.297 | Acc: 63.563,72.759,77.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 0.833 | Acc: 82.031,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.845 | Acc: 80.432,99.591,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.835 | Acc: 80.526,99.619,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.828 | Acc: 80.763,99.590,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.833 | Acc: 80.623,99.556,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.844 | Acc: 80.337,99.451,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.847 | Acc: 80.275,99.412,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.848 | Acc: 80.253,99.424,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.847 | Acc: 80.202,99.432,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 80.244,99.426,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.850 | Acc: 80.134,99.433,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.851 | Acc: 80.045,99.413,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.854 | Acc: 79.953,99.391,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.856 | Acc: 79.891,99.386,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.857 | Acc: 79.813,99.391,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.855 | Acc: 79.947,99.395,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.856 | Acc: 79.950,99.413,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.857 | Acc: 79.928,99.411,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 80.021,99.433,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 80.034,99.440,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.906 | Acc: 65.625,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.274 | Acc: 63.095,72.917,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.307 | Acc: 63.091,72.637,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.302 | Acc: 63.537,72.631,77.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 0.922 | Acc: 77.344,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.874 | Acc: 79.501,99.107,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.858 | Acc: 79.497,99.295,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.861 | Acc: 79.752,99.347,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 79.446,99.402,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.864 | Acc: 79.533,99.397,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.862 | Acc: 79.591,99.374,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.861 | Acc: 79.604,99.396,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.863 | Acc: 79.600,99.369,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.861 | Acc: 79.605,99.387,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.860 | Acc: 79.695,99.409,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.863 | Acc: 79.698,99.378,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.862 | Acc: 79.691,99.371,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.860 | Acc: 79.798,99.386,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 79.874,99.383,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.859 | Acc: 79.825,99.377,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.858 | Acc: 79.872,99.382,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.856 | Acc: 79.882,99.386,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 79.919,99.385,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.855 | Acc: 79.882,99.387,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.888 | Acc: 65.625,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.267 | Acc: 62.909,72.991,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.301 | Acc: 63.205,72.847,77.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.295 | Acc: 63.627,72.810,77.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 0.830 | Acc: 83.594,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.871 | Acc: 78.720,99.330,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.872 | Acc: 79.287,99.428,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.863 | Acc: 79.816,99.398,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.859 | Acc: 79.996,99.412,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.856 | Acc: 79.943,99.420,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.856 | Acc: 79.978,99.400,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.855 | Acc: 80.025,99.391,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.849 | Acc: 80.066,99.398,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 80.089,99.404,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.847 | Acc: 80.049,99.405,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.850 | Acc: 80.020,99.385,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.852 | Acc: 79.992,99.384,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.852 | Acc: 80.062,99.380,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.851 | Acc: 80.080,99.377,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 80.030,99.377,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.852 | Acc: 80.016,99.375,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 80.004,99.372,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 79.941,99.377,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 79.987,99.375,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.895 | Acc: 65.625,75.000,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.268 | Acc: 62.872,73.289,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.299 | Acc: 63.129,72.961,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.292 | Acc: 63.653,72.912,77.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 0.842 | Acc: 81.250,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.867 | Acc: 79.948,99.442,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.850 | Acc: 80.069,99.543,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.851 | Acc: 79.867,99.552,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.844 | Acc: 80.093,99.518,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.843 | Acc: 79.981,99.544,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.847 | Acc: 79.991,99.522,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.848 | Acc: 79.920,99.535,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.847 | Acc: 79.969,99.563,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.849 | Acc: 79.934,99.551,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.845 | Acc: 80.115,99.553,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.846 | Acc: 80.179,99.548,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.848 | Acc: 80.112,99.540,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.849 | Acc: 80.011,99.509,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.851 | Acc: 79.968,99.500,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.853 | Acc: 79.921,99.496,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.853 | Acc: 79.880,99.499,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 79.903,99.491,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.856 | Acc: 79.850,99.472,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.856 | Acc: 79.841,99.473,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.894 | Acc: 67.188,75.000,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.268 | Acc: 63.318,72.917,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.299 | Acc: 63.262,72.885,77.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.293 | Acc: 63.704,72.836,77.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 0.865 | Acc: 79.688,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.861 | Acc: 79.464,99.628,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.853 | Acc: 80.069,99.371,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.855 | Acc: 80.097,99.270,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.859 | Acc: 79.745,99.325,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.856 | Acc: 79.834,99.366,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.851 | Acc: 79.888,99.412,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.848 | Acc: 80.131,99.424,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.853 | Acc: 79.993,99.393,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.851 | Acc: 80.028,99.387,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.852 | Acc: 80.045,99.382,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.850 | Acc: 80.030,99.385,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.850 | Acc: 80.025,99.381,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.847 | Acc: 80.128,99.380,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.846 | Acc: 80.174,99.394,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.849 | Acc: 80.134,99.387,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.850 | Acc: 80.109,99.392,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 80.008,99.388,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 79.954,99.385,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 79.948,99.405,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.890 | Acc: 65.625,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.262 | Acc: 62.984,73.065,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.297 | Acc: 63.110,72.847,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.293 | Acc: 63.589,72.759,77.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 0.771 | Acc: 81.250,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.827 | Acc: 81.064,99.219,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.837 | Acc: 80.145,99.447,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.860 | Acc: 79.841,99.449,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.856 | Acc: 79.688,99.489,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.852 | Acc: 79.788,99.497,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.857 | Acc: 79.700,99.522,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.862 | Acc: 79.566,99.479,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.857 | Acc: 79.620,99.486,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.854 | Acc: 79.804,99.499,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.855 | Acc: 79.827,99.499,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.855 | Acc: 79.847,99.487,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.855 | Acc: 79.853,99.472,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.854 | Acc: 79.885,99.446,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.855 | Acc: 79.943,99.433,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 79.843,99.447,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.857 | Acc: 79.778,99.450,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 79.823,99.439,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.856 | Acc: 79.768,99.439,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 79.804,99.444,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.874 | Acc: 64.844,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.267 | Acc: 62.798,72.842,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.296 | Acc: 63.091,72.752,77.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.288 | Acc: 63.537,72.720,77.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 0.888 | Acc: 78.125,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 79.985,99.330,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 79.707,99.428,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.862 | Acc: 79.278,99.436,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.855 | Acc: 79.552,99.508,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.855 | Acc: 79.595,99.482,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.853 | Acc: 79.778,99.477,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.853 | Acc: 79.837,99.457,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 79.765,99.461,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.857 | Acc: 79.683,99.439,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.854 | Acc: 79.757,99.421,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.852 | Acc: 79.695,99.445,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.849 | Acc: 79.879,99.465,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 79.852,99.461,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 79.788,99.438,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.854 | Acc: 79.789,99.439,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.854 | Acc: 79.819,99.423,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 79.811,99.413,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 79.830,99.420,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 79.854,99.420,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.891 | Acc: 65.625,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.274 | Acc: 63.021,72.879,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.304 | Acc: 63.167,72.809,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.298 | Acc: 63.627,72.759,77.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 1.061 | Acc: 73.438,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.846 | Acc: 80.283,99.516,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.850 | Acc: 79.878,99.524,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.859 | Acc: 79.944,99.475,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.858 | Acc: 80.064,99.489,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.858 | Acc: 80.067,99.459,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.855 | Acc: 80.172,99.471,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.851 | Acc: 80.219,99.457,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.858 | Acc: 79.993,99.408,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.858 | Acc: 80.024,99.400,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.857 | Acc: 80.080,99.405,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.859 | Acc: 79.910,99.396,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.860 | Acc: 79.814,99.397,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.859 | Acc: 79.858,99.404,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 79.888,99.405,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.859 | Acc: 79.864,99.393,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.857 | Acc: 79.863,99.409,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.856 | Acc: 79.875,99.400,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.856 | Acc: 79.837,99.396,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 79.841,99.391,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.909 | Acc: 65.625,74.219,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.271 | Acc: 63.132,73.103,77.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.305 | Acc: 63.148,72.942,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.302 | Acc: 63.601,72.784,77.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 0.904 | Acc: 75.781,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.809 | Acc: 81.920,99.368,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.824 | Acc: 81.079,99.352,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.830 | Acc: 80.904,99.308,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.833 | Acc: 80.758,99.277,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.847 | Acc: 80.446,99.196,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.846 | Acc: 80.449,99.212,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.852 | Acc: 80.253,99.230,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 80.115,99.262,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.857 | Acc: 80.063,99.283,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.857 | Acc: 80.088,99.281,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.855 | Acc: 80.144,99.307,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.853 | Acc: 80.274,99.310,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 80.352,99.318,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.850 | Acc: 80.330,99.338,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 80.271,99.338,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.853 | Acc: 80.221,99.350,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 80.217,99.352,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 80.179,99.359,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 80.167,99.360,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.868 | Acc: 65.625,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.263 | Acc: 62.835,73.177,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.292 | Acc: 63.034,72.999,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.286 | Acc: 63.473,72.938,77.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 0.811 | Acc: 78.906,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.846 | Acc: 79.464,99.330,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.844 | Acc: 80.145,99.447,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.853 | Acc: 80.085,99.360,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.852 | Acc: 80.160,99.431,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.850 | Acc: 80.198,99.443,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.854 | Acc: 79.965,99.425,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.858 | Acc: 79.953,99.413,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.856 | Acc: 79.935,99.432,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.855 | Acc: 79.946,99.426,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.855 | Acc: 79.963,99.413,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.856 | Acc: 79.885,99.413,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.854 | Acc: 79.866,99.426,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.854 | Acc: 79.909,99.407,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.854 | Acc: 79.907,99.405,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 79.926,99.413,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.852 | Acc: 79.972,99.421,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 79.956,99.402,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 79.947,99.403,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.855 | Acc: 79.886,99.383,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.908 | Acc: 65.625,75.781,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.277 | Acc: 63.207,73.140,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.303 | Acc: 63.148,72.923,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.296 | Acc: 63.589,72.836,77.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 0.814 | Acc: 81.250,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.875 | Acc: 79.762,99.330,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.860 | Acc: 79.688,99.257,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.858 | Acc: 79.764,99.270,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.859 | Acc: 79.630,99.296,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.865 | Acc: 79.641,99.281,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.862 | Acc: 79.720,99.316,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.861 | Acc: 79.748,99.324,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.857 | Acc: 79.867,99.316,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.859 | Acc: 79.774,99.331,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 79.847,99.308,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 79.744,99.318,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.858 | Acc: 79.658,99.335,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 79.685,99.332,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.855 | Acc: 79.746,99.349,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.855 | Acc: 79.724,99.343,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.855 | Acc: 79.644,99.345,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.854 | Acc: 79.713,99.359,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 79.772,99.344,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 79.804,99.346,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.876 | Acc: 66.406,75.000,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.273 | Acc: 63.095,72.879,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 63.129,72.732,77.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.295 | Acc: 63.422,72.682,77.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 0.837 | Acc: 85.156,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.838 | Acc: 80.804,99.516,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.838 | Acc: 80.869,99.466,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.833 | Acc: 80.789,99.449,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.836 | Acc: 80.594,99.421,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.838 | Acc: 80.554,99.474,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.844 | Acc: 80.230,99.464,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.845 | Acc: 80.175,99.479,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.844 | Acc: 80.129,99.486,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 80.098,99.439,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.847 | Acc: 80.131,99.444,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.849 | Acc: 80.087,99.427,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.849 | Acc: 80.077,99.433,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.850 | Acc: 80.014,99.437,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.851 | Acc: 79.968,99.416,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 79.903,99.429,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.852 | Acc: 79.855,99.435,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 79.809,99.434,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.852 | Acc: 79.828,99.437,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 79.833,99.436,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.909 | Acc: 65.625,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.274 | Acc: 63.132,72.954,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.301 | Acc: 63.224,72.771,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.296 | Acc: 63.678,72.720,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 0.795 | Acc: 81.250,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.821 | Acc: 80.804,99.777,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.839 | Acc: 80.393,99.638,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.847 | Acc: 80.379,99.590,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.853 | Acc: 79.890,99.576,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 79.958,99.544,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.848 | Acc: 80.030,99.548,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 79.942,99.529,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.846 | Acc: 80.022,99.544,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.852 | Acc: 79.882,99.534,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.853 | Acc: 79.859,99.506,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.854 | Acc: 79.822,99.484,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.854 | Acc: 79.804,99.491,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 79.714,99.485,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.857 | Acc: 79.793,99.488,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 79.856,99.483,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.857 | Acc: 79.824,99.465,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.858 | Acc: 79.846,99.466,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.857 | Acc: 79.904,99.463,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.857 | Acc: 79.891,99.475,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.900 | Acc: 66.406,76.562,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.265 | Acc: 63.021,73.251,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.301 | Acc: 63.205,72.866,77.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.297 | Acc: 63.601,72.810,77.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 0.874 | Acc: 79.688,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.860 | Acc: 80.543,99.405,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.868 | Acc: 80.183,99.371,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 80.020,99.398,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.875 | Acc: 79.514,99.460,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.864 | Acc: 79.742,99.435,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.858 | Acc: 79.842,99.438,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.857 | Acc: 79.865,99.446,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.858 | Acc: 79.843,99.447,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.861 | Acc: 79.705,99.435,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.858 | Acc: 79.715,99.460,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.858 | Acc: 79.765,99.449,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.856 | Acc: 79.817,99.446,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.853 | Acc: 79.933,99.461,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.851 | Acc: 79.949,99.475,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.851 | Acc: 79.981,99.463,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.849 | Acc: 80.016,99.469,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.849 | Acc: 80.075,99.459,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.849 | Acc: 80.042,99.465,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.851 | Acc: 80.036,99.463,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.891 | Acc: 65.625,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.267 | Acc: 63.281,72.879,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.299 | Acc: 63.377,72.904,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.294 | Acc: 63.768,72.810,77.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 0.683 | Acc: 86.719,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.852 | Acc: 79.762,99.330,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.881 | Acc: 79.135,99.238,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.874 | Acc: 79.316,99.308,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 79.823,99.373,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 79.896,99.335,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 79.739,99.341,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.857 | Acc: 79.898,99.330,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.856 | Acc: 79.950,99.330,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.855 | Acc: 79.946,99.340,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 79.847,99.339,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 79.854,99.332,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.858 | Acc: 79.863,99.329,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 79.852,99.338,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.855 | Acc: 79.915,99.363,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 79.887,99.369,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.855 | Acc: 79.970,99.387,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 79.992,99.400,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 80.010,99.401,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 80.020,99.397,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.910 | Acc: 65.625,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.269 | Acc: 63.021,73.177,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.300 | Acc: 63.205,72.809,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.295 | Acc: 63.601,72.784,77.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 0.819 | Acc: 85.938,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.893 | Acc: 79.241,99.479,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.864 | Acc: 79.707,99.428,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.855 | Acc: 79.841,99.411,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.852 | Acc: 79.919,99.441,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 80.059,99.443,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 80.172,99.425,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.851 | Acc: 80.214,99.440,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.849 | Acc: 80.343,99.437,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.847 | Acc: 80.382,99.452,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.849 | Acc: 80.267,99.440,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.850 | Acc: 80.168,99.431,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.850 | Acc: 80.222,99.416,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 80.175,99.407,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 80.152,99.419,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.853 | Acc: 80.105,99.419,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 80.152,99.438,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.851 | Acc: 80.125,99.430,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 80.118,99.429,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 79.981,99.418,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.895 | Acc: 65.625,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.272 | Acc: 63.207,73.028,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 63.243,72.942,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.297 | Acc: 63.576,72.810,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 0.860 | Acc: 82.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.891 | Acc: 79.390,99.219,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.882 | Acc: 79.516,99.295,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.873 | Acc: 79.700,99.321,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.876 | Acc: 79.572,99.248,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.868 | Acc: 79.718,99.273,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.869 | Acc: 79.545,99.270,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 79.549,99.291,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.865 | Acc: 79.702,99.306,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.865 | Acc: 79.718,99.309,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.863 | Acc: 79.715,99.300,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.864 | Acc: 79.705,99.325,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.864 | Acc: 79.642,99.316,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.860 | Acc: 79.759,99.318,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.859 | Acc: 79.765,99.327,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.859 | Acc: 79.745,99.333,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.857 | Acc: 79.834,99.340,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.854 | Acc: 79.921,99.322,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 79.952,99.336,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.855 | Acc: 79.954,99.340,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.903 | Acc: 66.406,74.219,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.268 | Acc: 63.095,73.028,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.301 | Acc: 63.034,72.847,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 63.525,72.759,77.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 0.950 | Acc: 76.562,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.885 | Acc: 78.646,99.591,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.864 | Acc: 79.306,99.619,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.859 | Acc: 79.534,99.565,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.850 | Acc: 79.851,99.576,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.856 | Acc: 79.765,99.575,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.853 | Acc: 79.881,99.535,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.854 | Acc: 79.854,99.501,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.853 | Acc: 79.950,99.495,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.849 | Acc: 80.106,99.504,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.847 | Acc: 80.162,99.475,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.848 | Acc: 80.133,99.484,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.847 | Acc: 80.219,99.491,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.846 | Acc: 80.181,99.464,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.845 | Acc: 80.196,99.455,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.847 | Acc: 80.168,99.439,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.849 | Acc: 80.116,99.426,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.849 | Acc: 80.114,99.420,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.850 | Acc: 80.088,99.414,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 79.991,99.414,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.904 | Acc: 65.625,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.275 | Acc: 63.021,73.028,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.307 | Acc: 63.091,72.809,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.303 | Acc: 63.589,72.759,77.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 0.831 | Acc: 84.375,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.866 | Acc: 80.506,99.516,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.853 | Acc: 79.954,99.581,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.854 | Acc: 79.944,99.526,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.858 | Acc: 79.842,99.460,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.853 | Acc: 79.904,99.466,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.852 | Acc: 80.043,99.471,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.855 | Acc: 79.998,99.446,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.859 | Acc: 79.814,99.466,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.860 | Acc: 79.765,99.448,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.857 | Acc: 79.894,99.444,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 79.946,99.456,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 79.882,99.462,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.855 | Acc: 79.930,99.452,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.854 | Acc: 79.904,99.477,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.854 | Acc: 79.898,99.496,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.853 | Acc: 79.950,99.501,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 79.942,99.507,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 79.995,99.513,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.850 | Acc: 80.065,99.508,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.897 | Acc: 66.406,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.271 | Acc: 63.095,72.917,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.305 | Acc: 63.091,72.847,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 63.473,72.772,77.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 0.831 | Acc: 78.906,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.824 | Acc: 81.250,99.516,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.829 | Acc: 81.059,99.562,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.840 | Acc: 80.789,99.552,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.845 | Acc: 80.527,99.518,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 80.167,99.474,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.855 | Acc: 79.926,99.477,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 79.765,99.413,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.859 | Acc: 79.877,99.384,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.855 | Acc: 79.895,99.387,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.853 | Acc: 79.936,99.394,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.854 | Acc: 79.921,99.392,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.850 | Acc: 80.018,99.410,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.852 | Acc: 79.891,99.404,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 79.868,99.394,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.853 | Acc: 79.859,99.395,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.854 | Acc: 79.807,99.401,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 79.752,99.411,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.856 | Acc: 79.776,99.422,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.856 | Acc: 79.757,99.424,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.897 | Acc: 65.625,75.000,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.276 | Acc: 63.021,73.140,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.303 | Acc: 63.224,72.999,77.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.297 | Acc: 63.653,72.848,77.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 0.977 | Acc: 80.469,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.871 | Acc: 80.134,99.182,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.854 | Acc: 79.897,99.371,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.854 | Acc: 80.251,99.308,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.860 | Acc: 79.948,99.325,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.859 | Acc: 79.912,99.350,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.853 | Acc: 80.127,99.387,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.850 | Acc: 80.258,99.391,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.851 | Acc: 80.236,99.393,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.852 | Acc: 80.223,99.404,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.853 | Acc: 80.181,99.398,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.854 | Acc: 80.101,99.403,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.852 | Acc: 80.151,99.404,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.849 | Acc: 80.181,99.383,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 80.113,99.377,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 80.150,99.377,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.849 | Acc: 80.240,99.377,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.850 | Acc: 80.205,99.370,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 80.092,99.372,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 80.042,99.377,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.868 | Acc: 65.625,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.270 | Acc: 62.872,73.103,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.300 | Acc: 63.034,72.790,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.295 | Acc: 63.563,72.695,77.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 0.997 | Acc: 76.562,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.885 | Acc: 78.869,99.182,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.868 | Acc: 79.630,99.428,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.870 | Acc: 79.342,99.475,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 79.331,99.498,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.866 | Acc: 79.324,99.489,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 79.649,99.471,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 79.793,99.440,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.858 | Acc: 79.877,99.447,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.859 | Acc: 79.774,99.443,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.857 | Acc: 79.851,99.436,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.856 | Acc: 79.854,99.438,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 79.820,99.420,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.855 | Acc: 79.903,99.422,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.857 | Acc: 79.902,99.411,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 79.895,99.408,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.857 | Acc: 79.838,99.375,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.856 | Acc: 79.871,99.381,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.856 | Acc: 79.915,99.388,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.856 | Acc: 79.911,99.397,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.886 | Acc: 65.625,75.781,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.274 | Acc: 63.207,72.879,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 63.262,72.732,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.296 | Acc: 63.678,72.707,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 0.982 | Acc: 78.125,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.889 | Acc: 78.385,99.330,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.867 | Acc: 79.630,99.314,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.866 | Acc: 79.700,99.321,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.863 | Acc: 79.688,99.354,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 79.672,99.304,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.866 | Acc: 79.410,99.322,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.864 | Acc: 79.449,99.363,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.863 | Acc: 79.406,99.393,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 79.485,99.396,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.863 | Acc: 79.384,99.405,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.864 | Acc: 79.412,99.406,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.860 | Acc: 79.506,99.397,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.860 | Acc: 79.484,99.401,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.859 | Acc: 79.496,99.416,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.857 | Acc: 79.602,99.421,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.856 | Acc: 79.653,99.421,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 79.763,99.411,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 79.763,99.401,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.851 | Acc: 79.874,99.393,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.873 | Acc: 66.406,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.268 | Acc: 62.946,73.065,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.298 | Acc: 63.129,72.847,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.292 | Acc: 63.627,72.733,77.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 0.849 | Acc: 72.656,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.839 | Acc: 79.874,99.330,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.852 | Acc: 79.630,99.314,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.850 | Acc: 79.828,99.411,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.842 | Acc: 80.122,99.450,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.844 | Acc: 79.935,99.482,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 80.049,99.477,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.846 | Acc: 79.926,99.474,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.844 | Acc: 79.979,99.471,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.847 | Acc: 79.856,99.504,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.849 | Acc: 79.824,99.491,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.850 | Acc: 79.783,99.502,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.851 | Acc: 79.726,99.485,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.850 | Acc: 79.750,99.494,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 79.713,99.488,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 79.698,99.494,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.852 | Acc: 79.726,99.486,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.854 | Acc: 79.713,99.466,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 79.776,99.468,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 79.782,99.467,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.891 | Acc: 64.844,75.781,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.271 | Acc: 62.946,73.103,77.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.302 | Acc: 63.014,72.752,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.297 | Acc: 63.422,72.746,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 1.078 | Acc: 71.875,100.000,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.833 | Acc: 80.766,99.740,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.849 | Acc: 80.030,99.466,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.850 | Acc: 80.149,99.436,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.847 | Acc: 80.237,99.441,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.856 | Acc: 79.896,99.443,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.856 | Acc: 79.855,99.432,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.857 | Acc: 80.009,99.440,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.860 | Acc: 79.969,99.432,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.859 | Acc: 79.942,99.443,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 80.002,99.440,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 79.988,99.417,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 79.927,99.407,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 79.927,99.401,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 79.915,99.408,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.854 | Acc: 80.007,99.408,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.856 | Acc: 79.948,99.406,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.854 | Acc: 79.962,99.411,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 79.997,99.407,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.855 | Acc: 79.993,99.416,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.893 | Acc: 65.625,75.781,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.270 | Acc: 62.909,72.954,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.300 | Acc: 63.110,72.866,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.294 | Acc: 63.691,72.772,77.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 0.736 | Acc: 82.812,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.856 | Acc: 79.129,99.628,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.856 | Acc: 79.268,99.543,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.860 | Acc: 79.265,99.526,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.852 | Acc: 79.823,99.508,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.852 | Acc: 79.974,99.513,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.853 | Acc: 79.913,99.529,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.854 | Acc: 79.887,99.523,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.852 | Acc: 80.100,99.510,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.853 | Acc: 80.110,99.499,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 79.991,99.491,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.855 | Acc: 80.023,99.487,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.856 | Acc: 80.038,99.472,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 79.963,99.476,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.856 | Acc: 79.949,99.455,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 79.890,99.450,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.857 | Acc: 79.868,99.440,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.857 | Acc: 79.862,99.432,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.856 | Acc: 79.861,99.429,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.856 | Acc: 79.860,99.457,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.898 | Acc: 65.625,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.269 | Acc: 62.946,72.991,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.297 | Acc: 63.072,72.904,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.292 | Acc: 63.525,72.772,77.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 0.998 | Acc: 75.781,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.827 | Acc: 80.729,99.516,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.823 | Acc: 80.812,99.371,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.841 | Acc: 80.225,99.321,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.852 | Acc: 79.948,99.354,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.856 | Acc: 79.804,99.350,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.859 | Acc: 79.720,99.367,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.853 | Acc: 79.848,99.379,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.852 | Acc: 79.862,99.355,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.849 | Acc: 80.016,99.370,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.847 | Acc: 80.142,99.374,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.846 | Acc: 80.154,99.378,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 80.151,99.378,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.848 | Acc: 80.038,99.353,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.848 | Acc: 80.038,99.363,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.850 | Acc: 80.015,99.364,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 79.963,99.370,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.851 | Acc: 79.965,99.377,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.849 | Acc: 79.947,99.379,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.850 | Acc: 79.983,99.373,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.908 | Acc: 64.844,75.000,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.271 | Acc: 62.909,73.103,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.305 | Acc: 62.919,72.885,77.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 63.512,72.746,77.677,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 0.756 | Acc: 79.688,99.219,100.000,% | Adaptive Acc: 97.656% | clf_exit: 0.695 0.289 0.016
Batch: 20 | Loss: 0.859 | Acc: 78.869,99.591,100.000,% | Adaptive Acc: 95.350% | clf_exit: 0.689 0.299 0.012
Batch: 40 | Loss: 0.860 | Acc: 79.040,99.390,99.981,% | Adaptive Acc: 95.122% | clf_exit: 0.685 0.303 0.012
Batch: 60 | Loss: 0.854 | Acc: 79.175,99.385,99.987,% | Adaptive Acc: 95.146% | clf_exit: 0.688 0.300 0.012
Batch: 80 | Loss: 0.863 | Acc: 78.916,99.450,99.971,% | Adaptive Acc: 94.985% | clf_exit: 0.686 0.302 0.013
Batch: 100 | Loss: 0.858 | Acc: 79.185,99.404,99.977,% | Adaptive Acc: 95.073% | clf_exit: 0.687 0.300 0.013
Batch: 120 | Loss: 0.863 | Acc: 79.236,99.393,99.981,% | Adaptive Acc: 95.087% | clf_exit: 0.687 0.300 0.013
Batch: 140 | Loss: 0.862 | Acc: 79.399,99.391,99.978,% | Adaptive Acc: 95.102% | clf_exit: 0.687 0.300 0.013
Batch: 160 | Loss: 0.861 | Acc: 79.445,99.369,99.971,% | Adaptive Acc: 95.084% | clf_exit: 0.688 0.299 0.013
Batch: 180 | Loss: 0.862 | Acc: 79.450,99.357,99.974,% | Adaptive Acc: 95.006% | clf_exit: 0.688 0.298 0.013
Batch: 200 | Loss: 0.859 | Acc: 79.598,99.378,99.977,% | Adaptive Acc: 95.106% | clf_exit: 0.688 0.299 0.014
Batch: 220 | Loss: 0.856 | Acc: 79.737,99.378,99.965,% | Adaptive Acc: 95.168% | clf_exit: 0.687 0.300 0.013
Batch: 240 | Loss: 0.855 | Acc: 79.736,99.400,99.968,% | Adaptive Acc: 95.121% | clf_exit: 0.687 0.300 0.013
Batch: 260 | Loss: 0.853 | Acc: 79.846,99.419,99.970,% | Adaptive Acc: 95.163% | clf_exit: 0.687 0.300 0.013
Batch: 280 | Loss: 0.854 | Acc: 79.768,99.416,99.972,% | Adaptive Acc: 95.160% | clf_exit: 0.687 0.301 0.012
Batch: 300 | Loss: 0.856 | Acc: 79.773,99.406,99.969,% | Adaptive Acc: 95.144% | clf_exit: 0.687 0.300 0.013
Batch: 320 | Loss: 0.857 | Acc: 79.705,99.396,99.968,% | Adaptive Acc: 95.159% | clf_exit: 0.687 0.300 0.013
Batch: 340 | Loss: 0.858 | Acc: 79.683,99.393,99.968,% | Adaptive Acc: 95.166% | clf_exit: 0.687 0.300 0.013
Batch: 360 | Loss: 0.858 | Acc: 79.642,99.394,99.968,% | Adaptive Acc: 95.133% | clf_exit: 0.687 0.300 0.013
Batch: 380 | Loss: 0.855 | Acc: 79.726,99.395,99.969,% | Adaptive Acc: 95.148% | clf_exit: 0.688 0.299 0.013
Batch: 0 | Loss: 2.898 | Acc: 66.406,74.219,81.250,% | Adaptive Acc: 76.562% | clf_exit: 0.672 0.203 0.125
Batch: 20 | Loss: 3.272 | Acc: 63.281,72.917,77.232,% | Adaptive Acc: 70.796% | clf_exit: 0.690 0.209 0.101
Batch: 40 | Loss: 3.300 | Acc: 63.167,72.809,77.401,% | Adaptive Acc: 70.979% | clf_exit: 0.685 0.213 0.101
Batch: 60 | Loss: 3.297 | Acc: 63.601,72.720,77.561,% | Adaptive Acc: 71.119% | clf_exit: 0.690 0.208 0.102

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 11.751 |  Acc: 7.374,11.740,13.606,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=0 | Loss: 10.585 |  Acc: 10.740,17.770,20.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 9.728 |  Acc: 13.716,22.512,27.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=1 | Loss: 9.257 |  Acc: 13.830,23.610,31.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 8.413 |  Acc: 18.964,30.734,39.032,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=2 | Loss: 8.258 |  Acc: 17.850,29.840,39.530,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 7.487 |  Acc: 22.776,37.352,47.072,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=3 | Loss: 7.318 |  Acc: 23.430,36.810,47.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 6.800 |  Acc: 26.180,43.002,53.186,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=4 | Loss: 6.836 |  Acc: 24.380,41.780,51.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 6.275 |  Acc: 29.016,47.334,57.524,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=5 | Loss: 6.534 |  Acc: 26.580,43.730,55.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 5.863 |  Acc: 31.188,50.818,60.984,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=6 | Loss: 5.981 |  Acc: 31.190,49.400,58.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 5.495 |  Acc: 33.598,53.572,64.510,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=7 | Loss: 5.903 |  Acc: 31.390,50.110,59.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 5.228 |  Acc: 35.164,56.030,66.508,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=8 | Loss: 5.756 |  Acc: 32.030,51.420,61.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 4.965 |  Acc: 37.180,57.968,69.028,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=9 | Loss: 5.732 |  Acc: 31.040,52.290,61.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 4.764 |  Acc: 38.586,59.424,70.992,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=10 | Loss: 5.486 |  Acc: 34.080,53.890,62.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 4.540 |  Acc: 40.174,61.356,73.190,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=11 | Loss: 5.462 |  Acc: 34.500,55.560,64.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 4.396 |  Acc: 41.188,62.566,74.222,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=12 | Loss: 5.541 |  Acc: 34.890,55.240,63.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 4.234 |  Acc: 42.322,64.016,75.870,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=13 | Loss: 5.157 |  Acc: 37.750,57.050,65.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 4.100 |  Acc: 43.588,64.834,77.040,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=14 | Loss: 5.048 |  Acc: 39.950,56.890,65.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 3.959 |  Acc: 44.592,66.068,78.426,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=15 | Loss: 4.930 |  Acc: 40.090,58.740,67.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 3.867 |  Acc: 45.316,66.864,79.698,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=16 | Loss: 5.060 |  Acc: 36.790,58.480,66.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 3.753 |  Acc: 46.260,67.686,80.504,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=17 | Loss: 4.726 |  Acc: 41.870,59.300,68.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 3.650 |  Acc: 47.020,68.510,81.620,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=18 | Loss: 4.848 |  Acc: 41.000,60.200,68.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 3.565 |  Acc: 47.688,69.472,82.392,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=19 | Loss: 4.744 |  Acc: 41.400,61.070,68.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 3.499 |  Acc: 48.228,70.054,83.010,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=20 | Loss: 4.809 |  Acc: 42.090,59.740,67.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 3.405 |  Acc: 48.876,70.912,84.174,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=21 | Loss: 4.438 |  Acc: 44.530,63.230,70.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 3.328 |  Acc: 49.524,71.436,84.896,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=22 | Loss: 4.844 |  Acc: 42.220,60.490,68.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 3.256 |  Acc: 50.096,71.954,85.754,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=23 | Loss: 4.461 |  Acc: 44.430,63.260,68.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 3.194 |  Acc: 50.514,72.402,86.320,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=24 | Loss: 4.456 |  Acc: 46.480,62.780,68.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 3.145 |  Acc: 50.872,73.084,86.560,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=25 | Loss: 4.656 |  Acc: 44.250,61.430,67.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 3.099 |  Acc: 51.234,73.492,87.274,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=26 | Loss: 4.494 |  Acc: 44.530,63.710,69.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 3.030 |  Acc: 51.840,74.144,87.802,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=27 | Loss: 4.621 |  Acc: 44.640,62.370,67.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 2.985 |  Acc: 52.206,74.560,88.366,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=28 | Loss: 4.439 |  Acc: 47.740,63.310,68.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 2.953 |  Acc: 52.838,74.864,88.550,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=29 | Loss: 4.520 |  Acc: 46.600,63.130,68.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 2.913 |  Acc: 53.072,75.118,89.110,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=30 | Loss: 4.382 |  Acc: 48.330,63.040,70.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 2.878 |  Acc: 53.430,75.410,89.304,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=31 | Loss: 4.461 |  Acc: 46.790,62.210,69.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 2.841 |  Acc: 53.470,75.820,89.812,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=32 | Loss: 4.486 |  Acc: 46.190,63.300,69.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 2.807 |  Acc: 54.098,76.162,90.008,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=33 | Loss: 4.332 |  Acc: 49.070,63.600,69.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 2.754 |  Acc: 54.506,76.660,90.518,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=34 | Loss: 4.692 |  Acc: 44.920,61.830,68.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 2.742 |  Acc: 54.562,76.808,90.648,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=35 | Loss: 4.559 |  Acc: 45.950,63.020,69.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 2.715 |  Acc: 54.776,77.076,90.596,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=36 | Loss: 4.330 |  Acc: 49.170,64.830,69.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 2.687 |  Acc: 55.088,77.380,91.108,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=37 | Loss: 4.401 |  Acc: 47.670,64.350,69.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 2.680 |  Acc: 55.302,77.244,90.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=38 | Loss: 4.518 |  Acc: 48.350,63.030,70.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 2.649 |  Acc: 55.486,77.796,91.210,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=39 | Loss: 4.537 |  Acc: 49.080,61.900,69.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 2.617 |  Acc: 55.966,78.074,91.504,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=40 | Loss: 4.482 |  Acc: 48.560,63.450,69.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 2.603 |  Acc: 55.818,78.056,91.854,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=41 | Loss: 4.355 |  Acc: 49.290,64.580,70.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 2.568 |  Acc: 56.234,78.684,91.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=42 | Loss: 4.355 |  Acc: 50.020,63.560,68.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 2.553 |  Acc: 56.526,78.892,92.264,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=43 | Loss: 4.200 |  Acc: 50.280,65.640,70.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 2.551 |  Acc: 56.472,78.962,92.108,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=44 | Loss: 4.252 |  Acc: 50.880,65.580,70.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 2.507 |  Acc: 57.210,79.524,92.386,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=45 | Loss: 4.495 |  Acc: 47.630,63.770,69.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 2.500 |  Acc: 57.092,79.560,92.502,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=46 | Loss: 4.393 |  Acc: 48.720,64.200,69.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 2.489 |  Acc: 56.954,79.490,92.580,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=47 | Loss: 4.363 |  Acc: 50.160,64.290,70.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 2.470 |  Acc: 57.434,79.638,92.540,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=48 | Loss: 4.341 |  Acc: 48.100,65.030,70.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 2.455 |  Acc: 57.292,79.796,92.896,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=49 | Loss: 4.599 |  Acc: 46.040,63.720,68.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 2.436 |  Acc: 57.778,79.878,92.804,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=50 | Loss: 4.470 |  Acc: 50.150,63.580,69.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 2.412 |  Acc: 58.120,80.270,93.086,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=51 | Loss: 4.217 |  Acc: 50.540,66.240,70.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 2.390 |  Acc: 58.022,80.622,93.356,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=52 | Loss: 4.304 |  Acc: 48.650,65.770,71.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 2.399 |  Acc: 58.360,80.580,93.098,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=53 | Loss: 4.402 |  Acc: 49.120,65.350,69.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 2.400 |  Acc: 58.348,80.362,92.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=54 | Loss: 4.421 |  Acc: 48.620,64.020,69.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 2.374 |  Acc: 58.476,80.738,93.306,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=55 | Loss: 4.425 |  Acc: 49.560,64.290,69.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 2.354 |  Acc: 58.692,81.192,93.434,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=56 | Loss: 4.241 |  Acc: 51.120,65.120,70.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 2.327 |  Acc: 58.972,81.326,93.644,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=57 | Loss: 4.372 |  Acc: 49.660,64.900,70.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 2.335 |  Acc: 59.198,81.446,93.458,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=58 | Loss: 4.256 |  Acc: 51.250,65.990,70.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 2.315 |  Acc: 59.094,81.658,93.658,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=59 | Loss: 4.430 |  Acc: 49.070,64.350,70.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 2.305 |  Acc: 59.220,81.602,93.886,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=60 | Loss: 4.204 |  Acc: 52.300,66.210,70.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 2.289 |  Acc: 59.318,81.758,93.768,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=61 | Loss: 4.293 |  Acc: 51.070,65.880,70.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 2.291 |  Acc: 59.542,81.632,93.834,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=62 | Loss: 4.053 |  Acc: 53.510,66.480,71.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 2.275 |  Acc: 59.592,81.756,93.744,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=63 | Loss: 4.544 |  Acc: 48.560,62.610,70.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 2.275 |  Acc: 59.528,81.772,93.870,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=64 | Loss: 4.291 |  Acc: 51.010,64.650,70.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 2.276 |  Acc: 59.854,81.772,93.794,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=65 | Loss: 4.258 |  Acc: 50.950,65.740,70.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 2.265 |  Acc: 59.848,82.056,93.788,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=66 | Loss: 4.265 |  Acc: 52.080,65.610,70.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 2.258 |  Acc: 59.838,81.966,93.684,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=67 | Loss: 4.379 |  Acc: 49.150,64.940,69.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 2.212 |  Acc: 60.248,82.832,94.314,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=68 | Loss: 4.118 |  Acc: 54.010,65.810,70.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 2.246 |  Acc: 60.032,82.118,93.734,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=69 | Loss: 4.486 |  Acc: 48.990,63.890,69.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 2.199 |  Acc: 60.636,82.804,94.412,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=70 | Loss: 4.178 |  Acc: 52.830,65.360,70.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 2.209 |  Acc: 60.258,82.802,94.176,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=71 | Loss: 4.409 |  Acc: 51.660,64.810,69.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 2.191 |  Acc: 60.912,82.840,94.496,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=72 | Loss: 4.243 |  Acc: 53.010,65.470,70.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 2.207 |  Acc: 60.538,82.688,94.122,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=73 | Loss: 4.232 |  Acc: 51.790,66.120,70.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 2.172 |  Acc: 60.764,83.242,94.428,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=74 | Loss: 4.264 |  Acc: 51.600,65.450,70.640,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 2.169 |  Acc: 61.142,83.110,94.494,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=75 | Loss: 4.215 |  Acc: 51.610,65.860,70.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 2.212 |  Acc: 60.686,82.734,93.920,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=76 | Loss: 4.324 |  Acc: 52.500,64.830,69.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 2.144 |  Acc: 61.048,83.446,94.618,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=77 | Loss: 4.332 |  Acc: 52.090,65.790,70.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 2.165 |  Acc: 61.090,83.132,94.408,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=78 | Loss: 4.283 |  Acc: 51.380,65.630,69.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 2.151 |  Acc: 61.212,83.352,94.402,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=79 | Loss: 4.259 |  Acc: 52.120,65.560,70.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 2.124 |  Acc: 61.380,83.988,94.578,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=80 | Loss: 4.568 |  Acc: 47.190,64.820,70.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 2.141 |  Acc: 61.374,83.502,94.418,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=81 | Loss: 4.304 |  Acc: 50.880,65.600,70.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 2.132 |  Acc: 61.402,83.730,94.666,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=82 | Loss: 4.208 |  Acc: 52.860,66.100,70.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 2.132 |  Acc: 61.050,83.626,94.482,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=83 | Loss: 4.167 |  Acc: 51.430,66.730,71.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 2.120 |  Acc: 61.780,83.742,94.642,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=84 | Loss: 4.699 |  Acc: 47.600,65.230,69.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 2.098 |  Acc: 61.676,84.248,94.830,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=85 | Loss: 4.637 |  Acc: 49.010,63.490,69.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 2.119 |  Acc: 61.552,83.838,94.422,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=86 | Loss: 4.217 |  Acc: 51.300,65.890,70.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 2.102 |  Acc: 61.914,83.806,94.570,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=87 | Loss: 4.281 |  Acc: 52.690,65.650,69.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 2.099 |  Acc: 61.882,84.060,94.578,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=88 | Loss: 4.264 |  Acc: 52.410,65.630,70.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 2.103 |  Acc: 61.962,83.972,94.650,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=89 | Loss: 4.223 |  Acc: 52.950,66.840,70.400,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 2.103 |  Acc: 61.692,83.944,94.544,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=90 | Loss: 4.134 |  Acc: 52.830,66.100,70.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 2.096 |  Acc: 61.726,84.114,94.648,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=91 | Loss: 4.146 |  Acc: 52.370,66.670,71.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 2.100 |  Acc: 61.728,83.942,94.562,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=92 | Loss: 4.009 |  Acc: 54.860,66.440,70.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 2.073 |  Acc: 62.234,84.268,94.714,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=93 | Loss: 4.279 |  Acc: 51.910,66.370,69.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 2.085 |  Acc: 62.176,84.106,94.698,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=94 | Loss: 4.458 |  Acc: 50.680,64.850,70.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 2.075 |  Acc: 62.232,84.228,94.808,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=95 | Loss: 4.197 |  Acc: 53.210,65.770,70.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 2.068 |  Acc: 62.308,84.348,94.750,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=96 | Loss: 4.349 |  Acc: 51.990,65.650,70.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 2.034 |  Acc: 62.492,84.780,95.126,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=97 | Loss: 4.429 |  Acc: 51.650,64.940,69.590,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 2.050 |  Acc: 62.280,84.646,94.864,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=98 | Loss: 4.186 |  Acc: 52.360,66.480,70.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 2.051 |  Acc: 62.462,84.574,94.826,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=99 | Loss: 4.224 |  Acc: 53.370,66.480,70.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 2.040 |  Acc: 62.594,84.750,94.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=100 | Loss: 4.275 |  Acc: 53.590,65.990,70.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 2.027 |  Acc: 62.640,84.780,95.044,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=101 | Loss: 4.136 |  Acc: 54.790,66.430,71.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 2.034 |  Acc: 62.830,84.726,94.846,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=102 | Loss: 4.477 |  Acc: 51.210,64.420,70.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 2.023 |  Acc: 62.828,85.050,94.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=103 | Loss: 4.802 |  Acc: 46.820,64.530,69.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 2.032 |  Acc: 62.930,84.716,94.870,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=104 | Loss: 4.338 |  Acc: 52.270,65.130,69.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 2.015 |  Acc: 62.758,85.034,95.240,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=105 | Loss: 4.275 |  Acc: 52.350,65.760,70.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 2.041 |  Acc: 62.876,84.574,94.624,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=106 | Loss: 4.416 |  Acc: 53.440,63.820,69.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 2.033 |  Acc: 62.530,84.784,94.864,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=107 | Loss: 4.187 |  Acc: 53.180,66.320,70.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 2.021 |  Acc: 63.160,84.870,94.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=108 | Loss: 4.397 |  Acc: 50.160,65.630,70.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 2.004 |  Acc: 63.184,85.046,95.014,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=109 | Loss: 4.327 |  Acc: 51.750,64.980,69.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 2.003 |  Acc: 63.300,85.230,95.062,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=110 | Loss: 4.029 |  Acc: 55.500,67.170,71.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 1.979 |  Acc: 63.568,85.456,95.128,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=111 | Loss: 4.153 |  Acc: 53.710,66.180,70.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 2.013 |  Acc: 63.176,84.590,94.736,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=112 | Loss: 4.233 |  Acc: 53.010,66.290,70.510,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 2.027 |  Acc: 63.282,84.794,94.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=113 | Loss: 4.216 |  Acc: 54.330,65.700,70.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 2.007 |  Acc: 63.264,84.972,94.788,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=114 | Loss: 4.430 |  Acc: 50.670,64.520,70.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 2.001 |  Acc: 63.206,85.310,94.790,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=115 | Loss: 4.201 |  Acc: 53.630,66.000,70.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 1.964 |  Acc: 63.408,85.592,95.290,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=116 | Loss: 4.007 |  Acc: 55.080,66.890,71.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 1.963 |  Acc: 63.252,85.688,95.388,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=117 | Loss: 4.281 |  Acc: 52.110,65.610,71.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 1.981 |  Acc: 63.620,85.284,94.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=118 | Loss: 4.205 |  Acc: 53.580,64.360,69.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 1.974 |  Acc: 63.676,85.434,95.172,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=119 | Loss: 4.270 |  Acc: 52.100,66.290,70.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 1.964 |  Acc: 63.730,85.452,95.144,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=120 | Loss: 4.157 |  Acc: 53.670,66.110,71.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 1.974 |  Acc: 63.322,85.446,95.056,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=121 | Loss: 4.346 |  Acc: 52.110,66.310,71.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 1.967 |  Acc: 63.886,85.284,95.094,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=122 | Loss: 4.423 |  Acc: 50.610,65.140,70.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 1.971 |  Acc: 63.770,85.700,94.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=123 | Loss: 4.112 |  Acc: 54.550,66.690,71.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 1.949 |  Acc: 63.920,85.834,95.108,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=124 | Loss: 4.170 |  Acc: 53.130,65.580,70.570,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 1.983 |  Acc: 63.486,85.278,94.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=125 | Loss: 4.394 |  Acc: 51.680,65.280,69.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 1.948 |  Acc: 63.994,85.656,95.178,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=126 | Loss: 4.101 |  Acc: 54.540,66.530,71.590,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 1.939 |  Acc: 64.286,85.778,95.110,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=127 | Loss: 4.637 |  Acc: 49.360,65.000,69.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 1.986 |  Acc: 63.722,85.408,94.896,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=128 | Loss: 4.316 |  Acc: 52.840,65.340,68.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 1.939 |  Acc: 64.012,85.982,95.110,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=129 | Loss: 4.275 |  Acc: 52.640,65.310,70.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 1.944 |  Acc: 63.974,85.942,95.186,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=130 | Loss: 4.393 |  Acc: 49.820,65.730,70.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 1.932 |  Acc: 63.920,85.978,95.168,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=131 | Loss: 4.233 |  Acc: 53.380,67.060,70.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 1.933 |  Acc: 63.880,86.008,95.360,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=132 | Loss: 4.347 |  Acc: 51.290,66.020,71.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 1.958 |  Acc: 63.782,85.408,95.030,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=133 | Loss: 4.603 |  Acc: 49.070,63.530,69.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 1.922 |  Acc: 64.230,86.080,95.516,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=134 | Loss: 4.378 |  Acc: 52.230,64.760,70.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 1.902 |  Acc: 64.196,86.426,95.646,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=135 | Loss: 4.474 |  Acc: 51.280,64.850,69.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 1.925 |  Acc: 64.282,86.012,95.068,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=136 | Loss: 4.294 |  Acc: 52.470,66.440,70.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 1.918 |  Acc: 64.406,86.170,95.306,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=137 | Loss: 4.218 |  Acc: 53.670,65.960,70.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 1.933 |  Acc: 64.276,86.010,95.110,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=138 | Loss: 4.240 |  Acc: 53.680,65.740,70.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 1.920 |  Acc: 64.174,86.146,95.268,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=139 | Loss: 4.192 |  Acc: 54.660,65.130,70.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 1.919 |  Acc: 64.478,85.966,95.218,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=140 | Loss: 4.292 |  Acc: 53.470,66.220,70.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 1.915 |  Acc: 64.444,86.038,95.244,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=141 | Loss: 4.211 |  Acc: 54.000,66.160,70.520,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 1.888 |  Acc: 64.680,86.596,95.518,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=142 | Loss: 4.440 |  Acc: 51.940,66.270,69.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 1.931 |  Acc: 64.138,85.918,95.046,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=143 | Loss: 4.305 |  Acc: 53.960,66.020,69.530,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 1.926 |  Acc: 64.438,85.636,94.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=144 | Loss: 4.429 |  Acc: 50.550,65.260,70.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 1.896 |  Acc: 64.382,86.514,95.500,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=145 | Loss: 4.085 |  Acc: 54.770,67.240,71.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 1.913 |  Acc: 64.370,86.132,95.358,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=146 | Loss: 4.201 |  Acc: 53.630,66.730,71.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 1.891 |  Acc: 64.682,86.430,95.408,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=147 | Loss: 4.440 |  Acc: 49.540,65.110,70.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 1.903 |  Acc: 64.758,86.170,95.210,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=148 | Loss: 4.187 |  Acc: 54.870,65.910,70.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 1.907 |  Acc: 64.786,86.218,95.196,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=149 | Loss: 4.251 |  Acc: 52.690,66.670,71.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 1.383 |  Acc: 70.974,93.412,98.790,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=150 | Loss: 3.261 |  Acc: 62.940,73.520,76.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 1.236 |  Acc: 72.668,95.382,99.636,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=151 | Loss: 3.233 |  Acc: 63.100,73.720,77.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.198 |  Acc: 73.096,95.982,99.772,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=152 | Loss: 3.219 |  Acc: 63.420,74.250,77.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.169 |  Acc: 73.460,96.418,99.824,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=153 | Loss: 3.203 |  Acc: 63.280,74.070,77.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.153 |  Acc: 73.638,96.718,99.846,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=154 | Loss: 3.190 |  Acc: 63.640,74.200,77.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.137 |  Acc: 73.884,96.838,99.860,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=155 | Loss: 3.189 |  Acc: 63.610,74.070,77.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.119 |  Acc: 74.068,97.086,99.890,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=156 | Loss: 3.179 |  Acc: 63.660,74.110,77.650,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.116 |  Acc: 74.246,97.046,99.910,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=157 | Loss: 3.207 |  Acc: 63.350,73.900,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.101 |  Acc: 74.264,97.362,99.890,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=158 | Loss: 3.199 |  Acc: 63.350,73.940,77.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.089 |  Acc: 74.638,97.486,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=159 | Loss: 3.178 |  Acc: 63.570,74.110,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 1.087 |  Acc: 74.696,97.482,99.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=160 | Loss: 3.168 |  Acc: 63.670,73.930,77.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 1.080 |  Acc: 74.782,97.572,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=161 | Loss: 3.208 |  Acc: 63.240,73.590,77.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 1.074 |  Acc: 74.762,97.632,99.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=162 | Loss: 3.188 |  Acc: 63.420,73.880,77.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 1.068 |  Acc: 74.948,97.726,99.924,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=163 | Loss: 3.200 |  Acc: 63.080,73.870,77.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 1.061 |  Acc: 74.972,97.868,99.918,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=164 | Loss: 3.219 |  Acc: 63.010,73.900,77.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 1.059 |  Acc: 74.952,97.940,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=165 | Loss: 3.218 |  Acc: 62.890,73.990,78.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 1.050 |  Acc: 75.330,97.928,99.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=166 | Loss: 3.180 |  Acc: 63.880,74.310,77.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 1.048 |  Acc: 75.154,97.980,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=167 | Loss: 3.180 |  Acc: 63.510,73.870,78.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 1.041 |  Acc: 75.294,98.046,99.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=168 | Loss: 3.194 |  Acc: 63.410,73.940,78.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 1.043 |  Acc: 75.438,98.058,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=169 | Loss: 3.208 |  Acc: 62.930,74.050,78.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 1.037 |  Acc: 75.456,98.164,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=170 | Loss: 3.194 |  Acc: 63.430,74.030,78.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 1.031 |  Acc: 75.518,98.204,99.926,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=171 | Loss: 3.194 |  Acc: 63.460,73.860,78.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 1.029 |  Acc: 75.584,98.194,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=172 | Loss: 3.187 |  Acc: 63.430,73.880,77.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 1.026 |  Acc: 75.774,98.166,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=173 | Loss: 3.197 |  Acc: 63.370,74.050,77.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 1.021 |  Acc: 75.798,98.340,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=174 | Loss: 3.211 |  Acc: 63.150,73.550,77.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 1.020 |  Acc: 75.900,98.298,99.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=175 | Loss: 3.184 |  Acc: 63.540,74.080,78.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 1.021 |  Acc: 75.600,98.326,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=176 | Loss: 3.189 |  Acc: 63.660,74.080,77.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 1.010 |  Acc: 75.928,98.384,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=177 | Loss: 3.208 |  Acc: 63.640,73.730,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 1.013 |  Acc: 75.886,98.436,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=178 | Loss: 3.194 |  Acc: 63.820,73.630,77.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 1.008 |  Acc: 76.102,98.328,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=179 | Loss: 3.242 |  Acc: 62.980,73.620,77.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 1.004 |  Acc: 76.236,98.422,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=180 | Loss: 3.197 |  Acc: 63.780,73.860,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 1.000 |  Acc: 76.102,98.484,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=181 | Loss: 3.225 |  Acc: 63.150,73.560,78.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 0.998 |  Acc: 76.378,98.428,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=182 | Loss: 3.204 |  Acc: 63.330,73.760,77.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 0.998 |  Acc: 76.196,98.502,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=183 | Loss: 3.213 |  Acc: 63.120,73.560,78.070,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 0.997 |  Acc: 76.272,98.532,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=184 | Loss: 3.218 |  Acc: 63.540,73.660,77.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 0.994 |  Acc: 76.374,98.470,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=185 | Loss: 3.212 |  Acc: 63.350,73.660,77.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 0.989 |  Acc: 76.500,98.536,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=186 | Loss: 3.227 |  Acc: 63.270,73.840,78.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 0.990 |  Acc: 76.472,98.616,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=187 | Loss: 3.208 |  Acc: 63.600,73.920,77.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 0.991 |  Acc: 76.366,98.554,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=188 | Loss: 3.211 |  Acc: 63.340,73.720,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 0.987 |  Acc: 76.548,98.608,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=189 | Loss: 3.234 |  Acc: 63.300,73.610,77.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 0.983 |  Acc: 76.514,98.534,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=190 | Loss: 3.239 |  Acc: 63.170,73.620,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 0.979 |  Acc: 76.766,98.678,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=191 | Loss: 3.230 |  Acc: 63.260,73.420,77.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 0.982 |  Acc: 76.664,98.642,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=192 | Loss: 3.233 |  Acc: 63.250,73.520,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 0.974 |  Acc: 76.906,98.678,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=193 | Loss: 3.245 |  Acc: 62.880,73.580,77.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 0.975 |  Acc: 76.672,98.708,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=194 | Loss: 3.252 |  Acc: 63.310,73.130,77.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 0.976 |  Acc: 76.812,98.660,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=195 | Loss: 3.236 |  Acc: 63.100,73.420,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 0.974 |  Acc: 76.754,98.566,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=196 | Loss: 3.233 |  Acc: 63.230,73.510,77.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 0.969 |  Acc: 76.946,98.726,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=197 | Loss: 3.229 |  Acc: 63.540,73.450,77.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 0.966 |  Acc: 76.976,98.746,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=198 | Loss: 3.273 |  Acc: 62.880,73.360,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 0.968 |  Acc: 76.966,98.736,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=199 | Loss: 3.243 |  Acc: 63.440,73.170,77.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 0.961 |  Acc: 77.028,98.800,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=200 | Loss: 3.229 |  Acc: 63.090,73.410,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 0.962 |  Acc: 77.076,98.772,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=201 | Loss: 3.251 |  Acc: 63.390,73.560,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 0.961 |  Acc: 77.020,98.726,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=202 | Loss: 3.253 |  Acc: 63.580,73.110,78.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 0.957 |  Acc: 77.480,98.750,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=203 | Loss: 3.257 |  Acc: 63.110,72.980,78.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 0.961 |  Acc: 77.042,98.838,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=204 | Loss: 3.269 |  Acc: 63.020,72.920,77.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 0.954 |  Acc: 77.266,98.834,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=205 | Loss: 3.296 |  Acc: 63.030,73.010,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 0.955 |  Acc: 77.280,98.792,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=206 | Loss: 3.293 |  Acc: 62.760,73.030,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 0.953 |  Acc: 77.258,98.818,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=207 | Loss: 3.277 |  Acc: 62.940,73.120,77.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 0.951 |  Acc: 77.316,98.862,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=208 | Loss: 3.289 |  Acc: 63.030,73.120,77.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 0.955 |  Acc: 77.276,98.754,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=209 | Loss: 3.282 |  Acc: 63.160,73.080,77.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 0.953 |  Acc: 77.294,98.776,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=210 | Loss: 3.269 |  Acc: 63.030,72.930,77.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 0.950 |  Acc: 77.404,98.750,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=211 | Loss: 3.287 |  Acc: 63.130,73.010,77.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 0.946 |  Acc: 77.394,98.862,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=212 | Loss: 3.275 |  Acc: 63.340,73.090,78.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 0.944 |  Acc: 77.424,98.832,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=213 | Loss: 3.251 |  Acc: 63.420,73.230,77.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 0.945 |  Acc: 77.454,98.812,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=214 | Loss: 3.257 |  Acc: 63.420,73.010,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 0.940 |  Acc: 77.710,98.818,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=215 | Loss: 3.293 |  Acc: 63.050,72.840,77.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 0.940 |  Acc: 77.604,98.896,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=216 | Loss: 3.297 |  Acc: 62.730,73.040,77.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 0.937 |  Acc: 77.580,98.834,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=217 | Loss: 3.326 |  Acc: 62.390,72.890,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 0.939 |  Acc: 77.696,98.844,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=218 | Loss: 3.274 |  Acc: 63.050,73.130,77.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 0.940 |  Acc: 77.802,98.804,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=219 | Loss: 3.297 |  Acc: 62.990,72.740,77.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 0.940 |  Acc: 77.620,98.836,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=220 | Loss: 3.316 |  Acc: 62.640,73.040,77.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 0.938 |  Acc: 77.778,98.898,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=221 | Loss: 3.319 |  Acc: 62.850,72.600,77.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 0.932 |  Acc: 77.888,98.932,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=222 | Loss: 3.319 |  Acc: 63.140,72.490,77.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 0.933 |  Acc: 77.858,98.936,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=223 | Loss: 3.313 |  Acc: 62.890,72.800,77.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 0.928 |  Acc: 77.990,98.928,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=224 | Loss: 3.307 |  Acc: 63.110,72.700,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 0.888 |  Acc: 79.158,99.252,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=225 | Loss: 3.243 |  Acc: 64.190,73.190,78.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 0.874 |  Acc: 79.240,99.338,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=226 | Loss: 3.249 |  Acc: 64.080,73.050,77.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 0.874 |  Acc: 79.474,99.248,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=227 | Loss: 3.237 |  Acc: 64.110,73.100,77.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 0.874 |  Acc: 79.312,99.318,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=228 | Loss: 3.248 |  Acc: 63.980,73.180,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 0.872 |  Acc: 79.500,99.298,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=229 | Loss: 3.244 |  Acc: 64.010,73.150,77.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 0.871 |  Acc: 79.404,99.302,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=230 | Loss: 3.244 |  Acc: 63.870,73.140,77.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 0.870 |  Acc: 79.476,99.334,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=231 | Loss: 3.252 |  Acc: 64.040,73.110,77.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 0.867 |  Acc: 79.472,99.382,99.984,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=232 | Loss: 3.256 |  Acc: 63.920,73.090,77.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 0.875 |  Acc: 79.498,99.300,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=233 | Loss: 3.256 |  Acc: 63.930,73.120,77.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 0.867 |  Acc: 79.692,99.322,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=234 | Loss: 3.246 |  Acc: 64.100,73.090,77.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 0.871 |  Acc: 79.366,99.330,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=235 | Loss: 3.243 |  Acc: 63.900,73.200,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 0.872 |  Acc: 79.392,99.342,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=236 | Loss: 3.250 |  Acc: 63.930,73.240,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 0.868 |  Acc: 79.404,99.390,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=237 | Loss: 3.258 |  Acc: 63.960,73.390,77.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 0.865 |  Acc: 79.618,99.356,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=238 | Loss: 3.249 |  Acc: 63.970,73.090,77.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 0.864 |  Acc: 79.616,99.352,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=239 | Loss: 3.252 |  Acc: 63.870,73.220,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 0.865 |  Acc: 79.704,99.356,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=240 | Loss: 3.255 |  Acc: 63.720,73.160,77.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 0.866 |  Acc: 79.694,99.360,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=241 | Loss: 3.250 |  Acc: 63.800,73.220,77.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 0.869 |  Acc: 79.528,99.362,99.982,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=242 | Loss: 3.256 |  Acc: 63.950,73.050,77.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 0.865 |  Acc: 79.480,99.398,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=243 | Loss: 3.254 |  Acc: 63.940,73.030,77.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 0.866 |  Acc: 79.536,99.360,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=244 | Loss: 3.255 |  Acc: 64.060,73.280,77.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 0.868 |  Acc: 79.550,99.394,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=245 | Loss: 3.254 |  Acc: 64.090,73.060,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 0.861 |  Acc: 79.846,99.386,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=246 | Loss: 3.260 |  Acc: 63.870,73.100,77.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 0.866 |  Acc: 79.574,99.390,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=247 | Loss: 3.250 |  Acc: 63.890,73.180,77.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 0.862 |  Acc: 79.700,99.398,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=248 | Loss: 3.259 |  Acc: 63.630,73.330,77.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 0.864 |  Acc: 79.664,99.414,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=249 | Loss: 3.253 |  Acc: 63.860,73.140,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 0.862 |  Acc: 79.752,99.354,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=250 | Loss: 3.261 |  Acc: 63.870,73.160,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 0.862 |  Acc: 79.788,99.368,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=251 | Loss: 3.260 |  Acc: 63.660,73.040,77.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 0.863 |  Acc: 79.616,99.396,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=252 | Loss: 3.260 |  Acc: 63.930,72.950,77.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 0.859 |  Acc: 79.916,99.364,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=253 | Loss: 3.254 |  Acc: 63.950,73.090,77.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 0.861 |  Acc: 79.668,99.386,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=254 | Loss: 3.254 |  Acc: 63.880,73.010,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 0.859 |  Acc: 79.656,99.378,99.984,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=255 | Loss: 3.268 |  Acc: 63.880,72.970,77.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 0.861 |  Acc: 79.762,99.402,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=256 | Loss: 3.258 |  Acc: 63.850,73.100,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 0.861 |  Acc: 79.680,99.370,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=257 | Loss: 3.257 |  Acc: 63.880,73.200,77.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 0.859 |  Acc: 79.568,99.398,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=258 | Loss: 3.263 |  Acc: 63.850,73.130,77.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 0.860 |  Acc: 79.742,99.362,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=259 | Loss: 3.263 |  Acc: 63.750,72.980,77.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 0.863 |  Acc: 79.718,99.370,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=260 | Loss: 3.259 |  Acc: 63.990,73.230,78.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 0.861 |  Acc: 79.704,99.370,99.982,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=261 | Loss: 3.266 |  Acc: 63.690,73.060,77.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 0.853 |  Acc: 79.818,99.392,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=262 | Loss: 3.268 |  Acc: 63.680,73.110,77.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 0.854 |  Acc: 80.012,99.436,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=263 | Loss: 3.261 |  Acc: 63.810,73.060,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 0.856 |  Acc: 79.672,99.442,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=264 | Loss: 3.258 |  Acc: 63.900,73.150,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 0.856 |  Acc: 79.888,99.420,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=265 | Loss: 3.267 |  Acc: 63.750,73.110,77.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 0.854 |  Acc: 79.920,99.426,99.986,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=266 | Loss: 3.255 |  Acc: 63.920,73.110,77.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 0.854 |  Acc: 79.922,99.432,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=267 | Loss: 3.262 |  Acc: 63.800,73.120,77.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 0.852 |  Acc: 80.146,99.384,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=268 | Loss: 3.261 |  Acc: 63.740,73.140,77.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 0.853 |  Acc: 79.952,99.442,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=269 | Loss: 3.262 |  Acc: 63.890,73.250,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 0.853 |  Acc: 80.110,99.346,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=270 | Loss: 3.258 |  Acc: 63.790,73.030,77.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 0.853 |  Acc: 80.078,99.430,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=271 | Loss: 3.260 |  Acc: 63.750,73.050,77.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 0.853 |  Acc: 80.014,99.440,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=272 | Loss: 3.264 |  Acc: 63.770,73.010,77.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 0.856 |  Acc: 79.864,99.390,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=273 | Loss: 3.260 |  Acc: 63.840,73.130,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 0.852 |  Acc: 80.024,99.372,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=274 | Loss: 3.254 |  Acc: 63.950,73.240,77.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 0.856 |  Acc: 79.850,99.472,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=275 | Loss: 3.255 |  Acc: 63.940,73.220,78.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 0.853 |  Acc: 79.944,99.394,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=276 | Loss: 3.255 |  Acc: 63.820,73.090,77.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 0.854 |  Acc: 79.854,99.444,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=277 | Loss: 3.251 |  Acc: 63.810,73.110,77.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 0.854 |  Acc: 79.876,99.418,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=278 | Loss: 3.261 |  Acc: 63.880,73.110,77.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 0.854 |  Acc: 79.844,99.394,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=279 | Loss: 3.263 |  Acc: 63.860,73.130,77.770,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 0.851 |  Acc: 80.156,99.360,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=280 | Loss: 3.249 |  Acc: 63.790,73.240,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 0.854 |  Acc: 79.906,99.390,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=281 | Loss: 3.260 |  Acc: 63.850,73.170,77.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 0.854 |  Acc: 79.776,99.350,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=282 | Loss: 3.258 |  Acc: 63.760,73.020,78.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 0.851 |  Acc: 79.908,99.434,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=283 | Loss: 3.260 |  Acc: 63.940,73.030,77.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 0.856 |  Acc: 79.936,99.466,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=284 | Loss: 3.259 |  Acc: 63.870,73.210,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 0.852 |  Acc: 79.976,99.460,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=285 | Loss: 3.258 |  Acc: 63.950,73.150,78.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 0.853 |  Acc: 80.022,99.392,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=286 | Loss: 3.258 |  Acc: 63.890,73.160,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 0.852 |  Acc: 79.996,99.420,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=287 | Loss: 3.260 |  Acc: 63.890,73.140,77.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 0.854 |  Acc: 79.970,99.338,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=288 | Loss: 3.261 |  Acc: 63.790,73.090,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 0.852 |  Acc: 79.982,99.414,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=289 | Loss: 3.266 |  Acc: 63.820,73.130,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 0.850 |  Acc: 80.046,99.512,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=290 | Loss: 3.261 |  Acc: 63.790,73.120,77.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 0.855 |  Acc: 79.790,99.418,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=291 | Loss: 3.258 |  Acc: 63.860,73.240,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 0.851 |  Acc: 80.064,99.382,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=292 | Loss: 3.259 |  Acc: 63.850,73.060,77.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 0.857 |  Acc: 79.860,99.402,99.984,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=293 | Loss: 3.260 |  Acc: 63.890,73.080,77.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 0.852 |  Acc: 79.852,99.396,99.980,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=294 | Loss: 3.256 |  Acc: 63.910,73.040,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 0.853 |  Acc: 79.746,99.472,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=295 | Loss: 3.260 |  Acc: 63.750,73.110,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 0.854 |  Acc: 80.020,99.414,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=296 | Loss: 3.256 |  Acc: 63.910,73.150,77.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 0.855 |  Acc: 79.882,99.450,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=297 | Loss: 3.256 |  Acc: 63.750,73.080,77.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 0.851 |  Acc: 79.972,99.374,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=298 | Loss: 3.261 |  Acc: 63.820,73.100,77.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 0.855 |  Acc: 79.728,99.388,99.970,% | Adaptive Acc:95.156% | clf_exit: 0.688 0.299 0.013 
Testing: Epoch=299 | Loss: 3.262 |  Acc: 63.850,73.030,77.880,% | Adaptive Acc:71.510% | clf_exit: 0.691 0.209 0.100 
