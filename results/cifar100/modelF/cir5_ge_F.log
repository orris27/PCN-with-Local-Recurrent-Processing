==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
PredNetBpD(
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=32, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32x1x1])
      (FBconv): ConvTranspose2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(288, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=64, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (FFconv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (linear): Linear(in_features=64, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (PcConvs): ModuleList(
    (0): PcConvBp(
      (FFconv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): PcConvBp(
      (FFconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64x1x1])
      (FBconv): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): PcConvBp(
      (FFconv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x128x1x1])
      (FBconv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): PcConvBp(
      (FFconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x128x1x1])
      (FBconv): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): PcConvBp(
      (FFconv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x256x1x1])
      (FBconv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (5): PcConvBp(
      (FFconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x256x1x1])
      (FBconv): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (6): PcConvBp(
      (FFconv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x512x1x1])
      (FBconv): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (7): PcConvBp(
      (FFconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (relu): ReLU(inplace=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x512x1x1])
      (FBconv): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bypass): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (BNs): ModuleList(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)

Epoch: 0
Batch: 0 | Loss: 13.886 | Acc: 1.562,0.781,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.704 | Acc: 1.749,2.344,1.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.524 | Acc: 2.210,2.763,2.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.398 | Acc: 2.446,2.907,3.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.277 | Acc: 2.749,3.212,3.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.155 | Acc: 3.055,3.721,4.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.050 | Acc: 3.190,4.145,4.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.952 | Acc: 3.313,4.549,5.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.875 | Acc: 3.484,4.838,5.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.802 | Acc: 3.634,5.292,5.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.731 | Acc: 3.813,5.636,6.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.657 | Acc: 3.995,6.020,6.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.585 | Acc: 4.230,6.406,6.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.520 | Acc: 4.445,6.705,7.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.465 | Acc: 4.607,6.981,7.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.403 | Acc: 4.880,7.306,7.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.344 | Acc: 5.079,7.572,8.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.284 | Acc: 5.311,7.849,8.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.228 | Acc: 5.510,8.150,8.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.163 | Acc: 5.780,8.438,9.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.041 | Acc: 7.031,13.281,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.426 | Acc: 7.106,12.351,14.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.411 | Acc: 6.764,12.405,14.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.441 | Acc: 6.801,12.167,14.203,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 10.478 | Acc: 11.719,19.531,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.887 | Acc: 10.156,15.476,18.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.822 | Acc: 10.194,15.111,18.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.783 | Acc: 10.272,15.318,18.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.746 | Acc: 10.349,15.635,18.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.690 | Acc: 10.257,15.695,19.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.645 | Acc: 10.402,16.045,19.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.624 | Acc: 10.450,16.401,19.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.584 | Acc: 10.588,16.460,20.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.529 | Acc: 10.821,16.842,20.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.494 | Acc: 10.972,17.001,20.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.440 | Acc: 11.114,17.336,21.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.394 | Acc: 11.284,17.593,21.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.348 | Acc: 11.524,17.828,21.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.309 | Acc: 11.608,18.027,22.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.259 | Acc: 11.804,18.394,22.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.218 | Acc: 11.955,18.667,22.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.175 | Acc: 12.117,18.961,23.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.133 | Acc: 12.165,19.189,23.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.095 | Acc: 12.346,19.447,24.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.483 | Acc: 6.250,22.656,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.752 | Acc: 8.705,22.173,31.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.738 | Acc: 8.575,21.532,31.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.743 | Acc: 8.683,21.606,30.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 9.339 | Acc: 10.156,22.656,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.134 | Acc: 14.211,26.190,32.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.151 | Acc: 14.844,25.591,32.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.125 | Acc: 15.074,25.218,32.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.018 | Acc: 15.866,26.109,33.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.987 | Acc: 15.996,26.168,33.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.946 | Acc: 16.167,26.569,33.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.940 | Acc: 16.401,26.629,33.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.918 | Acc: 16.392,26.883,34.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.876 | Acc: 16.510,27.184,34.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.841 | Acc: 16.682,27.414,35.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.799 | Acc: 16.749,27.683,35.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.769 | Acc: 16.880,27.918,35.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.728 | Acc: 17.071,28.254,35.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.698 | Acc: 17.204,28.486,36.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.670 | Acc: 17.348,28.776,36.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.640 | Acc: 17.499,29.050,36.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.617 | Acc: 17.540,29.227,36.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.587 | Acc: 17.607,29.501,37.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.565 | Acc: 17.637,29.700,37.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.219 | Acc: 16.406,32.031,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.330 | Acc: 15.960,31.882,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.357 | Acc: 15.796,30.640,39.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.368 | Acc: 15.779,30.110,39.805,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 8.188 | Acc: 21.875,31.250,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.897 | Acc: 19.271,34.412,43.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.846 | Acc: 19.607,34.318,43.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.845 | Acc: 19.262,34.401,44.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.839 | Acc: 19.541,34.828,44.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.813 | Acc: 19.655,34.947,44.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.793 | Acc: 19.815,35.143,44.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.749 | Acc: 20.074,35.533,45.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.722 | Acc: 20.351,35.889,45.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.706 | Acc: 20.446,36.037,45.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.683 | Acc: 20.604,36.198,45.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.654 | Acc: 20.882,36.556,45.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.654 | Acc: 20.870,36.540,45.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.632 | Acc: 21.019,36.677,45.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.613 | Acc: 21.141,36.891,45.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.598 | Acc: 21.265,37.054,45.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.579 | Acc: 21.369,37.305,46.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.564 | Acc: 21.337,37.312,46.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.553 | Acc: 21.375,37.374,46.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.535 | Acc: 21.516,37.533,46.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.603 | Acc: 21.875,38.281,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.461 | Acc: 21.280,37.798,48.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.471 | Acc: 20.922,36.776,47.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.474 | Acc: 20.620,36.501,47.541,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 6.818 | Acc: 27.344,45.312,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.917 | Acc: 25.930,43.155,52.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.886 | Acc: 25.553,43.083,52.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.874 | Acc: 25.615,43.135,52.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.873 | Acc: 25.405,43.393,52.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.907 | Acc: 24.892,43.031,51.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.921 | Acc: 25.045,42.956,51.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.911 | Acc: 24.723,43.113,51.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.911 | Acc: 24.738,42.901,51.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.910 | Acc: 24.754,42.835,51.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.892 | Acc: 24.856,42.969,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.876 | Acc: 24.940,43.089,52.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.861 | Acc: 25.006,43.189,52.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.859 | Acc: 24.967,43.214,52.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.831 | Acc: 25.064,43.503,52.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.815 | Acc: 25.083,43.680,52.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.803 | Acc: 25.153,43.704,52.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.789 | Acc: 25.238,43.807,52.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.776 | Acc: 25.309,43.956,52.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.761 | Acc: 25.408,44.078,52.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.903 | Acc: 24.219,47.656,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.001 | Acc: 20.833,42.820,53.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.022 | Acc: 20.960,42.721,51.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.036 | Acc: 20.543,42.264,51.217,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 6.199 | Acc: 28.906,50.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.348 | Acc: 27.827,47.396,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.395 | Acc: 27.096,46.341,56.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.367 | Acc: 27.472,46.401,56.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.368 | Acc: 27.334,46.711,56.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.397 | Acc: 26.988,46.612,56.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.371 | Acc: 27.344,46.914,56.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.342 | Acc: 27.759,47.091,56.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.321 | Acc: 27.766,47.312,57.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.296 | Acc: 28.017,47.652,57.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.291 | Acc: 28.005,47.683,57.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.294 | Acc: 27.888,47.695,57.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.294 | Acc: 27.943,47.766,57.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.271 | Acc: 28.137,47.959,57.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.257 | Acc: 28.189,48.029,57.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.250 | Acc: 28.291,48.053,57.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.243 | Acc: 28.390,48.153,57.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.237 | Acc: 28.432,48.163,57.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.222 | Acc: 28.549,48.327,57.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.211 | Acc: 28.728,48.444,57.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.259 | Acc: 35.938,57.031,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.383 | Acc: 27.902,47.024,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.369 | Acc: 27.325,46.208,55.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.413 | Acc: 26.819,45.710,54.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 5.611 | Acc: 37.500,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.943 | Acc: 30.060,51.339,61.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.811 | Acc: 29.992,51.867,62.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.807 | Acc: 30.546,51.703,61.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.811 | Acc: 30.642,51.611,61.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.796 | Acc: 30.871,51.787,61.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.784 | Acc: 31.050,51.730,61.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.811 | Acc: 30.851,51.612,61.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.817 | Acc: 30.896,51.480,61.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.809 | Acc: 30.978,51.722,61.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.812 | Acc: 31.044,51.671,61.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.812 | Acc: 31.027,51.690,61.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.799 | Acc: 31.192,51.669,61.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.797 | Acc: 31.262,51.724,61.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.793 | Acc: 31.269,51.860,61.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.795 | Acc: 31.258,51.892,61.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.799 | Acc: 31.238,51.889,61.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.797 | Acc: 31.300,51.895,61.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.785 | Acc: 31.471,52.023,61.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.776 | Acc: 31.529,52.108,61.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.224 | Acc: 33.594,51.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.297 | Acc: 24.926,50.112,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.335 | Acc: 24.390,49.505,58.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.348 | Acc: 24.821,49.206,58.773,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 5.727 | Acc: 26.562,49.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.463 | Acc: 32.068,54.241,64.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.461 | Acc: 32.984,54.592,64.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.419 | Acc: 33.312,55.174,64.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.402 | Acc: 33.189,55.112,64.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.396 | Acc: 33.455,55.221,65.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.410 | Acc: 33.445,55.036,64.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.403 | Acc: 33.638,55.109,64.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.411 | Acc: 33.652,55.187,64.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.416 | Acc: 33.650,55.149,64.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.414 | Acc: 33.827,55.158,64.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.432 | Acc: 33.682,54.988,64.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.423 | Acc: 33.769,55.025,64.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.438 | Acc: 33.579,54.738,64.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.438 | Acc: 33.613,54.701,64.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.430 | Acc: 33.679,54.747,64.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.427 | Acc: 33.735,54.834,64.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.417 | Acc: 33.818,54.928,64.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.419 | Acc: 33.808,54.900,64.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.419 | Acc: 33.901,54.776,64.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.741 | Acc: 32.812,54.688,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.783 | Acc: 30.915,52.827,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.743 | Acc: 31.231,51.867,60.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.793 | Acc: 30.597,51.319,59.682,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 4.801 | Acc: 45.312,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.035 | Acc: 37.128,57.329,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.079 | Acc: 36.376,57.012,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.087 | Acc: 36.386,57.467,67.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.106 | Acc: 35.957,57.176,67.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.082 | Acc: 36.061,57.472,67.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.100 | Acc: 36.138,57.457,67.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.118 | Acc: 36.070,57.308,67.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.094 | Acc: 36.238,57.385,67.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.104 | Acc: 36.136,57.234,67.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.135 | Acc: 35.716,56.930,67.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.146 | Acc: 35.658,56.865,66.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.139 | Acc: 35.886,56.892,66.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.142 | Acc: 35.869,56.864,66.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.133 | Acc: 35.976,56.898,66.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.133 | Acc: 35.971,56.824,66.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.133 | Acc: 36.032,56.895,66.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.137 | Acc: 36.009,56.857,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.136 | Acc: 36.048,56.836,66.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.134 | Acc: 36.083,56.865,66.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.290 | Acc: 39.844,55.469,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.605 | Acc: 33.371,53.460,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.635 | Acc: 33.003,53.792,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.688 | Acc: 32.275,53.599,60.681,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 4.505 | Acc: 35.938,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.868 | Acc: 37.760,59.003,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.856 | Acc: 37.424,58.880,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.824 | Acc: 38.115,59.273,69.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.838 | Acc: 37.780,59.172,69.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.829 | Acc: 37.616,58.981,69.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.854 | Acc: 37.500,58.904,68.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.855 | Acc: 37.489,58.921,69.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.854 | Acc: 37.621,58.982,69.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.852 | Acc: 37.750,59.038,69.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.854 | Acc: 37.819,58.971,68.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.874 | Acc: 37.659,58.626,68.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.879 | Acc: 37.711,58.555,68.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.864 | Acc: 37.880,58.743,68.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.866 | Acc: 37.934,58.660,68.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.866 | Acc: 37.796,58.690,68.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.863 | Acc: 37.902,58.718,68.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.866 | Acc: 37.887,58.692,68.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.871 | Acc: 37.887,58.646,68.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.868 | Acc: 37.849,58.696,68.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.430 | Acc: 37.500,52.344,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.393 | Acc: 33.631,56.138,65.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.409 | Acc: 34.413,55.164,63.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.450 | Acc: 33.876,54.726,63.589,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 4.370 | Acc: 43.750,58.594,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.636 | Acc: 40.030,60.417,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.672 | Acc: 39.482,60.099,72.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.658 | Acc: 39.370,60.528,71.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.633 | Acc: 39.246,60.706,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.649 | Acc: 39.217,60.342,71.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.652 | Acc: 39.250,60.595,71.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.650 | Acc: 39.051,60.738,71.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.650 | Acc: 39.096,60.826,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.639 | Acc: 39.265,60.868,71.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.652 | Acc: 39.218,60.720,71.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.651 | Acc: 39.328,60.750,71.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.654 | Acc: 39.283,60.808,71.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.656 | Acc: 39.311,60.902,71.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.660 | Acc: 39.299,60.829,71.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.658 | Acc: 39.304,60.810,71.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.663 | Acc: 39.277,60.838,71.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.656 | Acc: 39.342,60.814,70.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.661 | Acc: 39.344,60.788,70.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.660 | Acc: 39.452,60.806,70.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.590 | Acc: 32.812,51.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.565 | Acc: 34.003,53.199,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.583 | Acc: 33.384,52.344,62.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.601 | Acc: 33.107,52.177,62.282,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 4.215 | Acc: 41.406,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.487 | Acc: 39.360,62.388,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.450 | Acc: 39.882,63.014,73.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.448 | Acc: 40.228,62.756,73.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.415 | Acc: 40.818,63.030,73.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.425 | Acc: 40.811,62.778,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.445 | Acc: 40.974,62.416,73.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.452 | Acc: 40.908,62.345,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.451 | Acc: 40.897,62.379,73.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.465 | Acc: 40.931,62.293,73.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.470 | Acc: 40.812,62.247,72.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.470 | Acc: 40.826,62.263,73.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.468 | Acc: 40.878,62.309,73.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.463 | Acc: 40.945,62.344,73.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.460 | Acc: 40.936,62.353,73.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.469 | Acc: 40.864,62.152,72.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.475 | Acc: 40.902,62.079,72.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.472 | Acc: 40.971,61.994,72.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.473 | Acc: 41.073,61.996,72.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.474 | Acc: 41.082,61.977,72.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.944 | Acc: 46.094,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.208 | Acc: 37.649,57.068,64.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.165 | Acc: 38.148,57.127,64.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.153 | Acc: 37.871,56.967,64.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 4.462 | Acc: 41.406,64.844,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.158 | Acc: 43.638,64.062,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.205 | Acc: 43.598,63.643,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.210 | Acc: 42.700,63.794,75.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.222 | Acc: 42.660,63.985,75.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.226 | Acc: 42.497,63.869,75.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.230 | Acc: 42.433,63.946,75.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.233 | Acc: 42.509,63.813,74.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.245 | Acc: 42.493,63.665,74.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.249 | Acc: 42.572,63.631,74.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.276 | Acc: 42.382,63.398,74.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.283 | Acc: 42.435,63.377,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.274 | Acc: 42.544,63.424,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.277 | Acc: 42.556,63.473,74.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.288 | Acc: 42.424,63.370,74.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.294 | Acc: 42.380,63.315,74.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.298 | Acc: 42.363,63.237,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.295 | Acc: 42.394,63.325,74.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.291 | Acc: 42.497,63.379,74.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.285 | Acc: 42.659,63.478,74.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.030 | Acc: 40.625,60.156,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.093 | Acc: 38.951,57.589,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.071 | Acc: 39.272,57.222,64.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.085 | Acc: 39.037,57.172,64.255,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 4.137 | Acc: 42.969,60.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.951 | Acc: 44.568,66.481,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.953 | Acc: 44.855,66.311,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.977 | Acc: 44.685,65.804,77.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.987 | Acc: 44.705,65.461,76.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.012 | Acc: 44.307,65.091,76.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.022 | Acc: 44.234,65.270,76.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.037 | Acc: 44.071,65.198,76.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.058 | Acc: 43.949,64.863,76.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.071 | Acc: 43.927,64.723,76.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.079 | Acc: 44.007,64.762,76.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.085 | Acc: 44.050,64.727,75.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.096 | Acc: 43.928,64.740,75.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.101 | Acc: 43.927,64.751,75.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.105 | Acc: 43.858,64.680,75.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.116 | Acc: 43.786,64.571,75.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.122 | Acc: 43.757,64.586,75.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.129 | Acc: 43.684,64.541,75.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.137 | Acc: 43.705,64.502,75.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.137 | Acc: 43.744,64.553,75.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.913 | Acc: 39.062,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.019 | Acc: 40.885,59.226,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.980 | Acc: 40.701,59.127,66.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.003 | Acc: 40.113,58.786,66.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 3.839 | Acc: 46.094,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.952 | Acc: 44.866,66.295,78.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.945 | Acc: 44.569,66.463,78.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.970 | Acc: 44.096,66.265,78.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.985 | Acc: 43.904,65.953,77.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.993 | Acc: 43.680,65.873,77.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.986 | Acc: 43.918,65.987,77.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.985 | Acc: 43.889,66.024,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.982 | Acc: 44.002,66.081,77.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.976 | Acc: 44.156,66.031,77.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.982 | Acc: 44.224,66.033,77.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.979 | Acc: 44.358,66.003,77.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.983 | Acc: 44.453,66.030,77.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.987 | Acc: 44.558,65.984,77.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.989 | Acc: 44.693,65.936,77.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.994 | Acc: 44.721,65.833,77.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.001 | Acc: 44.775,65.761,77.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.010 | Acc: 44.717,65.680,76.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.012 | Acc: 44.763,65.638,76.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.009 | Acc: 44.892,65.687,76.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.792 | Acc: 38.281,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.171 | Acc: 36.086,60.231,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.149 | Acc: 36.662,59.432,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.168 | Acc: 36.322,59.042,66.124,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 4.182 | Acc: 52.344,63.281,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.976 | Acc: 44.754,66.741,78.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.851 | Acc: 45.198,67.530,79.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.811 | Acc: 45.594,68.058,80.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.823 | Acc: 45.785,67.631,79.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.808 | Acc: 45.993,67.652,79.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.817 | Acc: 45.674,67.446,79.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.822 | Acc: 45.800,67.459,79.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.836 | Acc: 45.662,67.343,79.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.843 | Acc: 45.714,67.200,79.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.850 | Acc: 45.585,67.188,78.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.861 | Acc: 45.468,67.074,78.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.865 | Acc: 45.523,66.996,78.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.872 | Acc: 45.579,66.903,78.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.878 | Acc: 45.532,66.795,78.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.882 | Acc: 45.629,66.783,78.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.885 | Acc: 45.641,66.745,78.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.885 | Acc: 45.622,66.732,78.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.894 | Acc: 45.648,66.696,78.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.895 | Acc: 45.686,66.710,78.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.624 | Acc: 42.969,66.406,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.818 | Acc: 42.671,60.565,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.771 | Acc: 41.692,60.671,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.750 | Acc: 41.470,60.438,66.650,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 3.167 | Acc: 44.531,72.656,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.679 | Acc: 46.205,69.680,81.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.678 | Acc: 47.199,69.436,80.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.654 | Acc: 47.477,69.365,81.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.650 | Acc: 47.155,68.972,80.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.691 | Acc: 46.960,68.557,80.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.727 | Acc: 46.714,68.233,79.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.734 | Acc: 46.736,67.991,79.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.749 | Acc: 46.608,67.828,79.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.750 | Acc: 46.487,67.908,79.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.752 | Acc: 46.517,67.840,79.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.743 | Acc: 46.610,67.972,79.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.744 | Acc: 46.713,67.966,79.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.739 | Acc: 46.770,67.981,79.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.751 | Acc: 46.630,67.796,79.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.766 | Acc: 46.532,67.587,79.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.777 | Acc: 46.476,67.489,78.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.785 | Acc: 46.502,67.412,78.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.787 | Acc: 46.518,67.304,78.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.793 | Acc: 46.490,67.224,78.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.852 | Acc: 43.750,60.156,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.747 | Acc: 41.183,61.979,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.754 | Acc: 41.178,60.880,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.776 | Acc: 40.881,60.476,67.495,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 3.661 | Acc: 42.188,68.750,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.570 | Acc: 48.958,69.754,82.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.506 | Acc: 49.333,70.484,83.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.486 | Acc: 48.758,70.172,83.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.504 | Acc: 48.679,69.965,82.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.514 | Acc: 48.569,69.748,82.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.525 | Acc: 48.212,69.518,82.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.537 | Acc: 48.144,69.365,81.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.567 | Acc: 47.855,69.119,81.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.580 | Acc: 47.859,68.961,81.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.591 | Acc: 47.781,69.045,81.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.605 | Acc: 47.688,68.863,81.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.612 | Acc: 47.695,68.760,80.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.631 | Acc: 47.614,68.591,80.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.644 | Acc: 47.506,68.425,80.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.651 | Acc: 47.485,68.381,80.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.660 | Acc: 47.410,68.300,80.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.669 | Acc: 47.466,68.207,80.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.671 | Acc: 47.498,68.161,80.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.667 | Acc: 47.558,68.256,80.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.036 | Acc: 40.625,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.932 | Acc: 41.183,59.449,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.930 | Acc: 40.415,59.489,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.936 | Acc: 40.459,59.388,66.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 3.316 | Acc: 44.531,75.781,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.532 | Acc: 46.391,70.796,83.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.519 | Acc: 47.027,70.217,82.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.527 | Acc: 47.208,69.723,82.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.532 | Acc: 47.434,69.724,82.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.540 | Acc: 47.649,69.740,82.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.540 | Acc: 47.650,69.602,82.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.535 | Acc: 47.684,69.731,82.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.540 | Acc: 47.690,69.570,81.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.529 | Acc: 47.738,69.652,81.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.537 | Acc: 47.874,69.469,81.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.554 | Acc: 47.794,69.245,81.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.565 | Acc: 47.873,69.188,81.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.569 | Acc: 47.926,69.097,81.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.573 | Acc: 47.895,68.986,81.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.584 | Acc: 47.885,68.937,81.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.586 | Acc: 47.926,68.930,81.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.592 | Acc: 47.945,68.908,81.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.598 | Acc: 47.922,68.906,81.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.607 | Acc: 47.900,68.775,80.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.060 | Acc: 42.969,52.344,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.887 | Acc: 40.737,58.854,66.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.876 | Acc: 40.663,59.070,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.889 | Acc: 40.740,59.055,66.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 3.797 | Acc: 45.312,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.474 | Acc: 47.545,71.168,83.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.442 | Acc: 48.514,70.713,83.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.432 | Acc: 49.027,70.543,83.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.403 | Acc: 49.315,70.872,83.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.407 | Acc: 49.242,70.916,83.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.433 | Acc: 48.960,70.681,83.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.441 | Acc: 48.870,70.750,83.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.431 | Acc: 48.996,70.730,83.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.431 | Acc: 49.184,70.653,83.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.442 | Acc: 49.141,70.604,83.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.446 | Acc: 49.116,70.585,82.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.450 | Acc: 49.011,70.539,82.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.460 | Acc: 49.039,70.402,82.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.456 | Acc: 49.174,70.410,82.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.473 | Acc: 49.029,70.193,82.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.476 | Acc: 49.097,70.176,82.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.486 | Acc: 49.031,70.086,82.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.498 | Acc: 48.933,69.981,82.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.504 | Acc: 48.882,69.941,82.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.666 | Acc: 43.750,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.521 | Acc: 42.597,61.905,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 42.607,61.300,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.551 | Acc: 42.789,61.463,67.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 2.708 | Acc: 58.594,79.688,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.402 | Acc: 50.186,70.982,82.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.394 | Acc: 49.162,71.170,83.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.377 | Acc: 48.988,71.260,84.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.357 | Acc: 49.334,71.460,84.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.375 | Acc: 49.273,71.341,83.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.368 | Acc: 49.671,71.417,83.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.379 | Acc: 49.596,71.365,83.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.370 | Acc: 49.694,71.443,83.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.381 | Acc: 49.672,71.331,83.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.393 | Acc: 49.674,71.323,83.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.407 | Acc: 49.502,71.143,83.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.415 | Acc: 49.546,70.964,83.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.409 | Acc: 49.680,71.013,82.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.410 | Acc: 49.691,70.927,82.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.411 | Acc: 49.683,70.917,82.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.421 | Acc: 49.647,70.797,82.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.425 | Acc: 49.617,70.736,82.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.428 | Acc: 49.632,70.670,82.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.438 | Acc: 49.573,70.530,82.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.431 | Acc: 46.094,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 44.978,62.165,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.538 | Acc: 44.779,62.214,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 44.096,62.013,68.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 3.594 | Acc: 49.219,67.188,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.230 | Acc: 49.740,71.949,85.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.245 | Acc: 50.800,71.894,85.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.262 | Acc: 50.397,71.888,85.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.250 | Acc: 50.540,72.058,85.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.245 | Acc: 50.804,72.061,85.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.253 | Acc: 50.865,71.881,85.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.257 | Acc: 50.936,71.820,85.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.249 | Acc: 50.970,71.890,84.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.260 | Acc: 50.915,71.892,84.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.258 | Acc: 50.968,71.856,84.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.276 | Acc: 50.742,71.755,84.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.286 | Acc: 50.710,71.603,84.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.301 | Acc: 50.530,71.531,84.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.304 | Acc: 50.489,71.519,84.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.316 | Acc: 50.350,71.387,83.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.323 | Acc: 50.319,71.305,83.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.326 | Acc: 50.289,71.316,83.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.331 | Acc: 50.296,71.224,83.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.337 | Acc: 50.330,71.170,83.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.692 | Acc: 40.625,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.589 | Acc: 43.936,61.347,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 42.511,61.433,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 42.239,61.962,68.225,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 3.117 | Acc: 53.906,75.000,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.153 | Acc: 51.339,73.624,85.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.127 | Acc: 52.058,73.742,85.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.119 | Acc: 52.190,73.694,86.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.149 | Acc: 51.447,73.418,85.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.162 | Acc: 51.454,73.329,85.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.186 | Acc: 51.349,73.128,85.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.216 | Acc: 51.208,72.773,85.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.233 | Acc: 51.068,72.608,84.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.236 | Acc: 51.122,72.544,84.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.237 | Acc: 51.147,72.551,84.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.248 | Acc: 51.015,72.405,84.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.250 | Acc: 51.057,72.329,84.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.255 | Acc: 51.018,72.261,84.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.261 | Acc: 50.976,72.170,84.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.264 | Acc: 51.015,72.192,84.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.272 | Acc: 50.949,72.075,84.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.274 | Acc: 50.910,72.003,83.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.279 | Acc: 50.911,71.929,83.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.286 | Acc: 50.884,71.859,83.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.306 | Acc: 49.219,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.303 | Acc: 46.912,62.984,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.353 | Acc: 46.551,62.671,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.347 | Acc: 46.760,63.204,69.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 2.961 | Acc: 54.688,71.875,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.059 | Acc: 52.195,74.070,87.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.050 | Acc: 52.420,74.486,87.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.022 | Acc: 52.626,74.808,87.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.040 | Acc: 52.382,74.566,86.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.061 | Acc: 52.251,74.087,86.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.073 | Acc: 52.150,73.870,86.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.084 | Acc: 52.067,73.792,86.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.096 | Acc: 51.931,73.539,86.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.117 | Acc: 51.662,73.239,86.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.134 | Acc: 51.566,73.041,86.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.144 | Acc: 51.608,72.953,85.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.153 | Acc: 51.614,72.851,85.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.161 | Acc: 51.658,72.791,85.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.173 | Acc: 51.576,72.592,85.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.185 | Acc: 51.531,72.449,85.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.201 | Acc: 51.319,72.318,84.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.212 | Acc: 51.306,72.182,84.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.216 | Acc: 51.277,72.156,84.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.220 | Acc: 51.267,72.119,84.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.129 | Acc: 49.219,64.062,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 44.271,62.537,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 44.417,62.081,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 44.275,62.321,68.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 3.194 | Acc: 48.438,76.562,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.105 | Acc: 50.930,74.033,86.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.026 | Acc: 52.782,74.314,87.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.015 | Acc: 52.920,74.539,87.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.004 | Acc: 52.951,74.788,87.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.020 | Acc: 52.591,74.404,87.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.041 | Acc: 52.563,74.167,87.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.071 | Acc: 52.277,73.787,86.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.081 | Acc: 51.994,73.578,86.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.082 | Acc: 52.046,73.541,86.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.093 | Acc: 52.033,73.356,86.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.098 | Acc: 52.043,73.307,86.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.092 | Acc: 52.114,73.350,86.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.098 | Acc: 52.086,73.324,86.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.108 | Acc: 52.038,73.265,85.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.118 | Acc: 51.973,73.181,85.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.124 | Acc: 51.884,73.099,85.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.138 | Acc: 51.844,72.867,85.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.147 | Acc: 51.846,72.764,85.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.152 | Acc: 51.768,72.810,85.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.691 | Acc: 50.000,60.938,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.493 | Acc: 47.135,62.277,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.472 | Acc: 46.646,62.005,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.467 | Acc: 46.760,62.039,67.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 3.029 | Acc: 48.438,74.219,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.004 | Acc: 53.162,74.293,87.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.998 | Acc: 52.134,74.200,87.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.999 | Acc: 52.754,74.001,86.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.027 | Acc: 52.324,73.862,86.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.020 | Acc: 52.529,74.080,87.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.020 | Acc: 52.421,74.135,87.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.006 | Acc: 52.748,73.969,87.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.032 | Acc: 52.630,73.622,86.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.043 | Acc: 52.564,73.524,86.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.053 | Acc: 52.379,73.414,86.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.051 | Acc: 52.521,73.529,86.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.066 | Acc: 52.444,73.376,86.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.069 | Acc: 52.335,73.306,86.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.073 | Acc: 52.316,73.251,86.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.084 | Acc: 52.318,73.219,86.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.084 | Acc: 52.283,73.265,86.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.091 | Acc: 52.332,73.211,86.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.102 | Acc: 52.303,73.080,85.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.110 | Acc: 52.295,73.003,85.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.602 | Acc: 48.438,60.938,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.601 | Acc: 44.792,60.975,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 44.569,61.376,68.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.613 | Acc: 44.006,61.488,67.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 3.054 | Acc: 55.469,75.781,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.992 | Acc: 52.307,75.521,86.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.938 | Acc: 53.182,75.877,87.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.940 | Acc: 53.023,75.115,87.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.952 | Acc: 53.250,74.846,87.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.952 | Acc: 53.535,74.660,87.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.964 | Acc: 53.293,74.626,87.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.980 | Acc: 53.081,74.440,87.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.963 | Acc: 53.198,74.694,87.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.973 | Acc: 53.272,74.495,87.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.982 | Acc: 53.366,74.502,87.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.994 | Acc: 53.326,74.353,86.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.000 | Acc: 53.264,74.248,87.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.012 | Acc: 53.191,74.153,86.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.022 | Acc: 53.250,74.038,86.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.033 | Acc: 53.151,73.923,86.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.035 | Acc: 53.103,73.919,86.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.041 | Acc: 53.077,73.777,86.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.045 | Acc: 53.144,73.637,86.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.048 | Acc: 53.121,73.599,86.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.134 | Acc: 48.438,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.317 | Acc: 46.354,64.211,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.383 | Acc: 46.056,64.139,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.384 | Acc: 46.094,64.165,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 2.826 | Acc: 56.250,78.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.920 | Acc: 53.534,75.335,88.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.920 | Acc: 52.591,75.743,88.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.906 | Acc: 53.227,75.948,88.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.914 | Acc: 53.385,75.588,88.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.916 | Acc: 53.605,75.495,88.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.926 | Acc: 53.383,75.278,88.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.927 | Acc: 53.463,75.222,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.930 | Acc: 53.567,75.126,88.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.934 | Acc: 53.505,74.948,87.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.943 | Acc: 53.545,74.887,87.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.965 | Acc: 53.281,74.657,87.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.975 | Acc: 53.261,74.472,87.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.984 | Acc: 53.146,74.461,87.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.992 | Acc: 53.142,74.338,87.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.001 | Acc: 53.205,74.216,86.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.006 | Acc: 53.191,74.185,86.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.015 | Acc: 53.084,74.104,86.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.020 | Acc: 53.047,74.052,86.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.026 | Acc: 53.061,73.930,86.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.141 | Acc: 44.531,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.532 | Acc: 46.131,61.756,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 45.370,61.300,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 45.453,60.809,68.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 2.767 | Acc: 55.469,76.562,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.877 | Acc: 54.204,74.479,87.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.870 | Acc: 53.392,75.076,88.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.870 | Acc: 53.804,75.679,88.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.909 | Acc: 53.202,75.203,87.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.900 | Acc: 53.357,75.217,88.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.883 | Acc: 53.674,75.491,88.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.884 | Acc: 53.762,75.510,88.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.895 | Acc: 53.717,75.412,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.915 | Acc: 53.509,75.086,87.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.925 | Acc: 53.374,74.914,87.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.934 | Acc: 53.418,74.883,87.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.943 | Acc: 53.388,74.822,87.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.951 | Acc: 53.403,74.790,87.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.953 | Acc: 53.467,74.811,87.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.958 | Acc: 53.434,74.720,87.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.958 | Acc: 53.412,74.759,87.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.962 | Acc: 53.471,74.704,87.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.972 | Acc: 53.443,74.593,87.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.976 | Acc: 53.418,74.557,87.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.355 | Acc: 48.438,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.309 | Acc: 49.591,63.876,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.347 | Acc: 48.971,63.281,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.341 | Acc: 49.091,62.999,69.915,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 2.530 | Acc: 57.812,81.250,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.721 | Acc: 54.613,76.935,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.756 | Acc: 54.630,76.925,89.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.804 | Acc: 54.342,76.562,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.795 | Acc: 54.639,76.495,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.810 | Acc: 54.602,76.292,88.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.833 | Acc: 54.539,76.014,88.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.845 | Acc: 54.593,75.892,88.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.841 | Acc: 54.877,75.776,88.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.845 | Acc: 54.782,75.842,88.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.842 | Acc: 54.944,75.793,88.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.860 | Acc: 54.624,75.650,88.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.869 | Acc: 54.561,75.541,88.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.875 | Acc: 54.556,75.488,88.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.890 | Acc: 54.304,75.286,88.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.898 | Acc: 54.327,75.247,87.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.906 | Acc: 54.257,75.173,87.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.913 | Acc: 54.257,75.115,87.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.922 | Acc: 54.229,74.991,87.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.921 | Acc: 54.300,75.012,87.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.401 | Acc: 42.188,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.417 | Acc: 46.838,63.579,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.437 | Acc: 46.284,62.938,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.437 | Acc: 46.235,63.192,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 2.797 | Acc: 49.219,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.838 | Acc: 53.385,76.414,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.817 | Acc: 54.021,75.762,89.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.831 | Acc: 54.124,75.435,89.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.809 | Acc: 54.784,75.685,89.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.815 | Acc: 54.664,75.696,89.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.807 | Acc: 54.700,75.865,89.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.810 | Acc: 54.604,75.959,89.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.809 | Acc: 54.542,75.951,89.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.821 | Acc: 54.541,75.833,88.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.829 | Acc: 54.485,75.676,88.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.837 | Acc: 54.433,75.629,88.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.841 | Acc: 54.435,75.564,88.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.847 | Acc: 54.400,75.425,88.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.849 | Acc: 54.521,75.353,88.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.860 | Acc: 54.495,75.200,88.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.872 | Acc: 54.471,75.097,88.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.877 | Acc: 54.479,75.027,88.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.883 | Acc: 54.419,74.942,88.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.897 | Acc: 54.288,74.813,87.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.701 | Acc: 46.094,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.787 | Acc: 43.750,61.830,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.788 | Acc: 43.236,62.005,68.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.782 | Acc: 43.289,62.001,68.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 3.085 | Acc: 48.438,71.875,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.800 | Acc: 54.427,76.414,88.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.785 | Acc: 54.973,76.162,89.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.781 | Acc: 55.020,76.242,89.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 55.199,76.003,89.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.761 | Acc: 55.306,76.253,89.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.769 | Acc: 55.333,76.078,89.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.773 | Acc: 55.397,75.992,89.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.788 | Acc: 55.168,76.048,89.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.786 | Acc: 55.244,76.083,88.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.787 | Acc: 55.274,76.042,88.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.793 | Acc: 55.211,75.983,88.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.809 | Acc: 55.031,75.742,88.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.823 | Acc: 54.903,75.551,88.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.829 | Acc: 54.993,75.581,88.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.840 | Acc: 54.830,75.436,88.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.854 | Acc: 54.644,75.226,88.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.866 | Acc: 54.509,75.140,88.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.873 | Acc: 54.540,75.126,88.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.880 | Acc: 54.439,75.012,87.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.551 | Acc: 46.094,63.281,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.334 | Acc: 48.400,63.207,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.383 | Acc: 47.332,62.995,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.423 | Acc: 47.170,62.551,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 2.787 | Acc: 50.781,73.438,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.804 | Acc: 54.911,74.479,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.775 | Acc: 55.354,75.191,89.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.800 | Acc: 55.289,75.461,89.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.762 | Acc: 55.257,75.965,89.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.748 | Acc: 55.121,76.416,89.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.745 | Acc: 55.359,76.459,89.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.755 | Acc: 55.197,76.463,89.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.764 | Acc: 55.003,76.291,89.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.770 | Acc: 55.210,76.122,89.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.781 | Acc: 55.197,76.042,89.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.787 | Acc: 55.144,76.053,89.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.800 | Acc: 55.096,75.853,89.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.809 | Acc: 55.125,75.838,89.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.814 | Acc: 55.171,75.767,88.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.817 | Acc: 55.155,75.771,88.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.822 | Acc: 55.053,75.686,88.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.830 | Acc: 54.930,75.584,88.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.836 | Acc: 54.871,75.491,88.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.840 | Acc: 54.852,75.457,88.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.278 | Acc: 53.125,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.365 | Acc: 47.768,63.542,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.374 | Acc: 48.628,63.434,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.374 | Acc: 48.181,63.397,69.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 2.908 | Acc: 53.125,71.094,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.815 | Acc: 54.688,75.112,88.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.693 | Acc: 56.021,75.857,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.715 | Acc: 55.482,76.101,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.707 | Acc: 55.864,76.485,89.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.712 | Acc: 55.770,76.601,90.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.706 | Acc: 56.018,76.756,89.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.705 | Acc: 55.979,76.862,89.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.708 | Acc: 56.051,76.805,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.719 | Acc: 55.956,76.791,89.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.731 | Acc: 55.764,76.745,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.744 | Acc: 55.614,76.577,89.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.761 | Acc: 55.553,76.387,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.771 | Acc: 55.493,76.272,88.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.774 | Acc: 55.477,76.282,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.779 | Acc: 55.510,76.241,88.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.784 | Acc: 55.476,76.176,88.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.791 | Acc: 55.432,76.113,88.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.801 | Acc: 55.313,76.011,88.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.806 | Acc: 55.280,75.919,88.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.214 | Acc: 50.000,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.328 | Acc: 48.810,62.872,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.346 | Acc: 48.533,62.786,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.351 | Acc: 48.540,62.807,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 2.441 | Acc: 55.469,80.469,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 56.101,77.121,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.662 | Acc: 56.345,77.401,90.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.652 | Acc: 56.327,77.293,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.626 | Acc: 56.443,77.749,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.636 | Acc: 56.513,77.669,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.647 | Acc: 56.424,77.634,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.670 | Acc: 56.111,77.427,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.693 | Acc: 55.828,77.276,89.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.696 | Acc: 55.956,77.162,89.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.711 | Acc: 55.830,77.095,89.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.719 | Acc: 55.748,76.923,89.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.730 | Acc: 55.628,76.721,89.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.736 | Acc: 55.529,76.613,89.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.737 | Acc: 55.580,76.579,89.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.740 | Acc: 55.562,76.513,89.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.742 | Acc: 55.688,76.407,89.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.747 | Acc: 55.691,76.411,89.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.750 | Acc: 55.707,76.307,89.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.756 | Acc: 55.666,76.200,89.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.263 | Acc: 52.344,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.358 | Acc: 49.405,62.612,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.412 | Acc: 48.533,62.271,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.431 | Acc: 48.694,62.513,69.813,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 2.559 | Acc: 54.688,81.250,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.666 | Acc: 55.246,77.493,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.666 | Acc: 55.431,77.763,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.681 | Acc: 55.213,77.818,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.673 | Acc: 55.517,77.865,91.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.668 | Acc: 55.840,78.048,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.669 | Acc: 55.895,77.899,90.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.666 | Acc: 56.128,77.953,90.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.671 | Acc: 56.192,77.761,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.676 | Acc: 56.099,77.706,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.682 | Acc: 56.063,77.554,90.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.689 | Acc: 56.049,77.436,90.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.692 | Acc: 55.952,77.357,90.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.705 | Acc: 55.852,77.089,89.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.699 | Acc: 55.927,77.166,89.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.704 | Acc: 55.983,77.113,89.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.717 | Acc: 55.963,76.908,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.724 | Acc: 55.911,76.773,89.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.730 | Acc: 55.886,76.720,89.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.736 | Acc: 55.774,76.661,89.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.369 | Acc: 49.219,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.486 | Acc: 45.722,65.365,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.493 | Acc: 46.075,64.558,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.489 | Acc: 46.196,64.600,69.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 2.506 | Acc: 62.500,75.000,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.690 | Acc: 56.287,76.823,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.641 | Acc: 56.955,77.896,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.604 | Acc: 57.467,78.394,90.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.617 | Acc: 57.166,78.270,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.611 | Acc: 57.163,78.249,90.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.624 | Acc: 56.947,77.983,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.612 | Acc: 57.170,78.136,90.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.616 | Acc: 57.119,77.999,90.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.633 | Acc: 56.876,77.719,90.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.635 | Acc: 56.880,77.589,90.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.636 | Acc: 56.904,77.513,90.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.641 | Acc: 56.798,77.370,90.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.651 | Acc: 56.768,77.368,90.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.660 | Acc: 56.737,77.324,90.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.674 | Acc: 56.491,77.172,90.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.678 | Acc: 56.552,77.032,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.686 | Acc: 56.477,76.947,89.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.694 | Acc: 56.391,76.874,89.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.700 | Acc: 56.355,76.792,89.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.281 | Acc: 46.875,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.325 | Acc: 48.772,64.100,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.349 | Acc: 48.838,64.005,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.349 | Acc: 48.860,63.870,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 2.530 | Acc: 56.250,80.469,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.619 | Acc: 56.213,78.832,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.576 | Acc: 56.822,78.544,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.602 | Acc: 56.826,77.984,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.614 | Acc: 56.539,77.566,90.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.616 | Acc: 56.157,77.545,90.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.617 | Acc: 56.160,77.667,90.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.626 | Acc: 56.117,77.726,90.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.614 | Acc: 56.425,77.708,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.609 | Acc: 56.479,77.831,90.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.615 | Acc: 56.553,77.736,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.629 | Acc: 56.388,77.574,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.642 | Acc: 56.263,77.548,90.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.646 | Acc: 56.283,77.529,90.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.660 | Acc: 56.105,77.308,90.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.667 | Acc: 56.107,77.271,90.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.672 | Acc: 56.104,77.193,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.676 | Acc: 56.085,77.149,89.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.691 | Acc: 56.031,77.034,89.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.693 | Acc: 56.063,77.012,89.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.354 | Acc: 50.000,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.641 | Acc: 46.912,63.765,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.695 | Acc: 46.380,63.586,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.695 | Acc: 45.838,63.332,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 2.587 | Acc: 62.500,75.781,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.615 | Acc: 56.548,78.497,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.601 | Acc: 56.250,78.449,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.580 | Acc: 56.570,78.612,90.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.589 | Acc: 56.337,78.038,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.594 | Acc: 56.335,77.986,90.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.595 | Acc: 56.495,77.938,90.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.609 | Acc: 56.366,77.793,90.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.609 | Acc: 56.531,77.887,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.632 | Acc: 56.319,77.741,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.634 | Acc: 56.246,77.760,90.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.631 | Acc: 56.307,77.662,90.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.634 | Acc: 56.315,77.580,90.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.638 | Acc: 56.343,77.511,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.646 | Acc: 56.311,77.427,90.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.646 | Acc: 56.471,77.390,90.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.652 | Acc: 56.452,77.305,89.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.663 | Acc: 56.330,77.131,89.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.666 | Acc: 56.304,77.086,89.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.673 | Acc: 56.316,76.983,89.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.035 | Acc: 50.000,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.044 | Acc: 51.972,66.629,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.096 | Acc: 51.753,65.492,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.128 | Acc: 51.562,65.791,70.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 2.593 | Acc: 54.688,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.540 | Acc: 58.408,78.162,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.516 | Acc: 57.851,78.544,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.511 | Acc: 57.710,78.829,91.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.516 | Acc: 57.861,78.588,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 58.184,78.558,91.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.546 | Acc: 57.890,78.390,90.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.552 | Acc: 58.012,78.230,90.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.574 | Acc: 57.803,77.941,90.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.575 | Acc: 57.718,77.965,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.576 | Acc: 57.634,77.927,90.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.583 | Acc: 57.590,77.775,90.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.589 | Acc: 57.469,77.704,90.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.596 | Acc: 57.328,77.667,90.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.606 | Acc: 57.295,77.536,90.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.618 | Acc: 57.210,77.375,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.626 | Acc: 57.131,77.307,90.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.633 | Acc: 57.105,77.257,90.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.646 | Acc: 56.919,77.138,90.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.647 | Acc: 56.953,77.215,90.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.904 | Acc: 59.375,69.531,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.241 | Acc: 49.740,64.695,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.257 | Acc: 49.047,65.072,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.256 | Acc: 49.616,64.831,70.223,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 2.745 | Acc: 57.031,75.781,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.486 | Acc: 59.003,79.353,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.494 | Acc: 58.289,79.306,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.480 | Acc: 58.491,79.572,91.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.480 | Acc: 58.362,79.398,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.485 | Acc: 58.315,79.169,91.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.502 | Acc: 57.974,78.939,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.497 | Acc: 58.056,78.801,91.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.525 | Acc: 57.880,78.571,91.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.538 | Acc: 57.765,78.436,91.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.552 | Acc: 57.743,78.261,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.565 | Acc: 57.607,78.136,90.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.573 | Acc: 57.589,78.070,90.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.576 | Acc: 57.552,78.098,90.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.579 | Acc: 57.551,78.033,90.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.583 | Acc: 57.504,77.974,90.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.595 | Acc: 57.460,77.877,90.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.608 | Acc: 57.253,77.738,90.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.615 | Acc: 57.170,77.720,90.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.623 | Acc: 57.152,77.621,90.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.834 | Acc: 52.344,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.158 | Acc: 50.298,64.844,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.162 | Acc: 50.019,64.882,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.161 | Acc: 50.179,65.087,71.337,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 1.920 | Acc: 63.281,89.062,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.522 | Acc: 58.222,80.060,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.498 | Acc: 57.927,79.764,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.508 | Acc: 57.454,79.662,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 57.620,79.543,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.495 | Acc: 57.580,79.440,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.508 | Acc: 57.419,79.223,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.513 | Acc: 57.458,79.139,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.516 | Acc: 57.555,79.052,91.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.533 | Acc: 57.377,78.803,91.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.528 | Acc: 57.455,78.891,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.537 | Acc: 57.385,78.694,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.548 | Acc: 57.342,78.602,91.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.561 | Acc: 57.229,78.355,91.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.571 | Acc: 57.079,78.231,90.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.573 | Acc: 57.104,78.203,90.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.580 | Acc: 57.046,78.144,90.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.582 | Acc: 57.045,78.150,90.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.587 | Acc: 57.023,78.106,90.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.592 | Acc: 57.029,78.055,90.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.794 | Acc: 47.656,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.269 | Acc: 51.079,65.216,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.254 | Acc: 50.991,65.492,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.266 | Acc: 50.628,65.228,69.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 2.992 | Acc: 50.000,71.094,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.469 | Acc: 57.812,79.985,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.469 | Acc: 58.479,79.916,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.476 | Acc: 58.453,79.892,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.493 | Acc: 57.832,79.398,91.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.471 | Acc: 58.246,79.510,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.466 | Acc: 58.536,79.416,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.477 | Acc: 58.217,79.289,91.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.483 | Acc: 58.181,79.328,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.493 | Acc: 58.162,79.161,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.510 | Acc: 57.991,79.007,91.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.515 | Acc: 57.876,78.821,91.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.519 | Acc: 57.780,78.764,91.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.536 | Acc: 57.642,78.514,91.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.549 | Acc: 57.585,78.347,90.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.553 | Acc: 57.584,78.312,90.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.571 | Acc: 57.455,78.093,90.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.583 | Acc: 57.320,77.937,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.589 | Acc: 57.267,77.822,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.601 | Acc: 57.173,77.715,90.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.553 | Acc: 46.875,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.538 | Acc: 48.103,63.132,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.495 | Acc: 47.732,63.453,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.512 | Acc: 47.938,62.769,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 2.372 | Acc: 59.375,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.576 | Acc: 58.333,78.274,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.541 | Acc: 58.003,78.449,90.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.519 | Acc: 58.069,78.484,91.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.508 | Acc: 58.237,78.877,91.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.510 | Acc: 58.130,78.837,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.517 | Acc: 57.806,78.674,91.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.511 | Acc: 57.763,78.751,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 57.798,78.853,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.512 | Acc: 57.743,78.634,91.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.509 | Acc: 57.824,78.623,91.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.512 | Acc: 57.901,78.588,91.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.524 | Acc: 57.806,78.456,91.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.527 | Acc: 57.741,78.379,91.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.536 | Acc: 57.787,78.334,91.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.547 | Acc: 57.680,78.283,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.553 | Acc: 57.776,78.222,90.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.557 | Acc: 57.762,78.187,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.563 | Acc: 57.810,78.134,90.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.564 | Acc: 57.792,78.133,90.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.645 | Acc: 54.688,71.094,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.172 | Acc: 50.781,65.662,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.223 | Acc: 50.076,65.739,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.207 | Acc: 50.538,65.471,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 2.353 | Acc: 55.469,85.156,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.378 | Acc: 59.412,80.618,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.377 | Acc: 59.432,80.793,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.384 | Acc: 59.439,80.405,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.411 | Acc: 59.153,80.015,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.423 | Acc: 58.841,79.726,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.425 | Acc: 58.723,79.713,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.446 | Acc: 58.488,79.555,92.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.459 | Acc: 58.380,79.445,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.467 | Acc: 58.451,79.368,91.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.485 | Acc: 58.267,79.073,91.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.495 | Acc: 58.166,78.980,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.494 | Acc: 58.127,78.971,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.505 | Acc: 58.085,78.852,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 57.929,78.737,91.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 57.934,78.623,91.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.531 | Acc: 57.810,78.522,91.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.537 | Acc: 57.799,78.455,90.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.545 | Acc: 57.704,78.361,90.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.553 | Acc: 57.665,78.254,90.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.145 | Acc: 46.094,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.184 | Acc: 49.926,65.699,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.204 | Acc: 49.790,65.473,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.229 | Acc: 49.629,65.574,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 2.017 | Acc: 66.406,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.385 | Acc: 59.412,79.911,92.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.433 | Acc: 58.213,79.306,92.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.446 | Acc: 57.979,79.342,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.450 | Acc: 58.044,79.302,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.438 | Acc: 57.998,79.247,92.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.450 | Acc: 57.974,79.093,92.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.458 | Acc: 57.846,79.222,92.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.457 | Acc: 58.050,79.227,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.460 | Acc: 58.054,79.200,92.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.461 | Acc: 58.147,79.217,91.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.472 | Acc: 58.254,79.034,91.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 58.001,78.871,91.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.502 | Acc: 57.920,78.763,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.516 | Acc: 57.812,78.556,91.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.522 | Acc: 57.787,78.538,91.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.529 | Acc: 57.710,78.490,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.534 | Acc: 57.716,78.505,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.541 | Acc: 57.748,78.385,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.550 | Acc: 57.614,78.303,90.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.969 | Acc: 51.562,66.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.158 | Acc: 52.381,64.062,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.215 | Acc: 52.325,63.872,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.206 | Acc: 52.382,64.075,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 2.281 | Acc: 59.375,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.451 | Acc: 57.589,79.092,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.475 | Acc: 58.003,79.211,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.429 | Acc: 58.799,79.611,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.431 | Acc: 58.459,79.620,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.437 | Acc: 58.532,79.726,91.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.440 | Acc: 58.484,79.707,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.453 | Acc: 58.372,79.627,91.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.457 | Acc: 58.210,79.489,91.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.464 | Acc: 58.201,79.416,91.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.469 | Acc: 58.061,79.357,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.480 | Acc: 58.007,79.277,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 57.848,79.110,91.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.496 | Acc: 57.786,79.119,91.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.499 | Acc: 57.687,79.020,91.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.508 | Acc: 57.628,78.930,91.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.514 | Acc: 57.618,78.819,91.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.514 | Acc: 57.689,78.799,91.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.515 | Acc: 57.774,78.768,91.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.524 | Acc: 57.786,78.670,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.977 | Acc: 54.688,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.227 | Acc: 50.744,66.220,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 50.381,65.358,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.312 | Acc: 49.910,65.394,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 2.237 | Acc: 60.156,85.156,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.424 | Acc: 58.929,79.539,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.432 | Acc: 57.851,79.649,92.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.385 | Acc: 58.773,80.494,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.386 | Acc: 58.951,80.363,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.388 | Acc: 58.748,80.221,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.397 | Acc: 58.671,80.004,92.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.402 | Acc: 58.843,79.843,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.417 | Acc: 58.545,79.654,92.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.420 | Acc: 58.689,79.627,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.441 | Acc: 58.462,79.404,92.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.453 | Acc: 58.261,79.383,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.464 | Acc: 58.195,79.273,91.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.471 | Acc: 58.202,79.274,91.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.480 | Acc: 58.307,79.190,91.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.489 | Acc: 58.275,79.127,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 58.234,79.074,91.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 58.225,79.037,91.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.509 | Acc: 58.183,78.997,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.517 | Acc: 58.177,78.849,91.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.941 | Acc: 50.000,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.212 | Acc: 52.493,64.397,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.290 | Acc: 52.077,63.777,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.318 | Acc: 51.985,63.601,69.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 2.510 | Acc: 60.938,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.455 | Acc: 57.180,79.836,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.420 | Acc: 58.079,80.412,92.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.390 | Acc: 58.478,80.648,92.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.365 | Acc: 58.864,80.816,92.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.368 | Acc: 58.795,80.925,92.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.387 | Acc: 58.697,80.682,92.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.396 | Acc: 58.594,80.397,92.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.406 | Acc: 58.579,80.119,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.410 | Acc: 58.602,80.041,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.409 | Acc: 58.718,80.022,92.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.419 | Acc: 58.771,79.917,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.427 | Acc: 58.642,79.798,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.431 | Acc: 58.713,79.843,91.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.439 | Acc: 58.683,79.765,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.454 | Acc: 58.589,79.555,91.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.462 | Acc: 58.574,79.454,91.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.469 | Acc: 58.546,79.378,91.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.478 | Acc: 58.479,79.227,91.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 58.465,79.154,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.924 | Acc: 54.688,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.862 | Acc: 54.018,67.969,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.962 | Acc: 52.877,67.054,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.976 | Acc: 52.843,66.931,70.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 2.145 | Acc: 63.281,85.156,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.347 | Acc: 60.900,80.729,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.315 | Acc: 61.128,80.926,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.319 | Acc: 60.297,80.802,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.339 | Acc: 59.578,80.633,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.347 | Acc: 59.599,80.616,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.360 | Acc: 59.595,80.456,92.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.355 | Acc: 59.652,80.524,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.378 | Acc: 59.259,80.105,92.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.386 | Acc: 59.427,80.063,92.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.388 | Acc: 59.433,79.921,92.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.405 | Acc: 59.223,79.822,91.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.415 | Acc: 59.054,79.629,91.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.417 | Acc: 59.028,79.628,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.427 | Acc: 58.894,79.548,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.433 | Acc: 58.794,79.560,91.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.441 | Acc: 58.776,79.468,91.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.442 | Acc: 58.743,79.502,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.446 | Acc: 58.741,79.404,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.459 | Acc: 58.682,79.234,91.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.048 | Acc: 44.531,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.383 | Acc: 47.991,63.430,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.392 | Acc: 48.457,63.415,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 48.578,63.397,69.813,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 2.183 | Acc: 57.031,82.812,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.419 | Acc: 58.482,80.208,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.379 | Acc: 59.223,81.021,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.359 | Acc: 59.721,81.173,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.349 | Acc: 59.819,81.163,92.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.378 | Acc: 59.282,80.716,92.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.381 | Acc: 59.233,80.598,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.392 | Acc: 59.214,80.458,91.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.410 | Acc: 58.958,80.182,91.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.427 | Acc: 58.810,79.972,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.433 | Acc: 58.784,79.932,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.433 | Acc: 58.862,79.843,91.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.445 | Acc: 58.723,79.675,91.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.447 | Acc: 58.684,79.679,91.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.447 | Acc: 58.738,79.746,91.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.451 | Acc: 58.633,79.726,91.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.461 | Acc: 58.523,79.568,91.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.462 | Acc: 58.644,79.552,91.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.467 | Acc: 58.641,79.473,91.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.470 | Acc: 58.676,79.413,91.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.894 | Acc: 51.562,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.284 | Acc: 50.372,64.807,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.276 | Acc: 50.400,64.710,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 50.474,64.344,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 2.514 | Acc: 55.469,80.469,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.415 | Acc: 58.631,80.841,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.395 | Acc: 58.956,81.117,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.410 | Acc: 58.081,80.789,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.387 | Acc: 58.497,80.883,92.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.366 | Acc: 58.795,81.026,92.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.367 | Acc: 58.942,80.959,92.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.382 | Acc: 58.860,80.823,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.392 | Acc: 58.822,80.600,92.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.388 | Acc: 58.892,80.555,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.390 | Acc: 58.905,80.550,92.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.401 | Acc: 58.668,80.395,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.411 | Acc: 58.642,80.196,92.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.413 | Acc: 58.648,80.205,92.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.416 | Acc: 58.658,80.157,92.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.426 | Acc: 58.617,80.087,92.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.437 | Acc: 58.579,79.907,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.445 | Acc: 58.569,79.793,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.451 | Acc: 58.518,79.729,91.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.454 | Acc: 58.586,79.665,91.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.418 | Acc: 50.781,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.495 | Acc: 49.628,63.988,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.555 | Acc: 48.647,63.624,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.563 | Acc: 47.989,63.397,69.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 2.271 | Acc: 63.281,83.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.321 | Acc: 60.565,81.138,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.305 | Acc: 60.366,81.517,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.326 | Acc: 59.734,81.263,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.336 | Acc: 59.597,81.019,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.341 | Acc: 59.360,80.840,92.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.348 | Acc: 59.317,80.772,92.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.354 | Acc: 59.214,80.624,92.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.369 | Acc: 58.977,80.444,92.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.389 | Acc: 58.883,80.167,92.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.398 | Acc: 58.773,80.065,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.405 | Acc: 58.735,79.896,92.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.412 | Acc: 58.756,79.876,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.413 | Acc: 58.881,79.891,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.422 | Acc: 58.964,79.810,92.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.430 | Acc: 58.900,79.669,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.432 | Acc: 58.976,79.673,91.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.440 | Acc: 58.786,79.580,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.448 | Acc: 58.698,79.447,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.458 | Acc: 58.639,79.337,91.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.597 | Acc: 53.125,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.296 | Acc: 50.335,64.881,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.283 | Acc: 50.381,64.996,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.269 | Acc: 50.359,65.292,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 2.143 | Acc: 59.375,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.227 | Acc: 60.938,83.147,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.235 | Acc: 61.109,82.146,93.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.250 | Acc: 60.899,81.814,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.271 | Acc: 60.610,81.665,92.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.272 | Acc: 60.543,81.660,93.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.289 | Acc: 60.434,81.353,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.317 | Acc: 60.106,80.973,92.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.341 | Acc: 59.807,80.740,92.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.354 | Acc: 59.660,80.659,92.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.376 | Acc: 59.321,80.364,92.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.393 | Acc: 59.205,80.189,92.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.395 | Acc: 59.219,80.089,92.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.411 | Acc: 59.159,79.885,92.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.419 | Acc: 59.089,79.801,91.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.432 | Acc: 58.957,79.630,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.440 | Acc: 58.879,79.568,91.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.446 | Acc: 58.827,79.557,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.449 | Acc: 58.879,79.471,91.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.449 | Acc: 58.942,79.425,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.073 | Acc: 48.438,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.191 | Acc: 50.595,66.964,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.208 | Acc: 50.419,66.616,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.187 | Acc: 50.410,66.855,71.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 2.259 | Acc: 61.719,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.352 | Acc: 60.231,80.618,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.290 | Acc: 60.232,81.307,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.292 | Acc: 60.054,81.301,93.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.303 | Acc: 60.050,80.980,93.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.316 | Acc: 59.916,80.801,93.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.324 | Acc: 59.666,80.733,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.327 | Acc: 59.530,80.674,93.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.338 | Acc: 59.341,80.580,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.341 | Acc: 59.474,80.616,92.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.347 | Acc: 59.441,80.512,92.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.340 | Acc: 59.679,80.575,92.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.350 | Acc: 59.602,80.482,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.358 | Acc: 59.528,80.454,92.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.361 | Acc: 59.536,80.374,92.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.367 | Acc: 59.505,80.308,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.374 | Acc: 59.412,80.240,92.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.387 | Acc: 59.309,80.068,92.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.396 | Acc: 59.327,79.988,91.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.406 | Acc: 59.285,79.884,91.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.071 | Acc: 53.906,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.199 | Acc: 51.116,66.369,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.255 | Acc: 50.553,65.873,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.274 | Acc: 50.423,65.574,69.032,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 2.358 | Acc: 63.281,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.414 | Acc: 58.929,80.655,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.399 | Acc: 58.918,80.850,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.339 | Acc: 59.349,81.532,92.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.319 | Acc: 59.770,81.346,92.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.319 | Acc: 59.646,81.188,92.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.321 | Acc: 59.685,81.101,92.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.342 | Acc: 59.547,80.879,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.354 | Acc: 59.525,80.595,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.357 | Acc: 59.569,80.529,92.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.357 | Acc: 59.554,80.500,92.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.355 | Acc: 59.633,80.402,92.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.360 | Acc: 59.634,80.346,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.371 | Acc: 59.408,80.142,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.375 | Acc: 59.403,80.157,91.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.385 | Acc: 59.346,80.100,91.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.397 | Acc: 59.280,79.955,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.398 | Acc: 59.327,79.928,91.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.404 | Acc: 59.338,79.852,91.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.408 | Acc: 59.334,79.788,91.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.225 | Acc: 50.781,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.262 | Acc: 49.888,65.774,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.270 | Acc: 50.210,65.758,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.270 | Acc: 49.949,66.137,71.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 2.218 | Acc: 64.062,81.250,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.326 | Acc: 59.524,80.915,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.322 | Acc: 59.813,80.850,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.301 | Acc: 60.233,81.276,93.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.281 | Acc: 60.426,81.404,93.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.280 | Acc: 60.412,81.366,93.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.278 | Acc: 60.337,81.560,93.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.291 | Acc: 60.278,81.461,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.309 | Acc: 60.219,81.148,92.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.315 | Acc: 60.186,80.978,92.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.322 | Acc: 60.040,80.935,92.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.331 | Acc: 60.029,80.935,92.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.329 | Acc: 60.072,80.978,92.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.335 | Acc: 59.923,80.879,92.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.336 | Acc: 59.920,80.719,92.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.347 | Acc: 59.827,80.622,92.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.357 | Acc: 59.740,80.478,92.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.364 | Acc: 59.742,80.361,92.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.373 | Acc: 59.613,80.220,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.374 | Acc: 59.601,80.217,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.109 | Acc: 48.438,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.358 | Acc: 48.735,64.844,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.396 | Acc: 48.495,64.310,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.366 | Acc: 48.630,64.408,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 2.252 | Acc: 57.031,84.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.348 | Acc: 58.705,81.510,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.343 | Acc: 59.051,80.983,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.308 | Acc: 59.580,81.301,93.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.314 | Acc: 59.578,81.154,93.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.317 | Acc: 59.390,81.080,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.318 | Acc: 59.375,81.056,93.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.317 | Acc: 59.336,80.929,93.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.325 | Acc: 59.322,80.838,92.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.333 | Acc: 59.349,80.767,92.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.334 | Acc: 59.359,80.675,92.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.336 | Acc: 59.315,80.614,93.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.338 | Acc: 59.437,80.547,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.336 | Acc: 59.510,80.532,92.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.343 | Acc: 59.450,80.413,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.349 | Acc: 59.497,80.381,92.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.353 | Acc: 59.504,80.330,92.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.366 | Acc: 59.370,80.205,92.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.372 | Acc: 59.330,80.047,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.382 | Acc: 59.279,79.940,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.305 | Acc: 51.562,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.274 | Acc: 50.149,65.476,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.282 | Acc: 49.676,65.625,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.310 | Acc: 49.232,65.599,70.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 2.344 | Acc: 60.156,74.219,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.361 | Acc: 59.747,80.134,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.350 | Acc: 58.880,80.469,93.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.332 | Acc: 59.439,80.456,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.307 | Acc: 59.761,80.652,93.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.311 | Acc: 59.545,80.654,93.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.311 | Acc: 59.749,80.624,93.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.317 | Acc: 59.763,80.568,93.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.320 | Acc: 59.720,80.619,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.323 | Acc: 59.738,80.581,92.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.327 | Acc: 59.775,80.570,92.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.327 | Acc: 59.817,80.642,92.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.333 | Acc: 59.787,80.543,92.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.336 | Acc: 59.893,80.508,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.341 | Acc: 59.817,80.480,92.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.341 | Acc: 59.816,80.448,92.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.346 | Acc: 59.813,80.371,92.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.351 | Acc: 59.762,80.272,92.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.354 | Acc: 59.717,80.278,92.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.356 | Acc: 59.742,80.217,92.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.926 | Acc: 46.094,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.701 | Acc: 43.899,64.211,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.705 | Acc: 43.655,64.520,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.717 | Acc: 43.737,64.370,69.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 2.004 | Acc: 65.625,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.295 | Acc: 59.970,81.696,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.268 | Acc: 59.451,81.764,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.276 | Acc: 59.721,81.634,93.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.289 | Acc: 59.713,81.742,93.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.270 | Acc: 60.125,81.822,93.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.282 | Acc: 60.201,81.605,93.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.294 | Acc: 60.178,81.588,93.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.297 | Acc: 60.020,81.439,93.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.302 | Acc: 59.971,81.405,93.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.299 | Acc: 60.102,81.405,93.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.304 | Acc: 60.018,81.391,92.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.313 | Acc: 59.968,81.315,92.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.329 | Acc: 59.809,80.963,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.343 | Acc: 59.664,80.802,92.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.350 | Acc: 59.684,80.733,92.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.351 | Acc: 59.733,80.683,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.359 | Acc: 59.684,80.574,92.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.364 | Acc: 59.678,80.438,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.367 | Acc: 59.652,80.385,92.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.222 | Acc: 52.344,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.292 | Acc: 50.967,63.914,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.352 | Acc: 50.781,63.491,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.326 | Acc: 51.422,63.717,69.493,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 2.564 | Acc: 52.344,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.258 | Acc: 61.458,81.510,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.240 | Acc: 60.480,82.050,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.260 | Acc: 60.784,81.673,92.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.276 | Acc: 60.378,81.433,92.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.279 | Acc: 60.249,81.428,92.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.272 | Acc: 60.156,81.489,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.269 | Acc: 60.123,81.533,92.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.271 | Acc: 60.263,81.522,92.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.280 | Acc: 60.338,81.379,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.288 | Acc: 60.351,81.172,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.294 | Acc: 60.287,81.109,92.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.298 | Acc: 60.292,81.085,92.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.304 | Acc: 60.267,81.040,92.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.308 | Acc: 60.259,80.980,92.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.315 | Acc: 60.182,80.837,92.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.321 | Acc: 60.178,80.795,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.327 | Acc: 60.154,80.723,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.334 | Acc: 60.115,80.635,92.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.342 | Acc: 60.099,80.557,92.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.964 | Acc: 57.812,67.188,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.279 | Acc: 51.749,64.397,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.291 | Acc: 51.162,64.177,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.295 | Acc: 50.858,63.704,70.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 1.966 | Acc: 63.281,85.938,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.279 | Acc: 60.007,80.580,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.259 | Acc: 60.709,81.269,93.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.239 | Acc: 61.130,81.416,93.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.207 | Acc: 61.786,81.973,93.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.212 | Acc: 61.866,81.822,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.240 | Acc: 61.596,81.482,93.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.240 | Acc: 61.492,81.444,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.250 | Acc: 61.326,81.449,93.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.254 | Acc: 61.196,81.474,93.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.256 | Acc: 61.163,81.468,93.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.271 | Acc: 60.927,81.250,92.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.292 | Acc: 60.636,81.033,92.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.310 | Acc: 60.560,80.807,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.323 | Acc: 60.343,80.686,92.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.332 | Acc: 60.208,80.630,92.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.334 | Acc: 60.246,80.627,92.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.339 | Acc: 60.250,80.494,92.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.342 | Acc: 60.245,80.395,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.351 | Acc: 60.197,80.266,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.520 | Acc: 46.875,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.464 | Acc: 47.433,63.951,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.499 | Acc: 47.618,64.272,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.459 | Acc: 47.900,64.511,70.197,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 2.167 | Acc: 61.719,84.375,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.290 | Acc: 61.570,81.734,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.281 | Acc: 60.938,82.088,92.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.278 | Acc: 60.566,81.698,93.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.274 | Acc: 60.841,81.694,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.281 | Acc: 60.597,81.629,93.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.280 | Acc: 60.608,81.631,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.277 | Acc: 60.838,81.483,93.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.267 | Acc: 60.821,81.527,93.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.275 | Acc: 60.687,81.444,93.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.283 | Acc: 60.646,81.347,93.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.290 | Acc: 60.545,81.179,93.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.298 | Acc: 60.493,81.055,92.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.302 | Acc: 60.497,80.975,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.313 | Acc: 60.426,80.825,92.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.318 | Acc: 60.374,80.778,92.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.324 | Acc: 60.341,80.727,92.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.332 | Acc: 60.314,80.618,92.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.339 | Acc: 60.260,80.514,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.343 | Acc: 60.339,80.444,92.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.314 | Acc: 59.375,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.537 | Acc: 48.586,63.579,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.475 | Acc: 48.418,64.120,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.494 | Acc: 47.976,63.845,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 2.350 | Acc: 60.156,78.125,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.248 | Acc: 60.007,82.403,93.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.234 | Acc: 60.938,81.974,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.228 | Acc: 60.348,82.492,94.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.192 | Acc: 60.889,82.677,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.205 | Acc: 60.930,82.387,93.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.216 | Acc: 60.931,82.173,93.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.225 | Acc: 60.777,81.998,93.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.243 | Acc: 60.627,81.735,93.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.261 | Acc: 60.497,81.578,93.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.262 | Acc: 60.650,81.530,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.265 | Acc: 60.626,81.469,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.267 | Acc: 60.694,81.464,93.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.271 | Acc: 60.695,81.361,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.275 | Acc: 60.682,81.286,93.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.285 | Acc: 60.556,81.214,93.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.295 | Acc: 60.475,81.104,92.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.299 | Acc: 60.472,81.055,92.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.309 | Acc: 60.342,80.964,92.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.312 | Acc: 60.372,80.891,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.413 | Acc: 49.219,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.150 | Acc: 51.488,65.774,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.239 | Acc: 51.258,65.454,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.229 | Acc: 51.473,65.471,70.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 2.525 | Acc: 61.719,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.278 | Acc: 60.714,82.031,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.261 | Acc: 60.499,82.203,93.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.242 | Acc: 60.822,82.364,93.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.251 | Acc: 60.436,82.051,93.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.238 | Acc: 60.589,82.225,93.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.244 | Acc: 60.783,82.102,93.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.231 | Acc: 61.070,82.186,93.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.223 | Acc: 61.243,82.235,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.229 | Acc: 61.222,82.053,93.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.238 | Acc: 61.112,82.008,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.253 | Acc: 61.036,81.862,93.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.259 | Acc: 60.976,81.701,93.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.269 | Acc: 60.767,81.633,93.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.274 | Acc: 60.718,81.525,93.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.281 | Acc: 60.699,81.455,93.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.289 | Acc: 60.645,81.313,92.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.295 | Acc: 60.610,81.184,92.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.299 | Acc: 60.576,81.103,92.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.304 | Acc: 60.552,81.041,92.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.160 | Acc: 45.312,61.719,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.039 | Acc: 52.679,66.927,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.096 | Acc: 52.325,66.635,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.089 | Acc: 52.164,66.752,71.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 2.242 | Acc: 62.500,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.191 | Acc: 61.049,82.217,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.235 | Acc: 61.166,81.955,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.245 | Acc: 61.027,81.621,93.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.236 | Acc: 61.034,81.694,93.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.225 | Acc: 60.938,81.776,93.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.223 | Acc: 61.118,81.870,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.236 | Acc: 60.810,81.704,93.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.239 | Acc: 60.899,81.735,93.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.244 | Acc: 60.782,81.634,93.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.248 | Acc: 60.720,81.542,93.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.252 | Acc: 60.658,81.529,93.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.262 | Acc: 60.529,81.389,93.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.276 | Acc: 60.420,81.268,92.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.288 | Acc: 60.398,81.067,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.297 | Acc: 60.343,80.996,92.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.309 | Acc: 60.271,80.851,92.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.312 | Acc: 60.257,80.847,92.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.316 | Acc: 60.262,80.761,92.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.321 | Acc: 60.193,80.717,92.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.908 | Acc: 53.906,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.228 | Acc: 51.302,64.658,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.267 | Acc: 51.067,64.729,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.249 | Acc: 51.294,64.664,71.273,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 2.051 | Acc: 57.031,87.500,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.127 | Acc: 62.314,82.589,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.135 | Acc: 61.776,83.308,94.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.143 | Acc: 61.783,83.107,94.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.162 | Acc: 61.275,83.044,94.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.161 | Acc: 61.317,83.168,93.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.177 | Acc: 61.176,82.903,93.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.172 | Acc: 61.447,82.873,93.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.174 | Acc: 61.496,82.745,93.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.183 | Acc: 61.447,82.605,93.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.193 | Acc: 61.458,82.424,93.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.192 | Acc: 61.517,82.452,93.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.197 | Acc: 61.547,82.368,93.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.206 | Acc: 61.461,82.247,93.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.222 | Acc: 61.279,82.048,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.233 | Acc: 61.130,81.837,93.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.246 | Acc: 61.001,81.683,93.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.258 | Acc: 60.894,81.601,92.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.267 | Acc: 60.732,81.549,92.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.277 | Acc: 60.665,81.367,92.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.366 | Acc: 47.656,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.334 | Acc: 51.711,66.220,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.271 | Acc: 51.029,65.644,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.249 | Acc: 51.050,65.676,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 2.191 | Acc: 62.500,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.213 | Acc: 60.863,82.031,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.179 | Acc: 61.471,82.431,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.175 | Acc: 61.104,82.505,93.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.188 | Acc: 60.880,82.321,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.202 | Acc: 60.984,81.962,93.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.213 | Acc: 60.712,81.786,93.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.221 | Acc: 60.577,81.721,93.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.228 | Acc: 60.617,81.478,93.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.228 | Acc: 60.696,81.574,93.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.244 | Acc: 60.557,81.293,93.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.248 | Acc: 60.598,81.257,93.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.254 | Acc: 60.552,81.289,93.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.256 | Acc: 60.509,81.298,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.258 | Acc: 60.512,81.289,93.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.264 | Acc: 60.582,81.273,92.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.275 | Acc: 60.465,81.153,92.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.288 | Acc: 60.344,81.046,92.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.295 | Acc: 60.243,80.997,92.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.296 | Acc: 60.339,80.979,92.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.984 | Acc: 57.812,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.953 | Acc: 54.167,66.927,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.005 | Acc: 54.097,66.673,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.048 | Acc: 53.753,66.650,70.850,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 2.318 | Acc: 51.562,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.213 | Acc: 61.235,82.403,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.233 | Acc: 60.671,82.755,93.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.220 | Acc: 60.771,82.748,93.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.223 | Acc: 60.561,82.465,93.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.219 | Acc: 60.582,82.403,93.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.229 | Acc: 60.531,82.238,93.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.239 | Acc: 60.594,82.059,93.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.251 | Acc: 60.530,81.813,93.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.245 | Acc: 60.704,81.768,93.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.240 | Acc: 60.693,81.821,93.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.252 | Acc: 60.538,81.685,93.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.258 | Acc: 60.597,81.607,93.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.261 | Acc: 60.620,81.537,92.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.270 | Acc: 60.429,81.478,92.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.271 | Acc: 60.463,81.437,92.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.273 | Acc: 60.568,81.372,92.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.276 | Acc: 60.555,81.273,92.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.278 | Acc: 60.654,81.233,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.288 | Acc: 60.601,81.135,92.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.908 | Acc: 48.438,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.301 | Acc: 48.921,66.109,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.263 | Acc: 49.486,65.644,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.314 | Acc: 48.975,65.356,69.864,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 2.286 | Acc: 61.719,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.110 | Acc: 62.872,83.259,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.117 | Acc: 62.767,83.346,94.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.145 | Acc: 61.872,82.710,94.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.153 | Acc: 61.545,82.581,93.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.155 | Acc: 61.363,82.565,93.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.176 | Acc: 61.357,82.380,93.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.186 | Acc: 61.287,82.242,93.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.196 | Acc: 61.350,81.958,93.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.201 | Acc: 61.369,81.932,93.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.217 | Acc: 61.175,81.701,93.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.225 | Acc: 61.164,81.621,93.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.234 | Acc: 61.074,81.529,93.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.240 | Acc: 61.018,81.540,93.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.244 | Acc: 61.024,81.525,93.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.256 | Acc: 60.909,81.341,92.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.264 | Acc: 60.791,81.265,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.270 | Acc: 60.695,81.209,92.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.276 | Acc: 60.710,81.118,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.285 | Acc: 60.624,81.010,92.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.014 | Acc: 53.906,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.214 | Acc: 51.451,66.406,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.266 | Acc: 51.086,65.434,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.267 | Acc: 50.845,65.087,69.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 2.332 | Acc: 60.938,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.189 | Acc: 62.835,82.031,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.163 | Acc: 62.481,82.603,94.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.161 | Acc: 62.090,82.223,94.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.165 | Acc: 62.336,82.369,93.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.171 | Acc: 62.345,82.387,93.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.185 | Acc: 62.003,82.309,93.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.192 | Acc: 61.896,82.181,93.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.190 | Acc: 61.884,82.099,93.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.192 | Acc: 62.004,82.109,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.203 | Acc: 61.820,82.070,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.207 | Acc: 61.832,81.992,93.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.213 | Acc: 61.826,81.979,93.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.217 | Acc: 61.758,81.920,93.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.224 | Acc: 61.655,81.845,93.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.228 | Acc: 61.542,81.818,93.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.235 | Acc: 61.519,81.749,93.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.243 | Acc: 61.469,81.665,92.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.251 | Acc: 61.297,81.527,92.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.263 | Acc: 61.214,81.377,92.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.975 | Acc: 51.562,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.175 | Acc: 51.823,65.327,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.230 | Acc: 52.344,65.168,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.224 | Acc: 52.113,65.100,70.569,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 2.239 | Acc: 63.281,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.174 | Acc: 60.640,82.589,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.161 | Acc: 60.804,82.660,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.150 | Acc: 61.488,82.902,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.157 | Acc: 61.236,82.735,93.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.168 | Acc: 61.216,82.673,93.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.171 | Acc: 61.086,82.780,93.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.182 | Acc: 61.004,82.574,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.191 | Acc: 60.850,82.313,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.206 | Acc: 60.769,82.087,93.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.220 | Acc: 60.805,81.957,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.230 | Acc: 60.888,81.823,93.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.232 | Acc: 60.963,81.801,93.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.229 | Acc: 61.048,81.840,93.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.229 | Acc: 61.085,81.856,93.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.236 | Acc: 61.036,81.787,92.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.248 | Acc: 60.911,81.596,92.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.255 | Acc: 60.947,81.470,92.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.264 | Acc: 60.862,81.343,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.276 | Acc: 60.796,81.193,92.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.393 | Acc: 44.531,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.520 | Acc: 46.354,66.778,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.602 | Acc: 46.208,66.311,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.652 | Acc: 45.671,66.086,70.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 2.189 | Acc: 61.719,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.156 | Acc: 63.170,82.924,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.203 | Acc: 62.519,82.660,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.200 | Acc: 61.924,82.633,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.188 | Acc: 61.613,82.600,93.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.197 | Acc: 61.448,82.418,93.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.201 | Acc: 61.247,82.503,93.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.203 | Acc: 61.226,82.347,93.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.215 | Acc: 61.073,82.225,93.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.215 | Acc: 61.054,82.282,93.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.214 | Acc: 61.097,82.311,93.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.213 | Acc: 61.072,82.254,93.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.216 | Acc: 60.970,82.200,93.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.223 | Acc: 60.869,82.118,93.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.234 | Acc: 60.773,82.015,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.242 | Acc: 60.779,81.857,93.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.258 | Acc: 60.675,81.620,93.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.263 | Acc: 60.667,81.539,93.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.271 | Acc: 60.557,81.432,92.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.278 | Acc: 60.587,81.334,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.970 | Acc: 55.469,64.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.172 | Acc: 52.641,64.546,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.158 | Acc: 52.896,64.787,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.196 | Acc: 52.869,64.549,69.352,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 2.335 | Acc: 60.156,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.188 | Acc: 61.458,82.626,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.189 | Acc: 61.242,83.003,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.219 | Acc: 60.643,82.467,93.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.205 | Acc: 61.208,82.388,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.196 | Acc: 61.417,82.457,93.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.175 | Acc: 61.783,82.767,93.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.174 | Acc: 61.835,82.707,93.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.172 | Acc: 61.913,82.725,93.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.170 | Acc: 61.926,82.730,93.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.177 | Acc: 61.758,82.696,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.189 | Acc: 61.652,82.533,93.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.207 | Acc: 61.421,82.268,93.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.212 | Acc: 61.384,82.127,93.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.225 | Acc: 61.338,81.931,93.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.230 | Acc: 61.241,81.891,93.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.243 | Acc: 61.137,81.683,92.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.260 | Acc: 60.944,81.484,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.264 | Acc: 60.914,81.445,92.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.270 | Acc: 60.938,81.355,92.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.575 | Acc: 58.594,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.990 | Acc: 55.580,66.927,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.997 | Acc: 55.812,66.406,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.008 | Acc: 55.405,66.406,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 2.404 | Acc: 61.719,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.127 | Acc: 62.612,83.185,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.134 | Acc: 62.557,83.117,93.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.165 | Acc: 61.693,82.582,93.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.159 | Acc: 61.834,82.668,93.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.157 | Acc: 61.943,82.890,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.172 | Acc: 61.919,82.690,93.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.180 | Acc: 61.830,82.558,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.181 | Acc: 61.753,82.618,93.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.184 | Acc: 61.559,82.640,93.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.188 | Acc: 61.548,82.653,93.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.192 | Acc: 61.521,82.625,93.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.194 | Acc: 61.589,82.550,93.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.198 | Acc: 61.569,82.378,93.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.201 | Acc: 61.641,82.315,93.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.210 | Acc: 61.558,82.182,93.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.215 | Acc: 61.556,82.070,93.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.220 | Acc: 61.545,82.013,92.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.229 | Acc: 61.500,81.927,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.237 | Acc: 61.364,81.744,92.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.499 | Acc: 46.094,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.490 | Acc: 48.065,64.769,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.442 | Acc: 47.790,64.748,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.480 | Acc: 47.784,64.908,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 1.994 | Acc: 66.406,89.062,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.260 | Acc: 60.007,82.292,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.209 | Acc: 60.861,82.832,93.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.177 | Acc: 61.117,83.056,93.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.176 | Acc: 61.584,82.697,93.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.179 | Acc: 61.819,82.712,93.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.179 | Acc: 61.887,82.606,93.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.193 | Acc: 61.525,82.308,93.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.189 | Acc: 61.437,82.497,93.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.190 | Acc: 61.468,82.549,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.192 | Acc: 61.583,82.502,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.198 | Acc: 61.503,82.410,93.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.204 | Acc: 61.560,82.323,93.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.210 | Acc: 61.560,82.112,93.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.210 | Acc: 61.532,82.037,93.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.215 | Acc: 61.506,81.961,93.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.217 | Acc: 61.507,81.931,93.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.226 | Acc: 61.391,81.841,93.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.234 | Acc: 61.357,81.750,92.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.239 | Acc: 61.337,81.707,92.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.016 | Acc: 54.688,66.406,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.069 | Acc: 51.488,66.704,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.123 | Acc: 50.972,66.178,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.124 | Acc: 51.306,66.534,70.786,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 2.227 | Acc: 60.938,86.719,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.100 | Acc: 62.760,83.519,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.135 | Acc: 62.348,83.537,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.104 | Acc: 62.807,84.311,94.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.103 | Acc: 62.461,84.124,94.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.119 | Acc: 61.904,83.756,94.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.116 | Acc: 61.945,83.536,94.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.117 | Acc: 61.863,83.311,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.122 | Acc: 61.850,83.162,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.125 | Acc: 61.926,83.011,94.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.126 | Acc: 61.847,83.038,94.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.134 | Acc: 61.821,82.979,94.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.144 | Acc: 61.777,82.825,93.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.152 | Acc: 61.740,82.729,93.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.160 | Acc: 61.633,82.626,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.167 | Acc: 61.612,82.519,93.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.172 | Acc: 61.690,82.426,93.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.181 | Acc: 61.613,82.272,93.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.188 | Acc: 61.502,82.198,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.196 | Acc: 61.387,82.093,93.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.943 | Acc: 53.125,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.396 | Acc: 48.624,64.360,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.466 | Acc: 47.980,64.101,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.494 | Acc: 47.592,64.178,70.108,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 2.121 | Acc: 63.281,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.273 | Acc: 61.719,82.180,93.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.241 | Acc: 61.280,82.317,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.212 | Acc: 61.335,82.748,93.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.190 | Acc: 61.873,82.784,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.193 | Acc: 61.935,82.240,93.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.181 | Acc: 62.067,82.438,93.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.182 | Acc: 61.935,82.375,94.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.177 | Acc: 61.923,82.531,93.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.188 | Acc: 61.788,82.446,93.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.192 | Acc: 61.886,82.334,93.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.196 | Acc: 61.740,82.314,93.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.200 | Acc: 61.709,82.245,93.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.207 | Acc: 61.611,82.139,93.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.205 | Acc: 61.633,82.134,93.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.207 | Acc: 61.675,82.034,93.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.213 | Acc: 61.587,81.975,93.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.219 | Acc: 61.519,81.910,93.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.225 | Acc: 61.515,81.791,93.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.231 | Acc: 61.544,81.693,93.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.768 | Acc: 57.812,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.993 | Acc: 54.725,66.034,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.979 | Acc: 54.916,66.197,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.981 | Acc: 54.854,66.265,71.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 2.152 | Acc: 71.875,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.989 | Acc: 65.216,85.268,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.041 | Acc: 63.758,84.870,94.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.061 | Acc: 63.755,84.285,94.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.076 | Acc: 63.069,83.960,94.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.097 | Acc: 62.655,83.578,93.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.116 | Acc: 62.364,83.381,93.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.130 | Acc: 62.323,83.162,93.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.133 | Acc: 62.466,83.079,93.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.148 | Acc: 62.276,82.925,93.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.154 | Acc: 62.162,82.902,93.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.161 | Acc: 62.037,82.812,93.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.171 | Acc: 61.842,82.637,93.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.179 | Acc: 61.767,82.507,93.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.190 | Acc: 61.697,82.370,93.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.199 | Acc: 61.610,82.257,93.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.207 | Acc: 61.517,82.172,93.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.217 | Acc: 61.453,82.043,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.225 | Acc: 61.407,81.949,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.235 | Acc: 61.315,81.836,92.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.281 | Acc: 53.906,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.345 | Acc: 50.967,65.737,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.312 | Acc: 51.086,65.587,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.296 | Acc: 51.063,65.715,70.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 2.398 | Acc: 53.125,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.229 | Acc: 61.421,81.957,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.192 | Acc: 61.395,82.165,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.163 | Acc: 61.911,82.838,93.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.160 | Acc: 62.124,82.841,93.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.158 | Acc: 62.144,82.867,93.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.177 | Acc: 61.951,82.741,93.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.179 | Acc: 61.835,82.685,93.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.178 | Acc: 61.937,82.662,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.180 | Acc: 62.008,82.610,93.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.191 | Acc: 61.855,82.478,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.197 | Acc: 61.758,82.346,93.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.201 | Acc: 61.667,82.242,93.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.205 | Acc: 61.713,82.148,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.208 | Acc: 61.716,82.081,93.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.214 | Acc: 61.675,81.972,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.217 | Acc: 61.731,81.910,93.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.222 | Acc: 61.650,81.857,93.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.228 | Acc: 61.585,81.813,92.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.234 | Acc: 61.585,81.746,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.418 | Acc: 50.000,64.844,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.483 | Acc: 48.624,64.546,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.461 | Acc: 49.181,64.558,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.441 | Acc: 49.360,65.087,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 2.260 | Acc: 57.031,79.688,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.181 | Acc: 62.500,80.990,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.103 | Acc: 62.957,82.698,93.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.096 | Acc: 62.462,83.210,93.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.100 | Acc: 61.902,83.343,93.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.097 | Acc: 62.268,83.532,94.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.101 | Acc: 62.222,83.497,93.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.107 | Acc: 62.251,83.355,93.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.116 | Acc: 62.175,83.220,93.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.125 | Acc: 62.055,83.132,93.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.132 | Acc: 61.999,83.057,93.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.144 | Acc: 62.012,82.866,93.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.156 | Acc: 61.894,82.712,93.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.164 | Acc: 61.841,82.621,93.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.169 | Acc: 61.822,82.582,93.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.174 | Acc: 61.828,82.480,93.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.188 | Acc: 61.638,82.362,93.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.197 | Acc: 61.538,82.203,93.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.208 | Acc: 61.442,82.139,93.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.216 | Acc: 61.444,81.998,92.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.872 | Acc: 53.125,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.199 | Acc: 50.149,65.327,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.212 | Acc: 50.553,65.034,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.249 | Acc: 50.704,64.882,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 1.911 | Acc: 68.750,85.938,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.114 | Acc: 62.649,82.850,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.074 | Acc: 63.357,83.460,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.084 | Acc: 62.974,83.427,94.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.113 | Acc: 62.249,83.150,94.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.106 | Acc: 62.330,83.277,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.109 | Acc: 62.339,83.277,94.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.113 | Acc: 62.323,83.101,94.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.121 | Acc: 62.092,82.939,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.120 | Acc: 62.094,83.011,94.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.128 | Acc: 62.049,82.863,94.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.137 | Acc: 62.065,82.795,94.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.149 | Acc: 62.056,82.715,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.161 | Acc: 62.057,82.468,93.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.171 | Acc: 61.919,82.418,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.179 | Acc: 61.926,82.301,93.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.188 | Acc: 61.935,82.221,93.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.196 | Acc: 61.863,82.084,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.204 | Acc: 61.751,81.992,93.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.214 | Acc: 61.633,81.849,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.181 | Acc: 53.125,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.178 | Acc: 52.232,67.522,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.177 | Acc: 51.334,67.359,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.209 | Acc: 50.576,66.867,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 2.017 | Acc: 66.406,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.058 | Acc: 63.393,84.635,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.096 | Acc: 62.786,83.956,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.109 | Acc: 63.025,83.453,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.136 | Acc: 62.384,83.304,93.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.125 | Acc: 62.430,83.377,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.120 | Acc: 62.519,83.529,93.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.133 | Acc: 62.373,83.311,93.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.124 | Acc: 62.384,83.409,93.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.121 | Acc: 62.487,83.408,93.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.124 | Acc: 62.516,83.294,93.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.131 | Acc: 62.493,83.159,93.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.141 | Acc: 62.260,82.932,93.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.151 | Acc: 62.123,82.821,93.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.159 | Acc: 62.005,82.665,93.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.164 | Acc: 61.880,82.556,93.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.174 | Acc: 61.882,82.455,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.179 | Acc: 61.831,82.393,93.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.186 | Acc: 61.870,82.306,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.187 | Acc: 61.856,82.257,93.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.506 | Acc: 50.781,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.301 | Acc: 51.414,64.286,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.326 | Acc: 50.934,63.929,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.345 | Acc: 50.884,64.203,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 1.983 | Acc: 65.625,84.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.108 | Acc: 63.170,82.403,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.093 | Acc: 63.262,82.489,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.099 | Acc: 62.679,82.761,93.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.104 | Acc: 62.481,82.957,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.101 | Acc: 62.260,82.990,93.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.104 | Acc: 62.377,83.071,93.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.109 | Acc: 62.422,83.029,93.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.104 | Acc: 62.621,82.953,93.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.115 | Acc: 62.517,82.912,93.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.122 | Acc: 62.523,82.867,93.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.127 | Acc: 62.394,82.848,93.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.130 | Acc: 62.422,82.809,93.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.137 | Acc: 62.359,82.681,93.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.143 | Acc: 62.317,82.590,93.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.150 | Acc: 62.287,82.498,93.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.156 | Acc: 62.215,82.445,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.169 | Acc: 62.127,82.297,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.178 | Acc: 62.030,82.202,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.185 | Acc: 62.030,82.152,93.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.505 | Acc: 60.156,71.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.848 | Acc: 56.622,68.378,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.838 | Acc: 56.021,68.216,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.860 | Acc: 55.776,67.994,70.927,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 2.352 | Acc: 61.719,84.375,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.063 | Acc: 63.281,84.710,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.039 | Acc: 63.529,84.470,94.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.049 | Acc: 63.128,84.196,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.038 | Acc: 63.108,84.230,94.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.056 | Acc: 62.631,84.011,94.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.065 | Acc: 62.390,83.897,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.071 | Acc: 62.395,83.705,94.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.071 | Acc: 62.490,83.647,94.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.080 | Acc: 62.500,83.507,94.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.083 | Acc: 62.391,83.442,94.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.092 | Acc: 62.383,83.406,94.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.095 | Acc: 62.383,83.289,94.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.110 | Acc: 62.276,83.121,93.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.127 | Acc: 62.075,82.960,93.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.134 | Acc: 62.103,82.906,93.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.148 | Acc: 61.962,82.664,93.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.161 | Acc: 61.804,82.512,93.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.172 | Acc: 61.693,82.343,93.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.178 | Acc: 61.678,82.283,93.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.345 | Acc: 50.781,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.481 | Acc: 51.004,63.244,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.445 | Acc: 51.067,63.567,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.452 | Acc: 50.973,63.435,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 2.767 | Acc: 57.812,79.688,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.231 | Acc: 61.347,82.143,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.184 | Acc: 61.052,82.412,93.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.143 | Acc: 61.450,82.864,93.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.126 | Acc: 61.439,83.169,94.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.118 | Acc: 61.580,83.199,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.126 | Acc: 61.667,83.122,94.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.136 | Acc: 61.669,82.918,93.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.141 | Acc: 61.889,82.871,93.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.141 | Acc: 62.155,82.873,93.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.149 | Acc: 62.115,82.746,93.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.153 | Acc: 61.980,82.657,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.158 | Acc: 62.020,82.621,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.163 | Acc: 61.967,82.558,93.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.163 | Acc: 61.969,82.509,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.167 | Acc: 61.947,82.402,93.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.173 | Acc: 61.870,82.316,93.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.183 | Acc: 61.776,82.162,93.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.191 | Acc: 61.740,82.053,93.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.197 | Acc: 61.700,81.972,93.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.884 | Acc: 53.125,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.067 | Acc: 51.897,65.476,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.080 | Acc: 51.810,65.663,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.093 | Acc: 51.819,66.086,71.235,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 2.367 | Acc: 59.375,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.154 | Acc: 61.384,82.403,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.103 | Acc: 62.957,83.346,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.086 | Acc: 63.204,83.427,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.075 | Acc: 63.050,83.410,94.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.069 | Acc: 63.026,83.447,94.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.073 | Acc: 63.049,83.419,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.099 | Acc: 62.771,83.178,94.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.118 | Acc: 62.510,82.977,94.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.123 | Acc: 62.565,82.998,93.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.128 | Acc: 62.449,82.952,93.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.140 | Acc: 62.217,82.876,93.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.148 | Acc: 62.137,82.748,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.155 | Acc: 62.153,82.699,93.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.159 | Acc: 62.108,82.648,93.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.170 | Acc: 61.983,82.517,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.174 | Acc: 62.047,82.511,93.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.176 | Acc: 62.152,82.464,93.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.187 | Acc: 62.026,82.295,93.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.192 | Acc: 61.989,82.259,93.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.688 | Acc: 53.906,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.235 | Acc: 53.534,65.030,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.231 | Acc: 52.992,65.206,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.239 | Acc: 52.959,65.292,69.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 2.087 | Acc: 64.062,82.031,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.005 | Acc: 62.463,85.045,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.043 | Acc: 62.443,84.108,94.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.078 | Acc: 62.641,84.144,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.088 | Acc: 62.365,83.873,93.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.085 | Acc: 62.392,83.818,94.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.084 | Acc: 62.345,83.781,94.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.088 | Acc: 62.445,83.710,94.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.091 | Acc: 62.413,83.579,94.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.092 | Acc: 62.560,83.598,94.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.100 | Acc: 62.376,83.427,93.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.104 | Acc: 62.334,83.336,94.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.107 | Acc: 62.383,83.218,94.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.111 | Acc: 62.443,83.178,94.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.117 | Acc: 62.339,83.129,93.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.118 | Acc: 62.373,83.090,93.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.125 | Acc: 62.339,82.961,93.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.136 | Acc: 62.266,82.835,93.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.149 | Acc: 62.214,82.648,93.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.160 | Acc: 62.102,82.550,93.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.117 | Acc: 53.125,63.281,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.324 | Acc: 52.121,64.807,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 51.905,64.882,70.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.347 | Acc: 51.870,64.741,69.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 2.329 | Acc: 57.031,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.179 | Acc: 62.872,82.701,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.138 | Acc: 62.919,82.870,93.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.137 | Acc: 62.718,82.774,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.133 | Acc: 62.741,82.938,93.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.128 | Acc: 62.469,83.037,94.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.120 | Acc: 62.636,83.284,94.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.125 | Acc: 62.622,83.217,93.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.122 | Acc: 62.743,83.235,93.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.126 | Acc: 62.595,83.080,93.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.127 | Acc: 62.698,83.057,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.131 | Acc: 62.599,82.947,93.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.135 | Acc: 62.575,82.955,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.140 | Acc: 62.473,82.872,93.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.146 | Acc: 62.397,82.721,93.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.147 | Acc: 62.368,82.670,93.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.156 | Acc: 62.230,82.603,93.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.158 | Acc: 62.168,82.599,93.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.168 | Acc: 62.067,82.486,93.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.174 | Acc: 62.047,82.456,93.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.141 | Acc: 50.000,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.054 | Acc: 52.567,66.369,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.122 | Acc: 52.115,65.911,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.177 | Acc: 52.075,65.740,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 2.590 | Acc: 66.406,75.781,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.125 | Acc: 63.876,82.812,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.108 | Acc: 63.338,83.098,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.101 | Acc: 62.871,83.145,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.075 | Acc: 63.050,83.401,94.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.080 | Acc: 62.941,83.284,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.081 | Acc: 63.042,83.239,94.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.080 | Acc: 63.165,83.372,94.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.096 | Acc: 62.942,83.157,94.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.094 | Acc: 63.091,83.110,94.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.102 | Acc: 63.017,82.910,94.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.103 | Acc: 62.935,82.894,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.109 | Acc: 62.870,82.907,94.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.116 | Acc: 62.742,82.798,94.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.120 | Acc: 62.678,82.818,93.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.133 | Acc: 62.562,82.662,93.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.143 | Acc: 62.485,82.513,93.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.151 | Acc: 62.477,82.396,93.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.155 | Acc: 62.450,82.399,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.161 | Acc: 62.379,82.359,93.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.338 | Acc: 51.562,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.200 | Acc: 50.186,67.597,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.230 | Acc: 49.809,66.349,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.245 | Acc: 49.872,66.368,71.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 1.963 | Acc: 63.281,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.087 | Acc: 62.314,83.482,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.076 | Acc: 62.538,83.498,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.061 | Acc: 62.743,83.568,94.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.050 | Acc: 62.770,83.729,94.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.047 | Acc: 62.972,83.648,94.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.076 | Acc: 62.506,83.529,94.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.094 | Acc: 62.400,83.361,94.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.088 | Acc: 62.558,83.405,94.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.092 | Acc: 62.530,83.443,94.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.109 | Acc: 62.380,83.291,94.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.119 | Acc: 62.291,83.095,93.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.128 | Acc: 62.208,82.936,93.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.136 | Acc: 62.153,82.801,93.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.142 | Acc: 62.205,82.765,93.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.150 | Acc: 62.165,82.592,93.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.151 | Acc: 62.196,82.579,93.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.157 | Acc: 62.195,82.563,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.162 | Acc: 62.091,82.538,93.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.169 | Acc: 62.073,82.495,93.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.948 | Acc: 56.250,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.152 | Acc: 53.051,65.774,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.170 | Acc: 52.306,65.968,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.211 | Acc: 52.139,65.830,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 2.147 | Acc: 64.844,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.139 | Acc: 61.830,83.371,93.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.069 | Acc: 62.595,83.994,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.045 | Acc: 62.910,83.876,94.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.048 | Acc: 63.088,83.767,94.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.047 | Acc: 62.949,83.772,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.052 | Acc: 62.855,83.678,94.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.062 | Acc: 62.633,83.555,94.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.080 | Acc: 62.718,83.303,94.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.090 | Acc: 62.655,83.218,94.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.095 | Acc: 62.749,83.174,93.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.102 | Acc: 62.769,83.131,93.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.115 | Acc: 62.633,82.939,93.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.115 | Acc: 62.557,82.884,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.126 | Acc: 62.386,82.721,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.136 | Acc: 62.352,82.662,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.141 | Acc: 62.300,82.593,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.147 | Acc: 62.259,82.560,93.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.150 | Acc: 62.229,82.464,93.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.157 | Acc: 62.201,82.396,93.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.171 | Acc: 50.781,64.062,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.531 | Acc: 49.033,64.918,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.521 | Acc: 49.314,64.672,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.512 | Acc: 49.039,64.626,70.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 2.003 | Acc: 64.062,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.072 | Acc: 62.388,84.003,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 63.396,84.204,95.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.036 | Acc: 62.923,83.658,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.027 | Acc: 63.137,84.008,95.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.021 | Acc: 63.498,84.058,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.037 | Acc: 63.404,83.762,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.048 | Acc: 63.320,83.688,94.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.051 | Acc: 63.233,83.584,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.062 | Acc: 63.217,83.516,94.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.067 | Acc: 63.305,83.500,94.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.076 | Acc: 63.182,83.392,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.093 | Acc: 62.928,83.153,94.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.103 | Acc: 62.775,83.010,94.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.112 | Acc: 62.745,82.963,94.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.120 | Acc: 62.645,82.885,93.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.128 | Acc: 62.597,82.737,93.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.137 | Acc: 62.548,82.650,93.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.146 | Acc: 62.485,82.577,93.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.152 | Acc: 62.490,82.517,93.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.000 | Acc: 50.781,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.056 | Acc: 52.679,66.481,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.076 | Acc: 52.439,66.521,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.094 | Acc: 52.318,66.278,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 1.823 | Acc: 66.406,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 62.909,84.710,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.961 | Acc: 64.234,85.061,94.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.986 | Acc: 64.319,84.477,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.981 | Acc: 64.130,84.915,94.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.998 | Acc: 63.923,84.607,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.996 | Acc: 63.811,84.491,94.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.006 | Acc: 63.730,84.364,94.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.024 | Acc: 63.645,84.098,94.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.039 | Acc: 63.307,83.874,94.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.055 | Acc: 63.025,83.741,94.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.065 | Acc: 63.006,83.583,94.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.074 | Acc: 62.954,83.406,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.084 | Acc: 62.844,83.351,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.097 | Acc: 62.742,83.218,94.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.110 | Acc: 62.627,83.114,93.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.117 | Acc: 62.651,83.000,93.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.132 | Acc: 62.582,82.778,93.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.142 | Acc: 62.506,82.635,93.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.146 | Acc: 62.521,82.609,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.294 | Acc: 47.656,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.213 | Acc: 52.567,66.034,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.172 | Acc: 52.839,65.987,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.217 | Acc: 52.805,65.523,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 1.727 | Acc: 66.406,88.281,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.010 | Acc: 62.500,84.896,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.028 | Acc: 63.186,84.489,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 63.358,84.388,94.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.030 | Acc: 63.252,84.047,94.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.034 | Acc: 63.366,83.934,94.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.049 | Acc: 63.204,83.813,94.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.062 | Acc: 63.026,83.743,94.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.065 | Acc: 63.034,83.768,94.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.060 | Acc: 63.191,83.736,94.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.071 | Acc: 63.130,83.582,94.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.080 | Acc: 62.952,83.516,93.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.087 | Acc: 62.840,83.409,93.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.097 | Acc: 62.713,83.360,93.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.106 | Acc: 62.597,83.224,93.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.122 | Acc: 62.399,83.046,93.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.127 | Acc: 62.378,82.966,93.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.133 | Acc: 62.335,82.920,93.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.140 | Acc: 62.344,82.862,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.151 | Acc: 62.264,82.718,93.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.123 | Acc: 51.562,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.214 | Acc: 52.604,65.551,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.161 | Acc: 52.896,65.682,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.163 | Acc: 52.497,65.279,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 2.456 | Acc: 55.469,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.023 | Acc: 64.621,84.115,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.036 | Acc: 63.967,83.841,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.048 | Acc: 63.512,83.927,94.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.078 | Acc: 62.635,83.700,94.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.069 | Acc: 62.330,83.872,94.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.076 | Acc: 62.474,83.807,94.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.083 | Acc: 62.655,83.605,94.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.086 | Acc: 62.864,83.521,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.102 | Acc: 62.664,83.408,93.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.110 | Acc: 62.543,83.201,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.116 | Acc: 62.507,83.074,93.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.116 | Acc: 62.549,83.036,93.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.120 | Acc: 62.533,82.968,93.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.120 | Acc: 62.603,82.954,93.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.127 | Acc: 62.619,82.864,93.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.134 | Acc: 62.522,82.795,93.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.146 | Acc: 62.450,82.748,93.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.150 | Acc: 62.385,82.670,93.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.150 | Acc: 62.475,82.634,93.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.293 | Acc: 54.688,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.290 | Acc: 51.935,66.778,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.280 | Acc: 51.258,66.616,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.282 | Acc: 51.242,66.624,70.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 2.199 | Acc: 62.500,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.010 | Acc: 63.616,84.859,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.004 | Acc: 63.758,84.889,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.984 | Acc: 64.127,84.810,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.989 | Acc: 63.754,84.549,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.995 | Acc: 63.645,84.646,94.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.995 | Acc: 63.520,84.666,94.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.998 | Acc: 63.442,84.669,94.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.009 | Acc: 63.252,84.428,94.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.023 | Acc: 63.173,84.077,94.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.034 | Acc: 63.137,83.912,94.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.046 | Acc: 63.069,83.806,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.057 | Acc: 62.934,83.730,94.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.064 | Acc: 62.850,83.603,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.076 | Acc: 62.639,83.405,94.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.088 | Acc: 62.443,83.313,94.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.093 | Acc: 62.532,83.190,93.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.102 | Acc: 62.493,83.087,93.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.105 | Acc: 62.535,83.072,93.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.114 | Acc: 62.451,82.907,93.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.336 | Acc: 51.562,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.287 | Acc: 52.307,67.076,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.350 | Acc: 52.172,66.387,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.354 | Acc: 52.024,66.470,69.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 2.198 | Acc: 66.406,84.375,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.032 | Acc: 63.504,83.891,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.064 | Acc: 62.157,84.280,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.040 | Acc: 62.782,84.285,94.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.033 | Acc: 63.030,84.327,94.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.027 | Acc: 63.351,84.259,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.045 | Acc: 63.320,83.910,94.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.056 | Acc: 63.414,83.727,93.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.070 | Acc: 63.077,83.671,93.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.081 | Acc: 63.022,83.460,93.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.086 | Acc: 63.079,83.259,93.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.091 | Acc: 62.995,83.162,93.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.100 | Acc: 62.857,83.075,93.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.107 | Acc: 62.683,82.986,93.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.113 | Acc: 62.664,82.915,93.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.120 | Acc: 62.713,82.864,93.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.126 | Acc: 62.678,82.791,93.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.133 | Acc: 62.569,82.771,93.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.136 | Acc: 62.578,82.771,93.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.140 | Acc: 62.580,82.743,93.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.083 | Acc: 57.031,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.214 | Acc: 49.665,66.592,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.261 | Acc: 49.200,66.235,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.268 | Acc: 48.835,66.355,70.146,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 1.961 | Acc: 63.281,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.119 | Acc: 63.579,83.408,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.128 | Acc: 62.843,82.717,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.111 | Acc: 62.859,82.864,93.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.093 | Acc: 63.252,83.295,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.092 | Acc: 63.072,83.192,94.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.092 | Acc: 62.958,83.181,94.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.084 | Acc: 63.026,83.339,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.095 | Acc: 62.888,83.249,94.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.095 | Acc: 62.940,83.223,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.097 | Acc: 62.889,83.221,94.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.095 | Acc: 62.861,83.251,94.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.095 | Acc: 62.840,83.221,93.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.095 | Acc: 62.853,83.232,93.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.109 | Acc: 62.628,83.071,93.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.119 | Acc: 62.557,82.898,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.124 | Acc: 62.517,82.849,93.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.133 | Acc: 62.431,82.723,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.137 | Acc: 62.418,82.674,93.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.138 | Acc: 62.412,82.679,93.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.912 | Acc: 54.688,70.312,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.991 | Acc: 54.390,66.927,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.961 | Acc: 54.383,67.359,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.002 | Acc: 54.329,66.944,71.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 2.061 | Acc: 58.594,77.344,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.044 | Acc: 63.170,83.110,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.059 | Acc: 62.995,82.946,94.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.049 | Acc: 63.140,83.248,94.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.042 | Acc: 63.156,83.507,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.053 | Acc: 63.173,83.323,94.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.049 | Acc: 63.281,83.536,94.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.057 | Acc: 63.148,83.389,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.061 | Acc: 63.097,83.405,94.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.061 | Acc: 63.096,83.279,94.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.066 | Acc: 63.180,83.232,93.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.079 | Acc: 63.009,83.088,93.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.079 | Acc: 63.132,83.127,93.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.078 | Acc: 63.221,83.154,93.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.085 | Acc: 63.198,83.010,93.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.090 | Acc: 63.170,82.997,93.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.096 | Acc: 63.116,82.951,93.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.106 | Acc: 63.075,82.787,93.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.117 | Acc: 62.937,82.700,93.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.123 | Acc: 62.957,82.687,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.871 | Acc: 53.125,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.144 | Acc: 52.158,66.704,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.147 | Acc: 51.734,66.463,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.146 | Acc: 51.767,66.586,71.542,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 2.173 | Acc: 61.719,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.080 | Acc: 63.356,83.482,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.053 | Acc: 63.338,84.013,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.050 | Acc: 62.731,84.144,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.033 | Acc: 62.973,84.288,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.009 | Acc: 63.274,84.483,94.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.009 | Acc: 63.307,84.491,94.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.009 | Acc: 63.320,84.342,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.015 | Acc: 63.262,84.249,94.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.029 | Acc: 63.182,84.021,94.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.037 | Acc: 63.153,83.893,94.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.046 | Acc: 63.097,83.831,94.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.054 | Acc: 63.038,83.779,94.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.060 | Acc: 63.015,83.752,94.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.069 | Acc: 62.925,83.549,94.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.078 | Acc: 62.915,83.446,94.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.088 | Acc: 62.838,83.387,93.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.097 | Acc: 62.683,83.229,93.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.099 | Acc: 62.669,83.219,93.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.107 | Acc: 62.635,83.145,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.319 | Acc: 52.344,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.479 | Acc: 48.921,66.109,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.409 | Acc: 49.257,65.854,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.437 | Acc: 49.436,65.510,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 2.327 | Acc: 57.031,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.185 | Acc: 59.747,82.999,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.120 | Acc: 61.433,83.556,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.066 | Acc: 62.295,83.811,94.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.044 | Acc: 62.558,84.105,94.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.034 | Acc: 62.670,84.259,94.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.028 | Acc: 63.062,84.207,94.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.033 | Acc: 63.098,84.159,94.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.052 | Acc: 62.980,83.870,94.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.059 | Acc: 62.901,83.654,94.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.067 | Acc: 62.846,83.508,94.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.066 | Acc: 62.967,83.488,94.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.069 | Acc: 62.967,83.409,94.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.075 | Acc: 62.868,83.291,94.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.086 | Acc: 62.820,83.143,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.090 | Acc: 62.752,83.098,93.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.103 | Acc: 62.700,82.963,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.110 | Acc: 62.681,82.890,93.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.113 | Acc: 62.710,82.858,93.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.116 | Acc: 62.674,82.835,93.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.058 | Acc: 50.781,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.339 | Acc: 50.112,65.365,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.318 | Acc: 50.000,65.320,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.324 | Acc: 50.499,65.651,70.838,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 1.866 | Acc: 65.625,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.995 | Acc: 63.653,84.263,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.939 | Acc: 64.615,85.423,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.933 | Acc: 64.652,85.476,95.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.943 | Acc: 64.709,85.494,95.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.954 | Acc: 64.264,85.388,95.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.971 | Acc: 63.972,85.189,94.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.979 | Acc: 63.813,85.018,94.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.988 | Acc: 63.859,84.652,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.012 | Acc: 63.678,84.353,94.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.017 | Acc: 63.639,84.258,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.025 | Acc: 63.621,84.174,94.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.032 | Acc: 63.625,84.031,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.040 | Acc: 63.536,83.935,94.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.052 | Acc: 63.398,83.802,94.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.060 | Acc: 63.408,83.731,94.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.070 | Acc: 63.223,83.565,93.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.086 | Acc: 63.137,83.392,93.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.095 | Acc: 63.134,83.250,93.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.107 | Acc: 62.990,83.089,93.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.874 | Acc: 50.781,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.350 | Acc: 49.814,64.658,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.434 | Acc: 49.314,64.520,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.459 | Acc: 49.155,64.293,70.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 1.813 | Acc: 68.750,88.281,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.057 | Acc: 63.802,83.519,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.042 | Acc: 63.529,83.841,94.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.024 | Acc: 63.781,84.055,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.008 | Acc: 63.735,84.172,94.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.017 | Acc: 63.591,83.973,94.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.032 | Acc: 63.423,83.813,94.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.046 | Acc: 63.237,83.605,94.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.045 | Acc: 63.393,83.589,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.058 | Acc: 63.268,83.469,94.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.064 | Acc: 63.192,83.376,94.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.077 | Acc: 63.059,83.325,94.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.078 | Acc: 63.161,83.263,93.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.081 | Acc: 63.179,83.220,93.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.096 | Acc: 62.934,83.179,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.110 | Acc: 62.817,83.041,93.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.116 | Acc: 62.833,82.966,93.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.125 | Acc: 62.704,82.893,93.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.132 | Acc: 62.738,82.782,93.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.136 | Acc: 62.781,82.710,93.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.409 | Acc: 53.125,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.305 | Acc: 51.711,65.699,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.276 | Acc: 51.772,66.101,71.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 51.883,66.176,70.902,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 1.945 | Acc: 60.938,85.938,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.034 | Acc: 63.876,83.557,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.001 | Acc: 64.310,84.432,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 63.755,84.132,94.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.009 | Acc: 63.387,84.423,94.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.016 | Acc: 63.444,84.383,94.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.031 | Acc: 63.385,84.072,94.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.045 | Acc: 63.187,84.081,94.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.044 | Acc: 63.315,83.997,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.055 | Acc: 63.204,83.835,94.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.066 | Acc: 63.048,83.613,94.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.071 | Acc: 63.175,83.498,93.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.080 | Acc: 63.064,83.331,93.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.093 | Acc: 62.838,83.223,93.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.097 | Acc: 62.878,83.174,93.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.098 | Acc: 62.871,83.176,93.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.100 | Acc: 62.877,83.134,93.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.106 | Acc: 62.846,83.069,93.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.105 | Acc: 62.848,83.081,93.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.106 | Acc: 62.863,83.038,93.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.702 | Acc: 53.125,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.007 | Acc: 51.153,67.969,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.046 | Acc: 51.791,67.721,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.061 | Acc: 51.716,67.610,71.785,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 1.774 | Acc: 66.406,88.281,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.029 | Acc: 64.174,84.859,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.968 | Acc: 63.662,85.728,94.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.974 | Acc: 63.742,85.438,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.997 | Acc: 63.358,85.089,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.000 | Acc: 63.413,84.955,94.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.018 | Acc: 63.262,84.737,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.031 | Acc: 63.087,84.519,94.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.017 | Acc: 63.359,84.589,94.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.016 | Acc: 63.463,84.552,94.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.026 | Acc: 63.266,84.449,94.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.034 | Acc: 63.235,84.287,94.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.042 | Acc: 63.174,84.223,94.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.053 | Acc: 63.096,84.067,94.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.066 | Acc: 62.981,83.897,93.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.073 | Acc: 63.061,83.830,93.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.082 | Acc: 63.043,83.694,93.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.091 | Acc: 63.013,83.594,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.094 | Acc: 63.037,83.535,93.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.099 | Acc: 63.006,83.465,93.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.191 | Acc: 54.688,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.096 | Acc: 52.976,66.890,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.124 | Acc: 53.201,65.873,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.113 | Acc: 52.792,66.086,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 2.206 | Acc: 62.500,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.995 | Acc: 63.653,84.561,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.974 | Acc: 64.196,85.004,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.982 | Acc: 64.037,84.593,94.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.974 | Acc: 64.255,84.491,94.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.968 | Acc: 64.356,84.468,94.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.966 | Acc: 64.463,84.349,94.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.980 | Acc: 64.135,84.109,94.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.993 | Acc: 64.029,83.982,94.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.000 | Acc: 63.955,84.025,94.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.006 | Acc: 63.841,83.924,94.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.019 | Acc: 63.730,83.869,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.029 | Acc: 63.592,83.814,94.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.040 | Acc: 63.467,83.693,94.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.047 | Acc: 63.451,83.605,94.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.055 | Acc: 63.292,83.526,94.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.069 | Acc: 63.062,83.355,93.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.082 | Acc: 62.901,83.239,93.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.087 | Acc: 62.872,83.159,93.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.090 | Acc: 62.869,83.126,93.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.850 | Acc: 57.031,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.104 | Acc: 53.609,67.708,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.059 | Acc: 53.773,67.530,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.103 | Acc: 53.215,67.034,71.760,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 2.044 | Acc: 54.688,82.812,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.989 | Acc: 63.765,84.561,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.002 | Acc: 64.082,84.909,94.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.002 | Acc: 64.229,84.567,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.001 | Acc: 64.024,84.635,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.014 | Acc: 63.784,84.390,94.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.033 | Acc: 63.404,83.968,94.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.031 | Acc: 63.586,83.976,94.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.033 | Acc: 63.378,83.938,94.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.036 | Acc: 63.428,84.021,94.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.037 | Acc: 63.429,83.955,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.042 | Acc: 63.331,83.866,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.052 | Acc: 63.340,83.772,94.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.064 | Acc: 63.239,83.645,94.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.071 | Acc: 63.217,83.605,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.080 | Acc: 63.183,83.454,93.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.088 | Acc: 63.104,83.328,93.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.093 | Acc: 63.075,83.317,93.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.102 | Acc: 62.948,83.165,93.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.113 | Acc: 62.808,83.052,93.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.906 | Acc: 54.688,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.275 | Acc: 48.326,67.076,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.289 | Acc: 48.114,66.673,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.297 | Acc: 48.373,66.714,71.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 2.060 | Acc: 60.156,87.500,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.013 | Acc: 63.504,85.082,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.039 | Acc: 63.224,84.280,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.044 | Acc: 63.128,84.157,94.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.040 | Acc: 63.436,84.240,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.059 | Acc: 63.088,83.926,93.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.051 | Acc: 63.488,83.826,93.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.054 | Acc: 63.470,83.815,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.061 | Acc: 63.301,83.754,93.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.063 | Acc: 63.217,83.844,93.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.061 | Acc: 63.332,83.726,93.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.059 | Acc: 63.345,83.735,93.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.059 | Acc: 63.453,83.610,93.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.071 | Acc: 63.296,83.435,93.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.081 | Acc: 63.265,83.310,93.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.095 | Acc: 63.149,83.163,93.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.105 | Acc: 63.074,83.029,93.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.114 | Acc: 63.045,82.955,93.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.119 | Acc: 63.028,82.877,93.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.125 | Acc: 62.943,82.806,93.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.745 | Acc: 50.000,64.844,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.209 | Acc: 52.381,64.658,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.209 | Acc: 52.058,64.653,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.216 | Acc: 51.857,64.549,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 1.823 | Acc: 67.969,85.938,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.003 | Acc: 64.137,83.854,94.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.027 | Acc: 64.539,83.327,93.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.994 | Acc: 65.049,84.247,94.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.003 | Acc: 64.911,84.066,94.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.991 | Acc: 64.851,84.236,94.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.994 | Acc: 64.644,84.272,94.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.998 | Acc: 64.500,84.259,94.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.001 | Acc: 64.422,84.132,94.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.010 | Acc: 64.209,84.094,94.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.015 | Acc: 64.000,84.002,94.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.022 | Acc: 64.017,83.901,93.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.031 | Acc: 63.832,83.821,93.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.036 | Acc: 63.790,83.693,93.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.038 | Acc: 63.673,83.649,93.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.047 | Acc: 63.671,83.568,93.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.058 | Acc: 63.481,83.431,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.063 | Acc: 63.487,83.372,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.072 | Acc: 63.299,83.278,93.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.077 | Acc: 63.257,83.227,93.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.135 | Acc: 48.438,64.844,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.304 | Acc: 52.455,66.481,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.283 | Acc: 51.925,65.987,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.290 | Acc: 52.075,66.240,70.812,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 2.138 | Acc: 60.156,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.142 | Acc: 62.016,82.217,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.073 | Acc: 62.862,83.422,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.071 | Acc: 62.705,83.235,94.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.060 | Acc: 63.088,83.169,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.050 | Acc: 63.451,83.478,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.050 | Acc: 63.320,83.458,94.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.057 | Acc: 63.292,83.333,94.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.059 | Acc: 63.291,83.312,94.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.063 | Acc: 63.359,83.387,94.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.059 | Acc: 63.511,83.357,94.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.077 | Acc: 63.264,83.194,93.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.076 | Acc: 63.278,83.273,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.082 | Acc: 63.245,83.208,93.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.085 | Acc: 63.212,83.168,93.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.089 | Acc: 63.214,83.137,93.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.098 | Acc: 63.077,83.129,93.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.105 | Acc: 62.995,83.003,93.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.108 | Acc: 62.957,82.970,93.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.108 | Acc: 62.963,82.989,93.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.744 | Acc: 53.906,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.343 | Acc: 50.223,67.001,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.302 | Acc: 49.886,67.111,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.298 | Acc: 50.640,67.444,70.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 2.391 | Acc: 59.375,85.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.005 | Acc: 65.476,85.603,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.969 | Acc: 64.901,85.537,94.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 64.985,85.079,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.964 | Acc: 64.873,85.021,94.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.953 | Acc: 64.821,85.094,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.973 | Acc: 64.469,84.879,94.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.996 | Acc: 64.040,84.663,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.016 | Acc: 63.757,84.545,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.026 | Acc: 63.575,84.457,94.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.027 | Acc: 63.616,84.356,94.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.031 | Acc: 63.532,84.223,94.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.040 | Acc: 63.463,84.177,94.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.056 | Acc: 63.296,83.965,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.066 | Acc: 63.276,83.825,93.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.071 | Acc: 63.266,83.739,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.079 | Acc: 63.167,83.642,93.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.087 | Acc: 63.073,83.530,93.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.090 | Acc: 63.015,83.499,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.099 | Acc: 62.976,83.395,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.780 | Acc: 53.125,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.172 | Acc: 52.641,65.699,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.163 | Acc: 53.335,65.720,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.173 | Acc: 53.189,65.740,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 1.914 | Acc: 61.719,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.067 | Acc: 63.095,83.296,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.053 | Acc: 63.453,83.460,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.035 | Acc: 64.011,83.773,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.027 | Acc: 63.821,83.652,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.027 | Acc: 63.869,83.493,94.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.008 | Acc: 64.082,83.716,94.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.016 | Acc: 63.941,83.583,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.022 | Acc: 63.771,83.594,94.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.028 | Acc: 63.678,83.581,94.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.023 | Acc: 63.775,83.617,94.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.023 | Acc: 63.804,83.558,94.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.020 | Acc: 63.813,83.616,94.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.023 | Acc: 63.802,83.669,94.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.024 | Acc: 63.784,83.683,94.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.029 | Acc: 63.746,83.679,94.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.043 | Acc: 63.537,83.521,94.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.050 | Acc: 63.432,83.463,94.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.052 | Acc: 63.444,83.423,94.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.061 | Acc: 63.386,83.389,94.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.480 | Acc: 50.781,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.166 | Acc: 51.600,66.853,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.153 | Acc: 51.753,67.207,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.182 | Acc: 51.627,66.880,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 2.198 | Acc: 60.938,80.469,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.027 | Acc: 64.360,84.784,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.987 | Acc: 64.558,84.832,94.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 65.126,84.721,94.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.970 | Acc: 64.670,84.549,94.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.962 | Acc: 64.558,84.808,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.973 | Acc: 64.385,84.640,94.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.983 | Acc: 64.301,84.430,94.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.989 | Acc: 64.334,84.375,94.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.006 | Acc: 64.140,84.237,94.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.007 | Acc: 64.315,84.188,94.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.015 | Acc: 64.222,84.039,94.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.019 | Acc: 64.118,83.980,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.021 | Acc: 64.101,83.914,94.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.032 | Acc: 63.885,83.822,94.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.043 | Acc: 63.795,83.718,94.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.056 | Acc: 63.624,83.557,93.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.062 | Acc: 63.575,83.472,93.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.067 | Acc: 63.539,83.470,93.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.073 | Acc: 63.523,83.329,93.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.161 | Acc: 52.344,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.104 | Acc: 52.902,67.262,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.093 | Acc: 52.915,67.130,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.089 | Acc: 53.048,67.098,70.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 1.946 | Acc: 66.406,85.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.009 | Acc: 64.286,85.305,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.973 | Acc: 64.310,85.556,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.978 | Acc: 63.704,85.374,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.979 | Acc: 63.619,85.301,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.992 | Acc: 63.598,85.032,94.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.004 | Acc: 63.623,84.666,94.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.007 | Acc: 63.603,84.464,94.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.020 | Acc: 63.592,84.263,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.022 | Acc: 63.570,84.280,94.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.035 | Acc: 63.371,84.223,94.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.040 | Acc: 63.507,84.082,94.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.042 | Acc: 63.450,83.928,94.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.036 | Acc: 63.634,84.019,94.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.049 | Acc: 63.515,83.872,94.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.055 | Acc: 63.528,83.716,94.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.067 | Acc: 63.447,83.540,93.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.075 | Acc: 63.322,83.438,93.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.078 | Acc: 63.325,83.390,93.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.084 | Acc: 63.265,83.327,93.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.139 | Acc: 47.656,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.128 | Acc: 53.088,67.522,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.171 | Acc: 52.858,66.711,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.149 | Acc: 52.946,67.098,70.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 2.248 | Acc: 64.844,82.812,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.977 | Acc: 63.653,84.673,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.963 | Acc: 64.120,85.137,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.969 | Acc: 63.704,85.182,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.966 | Acc: 63.937,85.166,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.966 | Acc: 64.163,84.971,94.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.963 | Acc: 64.476,84.988,94.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.966 | Acc: 64.445,84.874,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.993 | Acc: 63.975,84.574,94.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.014 | Acc: 63.739,84.353,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.023 | Acc: 63.759,84.095,94.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.027 | Acc: 63.840,84.021,94.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.039 | Acc: 63.742,83.834,94.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.046 | Acc: 63.575,83.657,94.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.054 | Acc: 63.468,83.471,94.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.056 | Acc: 63.455,83.373,94.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.058 | Acc: 63.532,83.353,93.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.066 | Acc: 63.501,83.303,93.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.074 | Acc: 63.435,83.191,93.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.081 | Acc: 63.423,83.077,93.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.460 | Acc: 57.812,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.865 | Acc: 55.729,69.234,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.876 | Acc: 56.250,68.902,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.874 | Acc: 56.084,68.532,71.926,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 1.671 | Acc: 71.875,89.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.932 | Acc: 65.811,84.487,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.972 | Acc: 64.444,84.928,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.976 | Acc: 64.165,85.233,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.979 | Acc: 63.619,85.050,95.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.985 | Acc: 63.653,84.824,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.000 | Acc: 63.372,84.556,94.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.013 | Acc: 63.148,84.397,94.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.013 | Acc: 63.077,84.453,94.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.021 | Acc: 63.014,84.297,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.023 | Acc: 62.994,84.165,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.024 | Acc: 62.984,84.124,94.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.029 | Acc: 63.080,84.028,94.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.029 | Acc: 63.165,84.046,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.037 | Acc: 63.126,83.975,94.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.046 | Acc: 63.084,83.794,94.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.056 | Acc: 63.060,83.672,94.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.069 | Acc: 62.928,83.557,94.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.076 | Acc: 62.903,83.455,93.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.083 | Acc: 62.834,83.391,93.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.853 | Acc: 54.688,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.112 | Acc: 53.683,67.708,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.152 | Acc: 53.373,67.645,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.142 | Acc: 53.163,68.007,71.107,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 2.020 | Acc: 65.625,87.500,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.995 | Acc: 64.435,84.821,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.995 | Acc: 64.253,84.546,94.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.992 | Acc: 64.319,84.529,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.966 | Acc: 64.410,84.925,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.970 | Acc: 64.349,84.599,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.967 | Acc: 64.605,84.659,94.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.976 | Acc: 64.461,84.730,94.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.987 | Acc: 64.281,84.729,94.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.983 | Acc: 64.373,84.751,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.985 | Acc: 64.424,84.632,94.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.988 | Acc: 64.398,84.527,94.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.000 | Acc: 64.244,84.420,94.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.009 | Acc: 64.113,84.255,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.015 | Acc: 63.912,84.166,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.024 | Acc: 63.730,84.115,94.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.039 | Acc: 63.561,83.956,94.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.048 | Acc: 63.373,83.827,94.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.060 | Acc: 63.255,83.618,94.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.062 | Acc: 63.318,83.559,94.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.858 | Acc: 58.594,65.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.222 | Acc: 51.228,66.555,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.180 | Acc: 51.658,66.883,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.191 | Acc: 51.947,66.611,70.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 2.216 | Acc: 60.938,85.156,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.944 | Acc: 63.393,85.007,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.924 | Acc: 63.967,85.252,95.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.943 | Acc: 64.024,85.041,95.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.947 | Acc: 64.140,85.002,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.962 | Acc: 63.962,84.731,95.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.965 | Acc: 64.011,84.730,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.973 | Acc: 63.780,84.741,94.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.979 | Acc: 63.820,84.618,94.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.990 | Acc: 63.575,84.483,94.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.991 | Acc: 63.682,84.495,94.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.998 | Acc: 63.748,84.318,94.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.009 | Acc: 63.618,84.216,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.014 | Acc: 63.622,84.133,94.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.018 | Acc: 63.637,84.114,94.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.028 | Acc: 63.533,83.978,94.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.035 | Acc: 63.420,83.920,94.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.035 | Acc: 63.453,83.860,94.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.042 | Acc: 63.381,83.802,94.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.049 | Acc: 63.300,83.750,94.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.115 | Acc: 51.562,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.260 | Acc: 51.525,65.402,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.224 | Acc: 52.344,65.587,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.212 | Acc: 52.280,66.086,69.915,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 1.694 | Acc: 69.531,89.844,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.895 | Acc: 65.588,85.231,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.966 | Acc: 64.672,84.851,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.955 | Acc: 64.895,85.220,95.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.958 | Acc: 64.680,85.147,94.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.950 | Acc: 64.828,85.133,95.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.950 | Acc: 64.715,84.963,95.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.947 | Acc: 64.611,84.890,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.950 | Acc: 64.630,84.739,94.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.966 | Acc: 64.399,84.586,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.971 | Acc: 64.373,84.632,94.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.988 | Acc: 64.232,84.311,94.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.006 | Acc: 64.134,84.206,94.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.014 | Acc: 63.982,84.148,94.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.024 | Acc: 63.932,84.008,94.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.035 | Acc: 63.834,83.897,94.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.042 | Acc: 63.787,83.788,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.058 | Acc: 63.565,83.621,93.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.065 | Acc: 63.604,83.503,93.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.073 | Acc: 63.484,83.393,93.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.847 | Acc: 54.688,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.049 | Acc: 54.129,65.141,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.083 | Acc: 53.716,64.844,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.115 | Acc: 53.560,65.087,71.004,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 2.076 | Acc: 63.281,84.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.977 | Acc: 64.360,84.263,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.013 | Acc: 63.338,83.803,94.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.002 | Acc: 64.062,84.068,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.010 | Acc: 63.870,84.086,94.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.012 | Acc: 63.885,84.081,94.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.004 | Acc: 64.256,83.923,94.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.996 | Acc: 64.351,83.815,94.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.003 | Acc: 64.208,83.715,94.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.009 | Acc: 64.106,83.766,94.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.013 | Acc: 64.051,83.874,94.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.017 | Acc: 64.094,83.884,94.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.028 | Acc: 63.930,83.788,94.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.027 | Acc: 63.925,83.794,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.040 | Acc: 63.776,83.658,93.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.056 | Acc: 63.634,83.542,93.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.062 | Acc: 63.595,83.540,93.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.067 | Acc: 63.579,83.454,93.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.074 | Acc: 63.476,83.399,93.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.075 | Acc: 63.544,83.370,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.941 | Acc: 51.562,72.656,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.318 | Acc: 50.781,66.295,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.318 | Acc: 50.648,66.101,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.280 | Acc: 50.858,66.227,72.003,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 2.064 | Acc: 60.156,89.062,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.041 | Acc: 64.137,84.226,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.029 | Acc: 63.415,84.165,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.989 | Acc: 63.947,84.939,94.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.972 | Acc: 64.448,85.041,94.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.976 | Acc: 63.985,84.800,94.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.988 | Acc: 63.824,84.588,94.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.995 | Acc: 63.758,84.552,94.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.003 | Acc: 63.747,84.467,94.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.006 | Acc: 63.804,84.315,94.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.003 | Acc: 63.767,84.340,94.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.003 | Acc: 63.875,84.375,94.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.005 | Acc: 63.949,84.236,94.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.006 | Acc: 63.991,84.237,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.014 | Acc: 63.912,84.203,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.024 | Acc: 63.774,84.082,94.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.036 | Acc: 63.666,83.930,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.042 | Acc: 63.641,83.830,93.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.052 | Acc: 63.560,83.758,93.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.055 | Acc: 63.597,83.704,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.098 | Acc: 58.594,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.209 | Acc: 53.757,65.253,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.129 | Acc: 54.097,65.777,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.125 | Acc: 54.111,65.817,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 1.961 | Acc: 64.062,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.023 | Acc: 64.174,84.524,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.025 | Acc: 64.177,84.527,94.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.009 | Acc: 63.922,84.580,94.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.983 | Acc: 64.014,84.606,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.981 | Acc: 64.117,84.499,94.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.980 | Acc: 64.114,84.627,94.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.979 | Acc: 64.334,84.713,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.979 | Acc: 64.368,84.720,94.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.982 | Acc: 64.162,84.677,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.989 | Acc: 64.086,84.581,94.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.989 | Acc: 64.165,84.538,94.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.005 | Acc: 63.985,84.307,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.006 | Acc: 64.068,84.351,94.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.016 | Acc: 63.960,84.272,94.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.027 | Acc: 63.883,84.170,94.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.035 | Acc: 63.817,84.046,93.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.045 | Acc: 63.749,83.878,93.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.051 | Acc: 63.740,83.782,93.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.055 | Acc: 63.734,83.688,93.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.277 | Acc: 50.781,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.264 | Acc: 51.339,65.253,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.290 | Acc: 51.029,65.301,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.288 | Acc: 51.217,65.369,70.786,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 2.169 | Acc: 67.188,77.344,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.024 | Acc: 64.509,83.259,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.956 | Acc: 64.691,84.375,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.970 | Acc: 64.331,84.529,94.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.982 | Acc: 64.014,84.423,94.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.980 | Acc: 63.846,84.499,94.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.955 | Acc: 64.230,84.704,94.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.960 | Acc: 64.040,84.652,94.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.963 | Acc: 64.135,84.530,94.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.973 | Acc: 63.989,84.504,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.987 | Acc: 63.818,84.352,94.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.997 | Acc: 63.861,84.205,94.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.005 | Acc: 63.939,84.109,94.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.015 | Acc: 63.736,83.986,94.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.018 | Acc: 63.784,83.977,94.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.020 | Acc: 63.720,83.957,94.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.024 | Acc: 63.666,83.898,94.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.029 | Acc: 63.600,83.878,94.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.035 | Acc: 63.593,83.780,94.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.048 | Acc: 63.495,83.674,94.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.732 | Acc: 47.656,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.373 | Acc: 50.521,67.001,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.369 | Acc: 51.277,66.025,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.353 | Acc: 51.511,66.086,70.620,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 1.927 | Acc: 65.625,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.911 | Acc: 65.588,86.272,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.899 | Acc: 65.111,85.918,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.910 | Acc: 65.087,85.963,95.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.906 | Acc: 65.181,85.918,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.906 | Acc: 65.393,85.636,95.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.917 | Acc: 65.244,85.447,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.936 | Acc: 64.955,85.228,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.937 | Acc: 64.921,85.268,94.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.948 | Acc: 64.775,85.066,94.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.949 | Acc: 64.929,84.939,94.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.964 | Acc: 64.840,84.789,94.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.974 | Acc: 64.565,84.686,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.984 | Acc: 64.497,84.573,94.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.992 | Acc: 64.363,84.467,94.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.001 | Acc: 64.301,84.300,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.005 | Acc: 64.250,84.317,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.013 | Acc: 64.136,84.313,94.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.019 | Acc: 64.058,84.204,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.028 | Acc: 63.919,84.100,94.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.014 | Acc: 55.469,70.312,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.278 | Acc: 49.777,67.225,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.313 | Acc: 48.933,66.635,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.300 | Acc: 49.180,66.752,70.825,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 2.013 | Acc: 64.062,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.957 | Acc: 65.290,85.900,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.936 | Acc: 65.282,85.728,94.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.932 | Acc: 64.908,85.745,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.917 | Acc: 65.201,85.909,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.927 | Acc: 65.076,85.659,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.931 | Acc: 64.844,85.615,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.937 | Acc: 64.750,85.406,94.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.940 | Acc: 64.625,85.336,94.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.948 | Acc: 64.606,85.122,94.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.957 | Acc: 64.533,85.024,94.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.970 | Acc: 64.412,84.803,94.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.983 | Acc: 64.231,84.641,94.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.991 | Acc: 64.218,84.444,94.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.002 | Acc: 64.143,84.344,94.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.018 | Acc: 63.915,84.147,94.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.025 | Acc: 63.880,84.051,94.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.030 | Acc: 63.813,84.027,94.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.037 | Acc: 63.788,83.897,94.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.045 | Acc: 63.790,83.782,93.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.820 | Acc: 53.906,71.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.137 | Acc: 51.488,66.034,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.150 | Acc: 51.505,65.606,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.162 | Acc: 51.076,65.804,71.004,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 2.099 | Acc: 59.375,84.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.962 | Acc: 65.997,85.528,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.950 | Acc: 64.977,85.385,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.964 | Acc: 64.498,85.169,94.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.960 | Acc: 64.689,85.185,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.973 | Acc: 64.534,85.048,94.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.988 | Acc: 64.418,84.795,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.990 | Acc: 64.256,84.824,94.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.996 | Acc: 64.106,84.676,94.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.003 | Acc: 64.050,84.599,94.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.010 | Acc: 64.047,84.418,94.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.008 | Acc: 64.190,84.308,94.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.015 | Acc: 64.088,84.265,94.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.019 | Acc: 64.122,84.213,94.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.029 | Acc: 63.971,84.083,93.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.043 | Acc: 63.803,83.874,93.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.051 | Acc: 63.663,83.796,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.056 | Acc: 63.696,83.720,93.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.064 | Acc: 63.623,83.548,93.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.067 | Acc: 63.591,83.524,93.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.891 | Acc: 59.375,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.329 | Acc: 53.943,66.332,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.292 | Acc: 52.954,66.635,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.325 | Acc: 52.766,67.021,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 2.122 | Acc: 62.500,84.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.979 | Acc: 64.397,83.966,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.978 | Acc: 63.605,84.680,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.940 | Acc: 64.472,85.131,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.948 | Acc: 64.304,85.118,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.948 | Acc: 64.527,85.056,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.958 | Acc: 64.308,84.846,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.963 | Acc: 64.445,84.646,95.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.978 | Acc: 64.247,84.399,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.980 | Acc: 64.209,84.366,94.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.985 | Acc: 64.230,84.457,94.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.992 | Acc: 64.197,84.354,94.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.994 | Acc: 64.163,84.359,94.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.003 | Acc: 64.233,84.201,94.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.011 | Acc: 64.107,84.150,94.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.018 | Acc: 63.925,84.064,94.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.023 | Acc: 63.895,83.998,94.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.030 | Acc: 63.792,83.935,94.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.033 | Acc: 63.879,83.884,94.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.037 | Acc: 63.870,83.811,94.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.802 | Acc: 55.469,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.075 | Acc: 54.092,69.457,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.080 | Acc: 53.735,68.769,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.110 | Acc: 53.484,68.494,70.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 1.835 | Acc: 67.969,88.281,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.923 | Acc: 64.546,85.082,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.935 | Acc: 64.386,85.175,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.930 | Acc: 64.370,85.259,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.942 | Acc: 64.101,85.050,95.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.955 | Acc: 63.962,84.924,95.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.966 | Acc: 63.824,84.737,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.967 | Acc: 64.007,84.707,95.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.971 | Acc: 63.951,84.584,95.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.981 | Acc: 63.851,84.392,94.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.984 | Acc: 63.825,84.321,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.988 | Acc: 63.889,84.290,94.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.991 | Acc: 63.904,84.216,94.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.001 | Acc: 63.676,84.156,94.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.011 | Acc: 63.548,83.939,94.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.019 | Acc: 63.593,83.791,94.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.023 | Acc: 63.508,83.793,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.029 | Acc: 63.469,83.763,94.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.032 | Acc: 63.405,83.706,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.034 | Acc: 63.410,83.670,94.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.794 | Acc: 55.469,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.242 | Acc: 52.976,66.518,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.210 | Acc: 53.335,66.978,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.178 | Acc: 53.650,67.034,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 1.885 | Acc: 67.969,82.812,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.916 | Acc: 66.109,86.124,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.909 | Acc: 65.758,85.633,94.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.935 | Acc: 65.215,85.246,94.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.931 | Acc: 65.152,85.204,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.941 | Acc: 64.743,85.172,94.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.946 | Acc: 64.702,85.156,94.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.944 | Acc: 64.833,85.023,94.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.951 | Acc: 64.732,84.817,94.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.958 | Acc: 64.688,84.669,94.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.974 | Acc: 64.568,84.643,94.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.985 | Acc: 64.473,84.481,94.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.991 | Acc: 64.400,84.472,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.998 | Acc: 64.287,84.381,94.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.999 | Acc: 64.179,84.425,94.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.006 | Acc: 64.086,84.331,94.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.010 | Acc: 64.067,84.261,94.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.023 | Acc: 63.973,84.089,94.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.028 | Acc: 63.937,84.011,94.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.034 | Acc: 63.907,83.907,93.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.884 | Acc: 53.906,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.024 | Acc: 55.171,68.676,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.096 | Acc: 54.688,67.245,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.089 | Acc: 54.688,67.328,70.914,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 1.925 | Acc: 61.719,86.719,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.918 | Acc: 65.290,85.045,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.900 | Acc: 65.568,85.423,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.932 | Acc: 65.407,85.118,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.940 | Acc: 65.345,84.963,94.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.955 | Acc: 65.037,84.878,94.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.950 | Acc: 65.199,84.988,94.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.954 | Acc: 65.054,84.852,94.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.958 | Acc: 65.164,84.724,94.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.965 | Acc: 65.073,84.634,94.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.977 | Acc: 64.906,84.558,94.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.986 | Acc: 64.709,84.375,94.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.991 | Acc: 64.688,84.229,94.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.999 | Acc: 64.586,84.121,94.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.007 | Acc: 64.449,84.008,94.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.012 | Acc: 64.436,83.931,94.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.026 | Acc: 64.260,83.757,94.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.028 | Acc: 64.207,83.720,93.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.041 | Acc: 64.034,83.589,93.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.053 | Acc: 63.950,83.446,93.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.381 | Acc: 46.875,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.434 | Acc: 49.554,66.109,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.392 | Acc: 49.505,66.425,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.350 | Acc: 49.974,66.586,70.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 1.975 | Acc: 65.625,88.281,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.056 | Acc: 63.393,84.524,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.039 | Acc: 64.043,83.975,93.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.005 | Acc: 64.306,84.516,94.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.996 | Acc: 64.419,84.471,94.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.987 | Acc: 64.565,84.592,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.998 | Acc: 64.437,84.427,94.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.003 | Acc: 64.478,84.491,94.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.011 | Acc: 64.422,84.229,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.019 | Acc: 64.231,84.090,94.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.023 | Acc: 64.230,83.947,94.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.029 | Acc: 64.119,83.926,94.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.040 | Acc: 63.952,83.843,94.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.041 | Acc: 63.958,83.857,94.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.042 | Acc: 63.868,83.872,94.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.047 | Acc: 63.772,83.858,94.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.046 | Acc: 63.841,83.900,94.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.050 | Acc: 63.870,83.864,94.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.054 | Acc: 63.861,83.743,93.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.055 | Acc: 63.878,83.731,93.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.750 | Acc: 56.250,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.029 | Acc: 55.618,67.522,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.022 | Acc: 54.802,67.778,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.992 | Acc: 54.803,68.084,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 1.740 | Acc: 67.188,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.830 | Acc: 67.262,86.496,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.868 | Acc: 66.521,85.785,94.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.848 | Acc: 66.688,86.194,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.871 | Acc: 66.165,85.561,95.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.879 | Acc: 65.656,85.512,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.909 | Acc: 65.373,85.214,94.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.918 | Acc: 65.198,85.173,94.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.925 | Acc: 65.174,84.972,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.941 | Acc: 64.908,84.841,94.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.949 | Acc: 64.715,84.725,94.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.960 | Acc: 64.522,84.661,94.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.970 | Acc: 64.500,84.563,94.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.980 | Acc: 64.461,84.474,94.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.989 | Acc: 64.427,84.378,94.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.990 | Acc: 64.462,84.372,94.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.996 | Acc: 64.316,84.338,94.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.007 | Acc: 64.138,84.212,93.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.020 | Acc: 63.967,84.050,93.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.024 | Acc: 63.956,83.977,93.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.175 | Acc: 55.469,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.053 | Acc: 53.311,67.708,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.060 | Acc: 53.906,67.245,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.059 | Acc: 53.676,67.431,71.196,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 1.918 | Acc: 62.500,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.889 | Acc: 65.737,85.863,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.899 | Acc: 65.968,86.090,94.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.892 | Acc: 65.356,86.168,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.914 | Acc: 65.201,85.802,94.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.940 | Acc: 64.387,85.473,94.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.942 | Acc: 64.327,85.569,94.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.946 | Acc: 64.328,85.328,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.940 | Acc: 64.373,85.355,94.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.947 | Acc: 64.438,85.178,94.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.954 | Acc: 64.405,84.993,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.967 | Acc: 64.367,84.905,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.966 | Acc: 64.497,84.858,94.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.969 | Acc: 64.422,84.818,94.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.979 | Acc: 64.352,84.698,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.985 | Acc: 64.304,84.567,94.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.994 | Acc: 64.121,84.516,94.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.001 | Acc: 64.069,84.485,94.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.013 | Acc: 63.900,84.317,94.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.023 | Acc: 63.775,84.158,93.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.892 | Acc: 53.906,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.081 | Acc: 55.171,68.043,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.084 | Acc: 54.230,67.816,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.070 | Acc: 54.508,67.597,71.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 1.981 | Acc: 66.406,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.987 | Acc: 63.170,85.045,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.974 | Acc: 64.367,84.604,94.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 64.331,84.606,95.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.944 | Acc: 64.506,85.021,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.914 | Acc: 64.759,85.295,95.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.918 | Acc: 64.844,85.201,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.930 | Acc: 64.761,85.156,95.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.927 | Acc: 64.839,85.156,95.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.937 | Acc: 64.779,85.130,95.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.943 | Acc: 64.696,85.012,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.951 | Acc: 64.628,84.909,94.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.958 | Acc: 64.636,84.816,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.961 | Acc: 64.583,84.785,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.967 | Acc: 64.524,84.709,94.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.974 | Acc: 64.447,84.614,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.977 | Acc: 64.457,84.584,94.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.982 | Acc: 64.546,84.490,94.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.988 | Acc: 64.536,84.405,94.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.994 | Acc: 64.512,84.301,94.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.354 | Acc: 54.688,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.178 | Acc: 54.985,66.071,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.161 | Acc: 54.916,66.216,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.179 | Acc: 54.905,66.611,71.094,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 1.921 | Acc: 71.094,86.719,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.949 | Acc: 65.141,85.528,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.914 | Acc: 66.120,85.309,94.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.912 | Acc: 65.856,85.412,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.919 | Acc: 65.731,85.185,94.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.917 | Acc: 65.509,85.357,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.919 | Acc: 65.322,85.156,95.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.937 | Acc: 64.877,84.957,95.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.941 | Acc: 64.858,84.948,94.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.945 | Acc: 64.844,84.897,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.948 | Acc: 64.813,84.876,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.957 | Acc: 64.685,84.683,94.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.966 | Acc: 64.526,84.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.972 | Acc: 64.506,84.435,94.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.979 | Acc: 64.402,84.417,94.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.981 | Acc: 64.449,84.401,94.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.993 | Acc: 64.328,84.263,94.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.002 | Acc: 64.280,84.169,94.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.010 | Acc: 64.186,84.107,94.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.015 | Acc: 64.136,84.016,94.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.227 | Acc: 53.125,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.094 | Acc: 54.688,66.071,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.143 | Acc: 54.421,65.511,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.121 | Acc: 54.265,65.343,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 2.035 | Acc: 58.594,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.913 | Acc: 64.509,85.268,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.911 | Acc: 64.653,85.290,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.901 | Acc: 64.716,85.592,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.890 | Acc: 64.969,85.465,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.912 | Acc: 64.790,85.311,95.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.926 | Acc: 64.644,85.046,94.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.940 | Acc: 64.539,84.818,94.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.951 | Acc: 64.407,84.807,94.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.964 | Acc: 64.218,84.643,94.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.965 | Acc: 64.125,84.694,94.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.962 | Acc: 64.289,84.736,94.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.966 | Acc: 64.299,84.706,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.974 | Acc: 64.239,84.641,94.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.982 | Acc: 64.132,84.533,94.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.990 | Acc: 64.143,84.367,94.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.998 | Acc: 64.053,84.273,94.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.005 | Acc: 64.037,84.201,94.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.011 | Acc: 63.963,84.111,94.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.018 | Acc: 63.929,83.985,94.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.629 | Acc: 63.281,71.875,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.001 | Acc: 55.097,67.932,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.073 | Acc: 54.611,67.016,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.049 | Acc: 54.393,67.226,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 2.001 | Acc: 68.750,82.812,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.953 | Acc: 63.504,84.821,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.935 | Acc: 64.139,84.870,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.944 | Acc: 64.280,84.951,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.954 | Acc: 64.188,84.925,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.950 | Acc: 64.209,84.839,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.956 | Acc: 64.127,84.885,94.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.967 | Acc: 63.813,84.785,94.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.963 | Acc: 63.980,84.855,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.959 | Acc: 64.058,84.906,94.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.952 | Acc: 64.292,84.985,94.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.958 | Acc: 64.321,84.930,94.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.964 | Acc: 64.299,84.826,94.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.977 | Acc: 64.269,84.614,94.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.983 | Acc: 64.171,84.528,94.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.990 | Acc: 64.104,84.453,94.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.993 | Acc: 64.033,84.433,94.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.992 | Acc: 64.095,84.430,94.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.991 | Acc: 64.097,84.442,94.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.996 | Acc: 64.110,84.389,94.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.333 | Acc: 55.469,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.206 | Acc: 53.088,65.699,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.233 | Acc: 52.229,64.844,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.252 | Acc: 52.331,64.895,71.183,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 1.853 | Acc: 66.406,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 65.253,83.743,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.975 | Acc: 64.539,84.604,94.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.982 | Acc: 64.447,84.311,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.983 | Acc: 64.545,84.221,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.983 | Acc: 64.442,84.228,94.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.990 | Acc: 64.489,84.033,94.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.985 | Acc: 64.506,83.998,94.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.977 | Acc: 64.417,84.113,94.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.970 | Acc: 64.619,84.258,94.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.974 | Acc: 64.424,84.247,94.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.971 | Acc: 64.437,84.304,94.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.981 | Acc: 64.345,84.326,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.980 | Acc: 64.374,84.309,94.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.988 | Acc: 64.288,84.233,94.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.999 | Acc: 64.166,84.134,94.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.008 | Acc: 64.121,83.995,94.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.012 | Acc: 64.051,83.905,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.020 | Acc: 63.959,83.849,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.026 | Acc: 63.913,83.797,94.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.330 | Acc: 56.250,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.081 | Acc: 52.976,67.820,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.090 | Acc: 52.782,67.492,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.097 | Acc: 52.600,67.213,72.041,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 1.694 | Acc: 67.188,90.625,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.846 | Acc: 65.699,85.565,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.879 | Acc: 65.149,85.652,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.894 | Acc: 64.793,85.425,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.914 | Acc: 64.660,85.397,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.935 | Acc: 64.643,85.125,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.939 | Acc: 64.573,85.156,95.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.928 | Acc: 64.644,85.378,95.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.926 | Acc: 64.756,85.389,95.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.936 | Acc: 64.667,85.243,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.947 | Acc: 64.502,85.059,94.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.952 | Acc: 64.465,85.004,94.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.962 | Acc: 64.296,84.910,94.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.967 | Acc: 64.299,84.785,94.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.982 | Acc: 64.185,84.592,94.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.987 | Acc: 64.112,84.541,94.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.995 | Acc: 64.075,84.455,94.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.002 | Acc: 64.074,84.345,94.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.008 | Acc: 64.080,84.182,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.015 | Acc: 64.036,84.096,94.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.733 | Acc: 51.562,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.218 | Acc: 51.079,67.262,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.267 | Acc: 50.400,66.521,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.254 | Acc: 50.704,66.534,70.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 1.729 | Acc: 64.062,89.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.917 | Acc: 64.695,85.900,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.916 | Acc: 64.748,85.995,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.928 | Acc: 64.639,85.938,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.905 | Acc: 64.940,86.073,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.899 | Acc: 64.906,85.922,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.903 | Acc: 64.947,85.802,94.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.909 | Acc: 64.805,85.638,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.911 | Acc: 64.819,85.540,94.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.917 | Acc: 64.714,85.519,94.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.918 | Acc: 64.813,85.522,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.935 | Acc: 64.632,85.269,94.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.945 | Acc: 64.546,85.127,94.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.959 | Acc: 64.383,84.881,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.967 | Acc: 64.321,84.817,94.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.972 | Acc: 64.345,84.725,94.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.982 | Acc: 64.299,84.594,94.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.993 | Acc: 64.246,84.462,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.996 | Acc: 64.225,84.466,94.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.001 | Acc: 64.140,84.416,94.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.928 | Acc: 58.594,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.106 | Acc: 55.394,64.881,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.097 | Acc: 55.736,64.672,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.132 | Acc: 55.661,64.869,70.825,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 1.864 | Acc: 59.375,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.907 | Acc: 63.876,85.714,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.919 | Acc: 63.967,85.575,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.935 | Acc: 64.293,85.502,95.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.930 | Acc: 64.651,85.600,95.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.948 | Acc: 64.658,85.350,94.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.950 | Acc: 64.734,85.189,94.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.955 | Acc: 64.600,84.935,94.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.960 | Acc: 64.572,84.807,94.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.970 | Acc: 64.542,84.729,94.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.980 | Acc: 64.459,84.534,94.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.985 | Acc: 64.398,84.485,94.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.993 | Acc: 64.260,84.450,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.996 | Acc: 64.254,84.387,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.996 | Acc: 64.268,84.408,94.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.997 | Acc: 64.384,84.419,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.000 | Acc: 64.432,84.377,94.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.002 | Acc: 64.372,84.343,94.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.007 | Acc: 64.346,84.273,94.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.013 | Acc: 64.331,84.217,94.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.975 | Acc: 57.812,71.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.088 | Acc: 52.381,67.894,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.161 | Acc: 52.096,66.978,71.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.183 | Acc: 52.036,67.367,71.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 1.727 | Acc: 75.000,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.915 | Acc: 65.997,84.970,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.927 | Acc: 65.339,85.080,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.929 | Acc: 64.972,85.246,94.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.928 | Acc: 65.008,85.301,94.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.935 | Acc: 64.766,85.265,94.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.923 | Acc: 64.708,85.376,94.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.933 | Acc: 64.600,85.311,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.935 | Acc: 64.591,85.117,94.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.943 | Acc: 64.516,85.053,94.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.955 | Acc: 64.288,84.845,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.959 | Acc: 64.335,84.796,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.967 | Acc: 64.354,84.667,94.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.969 | Acc: 64.467,84.629,94.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.975 | Acc: 64.446,84.664,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.984 | Acc: 64.322,84.507,94.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.990 | Acc: 64.265,84.438,94.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.996 | Acc: 64.172,84.354,94.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.001 | Acc: 64.236,84.340,94.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.008 | Acc: 64.173,84.209,94.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.450 | Acc: 52.344,71.875,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.106 | Acc: 51.488,66.555,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.125 | Acc: 51.639,66.997,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.126 | Acc: 51.588,67.111,71.350,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 2.286 | Acc: 56.250,82.031,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.009 | Acc: 64.621,84.598,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.994 | Acc: 64.882,84.470,93.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.950 | Acc: 65.279,84.939,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.943 | Acc: 65.220,84.886,94.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.926 | Acc: 65.370,84.971,94.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.915 | Acc: 65.677,85.124,94.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.923 | Acc: 65.398,84.990,94.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.922 | Acc: 65.329,85.011,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.931 | Acc: 65.142,85.005,94.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.935 | Acc: 64.995,84.970,94.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.953 | Acc: 64.759,84.679,94.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.961 | Acc: 64.656,84.579,94.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.968 | Acc: 64.541,84.516,94.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.974 | Acc: 64.630,84.450,94.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.984 | Acc: 64.475,84.315,94.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.990 | Acc: 64.440,84.268,94.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.999 | Acc: 64.363,84.196,94.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.998 | Acc: 64.426,84.202,94.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.007 | Acc: 64.218,84.160,94.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.622 | Acc: 53.125,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.189 | Acc: 50.707,66.853,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.137 | Acc: 51.753,67.188,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.141 | Acc: 51.742,67.380,71.337,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 1.770 | Acc: 67.969,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.942 | Acc: 64.807,85.342,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.917 | Acc: 65.263,85.156,95.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.903 | Acc: 65.177,85.630,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.919 | Acc: 64.805,85.340,95.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.920 | Acc: 64.882,85.334,95.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.926 | Acc: 64.676,85.292,94.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.937 | Acc: 64.589,85.112,94.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.948 | Acc: 64.422,84.967,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.963 | Acc: 64.209,84.893,94.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.966 | Acc: 64.179,84.857,94.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.975 | Acc: 64.080,84.827,94.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.985 | Acc: 64.011,84.706,94.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.991 | Acc: 64.054,84.594,94.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.000 | Acc: 64.037,84.584,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.008 | Acc: 64.078,84.424,94.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.016 | Acc: 64.016,84.375,93.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.025 | Acc: 64.010,84.233,93.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.032 | Acc: 63.965,84.187,93.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.032 | Acc: 64.001,84.178,93.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.122 | Acc: 56.250,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.224 | Acc: 52.269,66.071,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.267 | Acc: 52.115,65.568,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.259 | Acc: 51.934,65.779,71.209,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 1.983 | Acc: 66.406,85.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.950 | Acc: 64.918,84.747,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.916 | Acc: 65.320,85.347,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.935 | Acc: 64.997,85.105,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.921 | Acc: 65.249,85.253,94.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.927 | Acc: 65.138,85.272,94.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.952 | Acc: 64.766,84.917,94.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.955 | Acc: 64.883,84.807,94.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.974 | Acc: 64.659,84.477,94.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.970 | Acc: 64.524,84.552,94.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.979 | Acc: 64.408,84.410,94.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.982 | Acc: 64.317,84.389,94.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.990 | Acc: 64.137,84.365,94.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.998 | Acc: 64.113,84.228,94.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.997 | Acc: 64.104,84.319,94.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.004 | Acc: 64.109,84.178,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.007 | Acc: 64.133,84.156,94.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.012 | Acc: 64.122,84.116,93.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.018 | Acc: 64.039,84.091,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.024 | Acc: 64.030,83.920,93.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.939 | Acc: 57.031,72.656,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.343 | Acc: 52.158,66.964,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.382 | Acc: 52.191,66.349,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.340 | Acc: 52.677,66.368,71.081,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 2.241 | Acc: 64.062,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.889 | Acc: 64.769,85.677,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.932 | Acc: 64.310,85.404,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.940 | Acc: 63.998,85.540,94.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.930 | Acc: 64.400,85.407,94.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.937 | Acc: 64.256,85.125,94.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.935 | Acc: 64.392,85.150,94.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.924 | Acc: 64.528,85.206,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.929 | Acc: 64.562,85.185,94.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.930 | Acc: 64.593,85.225,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.932 | Acc: 64.556,85.113,94.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.933 | Acc: 64.515,85.075,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.941 | Acc: 64.584,84.952,94.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.945 | Acc: 64.595,84.881,94.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.950 | Acc: 64.532,84.806,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.957 | Acc: 64.514,84.705,94.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.958 | Acc: 64.552,84.708,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.969 | Acc: 64.441,84.606,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.978 | Acc: 64.389,84.583,94.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.984 | Acc: 64.391,84.527,94.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.942 | Acc: 54.688,67.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.923 | Acc: 55.283,68.713,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.888 | Acc: 54.764,68.388,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.936 | Acc: 54.880,68.020,72.080,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 1.844 | Acc: 64.062,85.938,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.949 | Acc: 64.360,85.342,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.949 | Acc: 64.329,85.518,94.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.929 | Acc: 64.728,85.540,94.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.920 | Acc: 64.969,85.677,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.912 | Acc: 65.076,85.620,94.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.913 | Acc: 65.464,85.440,94.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.916 | Acc: 65.459,85.345,94.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.909 | Acc: 65.528,85.418,94.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.923 | Acc: 65.198,85.385,94.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.925 | Acc: 65.225,85.389,94.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.932 | Acc: 65.088,85.273,94.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.938 | Acc: 65.080,85.156,94.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.948 | Acc: 64.981,84.971,94.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.960 | Acc: 64.835,84.864,94.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.968 | Acc: 64.846,84.715,94.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.974 | Acc: 64.759,84.528,94.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.978 | Acc: 64.770,84.457,94.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.986 | Acc: 64.651,84.306,94.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.991 | Acc: 64.583,84.258,94.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.931 | Acc: 55.469,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.245 | Acc: 52.232,68.080,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.197 | Acc: 52.153,68.083,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.254 | Acc: 52.036,67.943,70.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 1.745 | Acc: 64.844,87.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.858 | Acc: 65.848,86.012,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.870 | Acc: 65.263,86.147,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.886 | Acc: 65.420,85.950,95.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.898 | Acc: 65.557,85.542,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.892 | Acc: 65.416,85.837,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.905 | Acc: 65.192,85.744,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.906 | Acc: 65.016,85.633,95.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.912 | Acc: 64.902,85.438,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.920 | Acc: 64.861,85.238,95.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.928 | Acc: 64.832,85.191,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.932 | Acc: 64.823,85.096,94.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.937 | Acc: 64.834,85.062,94.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.947 | Acc: 64.706,84.995,94.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.952 | Acc: 64.719,84.839,94.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.958 | Acc: 64.688,84.811,94.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.964 | Acc: 64.642,84.745,94.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.972 | Acc: 64.509,84.636,94.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.978 | Acc: 64.474,84.594,94.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.984 | Acc: 64.427,84.475,94.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.822 | Acc: 63.281,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.172 | Acc: 54.762,66.815,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.157 | Acc: 54.440,66.540,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.167 | Acc: 54.623,66.944,71.107,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 1.923 | Acc: 63.281,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.898 | Acc: 65.513,85.900,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.846 | Acc: 66.482,86.433,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.878 | Acc: 65.663,85.745,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.890 | Acc: 65.172,85.417,94.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.887 | Acc: 65.246,85.512,95.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.892 | Acc: 64.992,85.628,95.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.909 | Acc: 64.733,85.505,94.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.916 | Acc: 64.766,85.418,94.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.927 | Acc: 64.701,85.372,94.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.935 | Acc: 64.669,85.226,94.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.947 | Acc: 64.586,85.040,94.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.956 | Acc: 64.581,84.819,94.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.962 | Acc: 64.601,84.704,94.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.973 | Acc: 64.441,84.522,94.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.981 | Acc: 64.408,84.388,94.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.992 | Acc: 64.308,84.197,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.999 | Acc: 64.243,84.157,94.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.002 | Acc: 64.350,84.137,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.006 | Acc: 64.327,84.067,94.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.014 | Acc: 53.906,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.071 | Acc: 54.055,67.634,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.080 | Acc: 53.449,67.511,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.103 | Acc: 53.624,67.725,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 1.916 | Acc: 62.500,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.808 | Acc: 65.662,87.574,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.719 | Acc: 67.245,88.110,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.669 | Acc: 67.649,88.806,96.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.603 | Acc: 68.576,89.487,97.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.572 | Acc: 68.936,89.851,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.538 | Acc: 69.460,90.173,97.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.516 | Acc: 69.686,90.370,97.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.494 | Acc: 69.949,90.581,97.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.476 | Acc: 70.269,90.742,97.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.469 | Acc: 70.211,90.882,97.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.456 | Acc: 70.447,90.964,97.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.445 | Acc: 70.552,91.147,98.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.436 | Acc: 70.744,91.236,98.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.426 | Acc: 70.924,91.342,98.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.419 | Acc: 71.050,91.396,98.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.412 | Acc: 71.111,91.467,98.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.404 | Acc: 71.197,91.555,98.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.398 | Acc: 71.217,91.601,98.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.392 | Acc: 71.286,91.677,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.068 | Acc: 62.500,72.656,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.181 | Acc: 63.170,74.256,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.188 | Acc: 63.281,73.628,76.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.194 | Acc: 63.409,73.988,76.665,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 1.379 | Acc: 71.875,91.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.228 | Acc: 73.772,93.713,99.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.232 | Acc: 73.704,93.693,99.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.225 | Acc: 73.630,93.724,99.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.228 | Acc: 73.524,93.721,99.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.239 | Acc: 73.252,93.510,99.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.238 | Acc: 73.315,93.673,99.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.238 | Acc: 73.260,93.711,99.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.239 | Acc: 73.345,93.614,99.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.239 | Acc: 73.343,93.638,99.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.229 | Acc: 73.589,93.692,99.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.229 | Acc: 73.515,93.729,99.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.231 | Acc: 73.389,93.679,99.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.225 | Acc: 73.452,93.750,99.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.225 | Acc: 73.468,93.708,99.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.225 | Acc: 73.357,93.727,99.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.224 | Acc: 73.326,93.733,99.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.223 | Acc: 73.396,93.755,99.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.223 | Acc: 73.396,93.756,99.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.220 | Acc: 73.456,93.773,99.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.104 | Acc: 64.062,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.127 | Acc: 64.583,74.926,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.138 | Acc: 64.139,74.276,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.148 | Acc: 64.062,74.436,77.267,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.283 | Acc: 66.406,92.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.160 | Acc: 73.884,94.122,99.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.182 | Acc: 73.342,94.550,99.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.169 | Acc: 73.438,94.749,99.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.169 | Acc: 73.640,94.589,99.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.166 | Acc: 73.646,94.663,99.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.161 | Acc: 73.825,94.686,99.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.158 | Acc: 74.025,94.609,99.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.160 | Acc: 73.928,94.551,99.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.159 | Acc: 73.955,94.561,99.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.158 | Acc: 74.009,94.547,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.153 | Acc: 74.194,94.570,99.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.153 | Acc: 74.225,94.577,99.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.153 | Acc: 74.180,94.561,99.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.151 | Acc: 74.199,94.559,99.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.153 | Acc: 74.107,94.565,99.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.154 | Acc: 74.090,94.587,99.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.155 | Acc: 74.074,94.577,99.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.156 | Acc: 74.013,94.559,99.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.155 | Acc: 74.026,94.552,99.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.050 | Acc: 64.062,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.145 | Acc: 64.137,74.516,77.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.156 | Acc: 63.872,74.352,77.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.165 | Acc: 64.037,74.552,77.088,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.124 | Acc: 74.219,93.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.098 | Acc: 74.330,95.647,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.095 | Acc: 75.305,95.598,99.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.104 | Acc: 75.038,95.620,99.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.117 | Acc: 74.711,95.351,99.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.120 | Acc: 74.551,95.289,99.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.120 | Acc: 74.483,95.248,99.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.124 | Acc: 74.330,95.252,99.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.123 | Acc: 74.296,95.283,99.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.118 | Acc: 74.430,95.338,99.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.121 | Acc: 74.343,95.243,99.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.119 | Acc: 74.431,95.252,99.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.120 | Acc: 74.475,95.173,99.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.119 | Acc: 74.494,95.166,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.117 | Acc: 74.433,95.162,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.118 | Acc: 74.463,95.128,99.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.116 | Acc: 74.494,95.142,99.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.116 | Acc: 74.471,95.136,99.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.115 | Acc: 74.478,95.150,99.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.119 | Acc: 74.426,95.109,99.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.035 | Acc: 63.281,75.781,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.158 | Acc: 63.690,74.554,77.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.162 | Acc: 63.872,74.143,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.167 | Acc: 64.331,74.411,77.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.078 | Acc: 73.438,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.116 | Acc: 74.182,94.903,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.129 | Acc: 74.276,95.255,99.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.114 | Acc: 74.744,95.517,99.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.104 | Acc: 74.797,95.708,99.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.097 | Acc: 74.799,95.769,99.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.093 | Acc: 74.903,95.700,99.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.089 | Acc: 74.873,95.695,99.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.089 | Acc: 74.879,95.657,99.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.091 | Acc: 74.776,95.649,99.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.091 | Acc: 74.767,95.647,99.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.094 | Acc: 74.629,95.620,99.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.095 | Acc: 74.656,95.595,99.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.095 | Acc: 74.512,95.606,99.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.095 | Acc: 74.558,95.566,99.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.095 | Acc: 74.580,95.520,99.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.093 | Acc: 74.632,95.561,99.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.090 | Acc: 74.684,95.560,99.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.088 | Acc: 74.688,95.592,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.089 | Acc: 74.686,95.579,99.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.108 | Acc: 63.281,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.117 | Acc: 63.988,75.186,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.139 | Acc: 64.024,74.638,77.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.150 | Acc: 64.357,74.757,77.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.065 | Acc: 78.906,92.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.069 | Acc: 74.628,95.796,99.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.079 | Acc: 74.352,95.751,99.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.073 | Acc: 74.718,95.761,99.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.068 | Acc: 74.836,95.698,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.075 | Acc: 74.621,95.637,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.068 | Acc: 74.890,95.861,99.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.072 | Acc: 74.934,95.817,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.075 | Acc: 74.733,95.832,99.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.071 | Acc: 74.737,95.869,99.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.068 | Acc: 74.716,95.829,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.072 | Acc: 74.558,95.850,99.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.076 | Acc: 74.494,95.828,99.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.073 | Acc: 74.623,95.836,99.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.073 | Acc: 74.708,95.802,99.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.073 | Acc: 74.714,95.787,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.074 | Acc: 74.769,95.782,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.071 | Acc: 74.842,95.807,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.072 | Acc: 74.814,95.789,99.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.071 | Acc: 74.846,95.770,99.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.078 | Acc: 63.281,75.000,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.147 | Acc: 64.100,75.112,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.171 | Acc: 63.739,74.352,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.173 | Acc: 64.037,74.654,77.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.101 | Acc: 72.656,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.033 | Acc: 75.670,95.982,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.045 | Acc: 75.419,96.246,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.040 | Acc: 75.410,96.235,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.038 | Acc: 75.511,96.161,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.043 | Acc: 75.387,96.040,99.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.039 | Acc: 75.368,96.113,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.042 | Acc: 75.421,96.110,99.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.046 | Acc: 75.267,96.152,99.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.050 | Acc: 75.207,96.115,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.049 | Acc: 75.183,96.140,99.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.052 | Acc: 75.081,96.104,99.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.052 | Acc: 75.126,96.123,99.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.050 | Acc: 75.189,96.106,99.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.050 | Acc: 75.206,96.119,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.049 | Acc: 75.210,96.107,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.048 | Acc: 75.178,96.086,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.048 | Acc: 75.202,96.110,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.051 | Acc: 75.173,96.053,99.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.051 | Acc: 75.162,96.038,99.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.190 | Acc: 66.406,76.562,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.175 | Acc: 63.802,75.112,78.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.191 | Acc: 63.167,74.428,77.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.191 | Acc: 63.525,74.552,77.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 0.991 | Acc: 75.000,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.043 | Acc: 74.963,96.317,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.047 | Acc: 74.600,96.227,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.035 | Acc: 74.962,96.260,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.021 | Acc: 75.299,96.296,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.019 | Acc: 75.317,96.310,99.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.012 | Acc: 75.607,96.313,99.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.017 | Acc: 75.382,96.299,99.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.026 | Acc: 75.180,96.230,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.028 | Acc: 75.181,96.228,99.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.032 | Acc: 75.218,96.183,99.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.031 | Acc: 75.322,96.189,99.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.029 | Acc: 75.395,96.253,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.031 | Acc: 75.353,96.249,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.032 | Acc: 75.375,96.233,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.034 | Acc: 75.291,96.239,99.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.037 | Acc: 75.290,96.232,99.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.036 | Acc: 75.293,96.245,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.036 | Acc: 75.279,96.237,99.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.035 | Acc: 75.299,96.231,99.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.083 | Acc: 66.406,77.344,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.133 | Acc: 64.323,75.670,78.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.151 | Acc: 64.520,74.676,77.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.166 | Acc: 64.524,74.769,77.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 0.968 | Acc: 74.219,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.985 | Acc: 75.930,97.321,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.985 | Acc: 75.648,96.932,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.997 | Acc: 75.973,96.619,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.009 | Acc: 75.762,96.518,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.013 | Acc: 75.596,96.558,99.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.013 | Acc: 75.523,96.552,99.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.017 | Acc: 75.460,96.476,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.014 | Acc: 75.558,96.511,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.019 | Acc: 75.522,96.452,99.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.021 | Acc: 75.501,96.451,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.018 | Acc: 75.601,96.490,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.020 | Acc: 75.629,96.515,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.020 | Acc: 75.593,96.504,99.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.017 | Acc: 75.701,96.489,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.020 | Acc: 75.589,96.449,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.020 | Acc: 75.621,96.417,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.019 | Acc: 75.676,96.437,99.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.017 | Acc: 75.690,96.451,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.018 | Acc: 75.666,96.442,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.129 | Acc: 62.500,75.000,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.167 | Acc: 64.509,74.888,78.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.180 | Acc: 64.158,74.466,77.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.198 | Acc: 64.460,74.539,77.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 0.856 | Acc: 78.906,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.977 | Acc: 76.451,96.726,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.981 | Acc: 75.972,96.704,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.980 | Acc: 76.101,96.555,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.981 | Acc: 76.408,96.624,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.989 | Acc: 76.075,96.651,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.993 | Acc: 75.981,96.707,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.989 | Acc: 76.125,96.676,99.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.992 | Acc: 76.179,96.628,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.996 | Acc: 76.045,96.638,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.997 | Acc: 76.096,96.677,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.999 | Acc: 75.954,96.695,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.000 | Acc: 75.979,96.697,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.002 | Acc: 75.946,96.683,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.003 | Acc: 75.879,96.703,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.003 | Acc: 75.890,96.740,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.003 | Acc: 75.891,96.741,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.001 | Acc: 75.905,96.715,99.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.003 | Acc: 75.907,96.724,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.001 | Acc: 75.956,96.738,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.128 | Acc: 64.062,76.562,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.153 | Acc: 64.323,75.298,78.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.181 | Acc: 64.120,74.466,77.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.188 | Acc: 64.319,74.513,77.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 0.955 | Acc: 78.125,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.973 | Acc: 76.674,96.912,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.983 | Acc: 76.391,97.085,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.984 | Acc: 76.178,97.157,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.987 | Acc: 76.341,97.106,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.985 | Acc: 76.292,97.045,99.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.988 | Acc: 76.052,97.004,99.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.989 | Acc: 76.064,96.975,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.986 | Acc: 76.242,97.001,99.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.987 | Acc: 76.252,97.013,99.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.984 | Acc: 76.318,97.038,99.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.988 | Acc: 76.251,96.939,99.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.988 | Acc: 76.235,96.963,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.989 | Acc: 76.114,96.932,99.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.992 | Acc: 76.023,96.842,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.993 | Acc: 75.989,96.815,99.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.994 | Acc: 75.944,96.804,99.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.994 | Acc: 75.894,96.781,99.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.994 | Acc: 75.928,96.780,99.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.992 | Acc: 75.978,96.789,99.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.157 | Acc: 63.281,76.562,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.184 | Acc: 64.546,75.744,77.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.206 | Acc: 64.367,74.714,77.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.211 | Acc: 64.562,74.539,77.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.068 | Acc: 80.469,94.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.002 | Acc: 77.158,96.689,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.987 | Acc: 76.944,96.684,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.978 | Acc: 76.857,96.888,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.981 | Acc: 76.746,96.885,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.980 | Acc: 76.787,96.945,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.973 | Acc: 76.847,96.972,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.976 | Acc: 76.828,96.925,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.981 | Acc: 76.684,96.899,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.982 | Acc: 76.554,96.931,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.982 | Acc: 76.446,96.957,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.979 | Acc: 76.520,96.970,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.979 | Acc: 76.511,96.985,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.977 | Acc: 76.497,97.034,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.980 | Acc: 76.351,97.036,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.979 | Acc: 76.373,97.039,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.979 | Acc: 76.324,97.019,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.980 | Acc: 76.278,97.040,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.982 | Acc: 76.199,97.029,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.983 | Acc: 76.152,97.006,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.198 | Acc: 64.844,77.344,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.221 | Acc: 64.286,75.260,78.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.233 | Acc: 64.101,74.409,77.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.237 | Acc: 64.088,74.424,77.792,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 0.999 | Acc: 69.531,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.983 | Acc: 76.116,97.470,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.968 | Acc: 76.220,97.275,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.974 | Acc: 76.063,97.144,99.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.973 | Acc: 76.302,97.155,99.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.976 | Acc: 76.114,97.200,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.979 | Acc: 76.027,97.178,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.979 | Acc: 76.025,97.180,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.975 | Acc: 76.072,97.200,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.972 | Acc: 76.131,97.216,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.971 | Acc: 76.193,97.174,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.970 | Acc: 76.213,97.197,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.971 | Acc: 76.206,97.164,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.972 | Acc: 76.224,97.162,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.974 | Acc: 76.170,97.164,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.973 | Acc: 76.176,97.176,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.977 | Acc: 76.059,97.162,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.977 | Acc: 76.157,97.150,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.975 | Acc: 76.201,97.165,99.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.976 | Acc: 76.195,97.123,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.302 | Acc: 64.844,75.000,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.208 | Acc: 64.546,74.963,77.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.223 | Acc: 64.158,74.371,77.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.224 | Acc: 64.357,74.513,77.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 1.207 | Acc: 71.094,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.000 | Acc: 75.335,97.619,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.973 | Acc: 76.086,97.580,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.961 | Acc: 76.217,97.413,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.957 | Acc: 76.437,97.386,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.960 | Acc: 76.493,97.386,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.964 | Acc: 76.246,97.372,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.966 | Acc: 76.374,97.291,99.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.967 | Acc: 76.286,97.249,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.968 | Acc: 76.299,97.225,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.967 | Acc: 76.275,97.248,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.969 | Acc: 76.230,97.243,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.964 | Acc: 76.332,97.238,99.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.963 | Acc: 76.350,97.240,99.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.961 | Acc: 76.387,97.253,99.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.960 | Acc: 76.435,97.231,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.958 | Acc: 76.514,97.245,99.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.959 | Acc: 76.494,97.219,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.959 | Acc: 76.526,97.189,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.960 | Acc: 76.538,97.154,99.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.136 | Acc: 63.281,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.187 | Acc: 64.807,75.298,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.214 | Acc: 64.577,74.352,77.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.213 | Acc: 64.639,74.321,77.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 0.817 | Acc: 82.031,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.940 | Acc: 77.716,97.582,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.938 | Acc: 76.810,97.542,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.938 | Acc: 76.960,97.490,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.946 | Acc: 76.794,97.463,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.952 | Acc: 76.562,97.362,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.952 | Acc: 76.466,97.417,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.952 | Acc: 76.385,97.435,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.948 | Acc: 76.606,97.433,99.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.945 | Acc: 76.752,97.440,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.947 | Acc: 76.675,97.411,99.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.947 | Acc: 76.711,97.426,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.945 | Acc: 76.864,97.436,99.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.948 | Acc: 76.793,97.390,99.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.949 | Acc: 76.799,97.392,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.951 | Acc: 76.721,97.373,99.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.952 | Acc: 76.728,97.340,99.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.952 | Acc: 76.714,97.308,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.954 | Acc: 76.673,97.291,99.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.957 | Acc: 76.585,97.250,99.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.216 | Acc: 64.844,75.781,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.196 | Acc: 64.918,75.037,78.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.223 | Acc: 64.463,74.028,78.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.225 | Acc: 64.408,74.283,77.984,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 0.960 | Acc: 75.781,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.902 | Acc: 77.530,98.177,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.939 | Acc: 76.905,97.694,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.935 | Acc: 77.126,97.541,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.933 | Acc: 76.997,97.656,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.940 | Acc: 76.895,97.579,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.934 | Acc: 77.266,97.559,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.930 | Acc: 77.189,97.584,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.936 | Acc: 77.174,97.525,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.936 | Acc: 77.115,97.544,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.933 | Acc: 77.192,97.551,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.935 | Acc: 77.068,97.554,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.935 | Acc: 77.078,97.565,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.935 | Acc: 77.077,97.590,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.938 | Acc: 77.041,97.581,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.938 | Acc: 77.012,97.576,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.940 | Acc: 76.988,97.549,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.942 | Acc: 76.945,97.512,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.945 | Acc: 76.844,97.509,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.945 | Acc: 76.823,97.507,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.134 | Acc: 64.844,77.344,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.179 | Acc: 65.104,75.149,78.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.214 | Acc: 64.558,74.371,77.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.223 | Acc: 64.472,74.321,78.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 1.082 | Acc: 77.344,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.934 | Acc: 77.232,97.768,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.928 | Acc: 77.268,97.923,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.920 | Acc: 77.690,97.912,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.923 | Acc: 77.508,97.878,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.917 | Acc: 77.537,97.873,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.921 | Acc: 77.434,97.760,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.922 | Acc: 77.416,97.728,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.922 | Acc: 77.247,97.705,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.925 | Acc: 77.059,97.738,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.924 | Acc: 77.021,97.785,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.929 | Acc: 77.036,97.723,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.931 | Acc: 76.919,97.698,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.934 | Acc: 76.838,97.659,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.934 | Acc: 76.902,97.645,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.934 | Acc: 76.949,97.589,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.933 | Acc: 76.913,97.578,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.935 | Acc: 76.881,97.535,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.937 | Acc: 76.772,97.507,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.939 | Acc: 76.763,97.507,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.183 | Acc: 62.500,75.781,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.206 | Acc: 64.025,75.112,78.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.230 | Acc: 63.815,74.409,77.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.235 | Acc: 63.986,74.321,77.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.105 | Acc: 71.875,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.929 | Acc: 77.158,97.619,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.928 | Acc: 77.363,97.580,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.949 | Acc: 76.639,97.528,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.951 | Acc: 76.640,97.425,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.941 | Acc: 76.679,97.556,99.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.935 | Acc: 76.853,97.579,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.934 | Acc: 76.950,97.662,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.931 | Acc: 77.111,97.681,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.930 | Acc: 77.055,97.686,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.934 | Acc: 76.908,97.691,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.935 | Acc: 76.863,97.688,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.932 | Acc: 76.990,97.653,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.930 | Acc: 76.967,97.704,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.929 | Acc: 77.018,97.695,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.930 | Acc: 77.014,97.682,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.931 | Acc: 77.044,97.678,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.933 | Acc: 77.009,97.675,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.935 | Acc: 76.982,97.626,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.933 | Acc: 77.016,97.636,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.185 | Acc: 64.844,78.125,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.232 | Acc: 63.951,75.000,78.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.258 | Acc: 63.605,74.181,77.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.254 | Acc: 63.717,74.347,78.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 0.960 | Acc: 71.875,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.898 | Acc: 77.827,97.917,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.907 | Acc: 77.363,97.809,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.917 | Acc: 77.280,97.797,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.921 | Acc: 77.074,97.782,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.924 | Acc: 77.065,97.749,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.925 | Acc: 76.931,97.766,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.927 | Acc: 76.828,97.712,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.928 | Acc: 76.854,97.661,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.928 | Acc: 76.882,97.678,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.928 | Acc: 76.916,97.703,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.927 | Acc: 77.019,97.685,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.926 | Acc: 77.055,97.689,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.923 | Acc: 77.086,97.722,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.922 | Acc: 77.130,97.742,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.923 | Acc: 77.144,97.747,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.922 | Acc: 77.205,97.751,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.924 | Acc: 77.183,97.730,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.925 | Acc: 77.194,97.700,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.924 | Acc: 77.237,97.720,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.152 | Acc: 64.844,75.781,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.227 | Acc: 64.286,74.628,78.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.248 | Acc: 63.986,74.047,77.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.253 | Acc: 63.947,74.129,77.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 1.041 | Acc: 74.219,95.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.928 | Acc: 77.158,97.768,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.925 | Acc: 76.867,98.095,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.924 | Acc: 77.075,98.079,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.915 | Acc: 77.296,98.061,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.910 | Acc: 77.266,98.097,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.909 | Acc: 77.621,98.069,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.918 | Acc: 77.294,97.994,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.916 | Acc: 77.455,97.996,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.914 | Acc: 77.491,98.006,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.915 | Acc: 77.468,97.948,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.914 | Acc: 77.418,97.928,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.915 | Acc: 77.337,97.919,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.915 | Acc: 77.365,97.881,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.914 | Acc: 77.344,97.868,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.913 | Acc: 77.367,97.846,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.915 | Acc: 77.344,97.812,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.914 | Acc: 77.403,97.805,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.916 | Acc: 77.285,97.784,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.918 | Acc: 77.227,97.769,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.095 | Acc: 65.625,78.125,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.212 | Acc: 64.769,75.074,78.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.236 | Acc: 64.120,74.447,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.244 | Acc: 64.255,74.577,78.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 0.897 | Acc: 78.906,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.944 | Acc: 76.488,97.507,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.925 | Acc: 77.115,97.713,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.902 | Acc: 77.792,97.848,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.892 | Acc: 77.797,97.955,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.899 | Acc: 77.506,97.973,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.907 | Acc: 77.421,97.979,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.912 | Acc: 77.266,97.978,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.910 | Acc: 77.290,97.991,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.908 | Acc: 77.391,97.950,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.908 | Acc: 77.371,97.932,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.912 | Acc: 77.298,97.893,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.910 | Acc: 77.444,97.896,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.910 | Acc: 77.541,97.896,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.912 | Acc: 77.486,97.851,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.911 | Acc: 77.484,97.851,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.912 | Acc: 77.426,97.853,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.912 | Acc: 77.403,97.876,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.912 | Acc: 77.387,97.862,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.914 | Acc: 77.358,97.837,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.308 | Acc: 65.625,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.281 | Acc: 64.249,74.851,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.286 | Acc: 63.853,74.162,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.301 | Acc: 63.858,73.988,77.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 0.748 | Acc: 79.688,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.856 | Acc: 79.241,98.400,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.869 | Acc: 78.620,98.114,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.888 | Acc: 77.626,97.964,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.895 | Acc: 77.132,97.926,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.892 | Acc: 77.367,97.942,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.889 | Acc: 77.363,97.940,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.884 | Acc: 77.554,97.967,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.890 | Acc: 77.383,97.860,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.889 | Acc: 77.370,97.855,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.892 | Acc: 77.383,97.854,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.898 | Acc: 77.245,97.847,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.899 | Acc: 77.243,97.890,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.901 | Acc: 77.242,97.908,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.906 | Acc: 77.080,97.862,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.904 | Acc: 77.240,97.851,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.905 | Acc: 77.271,97.853,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.908 | Acc: 77.204,97.849,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.910 | Acc: 77.162,97.821,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.911 | Acc: 77.110,97.835,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.251 | Acc: 65.625,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.284 | Acc: 64.583,74.144,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.292 | Acc: 64.139,73.742,77.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.298 | Acc: 64.011,73.783,77.933,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 0.809 | Acc: 77.344,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.903 | Acc: 77.232,97.545,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.888 | Acc: 77.515,97.847,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.888 | Acc: 77.472,97.861,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.897 | Acc: 77.402,97.897,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.900 | Acc: 77.336,97.927,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.898 | Acc: 77.318,97.979,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.901 | Acc: 77.166,97.933,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.902 | Acc: 77.208,97.933,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.904 | Acc: 77.240,97.932,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.901 | Acc: 77.258,97.975,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.899 | Acc: 77.315,97.985,99.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.900 | Acc: 77.350,98.016,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.899 | Acc: 77.460,98.006,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.900 | Acc: 77.455,97.979,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.902 | Acc: 77.448,97.970,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.900 | Acc: 77.463,97.980,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.901 | Acc: 77.463,97.966,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.903 | Acc: 77.400,97.959,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.902 | Acc: 77.457,97.956,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.257 | Acc: 65.625,75.000,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.284 | Acc: 63.690,74.740,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.293 | Acc: 63.586,74.276,77.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.293 | Acc: 63.832,74.398,77.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 0.907 | Acc: 75.781,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.934 | Acc: 76.451,98.251,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.909 | Acc: 77.306,98.095,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.909 | Acc: 77.280,98.143,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.897 | Acc: 77.691,98.139,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.888 | Acc: 77.777,98.198,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.884 | Acc: 77.847,98.250,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.885 | Acc: 77.948,98.221,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.883 | Acc: 78.047,98.224,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.882 | Acc: 77.983,98.183,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.886 | Acc: 77.962,98.185,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.887 | Acc: 78.001,98.169,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.890 | Acc: 77.966,98.152,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.896 | Acc: 77.820,98.066,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.896 | Acc: 77.830,98.045,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.897 | Acc: 77.801,98.059,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.897 | Acc: 77.852,98.021,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.897 | Acc: 77.816,98.018,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.896 | Acc: 77.822,97.994,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.897 | Acc: 77.781,98.005,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.228 | Acc: 64.062,75.000,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.269 | Acc: 63.988,74.293,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.283 | Acc: 64.082,73.952,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.281 | Acc: 64.306,74.091,77.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 0.825 | Acc: 81.250,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.860 | Acc: 78.869,98.177,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.870 | Acc: 78.449,98.209,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 78.215,98.220,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.867 | Acc: 78.337,98.148,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.870 | Acc: 78.156,98.167,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.874 | Acc: 77.983,98.128,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.879 | Acc: 77.892,98.144,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.878 | Acc: 77.960,98.175,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.879 | Acc: 77.926,98.187,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.882 | Acc: 77.880,98.150,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.882 | Acc: 77.934,98.133,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.882 | Acc: 77.956,98.097,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.883 | Acc: 77.972,98.114,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.885 | Acc: 77.919,98.104,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.888 | Acc: 77.847,98.090,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.889 | Acc: 77.770,98.077,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.890 | Acc: 77.738,98.062,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.891 | Acc: 77.746,98.050,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.891 | Acc: 77.750,98.019,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.161 | Acc: 65.625,75.000,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.269 | Acc: 64.025,74.591,78.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.295 | Acc: 63.777,74.219,78.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.299 | Acc: 63.665,74.347,77.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 0.811 | Acc: 85.938,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.862 | Acc: 79.129,97.842,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.868 | Acc: 78.754,98.056,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.876 | Acc: 78.548,98.181,99.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 78.665,98.264,99.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.873 | Acc: 78.303,98.329,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.879 | Acc: 78.073,98.321,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.878 | Acc: 78.053,98.299,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.882 | Acc: 77.955,98.263,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.881 | Acc: 77.866,98.261,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.880 | Acc: 77.911,98.278,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.879 | Acc: 77.969,98.282,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.882 | Acc: 77.862,98.240,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.885 | Acc: 77.763,98.216,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.885 | Acc: 77.750,98.193,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.886 | Acc: 77.686,98.168,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.887 | Acc: 77.684,98.170,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.887 | Acc: 77.669,98.181,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.886 | Acc: 77.697,98.178,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.888 | Acc: 77.602,98.163,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.133 | Acc: 67.188,76.562,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.258 | Acc: 63.653,74.963,78.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.271 | Acc: 63.796,74.447,78.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.270 | Acc: 64.152,74.385,78.074,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 0.911 | Acc: 73.438,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.885 | Acc: 77.902,97.731,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.888 | Acc: 78.049,97.923,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.882 | Acc: 78.035,98.143,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.880 | Acc: 78.106,98.148,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.875 | Acc: 78.133,98.221,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.876 | Acc: 78.177,98.250,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.878 | Acc: 78.070,98.282,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.877 | Acc: 78.149,98.253,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.878 | Acc: 78.181,98.256,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.873 | Acc: 78.315,98.270,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.877 | Acc: 78.146,98.257,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.875 | Acc: 78.151,98.233,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.876 | Acc: 78.179,98.219,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.876 | Acc: 78.211,98.196,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.879 | Acc: 78.068,98.183,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.879 | Acc: 78.025,98.184,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.879 | Acc: 78.045,98.188,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.881 | Acc: 77.961,98.171,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.882 | Acc: 77.963,98.161,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.160 | Acc: 64.844,75.000,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.273 | Acc: 63.616,74.888,78.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.310 | Acc: 63.624,74.257,77.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.317 | Acc: 63.627,74.155,77.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 1.023 | Acc: 78.906,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.868 | Acc: 77.716,98.475,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.878 | Acc: 77.248,98.285,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 78.023,98.335,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.871 | Acc: 78.038,98.331,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 78.040,98.321,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.873 | Acc: 78.073,98.218,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.871 | Acc: 78.003,98.260,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.870 | Acc: 78.130,98.306,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.872 | Acc: 78.060,98.286,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.875 | Acc: 78.001,98.274,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.873 | Acc: 78.097,98.282,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.876 | Acc: 78.031,98.262,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.875 | Acc: 78.068,98.243,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.876 | Acc: 78.028,98.232,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.876 | Acc: 78.047,98.219,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.875 | Acc: 78.020,98.231,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.877 | Acc: 77.946,98.238,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.878 | Acc: 77.932,98.230,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.877 | Acc: 77.988,98.222,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.204 | Acc: 64.844,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.253 | Acc: 63.728,74.851,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.287 | Acc: 63.853,73.838,77.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.290 | Acc: 63.819,74.142,77.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 0.817 | Acc: 78.125,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.870 | Acc: 78.125,98.251,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.855 | Acc: 79.097,98.285,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.861 | Acc: 78.804,98.284,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 78.791,98.312,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 78.605,98.352,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.871 | Acc: 78.222,98.373,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.871 | Acc: 78.236,98.354,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.864 | Acc: 78.455,98.336,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.867 | Acc: 78.250,98.347,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.868 | Acc: 78.335,98.321,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.866 | Acc: 78.401,98.317,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 78.316,98.305,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.867 | Acc: 78.311,98.306,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 78.306,98.293,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.871 | Acc: 78.276,98.292,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.871 | Acc: 78.273,98.294,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 78.338,98.298,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.871 | Acc: 78.298,98.290,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.871 | Acc: 78.273,98.278,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.280 | Acc: 66.406,77.344,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.315 | Acc: 63.653,74.368,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.327 | Acc: 63.700,73.704,77.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.321 | Acc: 63.717,73.886,77.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 0.768 | Acc: 78.125,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.832 | Acc: 78.609,99.107,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.840 | Acc: 78.906,98.800,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.843 | Acc: 78.855,98.591,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.854 | Acc: 78.482,98.553,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.855 | Acc: 78.373,98.546,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.859 | Acc: 78.170,98.489,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 78.191,98.449,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.866 | Acc: 78.076,98.360,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 78.142,98.355,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.863 | Acc: 78.160,98.352,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.864 | Acc: 78.196,98.335,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.862 | Acc: 78.294,98.324,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.861 | Acc: 78.338,98.327,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.866 | Acc: 78.208,98.293,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.869 | Acc: 78.169,98.287,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 78.110,98.309,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 78.194,98.323,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 78.136,98.316,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 78.148,98.317,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.352 | Acc: 67.188,75.000,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.315 | Acc: 63.876,74.554,78.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.340 | Acc: 63.853,73.723,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.328 | Acc: 63.589,73.924,77.805,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 0.850 | Acc: 74.219,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.846 | Acc: 78.609,98.512,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.838 | Acc: 78.659,98.590,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.832 | Acc: 78.945,98.706,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.832 | Acc: 78.839,98.669,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.838 | Acc: 78.651,98.615,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.840 | Acc: 78.642,98.592,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.841 | Acc: 78.729,98.537,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.843 | Acc: 78.649,98.530,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.842 | Acc: 78.656,98.541,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.842 | Acc: 78.739,98.542,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.846 | Acc: 78.627,98.512,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.847 | Acc: 78.640,98.463,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.848 | Acc: 78.595,98.458,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.850 | Acc: 78.559,98.471,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.850 | Acc: 78.600,98.466,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.855 | Acc: 78.451,98.450,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.857 | Acc: 78.375,98.442,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.858 | Acc: 78.396,98.412,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.858 | Acc: 78.431,98.384,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.226 | Acc: 68.750,75.000,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.261 | Acc: 63.951,74.702,78.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.298 | Acc: 64.101,73.819,78.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.298 | Acc: 64.075,73.886,77.907,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 0.824 | Acc: 78.906,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.880 | Acc: 77.827,98.475,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.855 | Acc: 78.354,98.571,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.849 | Acc: 78.599,98.591,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.853 | Acc: 78.569,98.582,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 78.566,98.654,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.842 | Acc: 78.835,98.663,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.848 | Acc: 78.624,98.582,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 78.470,98.539,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.858 | Acc: 78.324,98.485,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 78.428,98.457,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.855 | Acc: 78.500,98.441,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.855 | Acc: 78.469,98.425,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.855 | Acc: 78.496,98.423,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.859 | Acc: 78.384,98.412,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.859 | Acc: 78.403,98.373,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.859 | Acc: 78.398,98.372,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.860 | Acc: 78.414,98.376,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.861 | Acc: 78.430,98.370,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.860 | Acc: 78.418,98.382,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.153 | Acc: 65.625,76.562,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.295 | Acc: 63.430,74.368,78.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.326 | Acc: 63.453,74.028,77.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.331 | Acc: 63.448,73.975,77.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 0.764 | Acc: 82.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.863 | Acc: 78.162,98.698,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.852 | Acc: 78.544,98.533,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.839 | Acc: 78.868,98.630,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.842 | Acc: 78.877,98.563,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.848 | Acc: 78.697,98.523,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 78.590,98.573,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.848 | Acc: 78.613,98.537,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.853 | Acc: 78.528,98.515,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.853 | Acc: 78.509,98.485,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.852 | Acc: 78.549,98.484,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.851 | Acc: 78.613,98.459,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.856 | Acc: 78.469,98.476,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.856 | Acc: 78.520,98.473,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.855 | Acc: 78.531,98.485,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 78.540,98.487,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.855 | Acc: 78.539,98.469,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 78.487,98.449,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 78.553,98.442,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 78.558,98.448,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.229 | Acc: 65.625,74.219,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.285 | Acc: 63.281,74.702,78.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.299 | Acc: 64.005,73.990,77.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.301 | Acc: 64.152,73.963,77.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 0.770 | Acc: 77.344,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.800 | Acc: 79.650,98.847,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.820 | Acc: 79.287,98.533,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.827 | Acc: 78.919,98.630,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.830 | Acc: 79.041,98.640,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.835 | Acc: 78.844,98.631,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.833 | Acc: 78.906,98.670,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.837 | Acc: 78.690,98.665,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.830 | Acc: 78.872,98.719,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.836 | Acc: 78.699,98.696,99.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.836 | Acc: 78.716,98.702,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.838 | Acc: 78.722,98.688,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.838 | Acc: 78.744,98.690,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.844 | Acc: 78.550,98.662,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 78.436,98.588,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.848 | Acc: 78.478,98.549,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.852 | Acc: 78.395,98.484,99.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 78.441,98.454,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 78.421,98.431,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.855 | Acc: 78.404,98.442,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.220 | Acc: 67.188,76.562,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.323 | Acc: 63.876,74.033,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.339 | Acc: 63.720,73.571,77.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.336 | Acc: 63.755,73.873,77.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 0.976 | Acc: 75.000,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.831 | Acc: 79.576,98.624,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.833 | Acc: 79.364,98.476,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.833 | Acc: 79.278,98.604,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.832 | Acc: 79.118,98.659,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.843 | Acc: 78.899,98.693,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.840 | Acc: 78.796,98.676,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.837 | Acc: 78.917,98.709,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.838 | Acc: 78.926,98.636,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.839 | Acc: 78.945,98.623,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.839 | Acc: 78.863,98.597,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.838 | Acc: 78.797,98.554,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.839 | Acc: 78.777,98.554,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.838 | Acc: 78.867,98.536,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 78.739,98.521,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.843 | Acc: 78.719,98.508,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.843 | Acc: 78.699,98.508,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.844 | Acc: 78.686,98.504,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.845 | Acc: 78.683,98.496,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.846 | Acc: 78.679,98.495,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.203 | Acc: 63.281,75.000,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.287 | Acc: 64.174,74.554,78.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.328 | Acc: 63.853,73.895,78.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.333 | Acc: 63.691,73.873,77.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 0.931 | Acc: 73.438,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.802 | Acc: 79.501,98.661,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.824 | Acc: 79.154,98.476,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.818 | Acc: 79.444,98.540,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.827 | Acc: 79.090,98.534,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.837 | Acc: 78.891,98.523,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.834 | Acc: 78.913,98.554,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.832 | Acc: 78.928,98.587,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.836 | Acc: 78.717,98.588,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.837 | Acc: 78.712,98.576,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.841 | Acc: 78.716,98.527,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.842 | Acc: 78.775,98.512,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.843 | Acc: 78.770,98.532,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.845 | Acc: 78.658,98.542,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.846 | Acc: 78.614,98.507,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.847 | Acc: 78.535,98.510,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.847 | Acc: 78.522,98.501,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.846 | Acc: 78.599,98.497,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.846 | Acc: 78.618,98.489,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.846 | Acc: 78.619,98.497,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.177 | Acc: 67.188,78.906,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.314 | Acc: 63.616,74.442,78.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.355 | Acc: 63.472,73.704,77.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.350 | Acc: 63.640,73.668,77.894,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 0.837 | Acc: 76.562,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.830 | Acc: 79.836,98.475,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.830 | Acc: 79.459,98.571,99.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.830 | Acc: 79.252,98.617,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.837 | Acc: 79.225,98.553,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.846 | Acc: 78.767,98.438,99.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 78.428,98.412,99.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 78.590,98.404,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.846 | Acc: 78.741,98.462,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.844 | Acc: 78.785,98.498,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.843 | Acc: 78.891,98.484,99.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.841 | Acc: 78.899,98.508,99.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 78.835,98.541,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.842 | Acc: 78.784,98.545,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 78.817,98.518,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.842 | Acc: 78.844,98.505,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.844 | Acc: 78.746,98.479,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.842 | Acc: 78.821,98.509,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.843 | Acc: 78.826,98.494,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.843 | Acc: 78.878,98.507,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.301 | Acc: 67.188,75.000,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.317 | Acc: 64.137,73.996,78.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.345 | Acc: 63.929,73.647,77.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.343 | Acc: 63.781,73.809,77.946,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 0.851 | Acc: 74.219,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.835 | Acc: 79.278,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.818 | Acc: 79.535,98.571,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.810 | Acc: 79.816,98.668,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.816 | Acc: 79.389,98.708,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.812 | Acc: 79.479,98.739,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.817 | Acc: 79.339,98.728,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.815 | Acc: 79.410,98.731,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.817 | Acc: 79.411,98.700,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.819 | Acc: 79.403,98.666,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.819 | Acc: 79.435,98.678,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.827 | Acc: 79.111,98.664,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.827 | Acc: 79.156,98.671,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.830 | Acc: 79.005,98.635,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.828 | Acc: 79.056,98.615,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.829 | Acc: 79.036,98.606,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.830 | Acc: 79.086,98.603,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.832 | Acc: 79.041,98.586,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.834 | Acc: 78.982,98.613,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.835 | Acc: 78.976,98.632,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.281 | Acc: 63.281,76.562,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.355 | Acc: 63.579,73.661,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.385 | Acc: 63.434,73.247,77.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.382 | Acc: 63.345,73.450,77.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 0.836 | Acc: 75.781,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.860 | Acc: 77.604,98.698,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.823 | Acc: 78.735,98.876,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.820 | Acc: 78.906,98.899,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.823 | Acc: 78.906,98.872,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.827 | Acc: 78.922,98.778,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.837 | Acc: 78.596,98.747,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.840 | Acc: 78.402,98.781,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.836 | Acc: 78.470,98.831,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.836 | Acc: 78.358,98.826,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.837 | Acc: 78.350,98.795,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.837 | Acc: 78.394,98.798,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.836 | Acc: 78.491,98.801,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.832 | Acc: 78.661,98.806,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.835 | Acc: 78.575,98.779,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.833 | Acc: 78.561,98.793,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.832 | Acc: 78.624,98.761,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.831 | Acc: 78.661,98.747,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.833 | Acc: 78.638,98.743,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.831 | Acc: 78.711,98.727,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.396 | Acc: 64.844,77.344,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.361 | Acc: 63.802,73.958,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.386 | Acc: 63.796,73.552,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.381 | Acc: 63.883,73.758,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 0.895 | Acc: 75.000,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.792 | Acc: 80.357,98.698,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.792 | Acc: 80.450,98.780,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.793 | Acc: 80.328,98.770,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.803 | Acc: 79.967,98.785,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.802 | Acc: 80.121,98.755,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.808 | Acc: 79.862,98.676,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.815 | Acc: 79.599,98.659,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.819 | Acc: 79.518,98.661,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.820 | Acc: 79.416,98.627,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.823 | Acc: 79.373,98.636,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.822 | Acc: 79.380,98.653,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.824 | Acc: 79.318,98.629,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.827 | Acc: 79.256,98.599,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.828 | Acc: 79.212,98.585,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.828 | Acc: 79.148,98.596,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.829 | Acc: 79.113,98.584,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.830 | Acc: 79.117,98.582,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.830 | Acc: 79.110,98.598,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.830 | Acc: 79.058,98.608,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.378 | Acc: 64.844,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.328 | Acc: 63.653,74.107,78.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.367 | Acc: 63.948,73.438,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.362 | Acc: 63.896,73.732,77.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 0.622 | Acc: 86.719,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.796 | Acc: 80.394,98.661,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.794 | Acc: 80.069,98.800,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.804 | Acc: 80.187,98.745,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.811 | Acc: 79.765,98.698,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.808 | Acc: 79.749,98.739,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.803 | Acc: 79.926,98.812,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.808 | Acc: 79.765,98.825,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.810 | Acc: 79.678,98.801,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.815 | Acc: 79.489,98.839,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.818 | Acc: 79.431,98.818,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.820 | Acc: 79.352,98.812,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.821 | Acc: 79.328,98.775,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.822 | Acc: 79.265,98.788,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.822 | Acc: 79.329,98.796,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.822 | Acc: 79.342,98.806,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.822 | Acc: 79.354,98.803,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.822 | Acc: 79.314,98.788,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.822 | Acc: 79.294,98.760,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.823 | Acc: 79.290,98.729,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.235 | Acc: 64.062,78.125,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.391 | Acc: 62.946,73.326,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.405 | Acc: 63.319,73.418,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.398 | Acc: 63.371,73.783,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 0.842 | Acc: 77.344,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.814 | Acc: 79.055,99.107,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.815 | Acc: 79.345,98.761,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.812 | Acc: 79.495,98.860,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.811 | Acc: 79.668,98.881,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.818 | Acc: 79.308,98.894,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.820 | Acc: 79.184,98.864,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.819 | Acc: 79.150,98.859,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.824 | Acc: 79.129,98.806,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.824 | Acc: 79.088,98.800,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.825 | Acc: 79.031,98.776,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.821 | Acc: 79.101,98.749,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.821 | Acc: 79.110,98.739,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.823 | Acc: 79.056,98.725,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.823 | Acc: 79.051,98.746,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.823 | Acc: 79.000,98.757,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.823 | Acc: 78.977,98.756,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.824 | Acc: 79.028,98.749,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.825 | Acc: 79.038,98.734,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.826 | Acc: 78.984,98.729,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.453 | Acc: 64.062,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.394 | Acc: 62.574,73.289,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.402 | Acc: 63.072,73.171,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.400 | Acc: 62.795,73.322,77.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 0.749 | Acc: 81.250,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.817 | Acc: 78.906,98.661,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.816 | Acc: 79.040,98.704,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.817 | Acc: 78.932,98.809,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.807 | Acc: 79.379,98.785,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.802 | Acc: 79.680,98.770,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.806 | Acc: 79.655,98.715,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.805 | Acc: 79.721,98.698,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.805 | Acc: 79.688,98.748,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.803 | Acc: 79.886,98.735,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.805 | Acc: 79.812,98.710,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.806 | Acc: 79.695,98.738,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.805 | Acc: 79.762,98.745,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.807 | Acc: 79.696,98.755,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.810 | Acc: 79.615,98.763,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.810 | Acc: 79.563,98.770,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.812 | Acc: 79.520,98.754,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.815 | Acc: 79.442,98.751,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.817 | Acc: 79.343,98.719,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.821 | Acc: 79.249,98.716,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.258 | Acc: 67.188,75.000,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.362 | Acc: 63.579,73.884,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.390 | Acc: 63.643,73.476,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.389 | Acc: 63.397,73.783,77.677,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 0.645 | Acc: 82.812,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.802 | Acc: 79.278,98.735,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.802 | Acc: 79.230,98.819,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.796 | Acc: 79.739,98.911,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.795 | Acc: 79.900,98.872,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.798 | Acc: 79.920,98.809,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.795 | Acc: 79.849,98.838,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.798 | Acc: 79.726,98.814,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.797 | Acc: 79.692,98.816,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.797 | Acc: 79.800,98.817,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.800 | Acc: 79.734,98.791,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.807 | Acc: 79.585,98.766,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.811 | Acc: 79.425,98.775,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.811 | Acc: 79.415,98.776,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.810 | Acc: 79.448,98.760,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.810 | Acc: 79.449,98.762,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.812 | Acc: 79.410,98.778,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.814 | Acc: 79.355,98.779,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.817 | Acc: 79.311,98.764,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.817 | Acc: 79.343,98.753,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.248 | Acc: 65.625,75.781,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.337 | Acc: 63.430,74.219,77.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.357 | Acc: 63.510,74.238,77.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.359 | Acc: 63.422,74.039,77.792,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 0.824 | Acc: 78.125,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.821 | Acc: 79.315,98.996,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.818 | Acc: 80.030,98.838,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.819 | Acc: 79.931,98.758,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.813 | Acc: 79.958,98.785,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.811 | Acc: 79.989,98.847,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.807 | Acc: 80.030,98.909,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.809 | Acc: 79.909,98.870,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.808 | Acc: 79.886,98.874,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.807 | Acc: 79.752,98.878,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.806 | Acc: 79.699,98.881,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.806 | Acc: 79.688,98.872,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.807 | Acc: 79.564,98.865,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.809 | Acc: 79.541,98.821,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.811 | Acc: 79.462,98.785,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.812 | Acc: 79.415,98.819,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.812 | Acc: 79.400,98.832,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.813 | Acc: 79.321,98.822,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.812 | Acc: 79.413,98.818,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.812 | Acc: 79.392,98.837,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.324 | Acc: 66.406,77.344,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.339 | Acc: 63.616,74.368,78.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.379 | Acc: 63.338,73.666,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.374 | Acc: 63.384,73.758,77.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 0.779 | Acc: 81.250,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.823 | Acc: 78.534,99.144,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.809 | Acc: 79.287,99.066,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.805 | Acc: 79.700,99.039,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.806 | Acc: 79.524,99.064,99.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.810 | Acc: 79.308,99.087,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.808 | Acc: 79.481,99.038,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.808 | Acc: 79.355,98.986,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.808 | Acc: 79.372,98.957,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.813 | Acc: 79.221,98.904,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.813 | Acc: 79.272,98.892,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.813 | Acc: 79.256,98.848,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.813 | Acc: 79.302,98.833,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.811 | Acc: 79.373,98.848,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.811 | Acc: 79.418,98.871,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.811 | Acc: 79.446,98.871,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.813 | Acc: 79.349,98.878,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.812 | Acc: 79.424,98.864,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.812 | Acc: 79.447,98.834,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.813 | Acc: 79.470,98.813,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.368 | Acc: 67.969,78.125,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.423 | Acc: 63.095,73.438,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.442 | Acc: 63.224,73.133,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.434 | Acc: 63.140,73.361,77.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 0.947 | Acc: 73.438,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.772 | Acc: 80.134,99.144,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.785 | Acc: 79.859,99.162,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.785 | Acc: 80.136,99.116,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.781 | Acc: 80.285,99.142,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.786 | Acc: 80.237,99.103,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.785 | Acc: 80.223,99.064,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.788 | Acc: 80.048,99.058,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.792 | Acc: 79.984,99.034,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.793 | Acc: 79.929,98.994,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.798 | Acc: 79.785,98.974,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.800 | Acc: 79.765,98.943,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.801 | Acc: 79.704,98.950,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.802 | Acc: 79.705,98.916,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.805 | Acc: 79.582,98.888,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.805 | Acc: 79.547,98.892,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.806 | Acc: 79.464,98.897,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.809 | Acc: 79.378,98.889,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.810 | Acc: 79.322,98.866,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.809 | Acc: 79.370,98.866,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.447 | Acc: 64.844,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.402 | Acc: 63.318,74.107,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.450 | Acc: 63.129,73.438,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.442 | Acc: 63.192,73.578,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 1.002 | Acc: 74.219,96.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.802 | Acc: 78.832,99.070,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.796 | Acc: 79.592,98.952,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.799 | Acc: 79.265,99.001,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.798 | Acc: 79.446,99.035,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.795 | Acc: 79.595,99.056,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.795 | Acc: 79.584,99.103,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.795 | Acc: 79.715,99.053,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.798 | Acc: 79.673,98.996,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.798 | Acc: 79.757,98.964,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.799 | Acc: 79.707,98.939,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.799 | Acc: 79.688,98.961,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.800 | Acc: 79.639,98.953,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.799 | Acc: 79.631,98.937,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.800 | Acc: 79.635,98.913,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.801 | Acc: 79.594,98.881,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.800 | Acc: 79.571,98.883,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.799 | Acc: 79.626,98.903,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.801 | Acc: 79.605,98.892,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.801 | Acc: 79.632,98.891,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.309 | Acc: 65.625,75.781,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.329 | Acc: 64.286,74.516,78.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.370 | Acc: 64.024,73.609,78.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.363 | Acc: 63.665,73.860,78.023,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 0.601 | Acc: 88.281,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.791 | Acc: 79.576,98.996,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.784 | Acc: 79.840,98.838,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.787 | Acc: 80.200,98.809,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.784 | Acc: 80.334,98.852,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.788 | Acc: 80.275,98.878,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.787 | Acc: 80.333,98.889,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.787 | Acc: 80.214,98.870,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.787 | Acc: 80.110,98.879,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.789 | Acc: 80.123,98.917,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.788 | Acc: 80.134,98.919,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.788 | Acc: 80.048,98.908,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.792 | Acc: 79.911,98.882,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.795 | Acc: 79.816,98.863,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.796 | Acc: 79.815,98.880,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.798 | Acc: 79.747,98.861,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.798 | Acc: 79.702,98.873,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.800 | Acc: 79.605,98.877,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.801 | Acc: 79.625,98.877,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.799 | Acc: 79.685,98.878,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.258 | Acc: 65.625,76.562,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.387 | Acc: 63.430,73.400,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.411 | Acc: 63.891,73.152,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.389 | Acc: 63.922,73.540,77.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 0.910 | Acc: 78.125,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 80.432,98.996,99.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.782 | Acc: 80.888,98.876,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.790 | Acc: 80.456,98.796,99.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.793 | Acc: 80.392,98.872,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.796 | Acc: 80.136,98.855,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.800 | Acc: 79.939,98.889,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.795 | Acc: 79.893,98.881,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.794 | Acc: 79.886,98.889,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.792 | Acc: 79.959,98.908,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.792 | Acc: 79.952,98.904,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.791 | Acc: 79.946,98.908,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.792 | Acc: 79.914,98.888,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.792 | Acc: 79.978,98.881,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.794 | Acc: 79.943,98.849,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.795 | Acc: 79.947,98.868,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.794 | Acc: 79.955,98.861,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.795 | Acc: 79.933,98.843,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.794 | Acc: 80.012,98.853,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.797 | Acc: 79.876,98.852,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.242 | Acc: 67.969,77.344,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.355 | Acc: 64.472,73.661,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.421 | Acc: 63.929,73.171,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.423 | Acc: 63.499,73.348,77.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 0.877 | Acc: 78.906,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.785 | Acc: 80.394,98.810,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.781 | Acc: 80.926,98.876,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.780 | Acc: 80.584,98.975,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.785 | Acc: 80.208,98.920,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.779 | Acc: 80.430,98.994,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.783 | Acc: 80.385,99.006,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.792 | Acc: 80.120,98.958,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.791 | Acc: 80.139,98.976,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.790 | Acc: 80.123,98.999,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.789 | Acc: 80.049,98.982,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.794 | Acc: 79.832,98.954,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.796 | Acc: 79.765,98.937,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.797 | Acc: 79.723,98.907,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.796 | Acc: 79.757,98.932,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.794 | Acc: 79.776,98.938,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.794 | Acc: 79.799,98.944,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.795 | Acc: 79.820,98.921,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.795 | Acc: 79.839,98.931,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.796 | Acc: 79.782,98.930,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.287 | Acc: 64.844,76.562,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.315 | Acc: 64.062,74.107,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.371 | Acc: 63.891,73.552,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.361 | Acc: 63.678,73.847,77.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 0.630 | Acc: 88.281,100.000,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.785 | Acc: 80.543,99.107,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.783 | Acc: 80.202,99.219,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.783 | Acc: 79.995,99.142,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.791 | Acc: 79.823,99.064,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.790 | Acc: 79.842,99.025,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.786 | Acc: 79.978,99.032,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.782 | Acc: 80.109,99.014,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.783 | Acc: 80.085,98.966,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.786 | Acc: 80.123,98.895,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.788 | Acc: 80.111,98.873,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.792 | Acc: 80.062,98.879,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.793 | Acc: 79.944,98.888,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.793 | Acc: 79.972,98.889,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.792 | Acc: 80.018,98.874,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.792 | Acc: 79.996,98.855,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.791 | Acc: 79.997,98.863,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.792 | Acc: 79.901,98.852,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.794 | Acc: 79.854,98.857,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.795 | Acc: 79.819,98.827,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.212 | Acc: 65.625,75.781,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.355 | Acc: 63.132,74.368,78.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.417 | Acc: 63.243,73.380,77.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.400 | Acc: 63.268,73.719,77.933,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 0.761 | Acc: 78.125,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.766 | Acc: 81.027,99.144,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.757 | Acc: 81.364,98.952,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 80.469,98.988,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 80.536,99.055,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.779 | Acc: 80.345,99.018,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.782 | Acc: 80.262,99.006,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.782 | Acc: 80.264,99.014,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.786 | Acc: 80.037,99.025,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.791 | Acc: 79.938,99.012,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.792 | Acc: 79.925,99.005,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.793 | Acc: 79.946,99.000,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.794 | Acc: 79.908,98.950,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.793 | Acc: 79.954,98.949,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.793 | Acc: 79.974,98.927,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.794 | Acc: 79.978,98.915,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.793 | Acc: 80.016,98.890,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.792 | Acc: 80.061,98.900,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.792 | Acc: 80.060,98.909,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.791 | Acc: 80.061,98.901,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.094 | Acc: 64.844,77.344,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.339 | Acc: 63.653,73.586,78.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.404 | Acc: 63.186,73.380,77.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.407 | Acc: 63.166,73.578,77.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 0.663 | Acc: 82.812,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.765 | Acc: 80.990,99.107,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.751 | Acc: 80.850,99.143,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.759 | Acc: 80.686,99.065,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.753 | Acc: 80.864,99.093,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.757 | Acc: 80.616,99.110,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.765 | Acc: 80.475,99.077,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.770 | Acc: 80.402,99.019,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.775 | Acc: 80.352,99.025,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.773 | Acc: 80.426,99.012,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 80.263,98.989,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 80.211,99.003,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.779 | Acc: 80.167,98.953,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.784 | Acc: 80.050,98.931,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.787 | Acc: 79.988,98.927,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.786 | Acc: 79.986,98.920,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.788 | Acc: 79.980,98.919,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.787 | Acc: 80.004,98.919,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.788 | Acc: 79.969,98.901,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.788 | Acc: 79.975,98.893,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.355 | Acc: 64.844,77.344,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.431 | Acc: 62.909,73.735,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.452 | Acc: 63.072,73.209,77.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.439 | Acc: 63.025,73.527,77.792,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 0.725 | Acc: 82.031,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.766 | Acc: 81.176,98.996,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.767 | Acc: 80.850,98.971,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.774 | Acc: 80.661,99.001,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.779 | Acc: 80.469,99.035,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 80.739,99.025,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 80.746,99.044,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.775 | Acc: 80.713,99.053,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.781 | Acc: 80.444,98.986,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.781 | Acc: 80.309,98.994,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.780 | Acc: 80.348,98.989,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.782 | Acc: 80.296,98.978,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.784 | Acc: 80.316,98.950,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.787 | Acc: 80.235,98.937,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.787 | Acc: 80.210,98.927,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.789 | Acc: 80.116,98.923,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.791 | Acc: 80.053,98.907,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.792 | Acc: 79.992,98.912,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.792 | Acc: 79.934,98.914,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.792 | Acc: 79.942,98.905,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.240 | Acc: 64.844,76.562,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.414 | Acc: 63.058,73.065,78.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.441 | Acc: 63.262,72.580,77.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.430 | Acc: 63.153,72.887,77.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 0.909 | Acc: 76.562,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.778 | Acc: 79.948,99.070,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.769 | Acc: 80.850,99.066,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.772 | Acc: 80.815,99.116,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 80.642,99.103,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.770 | Acc: 80.786,99.080,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.772 | Acc: 80.766,99.064,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.771 | Acc: 80.829,99.080,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.772 | Acc: 80.634,99.083,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.772 | Acc: 80.546,99.081,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.775 | Acc: 80.418,99.044,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 80.462,99.046,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.779 | Acc: 80.355,99.024,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.781 | Acc: 80.304,99.006,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.781 | Acc: 80.285,98.977,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.783 | Acc: 80.214,98.964,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.784 | Acc: 80.196,98.973,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.783 | Acc: 80.182,98.978,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.786 | Acc: 80.086,98.968,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.786 | Acc: 80.126,98.960,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.332 | Acc: 66.406,76.562,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.407 | Acc: 64.025,73.921,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.435 | Acc: 63.777,73.323,77.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.429 | Acc: 63.845,73.399,77.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 0.885 | Acc: 77.344,97.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.750 | Acc: 81.250,99.405,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.746 | Acc: 81.212,99.371,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.760 | Acc: 80.853,99.283,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.765 | Acc: 80.565,99.209,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.759 | Acc: 80.778,99.188,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.761 | Acc: 80.727,99.180,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.763 | Acc: 80.618,99.191,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.767 | Acc: 80.464,99.190,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.769 | Acc: 80.413,99.141,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.772 | Acc: 80.356,99.102,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.771 | Acc: 80.352,99.060,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.772 | Acc: 80.313,99.021,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.773 | Acc: 80.262,99.030,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 80.246,99.032,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 80.168,99.011,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 80.218,98.990,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 80.212,99.010,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.779 | Acc: 80.192,99.005,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.780 | Acc: 80.128,99.005,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.277 | Acc: 67.188,76.562,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.412 | Acc: 63.914,72.879,78.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.433 | Acc: 64.024,72.809,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.428 | Acc: 63.678,73.169,77.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 0.869 | Acc: 80.469,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.733 | Acc: 81.882,99.368,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.749 | Acc: 81.402,99.009,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.763 | Acc: 80.866,98.924,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.759 | Acc: 80.922,99.026,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.757 | Acc: 81.165,99.087,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.759 | Acc: 80.985,99.051,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.760 | Acc: 81.017,99.075,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.762 | Acc: 80.828,99.093,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 80.780,99.055,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.769 | Acc: 80.640,99.071,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.771 | Acc: 80.617,99.031,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.773 | Acc: 80.547,99.031,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.773 | Acc: 80.481,99.024,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 80.455,99.024,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.774 | Acc: 80.562,99.014,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 80.500,99.007,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 80.469,99.010,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.778 | Acc: 80.443,98.994,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.778 | Acc: 80.463,98.983,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.446 | Acc: 65.625,75.000,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.449 | Acc: 62.351,73.400,77.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.474 | Acc: 62.576,73.152,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.460 | Acc: 62.590,73.412,77.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 0.716 | Acc: 82.812,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.742 | Acc: 81.808,99.107,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.740 | Acc: 81.536,99.238,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.741 | Acc: 81.660,99.206,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.756 | Acc: 81.260,99.190,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.764 | Acc: 80.933,99.149,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.758 | Acc: 81.011,99.199,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.755 | Acc: 81.017,99.202,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.762 | Acc: 80.838,99.151,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.767 | Acc: 80.633,99.102,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.767 | Acc: 80.667,99.098,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.769 | Acc: 80.617,99.053,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.768 | Acc: 80.666,99.060,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.771 | Acc: 80.568,99.051,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.774 | Acc: 80.519,99.046,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.775 | Acc: 80.464,99.053,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 80.447,99.048,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.774 | Acc: 80.450,99.058,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.774 | Acc: 80.475,99.050,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.775 | Acc: 80.442,99.008,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.485 | Acc: 66.406,76.562,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.404 | Acc: 62.909,73.996,78.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.442 | Acc: 63.053,72.923,77.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.440 | Acc: 63.204,73.015,77.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 0.709 | Acc: 85.156,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.759 | Acc: 80.990,99.219,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.762 | Acc: 80.678,99.200,99.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.772 | Acc: 80.533,99.129,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 80.768,99.142,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.774 | Acc: 80.678,99.188,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.774 | Acc: 80.669,99.135,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.773 | Acc: 80.729,99.080,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.774 | Acc: 80.731,99.054,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.773 | Acc: 80.723,99.089,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.773 | Acc: 80.636,99.083,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.773 | Acc: 80.600,99.095,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.771 | Acc: 80.628,99.076,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.774 | Acc: 80.580,99.048,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.774 | Acc: 80.502,99.032,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.773 | Acc: 80.513,99.037,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 80.423,99.014,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.776 | Acc: 80.437,98.980,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 80.369,98.972,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 80.374,98.971,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.312 | Acc: 67.969,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.395 | Acc: 62.872,73.400,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.424 | Acc: 63.167,73.266,77.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.418 | Acc: 63.217,73.476,77.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 0.907 | Acc: 70.312,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.789 | Acc: 79.427,99.330,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.776 | Acc: 80.050,99.181,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.768 | Acc: 80.533,99.232,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.769 | Acc: 80.527,99.064,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.765 | Acc: 80.709,99.080,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.766 | Acc: 80.708,99.090,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 80.674,99.125,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.764 | Acc: 80.876,99.122,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.763 | Acc: 80.939,99.137,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.765 | Acc: 80.892,99.110,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.768 | Acc: 80.691,99.099,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 80.589,99.105,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 80.600,99.081,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 80.633,99.094,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.769 | Acc: 80.609,99.063,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.771 | Acc: 80.598,99.053,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.771 | Acc: 80.574,99.022,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.773 | Acc: 80.484,99.017,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.772 | Acc: 80.528,99.038,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.295 | Acc: 64.062,76.562,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.411 | Acc: 62.723,74.033,78.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.476 | Acc: 62.900,73.285,77.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.464 | Acc: 62.705,73.540,77.779,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 0.823 | Acc: 77.344,96.094,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.736 | Acc: 80.952,99.107,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.743 | Acc: 80.869,99.219,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.754 | Acc: 80.712,99.232,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.748 | Acc: 81.192,99.199,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.742 | Acc: 81.552,99.141,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.744 | Acc: 81.482,99.148,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.744 | Acc: 81.444,99.152,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.749 | Acc: 81.177,99.146,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.750 | Acc: 81.142,99.167,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.755 | Acc: 80.935,99.164,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.760 | Acc: 80.720,99.180,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.761 | Acc: 80.618,99.170,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 80.532,99.138,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 80.549,99.110,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 80.549,99.102,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 80.534,99.107,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.769 | Acc: 80.515,99.074,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.769 | Acc: 80.499,99.080,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 80.510,99.065,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.475 | Acc: 66.406,75.781,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.456 | Acc: 63.207,73.586,78.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.499 | Acc: 62.957,72.961,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.504 | Acc: 62.833,72.964,77.395,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 0.722 | Acc: 82.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.768 | Acc: 80.134,98.996,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.757 | Acc: 80.716,99.085,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.764 | Acc: 80.789,99.142,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.763 | Acc: 80.835,99.132,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.762 | Acc: 80.840,99.118,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.763 | Acc: 80.611,99.064,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.766 | Acc: 80.663,99.036,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.767 | Acc: 80.736,99.073,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.765 | Acc: 80.844,99.085,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.763 | Acc: 80.912,99.090,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.762 | Acc: 80.911,99.109,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.763 | Acc: 80.812,99.112,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 80.735,99.096,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 80.688,99.071,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 80.759,99.066,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 80.736,99.041,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.768 | Acc: 80.654,99.033,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 80.655,99.039,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.768 | Acc: 80.664,99.020,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.211 | Acc: 61.719,77.344,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.405 | Acc: 62.723,73.661,78.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.458 | Acc: 63.205,73.323,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.446 | Acc: 63.064,73.476,77.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 0.840 | Acc: 74.219,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.766 | Acc: 80.543,99.256,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.755 | Acc: 81.364,99.162,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.758 | Acc: 81.327,99.142,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.746 | Acc: 81.501,99.171,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.751 | Acc: 81.312,99.180,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.753 | Acc: 81.056,99.186,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.753 | Acc: 80.984,99.202,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.757 | Acc: 80.833,99.185,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 80.749,99.158,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.758 | Acc: 80.795,99.168,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.760 | Acc: 80.709,99.130,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.762 | Acc: 80.699,99.118,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.761 | Acc: 80.693,99.123,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.762 | Acc: 80.702,99.099,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.762 | Acc: 80.687,99.115,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.762 | Acc: 80.663,99.109,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.761 | Acc: 80.693,99.111,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.762 | Acc: 80.685,99.093,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.761 | Acc: 80.727,99.098,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.358 | Acc: 67.188,76.562,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.473 | Acc: 62.760,73.065,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.502 | Acc: 62.938,72.790,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.500 | Acc: 62.948,72.772,77.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 0.720 | Acc: 78.125,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.737 | Acc: 81.101,98.996,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.742 | Acc: 81.212,99.047,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.750 | Acc: 80.943,98.924,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.745 | Acc: 81.318,98.978,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.746 | Acc: 81.335,98.948,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.754 | Acc: 81.005,98.935,99.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.754 | Acc: 80.995,98.920,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.751 | Acc: 81.143,98.952,99.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.752 | Acc: 81.207,98.930,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.753 | Acc: 81.188,98.970,99.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.754 | Acc: 81.116,98.961,99.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.755 | Acc: 81.124,98.946,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.759 | Acc: 81.091,98.928,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 81.103,98.935,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.761 | Acc: 81.029,98.925,99.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.762 | Acc: 80.904,98.910,99.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.764 | Acc: 80.828,98.912,99.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.768 | Acc: 80.711,98.909,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 80.715,98.919,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.297 | Acc: 67.969,75.781,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.377 | Acc: 62.909,74.107,78.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.446 | Acc: 62.805,73.418,77.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.441 | Acc: 62.666,73.348,77.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 0.518 | Acc: 91.406,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.750 | Acc: 81.138,98.884,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.750 | Acc: 80.945,99.219,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.742 | Acc: 81.340,99.257,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.739 | Acc: 81.443,99.228,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.733 | Acc: 81.815,99.126,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.736 | Acc: 81.631,99.148,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.738 | Acc: 81.505,99.180,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.740 | Acc: 81.556,99.127,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.741 | Acc: 81.531,99.098,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.748 | Acc: 81.324,99.083,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.750 | Acc: 81.254,99.035,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.755 | Acc: 81.114,99.044,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.755 | Acc: 81.061,99.054,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.755 | Acc: 81.097,99.057,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.756 | Acc: 81.055,99.037,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 80.977,99.026,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.760 | Acc: 80.883,99.017,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.760 | Acc: 80.923,99.026,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.759 | Acc: 80.942,99.028,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.302 | Acc: 64.844,75.000,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.461 | Acc: 62.872,73.438,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.497 | Acc: 62.919,73.075,77.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.493 | Acc: 62.807,73.156,77.305,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 0.722 | Acc: 81.250,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.735 | Acc: 81.734,98.810,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.731 | Acc: 81.822,98.971,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.733 | Acc: 81.865,99.103,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.738 | Acc: 81.732,99.055,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.748 | Acc: 81.490,99.025,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.751 | Acc: 81.437,99.025,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.753 | Acc: 81.239,99.053,99.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.752 | Acc: 81.216,99.078,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.753 | Acc: 81.142,99.089,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.755 | Acc: 81.036,99.067,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.756 | Acc: 81.027,99.077,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.757 | Acc: 81.013,99.063,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.758 | Acc: 80.990,99.039,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.756 | Acc: 81.028,99.071,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.758 | Acc: 80.975,99.050,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 80.941,99.061,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.760 | Acc: 80.867,99.042,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.759 | Acc: 80.947,99.046,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.759 | Acc: 80.947,99.057,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.300 | Acc: 64.062,75.781,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.422 | Acc: 63.318,73.400,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.472 | Acc: 63.014,72.790,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.477 | Acc: 62.705,72.887,77.331,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 0.743 | Acc: 80.469,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.739 | Acc: 80.804,99.033,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.728 | Acc: 82.069,99.104,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.740 | Acc: 81.506,99.091,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.736 | Acc: 81.723,98.987,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.740 | Acc: 81.614,99.018,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.741 | Acc: 81.566,99.032,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.742 | Acc: 81.389,99.025,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.741 | Acc: 81.405,99.078,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.747 | Acc: 81.224,99.072,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.749 | Acc: 81.114,99.083,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.753 | Acc: 81.066,99.028,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.754 | Acc: 81.039,99.002,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 81.005,99.003,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.756 | Acc: 80.972,99.010,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.756 | Acc: 80.985,99.011,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.754 | Acc: 81.036,99.019,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.755 | Acc: 81.007,99.026,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.756 | Acc: 81.012,99.017,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.754 | Acc: 81.068,99.010,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.101 | Acc: 68.750,77.344,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.496 | Acc: 61.644,73.363,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.515 | Acc: 62.081,72.923,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.509 | Acc: 62.052,72.951,77.177,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 0.863 | Acc: 79.688,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.752 | Acc: 81.399,98.996,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.747 | Acc: 81.555,99.047,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.747 | Acc: 81.519,99.103,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.746 | Acc: 81.472,99.113,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.741 | Acc: 81.467,99.134,99.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.748 | Acc: 81.205,99.090,99.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.748 | Acc: 81.189,99.086,99.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.750 | Acc: 81.124,99.088,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.751 | Acc: 81.060,99.089,99.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.750 | Acc: 81.056,99.106,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.750 | Acc: 81.034,99.120,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.753 | Acc: 80.974,99.131,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.752 | Acc: 80.969,99.123,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.750 | Acc: 81.003,99.144,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.750 | Acc: 81.061,99.146,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.753 | Acc: 81.014,99.134,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.754 | Acc: 80.961,99.125,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.754 | Acc: 81.001,99.119,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.753 | Acc: 81.024,99.124,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.237 | Acc: 62.500,77.344,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.410 | Acc: 62.649,73.698,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.462 | Acc: 62.538,73.152,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.451 | Acc: 62.308,73.309,77.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 0.710 | Acc: 81.250,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.710 | Acc: 83.073,98.996,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.741 | Acc: 81.269,99.009,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.739 | Acc: 81.224,99.129,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.738 | Acc: 81.173,99.151,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.735 | Acc: 81.451,99.103,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.742 | Acc: 81.101,99.057,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.738 | Acc: 81.239,99.047,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.738 | Acc: 81.294,99.044,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.742 | Acc: 81.306,99.025,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.743 | Acc: 81.192,99.009,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.746 | Acc: 81.112,99.003,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.749 | Acc: 81.114,98.963,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.751 | Acc: 81.064,98.952,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.752 | Acc: 81.039,98.938,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 80.977,98.936,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.757 | Acc: 80.997,98.944,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 80.948,98.958,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.759 | Acc: 80.945,98.961,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.758 | Acc: 80.942,98.960,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.163 | Acc: 68.750,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.481 | Acc: 62.463,72.991,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.534 | Acc: 62.919,72.866,76.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.531 | Acc: 62.705,72.874,77.075,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 0.676 | Acc: 82.812,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.741 | Acc: 81.585,99.219,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.729 | Acc: 81.936,99.352,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.735 | Acc: 81.878,99.180,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.734 | Acc: 81.626,99.219,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.734 | Acc: 81.482,99.234,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.734 | Acc: 81.586,99.257,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.738 | Acc: 81.455,99.197,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.735 | Acc: 81.565,99.136,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.735 | Acc: 81.643,99.119,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.738 | Acc: 81.569,99.110,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.739 | Acc: 81.554,99.074,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.743 | Acc: 81.487,99.089,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.744 | Acc: 81.430,99.084,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.747 | Acc: 81.370,99.080,99.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.747 | Acc: 81.305,99.086,99.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.748 | Acc: 81.333,99.073,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.750 | Acc: 81.303,99.049,99.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.752 | Acc: 81.274,99.039,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.753 | Acc: 81.275,99.047,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.425 | Acc: 66.406,75.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.429 | Acc: 63.579,73.028,78.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.481 | Acc: 63.605,72.409,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.475 | Acc: 63.256,72.720,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 0.696 | Acc: 83.594,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.757 | Acc: 82.217,99.516,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.743 | Acc: 81.841,99.390,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.743 | Acc: 81.570,99.424,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.747 | Acc: 81.327,99.363,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.746 | Acc: 81.165,99.327,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.748 | Acc: 81.037,99.296,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.745 | Acc: 81.095,99.318,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.745 | Acc: 81.134,99.272,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.743 | Acc: 81.164,99.245,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.740 | Acc: 81.176,99.242,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.738 | Acc: 81.278,99.236,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.741 | Acc: 81.263,99.203,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.740 | Acc: 81.346,99.216,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.741 | Acc: 81.311,99.194,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 81.310,99.177,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.746 | Acc: 81.218,99.160,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.750 | Acc: 81.135,99.118,99.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.752 | Acc: 81.146,99.111,99.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.753 | Acc: 81.156,99.098,99.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.401 | Acc: 65.625,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.446 | Acc: 62.723,72.879,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.476 | Acc: 62.786,72.790,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.476 | Acc: 62.769,72.874,77.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 0.663 | Acc: 79.688,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.752 | Acc: 80.915,99.330,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.765 | Acc: 80.602,99.028,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.759 | Acc: 80.930,98.963,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.750 | Acc: 81.067,98.958,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.750 | Acc: 80.987,99.010,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.749 | Acc: 80.966,99.103,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.744 | Acc: 81.161,99.147,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.743 | Acc: 81.177,99.165,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.743 | Acc: 81.328,99.128,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.745 | Acc: 81.250,99.114,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.745 | Acc: 81.193,99.077,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.746 | Acc: 81.218,99.086,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.747 | Acc: 81.109,99.075,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.749 | Acc: 81.075,99.019,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.748 | Acc: 81.136,99.009,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.749 | Acc: 81.109,99.017,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.750 | Acc: 81.074,99.031,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.750 | Acc: 81.090,99.007,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.751 | Acc: 81.049,99.003,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.116 | Acc: 67.969,76.562,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.463 | Acc: 62.426,73.400,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.505 | Acc: 62.443,72.923,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.503 | Acc: 62.833,73.002,77.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 0.834 | Acc: 78.125,97.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.741 | Acc: 81.324,98.847,99.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.724 | Acc: 82.374,99.123,99.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.722 | Acc: 82.121,99.116,99.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.722 | Acc: 82.070,99.190,99.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.719 | Acc: 82.209,99.265,99.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.720 | Acc: 82.212,99.283,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.721 | Acc: 82.159,99.280,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.721 | Acc: 82.089,99.277,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.726 | Acc: 81.949,99.249,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.726 | Acc: 81.899,99.246,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.727 | Acc: 81.837,99.212,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.728 | Acc: 81.853,99.212,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.730 | Acc: 81.753,99.216,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.734 | Acc: 81.659,99.202,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.736 | Acc: 81.598,99.193,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.738 | Acc: 81.479,99.173,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.738 | Acc: 81.552,99.157,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.739 | Acc: 81.521,99.143,99.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 81.381,99.124,99.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.265 | Acc: 64.062,75.000,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.436 | Acc: 61.905,73.214,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.495 | Acc: 62.405,72.961,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.482 | Acc: 62.308,73.194,77.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 0.705 | Acc: 85.156,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.739 | Acc: 81.734,99.144,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.741 | Acc: 81.574,99.162,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.743 | Acc: 81.570,99.129,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.744 | Acc: 81.530,99.161,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.740 | Acc: 81.745,99.188,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.738 | Acc: 81.792,99.199,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.739 | Acc: 81.666,99.174,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.739 | Acc: 81.599,99.175,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.739 | Acc: 81.751,99.197,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.738 | Acc: 81.685,99.168,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.739 | Acc: 81.685,99.155,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.742 | Acc: 81.526,99.115,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.743 | Acc: 81.528,99.105,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.742 | Acc: 81.528,99.088,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.744 | Acc: 81.419,99.089,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.745 | Acc: 81.437,99.039,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 81.465,99.038,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.744 | Acc: 81.486,99.039,99.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.746 | Acc: 81.445,99.030,99.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.330 | Acc: 68.750,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.476 | Acc: 62.872,73.698,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.545 | Acc: 62.367,73.095,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.546 | Acc: 62.193,72.964,77.126,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 0.716 | Acc: 82.031,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.712 | Acc: 82.366,99.144,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.713 | Acc: 82.393,99.238,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.701 | Acc: 82.441,99.308,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.701 | Acc: 82.369,99.354,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.697 | Acc: 82.611,99.366,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.692 | Acc: 82.787,99.374,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.697 | Acc: 82.691,99.407,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.697 | Acc: 82.745,99.398,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.694 | Acc: 82.890,99.409,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.692 | Acc: 82.867,99.417,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.688 | Acc: 82.968,99.431,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.690 | Acc: 82.942,99.436,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.691 | Acc: 82.932,99.434,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.692 | Acc: 82.924,99.430,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.690 | Acc: 83.031,99.445,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.689 | Acc: 83.129,99.445,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.688 | Acc: 83.142,99.452,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.687 | Acc: 83.131,99.455,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.685 | Acc: 83.202,99.453,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.246 | Acc: 67.969,75.000,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.377 | Acc: 64.286,74.330,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.427 | Acc: 64.101,73.628,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.416 | Acc: 63.896,73.630,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 0.933 | Acc: 75.781,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.677 | Acc: 83.185,99.702,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.674 | Acc: 83.270,99.752,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.667 | Acc: 83.683,99.629,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.672 | Acc: 83.353,99.566,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.670 | Acc: 83.439,99.520,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.676 | Acc: 83.536,99.542,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.673 | Acc: 83.610,99.551,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.676 | Acc: 83.482,99.529,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.675 | Acc: 83.494,99.525,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.675 | Acc: 83.438,99.491,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.674 | Acc: 83.498,99.505,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.676 | Acc: 83.451,99.485,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.676 | Acc: 83.390,99.473,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.677 | Acc: 83.293,99.486,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.675 | Acc: 83.448,99.476,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.673 | Acc: 83.462,99.479,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.672 | Acc: 83.472,99.480,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.671 | Acc: 83.524,99.481,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.671 | Acc: 83.532,99.485,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.322 | Acc: 67.969,75.000,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.386 | Acc: 64.174,74.070,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.440 | Acc: 64.120,73.666,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.426 | Acc: 63.960,73.745,77.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 0.728 | Acc: 79.688,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.690 | Acc: 82.589,99.293,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.665 | Acc: 83.194,99.486,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.659 | Acc: 83.363,99.462,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.653 | Acc: 83.854,99.450,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.654 | Acc: 84.135,99.420,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.655 | Acc: 83.968,99.438,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.656 | Acc: 83.959,99.451,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.654 | Acc: 84.094,99.481,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.659 | Acc: 83.987,99.473,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.661 | Acc: 83.831,99.495,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.663 | Acc: 83.799,99.498,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.663 | Acc: 83.759,99.504,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.665 | Acc: 83.707,99.497,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.663 | Acc: 83.724,99.513,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.665 | Acc: 83.672,99.509,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.665 | Acc: 83.650,99.521,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.665 | Acc: 83.656,99.521,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.665 | Acc: 83.622,99.537,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.665 | Acc: 83.606,99.532,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.354 | Acc: 67.188,76.562,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.394 | Acc: 64.062,73.996,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.438 | Acc: 63.986,73.380,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.425 | Acc: 63.742,73.642,77.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 0.771 | Acc: 82.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.667 | Acc: 84.077,99.368,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.659 | Acc: 84.032,99.447,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.656 | Acc: 83.760,99.475,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.658 | Acc: 83.931,99.402,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.660 | Acc: 83.741,99.420,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.661 | Acc: 83.781,99.451,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.662 | Acc: 83.693,99.463,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.663 | Acc: 83.618,99.466,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.661 | Acc: 83.775,99.491,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.663 | Acc: 83.640,99.514,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.662 | Acc: 83.668,99.512,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.666 | Acc: 83.529,99.501,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.666 | Acc: 83.507,99.512,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.665 | Acc: 83.533,99.491,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.665 | Acc: 83.529,99.509,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.665 | Acc: 83.516,99.525,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.664 | Acc: 83.523,99.537,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.662 | Acc: 83.579,99.537,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.663 | Acc: 83.565,99.541,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.361 | Acc: 66.406,77.344,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.395 | Acc: 63.988,74.219,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.443 | Acc: 64.082,73.685,77.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.430 | Acc: 63.922,73.873,77.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 0.695 | Acc: 79.688,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.660 | Acc: 83.333,99.628,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.649 | Acc: 83.689,99.657,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.656 | Acc: 83.850,99.641,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.657 | Acc: 83.873,99.605,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.657 | Acc: 83.779,99.590,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.659 | Acc: 83.858,99.606,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.657 | Acc: 84.020,99.607,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.654 | Acc: 84.147,99.597,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.656 | Acc: 84.030,99.594,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.656 | Acc: 84.025,99.600,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.659 | Acc: 83.937,99.608,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.662 | Acc: 83.808,99.601,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.659 | Acc: 83.860,99.614,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.660 | Acc: 83.838,99.614,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.661 | Acc: 83.814,99.613,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.661 | Acc: 83.837,99.596,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.661 | Acc: 83.807,99.588,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.661 | Acc: 83.791,99.587,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.663 | Acc: 83.735,99.578,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.380 | Acc: 66.406,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.379 | Acc: 63.802,73.884,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.427 | Acc: 63.872,73.495,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.416 | Acc: 63.704,73.758,77.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 0.770 | Acc: 79.688,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.648 | Acc: 83.743,99.628,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.646 | Acc: 84.089,99.657,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.642 | Acc: 84.196,99.705,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.651 | Acc: 83.883,99.624,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.657 | Acc: 83.942,99.598,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.653 | Acc: 84.013,99.574,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.654 | Acc: 84.054,99.590,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.654 | Acc: 84.035,99.592,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.654 | Acc: 84.060,99.612,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.656 | Acc: 84.037,99.615,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.656 | Acc: 83.983,99.604,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.655 | Acc: 83.934,99.605,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.656 | Acc: 83.860,99.611,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.657 | Acc: 83.833,99.619,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.657 | Acc: 83.786,99.613,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.658 | Acc: 83.728,99.608,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.659 | Acc: 83.656,99.606,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.659 | Acc: 83.650,99.593,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.660 | Acc: 83.627,99.590,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.350 | Acc: 64.844,75.000,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.374 | Acc: 64.286,74.070,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.429 | Acc: 64.043,73.533,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.414 | Acc: 63.960,73.706,77.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 0.767 | Acc: 75.000,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.666 | Acc: 82.812,99.479,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.664 | Acc: 83.308,99.543,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.662 | Acc: 83.133,99.552,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.666 | Acc: 83.468,99.489,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.661 | Acc: 83.617,99.474,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.665 | Acc: 83.465,99.496,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.660 | Acc: 83.627,99.529,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.658 | Acc: 83.652,99.515,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.657 | Acc: 83.702,99.534,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.655 | Acc: 83.800,99.545,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.654 | Acc: 83.869,99.537,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.654 | Acc: 83.889,99.533,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.655 | Acc: 83.824,99.533,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.656 | Acc: 83.780,99.538,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.655 | Acc: 83.794,99.546,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.656 | Acc: 83.774,99.552,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.655 | Acc: 83.832,99.551,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.655 | Acc: 83.812,99.552,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.655 | Acc: 83.834,99.559,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.365 | Acc: 65.625,73.438,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.386 | Acc: 63.876,74.219,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.438 | Acc: 63.872,73.457,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.424 | Acc: 63.832,73.694,77.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 0.734 | Acc: 82.812,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.654 | Acc: 84.003,99.740,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.652 | Acc: 83.937,99.695,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.657 | Acc: 83.811,99.705,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.653 | Acc: 83.922,99.672,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.649 | Acc: 84.011,99.660,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.657 | Acc: 83.852,99.619,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.658 | Acc: 83.832,99.607,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.657 | Acc: 83.895,99.607,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.658 | Acc: 83.861,99.581,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.658 | Acc: 83.870,99.572,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.659 | Acc: 83.852,99.576,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.657 | Acc: 83.902,99.575,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.658 | Acc: 83.887,99.563,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.658 | Acc: 83.788,99.566,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.658 | Acc: 83.791,99.564,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.658 | Acc: 83.825,99.569,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.660 | Acc: 83.786,99.562,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.658 | Acc: 83.895,99.567,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.660 | Acc: 83.844,99.555,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.356 | Acc: 65.625,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.373 | Acc: 63.876,73.772,77.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.429 | Acc: 64.024,73.457,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.416 | Acc: 63.845,73.655,77.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 0.750 | Acc: 78.125,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.681 | Acc: 82.403,99.628,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.660 | Acc: 83.308,99.619,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.658 | Acc: 83.530,99.616,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.662 | Acc: 83.304,99.605,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.659 | Acc: 83.400,99.598,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.657 | Acc: 83.503,99.619,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.654 | Acc: 83.649,99.618,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.653 | Acc: 83.764,99.626,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.652 | Acc: 83.840,99.629,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.650 | Acc: 83.901,99.623,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.650 | Acc: 83.869,99.636,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.649 | Acc: 83.911,99.643,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.650 | Acc: 83.848,99.635,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.649 | Acc: 83.866,99.619,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.652 | Acc: 83.788,99.626,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.651 | Acc: 83.813,99.620,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.652 | Acc: 83.857,99.615,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.653 | Acc: 83.795,99.628,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.654 | Acc: 83.807,99.617,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.366 | Acc: 65.625,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.397 | Acc: 63.802,73.996,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.447 | Acc: 63.891,73.457,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.431 | Acc: 63.704,73.706,77.677,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 0.711 | Acc: 80.469,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.655 | Acc: 83.482,99.368,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.636 | Acc: 84.623,99.409,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.644 | Acc: 84.260,99.552,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.648 | Acc: 84.240,99.576,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.651 | Acc: 84.112,99.590,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.654 | Acc: 83.897,99.522,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.657 | Acc: 83.749,99.535,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.653 | Acc: 83.841,99.568,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.652 | Acc: 83.823,99.599,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.651 | Acc: 83.947,99.600,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.653 | Acc: 83.884,99.590,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.651 | Acc: 84.018,99.598,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.650 | Acc: 84.022,99.590,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.650 | Acc: 84.019,99.597,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.651 | Acc: 84.040,99.603,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.651 | Acc: 84.000,99.608,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.653 | Acc: 83.908,99.608,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.654 | Acc: 83.866,99.608,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.654 | Acc: 83.869,99.617,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.382 | Acc: 66.406,73.438,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.396 | Acc: 64.360,73.772,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.448 | Acc: 63.891,73.247,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.434 | Acc: 63.845,73.604,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 0.563 | Acc: 92.188,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.683 | Acc: 83.817,99.665,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.666 | Acc: 83.937,99.657,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.666 | Acc: 83.773,99.552,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.652 | Acc: 84.172,99.605,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.646 | Acc: 84.460,99.606,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.652 | Acc: 84.259,99.593,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.652 | Acc: 84.253,99.596,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.654 | Acc: 84.103,99.592,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.653 | Acc: 84.099,99.586,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.653 | Acc: 84.049,99.596,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.653 | Acc: 84.106,99.604,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.652 | Acc: 84.093,99.614,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.651 | Acc: 84.058,99.599,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.653 | Acc: 83.958,99.594,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.653 | Acc: 84.012,99.603,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.654 | Acc: 83.995,99.601,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.654 | Acc: 83.997,99.604,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.653 | Acc: 84.068,99.608,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.655 | Acc: 83.942,99.610,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.377 | Acc: 65.625,75.000,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.384 | Acc: 64.174,74.070,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.443 | Acc: 63.891,73.571,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.427 | Acc: 63.755,73.745,77.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 0.586 | Acc: 82.031,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.643 | Acc: 84.040,99.665,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.640 | Acc: 84.146,99.695,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.649 | Acc: 84.004,99.693,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.655 | Acc: 83.787,99.701,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.656 | Acc: 83.880,99.722,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.659 | Acc: 83.742,99.671,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.655 | Acc: 83.910,99.695,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.653 | Acc: 83.963,99.694,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.653 | Acc: 83.974,99.689,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.656 | Acc: 83.862,99.689,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.657 | Acc: 83.795,99.675,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.659 | Acc: 83.740,99.660,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.657 | Acc: 83.809,99.665,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.656 | Acc: 83.850,99.675,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.655 | Acc: 83.833,99.663,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.656 | Acc: 83.849,99.662,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.656 | Acc: 83.850,99.645,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.656 | Acc: 83.856,99.636,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.657 | Acc: 83.801,99.625,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.388 | Acc: 65.625,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.396 | Acc: 63.951,73.698,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.448 | Acc: 63.929,73.209,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.435 | Acc: 63.691,73.527,77.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 0.537 | Acc: 83.594,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.655 | Acc: 83.333,99.591,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.662 | Acc: 83.498,99.562,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.661 | Acc: 83.632,99.590,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.655 | Acc: 83.854,99.624,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.653 | Acc: 84.089,99.629,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.652 | Acc: 84.078,99.587,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.650 | Acc: 84.137,99.551,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.649 | Acc: 84.118,99.544,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.650 | Acc: 84.090,99.551,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.650 | Acc: 84.033,99.572,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.650 | Acc: 84.007,99.590,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.654 | Acc: 83.889,99.588,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.655 | Acc: 83.905,99.596,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.653 | Acc: 83.955,99.611,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.653 | Acc: 83.947,99.621,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.653 | Acc: 83.959,99.623,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.652 | Acc: 83.986,99.617,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.652 | Acc: 83.884,99.613,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.652 | Acc: 83.897,99.612,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.397 | Acc: 67.969,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.404 | Acc: 63.542,73.958,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.461 | Acc: 63.700,73.380,77.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.445 | Acc: 63.486,73.489,77.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 0.665 | Acc: 85.156,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.663 | Acc: 83.929,99.554,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.648 | Acc: 84.375,99.581,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.648 | Acc: 84.324,99.629,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.641 | Acc: 84.655,99.605,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.644 | Acc: 84.553,99.636,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.647 | Acc: 84.530,99.645,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.649 | Acc: 84.381,99.668,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.647 | Acc: 84.390,99.646,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.650 | Acc: 84.289,99.633,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.649 | Acc: 84.274,99.646,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.651 | Acc: 84.163,99.632,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.650 | Acc: 84.142,99.650,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.650 | Acc: 84.151,99.644,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.649 | Acc: 84.144,99.639,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.648 | Acc: 84.126,99.644,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.649 | Acc: 84.039,99.637,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.650 | Acc: 84.013,99.640,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.650 | Acc: 83.996,99.626,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.650 | Acc: 83.987,99.629,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.400 | Acc: 66.406,75.000,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.389 | Acc: 64.025,74.107,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.447 | Acc: 64.024,73.495,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.432 | Acc: 63.832,73.655,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 0.702 | Acc: 79.688,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.663 | Acc: 83.631,99.740,99.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.655 | Acc: 84.108,99.752,99.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.657 | Acc: 83.837,99.782,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.649 | Acc: 84.134,99.759,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.652 | Acc: 83.926,99.706,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.653 | Acc: 83.846,99.716,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.652 | Acc: 83.943,99.712,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.650 | Acc: 84.103,99.704,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.650 | Acc: 84.043,99.698,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.649 | Acc: 84.037,99.685,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.646 | Acc: 84.135,99.668,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.650 | Acc: 84.064,99.669,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.649 | Acc: 84.064,99.683,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.649 | Acc: 84.064,99.675,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.648 | Acc: 84.105,99.678,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.650 | Acc: 84.027,99.679,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.650 | Acc: 84.020,99.672,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.651 | Acc: 83.970,99.665,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.651 | Acc: 83.936,99.668,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.414 | Acc: 66.406,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.401 | Acc: 63.616,74.256,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.455 | Acc: 63.681,73.495,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.438 | Acc: 63.653,73.732,77.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 0.670 | Acc: 82.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.625 | Acc: 83.557,99.665,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.632 | Acc: 83.975,99.695,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.647 | Acc: 83.696,99.680,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.651 | Acc: 83.767,99.672,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.652 | Acc: 83.895,99.683,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.654 | Acc: 83.852,99.638,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.650 | Acc: 84.015,99.618,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.648 | Acc: 84.113,99.612,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.648 | Acc: 84.060,99.616,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.648 | Acc: 84.006,99.615,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.651 | Acc: 83.912,99.608,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.650 | Acc: 83.866,99.598,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.649 | Acc: 83.923,99.599,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.651 | Acc: 83.905,99.602,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.650 | Acc: 83.905,99.603,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.651 | Acc: 83.898,99.598,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.651 | Acc: 83.857,99.601,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.650 | Acc: 83.918,99.604,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.651 | Acc: 83.934,99.615,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.393 | Acc: 66.406,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.398 | Acc: 64.100,73.810,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.448 | Acc: 64.043,73.399,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.437 | Acc: 63.730,73.399,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 0.666 | Acc: 85.938,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.645 | Acc: 84.115,99.702,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.642 | Acc: 84.108,99.676,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.651 | Acc: 83.760,99.641,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.655 | Acc: 83.468,99.662,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.652 | Acc: 83.965,99.621,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.651 | Acc: 83.962,99.638,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.655 | Acc: 83.804,99.607,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.651 | Acc: 83.919,99.607,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.650 | Acc: 83.965,99.607,99.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.649 | Acc: 84.130,99.611,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.649 | Acc: 84.071,99.590,99.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.646 | Acc: 84.155,99.598,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.650 | Acc: 84.031,99.602,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.649 | Acc: 84.058,99.591,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.648 | Acc: 84.089,99.587,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.649 | Acc: 84.042,99.591,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.647 | Acc: 84.125,99.592,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.648 | Acc: 84.070,99.593,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.648 | Acc: 84.055,99.588,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.407 | Acc: 66.406,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.400 | Acc: 64.062,74.107,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.448 | Acc: 64.082,73.361,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.437 | Acc: 63.973,73.540,77.344,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 0.591 | Acc: 86.719,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.636 | Acc: 84.673,99.814,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.634 | Acc: 84.889,99.657,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.633 | Acc: 84.734,99.680,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.640 | Acc: 84.423,99.682,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.644 | Acc: 84.421,99.644,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.644 | Acc: 84.375,99.638,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.643 | Acc: 84.392,99.629,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.647 | Acc: 84.239,99.617,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.650 | Acc: 84.146,99.624,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.651 | Acc: 84.041,99.627,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.652 | Acc: 83.972,99.636,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.652 | Acc: 83.986,99.637,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.653 | Acc: 83.881,99.626,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.650 | Acc: 83.941,99.639,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.650 | Acc: 83.931,99.639,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.651 | Acc: 83.886,99.640,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.651 | Acc: 83.937,99.649,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.651 | Acc: 83.940,99.643,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.650 | Acc: 83.959,99.656,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.405 | Acc: 67.188,73.438,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.399 | Acc: 63.914,73.810,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.455 | Acc: 63.967,73.323,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.445 | Acc: 63.768,73.412,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 0.728 | Acc: 77.344,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.644 | Acc: 84.226,99.442,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.645 | Acc: 84.299,99.676,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.642 | Acc: 84.362,99.667,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.644 | Acc: 84.298,99.624,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.643 | Acc: 84.298,99.636,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.645 | Acc: 84.369,99.593,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.648 | Acc: 84.275,99.579,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.649 | Acc: 84.108,99.583,99.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.650 | Acc: 84.017,99.564,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.651 | Acc: 83.955,99.584,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.648 | Acc: 84.046,99.593,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.650 | Acc: 83.980,99.588,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.649 | Acc: 83.989,99.587,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.648 | Acc: 84.005,99.611,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.648 | Acc: 83.986,99.624,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.650 | Acc: 83.939,99.623,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.649 | Acc: 83.986,99.627,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.651 | Acc: 83.964,99.636,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.650 | Acc: 84.026,99.643,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.420 | Acc: 66.406,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.419 | Acc: 63.616,73.661,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.470 | Acc: 63.643,73.114,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.456 | Acc: 63.537,73.309,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 0.718 | Acc: 78.906,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.637 | Acc: 84.524,99.628,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.648 | Acc: 84.127,99.657,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.646 | Acc: 83.811,99.705,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.648 | Acc: 83.883,99.701,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.651 | Acc: 83.764,99.660,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.653 | Acc: 83.736,99.645,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.654 | Acc: 83.777,99.618,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.653 | Acc: 83.827,99.597,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.654 | Acc: 83.689,99.594,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.657 | Acc: 83.671,99.604,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.655 | Acc: 83.760,99.618,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.654 | Acc: 83.866,99.611,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.654 | Acc: 83.884,99.614,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.653 | Acc: 83.916,99.633,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.652 | Acc: 83.929,99.631,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.651 | Acc: 83.981,99.632,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.650 | Acc: 84.008,99.638,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.649 | Acc: 84.031,99.632,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.647 | Acc: 84.063,99.639,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.433 | Acc: 66.406,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.402 | Acc: 63.951,74.033,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.460 | Acc: 63.777,73.399,77.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.449 | Acc: 63.640,73.540,77.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 0.654 | Acc: 80.469,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.666 | Acc: 83.557,99.628,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.652 | Acc: 83.975,99.638,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.650 | Acc: 84.170,99.603,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.646 | Acc: 84.394,99.595,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.640 | Acc: 84.545,99.613,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.644 | Acc: 84.330,99.619,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.641 | Acc: 84.397,99.645,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.639 | Acc: 84.390,99.651,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.639 | Acc: 84.371,99.646,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.642 | Acc: 84.231,99.658,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.642 | Acc: 84.209,99.661,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.642 | Acc: 84.258,99.669,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.643 | Acc: 84.237,99.674,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.643 | Acc: 84.255,99.680,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.645 | Acc: 84.152,99.678,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.646 | Acc: 84.154,99.669,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.647 | Acc: 84.105,99.661,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.647 | Acc: 84.100,99.665,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.647 | Acc: 84.088,99.668,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.458 | Acc: 66.406,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.423 | Acc: 63.690,74.070,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.478 | Acc: 63.662,73.304,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.462 | Acc: 63.550,73.502,77.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 0.587 | Acc: 84.375,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.649 | Acc: 83.259,99.740,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.653 | Acc: 83.632,99.695,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.643 | Acc: 84.055,99.680,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.633 | Acc: 84.385,99.672,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.635 | Acc: 84.375,99.621,99.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.639 | Acc: 84.175,99.638,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.641 | Acc: 84.081,99.640,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.640 | Acc: 84.215,99.631,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.640 | Acc: 84.138,99.637,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.642 | Acc: 84.072,99.639,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.641 | Acc: 84.138,99.643,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.642 | Acc: 84.119,99.653,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.641 | Acc: 84.082,99.656,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.643 | Acc: 84.083,99.647,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.645 | Acc: 84.043,99.644,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.648 | Acc: 83.978,99.640,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.648 | Acc: 83.983,99.654,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.647 | Acc: 84.035,99.654,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.648 | Acc: 84.002,99.656,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.388 | Acc: 67.188,74.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.412 | Acc: 63.765,74.033,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.468 | Acc: 63.720,73.399,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.457 | Acc: 63.640,73.386,77.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 0.555 | Acc: 87.500,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.614 | Acc: 85.007,99.665,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.635 | Acc: 84.947,99.657,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.637 | Acc: 84.644,99.705,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.635 | Acc: 84.780,99.653,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.636 | Acc: 84.592,99.667,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.637 | Acc: 84.582,99.703,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.641 | Acc: 84.392,99.679,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.645 | Acc: 84.322,99.665,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.647 | Acc: 84.211,99.650,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.646 | Acc: 84.258,99.662,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.646 | Acc: 84.145,99.654,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.645 | Acc: 84.096,99.653,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.646 | Acc: 84.058,99.656,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.645 | Acc: 84.078,99.658,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.647 | Acc: 84.009,99.663,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.648 | Acc: 83.961,99.667,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.649 | Acc: 83.896,99.675,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.649 | Acc: 83.886,99.662,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.648 | Acc: 83.924,99.666,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.413 | Acc: 67.188,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.413 | Acc: 63.802,73.996,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.467 | Acc: 63.872,73.247,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.451 | Acc: 63.665,73.373,77.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 0.682 | Acc: 82.812,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.657 | Acc: 83.519,99.814,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.664 | Acc: 83.765,99.714,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.650 | Acc: 84.221,99.718,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.654 | Acc: 83.999,99.682,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.651 | Acc: 83.973,99.698,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.648 | Acc: 84.136,99.709,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.648 | Acc: 84.181,99.684,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.646 | Acc: 84.200,99.694,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.648 | Acc: 84.081,99.689,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.648 | Acc: 84.134,99.674,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.649 | Acc: 84.106,99.675,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.649 | Acc: 84.125,99.669,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.649 | Acc: 84.094,99.680,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.647 | Acc: 84.072,99.686,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.647 | Acc: 84.089,99.670,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.649 | Acc: 83.988,99.671,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.648 | Acc: 84.034,99.663,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.649 | Acc: 84.029,99.649,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.649 | Acc: 84.028,99.656,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.375 | Acc: 66.406,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.400 | Acc: 63.430,73.884,77.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.453 | Acc: 63.815,73.418,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.438 | Acc: 63.730,73.476,77.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 0.635 | Acc: 82.812,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.622 | Acc: 84.003,99.628,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.650 | Acc: 83.422,99.733,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.641 | Acc: 83.927,99.718,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.639 | Acc: 84.047,99.730,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.651 | Acc: 83.687,99.675,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.650 | Acc: 83.787,99.684,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.644 | Acc: 84.004,99.662,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.642 | Acc: 84.069,99.636,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.643 | Acc: 84.056,99.646,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.643 | Acc: 84.068,99.635,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.644 | Acc: 84.082,99.643,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.645 | Acc: 84.038,99.650,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.647 | Acc: 83.980,99.647,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.647 | Acc: 83.983,99.633,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.647 | Acc: 83.905,99.629,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.649 | Acc: 83.823,99.632,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.648 | Acc: 83.873,99.627,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.648 | Acc: 83.899,99.621,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.647 | Acc: 83.914,99.617,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.331 | Acc: 67.969,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.398 | Acc: 63.951,73.884,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.452 | Acc: 63.910,73.361,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.436 | Acc: 63.794,73.361,77.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 0.543 | Acc: 83.594,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.675 | Acc: 83.073,99.628,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.639 | Acc: 84.489,99.638,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.644 | Acc: 84.132,99.616,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.643 | Acc: 84.008,99.662,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.645 | Acc: 84.019,99.644,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.642 | Acc: 84.110,99.619,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.647 | Acc: 83.915,99.618,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.643 | Acc: 84.055,99.607,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.643 | Acc: 84.073,99.612,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.645 | Acc: 83.932,99.619,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.648 | Acc: 83.877,99.625,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.645 | Acc: 83.931,99.640,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.645 | Acc: 83.989,99.635,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.644 | Acc: 84.033,99.636,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.643 | Acc: 84.074,99.652,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.645 | Acc: 84.032,99.635,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.644 | Acc: 84.084,99.643,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.645 | Acc: 84.059,99.649,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.645 | Acc: 84.086,99.651,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.410 | Acc: 65.625,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.407 | Acc: 63.690,73.847,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.469 | Acc: 63.777,73.228,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.452 | Acc: 63.704,73.425,77.549,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 0.595 | Acc: 85.938,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.643 | Acc: 84.338,99.702,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.644 | Acc: 84.375,99.752,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.649 | Acc: 84.221,99.718,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.642 | Acc: 84.443,99.720,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.635 | Acc: 84.661,99.729,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.637 | Acc: 84.478,99.748,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.637 | Acc: 84.453,99.729,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.638 | Acc: 84.331,99.719,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.639 | Acc: 84.310,99.715,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.640 | Acc: 84.356,99.705,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.641 | Acc: 84.290,99.700,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.641 | Acc: 84.268,99.702,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.643 | Acc: 84.264,99.701,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.640 | Acc: 84.369,99.697,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.641 | Acc: 84.320,99.704,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.641 | Acc: 84.273,99.706,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.642 | Acc: 84.203,99.702,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.642 | Acc: 84.239,99.682,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.641 | Acc: 84.242,99.680,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.422 | Acc: 67.188,72.656,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.412 | Acc: 63.839,73.884,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.471 | Acc: 63.815,73.190,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.457 | Acc: 63.653,73.386,77.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 0.700 | Acc: 81.250,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.615 | Acc: 84.821,99.702,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.620 | Acc: 84.508,99.619,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.640 | Acc: 84.157,99.680,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.647 | Acc: 84.018,99.662,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.643 | Acc: 84.050,99.667,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.641 | Acc: 84.155,99.684,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.641 | Acc: 84.104,99.679,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.646 | Acc: 83.938,99.685,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.647 | Acc: 83.874,99.672,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.646 | Acc: 83.947,99.670,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.645 | Acc: 83.944,99.654,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.647 | Acc: 83.895,99.660,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.647 | Acc: 83.929,99.665,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.647 | Acc: 83.911,99.677,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.647 | Acc: 83.905,99.668,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.647 | Acc: 83.939,99.671,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.646 | Acc: 83.969,99.666,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.645 | Acc: 84.009,99.665,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.647 | Acc: 83.990,99.668,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.474 | Acc: 67.969,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.416 | Acc: 63.876,73.884,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.468 | Acc: 63.929,73.285,77.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.454 | Acc: 63.730,73.284,77.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 0.598 | Acc: 85.938,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.652 | Acc: 84.524,99.665,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.656 | Acc: 83.803,99.638,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.651 | Acc: 83.991,99.629,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.650 | Acc: 83.970,99.624,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.643 | Acc: 84.011,99.636,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.638 | Acc: 84.343,99.645,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.639 | Acc: 84.225,99.656,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.640 | Acc: 84.142,99.626,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.642 | Acc: 84.060,99.629,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.640 | Acc: 84.173,99.639,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.641 | Acc: 84.110,99.657,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.643 | Acc: 84.106,99.653,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.644 | Acc: 84.067,99.650,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.643 | Acc: 84.114,99.644,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.644 | Acc: 84.154,99.629,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.645 | Acc: 84.139,99.625,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.645 | Acc: 84.167,99.633,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.644 | Acc: 84.185,99.634,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.644 | Acc: 84.193,99.635,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.427 | Acc: 67.969,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.432 | Acc: 63.802,73.772,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.486 | Acc: 63.624,73.323,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.470 | Acc: 63.499,73.386,77.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 0.559 | Acc: 87.500,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.643 | Acc: 82.999,99.740,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.635 | Acc: 83.937,99.714,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.638 | Acc: 83.927,99.693,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.642 | Acc: 83.767,99.691,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.638 | Acc: 84.035,99.714,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.638 | Acc: 84.149,99.690,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.640 | Acc: 84.115,99.662,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.638 | Acc: 84.234,99.670,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.637 | Acc: 84.310,99.685,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.637 | Acc: 84.359,99.670,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.636 | Acc: 84.428,99.675,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.636 | Acc: 84.391,99.686,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.636 | Acc: 84.462,99.680,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.636 | Acc: 84.458,99.694,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.636 | Acc: 84.484,99.694,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.637 | Acc: 84.487,99.681,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.639 | Acc: 84.393,99.672,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.641 | Acc: 84.310,99.671,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.641 | Acc: 84.264,99.668,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.451 | Acc: 67.969,73.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.407 | Acc: 64.025,73.624,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.468 | Acc: 63.929,73.018,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.456 | Acc: 63.742,73.194,77.344,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 0.709 | Acc: 82.812,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.639 | Acc: 84.263,99.665,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.629 | Acc: 84.394,99.695,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.637 | Acc: 84.324,99.641,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.636 | Acc: 84.279,99.682,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.634 | Acc: 84.383,99.691,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.634 | Acc: 84.459,99.703,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.632 | Acc: 84.419,99.701,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.635 | Acc: 84.360,99.675,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.639 | Acc: 84.185,99.655,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.641 | Acc: 84.087,99.666,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.643 | Acc: 84.014,99.654,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.644 | Acc: 84.077,99.663,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.643 | Acc: 84.094,99.662,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.642 | Acc: 84.166,99.664,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.643 | Acc: 84.092,99.652,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.642 | Acc: 84.098,99.647,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.643 | Acc: 84.144,99.638,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.642 | Acc: 84.195,99.639,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.643 | Acc: 84.162,99.637,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.387 | Acc: 66.406,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.406 | Acc: 63.616,73.996,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.465 | Acc: 63.834,73.323,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.449 | Acc: 63.806,73.425,77.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 0.588 | Acc: 89.844,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.631 | Acc: 85.045,99.665,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.638 | Acc: 84.661,99.676,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.636 | Acc: 84.567,99.641,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.640 | Acc: 84.086,99.691,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.637 | Acc: 84.251,99.737,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.638 | Acc: 84.136,99.716,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.639 | Acc: 84.070,99.729,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.639 | Acc: 84.084,99.719,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.635 | Acc: 84.159,99.724,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.637 | Acc: 84.064,99.697,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.639 | Acc: 83.979,99.696,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.641 | Acc: 83.986,99.695,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.641 | Acc: 84.016,99.674,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.640 | Acc: 84.064,99.669,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.641 | Acc: 84.058,99.683,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.640 | Acc: 84.083,99.698,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.642 | Acc: 84.029,99.702,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.645 | Acc: 83.925,99.695,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.646 | Acc: 83.885,99.692,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.373 | Acc: 67.969,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.401 | Acc: 63.914,74.033,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.462 | Acc: 63.720,73.323,77.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.449 | Acc: 63.717,73.438,77.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 0.607 | Acc: 90.625,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.673 | Acc: 82.701,99.628,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.664 | Acc: 83.194,99.619,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.652 | Acc: 83.683,99.680,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.648 | Acc: 83.806,99.711,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.650 | Acc: 83.764,99.660,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.651 | Acc: 83.697,99.651,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.646 | Acc: 83.898,99.662,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.646 | Acc: 83.953,99.665,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.645 | Acc: 83.978,99.659,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.646 | Acc: 83.940,99.650,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.645 | Acc: 83.954,99.636,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.645 | Acc: 83.960,99.640,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.646 | Acc: 83.944,99.626,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.644 | Acc: 83.980,99.630,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.645 | Acc: 83.957,99.634,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.645 | Acc: 83.983,99.642,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.643 | Acc: 84.018,99.647,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.645 | Acc: 83.998,99.643,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.645 | Acc: 84.047,99.639,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.388 | Acc: 65.625,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.409 | Acc: 63.393,73.958,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.464 | Acc: 63.510,73.228,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.449 | Acc: 63.550,73.322,77.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 0.558 | Acc: 85.938,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.638 | Acc: 84.412,99.777,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.639 | Acc: 84.127,99.733,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.640 | Acc: 84.465,99.757,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.644 | Acc: 84.307,99.682,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.648 | Acc: 84.182,99.613,99.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.648 | Acc: 84.272,99.626,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.644 | Acc: 84.248,99.673,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.643 | Acc: 84.225,99.665,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.641 | Acc: 84.220,99.685,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.643 | Acc: 84.231,99.697,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.643 | Acc: 84.251,99.703,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.642 | Acc: 84.317,99.708,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.643 | Acc: 84.258,99.716,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.644 | Acc: 84.217,99.700,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.642 | Acc: 84.186,99.712,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.641 | Acc: 84.234,99.701,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.639 | Acc: 84.336,99.698,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.639 | Acc: 84.334,99.699,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.641 | Acc: 84.303,99.699,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.475 | Acc: 67.188,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.423 | Acc: 64.174,73.884,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.471 | Acc: 63.910,73.209,77.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.458 | Acc: 63.691,73.373,77.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 0.630 | Acc: 83.594,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.658 | Acc: 83.482,99.777,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.648 | Acc: 83.765,99.733,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.637 | Acc: 84.247,99.731,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.635 | Acc: 84.336,99.730,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.628 | Acc: 84.476,99.722,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.626 | Acc: 84.427,99.716,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.630 | Acc: 84.381,99.740,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.634 | Acc: 84.191,99.709,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.636 | Acc: 84.151,99.689,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.636 | Acc: 84.216,99.685,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.636 | Acc: 84.290,99.685,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.636 | Acc: 84.268,99.669,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.639 | Acc: 84.156,99.662,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.639 | Acc: 84.144,99.669,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.639 | Acc: 84.170,99.673,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.639 | Acc: 84.188,99.681,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.639 | Acc: 84.208,99.684,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.640 | Acc: 84.182,99.688,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.640 | Acc: 84.205,99.682,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.426 | Acc: 67.188,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.427 | Acc: 63.653,73.698,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.486 | Acc: 63.548,73.171,77.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.473 | Acc: 63.627,73.130,77.305,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 0.580 | Acc: 85.156,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.667 | Acc: 82.961,99.591,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.648 | Acc: 84.127,99.676,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.650 | Acc: 83.927,99.705,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.640 | Acc: 84.076,99.730,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.641 | Acc: 84.066,99.675,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.640 | Acc: 84.078,99.697,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.640 | Acc: 84.187,99.706,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.641 | Acc: 84.142,99.699,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.637 | Acc: 84.340,99.698,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.640 | Acc: 84.247,99.674,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.639 | Acc: 84.251,99.685,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.639 | Acc: 84.284,99.676,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.637 | Acc: 84.318,99.689,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.636 | Acc: 84.339,99.689,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.637 | Acc: 84.269,99.691,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.638 | Acc: 84.248,99.688,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.639 | Acc: 84.242,99.693,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.639 | Acc: 84.282,99.695,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.640 | Acc: 84.275,99.686,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.389 | Acc: 66.406,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.410 | Acc: 63.728,73.772,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.461 | Acc: 63.758,73.209,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.448 | Acc: 63.832,73.258,77.280,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 0.627 | Acc: 85.156,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.660 | Acc: 82.850,99.777,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.638 | Acc: 83.803,99.790,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.631 | Acc: 84.119,99.744,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.627 | Acc: 84.250,99.749,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.627 | Acc: 84.406,99.745,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.636 | Acc: 84.201,99.697,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.635 | Acc: 84.320,99.734,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.635 | Acc: 84.341,99.704,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.634 | Acc: 84.517,99.711,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.633 | Acc: 84.608,99.708,99.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.636 | Acc: 84.485,99.703,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.637 | Acc: 84.482,99.715,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.637 | Acc: 84.486,99.710,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.639 | Acc: 84.431,99.716,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.638 | Acc: 84.422,99.702,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.638 | Acc: 84.441,99.701,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.638 | Acc: 84.471,99.695,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.638 | Acc: 84.455,99.697,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.641 | Acc: 84.344,99.694,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.430 | Acc: 66.406,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.424 | Acc: 63.765,73.958,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.481 | Acc: 63.834,73.266,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.470 | Acc: 63.730,73.297,77.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 0.670 | Acc: 85.938,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.637 | Acc: 84.933,99.516,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.647 | Acc: 84.204,99.524,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.644 | Acc: 83.952,99.577,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.635 | Acc: 84.250,99.547,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.635 | Acc: 84.367,99.590,99.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.640 | Acc: 84.220,99.619,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.641 | Acc: 84.275,99.612,99.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.633 | Acc: 84.438,99.646,99.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.633 | Acc: 84.427,99.668,99.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.635 | Acc: 84.371,99.674,99.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.635 | Acc: 84.396,99.671,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.634 | Acc: 84.537,99.673,99.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.633 | Acc: 84.635,99.680,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.634 | Acc: 84.533,99.680,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.634 | Acc: 84.567,99.686,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.633 | Acc: 84.553,99.691,99.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.635 | Acc: 84.467,99.684,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.634 | Acc: 84.488,99.673,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.635 | Acc: 84.475,99.676,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.416 | Acc: 66.406,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.410 | Acc: 64.100,74.033,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.468 | Acc: 63.891,73.228,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.457 | Acc: 63.768,73.361,77.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 0.572 | Acc: 85.938,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.625 | Acc: 84.152,99.702,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.631 | Acc: 84.832,99.657,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.628 | Acc: 84.631,99.731,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.628 | Acc: 84.761,99.740,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.636 | Acc: 84.514,99.737,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.640 | Acc: 84.349,99.716,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.641 | Acc: 84.297,99.690,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.645 | Acc: 84.239,99.670,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.643 | Acc: 84.289,99.689,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.641 | Acc: 84.363,99.685,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.642 | Acc: 84.336,99.661,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.641 | Acc: 84.326,99.653,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.641 | Acc: 84.270,99.656,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.639 | Acc: 84.328,99.669,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.639 | Acc: 84.261,99.673,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.639 | Acc: 84.309,99.664,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.639 | Acc: 84.343,99.670,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.639 | Acc: 84.338,99.671,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.640 | Acc: 84.326,99.672,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.381 | Acc: 65.625,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.408 | Acc: 63.802,73.958,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.465 | Acc: 63.796,73.209,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.454 | Acc: 63.704,73.258,77.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 0.511 | Acc: 88.281,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.651 | Acc: 84.152,99.479,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.649 | Acc: 83.880,99.600,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.645 | Acc: 83.850,99.667,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.644 | Acc: 84.047,99.653,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.642 | Acc: 84.127,99.667,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.643 | Acc: 84.136,99.671,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.643 | Acc: 84.164,99.640,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.640 | Acc: 84.263,99.641,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.639 | Acc: 84.375,99.659,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.638 | Acc: 84.422,99.666,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.635 | Acc: 84.460,99.675,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.636 | Acc: 84.398,99.673,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.639 | Acc: 84.270,99.659,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.636 | Acc: 84.344,99.661,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.635 | Acc: 84.398,99.668,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.635 | Acc: 84.390,99.674,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.634 | Acc: 84.444,99.672,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.634 | Acc: 84.418,99.680,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.634 | Acc: 84.441,99.680,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.439 | Acc: 66.406,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.419 | Acc: 64.174,73.624,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.478 | Acc: 64.024,73.056,77.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.467 | Acc: 63.794,73.130,77.254,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 0.635 | Acc: 85.156,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.610 | Acc: 85.342,99.628,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.626 | Acc: 84.680,99.581,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.630 | Acc: 84.567,99.565,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.632 | Acc: 84.346,99.605,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.634 | Acc: 84.274,99.598,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.634 | Acc: 84.233,99.619,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.631 | Acc: 84.464,99.618,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.628 | Acc: 84.525,99.641,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.631 | Acc: 84.392,99.655,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.632 | Acc: 84.383,99.666,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.631 | Acc: 84.421,99.668,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.634 | Acc: 84.346,99.673,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.634 | Acc: 84.405,99.674,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.635 | Acc: 84.375,99.677,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.635 | Acc: 84.372,99.678,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.638 | Acc: 84.300,99.671,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.635 | Acc: 84.334,99.672,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.635 | Acc: 84.319,99.673,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.636 | Acc: 84.264,99.680,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.384 | Acc: 67.188,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.411 | Acc: 64.100,73.847,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.471 | Acc: 63.891,73.133,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.459 | Acc: 63.691,73.181,77.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 0.738 | Acc: 79.688,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.651 | Acc: 83.296,99.740,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.630 | Acc: 84.318,99.695,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.628 | Acc: 84.529,99.705,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.622 | Acc: 84.693,99.711,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.628 | Acc: 84.537,99.737,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.631 | Acc: 84.575,99.690,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.635 | Acc: 84.519,99.673,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.634 | Acc: 84.545,99.689,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.635 | Acc: 84.483,99.694,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.632 | Acc: 84.464,99.708,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.633 | Acc: 84.488,99.714,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.633 | Acc: 84.482,99.695,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.632 | Acc: 84.483,99.701,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.632 | Acc: 84.506,99.697,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.634 | Acc: 84.417,99.702,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.634 | Acc: 84.382,99.693,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.632 | Acc: 84.496,99.704,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.634 | Acc: 84.451,99.699,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.634 | Acc: 84.465,99.699,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.395 | Acc: 66.406,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.407 | Acc: 63.951,73.921,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.468 | Acc: 63.700,73.247,77.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.457 | Acc: 63.499,73.156,77.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 0.585 | Acc: 84.375,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.633 | Acc: 83.966,99.702,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.641 | Acc: 83.937,99.752,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.634 | Acc: 84.234,99.795,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.636 | Acc: 84.240,99.769,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.637 | Acc: 84.290,99.760,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.635 | Acc: 84.388,99.748,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.634 | Acc: 84.458,99.729,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.634 | Acc: 84.516,99.728,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.632 | Acc: 84.530,99.732,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.635 | Acc: 84.480,99.755,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.635 | Acc: 84.523,99.742,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.632 | Acc: 84.592,99.737,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.633 | Acc: 84.570,99.728,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.634 | Acc: 84.586,99.736,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.634 | Acc: 84.549,99.738,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.635 | Acc: 84.485,99.732,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.635 | Acc: 84.467,99.739,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.635 | Acc: 84.464,99.736,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.635 | Acc: 84.547,99.723,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.436 | Acc: 66.406,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.407 | Acc: 63.876,73.847,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.467 | Acc: 63.910,73.228,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.454 | Acc: 63.704,73.335,77.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 0.622 | Acc: 85.156,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.611 | Acc: 85.007,99.740,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.626 | Acc: 84.451,99.733,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.630 | Acc: 84.490,99.744,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.633 | Acc: 84.365,99.749,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.634 | Acc: 84.282,99.737,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.637 | Acc: 84.110,99.729,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.633 | Acc: 84.220,99.740,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.635 | Acc: 84.176,99.743,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.634 | Acc: 84.315,99.732,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.633 | Acc: 84.278,99.736,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.634 | Acc: 84.336,99.721,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.635 | Acc: 84.352,99.721,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.636 | Acc: 84.327,99.719,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.633 | Acc: 84.417,99.728,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.634 | Acc: 84.401,99.735,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.632 | Acc: 84.458,99.730,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.633 | Acc: 84.469,99.718,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.632 | Acc: 84.481,99.723,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.632 | Acc: 84.502,99.721,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.424 | Acc: 66.406,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.423 | Acc: 63.914,73.735,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.480 | Acc: 63.910,73.018,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.468 | Acc: 63.678,73.143,77.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 0.497 | Acc: 85.156,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.658 | Acc: 83.891,99.665,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.664 | Acc: 83.518,99.752,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.657 | Acc: 83.453,99.705,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.646 | Acc: 83.883,99.749,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.636 | Acc: 84.151,99.745,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.628 | Acc: 84.485,99.748,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.627 | Acc: 84.536,99.762,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.629 | Acc: 84.579,99.748,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.630 | Acc: 84.466,99.745,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.629 | Acc: 84.565,99.736,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.631 | Acc: 84.502,99.749,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.630 | Acc: 84.589,99.747,99.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.630 | Acc: 84.573,99.752,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.630 | Acc: 84.600,99.755,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.632 | Acc: 84.497,99.756,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.632 | Acc: 84.450,99.744,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.633 | Acc: 84.430,99.737,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.630 | Acc: 84.539,99.740,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.631 | Acc: 84.514,99.731,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.425 | Acc: 66.406,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.422 | Acc: 63.839,73.996,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.478 | Acc: 63.891,73.190,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.468 | Acc: 63.653,73.271,77.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 0.654 | Acc: 86.719,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.603 | Acc: 85.789,99.777,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.615 | Acc: 85.156,99.809,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.625 | Acc: 85.041,99.731,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.625 | Acc: 85.012,99.711,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.626 | Acc: 84.971,99.722,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.625 | Acc: 84.956,99.716,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.628 | Acc: 84.813,99.706,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.628 | Acc: 84.773,99.709,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.630 | Acc: 84.707,99.706,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.629 | Acc: 84.705,99.728,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.632 | Acc: 84.647,99.728,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.631 | Acc: 84.618,99.721,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.634 | Acc: 84.471,99.725,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.634 | Acc: 84.447,99.722,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.633 | Acc: 84.479,99.720,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.632 | Acc: 84.562,99.720,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.632 | Acc: 84.529,99.725,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.632 | Acc: 84.533,99.729,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.632 | Acc: 84.584,99.723,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.406 | Acc: 67.969,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.408 | Acc: 63.988,74.070,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.467 | Acc: 63.948,73.209,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.456 | Acc: 63.819,73.335,77.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 0.608 | Acc: 85.938,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.637 | Acc: 84.747,99.368,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.627 | Acc: 85.099,99.486,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.626 | Acc: 85.156,99.539,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.626 | Acc: 85.012,99.605,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.628 | Acc: 84.646,99.636,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.631 | Acc: 84.562,99.619,99.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.630 | Acc: 84.558,99.640,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.629 | Acc: 84.627,99.655,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.631 | Acc: 84.517,99.659,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.631 | Acc: 84.414,99.662,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.633 | Acc: 84.400,99.664,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.631 | Acc: 84.450,99.666,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.633 | Acc: 84.432,99.659,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.632 | Acc: 84.486,99.677,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.631 | Acc: 84.541,99.681,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.630 | Acc: 84.587,99.679,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.632 | Acc: 84.540,99.679,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.634 | Acc: 84.490,99.673,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.634 | Acc: 84.498,99.666,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.415 | Acc: 67.188,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.414 | Acc: 64.137,74.182,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.471 | Acc: 63.948,73.418,77.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.457 | Acc: 63.742,73.489,77.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 0.597 | Acc: 86.719,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.624 | Acc: 84.487,99.479,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.631 | Acc: 84.527,99.619,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.634 | Acc: 84.503,99.667,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.630 | Acc: 84.568,99.701,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.626 | Acc: 84.615,99.722,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.624 | Acc: 84.549,99.716,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.625 | Acc: 84.536,99.729,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.624 | Acc: 84.535,99.738,99.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.627 | Acc: 84.414,99.737,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.628 | Acc: 84.437,99.728,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.626 | Acc: 84.485,99.724,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.629 | Acc: 84.453,99.711,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.628 | Acc: 84.477,99.713,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.630 | Acc: 84.403,99.716,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.631 | Acc: 84.385,99.704,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.630 | Acc: 84.419,99.706,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.629 | Acc: 84.428,99.714,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.628 | Acc: 84.440,99.716,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.629 | Acc: 84.404,99.713,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.424 | Acc: 66.406,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.413 | Acc: 63.914,73.847,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.475 | Acc: 63.834,73.209,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.463 | Acc: 63.704,73.297,77.344,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 0.731 | Acc: 81.250,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.652 | Acc: 84.226,99.591,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.645 | Acc: 84.356,99.600,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.640 | Acc: 84.554,99.616,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.641 | Acc: 84.500,99.633,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.637 | Acc: 84.630,99.667,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.635 | Acc: 84.607,99.658,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.634 | Acc: 84.619,99.651,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.630 | Acc: 84.724,99.660,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.633 | Acc: 84.656,99.637,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.632 | Acc: 84.663,99.642,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.632 | Acc: 84.622,99.664,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.630 | Acc: 84.657,99.653,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.632 | Acc: 84.599,99.662,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.633 | Acc: 84.514,99.666,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.635 | Acc: 84.455,99.663,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.635 | Acc: 84.455,99.674,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.635 | Acc: 84.444,99.677,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.636 | Acc: 84.390,99.680,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.636 | Acc: 84.342,99.676,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.392 | Acc: 67.188,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.409 | Acc: 63.951,73.958,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.473 | Acc: 63.872,73.133,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.461 | Acc: 63.768,73.245,77.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 0.798 | Acc: 82.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.673 | Acc: 82.961,99.777,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.647 | Acc: 83.918,99.752,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.641 | Acc: 84.221,99.680,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.646 | Acc: 84.259,99.682,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.643 | Acc: 84.205,99.652,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.638 | Acc: 84.323,99.651,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.635 | Acc: 84.381,99.640,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.634 | Acc: 84.341,99.670,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.636 | Acc: 84.280,99.676,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.634 | Acc: 84.363,99.681,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.634 | Acc: 84.333,99.668,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.634 | Acc: 84.323,99.663,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.634 | Acc: 84.402,99.650,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.633 | Acc: 84.403,99.664,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.634 | Acc: 84.346,99.670,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.635 | Acc: 84.341,99.664,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.631 | Acc: 84.448,99.672,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.633 | Acc: 84.440,99.652,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.631 | Acc: 84.508,99.662,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.413 | Acc: 67.188,74.219,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.412 | Acc: 63.876,74.144,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.473 | Acc: 63.758,73.399,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.460 | Acc: 63.665,73.463,77.408,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 0.594 | Acc: 87.500,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.644 | Acc: 84.301,99.628,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.647 | Acc: 84.184,99.581,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.655 | Acc: 83.735,99.565,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.643 | Acc: 84.066,99.643,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.644 | Acc: 84.143,99.660,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.643 | Acc: 84.233,99.651,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.638 | Acc: 84.447,99.679,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.638 | Acc: 84.496,99.685,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.639 | Acc: 84.483,99.698,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.638 | Acc: 84.503,99.697,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.636 | Acc: 84.580,99.707,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.636 | Acc: 84.557,99.715,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.635 | Acc: 84.588,99.719,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.636 | Acc: 84.553,99.725,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.637 | Acc: 84.526,99.720,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.636 | Acc: 84.614,99.727,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.634 | Acc: 84.684,99.730,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.633 | Acc: 84.659,99.727,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.633 | Acc: 84.678,99.723,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.387 | Acc: 67.188,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.404 | Acc: 63.988,73.921,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.463 | Acc: 63.929,73.266,77.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.449 | Acc: 63.806,73.348,77.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 0.751 | Acc: 82.812,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.663 | Acc: 84.152,99.702,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.649 | Acc: 84.642,99.676,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.645 | Acc: 84.362,99.680,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.642 | Acc: 84.529,99.730,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.642 | Acc: 84.499,99.722,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.638 | Acc: 84.478,99.729,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.635 | Acc: 84.530,99.717,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.639 | Acc: 84.390,99.719,99.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.639 | Acc: 84.336,99.719,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.640 | Acc: 84.356,99.728,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.638 | Acc: 84.371,99.724,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.636 | Acc: 84.511,99.711,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.637 | Acc: 84.468,99.713,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.638 | Acc: 84.445,99.716,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.638 | Acc: 84.414,99.712,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.638 | Acc: 84.370,99.706,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.637 | Acc: 84.414,99.704,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.636 | Acc: 84.464,99.701,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.636 | Acc: 84.430,99.707,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.402 | Acc: 67.188,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.408 | Acc: 63.765,73.772,77.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.470 | Acc: 63.739,73.056,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.457 | Acc: 63.640,73.207,77.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 0.632 | Acc: 85.938,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.612 | Acc: 85.082,99.665,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.636 | Acc: 84.470,99.657,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.635 | Acc: 84.349,99.693,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.627 | Acc: 84.500,99.701,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.633 | Acc: 84.483,99.714,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.633 | Acc: 84.530,99.709,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.635 | Acc: 84.502,99.729,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.633 | Acc: 84.564,99.728,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.636 | Acc: 84.388,99.728,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.634 | Acc: 84.398,99.724,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.632 | Acc: 84.449,99.728,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.632 | Acc: 84.511,99.741,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.632 | Acc: 84.498,99.734,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.632 | Acc: 84.553,99.722,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.631 | Acc: 84.611,99.709,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.632 | Acc: 84.584,99.713,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.632 | Acc: 84.556,99.714,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.634 | Acc: 84.498,99.708,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.633 | Acc: 84.574,99.715,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.431 | Acc: 67.188,74.219,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.418 | Acc: 63.876,73.810,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.479 | Acc: 63.796,73.171,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.465 | Acc: 63.640,73.361,77.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 0.643 | Acc: 85.156,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.638 | Acc: 84.301,99.591,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.649 | Acc: 83.880,99.752,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.650 | Acc: 84.016,99.769,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.639 | Acc: 84.240,99.749,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.640 | Acc: 84.213,99.729,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.636 | Acc: 84.317,99.742,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.636 | Acc: 84.331,99.723,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.639 | Acc: 84.288,99.738,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.637 | Acc: 84.319,99.732,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.636 | Acc: 84.309,99.728,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.637 | Acc: 84.269,99.717,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.634 | Acc: 84.343,99.728,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.636 | Acc: 84.315,99.728,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.636 | Acc: 84.300,99.730,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.635 | Acc: 84.357,99.730,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.634 | Acc: 84.365,99.725,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.635 | Acc: 84.341,99.730,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.635 | Acc: 84.291,99.727,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.635 | Acc: 84.293,99.723,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.451 | Acc: 67.188,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.429 | Acc: 64.062,73.772,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.485 | Acc: 63.853,73.095,77.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.470 | Acc: 63.742,73.284,77.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 0.612 | Acc: 86.719,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.615 | Acc: 85.156,99.591,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.627 | Acc: 84.737,99.733,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.629 | Acc: 84.541,99.731,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.625 | Acc: 84.635,99.769,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.624 | Acc: 84.723,99.745,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.628 | Acc: 84.698,99.735,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.630 | Acc: 84.597,99.729,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.633 | Acc: 84.487,99.719,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.633 | Acc: 84.448,99.711,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.630 | Acc: 84.562,99.720,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.629 | Acc: 84.605,99.714,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.631 | Acc: 84.511,99.695,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.630 | Acc: 84.492,99.704,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.630 | Acc: 84.489,99.714,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.631 | Acc: 84.468,99.712,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.630 | Acc: 84.482,99.703,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.632 | Acc: 84.451,99.693,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.633 | Acc: 84.371,99.691,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.634 | Acc: 84.361,99.699,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.394 | Acc: 67.188,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.422 | Acc: 63.914,73.958,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.482 | Acc: 63.891,73.285,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.467 | Acc: 63.781,73.309,77.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 0.663 | Acc: 82.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.617 | Acc: 84.635,99.665,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.619 | Acc: 84.375,99.752,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.621 | Acc: 84.836,99.757,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.632 | Acc: 84.664,99.740,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.628 | Acc: 84.739,99.714,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.630 | Acc: 84.653,99.716,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.633 | Acc: 84.502,99.690,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.629 | Acc: 84.681,99.689,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.627 | Acc: 84.755,99.706,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.626 | Acc: 84.717,99.716,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.624 | Acc: 84.803,99.731,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.624 | Acc: 84.764,99.728,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.624 | Acc: 84.755,99.725,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.627 | Acc: 84.720,99.725,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.630 | Acc: 84.627,99.717,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.631 | Acc: 84.558,99.718,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.631 | Acc: 84.547,99.714,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.633 | Acc: 84.509,99.719,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.632 | Acc: 84.514,99.721,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.418 | Acc: 67.969,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.412 | Acc: 63.988,73.847,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.471 | Acc: 63.853,73.304,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.457 | Acc: 63.691,73.348,77.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 0.539 | Acc: 88.281,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.605 | Acc: 85.938,99.851,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.619 | Acc: 85.328,99.790,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.617 | Acc: 85.143,99.718,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.619 | Acc: 85.098,99.614,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.620 | Acc: 85.087,99.621,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.626 | Acc: 84.879,99.626,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.625 | Acc: 84.901,99.640,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.633 | Acc: 84.491,99.612,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.635 | Acc: 84.362,99.612,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.632 | Acc: 84.433,99.631,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.632 | Acc: 84.446,99.646,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.634 | Acc: 84.326,99.666,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.633 | Acc: 84.408,99.671,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.632 | Acc: 84.428,99.669,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.632 | Acc: 84.479,99.670,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.631 | Acc: 84.536,99.676,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.631 | Acc: 84.540,99.677,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.630 | Acc: 84.589,99.686,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.630 | Acc: 84.584,99.684,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.399 | Acc: 67.188,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.420 | Acc: 63.914,73.884,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.477 | Acc: 63.777,73.228,77.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.463 | Acc: 63.576,73.335,77.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 0.606 | Acc: 82.812,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.639 | Acc: 84.226,99.665,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.640 | Acc: 84.184,99.657,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.653 | Acc: 83.747,99.693,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.643 | Acc: 84.066,99.740,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.634 | Acc: 84.383,99.737,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.636 | Acc: 84.246,99.703,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.634 | Acc: 84.198,99.712,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.636 | Acc: 84.244,99.694,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.636 | Acc: 84.258,99.689,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.635 | Acc: 84.266,99.697,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.634 | Acc: 84.442,99.689,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.634 | Acc: 84.498,99.692,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.632 | Acc: 84.579,99.689,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.632 | Acc: 84.578,99.694,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.633 | Acc: 84.549,99.704,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.634 | Acc: 84.502,99.696,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.633 | Acc: 84.517,99.700,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.633 | Acc: 84.490,99.708,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.632 | Acc: 84.545,99.719,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.432 | Acc: 66.406,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.423 | Acc: 63.616,73.735,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.477 | Acc: 63.681,73.171,77.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.461 | Acc: 63.627,73.335,77.446,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 0.565 | Acc: 84.375,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.621 | Acc: 84.710,99.591,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.625 | Acc: 84.451,99.676,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.635 | Acc: 84.311,99.654,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.633 | Acc: 84.394,99.633,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.630 | Acc: 84.623,99.652,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.625 | Acc: 84.827,99.684,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.629 | Acc: 84.719,99.679,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.632 | Acc: 84.555,99.651,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.634 | Acc: 84.440,99.650,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.632 | Acc: 84.461,99.666,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.632 | Acc: 84.400,99.671,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.634 | Acc: 84.313,99.686,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.634 | Acc: 84.363,99.686,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.634 | Acc: 84.389,99.697,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.634 | Acc: 84.398,99.702,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.633 | Acc: 84.441,99.710,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.634 | Acc: 84.389,99.711,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.634 | Acc: 84.466,99.712,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.633 | Acc: 84.441,99.721,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.393 | Acc: 67.188,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.417 | Acc: 63.914,73.810,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.474 | Acc: 63.891,73.133,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.462 | Acc: 63.755,73.156,77.395,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 0.440 | Acc: 87.500,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.660 | Acc: 83.966,99.740,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.656 | Acc: 84.051,99.733,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.648 | Acc: 84.439,99.641,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.648 | Acc: 84.327,99.633,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.643 | Acc: 84.375,99.644,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.643 | Acc: 84.298,99.677,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.642 | Acc: 84.264,99.673,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.641 | Acc: 84.336,99.680,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.640 | Acc: 84.392,99.681,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.637 | Acc: 84.394,99.681,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.634 | Acc: 84.481,99.692,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.635 | Acc: 84.388,99.679,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.634 | Acc: 84.459,99.692,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.634 | Acc: 84.450,99.691,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.634 | Acc: 84.479,99.707,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.634 | Acc: 84.489,99.701,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.633 | Acc: 84.492,99.704,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.634 | Acc: 84.479,99.704,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.634 | Acc: 84.469,99.697,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.404 | Acc: 66.406,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.422 | Acc: 63.690,73.996,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.474 | Acc: 63.777,73.228,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.457 | Acc: 63.678,73.309,77.587,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 0.783 | Acc: 82.031,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.644 | Acc: 84.524,99.702,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.633 | Acc: 84.546,99.657,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.628 | Acc: 84.580,99.680,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.624 | Acc: 84.635,99.672,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.626 | Acc: 84.514,99.675,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.625 | Acc: 84.530,99.684,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.626 | Acc: 84.514,99.684,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.627 | Acc: 84.491,99.694,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.626 | Acc: 84.492,99.689,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.627 | Acc: 84.484,99.697,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.627 | Acc: 84.509,99.703,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.628 | Acc: 84.537,99.708,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.630 | Acc: 84.495,99.701,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.630 | Acc: 84.514,99.700,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.632 | Acc: 84.476,99.702,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.632 | Acc: 84.487,99.698,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.632 | Acc: 84.535,99.702,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.631 | Acc: 84.535,99.710,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.633 | Acc: 84.510,99.711,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.429 | Acc: 66.406,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.425 | Acc: 63.690,74.070,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.479 | Acc: 63.681,73.247,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.464 | Acc: 63.525,73.373,77.574,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 0.665 | Acc: 82.031,100.000,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.656 | Acc: 83.891,99.740,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.654 | Acc: 84.337,99.714,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.645 | Acc: 84.529,99.718,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.645 | Acc: 84.500,99.701,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.648 | Acc: 84.305,99.745,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.645 | Acc: 84.472,99.735,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.644 | Acc: 84.397,99.734,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.644 | Acc: 84.356,99.723,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.640 | Acc: 84.353,99.711,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.641 | Acc: 84.352,99.685,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.638 | Acc: 84.428,99.700,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.635 | Acc: 84.498,99.705,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.637 | Acc: 84.432,99.692,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.637 | Acc: 84.461,99.700,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.636 | Acc: 84.468,99.707,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.635 | Acc: 84.579,99.703,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.635 | Acc: 84.586,99.709,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.634 | Acc: 84.596,99.712,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.632 | Acc: 84.637,99.713,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.412 | Acc: 67.188,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.422 | Acc: 64.100,73.698,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.479 | Acc: 63.891,73.133,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.466 | Acc: 63.768,73.143,77.267,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 0.484 | Acc: 86.719,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.629 | Acc: 84.375,99.814,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.629 | Acc: 84.756,99.752,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.634 | Acc: 84.285,99.757,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.635 | Acc: 84.365,99.720,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.631 | Acc: 84.561,99.722,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.628 | Acc: 84.743,99.729,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.629 | Acc: 84.658,99.717,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.630 | Acc: 84.535,99.733,99.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.630 | Acc: 84.617,99.719,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.631 | Acc: 84.503,99.724,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.634 | Acc: 84.463,99.731,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.632 | Acc: 84.540,99.737,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.631 | Acc: 84.540,99.743,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.631 | Acc: 84.558,99.741,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.631 | Acc: 84.567,99.746,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.630 | Acc: 84.609,99.735,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.631 | Acc: 84.567,99.739,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.631 | Acc: 84.563,99.729,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.632 | Acc: 84.580,99.733,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.413 | Acc: 66.406,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.416 | Acc: 63.467,74.070,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.471 | Acc: 63.491,73.247,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.458 | Acc: 63.422,73.450,77.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 0.527 | Acc: 89.844,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.632 | Acc: 84.821,99.702,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.626 | Acc: 84.585,99.714,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.635 | Acc: 84.247,99.718,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.628 | Acc: 84.394,99.711,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.631 | Acc: 84.182,99.737,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.630 | Acc: 84.323,99.722,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.632 | Acc: 84.331,99.695,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.631 | Acc: 84.360,99.694,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.630 | Acc: 84.349,99.694,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.629 | Acc: 84.359,99.681,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.630 | Acc: 84.354,99.678,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.631 | Acc: 84.362,99.679,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.630 | Acc: 84.432,99.677,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.629 | Acc: 84.414,99.666,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.630 | Acc: 84.398,99.665,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.634 | Acc: 84.292,99.667,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.634 | Acc: 84.286,99.670,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.635 | Acc: 84.260,99.660,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.633 | Acc: 84.330,99.662,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.437 | Acc: 65.625,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.423 | Acc: 63.988,73.884,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.479 | Acc: 63.853,73.018,77.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.467 | Acc: 63.691,73.130,77.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 0.588 | Acc: 82.812,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.635 | Acc: 83.557,99.628,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.633 | Acc: 83.918,99.638,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.626 | Acc: 84.452,99.705,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.638 | Acc: 84.288,99.691,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.635 | Acc: 84.390,99.706,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.636 | Acc: 84.375,99.729,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.636 | Acc: 84.358,99.734,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.639 | Acc: 84.293,99.723,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.637 | Acc: 84.379,99.732,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.634 | Acc: 84.472,99.736,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.635 | Acc: 84.379,99.735,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.635 | Acc: 84.336,99.724,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.636 | Acc: 84.306,99.716,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.635 | Acc: 84.356,99.719,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.636 | Acc: 84.328,99.725,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.636 | Acc: 84.302,99.715,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.637 | Acc: 84.274,99.716,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.635 | Acc: 84.369,99.721,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.633 | Acc: 84.445,99.717,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.398 | Acc: 67.969,72.656,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.419 | Acc: 63.914,73.586,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.475 | Acc: 63.834,72.942,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.463 | Acc: 63.755,73.207,77.331,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 0.626 | Acc: 86.719,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.621 | Acc: 84.338,99.740,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.612 | Acc: 84.642,99.638,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.622 | Acc: 84.580,99.616,99.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.627 | Acc: 84.578,99.643,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.628 | Acc: 84.584,99.675,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.632 | Acc: 84.388,99.690,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.634 | Acc: 84.325,99.673,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.631 | Acc: 84.414,99.680,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.633 | Acc: 84.345,99.685,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.629 | Acc: 84.550,99.685,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.630 | Acc: 84.523,99.675,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.631 | Acc: 84.501,99.686,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.629 | Acc: 84.543,99.704,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.630 | Acc: 84.545,99.694,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.630 | Acc: 84.518,99.689,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.630 | Acc: 84.511,99.698,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.630 | Acc: 84.563,99.700,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.632 | Acc: 84.516,99.699,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.631 | Acc: 84.564,99.694,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.411 | Acc: 67.188,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.425 | Acc: 63.951,73.884,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.475 | Acc: 63.777,73.228,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.463 | Acc: 63.653,73.245,77.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 0.613 | Acc: 81.250,98.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.634 | Acc: 84.933,99.702,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.638 | Acc: 84.508,99.752,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.639 | Acc: 84.413,99.693,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.630 | Acc: 84.471,99.720,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.630 | Acc: 84.545,99.698,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.627 | Acc: 84.743,99.709,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.625 | Acc: 84.890,99.684,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.623 | Acc: 84.943,99.699,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.623 | Acc: 84.949,99.681,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.626 | Acc: 84.865,99.677,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.627 | Acc: 84.799,99.692,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.625 | Acc: 84.796,99.699,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.627 | Acc: 84.716,99.707,99.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.626 | Acc: 84.778,99.711,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.627 | Acc: 84.757,99.704,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.628 | Acc: 84.733,99.703,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.629 | Acc: 84.723,99.707,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.629 | Acc: 84.723,99.706,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.630 | Acc: 84.637,99.705,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.404 | Acc: 66.406,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.424 | Acc: 63.728,73.996,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.479 | Acc: 63.662,73.152,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.463 | Acc: 63.589,73.245,77.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 0.647 | Acc: 80.469,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.642 | Acc: 84.487,99.591,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.622 | Acc: 84.661,99.714,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.627 | Acc: 84.657,99.718,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.622 | Acc: 84.819,99.691,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.625 | Acc: 84.754,99.706,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.621 | Acc: 84.795,99.716,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.623 | Acc: 84.591,99.729,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.625 | Acc: 84.603,99.719,99.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.627 | Acc: 84.504,99.711,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.627 | Acc: 84.573,99.689,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.626 | Acc: 84.633,99.692,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.624 | Acc: 84.676,99.692,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.626 | Acc: 84.573,99.701,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.628 | Acc: 84.528,99.700,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.630 | Acc: 84.422,99.702,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.629 | Acc: 84.470,99.703,99.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.630 | Acc: 84.462,99.698,99.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.629 | Acc: 84.464,99.706,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.630 | Acc: 84.420,99.690,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.452 | Acc: 66.406,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.435 | Acc: 63.579,73.772,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.485 | Acc: 63.739,73.075,76.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.468 | Acc: 63.627,73.271,77.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 0.617 | Acc: 82.031,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.645 | Acc: 83.594,99.814,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.637 | Acc: 84.032,99.771,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.642 | Acc: 83.965,99.667,99.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.636 | Acc: 84.356,99.691,99.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.635 | Acc: 84.220,99.714,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.631 | Acc: 84.478,99.697,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.629 | Acc: 84.597,99.701,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.630 | Acc: 84.661,99.709,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.632 | Acc: 84.591,99.685,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.632 | Acc: 84.558,99.662,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.635 | Acc: 84.421,99.668,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.634 | Acc: 84.427,99.679,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.635 | Acc: 84.348,99.686,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.634 | Acc: 84.325,99.689,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.633 | Acc: 84.487,99.670,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.632 | Acc: 84.531,99.676,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.631 | Acc: 84.531,99.672,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.631 | Acc: 84.548,99.673,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.631 | Acc: 84.570,99.676,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.437 | Acc: 68.750,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.420 | Acc: 63.914,74.182,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.473 | Acc: 63.815,73.361,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.460 | Acc: 63.691,73.412,77.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 0.598 | Acc: 87.500,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.620 | Acc: 85.231,99.628,99.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.624 | Acc: 84.947,99.695,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.620 | Acc: 84.734,99.705,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.617 | Acc: 84.848,99.672,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.623 | Acc: 84.723,99.683,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.629 | Acc: 84.659,99.690,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.629 | Acc: 84.685,99.701,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.628 | Acc: 84.656,99.728,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.630 | Acc: 84.574,99.728,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.630 | Acc: 84.515,99.716,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.630 | Acc: 84.520,99.724,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.629 | Acc: 84.537,99.728,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.628 | Acc: 84.528,99.725,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.630 | Acc: 84.425,99.719,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.630 | Acc: 84.422,99.717,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.630 | Acc: 84.424,99.725,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.630 | Acc: 84.467,99.718,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.631 | Acc: 84.483,99.710,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.633 | Acc: 84.441,99.699,99.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.419 | Acc: 67.969,73.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.415 | Acc: 64.174,73.810,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.471 | Acc: 63.986,73.095,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.459 | Acc: 63.883,73.156,77.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 0.607 | Acc: 85.156,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.621 | Acc: 84.821,99.554,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.628 | Acc: 84.546,99.676,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.637 | Acc: 84.221,99.693,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.634 | Acc: 84.288,99.691,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.632 | Acc: 84.452,99.691,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.632 | Acc: 84.407,99.690,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.631 | Acc: 84.441,99.717,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.632 | Acc: 84.370,99.685,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.632 | Acc: 84.427,99.685,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.631 | Acc: 84.480,99.705,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.631 | Acc: 84.467,99.703,99.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.629 | Acc: 84.576,99.708,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.631 | Acc: 84.510,99.710,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.632 | Acc: 84.503,99.711,99.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.630 | Acc: 84.544,99.707,99.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.632 | Acc: 84.482,99.715,99.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.630 | Acc: 84.490,99.720,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.632 | Acc: 84.440,99.723,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.631 | Acc: 84.457,99.731,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.427 | Acc: 67.969,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.416 | Acc: 64.137,73.847,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.473 | Acc: 63.929,73.304,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.460 | Acc: 63.755,73.425,77.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 0.646 | Acc: 82.812,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.624 | Acc: 84.784,99.777,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.628 | Acc: 84.966,99.714,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.626 | Acc: 85.015,99.744,99.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.626 | Acc: 84.944,99.769,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.628 | Acc: 84.677,99.745,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.625 | Acc: 84.756,99.748,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.629 | Acc: 84.597,99.723,99.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.630 | Acc: 84.491,99.738,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.631 | Acc: 84.405,99.728,99.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.630 | Acc: 84.445,99.740,99.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.626 | Acc: 84.470,99.735,99.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.627 | Acc: 84.463,99.718,99.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.624 | Acc: 84.608,99.719,99.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.627 | Acc: 84.572,99.694,99.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.628 | Acc: 84.575,99.696,99.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.629 | Acc: 84.560,99.701,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.629 | Acc: 84.538,99.702,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.628 | Acc: 84.568,99.704,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.628 | Acc: 84.545,99.699,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.443 | Acc: 67.188,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.425 | Acc: 63.839,73.772,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.478 | Acc: 63.758,73.190,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.468 | Acc: 63.704,73.322,77.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 0.495 | Acc: 89.062,100.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.633 | Acc: 84.189,99.702,99.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.635 | Acc: 84.299,99.771,99.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.641 | Acc: 84.170,99.795,99.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.631 | Acc: 84.394,99.826,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.632 | Acc: 84.298,99.752,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.631 | Acc: 84.381,99.716,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.631 | Acc: 84.475,99.740,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.635 | Acc: 84.360,99.728,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.632 | Acc: 84.461,99.732,99.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.631 | Acc: 84.527,99.743,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.629 | Acc: 84.598,99.745,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.631 | Acc: 84.599,99.737,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.631 | Acc: 84.594,99.743,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.631 | Acc: 84.497,99.736,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.631 | Acc: 84.476,99.740,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.630 | Acc: 84.558,99.737,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.631 | Acc: 84.515,99.739,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.630 | Acc: 84.572,99.736,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.630 | Acc: 84.588,99.744,99.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.401 | Acc: 67.969,74.219,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.412 | Acc: 63.914,73.810,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.470 | Acc: 63.796,73.228,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.456 | Acc: 63.704,73.373,77.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 0.628 | Acc: 85.938,99.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.649 | Acc: 83.929,99.740,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.628 | Acc: 84.909,99.752,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.630 | Acc: 84.580,99.705,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.625 | Acc: 84.742,99.682,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.625 | Acc: 84.723,99.698,99.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.631 | Acc: 84.543,99.703,99.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.627 | Acc: 84.669,99.684,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.629 | Acc: 84.569,99.689,99.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.629 | Acc: 84.453,99.698,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.633 | Acc: 84.282,99.689,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.634 | Acc: 84.290,99.696,99.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.636 | Acc: 84.190,99.695,99.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.633 | Acc: 84.300,99.695,99.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.631 | Acc: 84.386,99.703,99.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.632 | Acc: 84.391,99.704,99.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.633 | Acc: 84.390,99.713,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.632 | Acc: 84.421,99.714,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.632 | Acc: 84.392,99.716,99.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.631 | Acc: 84.443,99.719,99.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.417 | Acc: 67.188,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.415 | Acc: 63.728,73.884,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.474 | Acc: 63.662,73.285,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.459 | Acc: 63.589,73.399,77.395,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 0.636 | Acc: 82.812,100.000,100.000,% | Adaptive Acc: 96.875% | clf_exit: 0.750 0.242 0.008
Batch: 20 | Loss: 0.602 | Acc: 85.305,99.814,100.000,% | Adaptive Acc: 95.833% | clf_exit: 0.775 0.222 0.003
Batch: 40 | Loss: 0.620 | Acc: 85.099,99.733,99.981,% | Adaptive Acc: 95.655% | clf_exit: 0.771 0.226 0.003
Batch: 60 | Loss: 0.627 | Acc: 84.772,99.808,99.974,% | Adaptive Acc: 95.517% | clf_exit: 0.770 0.227 0.003
Batch: 80 | Loss: 0.626 | Acc: 84.568,99.817,99.971,% | Adaptive Acc: 95.409% | clf_exit: 0.773 0.224 0.003
Batch: 100 | Loss: 0.628 | Acc: 84.514,99.760,99.969,% | Adaptive Acc: 95.390% | clf_exit: 0.772 0.225 0.003
Batch: 120 | Loss: 0.629 | Acc: 84.530,99.742,99.974,% | Adaptive Acc: 95.332% | clf_exit: 0.774 0.224 0.003
Batch: 140 | Loss: 0.630 | Acc: 84.525,99.717,99.972,% | Adaptive Acc: 95.318% | clf_exit: 0.773 0.224 0.003
Batch: 160 | Loss: 0.630 | Acc: 84.559,99.728,99.971,% | Adaptive Acc: 95.317% | clf_exit: 0.773 0.224 0.003
Batch: 180 | Loss: 0.631 | Acc: 84.483,99.737,99.974,% | Adaptive Acc: 95.278% | clf_exit: 0.772 0.226 0.003
Batch: 200 | Loss: 0.631 | Acc: 84.550,99.720,99.969,% | Adaptive Acc: 95.281% | clf_exit: 0.772 0.225 0.003
Batch: 220 | Loss: 0.629 | Acc: 84.605,99.724,99.972,% | Adaptive Acc: 95.302% | clf_exit: 0.773 0.224 0.003
Batch: 240 | Loss: 0.628 | Acc: 84.612,99.731,99.974,% | Adaptive Acc: 95.364% | clf_exit: 0.773 0.224 0.003
Batch: 260 | Loss: 0.627 | Acc: 84.629,99.734,99.970,% | Adaptive Acc: 95.405% | clf_exit: 0.773 0.224 0.003
Batch: 280 | Loss: 0.628 | Acc: 84.617,99.736,99.972,% | Adaptive Acc: 95.415% | clf_exit: 0.772 0.225 0.003
Batch: 300 | Loss: 0.629 | Acc: 84.567,99.722,99.974,% | Adaptive Acc: 95.377% | clf_exit: 0.773 0.224 0.003
Batch: 320 | Loss: 0.630 | Acc: 84.570,99.720,99.976,% | Adaptive Acc: 95.412% | clf_exit: 0.772 0.225 0.003
Batch: 340 | Loss: 0.630 | Acc: 84.597,99.711,99.973,% | Adaptive Acc: 95.427% | clf_exit: 0.772 0.225 0.003
Batch: 360 | Loss: 0.630 | Acc: 84.604,99.712,99.972,% | Adaptive Acc: 95.470% | clf_exit: 0.772 0.225 0.003
Batch: 380 | Loss: 0.631 | Acc: 84.592,99.709,99.971,% | Adaptive Acc: 95.466% | clf_exit: 0.771 0.226 0.003
Batch: 0 | Loss: 3.406 | Acc: 67.188,74.219,77.344,% | Adaptive Acc: 75.000% | clf_exit: 0.812 0.148 0.039
Batch: 20 | Loss: 3.415 | Acc: 63.802,73.661,77.604,% | Adaptive Acc: 70.982% | clf_exit: 0.745 0.195 0.060
Batch: 40 | Loss: 3.472 | Acc: 63.834,73.056,77.210,% | Adaptive Acc: 70.522% | clf_exit: 0.750 0.189 0.061
Batch: 60 | Loss: 3.458 | Acc: 63.678,73.233,77.485,% | Adaptive Acc: 70.377% | clf_exit: 0.754 0.183 0.063

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 12.133 |  Acc: 5.904,8.548,9.548,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=0 | Loss: 11.437 |  Acc: 6.940,12.050,14.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 10.076 |  Acc: 12.394,19.508,24.248,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=1 | Loss: 9.713 |  Acc: 8.910,21.720,31.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 8.554 |  Acc: 17.648,29.756,37.594,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=2 | Loss: 8.347 |  Acc: 15.580,30.050,40.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 7.523 |  Acc: 21.592,37.638,46.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=3 | Loss: 7.448 |  Acc: 20.800,36.700,47.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 6.754 |  Acc: 25.462,44.194,52.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=4 | Loss: 7.005 |  Acc: 20.560,42.410,51.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 6.210 |  Acc: 28.756,48.424,57.634,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=5 | Loss: 6.393 |  Acc: 26.900,45.680,54.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 5.770 |  Acc: 31.528,52.112,61.244,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=6 | Loss: 6.348 |  Acc: 24.830,49.270,58.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 5.415 |  Acc: 33.936,54.790,64.310,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=7 | Loss: 5.773 |  Acc: 30.590,51.380,60.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 5.126 |  Acc: 36.176,56.896,66.558,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=8 | Loss: 5.659 |  Acc: 32.320,53.860,60.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 4.868 |  Acc: 37.886,58.746,68.788,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=9 | Loss: 5.416 |  Acc: 33.900,55.140,63.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 4.664 |  Acc: 39.446,60.782,70.810,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=10 | Loss: 5.584 |  Acc: 33.150,52.440,62.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 4.475 |  Acc: 41.094,61.954,72.686,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=11 | Loss: 5.129 |  Acc: 37.640,57.290,64.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 4.286 |  Acc: 42.638,63.508,74.276,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=12 | Loss: 5.059 |  Acc: 38.760,57.190,64.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 4.136 |  Acc: 43.730,64.570,75.472,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=13 | Loss: 4.965 |  Acc: 40.090,58.920,66.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 4.012 |  Acc: 44.914,65.654,76.804,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=14 | Loss: 5.165 |  Acc: 36.440,59.090,66.430,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 3.893 |  Acc: 45.668,66.702,78.054,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=15 | Loss: 4.737 |  Acc: 41.290,60.680,66.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 3.790 |  Acc: 46.602,67.252,78.754,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=16 | Loss: 4.753 |  Acc: 40.770,60.740,67.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 3.670 |  Acc: 47.544,68.246,79.992,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=17 | Loss: 4.908 |  Acc: 40.470,59.430,67.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 3.607 |  Acc: 47.946,68.788,80.912,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=18 | Loss: 4.846 |  Acc: 40.890,59.520,67.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 3.507 |  Acc: 48.886,69.890,82.114,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=19 | Loss: 4.514 |  Acc: 43.110,61.930,68.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 3.438 |  Acc: 49.618,70.514,82.450,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=20 | Loss: 4.551 |  Acc: 44.220,62.160,69.420,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 3.339 |  Acc: 50.364,71.164,83.370,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=21 | Loss: 4.599 |  Acc: 42.420,62.220,68.440,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 3.290 |  Acc: 50.846,71.780,83.700,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=22 | Loss: 4.338 |  Acc: 46.580,63.610,69.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 3.224 |  Acc: 51.222,72.076,84.656,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=23 | Loss: 4.540 |  Acc: 44.260,62.830,68.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 3.153 |  Acc: 51.804,72.778,85.316,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=24 | Loss: 4.428 |  Acc: 46.680,62.480,68.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 3.113 |  Acc: 52.276,73.028,85.804,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=25 | Loss: 4.575 |  Acc: 44.050,61.900,68.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 3.055 |  Acc: 53.074,73.548,86.194,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=26 | Loss: 4.350 |  Acc: 46.360,64.320,69.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 3.029 |  Acc: 53.066,73.878,86.530,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=27 | Loss: 4.520 |  Acc: 45.380,61.320,69.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 2.980 |  Acc: 53.358,74.490,87.032,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=28 | Loss: 4.305 |  Acc: 49.290,63.220,70.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 2.922 |  Acc: 54.278,75.016,87.474,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=29 | Loss: 4.401 |  Acc: 46.130,63.480,69.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 2.905 |  Acc: 54.266,74.720,87.778,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=30 | Loss: 4.725 |  Acc: 43.240,62.650,68.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 2.887 |  Acc: 54.374,74.994,87.890,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=31 | Loss: 4.384 |  Acc: 47.300,62.980,70.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 2.841 |  Acc: 54.850,75.476,88.538,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=32 | Loss: 4.336 |  Acc: 48.200,63.310,69.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 2.808 |  Acc: 55.282,75.904,88.458,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=33 | Loss: 4.321 |  Acc: 48.580,62.990,69.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 2.760 |  Acc: 55.706,76.164,88.982,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=34 | Loss: 4.381 |  Acc: 48.780,62.910,69.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 2.736 |  Acc: 55.822,76.650,89.306,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=35 | Loss: 4.457 |  Acc: 46.210,65.050,69.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 2.703 |  Acc: 56.332,76.732,89.596,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=36 | Loss: 4.301 |  Acc: 49.110,64.370,69.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 2.695 |  Acc: 56.036,76.996,89.664,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=37 | Loss: 4.664 |  Acc: 45.540,63.560,69.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 2.675 |  Acc: 56.314,77.002,89.690,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=38 | Loss: 4.078 |  Acc: 51.640,66.030,70.630,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 2.649 |  Acc: 56.934,77.192,90.142,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=39 | Loss: 4.255 |  Acc: 49.610,65.260,70.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 2.624 |  Acc: 57.130,77.606,90.116,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=40 | Loss: 4.130 |  Acc: 50.460,65.390,71.370,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 2.594 |  Acc: 57.044,78.040,90.514,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=41 | Loss: 4.216 |  Acc: 50.950,65.590,69.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 2.609 |  Acc: 57.110,77.636,90.278,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=42 | Loss: 4.503 |  Acc: 47.640,63.030,69.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 2.565 |  Acc: 57.792,78.100,90.654,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=43 | Loss: 4.155 |  Acc: 50.690,66.080,70.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 2.556 |  Acc: 57.650,78.256,90.802,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=44 | Loss: 4.184 |  Acc: 49.750,65.880,70.680,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 2.552 |  Acc: 57.638,78.302,90.882,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=45 | Loss: 4.165 |  Acc: 52.450,64.580,70.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 2.525 |  Acc: 57.814,78.626,90.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=46 | Loss: 4.259 |  Acc: 50.010,65.750,70.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 2.517 |  Acc: 58.176,78.858,91.144,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=47 | Loss: 4.292 |  Acc: 52.040,63.800,69.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 2.483 |  Acc: 58.486,79.160,91.306,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=48 | Loss: 3.931 |  Acc: 52.930,67.540,71.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 2.461 |  Acc: 58.742,79.224,91.376,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=49 | Loss: 4.352 |  Acc: 48.840,63.850,70.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 2.476 |  Acc: 58.694,79.288,91.210,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=50 | Loss: 4.263 |  Acc: 50.500,64.600,70.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 2.458 |  Acc: 58.522,79.594,91.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=51 | Loss: 4.532 |  Acc: 47.970,63.740,69.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 2.458 |  Acc: 58.632,79.372,91.476,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=52 | Loss: 4.243 |  Acc: 50.470,65.310,70.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 2.450 |  Acc: 58.948,79.412,91.396,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=53 | Loss: 4.135 |  Acc: 50.770,67.060,71.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 2.414 |  Acc: 59.176,79.780,91.706,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=54 | Loss: 4.219 |  Acc: 50.600,65.890,69.290,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 2.410 |  Acc: 59.264,79.776,91.620,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=55 | Loss: 4.200 |  Acc: 50.140,66.390,71.390,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 2.379 |  Acc: 59.548,80.184,92.130,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=56 | Loss: 4.305 |  Acc: 48.660,64.990,70.470,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 2.383 |  Acc: 59.274,79.908,92.190,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=57 | Loss: 4.269 |  Acc: 49.490,66.270,70.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 2.361 |  Acc: 59.700,80.160,92.432,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=58 | Loss: 4.698 |  Acc: 44.050,64.390,69.660,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 2.369 |  Acc: 59.646,80.352,92.108,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=59 | Loss: 4.277 |  Acc: 51.550,64.020,69.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 2.346 |  Acc: 60.042,80.494,92.110,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=60 | Loss: 4.254 |  Acc: 51.200,64.330,70.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 2.357 |  Acc: 60.170,80.246,92.058,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=61 | Loss: 4.426 |  Acc: 48.040,64.810,70.350,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 2.346 |  Acc: 60.306,80.388,92.202,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=62 | Loss: 4.478 |  Acc: 47.880,63.860,70.490,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 2.315 |  Acc: 60.380,80.836,92.768,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=63 | Loss: 4.197 |  Acc: 51.540,65.800,71.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 2.304 |  Acc: 60.588,81.042,92.684,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=64 | Loss: 4.047 |  Acc: 52.330,67.070,71.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 2.323 |  Acc: 60.124,80.724,92.488,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=65 | Loss: 4.225 |  Acc: 51.110,65.060,71.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 2.282 |  Acc: 60.638,81.320,92.680,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=66 | Loss: 4.233 |  Acc: 51.090,65.980,70.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 2.298 |  Acc: 60.318,80.998,92.610,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=67 | Loss: 3.996 |  Acc: 53.780,67.150,71.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 2.293 |  Acc: 60.592,81.120,92.534,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=68 | Loss: 4.265 |  Acc: 49.390,65.970,70.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 2.290 |  Acc: 60.596,80.982,92.586,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=69 | Loss: 4.216 |  Acc: 51.020,65.500,69.970,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 2.264 |  Acc: 61.214,81.344,92.746,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=70 | Loss: 4.191 |  Acc: 52.110,65.610,71.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 2.281 |  Acc: 60.768,81.180,92.562,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=71 | Loss: 4.595 |  Acc: 46.100,66.470,70.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 2.280 |  Acc: 60.606,81.260,92.846,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=72 | Loss: 4.155 |  Acc: 52.590,64.820,69.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 2.267 |  Acc: 60.964,81.400,92.644,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=73 | Loss: 3.965 |  Acc: 55.340,66.950,70.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 2.243 |  Acc: 61.310,81.632,92.814,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=74 | Loss: 4.473 |  Acc: 47.820,65.020,70.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 2.244 |  Acc: 61.308,81.670,92.896,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=75 | Loss: 4.082 |  Acc: 51.390,66.930,71.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 2.202 |  Acc: 61.352,81.986,93.490,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=76 | Loss: 4.459 |  Acc: 47.740,64.390,70.410,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 2.234 |  Acc: 61.538,81.674,93.120,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=77 | Loss: 3.963 |  Acc: 54.590,66.480,71.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 2.240 |  Acc: 61.286,81.782,92.738,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=78 | Loss: 4.247 |  Acc: 50.900,66.130,71.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 2.235 |  Acc: 61.638,81.698,92.832,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=79 | Loss: 4.384 |  Acc: 49.440,65.450,69.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 2.222 |  Acc: 61.360,81.916,92.914,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=80 | Loss: 4.181 |  Acc: 51.110,65.380,71.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 2.218 |  Acc: 61.628,81.830,93.120,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=81 | Loss: 4.178 |  Acc: 50.540,67.370,70.560,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 2.189 |  Acc: 61.856,82.204,93.328,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=82 | Loss: 4.298 |  Acc: 51.400,64.760,70.320,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 2.184 |  Acc: 62.026,82.190,93.060,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=83 | Loss: 3.803 |  Acc: 56.100,68.500,71.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 2.181 |  Acc: 61.668,82.236,93.172,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=84 | Loss: 4.411 |  Acc: 51.190,63.900,70.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 2.201 |  Acc: 61.672,81.930,93.130,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=85 | Loss: 4.076 |  Acc: 51.940,66.350,71.540,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 2.191 |  Acc: 62.016,82.260,92.998,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=86 | Loss: 4.202 |  Acc: 53.080,65.930,70.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 2.162 |  Acc: 62.076,82.514,93.446,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=87 | Loss: 4.318 |  Acc: 51.900,65.050,70.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 2.178 |  Acc: 61.986,82.406,93.324,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=88 | Loss: 4.153 |  Acc: 52.230,66.160,70.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 2.164 |  Acc: 62.400,82.354,93.432,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=89 | Loss: 4.216 |  Acc: 49.770,66.840,72.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 2.173 |  Acc: 61.988,82.412,93.252,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=90 | Loss: 4.172 |  Acc: 52.240,66.170,70.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 2.160 |  Acc: 62.224,82.352,93.344,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=91 | Loss: 4.480 |  Acc: 49.250,64.600,70.270,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 2.156 |  Acc: 62.408,82.500,93.546,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=92 | Loss: 4.038 |  Acc: 52.910,66.820,70.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 2.151 |  Acc: 62.492,82.522,93.544,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=93 | Loss: 4.179 |  Acc: 52.760,66.000,70.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 2.157 |  Acc: 62.234,82.630,93.284,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=94 | Loss: 4.127 |  Acc: 52.560,65.560,70.340,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 2.151 |  Acc: 62.492,82.622,93.236,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=95 | Loss: 4.262 |  Acc: 51.320,66.690,70.750,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 2.118 |  Acc: 62.420,82.868,93.720,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=96 | Loss: 4.291 |  Acc: 52.180,67.000,69.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 2.142 |  Acc: 62.612,82.672,93.184,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=97 | Loss: 4.254 |  Acc: 48.930,66.800,70.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 2.138 |  Acc: 62.420,82.670,93.432,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=98 | Loss: 3.991 |  Acc: 54.320,67.060,71.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 2.129 |  Acc: 62.874,82.606,93.408,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=99 | Loss: 4.113 |  Acc: 52.070,66.650,72.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 2.110 |  Acc: 62.640,83.126,93.672,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=100 | Loss: 4.398 |  Acc: 49.900,65.700,70.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 2.119 |  Acc: 62.672,82.806,93.642,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=101 | Loss: 4.262 |  Acc: 50.740,66.210,71.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 2.113 |  Acc: 62.918,83.032,93.566,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=102 | Loss: 4.421 |  Acc: 49.240,64.510,70.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 2.136 |  Acc: 62.756,82.704,93.424,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=103 | Loss: 4.254 |  Acc: 52.070,66.550,71.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 2.109 |  Acc: 62.822,82.998,93.616,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=104 | Loss: 4.051 |  Acc: 51.770,67.560,72.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 2.101 |  Acc: 63.060,83.392,93.582,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=105 | Loss: 4.111 |  Acc: 52.780,66.320,70.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 2.095 |  Acc: 62.816,83.094,93.650,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=106 | Loss: 4.085 |  Acc: 53.060,67.180,71.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 2.115 |  Acc: 62.868,83.008,93.610,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=107 | Loss: 4.286 |  Acc: 48.380,66.830,71.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 2.128 |  Acc: 62.928,82.770,93.242,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=108 | Loss: 4.190 |  Acc: 52.100,64.970,70.480,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 2.082 |  Acc: 63.222,83.166,93.610,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=109 | Loss: 4.266 |  Acc: 52.020,66.780,71.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 2.114 |  Acc: 62.902,82.932,93.574,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=110 | Loss: 4.269 |  Acc: 50.700,67.600,70.620,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 2.100 |  Acc: 63.000,83.382,93.524,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=111 | Loss: 4.141 |  Acc: 53.360,66.060,71.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 2.065 |  Acc: 63.346,83.372,94.028,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=112 | Loss: 4.180 |  Acc: 51.800,67.210,71.550,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 2.077 |  Acc: 63.492,83.284,93.702,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=113 | Loss: 4.042 |  Acc: 53.530,67.550,71.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 2.084 |  Acc: 63.302,83.322,93.734,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=114 | Loss: 4.111 |  Acc: 52.940,67.750,70.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 2.082 |  Acc: 63.456,83.092,93.580,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=115 | Loss: 3.851 |  Acc: 56.360,68.900,72.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 2.083 |  Acc: 62.848,83.382,93.850,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=116 | Loss: 4.107 |  Acc: 53.190,68.200,71.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 2.064 |  Acc: 63.308,83.556,93.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=117 | Loss: 4.160 |  Acc: 51.840,67.280,70.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 2.054 |  Acc: 63.300,83.670,94.058,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=118 | Loss: 4.163 |  Acc: 52.370,66.700,70.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 2.074 |  Acc: 63.472,83.390,93.662,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=119 | Loss: 4.066 |  Acc: 53.890,65.840,71.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 2.080 |  Acc: 63.538,83.298,93.682,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=120 | Loss: 4.242 |  Acc: 50.780,66.560,72.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 2.060 |  Acc: 63.566,83.674,93.728,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=121 | Loss: 4.102 |  Acc: 54.060,66.220,71.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 2.059 |  Acc: 63.730,83.644,93.774,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=122 | Loss: 4.250 |  Acc: 51.570,65.760,70.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 2.052 |  Acc: 63.476,83.626,94.036,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=123 | Loss: 4.316 |  Acc: 51.820,66.450,71.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 2.031 |  Acc: 63.912,84.052,94.010,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=124 | Loss: 4.232 |  Acc: 49.570,67.260,71.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 2.044 |  Acc: 63.882,83.802,93.914,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=125 | Loss: 4.158 |  Acc: 51.530,66.060,71.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 2.069 |  Acc: 63.624,83.490,93.614,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=126 | Loss: 4.312 |  Acc: 52.870,67.160,70.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 2.037 |  Acc: 63.866,83.814,94.160,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=127 | Loss: 4.085 |  Acc: 53.780,68.620,71.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 2.037 |  Acc: 63.406,83.636,94.264,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=128 | Loss: 4.110 |  Acc: 53.760,67.450,71.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 2.039 |  Acc: 63.854,83.838,93.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=129 | Loss: 4.046 |  Acc: 54.850,67.750,71.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 2.056 |  Acc: 63.938,83.426,93.816,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=130 | Loss: 4.298 |  Acc: 50.280,67.080,71.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 2.055 |  Acc: 63.866,83.700,93.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=131 | Loss: 3.948 |  Acc: 54.930,68.390,70.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 2.023 |  Acc: 63.966,83.996,93.852,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=132 | Loss: 4.012 |  Acc: 54.190,67.790,71.610,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 2.027 |  Acc: 63.734,84.120,93.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=133 | Loss: 4.036 |  Acc: 54.260,67.900,71.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 1.999 |  Acc: 64.420,84.258,94.330,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=134 | Loss: 4.131 |  Acc: 55.230,66.970,71.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 2.019 |  Acc: 64.072,83.954,94.010,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=135 | Loss: 4.096 |  Acc: 54.240,65.770,70.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 2.021 |  Acc: 63.928,83.906,94.016,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=136 | Loss: 4.022 |  Acc: 54.340,67.580,71.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 2.002 |  Acc: 64.026,84.320,94.278,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=137 | Loss: 4.210 |  Acc: 52.630,65.510,71.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 2.029 |  Acc: 63.932,83.744,94.044,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=138 | Loss: 4.050 |  Acc: 53.040,67.700,72.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 2.018 |  Acc: 63.986,84.018,94.152,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=139 | Loss: 4.243 |  Acc: 50.900,66.760,70.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 2.006 |  Acc: 64.086,84.350,94.042,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=140 | Loss: 4.107 |  Acc: 55.490,65.340,71.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 2.015 |  Acc: 64.344,84.174,94.124,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=141 | Loss: 4.123 |  Acc: 52.170,67.920,72.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 2.013 |  Acc: 64.180,84.126,94.144,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=142 | Loss: 4.080 |  Acc: 52.080,67.580,71.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 2.010 |  Acc: 64.156,84.140,94.114,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=143 | Loss: 4.102 |  Acc: 52.010,67.580,71.460,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 2.035 |  Acc: 63.944,84.140,93.662,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=144 | Loss: 4.218 |  Acc: 52.340,65.930,71.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 2.025 |  Acc: 64.006,83.872,93.874,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=145 | Loss: 4.316 |  Acc: 52.550,66.700,71.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 1.986 |  Acc: 64.414,84.490,94.282,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=146 | Loss: 3.891 |  Acc: 55.250,68.330,72.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 1.994 |  Acc: 64.572,84.212,94.306,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=147 | Loss: 4.225 |  Acc: 51.710,68.210,70.710,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 1.988 |  Acc: 64.342,84.424,94.374,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=148 | Loss: 4.136 |  Acc: 54.800,66.940,71.380,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 2.006 |  Acc: 64.356,84.062,94.054,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=149 | Loss: 4.052 |  Acc: 53.890,68.300,72.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 1.389 |  Acc: 71.296,91.714,98.366,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=150 | Loss: 3.151 |  Acc: 63.940,74.540,77.030,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 1.220 |  Acc: 73.446,93.782,99.364,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=151 | Loss: 3.103 |  Acc: 64.090,74.840,77.670,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.156 |  Acc: 74.044,94.564,99.600,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=152 | Loss: 3.123 |  Acc: 64.350,75.020,77.450,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.118 |  Acc: 74.392,95.108,99.666,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=153 | Loss: 3.127 |  Acc: 64.600,74.930,77.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.089 |  Acc: 74.700,95.580,99.740,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=154 | Loss: 3.109 |  Acc: 64.440,75.140,77.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.071 |  Acc: 74.844,95.756,99.792,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=155 | Loss: 3.130 |  Acc: 64.340,75.040,77.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.051 |  Acc: 75.176,96.040,99.806,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=156 | Loss: 3.154 |  Acc: 63.780,75.000,78.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.035 |  Acc: 75.286,96.236,99.828,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=157 | Loss: 3.126 |  Acc: 64.850,75.120,78.210,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.018 |  Acc: 75.650,96.436,99.860,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=158 | Loss: 3.151 |  Acc: 64.620,75.160,78.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.004 |  Acc: 75.902,96.702,99.858,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=159 | Loss: 3.147 |  Acc: 64.500,75.030,78.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 0.993 |  Acc: 75.956,96.778,99.858,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=160 | Loss: 3.165 |  Acc: 64.960,74.980,78.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 0.984 |  Acc: 76.164,97.002,99.886,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=161 | Loss: 3.190 |  Acc: 64.380,74.890,78.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 0.975 |  Acc: 76.236,97.126,99.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=162 | Loss: 3.179 |  Acc: 64.540,75.010,78.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 0.961 |  Acc: 76.520,97.164,99.892,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=163 | Loss: 3.173 |  Acc: 64.750,74.720,78.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 0.957 |  Acc: 76.608,97.266,99.900,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=164 | Loss: 3.183 |  Acc: 64.520,74.650,78.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 0.945 |  Acc: 76.812,97.516,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=165 | Loss: 3.179 |  Acc: 64.640,74.810,78.330,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 0.939 |  Acc: 76.760,97.506,99.908,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=166 | Loss: 3.193 |  Acc: 64.200,74.730,78.140,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 0.932 |  Acc: 77.064,97.626,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=167 | Loss: 3.214 |  Acc: 63.960,74.770,78.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 0.923 |  Acc: 77.238,97.716,99.930,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=168 | Loss: 3.209 |  Acc: 64.280,74.670,78.190,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 0.918 |  Acc: 77.236,97.766,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=169 | Loss: 3.204 |  Acc: 64.410,74.800,78.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 0.914 |  Acc: 77.350,97.834,99.918,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=170 | Loss: 3.256 |  Acc: 63.940,74.550,78.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 0.911 |  Acc: 77.110,97.840,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=171 | Loss: 3.251 |  Acc: 64.170,74.360,78.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 0.902 |  Acc: 77.458,97.970,99.918,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=172 | Loss: 3.242 |  Acc: 64.130,74.820,78.150,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 0.898 |  Acc: 77.752,97.988,99.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=173 | Loss: 3.239 |  Acc: 64.520,74.620,78.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 0.891 |  Acc: 77.726,98.020,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=174 | Loss: 3.251 |  Acc: 63.900,74.830,78.250,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 0.888 |  Acc: 77.626,98.144,99.922,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=175 | Loss: 3.226 |  Acc: 64.490,74.740,78.360,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 0.884 |  Acc: 77.924,98.158,99.924,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=176 | Loss: 3.272 |  Acc: 63.960,74.430,78.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 0.877 |  Acc: 77.958,98.226,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=177 | Loss: 3.241 |  Acc: 64.200,74.710,78.120,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 0.871 |  Acc: 78.282,98.278,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=178 | Loss: 3.277 |  Acc: 63.990,74.410,78.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 0.868 |  Acc: 78.176,98.312,99.926,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=179 | Loss: 3.282 |  Acc: 63.730,74.400,78.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 0.858 |  Acc: 78.432,98.382,99.930,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=180 | Loss: 3.247 |  Acc: 64.340,74.490,78.230,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 0.860 |  Acc: 78.398,98.392,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=181 | Loss: 3.278 |  Acc: 63.690,74.310,78.310,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 0.854 |  Acc: 78.530,98.444,99.930,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=182 | Loss: 3.251 |  Acc: 64.440,74.560,78.240,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 0.855 |  Acc: 78.414,98.454,99.930,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=183 | Loss: 3.288 |  Acc: 64.050,74.350,78.200,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 0.847 |  Acc: 78.650,98.496,99.936,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=184 | Loss: 3.288 |  Acc: 63.840,74.560,78.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 0.847 |  Acc: 78.564,98.486,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=185 | Loss: 3.298 |  Acc: 63.920,74.110,78.180,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 0.843 |  Acc: 78.842,98.508,99.924,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=186 | Loss: 3.290 |  Acc: 63.900,74.310,78.260,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 0.835 |  Acc: 78.984,98.634,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=187 | Loss: 3.331 |  Acc: 63.420,73.930,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 0.831 |  Acc: 78.734,98.718,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=188 | Loss: 3.338 |  Acc: 63.930,73.980,77.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 0.831 |  Acc: 79.032,98.616,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=189 | Loss: 3.313 |  Acc: 64.070,74.180,78.220,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 0.825 |  Acc: 79.266,98.720,99.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=190 | Loss: 3.345 |  Acc: 63.390,74.260,77.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 0.826 |  Acc: 78.980,98.736,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=191 | Loss: 3.350 |  Acc: 63.070,73.990,78.090,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 0.820 |  Acc: 79.264,98.714,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=192 | Loss: 3.339 |  Acc: 63.700,74.220,77.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 0.817 |  Acc: 79.344,98.748,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=193 | Loss: 3.319 |  Acc: 63.690,74.450,78.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 0.813 |  Acc: 79.380,98.832,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=194 | Loss: 3.328 |  Acc: 63.640,74.260,78.100,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 0.813 |  Acc: 79.480,98.824,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=195 | Loss: 3.389 |  Acc: 63.270,73.810,78.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 0.807 |  Acc: 79.428,98.874,99.944,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=196 | Loss: 3.385 |  Acc: 63.260,74.220,78.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 0.803 |  Acc: 79.598,98.884,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=197 | Loss: 3.315 |  Acc: 63.730,74.190,78.300,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 0.800 |  Acc: 79.692,98.884,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=198 | Loss: 3.344 |  Acc: 63.920,73.910,78.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 0.797 |  Acc: 79.902,98.848,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=199 | Loss: 3.375 |  Acc: 63.620,73.810,78.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 0.796 |  Acc: 79.796,98.914,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=200 | Loss: 3.320 |  Acc: 63.960,74.200,78.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 0.795 |  Acc: 79.808,98.828,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=201 | Loss: 3.362 |  Acc: 63.370,74.100,78.170,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 0.790 |  Acc: 80.086,98.896,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=202 | Loss: 3.364 |  Acc: 63.460,73.880,78.280,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 0.788 |  Acc: 80.002,98.888,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=203 | Loss: 3.396 |  Acc: 63.270,73.880,78.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 0.793 |  Acc: 79.906,98.884,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=204 | Loss: 3.385 |  Acc: 63.600,73.360,78.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 0.786 |  Acc: 80.142,98.946,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=205 | Loss: 3.378 |  Acc: 64.070,73.910,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 0.780 |  Acc: 80.134,99.002,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=206 | Loss: 3.375 |  Acc: 63.850,73.620,78.000,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 0.778 |  Acc: 80.456,98.982,99.954,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=207 | Loss: 3.407 |  Acc: 62.770,73.870,78.130,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 0.774 |  Acc: 80.464,99.010,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=208 | Loss: 3.397 |  Acc: 63.270,73.480,77.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 0.776 |  Acc: 80.362,98.964,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=209 | Loss: 3.371 |  Acc: 63.310,74.020,77.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 0.772 |  Acc: 80.554,99.036,99.960,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=210 | Loss: 3.418 |  Acc: 62.960,73.840,78.160,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 0.771 |  Acc: 80.448,99.060,99.948,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=211 | Loss: 3.450 |  Acc: 63.070,73.560,77.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 0.770 |  Acc: 80.622,99.012,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=212 | Loss: 3.400 |  Acc: 63.170,73.940,78.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 0.763 |  Acc: 80.690,99.082,99.958,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=213 | Loss: 3.461 |  Acc: 63.080,73.320,77.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 0.768 |  Acc: 80.704,98.916,99.928,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=214 | Loss: 3.396 |  Acc: 62.710,73.810,77.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 0.761 |  Acc: 80.872,99.020,99.942,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=215 | Loss: 3.443 |  Acc: 62.760,73.720,77.720,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 0.760 |  Acc: 80.926,99.056,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=216 | Loss: 3.423 |  Acc: 63.020,73.510,77.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 0.756 |  Acc: 81.028,99.012,99.932,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=217 | Loss: 3.463 |  Acc: 62.270,73.340,77.690,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 0.755 |  Acc: 80.978,99.104,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=218 | Loss: 3.399 |  Acc: 62.620,73.920,77.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 0.760 |  Acc: 80.904,98.936,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=219 | Loss: 3.476 |  Acc: 62.690,73.420,77.600,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 0.752 |  Acc: 81.280,99.056,99.938,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=220 | Loss: 3.431 |  Acc: 63.440,73.240,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 0.752 |  Acc: 81.172,99.084,99.940,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=221 | Loss: 3.420 |  Acc: 62.750,73.530,78.080,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 0.750 |  Acc: 81.104,99.000,99.950,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=222 | Loss: 3.446 |  Acc: 62.870,73.280,77.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 0.743 |  Acc: 81.388,99.122,99.946,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=223 | Loss: 3.437 |  Acc: 62.550,73.520,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 0.746 |  Acc: 81.432,99.034,99.934,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=224 | Loss: 3.491 |  Acc: 62.530,73.430,77.580,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 0.685 |  Acc: 83.200,99.454,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=225 | Loss: 3.366 |  Acc: 64.110,74.050,77.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 0.671 |  Acc: 83.520,99.486,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=226 | Loss: 3.375 |  Acc: 64.100,74.110,77.990,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 0.665 |  Acc: 83.618,99.540,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=227 | Loss: 3.371 |  Acc: 63.950,74.050,77.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 0.664 |  Acc: 83.544,99.540,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=228 | Loss: 3.375 |  Acc: 64.070,74.260,77.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 0.663 |  Acc: 83.720,99.584,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=229 | Loss: 3.363 |  Acc: 64.030,74.150,77.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 0.659 |  Acc: 83.666,99.592,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=230 | Loss: 3.362 |  Acc: 64.160,74.200,78.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 0.655 |  Acc: 83.832,99.554,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=231 | Loss: 3.368 |  Acc: 64.070,74.130,78.060,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 0.660 |  Acc: 83.838,99.550,99.956,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=232 | Loss: 3.364 |  Acc: 64.070,74.010,77.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 0.654 |  Acc: 83.800,99.614,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=233 | Loss: 3.377 |  Acc: 63.970,74.160,78.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 0.654 |  Acc: 83.864,99.614,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=234 | Loss: 3.384 |  Acc: 64.070,74.030,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 0.655 |  Acc: 83.956,99.616,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=235 | Loss: 3.373 |  Acc: 63.950,74.030,78.040,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 0.657 |  Acc: 83.760,99.630,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=236 | Loss: 3.382 |  Acc: 63.960,73.960,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 0.652 |  Acc: 83.906,99.614,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=237 | Loss: 3.391 |  Acc: 63.740,73.930,77.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 0.651 |  Acc: 83.966,99.634,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=238 | Loss: 3.380 |  Acc: 64.010,74.050,77.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 0.651 |  Acc: 83.900,99.656,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=239 | Loss: 3.383 |  Acc: 63.850,74.110,78.110,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 0.651 |  Acc: 83.918,99.612,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=240 | Loss: 3.385 |  Acc: 63.950,73.790,77.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 0.648 |  Acc: 84.056,99.588,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=241 | Loss: 3.383 |  Acc: 64.170,73.960,77.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 0.650 |  Acc: 83.958,99.652,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=242 | Loss: 3.389 |  Acc: 63.920,73.920,77.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 0.650 |  Acc: 83.988,99.646,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=243 | Loss: 3.399 |  Acc: 63.720,73.840,77.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 0.648 |  Acc: 84.030,99.638,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=244 | Loss: 3.393 |  Acc: 63.820,73.930,77.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 0.646 |  Acc: 84.126,99.672,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=245 | Loss: 3.405 |  Acc: 63.750,73.980,78.020,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 0.647 |  Acc: 84.040,99.660,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=246 | Loss: 3.401 |  Acc: 63.770,73.820,77.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 0.648 |  Acc: 83.944,99.668,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=247 | Loss: 3.393 |  Acc: 63.820,73.740,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 0.650 |  Acc: 83.984,99.658,99.952,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=248 | Loss: 3.379 |  Acc: 63.980,73.880,78.010,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 0.646 |  Acc: 83.954,99.620,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=249 | Loss: 3.383 |  Acc: 64.080,73.770,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 0.646 |  Acc: 84.048,99.654,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=250 | Loss: 3.393 |  Acc: 63.970,73.870,77.950,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 0.641 |  Acc: 84.294,99.678,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=251 | Loss: 3.400 |  Acc: 63.870,73.830,77.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 0.646 |  Acc: 84.020,99.674,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=252 | Loss: 3.400 |  Acc: 63.910,73.660,77.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 0.645 |  Acc: 84.162,99.636,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=253 | Loss: 3.417 |  Acc: 63.710,73.750,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 0.641 |  Acc: 84.284,99.674,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=254 | Loss: 3.403 |  Acc: 63.900,73.690,77.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 0.644 |  Acc: 84.136,99.642,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=255 | Loss: 3.395 |  Acc: 63.940,73.770,77.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 0.645 |  Acc: 83.922,99.696,99.986,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=256 | Loss: 3.395 |  Acc: 63.870,73.830,77.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 0.644 |  Acc: 84.034,99.640,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=257 | Loss: 3.396 |  Acc: 63.780,73.750,77.960,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 0.641 |  Acc: 84.292,99.700,99.962,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=258 | Loss: 3.403 |  Acc: 63.850,73.760,77.980,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 0.639 |  Acc: 84.240,99.684,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=259 | Loss: 3.420 |  Acc: 63.710,73.590,77.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 0.639 |  Acc: 84.288,99.688,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=260 | Loss: 3.392 |  Acc: 63.970,73.730,77.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 0.640 |  Acc: 84.380,99.686,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=261 | Loss: 3.414 |  Acc: 63.950,73.750,77.910,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 0.637 |  Acc: 84.454,99.680,99.964,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=262 | Loss: 3.401 |  Acc: 63.940,73.780,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 0.639 |  Acc: 84.324,99.668,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=263 | Loss: 3.400 |  Acc: 63.940,73.690,77.870,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 0.632 |  Acc: 84.458,99.686,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=264 | Loss: 3.412 |  Acc: 63.910,73.600,77.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 0.636 |  Acc: 84.284,99.678,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=265 | Loss: 3.403 |  Acc: 63.850,73.620,77.940,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 0.633 |  Acc: 84.508,99.694,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=266 | Loss: 3.402 |  Acc: 63.740,73.620,77.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 0.633 |  Acc: 84.630,99.730,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=267 | Loss: 3.400 |  Acc: 63.860,73.770,77.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 0.633 |  Acc: 84.472,99.714,99.984,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=268 | Loss: 3.413 |  Acc: 63.830,73.650,77.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 0.632 |  Acc: 84.534,99.726,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=269 | Loss: 3.413 |  Acc: 63.810,73.740,77.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 0.631 |  Acc: 84.604,99.728,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=270 | Loss: 3.401 |  Acc: 63.950,73.710,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 0.634 |  Acc: 84.476,99.666,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=271 | Loss: 3.401 |  Acc: 63.870,73.880,77.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 0.631 |  Acc: 84.352,99.716,99.984,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=272 | Loss: 3.408 |  Acc: 63.940,73.760,77.740,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 0.635 |  Acc: 84.400,99.678,99.982,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=273 | Loss: 3.404 |  Acc: 63.920,73.670,77.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 0.632 |  Acc: 84.504,99.662,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=274 | Loss: 3.404 |  Acc: 63.820,73.830,77.830,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 0.632 |  Acc: 84.690,99.720,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=275 | Loss: 3.394 |  Acc: 64.000,73.810,77.780,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 0.637 |  Acc: 84.426,99.702,99.966,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=276 | Loss: 3.401 |  Acc: 63.830,73.670,78.050,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 0.632 |  Acc: 84.608,99.712,99.982,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=277 | Loss: 3.410 |  Acc: 63.890,73.770,77.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 0.634 |  Acc: 84.294,99.722,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=278 | Loss: 3.414 |  Acc: 63.990,73.780,77.810,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 0.633 |  Acc: 84.362,99.698,99.980,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=279 | Loss: 3.411 |  Acc: 63.930,73.720,77.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 0.633 |  Acc: 84.510,99.712,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=280 | Loss: 3.401 |  Acc: 63.850,73.770,77.930,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 0.630 |  Acc: 84.572,99.684,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=281 | Loss: 3.406 |  Acc: 63.820,73.770,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 0.632 |  Acc: 84.566,99.720,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=282 | Loss: 3.406 |  Acc: 63.850,73.790,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 0.632 |  Acc: 84.474,99.722,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=283 | Loss: 3.406 |  Acc: 63.960,73.580,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 0.633 |  Acc: 84.498,99.696,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=284 | Loss: 3.401 |  Acc: 63.890,73.730,77.920,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 0.633 |  Acc: 84.512,99.714,99.982,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=285 | Loss: 3.409 |  Acc: 63.760,73.810,77.900,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 0.632 |  Acc: 84.664,99.710,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=286 | Loss: 3.410 |  Acc: 63.930,73.540,77.730,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 0.633 |  Acc: 84.530,99.730,99.978,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=287 | Loss: 3.402 |  Acc: 63.680,73.890,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 0.633 |  Acc: 84.348,99.660,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=288 | Loss: 3.410 |  Acc: 63.900,73.580,77.820,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 0.634 |  Acc: 84.432,99.718,99.980,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=289 | Loss: 3.408 |  Acc: 63.930,73.630,77.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 0.631 |  Acc: 84.560,99.696,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=290 | Loss: 3.406 |  Acc: 63.820,73.660,77.850,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 0.631 |  Acc: 84.628,99.710,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=291 | Loss: 3.406 |  Acc: 63.800,73.700,77.890,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 0.630 |  Acc: 84.460,99.694,99.974,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=292 | Loss: 3.413 |  Acc: 63.890,73.680,77.700,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 0.630 |  Acc: 84.588,99.678,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=293 | Loss: 3.405 |  Acc: 63.910,73.820,77.760,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 0.633 |  Acc: 84.456,99.698,99.968,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=294 | Loss: 3.404 |  Acc: 64.040,73.600,77.840,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 0.632 |  Acc: 84.434,99.718,99.970,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=295 | Loss: 3.405 |  Acc: 63.960,73.790,77.860,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 0.630 |  Acc: 84.532,99.698,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=296 | Loss: 3.413 |  Acc: 63.870,73.790,77.790,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 0.629 |  Acc: 84.594,99.744,99.976,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=297 | Loss: 3.401 |  Acc: 63.930,73.770,77.880,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 0.631 |  Acc: 84.430,99.718,99.972,% | Adaptive Acc:0.000% | clf_exit:  
Testing: Epoch=298 | Loss: 3.404 |  Acc: 63.840,73.780,77.800,% | Adaptive Acc:0.000% | clf_exit:  

Training Setting: Namespace(adaptive=0, backend='modelF', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', ge=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 0.632 |  Acc: 84.574,99.708,99.972,% | Adaptive Acc:95.458% | clf_exit: 0.771 0.226 0.003 
Testing: Epoch=299 | Loss: 3.402 |  Acc: 63.830,73.660,77.880,% | Adaptive Acc:70.600% | clf_exit: 0.754 0.183 0.062 
